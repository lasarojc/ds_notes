# Coordena√ß√£o

Como visto na se√ß√£o sobre [Multiprograma√ß√£o](../Multiprograma√ß√£o concorrencia/concorrencia.md), diversas tarefas exigem coordena√ß√£o entre threads em uma aplica√ß√£o monol√≠tica em que se faz uso de concorr√™ncia para melhor uso de recursos computacionais, obten√ß√£o de melhor desempenho, e modulariza√ß√£o do c√≥digo. 

Sistemas distribu√≠dos levam concorr√™ncia a um novo patamar de complexidade, fazendo uso de m√∫ltiplos processos, cada um com possivelmente m√∫ltiplos *threads*, ainda por cima, espalhados geograficamente. 
Outras solu√ß√µes e abstra√ß√µes s√£o portanto necess√°rias.

## Exclus√£o M√∫tua
Um dos problemas enfrentados em sistemas que fazem uso de concorr√™ncia, distribu√≠dos ou n√£o, √© a exclus√£o m√∫tua.
Em um sistema monol√≠tico, uma vari√°vel global, um lock, ou outra primitiva de sincroniza√ß√£o podem ser usadas na sincroniza√ß√£o, mas em um sistema distribu√≠do, primitivas simples como estas provavelmente n√£o estar√£o dispon√≠veis ou o sistema ser√° muito restrito.
Como, ent√£o, controlar o acesso de m√∫ltiplos processos a um recurso compartilhado, garantindo que cada processo controla **exclusivamente** aquele recurso durante seu acesso?
Qualquer solu√ß√£o que se proponha a este problema de exclus√£o m√∫tua, precisa ter as propriedades 1, 2, 3, e, idealmente, a 4, a seguir:

!!!info "Exclus√£o M√∫tua"
    1. **exclus√£o m√∫tua** - somente um processo pode estar na **regi√£o cr√≠tica** em qualquer instante de tempo;
    2. **aus√™ncia de deadlocks** - se processos est√£o tentando acessar o recurso, ent√£o **algum processo deve conseguir acesso** em algum instante, dado que nenhum processo fique na regi√£o cr√≠tica indefinidamente;
    3. **n√£o-inani√ß√£o** - todos os processos interessados conseguem, em algum momento, acessar o recurso;
    4. **espera limitada** - o tempo de espera pelo recurso √© limitado.

H√° diversas solu√ß√µes para exclus√£o m√∫tua em sistemas distribu√≠dos, em diversos cen√°rios, com seus pr√≥s e contras.
Tr√™s das mais simples, e que ilustram o universo de solu√ß√µes s√£o via um processo centralizador, em um anel em que "a vez" √© circulada, e baseada em qu√≥runs.

### Coordenador 

Enquanto em um sistema monol√≠tico h√° um sistema operacional que  prov√™ abstra√ß√µes simples para os processos a serem coordenados, em um sistema distribu√≠do, n√£o h√° naturalmente tal entidade.
Uma poss√≠vel solu√ß√£o para o problema de exclus√£o m√∫tua em um ambiente distribu√≠do √© justamente dar um passo para tr√°s e introduzir um coordenador.

Nesta abordagem, os processos que precisam acessar a regi√£o cr√≠tica s√£o denominados **participantes** e um dos processos assume o papel de **coordenador**. √â poss√≠vel que um mesmo processo atue nos dois pap√©is sem nenhum preju√≠zo. Os processos executam o seguinte protocolo:

!!!example "Participante"
    1. Envia requisi√ß√£o de acesso ao coordenador
    2. Espera por resposta do coordenador
    3. Acessa o recurso
    4. Envia libera√ß√£o do recurso para o coordenador

!!!example "Coordenador"
    1. Inicializa recurso como livre
    2. Ao receber uma requisi√ß√£o, a enfileira
    3. Ao receber uma libera√ß√£o, marca o recurso como livre
    4. Sempre que recurso estiver marcado como livre **E** a fila n√£o estiver vazia
        1. remove primeiro processo da fila
        2. envia libera√ß√£o para processo removido
        3. marca o recurso como ocupado

O diagrama a seguir apresenta uma execu√ß√£o deste protocolo em um cen√°rio com tr√™s participantes.
O estado do coordenador mostra se o recurso est√° livre ou ocupado e quais processos esperam por permiss√£o de acesso.

```mermaid
sequenceDiagram
    participant Coordenador
    note over Coordenador: Recurso=livre/Fila = []
        Part1->>Coordenador: RequestAccess
    note over Coordenador: Recurso=livre/Fila = [Part1]
        Coordenador->>+Part1: ResponseOK
    note over Coordenador: Recurso=ocupado/Fila = []
        Part2->>Coordenador: RequestAccess
    note over Coordenador: Recurso=ocupado/Fila = [Part2]
        Part1->>-Coordenador: RequestFree
    note over Coordenador: Recurso=livre/Fila = [Part2]
        Coordenador->>Part1: ResponseFree
        Part3->>Coordenador: RequestAccess
    note over Coordenador: Recurso=livre/Fila = [Part2,Part3]
        Coordenador->>+Part2: ResponseOK
    note over Coordenador: Recurso=ocupado/Fila = [Part3]
        Part2->>-Coordenador: RequestFree
    note over Coordenador: Recurso=livre/Fila = [Part3]
        Coordenador->>Part2: ResponseFree
    note over Coordenador: Recurso=ocupado/Fila = []
        Coordenador->>+Part3: ResponseOK
        Part3->>-Coordenador: RequestFree
    note over Coordenador: Recurso=livre/Fila = []
        Coordenador->>Part3: ResponseFree
```

Este algoritmo satisfaz as caracter√≠sticas elencadas acima.   

* Exclus√£o m√∫tua - se o coordenador autoriza um participante X, somente ap√≥s o participante X liberar o recurso √© que outro participante poder√° obter nova autoriza√ß√£o.
* Aus√™ncia de deadlocks - Todo processo que requisitar o recurso, entrar√° em uma fila, em apenas uma posi√ß√£o; assim, a fila prover√° uma ordem total para os acessos, sem a possibilidade de circularidade nesta ordem.
* N√£o-inani√ß√£o - Dado que ningu√©m fura a fila e que a cada vez que o recurso √© liberado a fila anda, em algum momento a vez do processo chegar√°.
* Espera limitada - Dado que a posi√ß√£o na fila pode apenas decrementar, seria poss√≠vel estimar quanto tempo o participante precisa esperar para acessar o recurso.

Outra vantagem deste algoritmo √© sua simplicidade e, consequentemente, facilidade de implementa√ß√£o.
Contudo, este algoritmo tem tamb√©m desvantagens, por exemplo, se muitas requisi√ß√µes de acesso forem feitas, o coordenador pode ser sobrecarregado e se tornar um **gargalo** no acesso √† regi√£o cr√≠tica.

Mais s√©rio ainda √© a quest√£o de como lidar com falhas, por exemplo, se ou o coordenador ou o participante que detem o direito de acesso ao recurso para de funcionar,  ent√£o nenhum outro processo conseguir√° acesso.
Estes aspectos nos permitem mergulhar na √°rea de toler√¢ncia a falhas, e o faremos, mas mais tarde. 
Por enquanto, consideraremos toler√¢ncia a falhas de forma superficial, ap√≥s discutirmos outra abordagem.

### Anel

Nesta abordagem, os processos se organizam em um anel l√≥gico, com um processo antes e outro depois. 
Um dos processos √© iniciado com um *token* que d√° acesso ao recurso e o *token* √© passado adiante no anel; sempre que estiver de posse do token, o processo pode acessar o recurso. Ou seja, todos os participantes executam o seguinte protocolo:

!!!example "Participante"
    1. Ao receber o *token* de acesso, se quiser acessar o recurso, acessa.
    2. Envia o *token* para o pr√≥ximo n√≥ do anel.

O diagrama adiante mostra uma execu√ß√£o do algoritmo em que apenas os participantes 1 e 3 acessam o recurso.
  
```mermaid
sequenceDiagram
	Part1->>Part2: Permiss√£o de Acesso
	Part2->>Part3: Permiss√£o de Acesso
        note over Part3: Acessa o recurso
	Part3->>Part4: Permiss√£o de Acesso
	Part4->>Part1: Permiss√£o de Acesso
        note over Part1: Acessa o recurso
        Part1->>Part2: Permiss√£o de Acesso
	Part2->>Part3: Permiss√£o de Acesso
        note over Part3: Acessa o recurso
	Part3->>Part4: Permiss√£o de Acesso
	Part4->>Part1: Permiss√£o de Acesso
```

Como o algoritmo centralizado, o algoritmo do anel tamb√©m garante as propriedades 1, 2, 3 e 4, al√©m de ser f√°cil de implementar, testar e entender.
Diferente do algoritmo centralizado, o algoritmo do anel n√£o sofre com problemas de gargalo, pois nenhum processo precisa participar em todos os acessos, como o coordenador.
Contudo, o algoritmo do anel desperdi√ßa tempo passando o *token* para quem n√£o necessariamente quer acessar a regi√£o cr√≠tica.
Tamb√©m importante √© que este algoritmo tamb√©m sofre com falhas: se um participante falha enquanto com o *token*, levando-o para al√©m.

### Lidando com Falhas 
Em ambos os algoritmos, centralizado e do anel, se um processo falhar, o algoritmo pode ficar "travado". 
Vejamos alguns casos espec√≠ficos:

* No algoritmo centralizado, se o coordenador falha antes de liberar o acesso para algum processo, ele leva consigo a permiss√£o.
* Em ambos os algoritmos, se o processo acessando o recurso falha, a permiss√£o √© perdida e os demais processos sofrer√£o inani√ß√£o.
* No algoritmo do anel, se qualquer outro processo falha, o anel √© interrompido o anel n√£o conseguir√° circular.

Observe que nem falamos de falhas dos canais e j√° temos diversos cen√°rios a serem resolvidos, para os quais se lhes pedir uma solu√ß√£o, tenho certeza absoluta de que me oferecer√£o alguma baseada em *timeouts*.
Por exemplo, se o processo n√£o devolver a permiss√£o de acesso antes de que uma certa quantidade de tempo tenha passado, um *timeout*, ent√£o assuma que o mesmo parou de funcionar e n√£o voltar√° mais, e gere uma nova permiss√£o a ser passada a outros requisitantes.  Aplicada esta ideia do *timeout*  no algoritmo com coordenador, teremos o efeito ilustrado a seguir.

```mermaid
sequenceDiagram
    participant Coordenador
    note over Coordenador: Recurso=livre/Fila = []
        Part1->>Coordenador: RequestAccess
    note over Coordenador: Recurso=livre/Fila = [Part1]
        Coordenador->>+Part1: ResponseOK
    note over Coordenador: Recurso=ocupado/Fila = []
        Part2->>Coordenador: RequestAccess
    note over Coordenador: Recurso=ocupado/Fila = [Part2]
        Part1->>-Coordenador: RequestFree
    note over Coordenador: Recurso=livre/Fila = [Part2]
        Coordenador->>Part1: ResponseFree
        Part3->>Coordenador: RequestAccess
    note over Coordenador: Recurso=livre/Fila = [Part2,Part3]
        Coordenador->>Part2: ResponseOK
    activate Part2
    note over Coordenador: Recurso=ocupado/Fila = [Part3]

    note over Part2: üíÄ‚ò†Ô∏èüíÄ‚ò†Ô∏èüíÄ‚ò†Ô∏èüíÄ
    deactivate Part2
        Coordenador->>Coordenador: Timeout

    note over Coordenador: Recurso=livre/Fila = [Part3]
    note over Coordenador: Recurso=ocupado/Fila = []
        Coordenador->>+Part3: ResponseOK
        Part3->>-Coordenador: RequestFree
    note over Coordenador: Recurso=livre/Fila = []
        Coordenador->>Part3: ResponseFree
```

O problema desta e outras "solu√ß√µes" baseadas em *timeouts* est√° no **assumir que o processo parou de funcionar**, pois caso isso n√£o seja verdade, teremos agora duas autoriza√ß√µes ao mesmo tempo no sistema, podendo levar √† viola√ß√£o da propriedade de exclus√£o m√∫tua. 

```mermaid
sequenceDiagram
    participant Coordenador
    note over Coordenador: Recurso=livre/Fila = []
        Part1->>Coordenador: RequestAccess
    note over Coordenador: Recurso=livre/Fila = [Part1]
        Coordenador->>+Part1: ResponseOK
    note over Coordenador: Recurso=ocupado/Fila = []
        Part2->>Coordenador: RequestAccess
    note over Coordenador: Recurso=ocupado/Fila = [Part2]
        Part1->>-Coordenador: RequestFree
    note over Coordenador: Recurso=livre/Fila = [Part2]
        Coordenador->>Part1: ResponseFree
        Part3->>Coordenador: RequestAccess
    note over Coordenador: Recurso=livre/Fila = [Part2,Part3]
        Coordenador->>+Part2: ResponseOK
    note over Coordenador: Recurso=ocupado/Fila = [Part3]

        Coordenador->>Coordenador: Timeout

    note over Coordenador: Recurso=livre/Fila = [Part3]
    note over Coordenador: Recurso=ocupado/Fila = []
    rect rgb(200, 0, 0)
        Coordenador->>+Part3: ResponseOK

        Part2->>-Coordenador: RequestFree
        Part3->>-Coordenador: RequestFree
    end
    note over Coordenador: Recurso=livre/Fila = []
        Coordenador->>Part3: ResponseFree
```

Por mais que se ajuste o valor do temporizador, em um sistema distribu√≠do ass√≠ncrono, mesmo que aumentado com um rel√≥gio para medir a passagem do tempo local, o mesmo pode **sempre** estar errado. 

!!! warning "Impossibilidade de detec√ß√£o de falhas"
    Em um sistema distribu√≠do ass√≠ncrono, √© imposs√≠vel distinguir um processo falho de um processo lento.

Mais tarde discutiremos as implica√ß√µes desta impossibilidade. Por agora, tentemos responder √† seguinte quest√£o.

!!! question "Pergunta!"
    Qual deve ser um *timeout*  **razo√°vel** para o meu sistema?

A resposta depende de mais perguntas, como:

* Qual o custo $E$ de esperar por mais tempo?
* Qual o custo $C$ de cometer um engano?
* Qual a probabilidade $p$ de cometer um engano?

O custo esperado por causa dos erros, isto √©, a esperan√ßa matem√°tica da vari√°vel aleat√≥ria custo, √© menor que o custo de se esperar por mais tempo, isto √©, $C * p < E$?

Embora esta an√°lise possa ser feita para estes algoritmos, a verdade √© que s√£o realmente limitados e outras abordagens seriam melhor destino dos seus esfor√ßos.
Por exemplo, podemos partir para a an√°lise de algoritmos probabil√≠sticos, pois afinal, como disse certa vez Werner Vogels, CTO da Amazon

> Se o mundo √© probabil√≠stico, porqu√™ meus algoritmos devem ser determin√≠sticos?"

Uma abordagem probabil√≠stica interessante √© baseada em qu√≥runs.

### Qu√≥rum

De acordo com o [Dicion√°rio Priberam da L√≠ngua Portuguesa, consultado em 17-04-2019](https://dicionario.priberam.org/quorum), "qu√≥rum" √© o  
> N√∫mero de pessoas imprescind√≠vel para a realiza√ß√£o de algo.

Aqui, este este *algo* ser√° a libera√ß√£o de acesso ao recurso almejado pelos processos no sistema distribu√≠do.

Esta abordagem √© semelhante em v√°rios aspectos √† coordenada.
De fato, um dos pap√©is na abordagem √© o de coordenador, que executa o mesmo protocolo que antes.
Entretanto, em vez de apenas um coordenador no sistema, temos $n$, dos quais o participante precisa obter $m > n/2$ autoriza√ß√µes antes de acessar o recurso; $m$ √© o qu√≥rum do sistema.

!!! note "Qu√≥rum"
    * $n$ coordenadores.
    * $m > n/2$ coordenadores

J√° os demais participantes devem agora considerar todo o conjunto de coordenadores antes de assumir que tem acesso a um recurso. O algoritmo completo √© o seguinte:   

!!!example "Coordenador"
    1. Inicializa recurso como livre
    2. Ao receber uma requisi√ß√£o, a enfileira
    3. Ao receber uma libera√ß√£o
        1. se do processo a quem autorizou, marca o recurso como livre
        2. sen√£o e se de um processo na fila, remove o processo da fila[^id]
        3. sen√£o, ignore mensagem.
    4. Sempre que recurso estiver marcado como livre **E** a fila n√£o estiver vazia
        1. remove primeiro processo da fila
        2. envia libera√ß√£o para processo removido
        3. marca o recurso como ocupado

[^id]: para evitar que mensagens de requisi√ß√µes distintas do mesmo processo se confundam, √© √∫til identificar cada requisi√ß√£o, por exemplo, com um contador de requisi√ß√µes.

!!!example "Participante"
    1. Envia requisi√ß√£o de acesso aos $n$ coordenadores
    2. Espera por resposta de $m$ coordenadores
    3. Acessa o recurso
    4. Envia libera√ß√£o do recurso para os $n$ coordenadores


Vejamos uma execu√ß√£o bem sucedida destes algoritmo, com $n=3$ e $m=2$.

```mermaid
sequenceDiagram
    participant Coord1
    participant Coord2
    participant Coord3
    note over Coord1,Coord3: Recurso=livre/Fila = []
        Part1->>Coord1: RequestAccess
        Part1->>Coord2: RequestAccess

        Part2->>Coord1: RequestAccess
        Part2->>Coord2: RequestAccess

        Part2->>Coord3: RequestAccess

        Part1->>Coord3: RequestAccess

    note over Coord1,Coord2: Recurso=ocupado/Fila = [Part2]
        Coord1->>Part1: ResponseOK
        Coord2->>+Part1: ResponseOK


    note over Coord3: Recurso=ocupado/Fila = [Part1]
        Coord3->>Part2: ResponseOK
    
    Part1->>-Coord1: RequestFree
    Part1->>Coord2: RequestFree
    Part1->>Coord3: RequestFree

    note over Coord3: Recurso=ocupado/Fila = []

    note over Coord1,Coord2: Recurso=ocupado/Fila = []
        Coord1->>+Part2: ResponseOK
        Coord2->>Part2: ResponseOK

    Part2->>-Coord1: RequestFree
    Part2->>Coord2: RequestFree
    Part2->>Coord3: RequestFree

    note over Coord1,Coord3: Recurso=livre/Fila = []
```


Para tornamos o problema mais interessante e demonstrar o potencial deste algoritmo, consideremos que as autoriza√ß√µes s√£o armazenadas somente em mem√≥ria, e que coordenadores, ao falhar e ent√£o resumir suas atividades, esquecem das autoriza√ß√µes j√° atribu√≠das.

!!!warning "Perda de mem√≥ria"
    Quando um coordenador falha, esquece que deu ok e reinicia seu estado.



Este algoritmo √© bom? Suponhamos o seguinte cen√°rio:

* Coordenadores = {Coord1,Coord2,Coord3}
* $n = 3$
* $m = 2$
* Participante Part1 consegue autoriza√ß√£o de {Coord1,Coord2} e entra na regi√£o cr√≠tica.
* Coordenador Coord2 falha e se recupera
* Participante Part2 consegue autoriza√ß√£o de {Coord2,Coord3} e entra na regi√£o cr√≠tica.

```mermaid
sequenceDiagram
    participant Coord1
    participant Coord2
    participant Coord3
    note over Coord1,Coord3: Recurso=livre/Fila = []
        Part1->>Coord1: RequestAccess
        Part1->>Coord2: RequestAccess

        Part2->>Coord1: RequestAccess
        Part1->>Coord3: RequestAccess
        Part2->>Coord3: RequestAccess

    note over Coord1,Coord2: Recurso=livre/Fila = [Part1,Part2]
    note over Coord3: Recurso=livre/Fila = [Part2,Part1]


    note over Coord1,Coord2: Recurso=ocupado/Fila = [Part2]
    note over Coord3: Recurso=ocupado/Fila = [Part1]

        Coord1->>Part1: ResponseOK
        Coord2->>+Part1: ResponseOK
        Coord3->>Part2: ResponseOK

    note over Coord2: üíÄ‚ò†Ô∏èüíÄ‚ò†Ô∏èüíÄ‚ò†Ô∏èüíÄ
    note over Coord2: Recurso=livre/Fila = []

        Part2->>Coord2: RequestAccess
    note over Coord2: Recurso=livre/Fila = [Part2]
    note over Coord2: Recurso=livre/Fila = []
rect rgb(200, 0, 0)
        Coord2->>+Part2: ResponseOk


        Part1->>-Coord1: RequestFree
end
        Part1->>Coord2: RequestFree
        Part1->>Coord3: RequestFree

        Part2->>-Coord1: RequestFree
        Part2->>Coord2: RequestFree
        Part2->>Coord3: RequestFree
```

Neste cen√°rio, a propriedade de **Exclus√£o M√∫tua** √© violada. 
Isto porqu√™, dados os dois qu√≥runs, todos os processos na interse√ß√£o foram reinicidaos.
Mas de forma geral, qual a probabilidade de isso acontecer? 
Ou seja, dados dois qu√≥runs, de tamanho $m$, que se sobrep√µem em $k$ processos, qual a probabilidade $P_v$ de que os $k$ processos na interse√ß√£o sejam reiniciados e levem √† viola√ß√£o?

![Quoruns](drawings/quorum_k.drawio#0)

Seja a $P$ a probabilidade de **um coordenador em espec√≠fico falhar** e se recuperar dentro de uma janela de tempo $\delta t$. Temos

* Probabilidade de falha de **exatamente 1** coordenador: $P^1(1-P)^{n-1}$
* Probabilidade de **$k$ coordenadores** falharem: $P^k(1-P)^{n-k}$
* Probabilidade de quaisquer $k$ em $m$ coordenadores falharem: $\binom{m}{k} P^k(1-P)^{m-k}$		

Mas qual √© o tamanho $k$ da interse√ß√£o?

* $\left| A \cup B\right| = \left| A \right| + \left|B\right| - \left| A \cap B \right| \Rightarrow n = m + m - k$
* $\left| A \cap B \right| = \left| A \right| + \left|B\right| - \left| A \cup B\right| \Rightarrow k = m + m - n = 2m - n$

At√© agora consideramos que a $k$ corresponde √† cardinalidade da interse√ß√£o dos dois qu√≥runs, mas se mais do que a interse√ß√£o forem reiniciados, tamb√©m teremos problemas. Assim, se $k$ assume qualquer valor entre o tamanho da interse√ß√£o e o n√∫mero total de coordenadores, teremos problemas. 

* Probabilidade de quaisquer $k$ em $m$ coordenadores falharem, para qualquer $k$ variando de $2m-n$ a $n$: $P_v = \sum_{k=2m-n}^n \binom{m}{k} P^k(1-P)^{m-k}$


Para facilitar o entendimento desta grandeza, considere o exemplo:

* $P=0.0001$ (1 minuto a cada 10 dias)
* $n = 32$
* $m = 0.75n$
* $P_v < 10^{-40}$ ([Curiosidade sobre $10^{40}$](https://cosmosmagazine.com/mathematics/the-big-baffling-number-at-the-heart-of-a-cosmic-coincidence))

A probabilidade de viola√ß√£o da exclus√£o m√∫tua, neste caso, √© muito pequena, a despeito de suportar falhas dos coordenadores. 

!!! note "Pr√≥"
    * Tolera falhas de coordenadores, com probabilidade controlada de viola√ß√£o de exclus√£o m√∫tua.

Mas e as outras propriedades desej√°veis do algoritmo de exclus√£o m√∫tua, s√£o alcan√ßadas? Relembrando:

!!! note "Contras"
    * Exclus√£o M√∫tua probabil√≠stica: $1 - P_v$
    * N√£o-inani√ß√£o
        * E se cada participante obtiver o ok de um coordenador?
        * Temporizador para quebrar o *deadlock*?
    * Espera limitada
        * Aborts podem levar a espera infinita.

Assim, este agoritmo tamb√©m pode n√£o ser adequado para certas situa√ß√µes. Vamos tentar reacessar os problemas da primeira abordagem.
Por um lado, o uso de um l√≠der para coordenar a√ß√µes em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto √∫nico de falha, como no algoritmo de exclus√£o m√∫tua centralizado.
Mas e se substitu√≠ssemos o coordenador no caso de falhas? Este √© o problema conhecido como elei√ß√£o de l√≠deres.

???bug "TODO"
    * Maekawa - Diminui n√∫mero de votos necess√°rios ([descri√ß√£o](https://www.geeksforgeeks.org/maekawas-algorithm-for-mutual-exclusion-in-distributed-system/?ref=rp))
    * Lamport - Usa rel√≥gios l√≥gicos, mas √© poss√≠vel entender sem este background ([descri√ßao](https://www.geeksforgeeks.org/lamports-algorithm-for-mutual-exclusion-in-distributed-system/))
    * Ricart-Agrawala - Melhora algoritmo de Lamport ([descri√ß√£o](https://www.geeksforgeeks.org/ricart-agrawala-algorithm-in-mutual-exclusion-in-distributed-system/?ref=rp))
    * [Distributed-Mutual-Exclusion-slides](https://www.cs.cmu.edu/~dga/15-440/F09/lectures/Distributed-Mutual-Exclusion-slides.pdf)

## Elei√ß√£o de L√≠deres

O problema da escolha de um processo centralizador, ou l√≠der, pode ser posto informalmente como o procedimento pelo qual **um processo √© escolhido** dentre os demais processos, sendo que o **processo escolhido √© ciente da escolha** e **todos os demais processos o identificam como eleito**. Uma **nova elei√ß√£o** deve acontecer sempre que o l√≠der se tornar **indispon√≠vel**.
Formalmente, um algoritmo de elei√ß√£o de l√≠deres deve satisfazer as seguintes condi√ß√µes.

!!!note "Elei√ß√£o de L√≠deres[^guptaetal]"
     * Termina√ß√£o: algum processo deve se considerar l√≠der em algum momento.
     * Unicidade: somente um processo se considera l√≠der.
     * Acordo: todos os outros processos sabem quem foi eleito l√≠der.

[^guptaetal]:[A Probabilistically Correct Leader Election Protocol for Large Groups](https://www.cs.cornell.edu/home/rvr/papers/ProbLeaderElection.pdf)





Para entendermos melhor o problema, tentemos desenvolver um protocolo simples para escolhermos um l√≠der, por exemplo, em sua turma da disciplina de Sistemas Distribu√≠dos. Vejamos algumas quest√µes importantes.

* Candidatos: s√£o todos os membros eleg√≠veis ou apenas um subconjunto dos mesmos?
* Comunica√ß√£o: todos se conhecem e se falam diretamente ou h√° grupos incomunic√°veis dentro da turma?
* Estabilidade: de que adianta eleger um dos colegas se frequentemente falta n√£o est√° presente quando necess√°rio?

Em termos computacionais, estas quest√µes s√£o relevantes pois todos os processos **n√£o** nascem iguais; alguns residem em m√°quinas com mais mem√≥ria, mais poder de processamento, melhor conex√£o com o resto do mundo ou maior grau de conectividade. Talvez este processo seja um l√≠der mais √∫til que os demais.
Al√©m disso, se o processo est√° frequentemente desconectado, mesmo que bem servido de recursos, n√£o ser√° um bom l√≠der.

Ainda que assumamos um conjunto de processos indiferenci√°veis entre si, com acesso equivalente a recursos e que estejam sempre dispon√≠ves, ou exatamente por isso, temos  um problem mais fundamental para resolver: para eleger um l√≠der, precisamos diferenciar processos.
Dentro de uma √∫nica m√°quina, identificamos processos facilmente usando seu **PID**, ou *process id*, um inteiro associado a cada processo instanciado pelo sistema operacional; o PID √© v√°lido enquanto o processo estiver executando e pode ser reciclado uma vez que o processo para de executar, o que pode ser um problema. Al√©m disso, se o *host* √© reiniciado, os PID tamb√©m s√£o, e portanto esta identifica√ß√£o n√£o √© duradoura. Mais importante, o PID s√≥ faz sentido dentro de uma √∫nica m√°quina e n√£o em um sistema distribu√≠do.

Se apenas uma inst√¢ncia do processo executa em um mesmo *host*, ent√£o o identificador do *host* (e.g., endere√ßo IP) em si √© suficiente e, de fato, comumente utilizado. 
Se mais de um processo executa no mesmo *host*, ent√£o cabe ao desenvolvedor criar um esquema que permita diferenciar os processos, e n√£o precisa ser nada complicado; pode ser apenas um **par√¢metro** passado na inicializa√ß√£o do processo ou a combina√ß√£o **IP/porta**.

Assumindo que um esquema de nomea√ß√£o est√° dispon√≠vel e que todos os processos se conhecem, voltemos ao problema de eleger um l√≠der para sua turma.
Uma abordagem que pode funcionar √© colocar todos os candidatos para brigar e quem sobrar em p√© no final, √© o novo l√≠der.

[![](images/octogono.jpg)](https://esportes.umcomo.com.br/artigo/como-construir-um-octogono-de-mma-21408.html)

A despeito desta op√ß√£o gerar um l√≠der n√£o muito popular, o algoritmo do brig√£o √© um cl√°ssico.


### Algoritmo do Brig√£o (*Bully*)
No algoritmo do brig√£o, alguma **caracter√≠sticas compar√°vel** dos processos √© escolhida e aquele processo funcional com o valor de tal caracter√≠stica mais vantajoso para um l√≠der √© escolhido como tal.
Por exemplo, pode ser vantajoso ter um l√≠der com maior quantidade de mem√≥ria, frequ√™ncia da CPU ou largura de banda da conex√£o com a Internet; no caso de empate, o identificador do processo pode ser usado para gerar uma ordem total entre os processos.

Para simplificar, vamos assumir que o identificador do processo reflete as qualidades do mesmo para a lideran√ßa, tal que o processo com maior identificador seja o melhor candidato. Os maiores processos, os "brig√µes", eliminam os processos menores da competi√ß√£o, sempre que uma elei√ß√£o acontecer. 
O algoritmo √© apresentado a seguir, onde $p$ e $q$ s√£o usados para representar tanto identificadores de processos quando os processos em si.

!!!example "Algoritmo do Brig√£o"
    * Quando $p$ suspeita que o l√≠der n√£o est√° presente (muito tempo se receber mensagens do mesmo)
        * $p$ envia mensagem (ELEICAO,$p$) para todos os processos com identificador maior que $p$
        * Inicia temporizador de respostas
    * Quando temporizador de respostas expira
        * Envia (COORD,$p$) para todos os processos
    * Quando recebe (Ok,$p$)
        * Para temporizador de resposta
	* Quando $p$ recebe (ELEICAO,$q$), $q < p$
        * Envia (OK,$q$)
	* Quando um processo falho se recupera
        * Inicia uma elei√ß√£o

Observe como o algoritmo foi descrito em termos de **eventos** e n√£o de forma sequencial. Este tipo de especifica√ß√£o √© comum para algoritmos paralelos e distribu√≠dos, pois n√£o h√° uma sequ√™ncia pr√©-estabelecida de passos a serem executados por todos os processos, apenas alguns pontos de coordena√ß√£o.
No exemplo a seguir, temos 5 processos, com identificadores de 1 a 5, passando por 7 passos at√© que a elei√ß√£o se complete.
Observe que os processos n√£o sabem a priori como os eventos aconteceram e apenas reagem aos **eventos** de **recep√ß√£o de mensagens** e **expira√ß√£o de temporizadores**.

1. o l√≠der j√° √© o processo 5 (em rosa).
2. os processos 2 e 3 (amarelo) se "cansaram" de esperar por 5, que falhou (em cinza, e se candidataram a l√≠der, enviando (ELEICAO,2) e (ELEICAO,3), respectivamente, (verde).
3. 4 responde a 2 a 3 com (OK,2) e (OK,3) como resposta a 2 e 3, respectivamente, e 3 envia (OK,2) para 2.
4. 1 se candidata com enviando (ELEICAO,1).
5. 2, 3 e 4 respondem com (OK,1).
6. 4 se candidata enviando (ELEICAO,4) para 5, que n√£o responde, j√° que est√° falho.
7. 4 se declara l√≠der e envia (COORD,4) a todos os processos. 

![[Bully algorithm](https://my.oschina.net/juliashine/blog/88173)](./images/bully.png)


Como j√° discutido antes, a escolha do valor temporizador √© fundamental para o bom funcionamento do algoritmo.
Se o temporizador usado pelos processos para esperar pelo l√≠der for ajustado de forma agressiva, frequentemente ser√£o iniciadas elei√ß√µes mesmo que o l√≠der n√£o tenha falhado.
J√° se o valor do temporizador for muito grande, o sistema **demorar√° a eleger um novo l√≠der**.
Da mesma forma, se o tempo esperado por um candidato antes de se declarar l√≠der for muito curto, **mais de um processo pode se declarar l√≠der**, uma situa√ß√£o conhecida como *split-brain*.

Idealmente, um processo deveria esperar por outro enquanto o outro estiver apto a responder, mas isso requer saber quando o outro processo n√£o est√° mais apto, isto √©, falhou.
Como identificar exatamente quando isso aconteceu √© imposs√≠vel em sistemas distribu√≠dos ass√≠ncronos, o algoritmo do brig√£o n√£o resolve o problema neste ambiente.

![Why you bully?](./images/why-you-bully-meme.jpg)  

Mas se delimitarmos melhor o ambiente, podemos chegar a solu√ß√µes melhores.


### Algoritmos em An√©is

Consideremos processos organizados em um anel l√≥gico em que processos troquem mensagens apenas com processos √† "esquerda" e √† "direita".
Considere tamb√©m que todos os processos s√£o exatamente id√™nticos, inclusive n√£o possuindo identificadores pr√≥prios.
Suponha o seguinte algoritmo de elei√ß√£o neste anel, em que um processo inicialmente Seguidor se torna Candidato, ent√£o se declara Eleito, avisa a seus pares e, finalmente, se declara Empossado.

!!!example "Algoritmo do Anel 1"
     * Organize os n√≥s em um anel l√≥gico
     * $C \gets$ Seguidor
     * Quando um processo acha que o l√≠der est√° morto
          * $C \gets$ Candidato
          * Envia (VoteEmMim) para "a direita" no anel.
     * Quando um processo recebe (VoteEmMim)
          * Se $C =$ Seguidor 
              * envia (VoteEmMim) para a direita
          * Se $C =$ Candidato 
              * $C \gets$ Eleito
              * envia (HabemosLeader) para a direita
     * Quando um processo recebe (HabemosLeader)
          * Se $C =$ Seguidor
              * envia (HabemosLeader) para a direita
          * Se $C =$ Eleito 
              * $C \gets$ Empossado

Imagine um cen√°rio com dois processos, como na imagem a seguir. 
Os nomes dos processos s√£o apenas para facilitar o entendimento do fluxo dem mensagens e n√£o est√£o acess√≠veis aos processos.   
![](drawings/anel1.drawio)   
Executando o algoritmo Anel 1, os processos enviam ($\rightarrow$) e recebem ($\leftarrow$) as seguintes mensagens e ajustam $C$ da seguinte forma.

| 1 | 2 |
|----------|--------|
| $C \gets$ Seguidor  | $C \gets$ Seguidor |
| $C \gets$ Candidato |  |
| (VoteEmMim) $\rightarrow$| |
| | (VoteEmMim) $\leftarrow$|
| | (VoteEmMim) $\rightarrow$|
| (VoteEmMim) $\leftarrow$| |
| $C \gets$ Eleito |  |
| (HabemosLider) $\rightarrow$| |
| | (HabemosLider) $\leftarrow$|
| | (HabemosLider) $\rightarrow$|
| (HabemosLider) $\leftarrow$| |
| $C \gets$ Empossado |  |

Agora imagine que por um acaso, tanto processo 1 quanto o 2 se candidatassem ao mesmo tempo.

| 1 | 2 |
|----------|--------|
| $C \gets$ Seguidor  | $C \gets$ Seguidor |
| $C \gets$ Candidato | $C \gets$ Candidato |
| (VoteEmMim) $\rightarrow$| (VoteEmMim) $\rightarrow$|
| (VoteEmMim) $\leftarrow$ | (VoteEmMim) $\leftarrow$|
| $C \gets$ Eleito | $C \gets$ Eleito |
| (HabemosLider) $\rightarrow$| (HabemosLider) $\rightarrow$ |
| (HabemosLider) $\leftarrow$ | (HabemosLider) $\leftarrow$|
| $C \gets$ Empossado | $C \gets$ Empossado |

Como n√£o h√° nada que diferencie os processos entre si, este cen√°rio √© perfeitamente v√°lido, e se no primeiro cen√°rio o algoritmo estava correto ao eleger o processo 1, ent√£o no segundo cen√°rio o 1 tamb√©m deve ser eleito, j√° que a sequ√™ncia de evento observadas √© exatamente a mesma.
Mas o processo 2 tamb√©m v√™ a mesma sequ√™ncia, ent√£o tamb√©m deve ser eleito.
Assim, violamos a propriedade da Unicidade.

Para quebrar essa simetria entre os processo, podemos permitir que saibam seus identificadores.
No algoritmo seguinte, permitimos que os processos conhe√ßam seus identificadores e um processo que suspeite do l√≠der atual, envia uma mensagem no anel para coletar os identificadores de todos os processos.

!!!example "Algoritmo do Anel 2"
     * Organize os n√≥s em um anel l√≥gico
     * Quando $p$ acha que o l√≠der est√° morto:
          * Envia mensagem [$p$] "√† direita".
     * Quando $p$ recebe $l$
          * Se $p \not \in l$
              * Envia  $[p:l]$ para a direita.
          * Se $p \in l$
              *  Escolhe menor id em $l$ como l√≠der.

Este algoritmo envia at√© $n^2$ mensagens, se todos iniciarem a elei√ß√£o ao mesmo tempo, e as mensagens crescem at√© o tamanho $n$.
O algoritmo de Chang e Robert[^changrobert] limita o tamanho das mensagens ao pr√©-selecionar candidatos vi√°veis.

[^changrobert]: [An improved algorithm for decentralized extrema-finding in circular configurations of processes](https://dl.acm.org/doi/10.1145/359104.359108).

!!!note "Algoritmo de Chang e Robert"
        * Organize os n√≥s em um anel l√≥gico
        * Quando $p$ acha que o l√≠der est√° morto:
            * Envia mensagem $(p)$ √† direita
        * Quando $p$ recebe $(q)$
            * Se $p = q$
                * $p$ se declara l√≠der
            * Sen√£o e se $q > p$
                * Envia $(q)$ para a direita.

Neste algoritmo, todas as mensagens tem tamanho $O(1)$ e somente uma mensagem d√° uma volta completa do anel; todas as outras s√£o descartadas no meio do caminho.
Apesar disso, pode-se demonstrar que o pior caso em termos de n√∫mero de mensagens do algoritmo at√© que algu√©m se declare l√≠der √© $O(n^2)$.

!!!exercise "Exerc√≠cio: Quantidade de mensagens"
    * O pior caso em termos de n√∫mero de mensagens at√© que algu√©m seja eleito √© $O(n^2)$. Descreva como os n√≥s devem estar organizados para que esta situa√ß√£o ocorra.
    * Observe que no algoritmo um processo apenas se "declara l√≠der", mas os outros n√£o necessariamente ficam sabendo disso. Como voc√™ o corrigiria para que terminasse?

Diversos outros algoritmos existem para a topologia em anel. O algoritmo de Franklin √© um dos que prop√µe melhorias para reduzir quantidade de mensagens usadas na elei√ß√£o.
Ele faz isso em rodadas, comparando identificadores com outros processos ativos tanto √† esquerda quanto √† direita e desativando os processos n√£o vi√°veis.

!!!note "Algoritmo de Franklin"
    * Organize os n√≥s em um anel l√≥gico
    * Ativo $\gets 1$
    * Quando $p$ acha que o l√≠der est√° morto e se Ativo$ = 1$:
        * Envia mensagem $(p)$ √† direita e √† esquerda
    * Quando $p$ recebe $e$ e $d$, da esquerda e da direita, respectivamente:
        * Se Ativo $=1$
            * Se $max(e,d) < p$
                * Envia mensagem $p$ √† direita e √† esquerda
            * Se $max(q,r) > p$
                * Ativo $\gets 0$
                * Envia mensagem $-p$ √† direita e √† esquerda
            * Se $max(q,r) = p$
                * $p$ se declara l√≠der.
        * Se Ativo $=0$
            * Repassa cada messagem para o outro lado.

No exemplo na figura, os n√≥s brancos s√£o ativos e os amarelos inativos. 
Observe o papel do n√≥ no centro, supondo que tem o maior identificador entre todos os processos. 
Inicialmente ele envia as mensagens em verde para os lados, que levam seus vizinhos imediatos a se inativarem.
Na segunda rodada, as mensagens s√£o repassadas para os vizinhos dos vizinhos, que tamb√©m se inativam.

![Algoritmo de Franklin](drawings/leaderelection.drawio#0)

Observe o seguinte:

* Em cada fase, para qualquer par de vizinhos ativos, pelos um dos dois √© inativado e, portanto, o n√∫mero de ativos cai pela metade; logo h√° no m√°ximo $O(log n)$ fases.
* Na primeira fase, cada processo ativo leva a $4$ mensagens serem enviadas na rede (sem nenhuma otimiza√ß√£o). Dado que s√£o $n$ processos, temos $4n$ mensagens, $O(n)$
* Na segunda fase, cada processo ativo leva a 8 mensagens. Contudo, metade dos processos, pelo menos, foram inativados na primeira fase. Logo, temos $8n \times n/2, O(n)$
* Assim, no m√°ximo $O(n log n)$ mensagens s√£o enviadas em uma execu√ß√£o do algoritmo.


### Algoritmo do YoYo 
Saindo da topologia em anel, vejamos o algoritmo do Yoyo, que funciona em qualquer topologia conexa, mesmo se processos n√£o puderem se falar diretamente.
Inicialmente as arestas do formado pelos processos e seus canais de comunica√ß√£o s√£o n√£o direcionadas, mas na medida em que o protocolo √© executado,  as arestas s√£o marcadas como tendo um ou outro sentido.
Esta marca√ß√£o √© apenas l√≥gica e mensagens fluem em ambos os sentidos.
De acordo com o tipo de arestas que um processo tem, ele √© classificado como um de tr√™s tipos: 

* Fonte (source) - processo que s√≥ tem arestas de sa√≠da
* Vertedouro (sink) - processo que s√≥ tem arestas de chegada
* Interno - processo que tem arestas de chegada e de sa√≠da

O algoritmo executa em duas fases. Na primera, cada processo marca sua arestas como apondando para o maior dentre si pr√≥prio e seus vizinhos.
Na segunda fase, mensagens "v√£o e voltam", o que d√° o nome ao algoritmo.
Na "ida", as mensagens v√£o das fontes para os vertedouros, que identificam quais fontes tem os menores identificadores e sinalizam para que continuem fontes na pr√≥xima etapa com mensagens de volta.
As mensagens de volta reordenam as arestas para garantir este comportamento.
Vejamos o algoritmo em mais detalhes.

!!!note "Algoritmo do YoYo"
	* Fase 1
		* $p$ envia seu identificador para seus vizinhos.
		* Quando $p$ recebe $q$
			* Se $p>q$
                * Marca a aresta em que recebeu $q$ como sendo de chegada ($p\leftarrow q$)
			* Sen√£o
                * Marca a aresta em que recebeu $q$ como sendo de sa√≠da ($q\leftarrow p$)
	* Fase 2
        * Se $p$ √© uma **fonte**
            * $p$ envia seu identificador em todas as suas arestas de sa√≠da.
            * Quando $p$ receber $S$ ou $N$ em todas as suas arestas de sa√≠da
                * Se recebeu apenas $S$
                    * Executa fase 2 novamente

        * Se $p$ √© um **n√≥ interno**
            * Quando $p$ receber identificadores em todas as suas arestas de entrada
                * escolhe o menor id recebido $m$
                * envia $m$ em todas as suas arestas de sa√≠da
            * Quando $p$ recebeu $S$ ou $N$ em todas as suas arestas de sa√≠da
                * Se recebeu algum $S$
                    * envia $S$ para vizinhos de onde recebeu $m$
                    * envia $N$ para vizinhos de onde recebeu $m' \neq m$
                * Se n√£o recebeu $S$
                    * envia $N$ para vizinhos de onde recebeu algum id.

        * Se $p$ √© um **vertedouro**
            * Quando $p$ receber identificadores em todas as suas arestas de entrada
                * escolhe o menor id recebido $m$
                * envia $S$ para vizinhos de onde recebeu $m$
                * envia $N$ para vizinhos de onde recebeu $m' \neq m$
	    
	    * N inverte a dire√ß√£o das arestas em que trafega.

[Fonte](https://en.wikipedia.org/wiki/Leader_election)

Veja um exemplo com 3 processos em destaque, uma fonte, um interno e um vertedouro.

![Algoritmo do YoYo](drawings/leaderelection.drawio#1)

Veja o seguinte exemplo, em que cada figura mostra um est√°gio da resolu√ß√£o do problema de elei√ß√£o de l√≠deres.

* a) A rede em seu estado inicial.
* b) Rede orientada pela primera fase
* c) Propaga√ß√£o de Fontes
* d) Propaga√ß√£o de Vertedouros
* e) Inativa√ß√£o dos vertedouros

Exemplo: 
![[Fonte: Hemis62 - Own work, CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=36757409)](./images/yoyo.png)



Embora interessante, este algoritmo tamb√©m tem problemas, sendo um dos mais cr√≠ticos a forma de lidar com falhas, mesmo sem considerar falhas de processos.
Suponha que o canal de comunica√ß√£o entre os processos 2 e 10 pare de funcionar. O que acontecer√°?
Esta √© uma situa√ß√£o que denominamos **particionamento** da rede e que neste caso levar√° a duas elei√ß√µes concorrentes acontecerem e, consequentemente, a dois l√≠deres sendo eleitos, o que √© conhecido na √°rea como ***split-brain***.
Vejamos esta e outras situa√ß√µes problem√°ticas em elei√ß√£o de l√≠deres.


### Quest√µes importantes

#### *Split-brain*
Se o algoritmo viola a propridade de unicidade, ent√£o fica com *split-brain*, em que parte da rede v√™ um processo como l√≠der e parte v√™ outro.
Se o l√≠der √© o respons√°vel por coordenar o acesso a uma regi√£o cr√≠tica, como visto no algoritmo coordenado de exclus√£o m√∫tua, ent√£o ter dois l√≠deres poder√° levar a dois processos na regi√£o cr√≠tica e portanto viola√ß√£o da exclus√£o m√∫tua. 

Uma das formas de evitar *split-brain* √© atribuir um **"peso"** para cada processo e s√≥ aceitar que um l√≠der seja declarado se o mesmo seus votos carregarem mais da metade do peso do sistema.
Ainda assim, temos problemas, pois √© necess√°rio que rodadas sucessivas do algoritmo invalidem as elei√ß√µes anteriores.
O algoritmo Raft de difus√£o at√¥mica, que estudaremos adiante, define mandatos e garante, com pesos, que somente um l√≠der existe em cada mandato. Devido √† natureza ass√≠ncrona do sistema, processos podem se achar em mandatos distintos e, por isso, o mandato √© associado a todas as comunica√ß√µes; mensagens recebidas de mandatos anteriores s√£o sumariamente descartadas.

Mas por qu√™ precisamos de mandatos sucessivos? Para substituir um l√≠der que tenha falhado. O que nos leva a outros dois problemas, o da detec√ß√£o de falhas e o da estabilidade do l√≠der.

#### Estabilidade
Dizemos que um algoritmo de elei√ß√£o de l√≠deres √© est√°vel se uma vez que um l√≠der √© eleito, uma nova elei√ß√£o s√≥ acontece se o l√≠der falha.
Considere o algoritmo do brig√£o. Imagine, no exemplo apresentado, que o processo 5 teve problemas de comunica√ß√£o e foi percebido como falho pelos demais.  Neste caso, o 4 seria eleito l√≠der.
Mas se o problema que aflige 5 √© tempor√°rio, 5 voltar√° e executar√° nova elei√ß√£o, tornando-se l√≠der novamente. Se este cen√°rio se repente indefinidamente, o sistema poder√° ser seriamente comprometido em seu desempenho.

Uma vers√£o est√°vel do algoritmo tentaria, por exemplo, associar ao peso do processo o tempo de exe√ß√£o ininterrupta do mesmo. Assim, quanto mais tempo um processo execute, maior ser√° seu peso e sua capacidade de manter a lideran√ßa. 
Se o mesmo falhar, ent√£o seu peso ser√° drasticamente reduzido e suas chances de ser eleito l√≠der reduzidas temporariamente.

Observe que os problemas enfrentados s√£o ligados √† detec√ß√£o e contorna√ß√£o de falhas.

#### Detec√ß√£o de falhas
Como j√° mencionado antes, detec√ß√£o de falhas √© o mecanismo pelo qual um processo monitora e percebe se outro falhou.
Pensemos em como um processo monitora o outro em um sitema distribu√≠do. Claramente, por meio de troca de mensagens e temporizadores.
Mas se estamos falando de sistemas distribu√≠dos ass√≠ncronos, ent√£o mensagens podem ser atrasadas indefinidamente ou rel√≥gios podem ser atrasados, ent√£o n√£o se pode confiar na falta de recep√ß√£o de uma mensagem como garantia de que um processo parou de funcionar.
Aprofundemo-nos nos pr√≥ximos cap√≠tulo nos conceitos de tempo e toler√¢ncia a falhas, mas enquanto isso, fiquemos com o seguinte resultado.

!!!note "Detec√ß√£o de falhas"
    * Detec√ß√£o de falhas perfeita √© imposs√≠vel...
    * em sistemas distribu√≠dos ass√≠ncronos (Internet)
    * sujeitos √† parti√ß√µes (Internet)
    * com requisitos de disponibilidade total.


