<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Estruturas de Dados para SD - Sistemas Distribuídos</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Estruturas de Dados para SD";
    var mkdocs_page_input_path = "p2p/2_ed_sd.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Sistemas Distribuídos</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Prólogo</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../intro/">Introdução</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Sistemas Distribuídos</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
    
    <li>Estruturas de Dados para SD</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p>Qualquer que seja a escolha de algoritmo para fazer o particionamento dos dados entre servidores, sobra ainda a questão de como manipular os dados dentro do servidor.
Idealmente, toda operação seria executada a partir da memória principal, tendo assim a menor latência possível.
Contudo, para que se tenha também durabilidade das operações executadas, para que os dados manipulados sobrevivam a reinicializações do servidor, intencionais ou não, é preciso armazenar os dados em <strong>memória estável</strong>, da qual a mais comum é são os <strong>discos rígidos</strong>.</p>
<p>É notório que escritas em disco são muito mais lentas que em memória principal, mas o que exatamente é lento no acesso ao disco?
Essencialmente, o posicionamento da cabeca de leitura/escrita na trilha correta do disco, pois esta operação é mecânica.
Por esta razão, acessos aleatórios são mais custosos que acessos sequenciais, pois neste o custo de posicionamento é pago apenas uma vez.
Por este motivo, muitos bancos de dados, especialmente DHT pois tem seu uso focado em quantidades muito grandes de dados, gerados e acessados com grande velocidade, tentam acessar o disco sempre de forma sequencial.
Alguns bancos de dados, como o Cassandra, armazenam os dados na forma de uma <em>Log Structured Merge Tree</em>, ou LSMT.</p>
<h2 id="log-structured-merge-tree">Log Structured Merge Tree</h2>
<p>Uma Log Structured Merge Tree é uma forma de se armazenar dados em disco de forma de forma quase sempre sequencial, minimizando assim os o impacto da durabilidade no desempenho do sistema.
Considere um banco armazenando uma pequena quantidade de dados, que cabe em memória principal.
Na LSMT, operações de escrita são adicionadas a um <strong><em>commit log</em></strong>, em disco,  e somente então são executadas em memória principal e confirmadas para o cliente; a estrutura que armazena os dados em memória é denominada <em>memory table</em>, ou simplesmente <strong>memtable</strong>.
Neste cenário o acesso ao disco na escrita é sequencial, o melhor que se pode ter em um disco, e a recuperação dos dados é feita diretamente da memória, rápida.</p>
<p><img alt="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataWritten.html" src="../images/lsm2.png" /></p>
<p>No caso de uma reinicialização do processo, a reexecução do <em>commit log</em> restaurará o estado da memtable. Contudo, se o <em>commit log</em> for extenso, reexecutá-lo demandará um tempo significativo.
Uma forma de acelerar o processo é fazer <strong><em>snapshots</em></strong> da memtable de forma sincronizada com a escrita no log. 
Isto é, digamos que todas as operações de escrita, até a décima, estão salvas no commit log e refletidas na memtable.
Digamos também que todas as operações são modificações da mesma linha do banco de dados em memória.
Se um <em>snapshot</em>  é tomado, ele será correspondente ao commit log, isto é, conterá o efeito de exatamente as mesmas 10 operações, mas de forma mais compacta que o log, uma vez que o log conterá dez operações e o snapshot somente uma linha de dados.
Após o snapshot ser concluído, o log correspondente pode ser apagado.
Novas operações de escrita devem ser armazenadas em um novo log e, no caso de uma reinicialização, primeiro se deve restaurar o <em>snapshot</em> e então o novo log.
Para lidar com corrupções de arquivo no sistema, pode ser uma boa ideia manter mais do que o último log e <em>snapshot</em>, já que a recuperação do estado exigiria voltar mais atrás na reexecução de operações.</p>
<p>Observe que, além da escrita dos logs, todos os outros acessos ao disco também são sequenciais, seja o <em>flush</em> das memtables, ou a leitura dos snapshots para recuperação e do commit log para reexecução, e já que operações de leitura são todas respondidas da memória, o sistema terá um excelente desempenho.
Contudo, há outro limitante de desempenho importante, relacionado à premissa pouco realista de que os dados cabem todos em memória. Isto é, se os dados não cabem em memória, <em>snapshots</em>  serão importantes não somente para permitir coletar lixo dos logs, isto é, dados obsoletos, mas também, para usar a capacidade de armazenamento dos discos.</p>
<p>Consideremos então um cenário em que a memtable cabe apenas <em>n</em> entradas; quando a operação para adicionar $n+1$-ésima entrada à memtable é recebida, um <strong><em>flushs</em></strong> dos dados para um novo <em>snapshot</em> é feito e a memtable é <em>resetada</em>, liberando espaço em memória. Para melhorar o desempenho, estas descargas podem ser feitas proativamente antes da chegada de novas entradas e fora do <em>caminho crítico</em> da operação de escrita, mas isto é apenas uma otimização e portanto não a consideraremos aqui.</p>
<p><img alt="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataWritten.html" src="../images/lsm2.png" /></p>
<p>Neste novo fluxo, os arquivos em disco não correspondem mais a <em>snapshots</em> do banco de dados, então nos referiremos a eles como <em>stable storage tables</em>, ou <strong>sstables</strong>, em oposição às <em>memtables</em>, pelo menos por enquanto.</p>
<h3 id="compactacoes">Compactações</h3>
<p>Apesar deste novo fluxo de escrita aumentar a capacidade de armazenamento do nosso banco de dados, ele traz problemas para o fluxo de leitura.
Digamos que a chave $k$ teve um valor atribuído e descarregado em uma sstable em diversas ocasiões.
O primeiro problema aqui é que há vários valores antigos associados a $k$, inutilmente e ocupando espaço, isto é, lixo.
O segundo é que caso o valor associado a $k$ seja requisitado, o sistema deverá retornar a última versão, que pode estar em diversos arquivos.
Para lidar com ambos os problemas, podemos <strong>compactar</strong> as sstables juntas, eliminados dados obsoletos e minimizando o número de arquivos a serem pesquisados no caso de leitura.
Caso a sstables estejam ordenadas, o procedimento de compactação pode ser feito como a união de dois segmentos de dados no <em>merge sort</em>, isto é, iterando-se paralelamente nos dois arquivos e escolhendo sempre a menor chave da vez e movendo-a para um novo segmento que conterá a união dos dados.
A figura a seguir mostra um exemplo que várias sstables de nível 0, aquelas geradas por <em>flushs</em>, são unidas gerando sstables de nível 1 e assim sucessivamente.
Observe como as compactações geram uma árvore (na verdade, uma floresta), razão do nome <em>merge tree</em>.</p>
<p><img alt="https://www.hedvig.io/blog/hedvig-internals-log-structured-merge-trees-and-folding-of-bloom-filters" src="../images/lsm_compac.png" /></p>
<p>No caso de uma pesquisa, somente as tabelas mais à direita e de nível mais alto precisam ser consultadas e portanto as sstables já usadas como entrada podem ser eliminadas como lixo do sistema.
Ainda assim, no caso de uma leitura, diversas sstables potencialmente contém o dado a ser retornado. 
O problema se agrava em sistemas em que partes do dado possam ser gravadas independentemente, como no CassandraDB, em que cada coluna é independente das outras.
Diversas propostas poderiam ser feitas para se identificar mais rapidamente se uma sstable contém uma chave.
Por exemplo, pode-se associar a cada tabela um bitmap indicando a presença ou não de uma certa chave, mas esta abordagem obviamente falha se o espaço de chaves for grande.
Outra possibilidade é lembrar a faixa de chaves contida na tabela. Esta estratégia pode ser útil caso haja localidade no espaço de chaves no momento da escrita, mas falhará miseravelmente se o espaço de chaves for usado uniformemente, resultando em faixas grandes entre a menor e maior chaves de cada tabela.
Como acelerar a identificação das sstables pertinentes? Entram em cena os filtros de <strong>Bloom</strong>.</p>
<h2 id="filtros-de-bloom">Filtros de Bloom</h2>
<p>De acordo com nossa fonte mais que confiável, a <a href="https://en.wikipedia.org/wiki/Bloom_filter">Wikipedia</a></p>
<blockquote>
<p><em>A Bloom filter is a </em><em>space-efficient</em><em> </em><em>probabilistic</em><em> data structure, conceived by Burton Howard </em>Bloom<em> in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not, thus a Bloom filter has a 100% recall rate. In other words, a query returns either </em><em>"possibly in set"</em><em> or </em><em>"definitely not in set"</em><em>.</em></p>
</blockquote>
<p>Se associarmos a cada sstable um filtro de Bloom, então só será preciso lê-la se o filtro correspondente disser que a chave possivelmente está contida, como no seguinte exemplo.</p>
<p><img alt="LSMT+Bloom Filter" src="../images/bf_lsm.jpg" /></p>
<p>Mas como exatamente construímos um filtro de Bloom?
Iniciamos com um vetor de bits inicialmente zerados e um conjunto finito de funções de hash cujo resultado seja uniformemente distribuído no tamanho do vetor de bits.
Para cada elemento colocado no conjunto a ser refletido pelo filtro, aplicamos cada uma das funções hash e colocamos o bit 1 na posição do vetor igual ao resultado da função.
No exemplo a seguir, inserimos os elementos x, y e z e usamos três funções hash.</p>
<p><img alt="By David Eppstein" src="../images/bloom.png" /></p>
<p>Na <strong>consulta</strong>, cada elemento passa por pelas mesmas funções hash. 
Se algum dos índices apontados não estiver com um 1, como no caso do w, no exemplo, o elemento não pertence ao conjunto. 
Caso contrário, o filtro responderá que é possível que pertença.</p>
<p>Mas quão bom é um filtro de Bloom na identificação do das sstables? Ou, de outra forma, quais fatores influenciam na taxa de falsos positivos do filtro?
* o número $n$ de elementos no conjunto, uma vez que quanto mais elementos, mais bits  1;
* o número $k$ de hashes, pois quanto mais hashes, mais bits transformados em 1; e,
* o número $m$ de bits no vetor, pois quanto menos bits, mais colisões de bits.</p>
<p>De forma mais precisa,
* a probabilidade de setar um certo bit na inserção de um elemento é $1/m$, e
* a probabilidade de não setar tal bit é $1 - 1/m$;
* a probabilidade de $k$ hashes não setarem um bit é $(1 - 1/m)^k$;
* a probabilidade de não setar um bit após $n$ inserções é $(1 - 1/m)^{kn}$;
* a probabilidade de setar um bit após $n$ inserções é $1 - (1 - 1/m)^{kn}$</p>
<p>Logo,
* a probabilidade de falso positivo $p = (1 - (1 - 1/m)^{kn})^k \approx (1 - e^{-kn/m})^k$
O que nos permite chegar à relação
* $m/n = - 1.44\log_2 p$, em que podemos calcular $m$ em função do $n$ esperado e do $p$ desejado.
E podemos também identificar o $k$ ótimo para a situação, pela equação 
* $k = - \frac{\ln p}{\ln 2} = - \log_2 p$</p>
<p>Uma forma "simples" de visualizar este resultado é dada pela figura a seguir, em que o eixo Y dá a taxa de falsos positivos do filtro em função do número de elementos inseridos, indicado no eixo X, para diversas configurações, apresentadas como curvas.
Por exemplo, com um filtro com $m = 2^{24}b = 2MB$, após 1 milhão de inserções, tem-se probabilidade de falsos positivo $p = 0,0001$.</p>
<h3 id="referencias">Referências</h3>
<p><a href="http://www.slideshare.net/quipo/modern-algorithms-and-data-structures-1-bloom-filters-merkle-trees">Modern Algorithms and Data Structures: Bloom-Filter</a></p>
<h2 id="merkle-trees">Merkle Trees</h2>
<p>TODO</p>
<h6 id="como-sincronizar-duas-maquinas">Como sincronizar duas máquinas?</h6>
<p>Suponha que um mesmo arquivo exista em duas máquinas. Como sincronizá-los de forma eficiente, onde eficiência se mede em termos de uso da rede?</p>
<ul>
<li>Copie os arquivos de um servidor para outro</li>
<li>Mantenha o mais novo</li>
</ul>
<p>Isso é eficiente?</p>
<h6 id="como-sincronizar-duas-maquinas_1">Como sincronizar duas máquinas?</h6>
<ul>
<li>Produza um hash dos arquivos</li>
<li>Troque hashes</li>
<li>Se hashes iguais, pronto.</li>
<li>Se hashes diferentes, volte para o slide anterior.</li>
</ul>
<h6 id="merkle-trees_1">Merkle Trees</h6>
<ul>
<li>Divida o arquivo em blocos de mesmo tamanho</li>
<li>Faça um hash de cada bloco</li>
<li>Se mais de um hash gerado, <ul>
<li>Concatene os hashes em um arquivo</li>
<li>Volte para o primeiro item</li>
</ul>
</li>
</ul>
<p><img alt="By Azaghal" src="../images/merkle_tree.png" /></p>
<ul>
<li>Troque hashes da raiz.</li>
<li>Se hashes iguais, pronto.</li>
<li>Se hashes diferentes \pause compare subárvore.</li>
</ul>
<p>Se a única mudança no arquivo foi a adição de um byte no começo do arquivo?</p>
<h3 id="referencias_1">Referências</h3>
<p><a href="http://www.slideshare.net/quipo/modern-algorithms-and-data-structures-1-bloom-filters-merkle-trees">Modern Algorithms and Data Structures: Merkle Trees</a></p>
<h2 id="rabin-fingerprint">Rabin Fingerprint</h2>
<p><a href="https://en.wikipedia.org/wiki/Rolling_hash">Rolling Hash</a></p>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
