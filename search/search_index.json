{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pref\u00e1cio Por qu\u00ea ler estas notas? Computa\u00e7\u00e3o distribu\u00edda \u00c1rea extremamente ativa Diferencial As \u00e1reas ligadas ao desenvolvimentos de sistemas computacionais, como Ci\u00eancia e Engenharia de Computa\u00e7\u00e3o e Sistemas de Informa\u00e7\u00e3o, est\u00e3o extremamente em voga e tem atra\u00eddo mais e mais profissionais, mais ou menos qualificados, tornando este mercado cada vez mais competitivo . Dentro destas grandes \u00e1reas, o desenvolvimento de sistemas distribu\u00eddos \u00e9 um dos t\u00f3picos mais \"quentes\" e ter conhecimentos espec\u00edficos desta sub\u00e1rea pode ser uma excelente vantagem e forma de se destacar de seus colegas e competidores. Fundamental a outras \u00e1reas Aprendizado de m\u00e1quina Ci\u00eancia de dados Computa\u00e7\u00e3o gr\u00e1fica Se estiver se perguntando do que estou falando, sobre como posso dizer que \u00e9 quente uma \u00e1rea sobre a qual talvez voc\u00ea nunca tenha ouvido falar, ao contr\u00e1rio de \u00e1reas como aprendizado de m\u00e1quina e ci\u00eancia de dados , ent\u00e3o deixe-me explicar o que quero dizer. Sem o desenvolvimento da teoria da computa\u00e7\u00e3o distribu\u00edda , na forma do estudo de algoritmos e t\u00e9cnicas de implementa\u00e7\u00e3o, e sua coloca\u00e7\u00e3o em pr\u00e1tica, na forma do desenvolvimento de sistemas distribu\u00eddos, nenhum desenvolvimento s\u00e9rio destas outras \u00e1reas, sedentas por desempenho, escalaria para problemas reais. Veja, por exemplo, a seguinte descri\u00e7\u00e3o dos skills necess\u00e1rios para se atuar como cientista de dados ou como engenheiro de software no Facebook . \u00c9 fato que aplica\u00e7\u00f5es distribu\u00eddos j\u00e1 s\u00e3o parte inexpurg\u00e1vel da infraestrutura computacional que usamos para resolver os mais diversos problemas. Este curso A teoria por baixo dos frameworks que j\u00e1 usam Assim, respondendo \u00e0 pergunta acima, entendo que ler estas notas lhe permitir\u00e1 mergulhar rapidamente no cora\u00e7\u00e3o da computa\u00e7\u00e3o distribu\u00edda, para entender os fundamentos de como as grandes infra-estruturas computacionais que usamos hoje funcionam, muito al\u00e9m das anota\u00e7\u00f5es do Springboot e dos clientes de bancos de dados. Isso, de uma forma muito direta e mais simples de digerir quer as fontes onde me baseei para escrev\u00ea-las, al\u00e9m de usar diversos materiais dispon\u00edveis mais recentes que a bibliografia b\u00e1sica. Estrutura Por qu\u00ea? Vis\u00e3o geral Teoria Pr\u00e1tica Cen\u00e1rio atual Neste curso apesentaremos uma vis\u00e3o geral do que s\u00e3o sistemas distribu\u00eddos, porqu\u00eas t\u00e9cnicos para os desenvolvermos e como faz\u00ea-lo, com uma forte componente pr\u00e1tica, por meio do desenvolvimento de um projeto com (um dos) p\u00e9s na realidade. Faremos isso come\u00e7ando por uma revis\u00e3o de conceitos de redes de computadores e sistemas operacionais enquanto falamos sobre a arquitetura mais fundamental de computa\u00e7\u00e3o distribu\u00edda, Cliente/Servidor, e de como \u00e9 usada para implementar um proto banco de dados distribu\u00eddo, uma Tabela de Espalhamento Distribu\u00edda em mem\u00f3ria. \u00c0 medida em que apresentamos problemas com o modelo assumido inicialmente e com nossa implementa\u00e7\u00e3o inicial, buscaremos por solu\u00e7\u00f5es enquanto introduzimos novas abstra\u00e7\u00f5es, mais poderosas e mais complexas. Ao final desta jornada, teremos fundamentado a constru\u00e7\u00e3o de uma Tabela de Espalhamento Distribu\u00eddo com particionamento de dados entre n\u00f3s, usando protocolos par-a-par e replica\u00e7\u00e3o de m\u00e1quinas de estados. Em paralelo, teremos estudado diversos frameworks de computa\u00e7\u00e3o distribu\u00edda atuais, como modelo ou bloco de constru\u00e7\u00e3o para a resolu\u00e7\u00e3o de nossos problemas. Em resumo, durante este curso voc\u00ea ir\u00e1: programar processos que se comuniquem via redes de computadores; conhecer arquiteturas cl\u00e1ssicas de sistemas distribu\u00eddos (e.g, cliente/servidor, p2p e h\u00edbrida), seus usos e limita\u00e7\u00f5es; escrever programas multithreaded simples e a entender como o uso de multithreading afeta os componentes de um sistema distribu\u00eddo; entender a problem\u00e1tica da coordena\u00e7\u00e3o e do controle de concorr\u00eancia em sistemas distribu\u00eddos; entender o uso de sistemas de nomea\u00e7\u00e3o em sistemas distribu\u00eddos bem como diversas formas de se implementar tais sistemas de nomea\u00e7\u00e3o; entender os conceitos b\u00e1sicos de replica\u00e7\u00e3o e toler\u00e2ncia a falhas; entender as implica\u00e7\u00f5es da dessincroniza\u00e7\u00e3o de rel\u00f3gios na coordena\u00e7\u00e3o, replica\u00e7\u00e3o e toler\u00e2ncia a falhas; projetar sistemas com componentes geograficamente distantes, fracamente acoplados; entender onde os diversos middleware podem ser usados para acoplar tais componentes; conhecer v\u00e1rias t\u00e9cnicas que controle de concorr\u00eancia controlar o acesso a um recurso compartilhado; TODO Estruturar melhor esta se\u00e7\u00e3o uma vez que a estrutura do documento tenha estabilizado mais. Conven\u00e7\u00f5es Neste documento, usamos diversos recursos visuais com diferentes prop\u00f3sitos. it\u00e1lico indica termos em outras l\u00ednguas, como framework ou middleware . Alguns termos, contudo, s\u00e3o t\u00e3o corriqueiramente usados que me escapam quando escrevendo e acabam n\u00e3o grafados corretamente. negrito indica a introdu\u00e7\u00e3o de termos e conceitos importantes, como escalabilidade e falha . Apontadores indicam um s\u00edtio relacionado ao termo, por exemplo, como criar um reposit\u00f3rio no Github , e cuja leitura \u00e9 sugerida ao final da aula. Notas de rodap\u00e9, indicam uma observa\u00e7\u00e3o importante sobre o que est\u00e1 sendo apresentado, cuja leitura \u00e9 sugerida ao final do par\u00e1grafo. 1 Estas notas incluem referenciais te\u00f3ricos importantes, com detalhes da publica\u00e7\u00e3o e apontadores para onde a publica\u00e7\u00e3o pode ser lida, por exemplo, para o livro Distributed Systems: Principles and Paradigms 2 no qual estas notas s\u00e3o fortemente baseadas; este uso dever\u00e1 ser migrado para uma forma mais can\u00f4nica de refer\u00eancias. Imagens n\u00e3o autorais s\u00e3o tamb\u00e9m apontadores para onde s\u00e3o encontradas e tem como texto alternativo as informa\u00e7\u00f5es da autoria. Caixas alinhadas \u00e0 esquerda s\u00e3o usadas para v\u00e1rias finalidades. Por exemplo, para apresentar exerc\u00edcios, destacar especifica\u00e7\u00f5es, apontar tarefas a serem executas por mim... Os diversos usos s\u00e3o indicados nos \u00edcones e cores das caixas. Exerc\u00edcio Isso \u00e9 um exerc\u00edcio! Resumo Elementos visuais Caixas alinhadas \u00e0 direita podem ser vistas como um sum\u00e1rio executivo do que est\u00e1 sendo apresentado no texto pr\u00f3ximo. TODO Diferenciar os usos de negrito, Ativar plugin bibtex Diferenciar caixas Agradecimentos Agrade\u00e7o ao Prof. Paulo R. S. L. Coelho pelas diversas contribui\u00e7\u00f5es feitas a este texto. Agrade\u00e7o tamb\u00e9m aos diversos alunos est\u00e3o sempre, gentilmente, apresentando oportunidades de melhorias. Caso queira sugerir corre\u00e7\u00f5es, fa\u00e7a um pull request a apontando a corre\u00e7\u00e3o no branch main, a partir do qual eu atualizarei o HTML. TODO Adicionar guia de sugest\u00f5es. Referencial Estas notas, em sua forma atual, s\u00e3o fortemente baseadas no livro Distributed Systems: Principles and Paradigms 2 , mas tamb\u00e9m em alguns materiais mais recentes dispon\u00edveis livremente na Internet. Exemplo de nota de rodap\u00e9. \u21a9 Distributed Systems: Principles and Paradigms \u21a9 \u21a9","title":"Pref\u00e1cio"},{"location":"#prefacio","text":"","title":"Pref\u00e1cio"},{"location":"#por-que-ler-estas-notas","text":"Computa\u00e7\u00e3o distribu\u00edda \u00c1rea extremamente ativa Diferencial As \u00e1reas ligadas ao desenvolvimentos de sistemas computacionais, como Ci\u00eancia e Engenharia de Computa\u00e7\u00e3o e Sistemas de Informa\u00e7\u00e3o, est\u00e3o extremamente em voga e tem atra\u00eddo mais e mais profissionais, mais ou menos qualificados, tornando este mercado cada vez mais competitivo . Dentro destas grandes \u00e1reas, o desenvolvimento de sistemas distribu\u00eddos \u00e9 um dos t\u00f3picos mais \"quentes\" e ter conhecimentos espec\u00edficos desta sub\u00e1rea pode ser uma excelente vantagem e forma de se destacar de seus colegas e competidores. Fundamental a outras \u00e1reas Aprendizado de m\u00e1quina Ci\u00eancia de dados Computa\u00e7\u00e3o gr\u00e1fica Se estiver se perguntando do que estou falando, sobre como posso dizer que \u00e9 quente uma \u00e1rea sobre a qual talvez voc\u00ea nunca tenha ouvido falar, ao contr\u00e1rio de \u00e1reas como aprendizado de m\u00e1quina e ci\u00eancia de dados , ent\u00e3o deixe-me explicar o que quero dizer. Sem o desenvolvimento da teoria da computa\u00e7\u00e3o distribu\u00edda , na forma do estudo de algoritmos e t\u00e9cnicas de implementa\u00e7\u00e3o, e sua coloca\u00e7\u00e3o em pr\u00e1tica, na forma do desenvolvimento de sistemas distribu\u00eddos, nenhum desenvolvimento s\u00e9rio destas outras \u00e1reas, sedentas por desempenho, escalaria para problemas reais. Veja, por exemplo, a seguinte descri\u00e7\u00e3o dos skills necess\u00e1rios para se atuar como cientista de dados ou como engenheiro de software no Facebook . \u00c9 fato que aplica\u00e7\u00f5es distribu\u00eddos j\u00e1 s\u00e3o parte inexpurg\u00e1vel da infraestrutura computacional que usamos para resolver os mais diversos problemas. Este curso A teoria por baixo dos frameworks que j\u00e1 usam Assim, respondendo \u00e0 pergunta acima, entendo que ler estas notas lhe permitir\u00e1 mergulhar rapidamente no cora\u00e7\u00e3o da computa\u00e7\u00e3o distribu\u00edda, para entender os fundamentos de como as grandes infra-estruturas computacionais que usamos hoje funcionam, muito al\u00e9m das anota\u00e7\u00f5es do Springboot e dos clientes de bancos de dados. Isso, de uma forma muito direta e mais simples de digerir quer as fontes onde me baseei para escrev\u00ea-las, al\u00e9m de usar diversos materiais dispon\u00edveis mais recentes que a bibliografia b\u00e1sica.","title":"Por qu\u00ea ler estas notas?"},{"location":"#estrutura","text":"Por qu\u00ea? Vis\u00e3o geral Teoria Pr\u00e1tica Cen\u00e1rio atual Neste curso apesentaremos uma vis\u00e3o geral do que s\u00e3o sistemas distribu\u00eddos, porqu\u00eas t\u00e9cnicos para os desenvolvermos e como faz\u00ea-lo, com uma forte componente pr\u00e1tica, por meio do desenvolvimento de um projeto com (um dos) p\u00e9s na realidade. Faremos isso come\u00e7ando por uma revis\u00e3o de conceitos de redes de computadores e sistemas operacionais enquanto falamos sobre a arquitetura mais fundamental de computa\u00e7\u00e3o distribu\u00edda, Cliente/Servidor, e de como \u00e9 usada para implementar um proto banco de dados distribu\u00eddo, uma Tabela de Espalhamento Distribu\u00edda em mem\u00f3ria. \u00c0 medida em que apresentamos problemas com o modelo assumido inicialmente e com nossa implementa\u00e7\u00e3o inicial, buscaremos por solu\u00e7\u00f5es enquanto introduzimos novas abstra\u00e7\u00f5es, mais poderosas e mais complexas. Ao final desta jornada, teremos fundamentado a constru\u00e7\u00e3o de uma Tabela de Espalhamento Distribu\u00eddo com particionamento de dados entre n\u00f3s, usando protocolos par-a-par e replica\u00e7\u00e3o de m\u00e1quinas de estados. Em paralelo, teremos estudado diversos frameworks de computa\u00e7\u00e3o distribu\u00edda atuais, como modelo ou bloco de constru\u00e7\u00e3o para a resolu\u00e7\u00e3o de nossos problemas. Em resumo, durante este curso voc\u00ea ir\u00e1: programar processos que se comuniquem via redes de computadores; conhecer arquiteturas cl\u00e1ssicas de sistemas distribu\u00eddos (e.g, cliente/servidor, p2p e h\u00edbrida), seus usos e limita\u00e7\u00f5es; escrever programas multithreaded simples e a entender como o uso de multithreading afeta os componentes de um sistema distribu\u00eddo; entender a problem\u00e1tica da coordena\u00e7\u00e3o e do controle de concorr\u00eancia em sistemas distribu\u00eddos; entender o uso de sistemas de nomea\u00e7\u00e3o em sistemas distribu\u00eddos bem como diversas formas de se implementar tais sistemas de nomea\u00e7\u00e3o; entender os conceitos b\u00e1sicos de replica\u00e7\u00e3o e toler\u00e2ncia a falhas; entender as implica\u00e7\u00f5es da dessincroniza\u00e7\u00e3o de rel\u00f3gios na coordena\u00e7\u00e3o, replica\u00e7\u00e3o e toler\u00e2ncia a falhas; projetar sistemas com componentes geograficamente distantes, fracamente acoplados; entender onde os diversos middleware podem ser usados para acoplar tais componentes; conhecer v\u00e1rias t\u00e9cnicas que controle de concorr\u00eancia controlar o acesso a um recurso compartilhado; TODO Estruturar melhor esta se\u00e7\u00e3o uma vez que a estrutura do documento tenha estabilizado mais.","title":"Estrutura"},{"location":"#convencoes","text":"Neste documento, usamos diversos recursos visuais com diferentes prop\u00f3sitos. it\u00e1lico indica termos em outras l\u00ednguas, como framework ou middleware . Alguns termos, contudo, s\u00e3o t\u00e3o corriqueiramente usados que me escapam quando escrevendo e acabam n\u00e3o grafados corretamente. negrito indica a introdu\u00e7\u00e3o de termos e conceitos importantes, como escalabilidade e falha . Apontadores indicam um s\u00edtio relacionado ao termo, por exemplo, como criar um reposit\u00f3rio no Github , e cuja leitura \u00e9 sugerida ao final da aula. Notas de rodap\u00e9, indicam uma observa\u00e7\u00e3o importante sobre o que est\u00e1 sendo apresentado, cuja leitura \u00e9 sugerida ao final do par\u00e1grafo. 1 Estas notas incluem referenciais te\u00f3ricos importantes, com detalhes da publica\u00e7\u00e3o e apontadores para onde a publica\u00e7\u00e3o pode ser lida, por exemplo, para o livro Distributed Systems: Principles and Paradigms 2 no qual estas notas s\u00e3o fortemente baseadas; este uso dever\u00e1 ser migrado para uma forma mais can\u00f4nica de refer\u00eancias. Imagens n\u00e3o autorais s\u00e3o tamb\u00e9m apontadores para onde s\u00e3o encontradas e tem como texto alternativo as informa\u00e7\u00f5es da autoria. Caixas alinhadas \u00e0 esquerda s\u00e3o usadas para v\u00e1rias finalidades. Por exemplo, para apresentar exerc\u00edcios, destacar especifica\u00e7\u00f5es, apontar tarefas a serem executas por mim... Os diversos usos s\u00e3o indicados nos \u00edcones e cores das caixas. Exerc\u00edcio Isso \u00e9 um exerc\u00edcio! Resumo Elementos visuais Caixas alinhadas \u00e0 direita podem ser vistas como um sum\u00e1rio executivo do que est\u00e1 sendo apresentado no texto pr\u00f3ximo. TODO Diferenciar os usos de negrito, Ativar plugin bibtex Diferenciar caixas","title":"Conven\u00e7\u00f5es"},{"location":"#agradecimentos","text":"Agrade\u00e7o ao Prof. Paulo R. S. L. Coelho pelas diversas contribui\u00e7\u00f5es feitas a este texto. Agrade\u00e7o tamb\u00e9m aos diversos alunos est\u00e3o sempre, gentilmente, apresentando oportunidades de melhorias. Caso queira sugerir corre\u00e7\u00f5es, fa\u00e7a um pull request a apontando a corre\u00e7\u00e3o no branch main, a partir do qual eu atualizarei o HTML. TODO Adicionar guia de sugest\u00f5es.","title":"Agradecimentos"},{"location":"#referencial","text":"Estas notas, em sua forma atual, s\u00e3o fortemente baseadas no livro Distributed Systems: Principles and Paradigms 2 , mas tamb\u00e9m em alguns materiais mais recentes dispon\u00edveis livremente na Internet. Exemplo de nota de rodap\u00e9. \u21a9 Distributed Systems: Principles and Paradigms \u21a9 \u21a9","title":"Referencial"},{"location":"arch/","text":"Arquiteturas De acordo com David Garlan and Mary Shaw, January 1994, CMU-CS-94-166, em An Introduction to Software Architecture ... an architectural style determines the vocabulary of components and connectors that can be used in instances of that style, together with a set of constraints on how they can be combined. These can include topological constraints on architectural descriptions (e.g., no cycles). Other constraints\u2014say, having to do with execution semantics\u2014might also be part of the style definition. Em outras palavras, um estilo ou padr\u00e3o arquitetural \u00e9 o conjunto de princ\u00edpios que prov\u00ea uma infraestrutura abstrata para uma fam\u00edlia de sistemas, e promove o reuso de projeto ao prover solu\u00e7\u00f5es para problemas recorrentes e frequentes . Quando falamos de arquiteturas em sistemas distribu\u00eddos, estamos primariamente focados na forma como os componentes do sistema interagem uns com os outros, por meio de conectores , para implementar a solu\u00e7\u00e3o para um problema. Componentes e Conectores Todo comp e conec graph LR A[Componente 1] --> C{Conector} --> B(Componente 2) Dependendo de como s\u00e3o conectados, haver\u00e1 maior ou menor depend\u00eancia entre os componentes. Quando houver forte depend\u00eancia, diremos que os componentes est\u00e3o fortemente acoplados ( tightly coupled ). Caso contr\u00e1rio, diremos que est\u00e3o fracamente acoplados ( loosely coupled ). A raz\u00e3o \u00f3bvia para preferir sistemas fracamente conectados \u00e9 sua capacidade de tolerar disrup\u00e7\u00f5es; se um componente depende pouco de outro, ent\u00e3o n\u00e3o se incomodar\u00e1 com sua aus\u00eancia por causa de uma falha. Certos middleware permitem um acoplamento t\u00e3o fraco entre componentes, que estes n\u00e3o precisam se conhecer ou sequer estar ativos no mesmo momento. Tamb\u00e9m a quest\u00e3o da simplifica\u00e7\u00e3o de API, uma vez que o middleware pode impor um padr\u00e3o a ser seguido por todos os componentes e minimizar a necessidade os componentes conhecerem as interfaces uns dos outros. Cliente/Servidor A forma como os componentes se comunicam, isto \u00e9, os conectores usados, \u00e9 importante no estudo arquitetural. Mas tamb\u00e9m s\u00e3o importantes os pap\u00e9is assumidos pelos componentes na realiza\u00e7\u00e3o de tarefas. Neste sentido, provavelmente a arquitetura de computa\u00e7\u00e3o distribu\u00edda mais comum \u00e9 a Cliente/Servidor . Na arquitetura Cliente/Servidor, como implicado pelo nome, h\u00e1 um processo que serve a pedidos realizados por outros processos. Isto \u00e9 feito quando o cliente o contacta o servidor e requer ( request ) a realiza\u00e7\u00e3o do servi\u00e7o. O servidor , por sua vez, pode desempenhar tarefas como fazer c\u00e1lculos, armazenar dados, ou repassar uma mensagem e, ao final da realiza\u00e7\u00e3o da tarefa, responder ( response ) ao cliente. Um mesmo servidor pode atender a diversos clientes e, geralmente, a comunica\u00e7\u00e3o entre os mesmos \u00e9 feita diretamente por sockets. Embora seja poss\u00edvel usar sockets de forma ass\u00edncrona, a API mais comum \u00e9 s\u00edncrona, isto \u00e9, quando um processo espera receber uma mensagem de outro, ele fica bloqueado esperando algum dado estar dispon\u00edvel para leitura no referido socket. Assim, geralmente a comunica\u00e7\u00e3o entre cliente e servidor segue o seguinte esquema: sequenceDiagram activate Cliente note left of Servidor: Espera pela requisi\u00e7\u00e3o Cliente->>Servidor: Request deactivate Cliente activate Servidor note right of Cliente: Espera pela resposta note left of Servidor: Executa servi\u00e7o Servidor-->>Cliente: Resposta deactivate Servidor activate Cliente note left of Servidor: Espera pela requisi\u00e7\u00e3o deactivate Cliente Observe que o cliente fica inativo enquanto espera a resposta e que o servidor fica inativo enquanto espera outras requisi\u00e7\u00f5es. Para minimizar os per\u00edodos de inatividade, o cliente pode usar o socket ass\u00edncronamente, o que n\u00e3o \u00e9 exatamente simples, ou usar m\u00faltiplos threads, para que continue operando mesmo enquanto um thread estiver bloqueado esperando a resposta do servidor. No lado do servidor, o minimiza\u00e7\u00e3o da ociosidade \u00e9 feita pelo uso de m\u00faltiplos clientes, concorrentes, e tamb\u00e9m pelo uso de m\u00faltiplos threads. Neste caso, contudo, \u00e9 necess\u00e1rio tomar muito cuidado para garantir que a concorr\u00eancia n\u00e3o causar\u00e1 efeitos indesejados nos dados e execu\u00e7\u00e3o das tarefas. Veja o caso de um banco de dados transacional, por exemplo, como discutido acima; ele precisa garantir ACID entre as transa\u00e7\u00f5es propostas pelos clientes. Embora tenhamos colocado aqui apenas um servidor atendendo aos clientes, em muitas aplica\u00e7\u00f5es modernas, m\u00faltiplos servidores atender\u00e3o ao conjunto de clientes. Pense por exemplo no servi\u00e7o de email do Google, o Gmail. Com os milh\u00f5es de usu\u00e1rios que tem, certamente h\u00e1 mais de um servidor implementando o servi\u00e7o. Provavelmente estes diversos servidores ficam atr\u00e1s do que chamamos de um balanceador de carga, que roteia as requisi\u00e7\u00f5es seguindo diferentes pol\u00edticas, por exemplo, round robin . Par-a-Par (P2P) Diferentemente de sistemas cliente/servidor, em que um n\u00f3 serve o outro, em sistemas par-a-par, os n\u00f3s s\u00e3o parceiros e tem igual responsabilidade (e da\u00ed o nome) na execu\u00e7\u00e3o das tarefas. Diversos sistemas P2P existem, sendo, provavelmente, os mais famosos, os sistemas de compartilhamento de arquivos. Nesta linha, embora diversos tenham existido, hoje o mais famoso \u00e9 o Bittorrent, mesmo que, como veremos adiante, n\u00e3o seja P2P puro. Outro exemplo importante por ter inspirado diversos outros sistemas \u00e9 o Chord. Neste sistema, n\u00f3s organizam-se em um anel l\u00f3gico e cada um se torna respons\u00e1vel por um dos segmentos do anel adjacente a onde se encontra no mesmo. Requisi\u00e7\u00f5es para correspondentes a um segmento s\u00e3o roteados para o n\u00f3 respons\u00e1vel usando uma tabela de rotas conhecida como finger table . Se tra\u00e7armos os caminhos apontados por esta tabela sobre o anel, desenharemos cordas sobre o mesmo, o que explica o nome do sistema. H\u00edbridos Embora cliente/servidor e P2P sejam arquiteturas cl\u00e1ssicas, boa parte dos sistemas que distribu\u00eddos podem ser na verdade consideradas h\u00edbridos. Considere um sistema de email, por exemplo. Embora clientes usem as funcionalidades dos servidores de email para enviar e receber mensagens, os servidores conversam uns com os outros para implementar a tarefa de encaminhar as mensagens. Neste sentido, o sistema \u00e9 um h\u00edbrido P2P e cliente/servidor. Outros exemplos abundam. Bancos de dados, e.g., DynamoDB, CassandraDB , Redis,... Jogos multiplayer (pense no particionamento dos mapas ) Compartilhamento de arquivos: Bittorrent Voltemos ao exemplo do Bittorrent; observe na figura adiante os diversos passos necess\u00e1rios \u00e0 recupera\u00e7\u00e3o do arquivo de interesse neste sistema. Diversos passos seguem a arquitetura cliente/servidor enquanto \"somente\" o passo de compartilhamento de arquivos \u00e9 P2P. Voltando ao exemplo do sistema de informa\u00e7\u00e3o, observe que o cliente acessa um servi\u00e7o, implementado por pares de n\u00f3s. Podemos dizer que tamb\u00e9m este \u00e9 h\u00edbrido. graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B Sistemas multi-camadas Outra forma de hibridismo que podemos citar \u00e9 quando um componente haje tanto como cliente quanto como servidor. Veja o seguinte exemplo, conhecido no meio como arquitetura em 3-camadas (3 tiers ). Neste caso, \u00e9 interessante notar que esta disposi\u00e7\u00e3o dos componentes \u00e9 independente da disposi\u00e7\u00e3o f\u00edsica. De fato, as tr\u00eas camadas podem estar em um mesmo n\u00f3, ou combinadas duas a duas, neste \u00faltimo caso resultando em duas camadas. Por outro lado, cada camada pode ser subdividida em mais componentes, resultando em m\u00faltiplos tiers, como neste exemplo de um sistema de busca na Web. Outras arquiteturas Diversas outras arquiteturas podem e foram propostas para o desenvolvimento de Sistemas Distribu\u00eddos. A moda da vez \u00e9 a chamada arquitetura de micro servi\u00e7os, na qual a divis\u00e3o de tarefas entre componentes visa levar aos componentes mais simples para tal tarefa. Assim, os mesmos podem ser replicados, escalonados, desenvolvidos e mantidos independentemnte. Cada tarefa conta ent\u00e3o com diversos componentes, organizados em camadas resolvendo um problema em espec\u00edfico, mas todos contribuindo para a realiza\u00e7\u00e3o de uma tarefa maior comum. N\u00f3s discutiremos micro-servi\u00e7os mais adiante. Por agora, apenas tenha em mente que embora seja vendido por muitos como tal, os micro-servi\u00e7os n\u00e3o s\u00e3o uma panac\u00e9ia . Uma extrapola\u00e7\u00e3o que pode ser feita aqui, refor\u00e7ando a observa\u00e7\u00e3o que problemas (e solu\u00e7\u00f5es) de sistemas distribu\u00eddos s\u00e3o refletidos em n\u00edvel de processamento paralelo e concorrente, \u00e9 que a uma arquitetura SEDA lembra em muito a arquitetura de micro-servi\u00e7os . Todo Event sourcing Todo MOM Todo Pub/Sub Para aprender mais Para aprender mais sobre arquiteturas, consulte a seguinte refer\u00eancia: Distributed System Architectures and Architectural Styles . Para aprender um pouco sobre como funcionam as redes de um datacenter , definidas por software, assista ao seguinte v\u00eddeo, que fala sobre a infra-estrutura do Facebook. Cliente Servidor Como brevemente discutido em Fundamentos , quando pensamos em termos de comunica\u00e7\u00e3o entre dois processos usando sockets, em geral pensamos em processos clientes e servidores, onde servidores esperam a conex\u00e3o por parte de clientes e executam as opera\u00e7\u00f5es requisitadas pelos mesmos. Como exemplos desta arquitetura, podemos pensar em um navegador requisitando a um servidor Apache que lhe retorne uma p\u00e1gina Web, ou em um aplicativo m\u00f3vel solicitando ao servidor de aplica\u00e7\u00f5es que dispare uma transfer\u00eancia de fundos. Um exemplo gen\u00e9rico \u00e9 apresentado na figura a seguir. sequenceDiagram activate Servidor activate Cliente note left of Servidor: Cria socket e espera por conex\u00f5es deactivate Servidor Cliente->>+Servidor: Connect? note left of Servidor: Aceita conex\u00e3o Servidor->>-Cliente: Connect! note right of Cliente: Ativo (gerando requisi\u00e7\u00e3o) note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) Cliente->>+Servidor: Request deactivate Cliente note right of Cliente: Inativo (esperando resposta) note left of Servidor: Ativo (processando requisi\u00e7\u00e3o) Servidor-->>-Cliente: Response activate Cliente note right of Cliente: Ativo (processando resposta note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) deactivate Cliente O modelo cliente/servidor forma a base da computa\u00e7\u00e3o distribu\u00edda, sobre a qual todos os outros modelos s\u00e3o implementados. Uma das raz\u00f5es \u00e9 hist\u00f3rica: os primeiros sistemas a permitirem a opera\u00e7\u00e3o por m\u00faltiplos usu\u00e1rios, ainda na d\u00e9cada de 60, eram compostos de uma host robusto ao qual se conectavam diversos terminais, essencialmente com teclado e monitor, isto \u00e9, um servidor e v\u00e1rios clientes. Com a redu\u00e7\u00e3o dos computadores, surgiram as primeiras redes de computadores e a necessidade de uma abstra\u00e7\u00e3o para o estabelecimento de comunica\u00e7\u00e3o entre processos em hosts distintos, e assim surgiram os sockets . Com os sockets, vem uma grande flexibilidade, pois um processo n\u00e3o precisa saber como o outro manuseia os dados que lhe cabem, desde que siga um protocolo pr\u00e9-estabelecido na comunica\u00e7\u00e3o. Isto \u00e9, processos podem ser implementado em diferentes linguagens, sistemas operacionais e arquiteturas, desde observadas os cuidados necess\u00e1rios para se obter transpar\u00eancia de acesso . Esta flexibilidade \u00e9 a outra raz\u00e3o do sucesso do modelo cliente/servidor, permitindo que clientes se conectem a servidores para usar seus recursos, que podem ser acessados concorrentemente por diversos clientes. Exemplos cotidianos disto s\u00e3o servidores de bancos de dados, de p\u00e1ginas Web e email. De fato, esta flexibilidade permite que diversas aplica\u00e7\u00f5es continuem operando de forma centralizada, com servidores rodando, por exemplo, em mainframes e clientes rodando de forma emulada por software em computadores pessoais. Contudo, em certas situa\u00e7\u00f5es, esta divis\u00e3o entre clientes e servidores pode ser tornar confusa. Primeiro, porqu\u00ea uma vez estabelecida a conex\u00e3o, n\u00e3o h\u00e1 uma diferencia\u00e7\u00e3o entre quem iniciou e quem aceitou a mesma; s\u00e3o apenas duas pontas do mesmo socket. Segundo, pode ser que o servi\u00e7o relevante sendo prestado, seja prestado por quem estabelece a conex\u00e3o. De fato ambos podem estar prestando servi\u00e7os um para o outro, no que \u00e9 conhecido como P2P. Terceiro, um mesmo processo pode atuar tanto como cliente quanto como servidor, no que \u00e9 conhecido como arquitetura multicamadas, tamb\u00e9m a ser visto adiante. Quarto, usando-se sockets como base, podemos construir outros modelos de comunica\u00e7\u00e3o entre processos, efetivamente colocando camadas na nossa cebola. 1 A seguir, exploraremos as arquiteturas constru\u00eddas sobre cliente/servidor. Arquitetura Orientada a Microsservi\u00e7os No dia 3 de Junho de 2020, termo microservice resultava em 6.6 milh\u00f5es de resultados no Google . Isso porqu\u00ea a organiza\u00e7\u00e3o de aplica\u00e7\u00f5es distribu\u00eddas na forma de \"pequenos\" processos, especializados e independentes, que colaboram para implementar um servi\u00e7o maior, se tornou um padr\u00e3o importante no desenvolvimento de novas aplica\u00e7\u00f5es. Exatamente por isso, precisamos come\u00e7ar com um aviso: diversas tecnologias surgiram com grande estrondo, sendo alguns exemplos recentes Docker, Golang, Angular, e JQuery, e embora seja certo que algumas destas encontrar\u00e3o seus nichos, como fizeram antes delas Cobol, C, e SQL, outras deparecer\u00e3o da face da ind\u00fastria; afinal, quem sabe o que \u00e9 Delphi e quem ainda usa JQuery? Este fen\u00f4meno \u00e9 capturado pelas v\u00e1rias fases do hype-cycle da Gartner. 3 A Arquitetura Orientada a Microsservi\u00e7os, tendo atingido o pico das expectativas infladas 4 em 2017, est\u00e1 deslizando na Trough of Desilusionment 4 em 2019. Isto \u00e9, este modelo de desenvolvimento n\u00e3o \u00e9 mais propagandeado como uma bala de prata para todas as aplica\u00e7\u00f5es distribu\u00eddas. Ainda assim, \u00e9 um importante modelo. Mas afinal, o que \u00e9 a arquitetura de microsservi\u00e7os? Em vez de explicar diretamente o que s\u00e3o, pode ser mais f\u00e1cil pensar primeiro termos do que n\u00e3o s\u00e3o, em termoss de sistemas monol\u00edticos. Monolitos Muitas aplica\u00e7\u00f5es seguem o modelo de 3 camadas em que em um dos extremos tem-se a interface com os usu\u00e1rios, materializada normalmente por um navegador, no outro tem-se um SGBD onde s\u00e3o armazenados os dados da aplica\u00e7\u00e3o, e, no meio, a l\u00f3gica do neg\u00f3cio. A camada central, implementada por um \u00fanico processo, que alimenta a interface com o usu\u00e1rio, manipula o modelo de dados, e onde reside a l\u00f3gica do neg\u00f3cio, \u00e9 um monolito . Monolitos seguem um modelo simples e largamente utilizado de desenvolvimento em que v\u00e1rios contribuidores implementam partes distintas da l\u00f3gica, que s\u00e3o compiladas em colocadas em desenvolvimento de forma at\u00f4mica: Desenvolva Teste Implante loop Simples n\u00e3o quer dizer necessariamente eficiente; no caso de atualiza\u00e7\u00f5es de uma parte do sistema, todo o monolito precisa ser trocado, incorrendo em indisponibilidade total do sistema, mesmo das partes n\u00e3o modificadas. Esta dificuldade tende a limitar as janelas de atualiza\u00e7\u00e3o do sistema, o que aumenta no n\u00famero de mudan\u00e7as que ocorrem a cada atualiza\u00e7\u00e3o, o que aumenta o risco de regress\u00f5es e portanto requer mais testes, o que aumenta o intervalo entre janelas de atualiza\u00e7\u00e3o. Al\u00e9m disso, nos caso de bugs, \u00e9 mais dif\u00edcil encontrar o problema, uma vez que fica imposs\u00edvel os desenvolvedores conhecerem todo o sistema. Isso apenas exacerba o problema, o que limita mais ainda as atualiza\u00e7\u00f5es, gerando um ciclo vicioso que mantem desenvolvedores acordados nas madrugadas de sexta para s\u00e1bado quando \u00e9 dia de deploy . Sistemas monol\u00edticos tamb\u00e9m podem ser problem\u00e1ticos quanto \u00e0 escalabilidde, pois quando a capacidade do sistema \u00e9 atingida, ou todo o sistema \u00e9 movido para um host de maior capacidade ou todo o sistema deve ser replicado. Na primeira abordagem, o custo geralmente \u00e9 um impecilho, pois pre\u00e7os de hardware crescem exponencialmente. Al\u00e9m disso, um servidor, por mais parrudo que seja, \u00e9 um Ponto \u00danico de Falha (ou SPOF, do ingl\u00eas single point of failure ). Quanto \u00e0 segunda abordagem, ela traz complexidades na coordena\u00e7\u00e3o das r\u00e9plicas e inefici\u00eancias ao replicar inclusive as partes subutilizadas. Ambas as abordagens tamb\u00e9m esbarram na escalabilidade do banco de dados que lhes serve de backend . Para contornar ou pelo menos minimizar estes problemas, pode-se fragmentar o servi\u00e7o e o banco de dados, o que facilita tanto a escalabilidade vertical quanto horizontal de cada m\u00f3dulo, que \u00e9 menor e mais simples de coordenar, e divide a carga nos bancos de dados; mas isso \u00e9 a troca do serv\u00ed\u00e7o monol\u00edtico por microsservi\u00e7os. Microsservi\u00e7os De acordo com Lewis & Fowler The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. Em outras palavras, com os microsservi\u00e7os, quebra-se o monolito em diferentes processos, \" small autonomous services that work together, modelled around a business domain \", cada um gerenciando os dados relevantes para aquela parte do sistema e, possivelmente, sua pr\u00f3pria intera\u00e7\u00e3o com o usu\u00e1rio. Este modelo tem implica\u00e7\u00f5es diretas no desenvolvimento: cada processo \u00e9 desenvolvido por um time diferente, que mantem controle sobre desenvolvimento, teste, e manuten\u00e7\u00e3o em produ\u00e7\u00e3o, o que \u00e9 fact\u00edvel j\u00e1 que cada servi\u00e7o \u00e9 simples e focado em um problema pequeno e ningu\u00e9m tem que entender em detalhas o funcionamento de todo o sistema. Al\u00e9m disso, quando um servi\u00e7o precisa ser atualizado, todos os demais podem continuar operantes e poss\u00edvel at\u00e9 que m\u00faltiplas vers\u00f5es do mesmo servi\u00e7o sejam executadas concorrentemente, possibilitando atualiza\u00e7\u00f5es sem janelas de manuten\u00e7\u00e3o. Quanto \u00e0 escalabilidade, esta \u00e9 feita indepentendentemente tamb\u00e9m; no exemplo na imagem seguinte, \u00e9 prov\u00e1vel que o servi\u00e7o de acesso ao cat\u00e1logo seja mais utilizado que os demais e portanto merecedor de mais recursos e mais c\u00f3pias. Como se percebe facilmente, o uso de microsservi\u00e7os pode ser relacionado \u00e0s t\u00e9cnicas de processamento paralelo: trate dados diferentes em blocos diferentes (paralelismo de dados ou replica\u00e7\u00e3o) e trate fun\u00e7\u00f5es diferentes em blocos diferentes (paralelismo de tarefas ou sharding ). Como na computa\u00e7\u00e3o paralela, na componentiza\u00e7\u00e3o \u00e9 importante considerar os requisitos das diferentes tarefas em termos de CPU, E/S, e mem\u00f3ria, para que possam escalar independentemente e n\u00e3o gerar gargalos desnecess\u00e1rios. Do Monolito aos Microsservi\u00e7os Com tantas vantagens, suge a d\u00favida se todos os sistemas deveriam ser desenvolvidos usando-se a arquitetura de microsservi\u00e7os. A resposta \u00e9 n\u00e3o , pois como colocado no in\u00edcio desta se\u00e7\u00e3o, n\u00e3o existem balas de prata e se um sistema monol\u00edtico est\u00e1 funcionando para voc\u00ea e n\u00e3o h\u00e1 perspectiva de problemas acometerem (a demanda no sistema n\u00e3o est\u00e1 aumentando, a l\u00f3gica do sistema \u00e9 muito simples, indisponibilidade n\u00e3o te traz preju\u00edzo, voc\u00ea n\u00e3o pode arcar com a refatora\u00e7\u00e3o), ent\u00e3o mantenha seu sistema como est\u00e1. Caso haja a necessidade de evolu\u00e7\u00e3o e o modelo de microsservi\u00e7os pare\u00e7a adequado, existem recomenda\u00e7\u00f5es de como a migra\u00e7\u00e3o pode ser feita. Primeiro, \u00e9 preciso aceitar que o desenvolvimento de microsservi\u00e7os afeta a organiza\u00e7\u00e3o do time de desenvolvimento e que a organiza\u00e7\u00e3o provavelmente refletir\u00e1 a arquitetura. O desenvolvimento, manuten\u00e7\u00e3o e opera\u00e7\u00e3o de microsservi\u00e7os acontece em times pequenos, de 1 a 8 pessoas (\"pizza team\"), dependendo da complexidade do servi\u00e7o; se houver a necessidade de mais pesssoas no time, o escopo do microsservi\u00e7o provavelmente est\u00e1 grande demais; cada componente resolve um problema, bem. Segundo, a mudan\u00e7a n\u00e3o dever\u00e1 acontecer atomicamente. Uma boa estrat\u00e9gia \u00e9 identificar uma parte do sistema que funcionaria bem como microsservi\u00e7o, desenvolv\u00ea-la e modificar o monolito para usar o microsservi\u00e7o. O aprendizado ent\u00e3o \u00e9 usado para encontrar novo candidato e o procedimento \u00e9 iterado at\u00e9 que o monolito seja apenas uma casca e possa tamb\u00e9m ser removido. Mais f\u00e1cil dito que feito, h\u00e1 muita documenta\u00e7\u00e3o orientando o processo. Para saber mais Como esta arquitetura n\u00e3o faz parte ainda do nosso curr\u00edculo, n\u00e3o nos aprofundaremos nela aqui. Felizmente h\u00e1 muito material na Web sobre este modelo, sendo a lista a seguir uma \u00ednfima fra\u00e7\u00e3o. Para uma explica\u00e7\u00e3o geral do que s\u00e3o, assista a Martin Fowler no v\u00eddeo seguinte, assista ou consulte os v\u00e1rios artigos no seu s\u00edtio . Para entender os princ\u00edpios por tr\u00e1s do uso da arquitetura, Para um exemplo importante do uso de microsservi\u00e7os, considere a Netflix, que usa microsservi\u00e7os em larga escala em seus servi\u00e7os. Qu\u00e3o larga? \"...over five hundred services... we don't know how many...\" Apesar de tal uso, ou justamente por causa dele, seus servi\u00e7os mant\u00e9m uma \"...availability of 9.995...\", ou seja, ficam indispon\u00edveis por menos de 16 segundos por ano . Com respeito a estar preparado para falhas, afinal \"... it is not if failures will happen... ... it is when it happens...\", a empresa usa uma abordagem de inje\u00e7\u00e3o de falhas em servi\u00e7os em produ\u00e7\u00e3o. Os diferentes tiposde falhas s\u00e3o injetados por um \" ex\u00e9rcito de macacos do caos \" Para uma vis\u00e3o pr\u00e1tica da implementa\u00e7\u00e3o de microsservi\u00e7os usando AWS, veja TODO SOA - Foco no uso de outras formas de comunica\u00e7\u00e3o para chegar em outras arquiteturas. MOM Publish/Subscribe Message Queues Event Sourcing Stream Processing/Event Sourcing Kafka Overview Par-a-Par (Peer-to-Peer, P2P) Nos sistemas que seguem a arquitetura Par-a-Par, ou simplesmente P2P, h\u00e1 uma substitui\u00e7\u00e3o dos pap\u00e9is de clientes e servidores, em que h\u00e1 uma \"hirarquia\" entre os componentes, por uma onde todos os n\u00f3s s\u00e3o pares na execu\u00e7\u00e3o da tarefa em quest\u00e3o. Um exemplo comum destas arquitetura s\u00e3o os sistemas de compartilhamento de arquivos, em que cada n\u00f3 armazena e disponibiliza parte dos dados, bem como acessa os dados disponibilizados por outros n\u00f3s. Como todo sistema distribu\u00eddo, a arquitetura P2P visa agregar poder computacional de m\u00faltiplos n\u00f3s . Mas al\u00e9m disso, pelo n\u00e3o diferencia\u00e7\u00e3o dos componentes, espera-se tolerar falhas de componentes sem paralizar o servi\u00e7o , uma vez que n\u00e3o h\u00e1 um componenente centralizador, detentor \u00fanico de uma certa funcionalidade. Os sistemas P2P tendem portanto a lever a maior disponibilidade. Historicamente, e devido \u00e0s caracter\u00edsticas j\u00e1 mencionadas, os sistemas P2P tem outra caracter\u00edstica muito importante, a alta escalabilidade a que se oferecerem, chegando a n\u00edveis globais. Se pensarmos por exemplo nos sistemas de compartilhamento de arquivos, m\u00fasicas e filmes, raz\u00e3o da fama e inf\u00e2mia da arquitetura, teremos bons exemplos disso. Para que isso seja poss\u00edvel, estes sistemas precisam se tornar auto-gerenci\u00e1veis , pois sistemas globais devem tolerar entrada e sa\u00edda frequente de n\u00f3s (por falhas ou a\u00e7\u00e3o de seus usu\u00e1rios), diferentes dom\u00ednios administrativos , e heterogeneidade na comunica\u00e7\u00e3o. Uma das ferramentas utilizadas para simplificar o trabalho de auto-gerenciamento \u00e9 o conceito de redes sobrepostas . Rede Sobreposta ( Overlay ) Os componentes de um sistema P2P se organizam em uma rede l\u00f3gica, sobreposta \u00e0 rede f\u00edsica. Nesta rede l\u00f3gica, os processos estabelecem canais de comunica\u00e7\u00e3o tipicamente na forma de conex\u00f5es TCP/IP. Por serem ignorantes \u00e0 topologia f\u00edsica da rede e usarem a pilha de comunica\u00e7\u00e3o IP, as redes sobrepostas s\u00e3o mais simples e ao mesmo tempo mais poderosas. Nestas redes s\u00e3o executados diversos algoritmos, como de descoberta de n\u00f3s, roteamento de pacotes e de otimiza\u00e7\u00e3o de rotas pelo descarte e cria\u00e7\u00e3o de conex\u00f5es. Uma vez que as conex\u00f5es na rede sobreposta n\u00e3o correspondem a conex\u00f5es f\u00edsicas, como se pode ver na seguinte figura, vizinhos em um rede sobreposta n\u00e3o necessariamente correspondem a vizinhos na rede f\u00edsica e vice-versa. Isto tamb\u00e9m implica que a otimiza\u00e7\u00e3o da rota l\u00f3gica n\u00e3o necessariamente leva \u00e0 otimiza\u00e7\u00e3o da rota f\u00edsica. Todo A figura n\u00e3o mostra hosts, apenas roteadores. Trocar por figura em com hosts, roteadores, e processos nos hosts. Dependendo em como esta rede \u00e9 organizada (ou n\u00e3o), a mesma \u00e9 classificada como estruturada ou n\u00e3o-estruturada . Rede N\u00e3o-Estruturada Se a rede sobreposta \u00e9 constru\u00edda de forma aleat\u00f3ria, por exemplo deixando os n\u00f3s se conectarem apenas aos vizinhos na rede no ponto em que se conectaram inicialmente, ent\u00e3o esta \u00e9 denominada uma rede n\u00e3o-estruturada . A figura a seguir \u00e9 um exemplo que se percebe que n\u00f3s tem graus diferentes de conectividade e que n\u00e3o est\u00e3o particularmente organizados em nenhuma topologia. Suponha que esta rede seja usada para armazenar e consultar dados. Inser\u00e7\u00f5es de dados podem ser feitas muito rapidamente, armazenando-os no primeiro n\u00f3 dispon\u00edvel encontrado. Os objetos amarelo e vermelho foram inseridos desta forma, e copiados em n\u00f3s pr\u00f3ximos para tolerar a falha de alguns hosts sem perder os dados. Buscas, contudo, ter\u00e3o que vasculhar a rede usando algoritmos como busca em largura , busca em profundidade ou caminhada aleat\u00f3ria (resposta probabil\u00edstica). Rede Estruturada Se as conex\u00f5es s\u00e3o constru\u00eddas e mantidas de forma a gerar uma topologia bem definida, chamamos esta rede de estruturada . Nesta rede, a inser\u00e7\u00e3o de n\u00f3s requer a propaga\u00e7\u00e3o desta informa\u00e7\u00e3o para outros n\u00f3s e a atualiza\u00e7\u00e3o das conex\u00f5es para manter a estrutura. A estrutura geralmente serve ao prop\u00f3sito de associar os n\u00f3s aos dados de uma forma planejada. Por exemplo, n\u00f3s pr\u00f3ximos na rede podem ser respons\u00e1veis por dados logicamente pr\u00f3ximos. Claramente, a inser\u00e7\u00e3o e acesso a dados nesta rede \u00e9 mais custosa, pois independentemente de onde a requisi\u00e7\u00e3o \u00e9 feita, isto \u00e9, a partir de qual n\u00f3, ela dever\u00e1 ser atendida por um n\u00f3 espec\u00edfico. Veja o exemplo do Chord, uma rede P2P em que os n\u00f3s formam um anel l\u00f3gico, cujos detalhes veremos adiante. Cada n\u00f3 \u00e9 respons\u00e1vel pela faixa de valores indexados por chaves entre o identificador do n\u00f3 e o do n\u00f3 anterior. Logo, qualquer inser\u00e7\u00e3o ou consulta de dados, deve ser feita especificamente para um determinado n\u00f3, e deve ser roteada para o mesmo. A estrutura da rede permite que tal roteamento seja feito eficientemente, no n\u00edvel da rede sobreposta. Como outro exemplo considere uma rede em que os n\u00f3s armazenam informa\u00e7\u00f5es sobre os dados de uma certa \u00e1rea geogr\u00e1fica e que n\u00f3s vizinhos na rede sejam aqueles respons\u00e1veis por \u00e1reas que se tocam. Neste exemplo, para se acessar os dados de um certo ponto no mapa, basta rotear a requisi\u00e7\u00e3o para o vizinho mais pr\u00f3ximo do ponto; necessariamente a requisi\u00e7\u00e3o chegar\u00e1 ao n\u00f3 correto. De n\u00e3o estruturada a estruturada A seguinte tabela resume as diferen\u00e7as entre os dois tipos de redes sobrepostas. Estruturada N\u00e3o-Estruturada Estrutura bem definida Estrutura aleat\u00f3ria Adi\u00e7\u00e3o de dados \u00e9 lenta Adi\u00e7\u00e3o de dados \u00e9 r\u00e1pida Adi\u00e7\u00e3o de n\u00f3s \u00e9 lenta Adi\u00e7\u00e3o de n\u00f3s \u00e9 r\u00e1pida Busca por dados \u00e9 r\u00e1pida Busca por dados lenta Mas, e se pud\u00e9ssemos juntar o melhor dos dois mundos em um \u00fanico sistema? Isso \u00e9 poss\u00edvel em certos cen\u00e1rios. Por exemplo, seja uma grade \\(N \\times N\\) em que n\u00f3s se conectam aleatoriamente uns aos outros, e que n\u00f3s em uma borda da matriz conseguem se conectar aos n\u00f3s da borda oposta, com dist\u00e2ncia 1. Efetivamente, temos a rede sobreposta \u00e0 esquerda. Se cada n\u00f3 executar o seguinte protocolo, a rede evoluir\u00e1 da topologia n\u00e3o estruturada para a estruturada, \u00e0 direita. Divida a organiza\u00e7\u00e3o da topologia em dois m\u00f3dulos, um de descoberta de novos n\u00f3s e outro de sele\u00e7\u00e3o. O m\u00f3dulo de descoberta, repetidamente, pergunta aos seus vizinhos quem s\u00e3o os seus vizinhos e se conecta aos mesmos. O m\u00f3dulo de sele\u00e7\u00e3o computa a dist\u00e2ncia entre o n\u00f3 e todos os seus vizinhos e descarta as conex\u00f5es com maior dist\u00e2ncia, onde \\(a = (x,y), b = (x', y')\\) \\(dx_{a,b} = min(|x - x'|, N - |x - x'|)\\) \\(dy_{a,b} = min(|y - y'|, N - |y - y'|)\\) Ao final de m\u00faltiplas intera\u00e7\u00f5es, cada n\u00f3 ter\u00e1 como seus vizinhos, os n\u00f3s mais pr\u00f3ximos. Se a rede for completa (um n\u00f3 em cada posi\u00e7\u00e3o da grade), os vizinhos ser'\u00e3o os n\u00f3s \u00e0 direita, esquerda, acima e abaixo. A seguinte figura apresenta uma outra rede resultada da aplica\u00e7\u00e3o do mesmo princ\u00edpio, mas em uma \"grade\" 3D. Se em vez da dist\u00e2ncia cartesiana fosse usada a dist\u00e2ncia de Hamming entre os identificadores dos n\u00f3s, ao final das itera\u00e7\u00f5es, a topologia alcan\u00e7ada seria um hyper-cubo, como os da seguinte figura, no qual diversos esquemas de roteamento eficientes podem ser usados . 5 Sistemas P2P Arquitetura decentralizada; N\u00e3o h\u00e1 distin\u00e7\u00e3o de pap\u00e9is entre n\u00f3s ou conjuntos de n\u00f3s desempenham os mesmos pap\u00e9is, em parceria; Escalabilidade geogr\u00e1fica global, isto \u00e9, com n\u00f3s espalhados por todo o globo; Pode haver entrada e sa\u00edda de n\u00f3s do sistema com alta frequ\u00eancia; N\u00f3s se organizam em redes sobrepostas (em ingl\u00eas, overlay ), redes l\u00f3gicas sobre as redes f\u00edsicas; Auto-administra\u00e7\u00e3o. Resiliente a falhas Tabelas de Espalhamento Distribu\u00eddas (DHT) A versatilidade dos sistemas P2P os levaram a ser amplamente estudados e aplicados, sendo que entre as aplica\u00e7\u00f5es mais bem sucedidas est\u00e3o as Tabelas de Espalhamento Distribu\u00edds (DHT, do ingl\u00eas, Distributed Hash Tables ). As tabelas de espalhamento (tamb\u00e9m conhecidas como mapas, dicion\u00e1rios, arrays associativos) tem caracter\u00edsticas que a tornam adequadas ao armazenamento de dados a v\u00e1rios cen\u00e1rios. Em ess\u00eancia, estas tabelas s\u00e3o fun\u00e7\u00f5es que mapeiam uma chave para um valor, uma fun\u00e7\u00e3o \\(f\\) tal que \\(f(K): V \\cup\\) {null} \\(K\\) : Universo de chaves \\(V\\) : Universo de valores isto \u00e9, \\(f(k) = v, k\\in K, v \\in V\\) ou \\(v =\\) null. Na pr\u00e1tica, s\u00e3o estruturas de dados adapt\u00e1veis, com um API muito simples, e com opera\u00e7\u00f5es de tempo (mais ou menos) constante para fazer CRUD de pares chave/valor. Tanto \\(K\\) quanto \\(V\\) s\u00e3o blobs de dados, isto \u00e9, sem nenhuma forma distinta, e por isso podem ser usadas para resolver uma gama de problemas. API \\(put(k,v)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else \\(k \\rightarrow v\\) ; return \\(\\emptyset\\) \\(update(k,v)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else return \\(\\emptyset\\) \\(get(k)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else return \\(\\emptyset\\) \\(del(k)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else \\(k \\rightarrow v\\) ; return \\(\\emptyset\\) \\(k\\) e \\(v\\) s\u00e3o blobs execu\u00e7\u00e3o \\(O(1)\\) Se as tabelas de espalhamento s\u00e3o estruturas de dados \u00fateis, uma vers\u00e3o distribu\u00edda seria ainda mais \u00fatil, principalmente porqu\u00ea ela poderia ser tolerante a falhas e ter escalabilidade linear . \u00c9 justamente desta idea que surgem as DHT, literalmente tabelas de espalhamento distribu\u00eddas, estruturas de dados que mant\u00e9m a mesma API e funcionalidades de tabelas de espalhamento, mas que agrega capacidades de diversos hosts . Dentre os desafios na implementa\u00e7\u00e3o de uma DHT est\u00e3o O que usar como chave? Uma DHT deve ser vers\u00e1til para ser utilizada para v\u00e1rios fins, ent\u00e3o a chave precisa ser independente da aplica\u00e7\u00e3o. Como dividir a carga entre hosts? \u00c9 preciso balancear a carga para que um lado da rede n\u00e3o se torne mais importante que o outro e para n\u00e3o levar a uma hierarquiza\u00e7\u00e3o entre os n\u00f3s. Como rotear requisi\u00e7\u00f5es para o host correto? Uma vez que os dados devem ser particionados entre hosts para garantir escalabilidade, como encontrar o n\u00f3 onde determinado dado est\u00e1 or deveria estar? Identifica\u00e7\u00e3o A identifica\u00e7\u00e3o de objetos precisa ser facilmente determin\u00e1vel pela aplica\u00e7\u00e3o para permitir a recupera\u00e7\u00e3o precisa dos dados. Por exemplo, pode-se dividir faixas de nomes entre os processos. A -- C -- Host1 CA -- E -- Host2 EA -- G -- Host3 ... Esta distribui\u00e7\u00e3o tem tr\u00eas problemas graves. O primeiro, \u00e9 no fato de nomes n\u00e3o serem un\u00edvocos . Neste caso, uma exemplo melhor seria o uso do CPF. 000.000.000-00 -- 111.111.111-00 -- Host1 111.111.111-01 -- 222.222.222-00 -- Host2 222.222.222-01 -- 333.333.333-00 -- Host3 ... O segundo problema, presente tamb\u00e9m no uso de CPF, tem a ver com a distribui\u00e7\u00e3o da carga de trabalho entre os hosts. Nem nomes e nem CPF tem distribui\u00e7\u00e3o uniforme, ent\u00e3o alguns n\u00f3s ficariam mais carregados que outros. O terceiro problema tem a ver com o uso de chaves n\u00e3o gen\u00e9ricas, dependentes da aplica\u00e7\u00e3o. Para este problema, poder\u00edamos usar um identificador auto-increment\u00e1vel, por exemplo, mas em muitas situa\u00e7\u00f5es esta abordagem implicaria em dificuldade para se recuperar os dados: \"qual \u00e9 mesmo o identificador num\u00e9rico do livro How Fascism Works ?\" Para resolver estes tr\u00eas problemas, recorremos a uma abordagem usada na literatura da \u00e1rea, dividindo a identifica\u00e7\u00e3o em duas camadas: Seja \\(i\\) o identificador do objeto, dado pela aplica\u00e7\u00e3o (e.g., CPF, nome, telefone) Seja \\(h\\) uma fun\u00e7\u00e3o criptogr\u00e1fica Seja \\(k = h(i)\\) o identificador do objeto \\(i\\) . Divis\u00e3o da carga Se usarmos, por exemplo, MD5, \u00e9 fato que \\(k\\) tem distribui\u00e7\u00e3o uniforme no espa\u00e7o de 0 a \\(2^{160}-1\\) poss\u00edveis valores. Para dividirmos os dados entre os hosts tamb\u00e9m uniformemente, distribua os valores entre os hosts em fun\u00e7\u00e3o de \\(k\\) . Alguns exemplos de divis\u00e3o s\u00e3o: definia buckets para cada host e atribua o dado com chave \\(k\\) para bucket \\(k \\% b\\) , onde \\(b\\) \u00e9 o n\u00famero de buckets divida a faixa de valores em \\(b\\) segmentos e atribua a cada host uma faixa dados \\(2^n\\) hosts, atribua ao host \\(0 < x < 2^n-1\\) os dados cujas chaves terminem com o valor \\(x\\) . S\u00e3o v\u00e1rias as formas de se dividir os dados e estas est\u00e3o intimamente ligadas \u00e0 rede sobreposta que se pretende montar e a como o roteamento ser\u00e1 feito. Roteamento Para estudar o desafio do roteamento, nas se\u00e7\u00f5es seguintes estudaremos o Chord, um sistema P2P que surgiu no meio acad\u00eamico mas cujo design influenciou fortemente a ind\u00fastria no desenvolvimento dos bancos dados distribu\u00eddos NOSQL, como Cassandra, Dynamo, e Redis. Estudo de Caso: Chord Chord \u00e9 uma sistema P2P de m\u00faltiplas aplica\u00e7\u00f5es desenvolvido pelos membros do CSAIL , do MIT, e publicado em 2001. Desde ent\u00e3o, inspirou diversos outros sistemas, tornando-se sin\u00f4nimo com P2P. Identifica\u00e7\u00e3o No Chord o problema da identifica\u00e7\u00e3o dos dados \u00e9 resolvido usando-se chaves de \\(m\\) bits , geradas por meio de uma fun\u00e7\u00e3o hash criptogr\u00e1fica a partir de chaves que fa\u00e7a sentido para a aplica\u00e7\u00e3o, por exemplo nome, telefone, ou CPF. Como a fun\u00e7\u00e3o hash \u00e9 criptogr\u00e1fica, uma pequena varia\u00e7\u00e3o na entrada implica em grande varia\u00e7\u00e3o na sa\u00edda e, para quem observa apenas a sa\u00edda da fun\u00e7\u00e3o, uma sequ\u00eancia de chaves \u00e9 indistingu\u00edvel de uma sequ\u00eancia aleat\u00f3ria. Divis\u00e3o de carga A cada n\u00f3 \u00e9 atribu\u00eddo um identificador \u00fanico de \\(m\\) bits , gerado aleatoriamente. Como \\(m\\) normalmente \u00e9 grande, com mais de uma centena de bits, a probabilidade de dois n\u00f3s terem o mesmo identificar \u00e9 desprez\u00edvel. Al\u00e9m disso, os n\u00f3s se organizam em uma rede sobreposta estruturada na forma de um anel l\u00f3gico , em que os n\u00f3s aparecem ordenadamente de acordo com seus identificadores. A figura a seguir mostra um anel em cujo os n\u00f3s tem identificadores de 8 bits (0 a 253), com cinco n\u00f3s. 6 Assumamos inicialmente que os n\u00f3s s\u00f3 est\u00e3o cientes dos seus vizihos imediatos no anel. Cada chave \u00e9 associada a um n\u00f3, respons\u00e1vel por atender requisi\u00e7\u00f5es de cria\u00e7\u00e3o, consulta, modifica\u00e7\u00e3o e remo\u00e7\u00e3o dos dados relacionados \u00e0quela chave. A pseudo aleatoriedade na gera\u00e7\u00e3o da chave e a aleatoriedade na gera\u00e7\u00e3o dos identificadores de n\u00f3s faz com que a distribui\u00e7\u00e3o de carga entre os n\u00f3s seja uniforme. O dado com chave \\(k\\) \u00e9 responsabilidade do n\u00f3 com menor identificador \\(i \\geq k\\) , aka, sucessor de \\(k\\) ( \\(i = suc(k)\\) ), no anel. Na figura a seguir, \u00e9 apresentado junto a cada n\u00f3 as chaves pelas quais o n\u00f3 \u00e9 respons\u00e1vel. Roteamento Suponha que um cliente solicite ao Chord do exemplo anterior que armazene o valor \\(v\\) associado \u00e0 chave \\(k\\) . A solicita\u00e7\u00e3o \u00e9 feita pelo contato a um dos n\u00f3s no sistema, que pode ou n\u00e3o ser o respons\u00e1vel por \\(k\\) . Caso seja o respons\u00e1vel, a solicita\u00e7\u00e3o \u00e9 executada localmente e uma resposta devolvida ao cliente. Caso contr\u00e1rio, a requisi\u00e7\u00e3o deve repassada ou roteada para o n\u00f3 correto. Na rede estruturada definida at\u00e9 agora, uma op\u00e7\u00e3o \u00f3bvia \u00e9 repassar a requisi\u00e7\u00e3o para um dos vizinhos e assim sucessivamente at\u00e9 que alcance o n\u00f3 correto. Esta solu\u00e7\u00e3o, correta, tem custo da ordem do n\u00famero de n\u00f3s no sistema, \\(O(n)\\) . Em uma inst\u00e2ncia com milhares de n\u00f3s, \\(O(n)\\) \u00e9 um custo muito alto, ainda mais se considerarmos que cada salto na rede sobreposta potencialmente cruza toda a Internet, uma vez que, refor\u00e7ando, a proximidade na rede sobreposta n\u00e3o implica em proximidade na rede f\u00edsica abaixo. Observe que o custo em termos de espa\u00e7o para se implementar esta solu\u00e7\u00e3o \u00e9 \\(O(1)\\) para cada n\u00f3 do sistema. Em outras palavras, cada n\u00f3 mantem uma tabela de rotas com uma ou duas entradas, apontando para seus vizinhos. Com uma rede com milhares de n\u00f3s, uma solu\u00e7\u00e3o \\(O(n)\\) saltos, onde cada pode levar ao outro lado do planeta , opera\u00e7\u00f5es teriam uma lat\u00eancia muito alta. Para amenizar o custo, Chord prop\u00f5e a cria\u00e7\u00e3o de uma tabela de rotas, tamb\u00e9m conhecida como finger-table , que aponta para n\u00f3s no anel com dist\u00e2ncias que se dobram a cada entrada. A finger-table \u00e9 constru\u00edda da seguinte forma, onde \\(m\\) \u00e9 a quantidade de bits usados para identificar n\u00f3s no sistema: seja \\(F_p\\) a finger-table do processo \\(p\\) ; seja \\(F_p[i]\\) a \\(i\\) -\u00e9sima da tabela; e, \\(F_p[i] = suc(p+2^{i-1})\\) . Observe que nesta tabela, a \\(i\\) -\u00e9sima entrada aponta para o processo que no que sucede \\(p\\) pelo menos \\(2^{i-1}\\) , e que esta dist\u00e2ncia de sucess\u00e3o aumenta exponencialmente. Observe tamb\u00e9m que a maior dist\u00e2ncia \u00e9 proporcional a metade do tamanho do anel. Isto quer dizer que o \u00faltimo finger da tabela proporciona um salto de \\(1/2\\) anel, o pen\u00faltimo \\(1/4\\) do anel, o ante-pen\u00faltimo \\(1/8\\) , e assim sucessivamente. Outra forma de se ver esta tabela \u00e9 como proporcionando um salto de pelo menos metade da dist\u00e2ncia restante para o n\u00f3 respons\u00e1vel pela chave, resultando em um roteamento com custo \\(O(log n)\\) . Mas como este potencial \u00e9 explorado? Usando-se o seguinte algoritmo de busca pela entrada correta na tabela de roteamento, do ponto de vista do processo \\(p\\) : seja \\(k\\) a chave para qual estamos procurando o sucessor; itere pela tabela at\u00e9 achar a primeira entrada cujo valor, i.e., o identificador de um n\u00f3, \u00e9 maior que \\(k\\) ; se a entrada \u00e9 a primeira da tabela, ent\u00e3o encaminhe a requisi\u00e7\u00e3o para o n\u00f3 apontado, pois ele \u00e9 o sucessor de \\(k\\) , at\u00e9 onde \\(p\\) consegue determinar; sen\u00e3o, encaminhe a requisi\u00e7\u00e3o para a entrada anterior, pois o n\u00f3 referenciado est\u00e1 mais pr\u00f3ximo do sucessor para determin\u00e1-lo com seguran\u00e7a. Considere no exemplo a seguir a busca pelo sucessor de 26, iniciada pelo n\u00f3 1. Duas observa\u00e7\u00f5es s\u00e3o importantes aqui. A primeira, \u00e9 que as compara\u00e7\u00f5es para se encontrar a entrada correta, deve respeitar o anel, por exemplo, em um anel com 32 posi\u00e7\u00f5es, por exemplo, \\(31 < 0\\) . No seguinte exemplo, considere por exemplo a busca que o n\u00f3 21 faz pelo sucessor de 31; qual deve ser a entrada selecionada? A segunda observa\u00e7\u00e3o \u00e9 que n\u00e3o se pode encaminhar a requisi\u00e7\u00e3o diretamente para o n\u00f3 apontado na entrada encontrada, pois a vis\u00e3o de \\(p\\) pode ser incompleta para partes distantes do anel. Tente identificar exemplos no anel a seguir onde este comportamento seria errado. A organiza\u00e7\u00e3o dos n\u00f3s em um anel virtual e a distribui\u00e7\u00e3o da responsabilidade dos dados pelo particionamento do espa\u00e7o das chaves de forma correspondente \u00e0s faixas no anel l\u00f3gico \u00e9 a t\u00e9cnica conhecida como espalhamento consistente , do ingl\u00eas, consistent hashing . Churn Apesar do espalhamento consistente ser uma t\u00e9cnica muito \u00fatil, ela n\u00e3o resolve todos os problemas. Ali\u00e1s, v\u00e1rios outros problemas precisam ser resolvidos, sendo o primeiro deles lidar com a entrada e sa\u00edda de n\u00f3s, principalmente por falhas de n\u00f3s e comunica\u00e7\u00e3o. Quando um novo n\u00f3 entra do sistema, ele precisa seguir os seguintes passos: Escolher um novo Identificador \\(I\\) Identificar o sucessor \\(S\\) de \\(I\\) Identificar o antecessor \\(A\\) de \\(I\\) Informar \\(A\\) e \\(S\\) de sua entrada, para que ajustem suas tabelas de rota. \\(A\\) e \\(S\\) propagam a informa\u00e7\u00e3o da entrada de \\(I\\) para seus vizinhos, permitindo que ajustem suas tabelas de rota. Al\u00e9m disto, a reorganiza\u00e7\u00e3o dos n\u00f3s exige movimenta\u00e7\u00e3o de dados, pois parte dos dados armazenados em \\(S\\) , com chaves menores que \\(I\\) , precisam ser copiadas para \\(I\\) , o novo respons\u00e1vel. As principais quest\u00f5es a serem respondidas durante a movimenta\u00e7\u00e3o dos dados s\u00e3o como manter os dados dispon\u00edveis para inser\u00e7\u00e3o e consulta durante todo o processo, e como minimizar o impacto da reorganiza\u00e7\u00e3o nos n\u00f3s vizinhos ao novo n\u00f3 Quanto \u00e0 primeira quest\u00e3o, pode-se rotear as requisi\u00e7\u00f5es para os dois n\u00f3s respons\u00e1veis, o atual e o novo, e combinar as respostas, mantendo os dados mais recentes. Quanto \u00e0 segunda, uma op\u00e7\u00e3o \u00e9 fazer com que cada novo n\u00f3 assuma diversas posi\u00e7\u00f5es no anel, com identificadores distintos, passando a \"incomodar\" m\u00faltiplos processos, mas de forma mais suave. Embora se possa \"facilmente\" resolver os problemas da entrada de n\u00f3s, os da sa\u00edda s\u00e3o mais complexos, principalmente porqu\u00ea a sa\u00edda acontece geralmente bruscamente, por exemplo por falhas no sistema. Quanto \u00e0 reorganiza\u00e7\u00e3o das tabelas de rota, cada n\u00f3 precisa monitorar os n\u00f3s que figuram em sua tabela e, caso pare\u00e7am indispon\u00edveis, ajustar par apontar para outro n\u00f3. Contudo, caso a suspeita seja indevida, isto pode levar a dados serem consultados e armazenados nos n\u00f3s errados. Tamb\u00e9m com rela\u00e7\u00e3o aos dados, h\u00e1 o problema de n\u00e3o perd\u00ea-los quando o n\u00f3 respons\u00e1vel se torna indispon\u00edvel. O tratamento destes problemas est\u00e1 relacionado e \u00e9 feito pelo replica\u00e7\u00e3o dos dados em m\u00faltiplos n\u00f3s. Isto \u00e9 feito no Chord, por exemplo, da seguinte forma: para cada dado, com chave \\(k\\) , h\u00e1 \\(r\\) c\u00f3pias; a primeira c\u00f3pia \u00e9 mantida no sucessor de \\(k\\) ; a segunda c\u00f3pia, no sucessor do sucessor de \\(k\\) , e assim por diante; cada escrita \u00e9 feita na primeira c\u00f3pia, respondida, e replicada para as demais c\u00f3pias; cada leitura \u00e9 feita na c\u00f3pia com menor identificador. No caso de falha de uma c\u00f3pia, h\u00e1 \\(r-1\\) c\u00f3pias ainda dispon\u00edveis para responder \u00e0 requisi\u00e7\u00e3o, mantendo o sistema dispon\u00edvel a despeito de ( \\(r-1\\) ) falhas, no que se chama de degrada\u00e7\u00e3o graciosa . H\u00e1 contudo, um problema introduzido por esta abordagem. Assuma a seguinte sequ\u00eancia de passos, em um sistema com \\(r=2\\) . escrita na c\u00f3pia 1; resposta ao cliente; replica\u00e7\u00e3o para c\u00f3pia 2; escrita na c\u00f3pia 1; resposta ao cliente; falha da c\u00f3pia 1; leitura na c\u00f3pia 2. O cliente, ao ler o dado, l\u00ea uma vers\u00e3o antiga do mesmo, inconsistente com a vis\u00e3o que tinha do sistema. De fato, este tipo de sistema \u00e9 chamado de eventualmente consistente pois somente na aus\u00eancia de falhas e de escritas as diversas r\u00e9plicas ser\u00e3o consistentes umas com as outras. Continuemos a sequ\u00eancia: escrita na c\u00f3pia 2; c\u00f3pia 1 volta a funcionar; leitura na c\u00f3pia 1. Neste caso, a c\u00f3pia \"secund\u00e1ria\" 2 tem um dado mais atual, que precisa ser repassado para a c\u00f3pia 1; este movimento de converg\u00eancia de dados \u00e9 conhecido como anti-entropia. Finalmente, continuemos a sequ\u00eancia: escrita na c\u00f3pia 1, por outro cliente. Assim, ambas as c\u00f3pias, 1 e 2, tem dados derivados da primeira escrita, mas feitos \"concorrentemente\", um conflito . Qual dos dois \u00e9 o correto neste contexto? \u00c9 imposs\u00edvel apresentar uma estrat\u00e9gia gen\u00e9rica para resolver esta situa\u00e7\u00e3o, mas alguns sistemas usar\u00e3o uma estrat\u00e9gia do tipo \"a \u00faltima escrita vence\", onde a \u00faltima escrita pode ser determinada em por rel\u00f3gios l\u00f3gicos, vetoriais, tempo, e uma pitada de \"arranjo t\u00e9cnico\" para quebrar empates. O Dynamo, que veremos a seguir, \u00e9 um destes sistemas. Espalhamento Consistente Carga uniforme entre n\u00f3s. Todos os n\u00f3s sabem como rotear requisi\u00e7\u00f5es N\u00famero de saltos m\u00e9dio \u00e9 conhecido. O sistema se adapta a entrada e sa\u00edda de n\u00f3s, por falhas ou n\u00e3o. Refer\u00eancias https://www.cs.cmu.edu/~dga/15-744/S07/lectures/16-dht.pdf Estudo de Caso: DynamoDB DynamoDB \u00e9 o marco fundamental dos bancos de dados NoSQL. No v\u00eddeo a seguir um de seus evangelizadores, descreve rapidamente o banco, os cen\u00e1rios em que deveria ser usado e diversos padr\u00f5es de projeto para modelagem de dados. Enquanto o assiste, alguns pontos devem ser ressaltados sobre o Dynamo de forma espec\u00edfica e os NoSQL de forma geral: surgiram da necessidade de escalabilidade dos bancos de dados, isto \u00e9, da necessidade de lidar com milh\u00f5es e milh\u00f5es de entradas de dados, gerados e processados com baixa lat\u00eancia e alta vaz\u00e3o, a despeito de falhas; maior escalabilidade implica em maior exposi\u00e7\u00e3o a particionamentos da rede em que o sistema roda, que associado \u00e0 necessidade de manuten\u00e7\u00e3o de alta disponibilidade, implica em perda de garantias de consist\u00eancia (veremos o Teorema CAP adiante); Partition keys s\u00e3o as chaves usadas para roteamento dos dados, ou seja, as chaves discutidas anteriormente neste cap\u00edtulo sobre sistema P2P; Sort keys s\u00e3o chaves usadas dentro de cada n\u00f3 para ordenar os dados na hora de gerar as SSTables ( String Sorted Tables ), e se usadas em agregados de valores, s\u00e3o equivalentes ao GROUP BY do SQL; Lambda functions s\u00e3o fun\u00e7\u00f5es para processamento de dados executadas em entradas definidas por um pipeline de processamento sem a defini\u00e7\u00e3o expl\u00edcita de sockets e portas, em um modelo conhecido como Serverless . Este modelo \u00e9 adequado a algumas aplica\u00e7\u00f5es, como o carrinho de compras da Amazon.com, aplica\u00e7\u00e3o para a qual o Dynamodb foi inicialmente desenvolvido. Nesta aplica\u00e7\u00e3o, cada usu\u00e1rio tem um identificador \u00fanico , recuperado no momento em que se loga ao sistema da Amazon. Este identificador \u00fanico \u00e9 a chave de particionamento e os dados s\u00e3o o conte\u00fado do carrinho de compras. Para lidar com falhas, o conte\u00fado do carrinho \u00e9 replicado nos n\u00f3s sucessivos ao respons\u00e1vel pela dupla chave valor. O carrinho \u00e9 modificado atomicamente , isto \u00e9, sobrescrito por inteiro. A replica\u00e7\u00e3o, associada \u00e0s modifica\u00e7\u00f5es at\u00f4micas, potencializa conflitos, que s\u00e3o identificados comparando-se os vetores de vers\u00e3o (rel\u00f3gios vetoriais) associados a cada valor escrito. No caso de conflitos, as m\u00faltiplas c\u00f3pias concorrentes s\u00e3o apresentadas ao usu\u00e1rio na forma de um carrinho de compras com a uni\u00e3o dos itens nos respectivos carrinhos, de forma que o usu\u00e1rio possa corrig\u00ed-lo. Na pior das hip\u00f3teses, uma compra com erros ser\u00e1 feita, e necessitar\u00e1 de uma atividade compensat\u00f3ria para o usu\u00e1rio, como um brinde. Na pr\u00e1tica, muitos sistemas mant\u00e9m os pap\u00e9is de clientes, que requisitam a execu\u00e7\u00e3o de servi\u00e7os, e servidores, que executam as requisi\u00e7\u00f5es, mas distribuem as tarefas dos servidores entre pares para aquela fun\u00e7\u00e3o, sendo efetivamente sistemas h\u00edbridos. Este \u00e9 o caso dos bancos de dados NOSQL, como o Dynamo, que acabamos de estudar, e tamb\u00e9m do Cassandra, que veremos a seguir. Estudo de Caso: Cassandra Outra alternativa \u00e9 fazer com que cada n\u00f3 do sistema conhe\u00e7a todos os outros. Assim, cada requisi\u00e7\u00e3o pode ser diretamente encaminhada ao n\u00f3 respons\u00e1vel por trat\u00e1-la. O custo do roteamento, neste caso, \u00e9 \\(O(1)\\) , muito mais r\u00e1pido que na abordagem anterior. O custo de armazenamento da tabela de rotas \u00e9, contudo, \\(O(n)\\) , o que pode ser proibitivo em uma rede com milhares de n\u00f3s, apesar de ser uma solu\u00e7\u00e3o vi\u00e1vel em redes menores. Este \u00e9 o caso do CassandraDB, uma banco de dados distribu\u00eddo baseado no Chord, que estudaremos melhor mais adiante, considerado uma DHT de salto \u00fanico ( single-hop DHT). O CassandraDB foi, sem sombra de d\u00favida, influenciado pelo projeto do DynamoDB, o que \u00e9 facilmente explic\u00e1vel j\u00e1 que um dos criadores do Dynamo foi o arquiteto do Cassandra. Mas em vez de uma c\u00f3pia, o Cassandra largamente expande a funcionalidade do Dynamo ao se inspirar no banco de dados BigTable , do Google. Com isso, o Cassandra se aproxima do modelo relacional, facilitando o desenvolvimento de certas aplica\u00e7\u00f5es, sem perder as caracter\u00edsticas desej\u00e1veis das DHT. A principal caracter\u00edstica neste sentido \u00e9 o modelo h\u00edbrido chave-valor/relacional, em que os valores associados a uma chave s\u00e3o divididos em colunas. A combina\u00e7\u00e3o chave-colunas s\u00e3o denominadas column-families e seu conjunto keyspace . Estas duas estruturas s\u00e3o equivalente \u00e0s tabelas/rela\u00e7\u00f5es e aos bancos de dados, dos bancos de dados relacionais. Uma diferen\u00e7a fundamental entre column-families e rela\u00e7\u00f5es \u00e9 que as \u00faltimas precisam de um esquema pr\u00e9-definido, enquanto que as primeiras n\u00e3o tem um esquema. Isto quer dizer que novas colunas podem ser adicionadas dinamicamente e que nem todas precisam estar presentes para cada chave. De fato, m\u00faltiplos registros com a mesma chave, ou linhas, podem ter conjuntos de colunas diferentes. Para que o correto conjunto de colunas associado a uma chave possa ser apurado, ap\u00f3s m\u00faltiplas escritas com a mesma chave tenham ocorrido, a cada tupla (chave,coluna,valor) \u00e9 associado tamb\u00e9m um timestamp . . Assim, dados uma mesma chave e coluna, o valor v\u00e1lido \u00e9 o com o maior timestamp. Devido a possibilidade de valores serem escritos para diferentes colunas independentemente, valores v\u00e1lidos e inv\u00e1lidos podem ter o mesmo timestamp . Por exemplo, considere os seguintes dados escritos no banco: Chave Coluna \\(\\rightarrow\\) Valor Timestamp 3 Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 30 02:02:2020,13:45:00 3 Idade \\(\\rightarrow\\) 33 02:02:2020,13:50:00 3 Telefone \\(\\rightarrow\\) 333444554433 02:02:2020,13:55:00 Uma busca pelos dados associados \u00e0 chave 3 retornar\u00e1 o seguinte resultado: Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 33, Telefone \\(\\rightarrow\\) 333444554433. Para facilitar mais ainda o desenvolvimento, o Cassandra conta com uma linguagem de consulta similar ao SQL (Structured Query Language), a CQL (Cassandra Query Language). Assim, a consulta a estes dados seria mais ou menos como SELECT * FROM dados WHERE key == 3 . 7 H\u00e1 muitos recursos online para se aprender mais se aprender mais sobre como usar o Cassandra, por exemplo, aqui . H\u00e1 tamb\u00e9m diversos projetos de c\u00f3digo livre que o usam e podem ser estudados, por exemplo, o clone de Twiter Twissandra . Mas embora o uso de sistemas gerenciadores de bancos de dados em sistemas distribu\u00eddos seja interessante, aqui nos focaremos em alguns dos aspectos de como estes SGBD s\u00e3o constru\u00eddos. Detalhes de Implementa\u00e7\u00e3o A se\u00e7\u00e3o de tecnologias descreve v\u00e1rias estruturas de dados recorrentemente usadas em implementa\u00e7\u00e3o de bancos de dados como o Cassandra. Outros exemplos P2P \u00e9 terreno f\u00e9rtil e poder\u00edamos passar muito tempo apenas enumerando exemplos interessantes, mas nos limitaremos aqui a dois dos mais atuais. O primeiro \u00e9 o sistema de compartilhamento de arquivos j\u00e1 mencionado na introdu\u00e7\u00e3o , BitTorrent. O que h\u00e1 de mais interessante neste exemplo o fato de haverem diversas implementa\u00e7\u00f5es dos clientes, e.g., \\(\\mu\\) Torrent, Azureus, Transmission, Vuze, qTorrent, implemenados em diversas linguagens e para diversas plataformas, todos interoper\u00e1veis. Isso \u00e9 um atestado do que uma especifica\u00e7\u00e3o bem feita e aberta pode alcan\u00e7ar. O segundo \u00e9 o sistema que suporta a criptomoeda BitCoin, em que milhares de n\u00f3s armazenam coletivamente o hist\u00f3rico de transa\u00e7\u00f5es de trocas de dono das moedas. Mas em vez de expandir aqui este assunto, deferiremos esta discuss\u00e3o para a se\u00e7\u00e3o BlockChain . Apenas para abrir o apetite, Se voc\u00ea n\u00e3o pegou a refer\u00eancia, volte uma casa 2 um cap\u00edtulo. \u21a9 Se voc\u00ea n\u00e3o pegou esta refer\u00eancia, n\u00e3o teve inf\u00e2ncia. \u21a9 \"The hype cycle is a branded graphical presentation developed and used by the American research, advisory and information technology firm Gartner, for representing the maturity, adoption and social application of specific technologies.\" \u21a9 Peak of Inflated - Expectations Early publicity produces a number of success stories\u2014often accompanied by scores of failures. Some companies take action; most don't. Technology Trigger -- A potential technology breakthrough kicks things off. Early proof-of-concept stories and media interest trigger significant publicity. Often no usable products exist and commercial viability is unproven. Slope of Enlightenment -- More instances of how the technology can benefit the enterprise start to crystallize and become more widely understood. Second- and third-generation products appear from technology providers. More enterprises fund pilots; conservative companies remain cautious. Plateau of Productivity -- Mainstream adoption starts to take off. Criteria for assessing provider viability are more clearly defined. The technology's broad market applicability and relevance are clearly paying off. Trough of Disillusionmen - Interest wanes as experiments and implementations fail to deliver. Producers of the technology shake out or fail. Investment continues only if the surviving providers improve their products to the satisfaction of early adopters. \u21a9 \u21a9 Neste problema do ICPC, um esquema de nomea\u00e7\u00e3o dos n\u00f3s de um hypercube \u00e9 apresentado; usando este esquema, derive um algoritmo de roteamento em que a dist\u00e2ncia percorrida por qualquer mensagem seja sempre igual ao n\u00famero de dimens\u00f5es do cubo. \u21a9 Observe que as dist\u00e2ncias entre os n\u00f3s no anel foram desenhadas de forma proporcial \u00e0 diferen\u00e7a num\u00e9rica entre os identificadores. \u21a9 Este exemplo \u00e9 meramente ilustrativo e n\u00e3o segue estritamente a sintaxe do CQL. \u21a9","title":"Arquiteturas"},{"location":"arch/#arquiteturas","text":"De acordo com David Garlan and Mary Shaw, January 1994, CMU-CS-94-166, em An Introduction to Software Architecture ... an architectural style determines the vocabulary of components and connectors that can be used in instances of that style, together with a set of constraints on how they can be combined. These can include topological constraints on architectural descriptions (e.g., no cycles). Other constraints\u2014say, having to do with execution semantics\u2014might also be part of the style definition. Em outras palavras, um estilo ou padr\u00e3o arquitetural \u00e9 o conjunto de princ\u00edpios que prov\u00ea uma infraestrutura abstrata para uma fam\u00edlia de sistemas, e promove o reuso de projeto ao prover solu\u00e7\u00f5es para problemas recorrentes e frequentes . Quando falamos de arquiteturas em sistemas distribu\u00eddos, estamos primariamente focados na forma como os componentes do sistema interagem uns com os outros, por meio de conectores , para implementar a solu\u00e7\u00e3o para um problema.","title":"Arquiteturas"},{"location":"arch/#componentes-e-conectores","text":"Todo comp e conec graph LR A[Componente 1] --> C{Conector} --> B(Componente 2) Dependendo de como s\u00e3o conectados, haver\u00e1 maior ou menor depend\u00eancia entre os componentes. Quando houver forte depend\u00eancia, diremos que os componentes est\u00e3o fortemente acoplados ( tightly coupled ). Caso contr\u00e1rio, diremos que est\u00e3o fracamente acoplados ( loosely coupled ). A raz\u00e3o \u00f3bvia para preferir sistemas fracamente conectados \u00e9 sua capacidade de tolerar disrup\u00e7\u00f5es; se um componente depende pouco de outro, ent\u00e3o n\u00e3o se incomodar\u00e1 com sua aus\u00eancia por causa de uma falha. Certos middleware permitem um acoplamento t\u00e3o fraco entre componentes, que estes n\u00e3o precisam se conhecer ou sequer estar ativos no mesmo momento. Tamb\u00e9m a quest\u00e3o da simplifica\u00e7\u00e3o de API, uma vez que o middleware pode impor um padr\u00e3o a ser seguido por todos os componentes e minimizar a necessidade os componentes conhecerem as interfaces uns dos outros.","title":"Componentes e Conectores"},{"location":"arch/#clienteservidor","text":"A forma como os componentes se comunicam, isto \u00e9, os conectores usados, \u00e9 importante no estudo arquitetural. Mas tamb\u00e9m s\u00e3o importantes os pap\u00e9is assumidos pelos componentes na realiza\u00e7\u00e3o de tarefas. Neste sentido, provavelmente a arquitetura de computa\u00e7\u00e3o distribu\u00edda mais comum \u00e9 a Cliente/Servidor . Na arquitetura Cliente/Servidor, como implicado pelo nome, h\u00e1 um processo que serve a pedidos realizados por outros processos. Isto \u00e9 feito quando o cliente o contacta o servidor e requer ( request ) a realiza\u00e7\u00e3o do servi\u00e7o. O servidor , por sua vez, pode desempenhar tarefas como fazer c\u00e1lculos, armazenar dados, ou repassar uma mensagem e, ao final da realiza\u00e7\u00e3o da tarefa, responder ( response ) ao cliente. Um mesmo servidor pode atender a diversos clientes e, geralmente, a comunica\u00e7\u00e3o entre os mesmos \u00e9 feita diretamente por sockets. Embora seja poss\u00edvel usar sockets de forma ass\u00edncrona, a API mais comum \u00e9 s\u00edncrona, isto \u00e9, quando um processo espera receber uma mensagem de outro, ele fica bloqueado esperando algum dado estar dispon\u00edvel para leitura no referido socket. Assim, geralmente a comunica\u00e7\u00e3o entre cliente e servidor segue o seguinte esquema: sequenceDiagram activate Cliente note left of Servidor: Espera pela requisi\u00e7\u00e3o Cliente->>Servidor: Request deactivate Cliente activate Servidor note right of Cliente: Espera pela resposta note left of Servidor: Executa servi\u00e7o Servidor-->>Cliente: Resposta deactivate Servidor activate Cliente note left of Servidor: Espera pela requisi\u00e7\u00e3o deactivate Cliente Observe que o cliente fica inativo enquanto espera a resposta e que o servidor fica inativo enquanto espera outras requisi\u00e7\u00f5es. Para minimizar os per\u00edodos de inatividade, o cliente pode usar o socket ass\u00edncronamente, o que n\u00e3o \u00e9 exatamente simples, ou usar m\u00faltiplos threads, para que continue operando mesmo enquanto um thread estiver bloqueado esperando a resposta do servidor. No lado do servidor, o minimiza\u00e7\u00e3o da ociosidade \u00e9 feita pelo uso de m\u00faltiplos clientes, concorrentes, e tamb\u00e9m pelo uso de m\u00faltiplos threads. Neste caso, contudo, \u00e9 necess\u00e1rio tomar muito cuidado para garantir que a concorr\u00eancia n\u00e3o causar\u00e1 efeitos indesejados nos dados e execu\u00e7\u00e3o das tarefas. Veja o caso de um banco de dados transacional, por exemplo, como discutido acima; ele precisa garantir ACID entre as transa\u00e7\u00f5es propostas pelos clientes. Embora tenhamos colocado aqui apenas um servidor atendendo aos clientes, em muitas aplica\u00e7\u00f5es modernas, m\u00faltiplos servidores atender\u00e3o ao conjunto de clientes. Pense por exemplo no servi\u00e7o de email do Google, o Gmail. Com os milh\u00f5es de usu\u00e1rios que tem, certamente h\u00e1 mais de um servidor implementando o servi\u00e7o. Provavelmente estes diversos servidores ficam atr\u00e1s do que chamamos de um balanceador de carga, que roteia as requisi\u00e7\u00f5es seguindo diferentes pol\u00edticas, por exemplo, round robin .","title":"Cliente/Servidor"},{"location":"arch/#par-a-par-p2p","text":"Diferentemente de sistemas cliente/servidor, em que um n\u00f3 serve o outro, em sistemas par-a-par, os n\u00f3s s\u00e3o parceiros e tem igual responsabilidade (e da\u00ed o nome) na execu\u00e7\u00e3o das tarefas. Diversos sistemas P2P existem, sendo, provavelmente, os mais famosos, os sistemas de compartilhamento de arquivos. Nesta linha, embora diversos tenham existido, hoje o mais famoso \u00e9 o Bittorrent, mesmo que, como veremos adiante, n\u00e3o seja P2P puro. Outro exemplo importante por ter inspirado diversos outros sistemas \u00e9 o Chord. Neste sistema, n\u00f3s organizam-se em um anel l\u00f3gico e cada um se torna respons\u00e1vel por um dos segmentos do anel adjacente a onde se encontra no mesmo. Requisi\u00e7\u00f5es para correspondentes a um segmento s\u00e3o roteados para o n\u00f3 respons\u00e1vel usando uma tabela de rotas conhecida como finger table . Se tra\u00e7armos os caminhos apontados por esta tabela sobre o anel, desenharemos cordas sobre o mesmo, o que explica o nome do sistema.","title":"Par-a-Par (P2P)"},{"location":"arch/#hibridos","text":"Embora cliente/servidor e P2P sejam arquiteturas cl\u00e1ssicas, boa parte dos sistemas que distribu\u00eddos podem ser na verdade consideradas h\u00edbridos. Considere um sistema de email, por exemplo. Embora clientes usem as funcionalidades dos servidores de email para enviar e receber mensagens, os servidores conversam uns com os outros para implementar a tarefa de encaminhar as mensagens. Neste sentido, o sistema \u00e9 um h\u00edbrido P2P e cliente/servidor. Outros exemplos abundam. Bancos de dados, e.g., DynamoDB, CassandraDB , Redis,... Jogos multiplayer (pense no particionamento dos mapas ) Compartilhamento de arquivos: Bittorrent Voltemos ao exemplo do Bittorrent; observe na figura adiante os diversos passos necess\u00e1rios \u00e0 recupera\u00e7\u00e3o do arquivo de interesse neste sistema. Diversos passos seguem a arquitetura cliente/servidor enquanto \"somente\" o passo de compartilhamento de arquivos \u00e9 P2P. Voltando ao exemplo do sistema de informa\u00e7\u00e3o, observe que o cliente acessa um servi\u00e7o, implementado por pares de n\u00f3s. Podemos dizer que tamb\u00e9m este \u00e9 h\u00edbrido. graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B","title":"H\u00edbridos"},{"location":"arch/#sistemas-multi-camadas","text":"Outra forma de hibridismo que podemos citar \u00e9 quando um componente haje tanto como cliente quanto como servidor. Veja o seguinte exemplo, conhecido no meio como arquitetura em 3-camadas (3 tiers ). Neste caso, \u00e9 interessante notar que esta disposi\u00e7\u00e3o dos componentes \u00e9 independente da disposi\u00e7\u00e3o f\u00edsica. De fato, as tr\u00eas camadas podem estar em um mesmo n\u00f3, ou combinadas duas a duas, neste \u00faltimo caso resultando em duas camadas. Por outro lado, cada camada pode ser subdividida em mais componentes, resultando em m\u00faltiplos tiers, como neste exemplo de um sistema de busca na Web.","title":"Sistemas multi-camadas"},{"location":"arch/#outras-arquiteturas","text":"Diversas outras arquiteturas podem e foram propostas para o desenvolvimento de Sistemas Distribu\u00eddos. A moda da vez \u00e9 a chamada arquitetura de micro servi\u00e7os, na qual a divis\u00e3o de tarefas entre componentes visa levar aos componentes mais simples para tal tarefa. Assim, os mesmos podem ser replicados, escalonados, desenvolvidos e mantidos independentemnte. Cada tarefa conta ent\u00e3o com diversos componentes, organizados em camadas resolvendo um problema em espec\u00edfico, mas todos contribuindo para a realiza\u00e7\u00e3o de uma tarefa maior comum. N\u00f3s discutiremos micro-servi\u00e7os mais adiante. Por agora, apenas tenha em mente que embora seja vendido por muitos como tal, os micro-servi\u00e7os n\u00e3o s\u00e3o uma panac\u00e9ia . Uma extrapola\u00e7\u00e3o que pode ser feita aqui, refor\u00e7ando a observa\u00e7\u00e3o que problemas (e solu\u00e7\u00f5es) de sistemas distribu\u00eddos s\u00e3o refletidos em n\u00edvel de processamento paralelo e concorrente, \u00e9 que a uma arquitetura SEDA lembra em muito a arquitetura de micro-servi\u00e7os . Todo Event sourcing Todo MOM Todo Pub/Sub","title":"Outras arquiteturas"},{"location":"arch/#para-aprender-mais","text":"Para aprender mais sobre arquiteturas, consulte a seguinte refer\u00eancia: Distributed System Architectures and Architectural Styles . Para aprender um pouco sobre como funcionam as redes de um datacenter , definidas por software, assista ao seguinte v\u00eddeo, que fala sobre a infra-estrutura do Facebook.","title":"Para aprender mais"},{"location":"arch/#cliente-servidor","text":"Como brevemente discutido em Fundamentos , quando pensamos em termos de comunica\u00e7\u00e3o entre dois processos usando sockets, em geral pensamos em processos clientes e servidores, onde servidores esperam a conex\u00e3o por parte de clientes e executam as opera\u00e7\u00f5es requisitadas pelos mesmos. Como exemplos desta arquitetura, podemos pensar em um navegador requisitando a um servidor Apache que lhe retorne uma p\u00e1gina Web, ou em um aplicativo m\u00f3vel solicitando ao servidor de aplica\u00e7\u00f5es que dispare uma transfer\u00eancia de fundos. Um exemplo gen\u00e9rico \u00e9 apresentado na figura a seguir. sequenceDiagram activate Servidor activate Cliente note left of Servidor: Cria socket e espera por conex\u00f5es deactivate Servidor Cliente->>+Servidor: Connect? note left of Servidor: Aceita conex\u00e3o Servidor->>-Cliente: Connect! note right of Cliente: Ativo (gerando requisi\u00e7\u00e3o) note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) Cliente->>+Servidor: Request deactivate Cliente note right of Cliente: Inativo (esperando resposta) note left of Servidor: Ativo (processando requisi\u00e7\u00e3o) Servidor-->>-Cliente: Response activate Cliente note right of Cliente: Ativo (processando resposta note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) deactivate Cliente O modelo cliente/servidor forma a base da computa\u00e7\u00e3o distribu\u00edda, sobre a qual todos os outros modelos s\u00e3o implementados. Uma das raz\u00f5es \u00e9 hist\u00f3rica: os primeiros sistemas a permitirem a opera\u00e7\u00e3o por m\u00faltiplos usu\u00e1rios, ainda na d\u00e9cada de 60, eram compostos de uma host robusto ao qual se conectavam diversos terminais, essencialmente com teclado e monitor, isto \u00e9, um servidor e v\u00e1rios clientes. Com a redu\u00e7\u00e3o dos computadores, surgiram as primeiras redes de computadores e a necessidade de uma abstra\u00e7\u00e3o para o estabelecimento de comunica\u00e7\u00e3o entre processos em hosts distintos, e assim surgiram os sockets . Com os sockets, vem uma grande flexibilidade, pois um processo n\u00e3o precisa saber como o outro manuseia os dados que lhe cabem, desde que siga um protocolo pr\u00e9-estabelecido na comunica\u00e7\u00e3o. Isto \u00e9, processos podem ser implementado em diferentes linguagens, sistemas operacionais e arquiteturas, desde observadas os cuidados necess\u00e1rios para se obter transpar\u00eancia de acesso . Esta flexibilidade \u00e9 a outra raz\u00e3o do sucesso do modelo cliente/servidor, permitindo que clientes se conectem a servidores para usar seus recursos, que podem ser acessados concorrentemente por diversos clientes. Exemplos cotidianos disto s\u00e3o servidores de bancos de dados, de p\u00e1ginas Web e email. De fato, esta flexibilidade permite que diversas aplica\u00e7\u00f5es continuem operando de forma centralizada, com servidores rodando, por exemplo, em mainframes e clientes rodando de forma emulada por software em computadores pessoais. Contudo, em certas situa\u00e7\u00f5es, esta divis\u00e3o entre clientes e servidores pode ser tornar confusa. Primeiro, porqu\u00ea uma vez estabelecida a conex\u00e3o, n\u00e3o h\u00e1 uma diferencia\u00e7\u00e3o entre quem iniciou e quem aceitou a mesma; s\u00e3o apenas duas pontas do mesmo socket. Segundo, pode ser que o servi\u00e7o relevante sendo prestado, seja prestado por quem estabelece a conex\u00e3o. De fato ambos podem estar prestando servi\u00e7os um para o outro, no que \u00e9 conhecido como P2P. Terceiro, um mesmo processo pode atuar tanto como cliente quanto como servidor, no que \u00e9 conhecido como arquitetura multicamadas, tamb\u00e9m a ser visto adiante. Quarto, usando-se sockets como base, podemos construir outros modelos de comunica\u00e7\u00e3o entre processos, efetivamente colocando camadas na nossa cebola. 1 A seguir, exploraremos as arquiteturas constru\u00eddas sobre cliente/servidor.","title":"Cliente Servidor"},{"location":"arch/#arquitetura-orientada-a-microsservicos","text":"No dia 3 de Junho de 2020, termo microservice resultava em 6.6 milh\u00f5es de resultados no Google . Isso porqu\u00ea a organiza\u00e7\u00e3o de aplica\u00e7\u00f5es distribu\u00eddas na forma de \"pequenos\" processos, especializados e independentes, que colaboram para implementar um servi\u00e7o maior, se tornou um padr\u00e3o importante no desenvolvimento de novas aplica\u00e7\u00f5es. Exatamente por isso, precisamos come\u00e7ar com um aviso: diversas tecnologias surgiram com grande estrondo, sendo alguns exemplos recentes Docker, Golang, Angular, e JQuery, e embora seja certo que algumas destas encontrar\u00e3o seus nichos, como fizeram antes delas Cobol, C, e SQL, outras deparecer\u00e3o da face da ind\u00fastria; afinal, quem sabe o que \u00e9 Delphi e quem ainda usa JQuery? Este fen\u00f4meno \u00e9 capturado pelas v\u00e1rias fases do hype-cycle da Gartner. 3 A Arquitetura Orientada a Microsservi\u00e7os, tendo atingido o pico das expectativas infladas 4 em 2017, est\u00e1 deslizando na Trough of Desilusionment 4 em 2019. Isto \u00e9, este modelo de desenvolvimento n\u00e3o \u00e9 mais propagandeado como uma bala de prata para todas as aplica\u00e7\u00f5es distribu\u00eddas. Ainda assim, \u00e9 um importante modelo. Mas afinal, o que \u00e9 a arquitetura de microsservi\u00e7os? Em vez de explicar diretamente o que s\u00e3o, pode ser mais f\u00e1cil pensar primeiro termos do que n\u00e3o s\u00e3o, em termoss de sistemas monol\u00edticos.","title":"Arquitetura Orientada a Microsservi\u00e7os"},{"location":"arch/#monolitos","text":"Muitas aplica\u00e7\u00f5es seguem o modelo de 3 camadas em que em um dos extremos tem-se a interface com os usu\u00e1rios, materializada normalmente por um navegador, no outro tem-se um SGBD onde s\u00e3o armazenados os dados da aplica\u00e7\u00e3o, e, no meio, a l\u00f3gica do neg\u00f3cio. A camada central, implementada por um \u00fanico processo, que alimenta a interface com o usu\u00e1rio, manipula o modelo de dados, e onde reside a l\u00f3gica do neg\u00f3cio, \u00e9 um monolito . Monolitos seguem um modelo simples e largamente utilizado de desenvolvimento em que v\u00e1rios contribuidores implementam partes distintas da l\u00f3gica, que s\u00e3o compiladas em colocadas em desenvolvimento de forma at\u00f4mica: Desenvolva Teste Implante loop Simples n\u00e3o quer dizer necessariamente eficiente; no caso de atualiza\u00e7\u00f5es de uma parte do sistema, todo o monolito precisa ser trocado, incorrendo em indisponibilidade total do sistema, mesmo das partes n\u00e3o modificadas. Esta dificuldade tende a limitar as janelas de atualiza\u00e7\u00e3o do sistema, o que aumenta no n\u00famero de mudan\u00e7as que ocorrem a cada atualiza\u00e7\u00e3o, o que aumenta o risco de regress\u00f5es e portanto requer mais testes, o que aumenta o intervalo entre janelas de atualiza\u00e7\u00e3o. Al\u00e9m disso, nos caso de bugs, \u00e9 mais dif\u00edcil encontrar o problema, uma vez que fica imposs\u00edvel os desenvolvedores conhecerem todo o sistema. Isso apenas exacerba o problema, o que limita mais ainda as atualiza\u00e7\u00f5es, gerando um ciclo vicioso que mantem desenvolvedores acordados nas madrugadas de sexta para s\u00e1bado quando \u00e9 dia de deploy . Sistemas monol\u00edticos tamb\u00e9m podem ser problem\u00e1ticos quanto \u00e0 escalabilidde, pois quando a capacidade do sistema \u00e9 atingida, ou todo o sistema \u00e9 movido para um host de maior capacidade ou todo o sistema deve ser replicado. Na primeira abordagem, o custo geralmente \u00e9 um impecilho, pois pre\u00e7os de hardware crescem exponencialmente. Al\u00e9m disso, um servidor, por mais parrudo que seja, \u00e9 um Ponto \u00danico de Falha (ou SPOF, do ingl\u00eas single point of failure ). Quanto \u00e0 segunda abordagem, ela traz complexidades na coordena\u00e7\u00e3o das r\u00e9plicas e inefici\u00eancias ao replicar inclusive as partes subutilizadas. Ambas as abordagens tamb\u00e9m esbarram na escalabilidade do banco de dados que lhes serve de backend . Para contornar ou pelo menos minimizar estes problemas, pode-se fragmentar o servi\u00e7o e o banco de dados, o que facilita tanto a escalabilidade vertical quanto horizontal de cada m\u00f3dulo, que \u00e9 menor e mais simples de coordenar, e divide a carga nos bancos de dados; mas isso \u00e9 a troca do serv\u00ed\u00e7o monol\u00edtico por microsservi\u00e7os.","title":"Monolitos"},{"location":"arch/#microsservicos","text":"De acordo com Lewis & Fowler The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. Em outras palavras, com os microsservi\u00e7os, quebra-se o monolito em diferentes processos, \" small autonomous services that work together, modelled around a business domain \", cada um gerenciando os dados relevantes para aquela parte do sistema e, possivelmente, sua pr\u00f3pria intera\u00e7\u00e3o com o usu\u00e1rio. Este modelo tem implica\u00e7\u00f5es diretas no desenvolvimento: cada processo \u00e9 desenvolvido por um time diferente, que mantem controle sobre desenvolvimento, teste, e manuten\u00e7\u00e3o em produ\u00e7\u00e3o, o que \u00e9 fact\u00edvel j\u00e1 que cada servi\u00e7o \u00e9 simples e focado em um problema pequeno e ningu\u00e9m tem que entender em detalhas o funcionamento de todo o sistema. Al\u00e9m disso, quando um servi\u00e7o precisa ser atualizado, todos os demais podem continuar operantes e poss\u00edvel at\u00e9 que m\u00faltiplas vers\u00f5es do mesmo servi\u00e7o sejam executadas concorrentemente, possibilitando atualiza\u00e7\u00f5es sem janelas de manuten\u00e7\u00e3o. Quanto \u00e0 escalabilidade, esta \u00e9 feita indepentendentemente tamb\u00e9m; no exemplo na imagem seguinte, \u00e9 prov\u00e1vel que o servi\u00e7o de acesso ao cat\u00e1logo seja mais utilizado que os demais e portanto merecedor de mais recursos e mais c\u00f3pias. Como se percebe facilmente, o uso de microsservi\u00e7os pode ser relacionado \u00e0s t\u00e9cnicas de processamento paralelo: trate dados diferentes em blocos diferentes (paralelismo de dados ou replica\u00e7\u00e3o) e trate fun\u00e7\u00f5es diferentes em blocos diferentes (paralelismo de tarefas ou sharding ). Como na computa\u00e7\u00e3o paralela, na componentiza\u00e7\u00e3o \u00e9 importante considerar os requisitos das diferentes tarefas em termos de CPU, E/S, e mem\u00f3ria, para que possam escalar independentemente e n\u00e3o gerar gargalos desnecess\u00e1rios.","title":"Microsservi\u00e7os"},{"location":"arch/#do-monolito-aos-microsservicos","text":"Com tantas vantagens, suge a d\u00favida se todos os sistemas deveriam ser desenvolvidos usando-se a arquitetura de microsservi\u00e7os. A resposta \u00e9 n\u00e3o , pois como colocado no in\u00edcio desta se\u00e7\u00e3o, n\u00e3o existem balas de prata e se um sistema monol\u00edtico est\u00e1 funcionando para voc\u00ea e n\u00e3o h\u00e1 perspectiva de problemas acometerem (a demanda no sistema n\u00e3o est\u00e1 aumentando, a l\u00f3gica do sistema \u00e9 muito simples, indisponibilidade n\u00e3o te traz preju\u00edzo, voc\u00ea n\u00e3o pode arcar com a refatora\u00e7\u00e3o), ent\u00e3o mantenha seu sistema como est\u00e1. Caso haja a necessidade de evolu\u00e7\u00e3o e o modelo de microsservi\u00e7os pare\u00e7a adequado, existem recomenda\u00e7\u00f5es de como a migra\u00e7\u00e3o pode ser feita. Primeiro, \u00e9 preciso aceitar que o desenvolvimento de microsservi\u00e7os afeta a organiza\u00e7\u00e3o do time de desenvolvimento e que a organiza\u00e7\u00e3o provavelmente refletir\u00e1 a arquitetura. O desenvolvimento, manuten\u00e7\u00e3o e opera\u00e7\u00e3o de microsservi\u00e7os acontece em times pequenos, de 1 a 8 pessoas (\"pizza team\"), dependendo da complexidade do servi\u00e7o; se houver a necessidade de mais pesssoas no time, o escopo do microsservi\u00e7o provavelmente est\u00e1 grande demais; cada componente resolve um problema, bem. Segundo, a mudan\u00e7a n\u00e3o dever\u00e1 acontecer atomicamente. Uma boa estrat\u00e9gia \u00e9 identificar uma parte do sistema que funcionaria bem como microsservi\u00e7o, desenvolv\u00ea-la e modificar o monolito para usar o microsservi\u00e7o. O aprendizado ent\u00e3o \u00e9 usado para encontrar novo candidato e o procedimento \u00e9 iterado at\u00e9 que o monolito seja apenas uma casca e possa tamb\u00e9m ser removido. Mais f\u00e1cil dito que feito, h\u00e1 muita documenta\u00e7\u00e3o orientando o processo. Para saber mais Como esta arquitetura n\u00e3o faz parte ainda do nosso curr\u00edculo, n\u00e3o nos aprofundaremos nela aqui. Felizmente h\u00e1 muito material na Web sobre este modelo, sendo a lista a seguir uma \u00ednfima fra\u00e7\u00e3o. Para uma explica\u00e7\u00e3o geral do que s\u00e3o, assista a Martin Fowler no v\u00eddeo seguinte, assista ou consulte os v\u00e1rios artigos no seu s\u00edtio . Para entender os princ\u00edpios por tr\u00e1s do uso da arquitetura, Para um exemplo importante do uso de microsservi\u00e7os, considere a Netflix, que usa microsservi\u00e7os em larga escala em seus servi\u00e7os. Qu\u00e3o larga? \"...over five hundred services... we don't know how many...\" Apesar de tal uso, ou justamente por causa dele, seus servi\u00e7os mant\u00e9m uma \"...availability of 9.995...\", ou seja, ficam indispon\u00edveis por menos de 16 segundos por ano . Com respeito a estar preparado para falhas, afinal \"... it is not if failures will happen... ... it is when it happens...\", a empresa usa uma abordagem de inje\u00e7\u00e3o de falhas em servi\u00e7os em produ\u00e7\u00e3o. Os diferentes tiposde falhas s\u00e3o injetados por um \" ex\u00e9rcito de macacos do caos \" Para uma vis\u00e3o pr\u00e1tica da implementa\u00e7\u00e3o de microsservi\u00e7os usando AWS, veja TODO SOA - Foco no uso de outras formas de comunica\u00e7\u00e3o para chegar em outras arquiteturas. MOM Publish/Subscribe Message Queues Event Sourcing Stream Processing/Event Sourcing Kafka Overview","title":"Do Monolito aos Microsservi\u00e7os"},{"location":"arch/#par-a-par-peer-to-peer-p2p","text":"Nos sistemas que seguem a arquitetura Par-a-Par, ou simplesmente P2P, h\u00e1 uma substitui\u00e7\u00e3o dos pap\u00e9is de clientes e servidores, em que h\u00e1 uma \"hirarquia\" entre os componentes, por uma onde todos os n\u00f3s s\u00e3o pares na execu\u00e7\u00e3o da tarefa em quest\u00e3o. Um exemplo comum destas arquitetura s\u00e3o os sistemas de compartilhamento de arquivos, em que cada n\u00f3 armazena e disponibiliza parte dos dados, bem como acessa os dados disponibilizados por outros n\u00f3s. Como todo sistema distribu\u00eddo, a arquitetura P2P visa agregar poder computacional de m\u00faltiplos n\u00f3s . Mas al\u00e9m disso, pelo n\u00e3o diferencia\u00e7\u00e3o dos componentes, espera-se tolerar falhas de componentes sem paralizar o servi\u00e7o , uma vez que n\u00e3o h\u00e1 um componenente centralizador, detentor \u00fanico de uma certa funcionalidade. Os sistemas P2P tendem portanto a lever a maior disponibilidade. Historicamente, e devido \u00e0s caracter\u00edsticas j\u00e1 mencionadas, os sistemas P2P tem outra caracter\u00edstica muito importante, a alta escalabilidade a que se oferecerem, chegando a n\u00edveis globais. Se pensarmos por exemplo nos sistemas de compartilhamento de arquivos, m\u00fasicas e filmes, raz\u00e3o da fama e inf\u00e2mia da arquitetura, teremos bons exemplos disso. Para que isso seja poss\u00edvel, estes sistemas precisam se tornar auto-gerenci\u00e1veis , pois sistemas globais devem tolerar entrada e sa\u00edda frequente de n\u00f3s (por falhas ou a\u00e7\u00e3o de seus usu\u00e1rios), diferentes dom\u00ednios administrativos , e heterogeneidade na comunica\u00e7\u00e3o. Uma das ferramentas utilizadas para simplificar o trabalho de auto-gerenciamento \u00e9 o conceito de redes sobrepostas .","title":"Par-a-Par (Peer-to-Peer, P2P)"},{"location":"arch/#rede-sobreposta-overlay","text":"Os componentes de um sistema P2P se organizam em uma rede l\u00f3gica, sobreposta \u00e0 rede f\u00edsica. Nesta rede l\u00f3gica, os processos estabelecem canais de comunica\u00e7\u00e3o tipicamente na forma de conex\u00f5es TCP/IP. Por serem ignorantes \u00e0 topologia f\u00edsica da rede e usarem a pilha de comunica\u00e7\u00e3o IP, as redes sobrepostas s\u00e3o mais simples e ao mesmo tempo mais poderosas. Nestas redes s\u00e3o executados diversos algoritmos, como de descoberta de n\u00f3s, roteamento de pacotes e de otimiza\u00e7\u00e3o de rotas pelo descarte e cria\u00e7\u00e3o de conex\u00f5es. Uma vez que as conex\u00f5es na rede sobreposta n\u00e3o correspondem a conex\u00f5es f\u00edsicas, como se pode ver na seguinte figura, vizinhos em um rede sobreposta n\u00e3o necessariamente correspondem a vizinhos na rede f\u00edsica e vice-versa. Isto tamb\u00e9m implica que a otimiza\u00e7\u00e3o da rota l\u00f3gica n\u00e3o necessariamente leva \u00e0 otimiza\u00e7\u00e3o da rota f\u00edsica. Todo A figura n\u00e3o mostra hosts, apenas roteadores. Trocar por figura em com hosts, roteadores, e processos nos hosts. Dependendo em como esta rede \u00e9 organizada (ou n\u00e3o), a mesma \u00e9 classificada como estruturada ou n\u00e3o-estruturada .","title":"Rede Sobreposta (Overlay)"},{"location":"arch/#rede-nao-estruturada","text":"Se a rede sobreposta \u00e9 constru\u00edda de forma aleat\u00f3ria, por exemplo deixando os n\u00f3s se conectarem apenas aos vizinhos na rede no ponto em que se conectaram inicialmente, ent\u00e3o esta \u00e9 denominada uma rede n\u00e3o-estruturada . A figura a seguir \u00e9 um exemplo que se percebe que n\u00f3s tem graus diferentes de conectividade e que n\u00e3o est\u00e3o particularmente organizados em nenhuma topologia. Suponha que esta rede seja usada para armazenar e consultar dados. Inser\u00e7\u00f5es de dados podem ser feitas muito rapidamente, armazenando-os no primeiro n\u00f3 dispon\u00edvel encontrado. Os objetos amarelo e vermelho foram inseridos desta forma, e copiados em n\u00f3s pr\u00f3ximos para tolerar a falha de alguns hosts sem perder os dados. Buscas, contudo, ter\u00e3o que vasculhar a rede usando algoritmos como busca em largura , busca em profundidade ou caminhada aleat\u00f3ria (resposta probabil\u00edstica).","title":"Rede N\u00e3o-Estruturada"},{"location":"arch/#rede-estruturada","text":"Se as conex\u00f5es s\u00e3o constru\u00eddas e mantidas de forma a gerar uma topologia bem definida, chamamos esta rede de estruturada . Nesta rede, a inser\u00e7\u00e3o de n\u00f3s requer a propaga\u00e7\u00e3o desta informa\u00e7\u00e3o para outros n\u00f3s e a atualiza\u00e7\u00e3o das conex\u00f5es para manter a estrutura. A estrutura geralmente serve ao prop\u00f3sito de associar os n\u00f3s aos dados de uma forma planejada. Por exemplo, n\u00f3s pr\u00f3ximos na rede podem ser respons\u00e1veis por dados logicamente pr\u00f3ximos. Claramente, a inser\u00e7\u00e3o e acesso a dados nesta rede \u00e9 mais custosa, pois independentemente de onde a requisi\u00e7\u00e3o \u00e9 feita, isto \u00e9, a partir de qual n\u00f3, ela dever\u00e1 ser atendida por um n\u00f3 espec\u00edfico. Veja o exemplo do Chord, uma rede P2P em que os n\u00f3s formam um anel l\u00f3gico, cujos detalhes veremos adiante. Cada n\u00f3 \u00e9 respons\u00e1vel pela faixa de valores indexados por chaves entre o identificador do n\u00f3 e o do n\u00f3 anterior. Logo, qualquer inser\u00e7\u00e3o ou consulta de dados, deve ser feita especificamente para um determinado n\u00f3, e deve ser roteada para o mesmo. A estrutura da rede permite que tal roteamento seja feito eficientemente, no n\u00edvel da rede sobreposta. Como outro exemplo considere uma rede em que os n\u00f3s armazenam informa\u00e7\u00f5es sobre os dados de uma certa \u00e1rea geogr\u00e1fica e que n\u00f3s vizinhos na rede sejam aqueles respons\u00e1veis por \u00e1reas que se tocam. Neste exemplo, para se acessar os dados de um certo ponto no mapa, basta rotear a requisi\u00e7\u00e3o para o vizinho mais pr\u00f3ximo do ponto; necessariamente a requisi\u00e7\u00e3o chegar\u00e1 ao n\u00f3 correto.","title":"Rede Estruturada"},{"location":"arch/#de-nao-estruturada-a-estruturada","text":"A seguinte tabela resume as diferen\u00e7as entre os dois tipos de redes sobrepostas. Estruturada N\u00e3o-Estruturada Estrutura bem definida Estrutura aleat\u00f3ria Adi\u00e7\u00e3o de dados \u00e9 lenta Adi\u00e7\u00e3o de dados \u00e9 r\u00e1pida Adi\u00e7\u00e3o de n\u00f3s \u00e9 lenta Adi\u00e7\u00e3o de n\u00f3s \u00e9 r\u00e1pida Busca por dados \u00e9 r\u00e1pida Busca por dados lenta Mas, e se pud\u00e9ssemos juntar o melhor dos dois mundos em um \u00fanico sistema? Isso \u00e9 poss\u00edvel em certos cen\u00e1rios. Por exemplo, seja uma grade \\(N \\times N\\) em que n\u00f3s se conectam aleatoriamente uns aos outros, e que n\u00f3s em uma borda da matriz conseguem se conectar aos n\u00f3s da borda oposta, com dist\u00e2ncia 1. Efetivamente, temos a rede sobreposta \u00e0 esquerda. Se cada n\u00f3 executar o seguinte protocolo, a rede evoluir\u00e1 da topologia n\u00e3o estruturada para a estruturada, \u00e0 direita. Divida a organiza\u00e7\u00e3o da topologia em dois m\u00f3dulos, um de descoberta de novos n\u00f3s e outro de sele\u00e7\u00e3o. O m\u00f3dulo de descoberta, repetidamente, pergunta aos seus vizinhos quem s\u00e3o os seus vizinhos e se conecta aos mesmos. O m\u00f3dulo de sele\u00e7\u00e3o computa a dist\u00e2ncia entre o n\u00f3 e todos os seus vizinhos e descarta as conex\u00f5es com maior dist\u00e2ncia, onde \\(a = (x,y), b = (x', y')\\) \\(dx_{a,b} = min(|x - x'|, N - |x - x'|)\\) \\(dy_{a,b} = min(|y - y'|, N - |y - y'|)\\) Ao final de m\u00faltiplas intera\u00e7\u00f5es, cada n\u00f3 ter\u00e1 como seus vizinhos, os n\u00f3s mais pr\u00f3ximos. Se a rede for completa (um n\u00f3 em cada posi\u00e7\u00e3o da grade), os vizinhos ser'\u00e3o os n\u00f3s \u00e0 direita, esquerda, acima e abaixo. A seguinte figura apresenta uma outra rede resultada da aplica\u00e7\u00e3o do mesmo princ\u00edpio, mas em uma \"grade\" 3D. Se em vez da dist\u00e2ncia cartesiana fosse usada a dist\u00e2ncia de Hamming entre os identificadores dos n\u00f3s, ao final das itera\u00e7\u00f5es, a topologia alcan\u00e7ada seria um hyper-cubo, como os da seguinte figura, no qual diversos esquemas de roteamento eficientes podem ser usados . 5 Sistemas P2P Arquitetura decentralizada; N\u00e3o h\u00e1 distin\u00e7\u00e3o de pap\u00e9is entre n\u00f3s ou conjuntos de n\u00f3s desempenham os mesmos pap\u00e9is, em parceria; Escalabilidade geogr\u00e1fica global, isto \u00e9, com n\u00f3s espalhados por todo o globo; Pode haver entrada e sa\u00edda de n\u00f3s do sistema com alta frequ\u00eancia; N\u00f3s se organizam em redes sobrepostas (em ingl\u00eas, overlay ), redes l\u00f3gicas sobre as redes f\u00edsicas; Auto-administra\u00e7\u00e3o. Resiliente a falhas","title":"De n\u00e3o estruturada a estruturada"},{"location":"arch/#tabelas-de-espalhamento-distribuidas-dht","text":"A versatilidade dos sistemas P2P os levaram a ser amplamente estudados e aplicados, sendo que entre as aplica\u00e7\u00f5es mais bem sucedidas est\u00e3o as Tabelas de Espalhamento Distribu\u00edds (DHT, do ingl\u00eas, Distributed Hash Tables ). As tabelas de espalhamento (tamb\u00e9m conhecidas como mapas, dicion\u00e1rios, arrays associativos) tem caracter\u00edsticas que a tornam adequadas ao armazenamento de dados a v\u00e1rios cen\u00e1rios. Em ess\u00eancia, estas tabelas s\u00e3o fun\u00e7\u00f5es que mapeiam uma chave para um valor, uma fun\u00e7\u00e3o \\(f\\) tal que \\(f(K): V \\cup\\) {null} \\(K\\) : Universo de chaves \\(V\\) : Universo de valores isto \u00e9, \\(f(k) = v, k\\in K, v \\in V\\) ou \\(v =\\) null. Na pr\u00e1tica, s\u00e3o estruturas de dados adapt\u00e1veis, com um API muito simples, e com opera\u00e7\u00f5es de tempo (mais ou menos) constante para fazer CRUD de pares chave/valor. Tanto \\(K\\) quanto \\(V\\) s\u00e3o blobs de dados, isto \u00e9, sem nenhuma forma distinta, e por isso podem ser usadas para resolver uma gama de problemas. API \\(put(k,v)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else \\(k \\rightarrow v\\) ; return \\(\\emptyset\\) \\(update(k,v)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else return \\(\\emptyset\\) \\(get(k)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else return \\(\\emptyset\\) \\(del(k)\\) : if \\(k \\rightarrow w\\) then return \\(w\\) else \\(k \\rightarrow v\\) ; return \\(\\emptyset\\) \\(k\\) e \\(v\\) s\u00e3o blobs execu\u00e7\u00e3o \\(O(1)\\) Se as tabelas de espalhamento s\u00e3o estruturas de dados \u00fateis, uma vers\u00e3o distribu\u00edda seria ainda mais \u00fatil, principalmente porqu\u00ea ela poderia ser tolerante a falhas e ter escalabilidade linear . \u00c9 justamente desta idea que surgem as DHT, literalmente tabelas de espalhamento distribu\u00eddas, estruturas de dados que mant\u00e9m a mesma API e funcionalidades de tabelas de espalhamento, mas que agrega capacidades de diversos hosts . Dentre os desafios na implementa\u00e7\u00e3o de uma DHT est\u00e3o O que usar como chave? Uma DHT deve ser vers\u00e1til para ser utilizada para v\u00e1rios fins, ent\u00e3o a chave precisa ser independente da aplica\u00e7\u00e3o. Como dividir a carga entre hosts? \u00c9 preciso balancear a carga para que um lado da rede n\u00e3o se torne mais importante que o outro e para n\u00e3o levar a uma hierarquiza\u00e7\u00e3o entre os n\u00f3s. Como rotear requisi\u00e7\u00f5es para o host correto? Uma vez que os dados devem ser particionados entre hosts para garantir escalabilidade, como encontrar o n\u00f3 onde determinado dado est\u00e1 or deveria estar?","title":"Tabelas de Espalhamento Distribu\u00eddas (DHT)"},{"location":"arch/#identificacao","text":"A identifica\u00e7\u00e3o de objetos precisa ser facilmente determin\u00e1vel pela aplica\u00e7\u00e3o para permitir a recupera\u00e7\u00e3o precisa dos dados. Por exemplo, pode-se dividir faixas de nomes entre os processos. A -- C -- Host1 CA -- E -- Host2 EA -- G -- Host3 ... Esta distribui\u00e7\u00e3o tem tr\u00eas problemas graves. O primeiro, \u00e9 no fato de nomes n\u00e3o serem un\u00edvocos . Neste caso, uma exemplo melhor seria o uso do CPF. 000.000.000-00 -- 111.111.111-00 -- Host1 111.111.111-01 -- 222.222.222-00 -- Host2 222.222.222-01 -- 333.333.333-00 -- Host3 ... O segundo problema, presente tamb\u00e9m no uso de CPF, tem a ver com a distribui\u00e7\u00e3o da carga de trabalho entre os hosts. Nem nomes e nem CPF tem distribui\u00e7\u00e3o uniforme, ent\u00e3o alguns n\u00f3s ficariam mais carregados que outros. O terceiro problema tem a ver com o uso de chaves n\u00e3o gen\u00e9ricas, dependentes da aplica\u00e7\u00e3o. Para este problema, poder\u00edamos usar um identificador auto-increment\u00e1vel, por exemplo, mas em muitas situa\u00e7\u00f5es esta abordagem implicaria em dificuldade para se recuperar os dados: \"qual \u00e9 mesmo o identificador num\u00e9rico do livro How Fascism Works ?\" Para resolver estes tr\u00eas problemas, recorremos a uma abordagem usada na literatura da \u00e1rea, dividindo a identifica\u00e7\u00e3o em duas camadas: Seja \\(i\\) o identificador do objeto, dado pela aplica\u00e7\u00e3o (e.g., CPF, nome, telefone) Seja \\(h\\) uma fun\u00e7\u00e3o criptogr\u00e1fica Seja \\(k = h(i)\\) o identificador do objeto \\(i\\) .","title":"Identifica\u00e7\u00e3o"},{"location":"arch/#divisao-da-carga","text":"Se usarmos, por exemplo, MD5, \u00e9 fato que \\(k\\) tem distribui\u00e7\u00e3o uniforme no espa\u00e7o de 0 a \\(2^{160}-1\\) poss\u00edveis valores. Para dividirmos os dados entre os hosts tamb\u00e9m uniformemente, distribua os valores entre os hosts em fun\u00e7\u00e3o de \\(k\\) . Alguns exemplos de divis\u00e3o s\u00e3o: definia buckets para cada host e atribua o dado com chave \\(k\\) para bucket \\(k \\% b\\) , onde \\(b\\) \u00e9 o n\u00famero de buckets divida a faixa de valores em \\(b\\) segmentos e atribua a cada host uma faixa dados \\(2^n\\) hosts, atribua ao host \\(0 < x < 2^n-1\\) os dados cujas chaves terminem com o valor \\(x\\) . S\u00e3o v\u00e1rias as formas de se dividir os dados e estas est\u00e3o intimamente ligadas \u00e0 rede sobreposta que se pretende montar e a como o roteamento ser\u00e1 feito.","title":"Divis\u00e3o da carga"},{"location":"arch/#roteamento","text":"Para estudar o desafio do roteamento, nas se\u00e7\u00f5es seguintes estudaremos o Chord, um sistema P2P que surgiu no meio acad\u00eamico mas cujo design influenciou fortemente a ind\u00fastria no desenvolvimento dos bancos dados distribu\u00eddos NOSQL, como Cassandra, Dynamo, e Redis.","title":"Roteamento"},{"location":"arch/#estudo-de-caso-chord","text":"Chord \u00e9 uma sistema P2P de m\u00faltiplas aplica\u00e7\u00f5es desenvolvido pelos membros do CSAIL , do MIT, e publicado em 2001. Desde ent\u00e3o, inspirou diversos outros sistemas, tornando-se sin\u00f4nimo com P2P.","title":"Estudo de Caso: Chord"},{"location":"arch/#identificacao_1","text":"No Chord o problema da identifica\u00e7\u00e3o dos dados \u00e9 resolvido usando-se chaves de \\(m\\) bits , geradas por meio de uma fun\u00e7\u00e3o hash criptogr\u00e1fica a partir de chaves que fa\u00e7a sentido para a aplica\u00e7\u00e3o, por exemplo nome, telefone, ou CPF. Como a fun\u00e7\u00e3o hash \u00e9 criptogr\u00e1fica, uma pequena varia\u00e7\u00e3o na entrada implica em grande varia\u00e7\u00e3o na sa\u00edda e, para quem observa apenas a sa\u00edda da fun\u00e7\u00e3o, uma sequ\u00eancia de chaves \u00e9 indistingu\u00edvel de uma sequ\u00eancia aleat\u00f3ria.","title":"Identifica\u00e7\u00e3o"},{"location":"arch/#divisao-de-carga","text":"A cada n\u00f3 \u00e9 atribu\u00eddo um identificador \u00fanico de \\(m\\) bits , gerado aleatoriamente. Como \\(m\\) normalmente \u00e9 grande, com mais de uma centena de bits, a probabilidade de dois n\u00f3s terem o mesmo identificar \u00e9 desprez\u00edvel. Al\u00e9m disso, os n\u00f3s se organizam em uma rede sobreposta estruturada na forma de um anel l\u00f3gico , em que os n\u00f3s aparecem ordenadamente de acordo com seus identificadores. A figura a seguir mostra um anel em cujo os n\u00f3s tem identificadores de 8 bits (0 a 253), com cinco n\u00f3s. 6 Assumamos inicialmente que os n\u00f3s s\u00f3 est\u00e3o cientes dos seus vizihos imediatos no anel. Cada chave \u00e9 associada a um n\u00f3, respons\u00e1vel por atender requisi\u00e7\u00f5es de cria\u00e7\u00e3o, consulta, modifica\u00e7\u00e3o e remo\u00e7\u00e3o dos dados relacionados \u00e0quela chave. A pseudo aleatoriedade na gera\u00e7\u00e3o da chave e a aleatoriedade na gera\u00e7\u00e3o dos identificadores de n\u00f3s faz com que a distribui\u00e7\u00e3o de carga entre os n\u00f3s seja uniforme. O dado com chave \\(k\\) \u00e9 responsabilidade do n\u00f3 com menor identificador \\(i \\geq k\\) , aka, sucessor de \\(k\\) ( \\(i = suc(k)\\) ), no anel. Na figura a seguir, \u00e9 apresentado junto a cada n\u00f3 as chaves pelas quais o n\u00f3 \u00e9 respons\u00e1vel.","title":"Divis\u00e3o de carga"},{"location":"arch/#roteamento_1","text":"Suponha que um cliente solicite ao Chord do exemplo anterior que armazene o valor \\(v\\) associado \u00e0 chave \\(k\\) . A solicita\u00e7\u00e3o \u00e9 feita pelo contato a um dos n\u00f3s no sistema, que pode ou n\u00e3o ser o respons\u00e1vel por \\(k\\) . Caso seja o respons\u00e1vel, a solicita\u00e7\u00e3o \u00e9 executada localmente e uma resposta devolvida ao cliente. Caso contr\u00e1rio, a requisi\u00e7\u00e3o deve repassada ou roteada para o n\u00f3 correto. Na rede estruturada definida at\u00e9 agora, uma op\u00e7\u00e3o \u00f3bvia \u00e9 repassar a requisi\u00e7\u00e3o para um dos vizinhos e assim sucessivamente at\u00e9 que alcance o n\u00f3 correto. Esta solu\u00e7\u00e3o, correta, tem custo da ordem do n\u00famero de n\u00f3s no sistema, \\(O(n)\\) . Em uma inst\u00e2ncia com milhares de n\u00f3s, \\(O(n)\\) \u00e9 um custo muito alto, ainda mais se considerarmos que cada salto na rede sobreposta potencialmente cruza toda a Internet, uma vez que, refor\u00e7ando, a proximidade na rede sobreposta n\u00e3o implica em proximidade na rede f\u00edsica abaixo. Observe que o custo em termos de espa\u00e7o para se implementar esta solu\u00e7\u00e3o \u00e9 \\(O(1)\\) para cada n\u00f3 do sistema. Em outras palavras, cada n\u00f3 mantem uma tabela de rotas com uma ou duas entradas, apontando para seus vizinhos. Com uma rede com milhares de n\u00f3s, uma solu\u00e7\u00e3o \\(O(n)\\) saltos, onde cada pode levar ao outro lado do planeta , opera\u00e7\u00f5es teriam uma lat\u00eancia muito alta. Para amenizar o custo, Chord prop\u00f5e a cria\u00e7\u00e3o de uma tabela de rotas, tamb\u00e9m conhecida como finger-table , que aponta para n\u00f3s no anel com dist\u00e2ncias que se dobram a cada entrada. A finger-table \u00e9 constru\u00edda da seguinte forma, onde \\(m\\) \u00e9 a quantidade de bits usados para identificar n\u00f3s no sistema: seja \\(F_p\\) a finger-table do processo \\(p\\) ; seja \\(F_p[i]\\) a \\(i\\) -\u00e9sima da tabela; e, \\(F_p[i] = suc(p+2^{i-1})\\) . Observe que nesta tabela, a \\(i\\) -\u00e9sima entrada aponta para o processo que no que sucede \\(p\\) pelo menos \\(2^{i-1}\\) , e que esta dist\u00e2ncia de sucess\u00e3o aumenta exponencialmente. Observe tamb\u00e9m que a maior dist\u00e2ncia \u00e9 proporcional a metade do tamanho do anel. Isto quer dizer que o \u00faltimo finger da tabela proporciona um salto de \\(1/2\\) anel, o pen\u00faltimo \\(1/4\\) do anel, o ante-pen\u00faltimo \\(1/8\\) , e assim sucessivamente. Outra forma de se ver esta tabela \u00e9 como proporcionando um salto de pelo menos metade da dist\u00e2ncia restante para o n\u00f3 respons\u00e1vel pela chave, resultando em um roteamento com custo \\(O(log n)\\) . Mas como este potencial \u00e9 explorado? Usando-se o seguinte algoritmo de busca pela entrada correta na tabela de roteamento, do ponto de vista do processo \\(p\\) : seja \\(k\\) a chave para qual estamos procurando o sucessor; itere pela tabela at\u00e9 achar a primeira entrada cujo valor, i.e., o identificador de um n\u00f3, \u00e9 maior que \\(k\\) ; se a entrada \u00e9 a primeira da tabela, ent\u00e3o encaminhe a requisi\u00e7\u00e3o para o n\u00f3 apontado, pois ele \u00e9 o sucessor de \\(k\\) , at\u00e9 onde \\(p\\) consegue determinar; sen\u00e3o, encaminhe a requisi\u00e7\u00e3o para a entrada anterior, pois o n\u00f3 referenciado est\u00e1 mais pr\u00f3ximo do sucessor para determin\u00e1-lo com seguran\u00e7a. Considere no exemplo a seguir a busca pelo sucessor de 26, iniciada pelo n\u00f3 1. Duas observa\u00e7\u00f5es s\u00e3o importantes aqui. A primeira, \u00e9 que as compara\u00e7\u00f5es para se encontrar a entrada correta, deve respeitar o anel, por exemplo, em um anel com 32 posi\u00e7\u00f5es, por exemplo, \\(31 < 0\\) . No seguinte exemplo, considere por exemplo a busca que o n\u00f3 21 faz pelo sucessor de 31; qual deve ser a entrada selecionada? A segunda observa\u00e7\u00e3o \u00e9 que n\u00e3o se pode encaminhar a requisi\u00e7\u00e3o diretamente para o n\u00f3 apontado na entrada encontrada, pois a vis\u00e3o de \\(p\\) pode ser incompleta para partes distantes do anel. Tente identificar exemplos no anel a seguir onde este comportamento seria errado. A organiza\u00e7\u00e3o dos n\u00f3s em um anel virtual e a distribui\u00e7\u00e3o da responsabilidade dos dados pelo particionamento do espa\u00e7o das chaves de forma correspondente \u00e0s faixas no anel l\u00f3gico \u00e9 a t\u00e9cnica conhecida como espalhamento consistente , do ingl\u00eas, consistent hashing .","title":"Roteamento"},{"location":"arch/#churn","text":"Apesar do espalhamento consistente ser uma t\u00e9cnica muito \u00fatil, ela n\u00e3o resolve todos os problemas. Ali\u00e1s, v\u00e1rios outros problemas precisam ser resolvidos, sendo o primeiro deles lidar com a entrada e sa\u00edda de n\u00f3s, principalmente por falhas de n\u00f3s e comunica\u00e7\u00e3o. Quando um novo n\u00f3 entra do sistema, ele precisa seguir os seguintes passos: Escolher um novo Identificador \\(I\\) Identificar o sucessor \\(S\\) de \\(I\\) Identificar o antecessor \\(A\\) de \\(I\\) Informar \\(A\\) e \\(S\\) de sua entrada, para que ajustem suas tabelas de rota. \\(A\\) e \\(S\\) propagam a informa\u00e7\u00e3o da entrada de \\(I\\) para seus vizinhos, permitindo que ajustem suas tabelas de rota. Al\u00e9m disto, a reorganiza\u00e7\u00e3o dos n\u00f3s exige movimenta\u00e7\u00e3o de dados, pois parte dos dados armazenados em \\(S\\) , com chaves menores que \\(I\\) , precisam ser copiadas para \\(I\\) , o novo respons\u00e1vel. As principais quest\u00f5es a serem respondidas durante a movimenta\u00e7\u00e3o dos dados s\u00e3o como manter os dados dispon\u00edveis para inser\u00e7\u00e3o e consulta durante todo o processo, e como minimizar o impacto da reorganiza\u00e7\u00e3o nos n\u00f3s vizinhos ao novo n\u00f3 Quanto \u00e0 primeira quest\u00e3o, pode-se rotear as requisi\u00e7\u00f5es para os dois n\u00f3s respons\u00e1veis, o atual e o novo, e combinar as respostas, mantendo os dados mais recentes. Quanto \u00e0 segunda, uma op\u00e7\u00e3o \u00e9 fazer com que cada novo n\u00f3 assuma diversas posi\u00e7\u00f5es no anel, com identificadores distintos, passando a \"incomodar\" m\u00faltiplos processos, mas de forma mais suave. Embora se possa \"facilmente\" resolver os problemas da entrada de n\u00f3s, os da sa\u00edda s\u00e3o mais complexos, principalmente porqu\u00ea a sa\u00edda acontece geralmente bruscamente, por exemplo por falhas no sistema. Quanto \u00e0 reorganiza\u00e7\u00e3o das tabelas de rota, cada n\u00f3 precisa monitorar os n\u00f3s que figuram em sua tabela e, caso pare\u00e7am indispon\u00edveis, ajustar par apontar para outro n\u00f3. Contudo, caso a suspeita seja indevida, isto pode levar a dados serem consultados e armazenados nos n\u00f3s errados. Tamb\u00e9m com rela\u00e7\u00e3o aos dados, h\u00e1 o problema de n\u00e3o perd\u00ea-los quando o n\u00f3 respons\u00e1vel se torna indispon\u00edvel. O tratamento destes problemas est\u00e1 relacionado e \u00e9 feito pelo replica\u00e7\u00e3o dos dados em m\u00faltiplos n\u00f3s. Isto \u00e9 feito no Chord, por exemplo, da seguinte forma: para cada dado, com chave \\(k\\) , h\u00e1 \\(r\\) c\u00f3pias; a primeira c\u00f3pia \u00e9 mantida no sucessor de \\(k\\) ; a segunda c\u00f3pia, no sucessor do sucessor de \\(k\\) , e assim por diante; cada escrita \u00e9 feita na primeira c\u00f3pia, respondida, e replicada para as demais c\u00f3pias; cada leitura \u00e9 feita na c\u00f3pia com menor identificador. No caso de falha de uma c\u00f3pia, h\u00e1 \\(r-1\\) c\u00f3pias ainda dispon\u00edveis para responder \u00e0 requisi\u00e7\u00e3o, mantendo o sistema dispon\u00edvel a despeito de ( \\(r-1\\) ) falhas, no que se chama de degrada\u00e7\u00e3o graciosa . H\u00e1 contudo, um problema introduzido por esta abordagem. Assuma a seguinte sequ\u00eancia de passos, em um sistema com \\(r=2\\) . escrita na c\u00f3pia 1; resposta ao cliente; replica\u00e7\u00e3o para c\u00f3pia 2; escrita na c\u00f3pia 1; resposta ao cliente; falha da c\u00f3pia 1; leitura na c\u00f3pia 2. O cliente, ao ler o dado, l\u00ea uma vers\u00e3o antiga do mesmo, inconsistente com a vis\u00e3o que tinha do sistema. De fato, este tipo de sistema \u00e9 chamado de eventualmente consistente pois somente na aus\u00eancia de falhas e de escritas as diversas r\u00e9plicas ser\u00e3o consistentes umas com as outras. Continuemos a sequ\u00eancia: escrita na c\u00f3pia 2; c\u00f3pia 1 volta a funcionar; leitura na c\u00f3pia 1. Neste caso, a c\u00f3pia \"secund\u00e1ria\" 2 tem um dado mais atual, que precisa ser repassado para a c\u00f3pia 1; este movimento de converg\u00eancia de dados \u00e9 conhecido como anti-entropia. Finalmente, continuemos a sequ\u00eancia: escrita na c\u00f3pia 1, por outro cliente. Assim, ambas as c\u00f3pias, 1 e 2, tem dados derivados da primeira escrita, mas feitos \"concorrentemente\", um conflito . Qual dos dois \u00e9 o correto neste contexto? \u00c9 imposs\u00edvel apresentar uma estrat\u00e9gia gen\u00e9rica para resolver esta situa\u00e7\u00e3o, mas alguns sistemas usar\u00e3o uma estrat\u00e9gia do tipo \"a \u00faltima escrita vence\", onde a \u00faltima escrita pode ser determinada em por rel\u00f3gios l\u00f3gicos, vetoriais, tempo, e uma pitada de \"arranjo t\u00e9cnico\" para quebrar empates. O Dynamo, que veremos a seguir, \u00e9 um destes sistemas. Espalhamento Consistente Carga uniforme entre n\u00f3s. Todos os n\u00f3s sabem como rotear requisi\u00e7\u00f5es N\u00famero de saltos m\u00e9dio \u00e9 conhecido. O sistema se adapta a entrada e sa\u00edda de n\u00f3s, por falhas ou n\u00e3o.","title":"Churn"},{"location":"arch/#referencias","text":"https://www.cs.cmu.edu/~dga/15-744/S07/lectures/16-dht.pdf","title":"Refer\u00eancias"},{"location":"arch/#estudo-de-caso-dynamodb","text":"DynamoDB \u00e9 o marco fundamental dos bancos de dados NoSQL. No v\u00eddeo a seguir um de seus evangelizadores, descreve rapidamente o banco, os cen\u00e1rios em que deveria ser usado e diversos padr\u00f5es de projeto para modelagem de dados. Enquanto o assiste, alguns pontos devem ser ressaltados sobre o Dynamo de forma espec\u00edfica e os NoSQL de forma geral: surgiram da necessidade de escalabilidade dos bancos de dados, isto \u00e9, da necessidade de lidar com milh\u00f5es e milh\u00f5es de entradas de dados, gerados e processados com baixa lat\u00eancia e alta vaz\u00e3o, a despeito de falhas; maior escalabilidade implica em maior exposi\u00e7\u00e3o a particionamentos da rede em que o sistema roda, que associado \u00e0 necessidade de manuten\u00e7\u00e3o de alta disponibilidade, implica em perda de garantias de consist\u00eancia (veremos o Teorema CAP adiante); Partition keys s\u00e3o as chaves usadas para roteamento dos dados, ou seja, as chaves discutidas anteriormente neste cap\u00edtulo sobre sistema P2P; Sort keys s\u00e3o chaves usadas dentro de cada n\u00f3 para ordenar os dados na hora de gerar as SSTables ( String Sorted Tables ), e se usadas em agregados de valores, s\u00e3o equivalentes ao GROUP BY do SQL; Lambda functions s\u00e3o fun\u00e7\u00f5es para processamento de dados executadas em entradas definidas por um pipeline de processamento sem a defini\u00e7\u00e3o expl\u00edcita de sockets e portas, em um modelo conhecido como Serverless . Este modelo \u00e9 adequado a algumas aplica\u00e7\u00f5es, como o carrinho de compras da Amazon.com, aplica\u00e7\u00e3o para a qual o Dynamodb foi inicialmente desenvolvido. Nesta aplica\u00e7\u00e3o, cada usu\u00e1rio tem um identificador \u00fanico , recuperado no momento em que se loga ao sistema da Amazon. Este identificador \u00fanico \u00e9 a chave de particionamento e os dados s\u00e3o o conte\u00fado do carrinho de compras. Para lidar com falhas, o conte\u00fado do carrinho \u00e9 replicado nos n\u00f3s sucessivos ao respons\u00e1vel pela dupla chave valor. O carrinho \u00e9 modificado atomicamente , isto \u00e9, sobrescrito por inteiro. A replica\u00e7\u00e3o, associada \u00e0s modifica\u00e7\u00f5es at\u00f4micas, potencializa conflitos, que s\u00e3o identificados comparando-se os vetores de vers\u00e3o (rel\u00f3gios vetoriais) associados a cada valor escrito. No caso de conflitos, as m\u00faltiplas c\u00f3pias concorrentes s\u00e3o apresentadas ao usu\u00e1rio na forma de um carrinho de compras com a uni\u00e3o dos itens nos respectivos carrinhos, de forma que o usu\u00e1rio possa corrig\u00ed-lo. Na pior das hip\u00f3teses, uma compra com erros ser\u00e1 feita, e necessitar\u00e1 de uma atividade compensat\u00f3ria para o usu\u00e1rio, como um brinde. Na pr\u00e1tica, muitos sistemas mant\u00e9m os pap\u00e9is de clientes, que requisitam a execu\u00e7\u00e3o de servi\u00e7os, e servidores, que executam as requisi\u00e7\u00f5es, mas distribuem as tarefas dos servidores entre pares para aquela fun\u00e7\u00e3o, sendo efetivamente sistemas h\u00edbridos. Este \u00e9 o caso dos bancos de dados NOSQL, como o Dynamo, que acabamos de estudar, e tamb\u00e9m do Cassandra, que veremos a seguir.","title":"Estudo de Caso: DynamoDB"},{"location":"arch/#estudo-de-caso-cassandra","text":"Outra alternativa \u00e9 fazer com que cada n\u00f3 do sistema conhe\u00e7a todos os outros. Assim, cada requisi\u00e7\u00e3o pode ser diretamente encaminhada ao n\u00f3 respons\u00e1vel por trat\u00e1-la. O custo do roteamento, neste caso, \u00e9 \\(O(1)\\) , muito mais r\u00e1pido que na abordagem anterior. O custo de armazenamento da tabela de rotas \u00e9, contudo, \\(O(n)\\) , o que pode ser proibitivo em uma rede com milhares de n\u00f3s, apesar de ser uma solu\u00e7\u00e3o vi\u00e1vel em redes menores. Este \u00e9 o caso do CassandraDB, uma banco de dados distribu\u00eddo baseado no Chord, que estudaremos melhor mais adiante, considerado uma DHT de salto \u00fanico ( single-hop DHT). O CassandraDB foi, sem sombra de d\u00favida, influenciado pelo projeto do DynamoDB, o que \u00e9 facilmente explic\u00e1vel j\u00e1 que um dos criadores do Dynamo foi o arquiteto do Cassandra. Mas em vez de uma c\u00f3pia, o Cassandra largamente expande a funcionalidade do Dynamo ao se inspirar no banco de dados BigTable , do Google. Com isso, o Cassandra se aproxima do modelo relacional, facilitando o desenvolvimento de certas aplica\u00e7\u00f5es, sem perder as caracter\u00edsticas desej\u00e1veis das DHT. A principal caracter\u00edstica neste sentido \u00e9 o modelo h\u00edbrido chave-valor/relacional, em que os valores associados a uma chave s\u00e3o divididos em colunas. A combina\u00e7\u00e3o chave-colunas s\u00e3o denominadas column-families e seu conjunto keyspace . Estas duas estruturas s\u00e3o equivalente \u00e0s tabelas/rela\u00e7\u00f5es e aos bancos de dados, dos bancos de dados relacionais. Uma diferen\u00e7a fundamental entre column-families e rela\u00e7\u00f5es \u00e9 que as \u00faltimas precisam de um esquema pr\u00e9-definido, enquanto que as primeiras n\u00e3o tem um esquema. Isto quer dizer que novas colunas podem ser adicionadas dinamicamente e que nem todas precisam estar presentes para cada chave. De fato, m\u00faltiplos registros com a mesma chave, ou linhas, podem ter conjuntos de colunas diferentes. Para que o correto conjunto de colunas associado a uma chave possa ser apurado, ap\u00f3s m\u00faltiplas escritas com a mesma chave tenham ocorrido, a cada tupla (chave,coluna,valor) \u00e9 associado tamb\u00e9m um timestamp . . Assim, dados uma mesma chave e coluna, o valor v\u00e1lido \u00e9 o com o maior timestamp. Devido a possibilidade de valores serem escritos para diferentes colunas independentemente, valores v\u00e1lidos e inv\u00e1lidos podem ter o mesmo timestamp . Por exemplo, considere os seguintes dados escritos no banco: Chave Coluna \\(\\rightarrow\\) Valor Timestamp 3 Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 30 02:02:2020,13:45:00 3 Idade \\(\\rightarrow\\) 33 02:02:2020,13:50:00 3 Telefone \\(\\rightarrow\\) 333444554433 02:02:2020,13:55:00 Uma busca pelos dados associados \u00e0 chave 3 retornar\u00e1 o seguinte resultado: Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 33, Telefone \\(\\rightarrow\\) 333444554433. Para facilitar mais ainda o desenvolvimento, o Cassandra conta com uma linguagem de consulta similar ao SQL (Structured Query Language), a CQL (Cassandra Query Language). Assim, a consulta a estes dados seria mais ou menos como SELECT * FROM dados WHERE key == 3 . 7 H\u00e1 muitos recursos online para se aprender mais se aprender mais sobre como usar o Cassandra, por exemplo, aqui . H\u00e1 tamb\u00e9m diversos projetos de c\u00f3digo livre que o usam e podem ser estudados, por exemplo, o clone de Twiter Twissandra . Mas embora o uso de sistemas gerenciadores de bancos de dados em sistemas distribu\u00eddos seja interessante, aqui nos focaremos em alguns dos aspectos de como estes SGBD s\u00e3o constru\u00eddos. Detalhes de Implementa\u00e7\u00e3o A se\u00e7\u00e3o de tecnologias descreve v\u00e1rias estruturas de dados recorrentemente usadas em implementa\u00e7\u00e3o de bancos de dados como o Cassandra.","title":"Estudo de Caso: Cassandra"},{"location":"arch/#outros-exemplos","text":"P2P \u00e9 terreno f\u00e9rtil e poder\u00edamos passar muito tempo apenas enumerando exemplos interessantes, mas nos limitaremos aqui a dois dos mais atuais. O primeiro \u00e9 o sistema de compartilhamento de arquivos j\u00e1 mencionado na introdu\u00e7\u00e3o , BitTorrent. O que h\u00e1 de mais interessante neste exemplo o fato de haverem diversas implementa\u00e7\u00f5es dos clientes, e.g., \\(\\mu\\) Torrent, Azureus, Transmission, Vuze, qTorrent, implemenados em diversas linguagens e para diversas plataformas, todos interoper\u00e1veis. Isso \u00e9 um atestado do que uma especifica\u00e7\u00e3o bem feita e aberta pode alcan\u00e7ar. O segundo \u00e9 o sistema que suporta a criptomoeda BitCoin, em que milhares de n\u00f3s armazenam coletivamente o hist\u00f3rico de transa\u00e7\u00f5es de trocas de dono das moedas. Mas em vez de expandir aqui este assunto, deferiremos esta discuss\u00e3o para a se\u00e7\u00e3o BlockChain . Apenas para abrir o apetite, Se voc\u00ea n\u00e3o pegou a refer\u00eancia, volte uma casa 2 um cap\u00edtulo. \u21a9 Se voc\u00ea n\u00e3o pegou esta refer\u00eancia, n\u00e3o teve inf\u00e2ncia. \u21a9 \"The hype cycle is a branded graphical presentation developed and used by the American research, advisory and information technology firm Gartner, for representing the maturity, adoption and social application of specific technologies.\" \u21a9 Peak of Inflated - Expectations Early publicity produces a number of success stories\u2014often accompanied by scores of failures. Some companies take action; most don't. Technology Trigger -- A potential technology breakthrough kicks things off. Early proof-of-concept stories and media interest trigger significant publicity. Often no usable products exist and commercial viability is unproven. Slope of Enlightenment -- More instances of how the technology can benefit the enterprise start to crystallize and become more widely understood. Second- and third-generation products appear from technology providers. More enterprises fund pilots; conservative companies remain cautious. Plateau of Productivity -- Mainstream adoption starts to take off. Criteria for assessing provider viability are more clearly defined. The technology's broad market applicability and relevance are clearly paying off. Trough of Disillusionmen - Interest wanes as experiments and implementations fail to deliver. Producers of the technology shake out or fail. Investment continues only if the surviving providers improve their products to the satisfaction of early adopters. \u21a9 \u21a9 Neste problema do ICPC, um esquema de nomea\u00e7\u00e3o dos n\u00f3s de um hypercube \u00e9 apresentado; usando este esquema, derive um algoritmo de roteamento em que a dist\u00e2ncia percorrida por qualquer mensagem seja sempre igual ao n\u00famero de dimens\u00f5es do cubo. \u21a9 Observe que as dist\u00e2ncias entre os n\u00f3s no anel foram desenhadas de forma proporcial \u00e0 diferen\u00e7a num\u00e9rica entre os identificadores. \u21a9 Este exemplo \u00e9 meramente ilustrativo e n\u00e3o segue estritamente a sintaxe do CQL. \u21a9","title":"Outros exemplos"},{"location":"basics/","text":"Fundamentos Uma vez que estejam convencidos de que n\u00e3o temos alternativas \u00e0 distribui\u00e7\u00e3o se queremos sistemas escal\u00e1veis e tolerantes a falhas, o pr\u00f3ximo passo \u00e9 entender como podemos implement\u00e1-los e quais desafios encontraremos. O primeiro desafio \u00e9 entender o ambiente no qual est\u00e3o inseridos, suas limita\u00e7\u00f5es e fragilidades. Isto \u00e9, precisamos definir um modelo computacional , sabendo que alguns problemas tem solu\u00e7\u00f5es triviais ou inexistentes, dependendo do modelo. Modelos computacionais Antes de distribuir nosso sistema, isto \u00e9, dividir a computa\u00e7\u00e3o/armazenamento em diversas m\u00e1quinas, e coordenar suas a\u00e7\u00f5es para que sejam consistentes com a especifica\u00e7\u00e3o, de forma a minimizar o tempo que o servi\u00e7o fica fora do ar, entregando o servi\u00e7o de acordo com expectativas especificadas, precisamos responder a algumas perguntas: Qual a probabilidade de um n\u00f3 parar de funcionar? Como os n\u00f3s se comunicam? Eles compartilham um espa\u00e7o de endere\u00e7amento ou enviam mensagens uns para os outros? A quais atrasos a comunica\u00e7\u00e3o est\u00e1 sujeita? Pode haver atrasos infinitos? A comunica\u00e7\u00e3o pode ser corrompida? Os rel\u00f3gios dos hospedeiros marcam o mesmo valor no mesmo instante, ou melhor, s\u00e3o sincronizados? H\u00e1 agentes que possam querer perturbar o sistema, por exemplo para ganhar acesso a mais recursos do que seria justo? Modelos Comunica\u00e7\u00e3o Sincronismo Falhas Estas perguntas s\u00e3o normalmente divididas em tr\u00eas eixos, Comunica\u00e7\u00e3o , Sincronismo e Falhas , e a combina\u00e7\u00e3o das respostas define o modelo computacional adotado. Comunica\u00e7\u00e3o De uma forma ou de outra, sistemas distribu\u00eddos tem \u00e0 sua disposi\u00e7\u00e3o m\u00faltiplos processadores e permitem o desenvolvimento de aplica\u00e7\u00f5es paralelas, isto \u00e9, onde m\u00faltiplas tarefas s\u00e3o executadas ao mesmo tempo ou paralelamente . Contudo, por um lado, quando falamos em sistemas multiprocessados, normalmente estamos falando de sistemas em que os processadores est\u00e3o pr\u00f3ximos e compartilham um mesmo espa\u00e7o de endere\u00e7amento, sejam computadores com m\u00faltiplos processadores ou sejam clusters de computadores conectados por um barramento de comunica\u00e7\u00e3o de alt\u00edssima largura de banda, como Infiniband que abstraiam m\u00faltiplos segmentos de mem\u00f3ria como um \u00fanico espa\u00e7o de endere\u00e7amento. Seja como for, estes sistemas com mem\u00f3ria compartilhada s\u00e3o normalmente usados para aplica\u00e7\u00f5es de computa\u00e7\u00e3o intensiva e em cujo os componentes s\u00e3o mais fortemente acoplados e melhor estudados em um curso de computa\u00e7\u00e3o paralela. Comunica\u00e7\u00e3o mem\u00f3ria compartilhada troca de mensagens Por outro lado, estamos mais interessados aqui em sistemas de maior escala geogr\u00e1fica, o que se adequa melhor ao modelo de troca de mensagens, isto \u00e9, onde cada n\u00f3 mantem controle total do seu espa\u00e7o de endere\u00e7amento e s\u00f3 exp\u00f5e seu estado via mensagens enviadas para os outros n\u00f3s. Este modelo \u00e9 mais adequado ao desenvolvimento de aplica\u00e7\u00f5es com componentes fracamente acoplados , em que atrasos de comunica\u00e7\u00e3o e ocorr\u00eancia de falhas independentes s\u00e3o intr\u00ednsecas. Mem\u00f3ria Compartilhada Distribu\u00edda (DSM, do ingl\u00eas, Distributed Shared Memory ) \u00e9 uma abordagem h\u00edbrida que tenta integrar a facilidade de se programar usando um \u00fanico espa\u00e7o de endere\u00e7amento mas com o n\u00edvel de distribui\u00e7\u00e3o necess\u00e1ria a aplica\u00e7\u00f5es de larga escala, inclusive geogr\u00e1fica. Considere uma poss\u00edvel implementa\u00e7\u00e3o em software da DSM, apresentada na pr\u00f3xima figura. Nesta abordagem, cada host contribui uma por\u00e7\u00e3o de sua mem\u00f3ria para um pool global. Processos acessam o pool via gerentes de mem\u00f3ria , que traduzem os endere\u00e7os de um espa\u00e7o de endere\u00e7amento virtual para um host e um endere\u00e7o local a tal host, e usam message passing para implementar o acesso. Esta abordagem resulta em uma arquitetura NUMA, isto \u00e9, Non-Uniform Memory Access , j\u00e1 que os acessos a endere\u00e7os locais s\u00e3o mais r\u00e1pidos que aos remotos. Sincronismo Sincronismo opera\u00e7\u00f5es comunica\u00e7\u00e3o rel\u00f3gio sincroniza\u00e7\u00e3o Quanto ao sincronismo, considera-se os processos tem a capacidade de medir a passagem de tempo, isto \u00e9, tem a acesso a rel\u00f3gios, o qu\u00e3o acurazes este s\u00e3o e o qu\u00e3o sincronizados s\u00e3o estes rel\u00f3gios uns com os outros. Al\u00e9m disso, considera-se a exist\u00eancia de limites de tempo para execu\u00e7\u00e3o de opera\u00e7\u00f5es, por exemplo, o tempo um processador leva para executar uma opera\u00e7\u00e3o de soma de dois inteiros, ou o tempo necess\u00e1rio para a entrega de uma mensagem ou acesso a uma regi\u00e3o de mem\u00f3ria. Falhas Quanto \u00e0s falhas, primeiro \u00e9 preciso aceitar o fato de que componentes independentes podem falhar independentemente e que quanto mais hosts , maior \u00e9 a probabilidade de que pelo menos um deles tenha uma CPU, disco, fonte, ou que quer que seja, falhando; e estejam certos, estas falhas acontecem o tempo todo. 1 Isto \u00e9 importante pois se em sistemas monol\u00edticos uma falha pode facilmente fazer com que o sistema todo pare e, portanto, n\u00e3o tente progredir na aus\u00eancia de um componente, em um sistema distribu\u00eddo queremos exatamente o contr\u00e1rio, isto \u00e9, que apesar da falha de um componente, os outros continuem prestando o servi\u00e7o, mesmo de forma deteriorada e sem comprometer a corretude do sistema. Falhas detect\u00e1vel temporiza\u00e7\u00e3o quebras maliciosas perda e corrup\u00e7\u00e3o de mensagens Para lidar com falhas, precisamos entender quais s\u00e3o suas poss\u00edveis formas, isto \u00e9, se o levam componentes falhos a parar de funcionar totalmente e de forma identific\u00e1vel por outros ou n\u00e3o, se h\u00e1 falhas \"maliciosas\", se os limites de tempo estabelecidos acima podem ser violados, se mensagens podem ser perdidas ou corrompidas. Modelo Assumido Outros carga de trabalho Embora modelos cl\u00e1ssicos sejam normalmente definidos em termos dos fatores acima, outras quest\u00f5es s\u00e3o tamb\u00e9m importantes, como o padr\u00e3o da carga de trabalho do sistema (maior carga \u00e0 noite? Na hora do almo\u00e7o? Black friday ?). Al\u00e9m de ignorarmos estes outros fatores, por enquanto assumiremos um modelo computacional n\u00e3o amig\u00e1vel, com comunica\u00e7\u00e3o por troca de mensagens, rel\u00f3gios e limites de tempo para opera\u00e7\u00f5es, mesmo que desconhecidos. Tamb\u00e9m assumiremos aus\u00eancia de falhas, a n\u00e3o ser quando quisermos provocar a an\u00e1lise de situa\u00e7\u00f5es mais interessantes. Este modelo ser\u00e1 ajustado na medida em que avan\u00e7armos, para tornar nossas an\u00e1lises mais realistas. SD s\u00e3o como cebolas! Uma vez definido o modelo computacional e identificado os algoritmos adequados aos problemas que queremos resolver, passamos \u00e0 implementa\u00e7\u00e3o. Distribuir \u00e9 dividir a computa\u00e7\u00e3o/armazenamento em diversos componentes, possivelmente geograficamente distantes , e coordenar suas a\u00e7\u00f5es para que resolvam a tarefa em quest\u00e3o de forma correta. Com a distribui\u00e7\u00e3o objetiva-se usar recursos dispon\u00edveis nos hosts onde os componentes s\u00e3o executados 2 e usar de redund\u00e2ncia para garantir que o servi\u00e7o sofra degrada\u00e7\u00e3o graciosa em caso de falhas, ou seja, fazer com que o servi\u00e7o continue funcionando, mesmo que com vaz\u00e3o reduzida , lat\u00eancia aumentada , menor capacidade de tratamento de requisi\u00e7\u00f5es concorrentes, ou com funcionalidades desabilitadas . Abstra\u00e7\u00f5es Comunica\u00e7\u00e3o Ordena\u00e7\u00e3o Confiabilidade Invoca\u00e7\u00e3o de procedimentos remotos Heterogeneidade Linguagens Arquiteturas Sistemas Operacionais Times Para colaborar, as diversas partes do sistema distribu\u00eddo devem se comunicar, o que pode pode ser feito de diversas formas e em diversos n\u00edveis de abstra\u00e7\u00e3o. Por exemplo, no caso troca de mensagens, estas podem ser desde pacotes de bytes entregues pelo IP/UDP como por troca de mensagens ordenadas, fluxos de dados , ou invoca\u00e7\u00e3o remota de procedimentos . Implementar estas abstra\u00e7\u00f5es em si j\u00e1 \u00e9 uma tarefa complicada, pois \u00e9 preciso levar em considera\u00e7\u00e3o que os componentes de um sistema distribu\u00eddo falham independentemente , executam em hosts com rel\u00f3gios dessincronizados , s\u00e3o desenvolvidos usando-se linguagens diversas , sistemas operacionais distintos , com arquiteturas diferentes e por times independentes . Apesar de tantas vari\u00e1veis, as abstra\u00e7\u00f5es precisam permitir que as aplica\u00e7\u00f5es que as usem possam se coordenar nos m\u00ednimos detalhes. Dado que a complexidade de se implementar estas abstra\u00e7\u00f5es j\u00e1 \u00e9 grande por si s\u00f3, se formos reinventar a roda a cada novo sistema, n\u00e3o faremos muitos avan\u00e7os. Mas, como voc\u00eas bem sabem, camadas de abstra\u00e7\u00e3o s\u00e3o a chave para se lidar com complexidade. Assim, sistemas distribu\u00eddos s\u00e3o como cebolas, cheias de camadas e que nos fazem chorar quando precisamos descasc\u00e1-las. 3 Felizmente, para cada problema que tenha que resolver, h\u00e1 uma boa probabilidade de que algu\u00e9m j\u00e1 o tenha atacado e disponibilizado uma solu\u00e7\u00e3o, de forma comercial ou n\u00e3o. Comunica\u00e7\u00e3o As camadas de abstra\u00e7\u00e3o mais b\u00e1sicas est\u00e3o na rede de computadores que serve de substrato a todo e qualquer sistema distribu\u00eddo, afinal, a pedra fundamental da constru\u00e7\u00e3o de sistemas distribu\u00eddos \u00e9 a capacidade de comunica\u00e7\u00e3o entre seus componentes. Tamb\u00e9m importantes, de um ponto de vista pr\u00e1tico do desenvolvimento, s\u00e3o os conceitos de concorr\u00eancia e paralelismo, pois componentes pode necessitar manter v\u00e1rias \"conversas\" em paralelo com m\u00faltiplos outros componentes. Canais e Protocolos Para que os componentes de um sistema distribu\u00eddo se comuniquem, \u00e9 necess\u00e1rio que seus hosts possuam interfaces de rede e que estas interfaces estejam ligadas a uma rede com capacidade de roteamento de dados, estabelecendo um canal de comunica\u00e7\u00e3o entre os componentes. Al\u00e9m do canal, \u00e9 tamb\u00e9m necess\u00e1rio que se estabele\u00e7a um protocolo de comunica\u00e7\u00e3o , que define as regras para que a comunica\u00e7\u00e3o aconte\u00e7a, por exemplo, a gram\u00e1tica para forma\u00e7\u00e3o de mensagens. Por exemplo, quando voc\u00ea fala com uma pessoa, cara-a-cara, o meio de comunica\u00e7\u00e3o \u00e9 o ar e o protocolo utilizado \u00e9 a linguagem conhecida pelas duas partes, o Portugu\u00eas por exemplo. Na pr\u00e1tica, canais de comunica\u00e7\u00e3o podem ter diversas topologias e caracter\u00edsticas, por exemplo: Ponto-a-ponto Barramento Compartilhado Token Ring Sem colis\u00f5es Com colis\u00f5es Sem colis\u00f5es Roteamento trivial Roteamento complexo Roteamento simples Caro (exponencial) Barato (linear) Barato (linear) Nas redes atuais, pode se dizer que o meio mais utilizado \u00e9 provido pela arquitetura Ethernet , que trata da comunica\u00e7\u00e3o entre n\u00f3s usando um barramento compartilhado , mesmo que este esteja por vezes escondido. Sobre este meio, s\u00e3o usados protocolos para, por exemplo, Controle de acesso ao meio Transmiss\u00e3o de mensagens Evitar e tratar colis\u00f5es As redes Ethernet, contudo, cobrem pequenas \u00e1reas e para se ter conversas mais \"abrangentes\", \u00e9 necess\u00e1rio que se conecte diversas destas redes. A conversa ent\u00e3o \u00e9 feita por meio de intermedi\u00e1rios, gateways que conectam duas ou mais redes, permitindo que mensagens de um interlocutor sejam roteadas para o outro, via tais intermedi\u00e1rios. Um exemplo interessante das quest\u00f5es ligadas \u00e0 manuten\u00e7\u00e3o da conversa entre dois pontos \u00e9 a decis\u00e3o sobre o uso de comuta\u00e7\u00e3o de pacotes ( packet switching ) ou de circuitos ( circuit switching ). Comuta\u00e7\u00e3o de pacotes Comuta\u00e7\u00e3o de circuito Cada pacote viaja independentemente Todo pacote viaja por caminho predefinido Lat\u00eancia vari\u00e1vel Lat\u00eancia mais constante Banda n\u00e3o reservada Banda reservada Banda n\u00e3o desperdi\u00e7ada Banda desperdi\u00e7ada Outro fator importante \u00e9 a unidade m\u00e1xima de transmiss\u00e3o ( maximum transmission unit , MTU), o tamanho m\u00e1ximo de um pacote em determinada rede. \u00c9 necess\u00e1rio entender que qualquer quantidade de dados maior que o MTU precisar\u00e1 ser dividida em m\u00faltiplos pacotes. Tamb\u00e9m \u00e9 importante perceber que redes s\u00e3o heterog\u00eaneas, e que o v\u00e1rios segmentos no caminho entre origem e destino podem ter MTU diferentes, levando \u00e0 fragmenta\u00e7\u00e3o de pacotes em tr\u00e2nsito e, possivelmente, entrega desordenada dos mesmos. Finalmente, h\u00e1 uma quest\u00e3o importante relativa \u00e0 confiabilidade na transmiss\u00e3o dos elementos da conversa, isto \u00e9, se a rede deve garantir ou n\u00e3o que algo \"dito\" por um interlocutor deve garantidamente ser \"ouvido\" pelo outro, ou se a mensagem pode ser perdida no meio. Felizmente boa parte da complexidade da resolu\u00e7\u00e3o destas quest\u00f5es \u00e9 abstra\u00edda do desenvolvedor dos sistemas distribu\u00eddos , isto \u00e9, voc\u00ea, lhe cabendo apenas a decis\u00e3o de qual protocolo utilizar. Nas redes atuais, a conversa em componentes ser\u00e1 feita, em algum n\u00edvel, por meio dos protocolos da arquitetura Internet . A Internet A Internet tem este nome por usar o protocolo de interconex\u00e3o de redes independentes, o internetworking protocol , ou IP. Para a aplica\u00e7\u00e3o usando o IP, todas as redes se comportam como uma \u00fanica e coerente rede, exceto por alguns detalhes. Os elementos que conectam as diversas redes s\u00e3o denominados roteadores e fazem um melhor esfor\u00e7o para encaminhar os pacotes de dados do remetente ao destinat\u00e1rio. 4 Se voc\u00ea se lembrar da pilha de protocolos de comunica\u00e7\u00e3o de refer\u00eancia OSI, lembrar\u00e1 que h\u00e1 uma organiza\u00e7\u00e3o em camadas em que cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel e serve de funda\u00e7\u00e3o para a funcionalidade da camada de cima, isto \u00e9, cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel de abstra\u00e7\u00e3o que serve de base para o n\u00edvel imediatamente superior: O protocolo de cada camada inclui cabe\u00e7alhos ( header ) e carga ( payload ) e o conjunto de cabe\u00e7alho + carga de uma camada \u00e9 considerado carga da camada inferior. Assim, embora tenha-se a impress\u00e3o de que cada camada conversa com a equivalente do outro lado da comunica\u00e7\u00e3o, na pr\u00e1tica, a comunica\u00e7\u00e3o desce e sobe a pilha. S\u00e3o sete as camadas: F\u00edsica: Bits Enlace: Frames/quadros; controle de fluxo; acesso ao meio. Rede: Datagramas/pacotes; roteamento Transporte: Controle de fluxo; fim a fim; confiabilidade; tcp e udp Sess\u00e3o: Streams/fluxos; conex\u00f5es l\u00f3gicas; restart; checkpoint; http, ssl Apresenta\u00e7\u00e3o: Objetos; json, xml; criptografia Aplica\u00e7\u00e3o: Aplica\u00e7\u00f5es; http, pop, ftp Embora o IP se refira estritamente ao protocolo da camada 3 da pilha, nos referimos \u00e0 pilha que usa este protocolo como a pilha IP. Comparada \u00e0 pilha OSI, a IP \u00e9 mais simples, como se v\u00ea na figura, pois as camadas 5 e 6 n\u00e3o est\u00e3o presentes na pilha IP e as funcionalidades correspondentes s\u00e3o implementadas na camada 7, de aplica\u00e7ao. Contudo, n\u00e3o tema! Estas funcionalidades podem se normalmente implementadas por meio de frameworks ou do middleware em uso. Alguns exemplos de tais funcionalidades s\u00e3o (De)Serializa\u00e7\u00e3o - convers\u00e3o de estruturas complexas, e.g., objetos e estruturas, em sequ\u00eancia de bytes. Nomeamento - identifica\u00e7\u00e3o de hosts Criptografia - oculta\u00e7\u00e3o dos dados trafegados Replica\u00e7\u00e3o - comunica\u00e7\u00e3o com m\u00faltiplos interlocutores Invoca\u00e7\u00e3o remota de procedimentos - abstra\u00e7\u00e3o de protocolos de comunica\u00e7\u00e3o A grande vantagem desta abordagem \u00e9 que se pode implementar exatamente e somente as funcionalidades desejadas. Este caracter\u00edstica \u00e9 conhecida como o argumento fim-a-fim no projeto de sistemas ; uma an\u00e1lise recente deste argumento foi feita aqui . Como usu\u00e1rios da pilha IP, temos que entender como a camada 3 funciona, mas dificilmente interagiremos com algo al\u00e9m da camada 4, a camada de transporte . Sockets Na pr\u00e1tica, para implementarmos a comunica\u00e7\u00e3o entre processos, usamos sockets . Para se definir um socket a partir de um host \u00e9 necess\u00e1rio identificar o outro fim da comunica\u00e7\u00e3o, isto \u00e9, o outro host , ou melhor, uma de suas interfaces de rede. Os sockets s\u00e3o ent\u00e3o a abstra\u00e7\u00e3o dos canais de comunica\u00e7\u00e3o, mas como dito antes, \u00e9 necess\u00e1rio definir tamb\u00e9m os protocolos usados por estes sockets. O primeiro protocolo \u00e9 o de endere\u00e7amento, que define qual pilha de protocolos usar, na camada 3. No caso da pilha IP, usa-se o protocolo AF_INET ou PF_INET. Escolhido o protocolo, cada interface tem um endere\u00e7o MAC, na camada 2, que a identifica entre as interfaces na mesma rede local, e cada interface tem um endere\u00e7o IPv4/IPv6 de 32/128 bits, que o indentifica entre todos os hosts na Internet. 5 Mas dentro de um host , podem haver diversas aplica\u00e7\u00f5es sendo executadas. Como identificar exatamente com qual se quer conversar? Isto \u00e9 feito pela defini\u00e7\u00e3o uma porta: Porta: inteiro de 16 bits Associadas a servi\u00e7os pela Internet Assigned Numbers Authority , IANA. Portas \"Bem conhecidas\": 0-1023 Portas Propriet\u00e1rias: 49151 Portas Din\u00e2micas: 65535 Tamb\u00e9m \u00e9 necess\u00e1rio definir o protocolo de transporte dos dados, na camada 4. Novamente, no caso da pilha IP, pode-se usar TCP ( SOCK_STREAM ) ou UDP ( SOCK_DGRAM ). A API usada para estabelecer a conversa via socket tem v\u00e1rias chamadas, que devem ser executadas na ordem certa no processo iniciando a conversa e naquele que aceita participar da mesma. Comecemos estudando o TCP. TCP O fluxograma da cria\u00e7\u00e3o de um socket TCP \u00e9 apresentado na seguinte figura: stateDiagram-v2 Servidor --> Entrada/Sa\u00edda Cliente --> Entrada/Sa\u00edda Entrada/Sa\u00edda --> Encerramento state Servidor { ss: Cria socket sb: Associa porta sl: Escuta conex\u00f5es sa: Aceita conex\u00f5es ss --> sb sb --> sl sl --> sa } state Entrada/Sa\u00edda { leitura --> escrita escrita --> leitura } state Cliente { cs: Cria socket cc: Inicia conex\u00e3o cs --> cc } state Encerramento { sc: Fecha conex\u00e3o } Estabelecido o socket, o mesmo pode ser usado como um arquivo , isto \u00e9, lendo-se e escrevendo-se bytes. O que exatamente deve ser escrito e como o que \u00e9 lido deve ser interpretado \u00e9 o protocolo da camada 7, sua responsabilidade . Vejamos um exemplo do uso de sockets, em Python, descrito no arquivo server.py . 6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #server.py #!/usr/bin/python # This is server.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . bind (( host , port )) # Bind to the port s . listen ( 5 ) # Now wait for client connections. while True : c , addr = s . accept () # Establish connection with client. print ( 'Got connection from' , addr ) c . send ( 'Thank you for connecting' . encode ()) c . close () # Close the connection Para execut\u00e1-lo, execute o seguinte comando em um terminal. 1 python server.py Em outro terminal, execute um dos dois comandos a seguir. 7 1 telnet localhost 12345 1 netcat localhost 12345 No segundo terminal a mensagem Thank you for connecting ser\u00e1 impressa, enquanto no primeiro veremos algo como ('Got connection from', ('127.0.0.1', 57801)) O que est\u00e1 acontecendo aqui \u00e9 um processo criou um socket e ficou aguardando uma conex\u00e3o, usando o c\u00f3digo em Python. Tanto o telnet quando o netcat s\u00e3o programas gen\u00e9ricos para se conversar com outro processo usando TCP/IP. Aqui, estes programas simplesmente se conectaram e imprimiram o que quer que o primeiro processo lhes tenha enviado, assumindo que correspondia a uma string, o que neste caso \u00e9 correto. Simples, n\u00e3o \u00e9 mesmo? Duas observa\u00e7\u00f5es importantes a serem feitas aqui. A primeira \u00e9 que, em geral, denominamos o processo que fica aguardando a conex\u00e3o de servidor e o processo que se conecta de cliente . Isto por qu\u00ea, em geral, o servidor executa alguma tarefa, serve, o cliente, embora isto n\u00e3o seja necessariamente verdade. Por completude, vamos tamb\u00e9m escrever o c\u00f3digo do cliente, agora que voc\u00ea j\u00e1 sabe que o servidor funciona. Do lado cliente, estabelece-se uma conex\u00e3o apontando-se para onde est\u00e1 o servidor. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #client.py #!/usr/bin/python # This is client.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . connect (( host , port )) data = s . recv ( 1024 ) print ( data . decode ()) s . close () # Close the socket when done E para se executar o cliente, fa\u00e7a: 1 python client.py Observe que o socket.close() encerra a conex\u00e3o do lado de quem invoca. Na contraparte, invoca\u00e7\u00f5es a socket.recv() retornam com 0 bytes lidos. A t\u00edtulo de compara\u00e7\u00e3o, em Java, a cria\u00e7\u00e3o do socket do lado do servidor seria muito mais simples, consistindo apenas em: 1 Socket s = new ServerSocket ( port ); O cliente em Java tamb\u00e9m \u00e9 simplificado. 1 Socket s = new Socket ( hostname , port ); Exerc\u00edcio: M\u00faltiplos Pacotes Fa\u00e7amos agora uma modifica\u00e7\u00e3o no c\u00f3digo do servidor para que envie n\u00e3o uma, mas duas mensagens para o cliente. Isto \u00e9, modifique seu servidor assim 1 2 3 4 ... c . send ( 'Thank you for connecting' . encode ()) c . send ( 'Come back often' . encode ()) ... Agora execute novamente o cliente e veja o que acontece. Consegue explicar o fen\u00f4meno? Modifiquemos o cliente agora, para que tenha dois recv , assim. 1 2 3 4 5 6 7 8 ... print ( \"1\" ) data = s . recv ( 1024 ) print ( data . decode ()) print ( \"2\" ) data = s . recv ( 1024 ) print ( data . decode ()) ... E agora, o que acontece? A sa\u00edda \u00e9 como esperava? Como explica este fen\u00f4meno e como poderia corrig\u00ed-lo? Exerc\u00edcio: Ping-Pong Modifique cliente e servidor tal que o cliente envie uma mensagem passada na linha de comando ao servidor e fique esperando uma resposta, e tal que o servidor fique esperando uma mensagem e ent\u00e3o solicite ao operador que digite uma resposta e a envie para o cliente. O loop continua at\u00e9 que o usu\u00e1rio digite SAIR, e a conex\u00e3o seja encerrada. Terminal 1 Terminal 2 python server.py python client.py Esperando conex\u00e3o. conectando-se ao servidor Conectado Conectado Esperando mensagem Digite mensagem: lalala Mensagem enviada Mensagem recebida: lalala Esperando resposta Digite resposta: lelele Resposta enviada. Resposta recebida: lelele Digite mensagem: SAIR Desconectando. Conex\u00e3o encerrada. Esperando conex\u00e3o. Observe que para ler do teclado em Python 2 voc\u00ea deve usar x = raw_input () , enquanto que em Python 3 seria x = input () . Al\u00e9m disso, em Python 2, voc\u00ea deve remover as invoca\u00e7\u00f5es para encode e decode . UDP No exemplo anterior, usamos o protocolo TCP (o padr\u00e3o da API). Caso quis\u00e9ssemos usar UDP, precisar\u00edamos nos atentar a alguns detalhes. A cria\u00e7\u00e3o do socket \u00e9 feita explicitando-se o uso de datagramas : s = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) Um servidor UDP n\u00e3o executa listen ou accept e, em Python, simplesmente executa data , addr = sock . recvfrom ( 4096 ) para receber o datagrama, onde data \u00e9 o conte\u00fado recebido e addr o endere\u00e7o de quem enviou o datagrama. Neste caso, um mesmo socket \u00e9 usado para manter comunica\u00e7\u00e3o com m\u00faltiplos interlocutores. Para enviar uma resposta a um interlocutor em espec\u00edfico, addr \u00e9 usado: sent = sock . sendto ( data , addr ) , onde sent \u00e9 a quantidade de bytes enviados. Al\u00e9m deste detalhe, \u00e9 importante manter em mente outras caracter\u00edsticas do UDP: falta de ordem falta de confiabilidade menos dados lidos que enviados. mais dados lidos que enviados (pode acontecer tamb\u00e9m no TCP) Com tantas dificuldades para se usar o UDP, fica a quest\u00e3o: para que serve UDP? Exerc\u00edcio: Ping-Pong UDP Modifique o c\u00f3digo do exerc\u00edcio Ping-Pong para usar UDP em vez de TCP na comunica\u00e7\u00e3o entre n\u00f3s. Execute m\u00faltiplos clientes ao mesmo tempo. Como o seu servidor lida com isso? Modifique-o para mandar um \"eco\" da mensagem recebida de volta ao remetente. IP-Multicast Imagine que voc\u00ea tenha que enviar um stream de v\u00eddeo para um amigo mostrando como voc\u00ea est\u00e1 jogando o mais novo jogo da velha no mercado. Qual protocolo de transporte voc\u00ea usaria? TCP, provavelmente, j\u00e1 que garante a entrega ordenada dos pacotes do v\u00eddeo. Como voc\u00ea j\u00e1 sabe, o TCP envia confirma\u00e7\u00f5es de pacotes recebidos e usa uma janela deslizante para determinar quais pacotes reenviar, o que pode causar interrup\u00e7\u00f5es na execu\u00e7\u00e3o do v\u00eddeo. Al\u00e9m do mais, as pessoas provavelmente preferir\u00e3o perder alguns quadros que perder a sincronia com sua excitante partida. Parece que uma op\u00e7\u00e3o melhor seria ent\u00e3o usar UDP, correto? Imagine agora que os mesmos dados devam ser enviados para m\u00faltiplos destinat\u00e1rios (voc\u00ea est\u00e1 ficando famoso!) Com m\u00faltiplos destinat\u00e1rios, m\u00faltiplos controles precisariam ser mantidos no TCP, o que pode se tornar custoso; mais uma raz\u00e3o para usar UDP! Para terminar, lhe darei uma raz\u00e3o final: IP-Multicast! Multicast, em oposi\u00e7\u00e3o ao Unicast, \u00e9 a capacidade de enviar mensagens para um grupo de destinat\u00e1rios, em vez de apenas um. IP-Multicast \u00e9 uma implementa\u00e7\u00e3o desta ideia, usando umaa configura\u00e7\u00e3o espec\u00edfica do UDP, associada a recursos dos comutadores de rede, para otimizar o envio dos mesmos dados a m\u00faltiplos destinat\u00e1rios. Grupos s\u00e3o identificados por endere\u00e7os IP especiais, conhecidos como Classe D (224.0.0.0-239.255.255.255), e propagados pela rede. A seguinte tabela descreve os usos das sub-faixas de endere\u00e7os. 8 Endere\u00e7o Uso 224.0.0.0-224.0.0.255 Multicast local - Usado por protocolos L2, como EIGRP e OSPF 224.0.1.0-224.0.1.255 Multicast roteaddo - Usado por protocolos L3 232.0.0.0-232.255.255.255 Source Specific Multicast - Receptores definem fontes confi\u00e1veis 233.0.0.0-233.255.255.255 Reservado para detentores Autonomous Systems 239.0.0.0-239.255.255.255 Reservado para IANA Resto Uso geral Quando um pacote \u00e9 enviado para o endere\u00e7o do grupo, todos os membros do grupo recebem tal mensagem. Melhor dizendo, todos os membros podem receber a mensagem, mas como estamos falando de UDP, \u00e9 poss\u00edvel que alguns n\u00e3o recebam . Al\u00e9m disso, n\u00e3o h\u00e1 garantia qualquer sobre a ordem de recep\u00e7\u00e3o das mensagens . Apenas refor\u00e7ando, IP-Multicast s\u00f3 funciona com UDP, pois lidar com retransmiss\u00f5es em um grupo grande levaria a um estado imenso sendo mantido na origem dos dados. Outro ponto importante \u00e9 que pelo podencial desestabilizador do IP-Multicast, ele \u00e9 normalemente limitado \u00e0 pequenas se\u00e7\u00f5es das redes. Mas experimentemos com esta tecnologia na pr\u00e1tica. Criemos um programa que criar Socket UDP , associa-o a um grupo , e recebe pacotes destinados ao grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // MReceiver.java import java.io.* ; import java.net.* ; public class MReceiver { public static void main ( String [] args ) { byte [] inBuf = new byte [ 256 ] ; try { MulticastSocket socket = new MulticastSocket ( 8888 ); InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); socket . joinGroup ( address ); while ( true ) { DatagramPacket inPacket = new DatagramPacket ( inBuf , inBuf . length ); socket . receive ( inPacket ); String msg = new String ( inBuf , 0 , inPacket . getLength ()); System . out . println ( \"From \" + inPacket . getAddress () + \" Msg : \" + msg ); } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Instancie m\u00faltiplos processos deste, na mesma m\u00e1quina e em m\u00e1quinas distintas. Agora criemos um programa que envia pacotes para o dito grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // MSender.java import java.io.* ; import java.net.* ; public class MSender { public static void main ( String [] args ) { byte [] outBuf ; final int PORT = 8888 ; try { DatagramSocket socket = new DatagramSocket (); long counter = 0 ; InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); while ( true ) { counter ++ ; outBuf = ( \"Multicast numero \" + counter + \" \" + address ). getBytes (); DatagramPacket outPacket = new DatagramPacket ( outBuf , outBuf . length , address , PORT ); socket . send ( outPacket ); try { Thread . sleep ( 500 ); } catch ( InterruptedException ie ) {} } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Observe como a mesma mensagem \u00e9 recebida pelos v\u00e1rios membros e que como diferentes fontes tem seus pacotes recebidos. A t\u00edtulo de curiosidade, IP-Multicast tamb\u00e9m est\u00e1 presente em IPv6, mas com algumas pequenas diferen\u00e7as IP-Multicast em IPv6 9 In IPv6, the left-most bits of an address are used to determine its type. For a multicast address, the first 8 bits are all ones, i.e. FF00::/8. Further, bit 113-116 represent the scope of the address, which can be either one of the following 4: Global, Site-local, Link-local, Node-local. In addition to unicast and multicast, IPv6 also supports anycast, in which a packet can be sent to any member of the group, but need not be sent to all members.'' Exerc\u00edcio: IP-Multicast Implemente e teste o seguinte receiver , colocando v\u00e1rias inst\u00e2ncias para executar em m\u00faltiplos terminais, ao mesmo tempo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import socket import struct MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) sock . bind (( '' , MCAST_PORT )) mreq = struct . pack ( \"=4sl\" , socket . inet_aton ( MCAST_GRP ), socket . INADDR_ANY ) #4 bytes (4s) seguidos de um long (l), usando ordem nativa (=) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_ADD_MEMBERSHIP , mreq ) while True : print ( sock . recv ( 10240 ) . decode ()) Implemente e teste o seguinte sender . 1 2 3 4 5 6 7 8 import socket MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_MULTICAST_TTL , 2 ) sock . sendto ( input () . encode (), ( MCAST_GRP , MCAST_PORT )) Concorr\u00eancia \u00c9 imposs\u00edvel pensar em sistemas distribu\u00eddos sem pensar em concorr\u00eancia na forma de m\u00faltiplos processos executando (normalmente) em hosts distintos e em termos de m\u00faltiplos threads nos processos. Os exemplos apresentados at\u00e9 agora, consistem todos em um processo cliente requisitando a\u00e7\u00f5es de algum processo servidor. Apesar disso, a intera\u00e7\u00e3o entre tais processos aconteceu sempre de forma sincronizada, lock-step , em que o cliente requisitava o servi\u00e7o e ficava bloqueado esperando a resposta do servidor para ent\u00e3o prosseguir em seu processamento, e o servidor fica bloqueado esperando requisi\u00e7\u00f5es que atende e ent\u00e3o volta a dormir. Este cen\u00e1rio, apresentado na figura a seguir, mostra que apesar do uso de processadores distintos e da concorr\u00eancia na execu\u00e7\u00e3o dos processos, temos um baixo grau de efetivo paralelismo; a requisi\u00e7\u00e3o (2) s\u00f3 \u00e9 processada depois que a resposta (1) \u00e9 enviada. sequenceDiagram activate Cliente note left of Cliente: Ativo gerando requisi\u00e7\u00e3o note right of Servidor: Inativo esperando requisi\u00e7\u00e3o activate Cliente2 note right of Cliente2: Ativo gerando requisi\u00e7\u00e3o Cliente->>+Servidor: Request (1) deactivate Cliente note left of Cliente: Inativo esperando resposta Cliente2-->>Servidor: Request (2) deactivate Cliente2 note right of Cliente2: Inativo esperando resposta note right of Servidor: Ativo processando requisi\u00e7\u00e3o (1) Servidor->>-Cliente: Response (1) activate Cliente activate Servidor note left of Cliente: Ativo processando resposta (1) note right of Servidor: Ativo processando requisi\u00e7\u00e3o (2) Servidor-->>Cliente2: Response (2) deactivate Servidor activate Cliente2 note right of Servidor: Inativo esperando requisi\u00e7\u00e3o note right of Cliente2: Ativo processando resposta (2) deactivate Cliente deactivate Cliente2 Este modelo de sincroniza\u00e7\u00e3o entre as partes comunicantes \u00e9 um exemplo de E/S bloqueante . O principal ponto positivo desta estrat\u00e9gia \u00e9 a simplicidade do c\u00f3digo e o principal ponto negativo \u00e9 a limita\u00e7\u00e3o do paralelismo no uso de recursos, uma das raz\u00f5es de ser da computa\u00e7\u00e3o distribu\u00edda. Para usarmos melhor os recursos dispon\u00edveis, tanto do lado dos clientes quanto servidores, temos ent\u00e3o que pensar em termos de eventos sendo disparados entre os componentes, que devem ser tratados assim que recebidos ou t\u00e3o logo haja recursos para faz\u00ea-lo. Estes eventos correspondem tanto a requisi\u00e7\u00f5es quanto a respostas (efetivamente tornando dif\u00edcil a distin\u00e7\u00e3o). No modelo bloqueante, quando um evento \u00e9 disparado (no exemplo, a requisi\u00e7\u00e3o), o sistema fica bloqueado at\u00e9 que um evento espec\u00edfico seja observado (no exemplo, a chegada da resposta). Sempre que poss\u00edvel, um componente n\u00e3o deve ficar esperando por eventos em espec\u00edfico, aproveitando a chance executar outras tarefas; quando eventos s\u00e3o recebidos, s\u00e3o ent\u00e3o atendidos. Esta \u00e9 a forma de fazer E/S ass\u00edncrona . Dada que processos interagem com a rede usando sockets, cuja interface mais simples para opera\u00e7\u00f5es de leitura \u00e9 bloqueante, neste curso n\u00e3o falaremos especificamene sobre E/S ass\u00edncrono 10 e por isso, para vermos como aumentar a concorr\u00eancia no sistema, \u00e9 necess\u00e1rio falar de multithreading e as v\u00e1rias formas em que aparecem nos sistemas. H\u00e1 duas raz\u00f5es claras para estudarmos multithreading . A primeira, de ordem pr\u00e1tica, \u00e9 a discutida acima: permitir o desenvolvimento de componentes que utilizem \"melhormente\" os recursos em um host. A segunda, did\u00e1tica, \u00e9 o fato que muitos dos problemas que aparecem em programa\u00e7\u00e3o multithread , aparecem em programa\u00e7\u00e3o multi-processo (como nos sistemas distribu\u00eddos), apenas em um grau de complexidade maior. Para relembrar, h\u00e1 v\u00e1rias diferen\u00e7as entre threads e processos, mas a abstra\u00e7\u00e3o \u00e9 essencialmente a mesma: Processo Thread Defini\u00e7\u00e3o Inst\u00e2ncia de um programa \"Processo leve\" Fun\u00e7\u00e3o de entrada main fun\u00e7\u00e3o \"qualquer\" Compartilhamento de c\u00f3digo e dados Privado ao processo Compartilhado pelos threads Estado C\u00f3digo, Stack, Heap, descritores (e.g, file descriptors), controle de acesso Stack, vari\u00e1veis locais Comunica\u00e7\u00e3o IPC ( Inter Process Communication ): sockets, FIFO, mem\u00f3ria compartilhada, etc IPC, mutex, vari\u00e1veis de condi\u00e7\u00e3o, sem\u00e1foros, etc N\u00edvel da implementa\u00e7\u00e3o Sistema operacional Diferentes implementa\u00e7\u00f5es API Posix, C++, Java, ... Bloqueio Mudan\u00e7a de contexto para outro thread mesmo sem terminar quantum Mudan\u00e7a de contexto para outro thread do mesmo processo Tempo de cria\u00e7\u00e3o, termina\u00e7\u00e3o e mudan\u00e7a de contexto Demora mais Demora menos Vejamos como o uso de m\u00faltiplos threads podem melhorar o desenvolvimento de sistemas distribu\u00eddos na pr\u00e1tica. Considere os exemplos de clientes e servidores vistos anteriormente . Imagine que em vez do servi\u00e7o simples feito no exemplo, o servidor retorne uma p\u00e1gina Web. Detalhes do protocolo seguido por navegadores e servidores ser\u00e3o vistos mais tarde. Por agora, considere apenas que uma requisi\u00e7\u00e3o GET arquivo.html ser\u00e1 enviada para o servidor que ler\u00e1 o arquivo especificado do sistema de arquivos; como voc\u00ea sabe, ler um arquivo \u00e9 uma opera\u00e7\u00e3o lenta e que n\u00e3o requer CPU. Cliente Do ponto de vista do cliente, a vantagem do uso de m\u00faltiplos threads s\u00e3o claras: permite lidar com v\u00e1rias tarefas concorrentemente , por exemplo solicitar CSS, HTML e imagens concorrentemente, escondendo lat\u00eancia das v\u00e1rias opera\u00e7\u00f5es, e permite organizar c\u00f3digo em blocos/m\u00f3dulos. Se voc\u00ea usar o console de desenvolvimento do navegador, ver\u00e1 como m\u00faltiplos arquivos s\u00e3o baixados em paralelo quando acessa um s\u00edtio. A figura a seguir mostra a carga do s\u00edtio da Facom . O primeiro arquivo, index.html \u00e9 baixado individualmente, mas uma vez que isso acontece e s\u00e3o determinados quais os demais arquivos necess\u00e1rios, requisi\u00e7\u00f5es concorrentes s\u00e3o disparadas, minimizando o tempo total da opera\u00e7\u00e3o. Como outros exemplos, considere um formul\u00e1rio online em que a valida\u00e7\u00e3o de um campo \u00e9 executada enquanto o campo seguinte est\u00e1 sendo preenchido, ou um servi\u00e7o de email em que arquivos s\u00e3o carregados enquanto a mensagem \u00e9 confeccionada. Servidor Do lado dos servidores h\u00e1 diversas possibilidades de uso de threads para aumentar o paralelismo no processamento de requisi\u00e7\u00f5es, melhor utilizando recursos dispon\u00edveis e melhorando a experi\u00eancia do usu\u00e1rio. Single-threaded A estrat\u00e9gia mais simples de se implementar \u00e9 a de usar apenas um thread, como temos feito at\u00e9 agora. Considere um servidor Web com esta esta caracter\u00edstica; o fluxo no tratamento de uma requisi\u00e7\u00e3o \u00e9 exemplificado na pela figura a seguir: O servidor \u00e9 iniciado, criando o socket e invocando accept o cliente envia a requisi\u00e7\u00e3o para o servidor o servidor aceita a conex\u00e3o em seu \u00fanico thread uma tarefa \u00e9 gerada para ler o arquivo o arquivo \u00e9 lido, de forma bloqueante, e uma resposta para o cliente \u00e9 preparada a resposta \u00e9 enviada para o cliente, de forma bloqueante a requisi\u00e7\u00e3o \u00e9 descartada o thread do servidor volta a esperar uma nova requisi\u00e7\u00e3o Se novas requisi\u00e7\u00f5es forem recebidas enquanto o servidor est\u00e1 executando os passos de 2 a 6, sejam requisi\u00e7\u00f5es paralelas do mesmo cliente ou de um outro cliente, estas ficar\u00e3o bloqueadas. A espera ser\u00e1 maior quanto mais o servidor demorar para atender \u00e0 primeira requisi\u00e7\u00e3o, por exemplo, se precisar consultar um banco de dados ou carregar o arquivo requisitado do disco. Para evitar que isto ocorra, o servidor pode usar mais threads. Thread per request O servidor pode criar um novo thread para cada nova requisi\u00e7\u00e3o, permitindo que m\u00faltiplas requisi\u00e7\u00f5es sejam tratadas concorrentemente. Isto \u00e9, mesmo que um thread do servidor seja bloqueado por muito tempo, somente um cliente ter\u00e1 sua resposta atrasada (excluindo-se necessidades de coordena\u00e7\u00e3o entre m\u00faltiplos threads) e outros clientes podem continuar sendo atendidos normalmente, como mostrado na figura a seguir. Lembre-se, entretanto, que o n\u00famero de threads que se pode criar em um SO \u00e9 limitado, pois cada thread usa recursos do SO. Al\u00e9m disso, a cria\u00e7\u00e3o e destrui\u00e7\u00e3o de threads \u00e9 cara pois \u00e9 feita por meio de uma chamada de sistema, pelo kernel, e portanto implica em alternar entre modo usu\u00e1rio e modo protegido. Se poss\u00edvel, devemos evitar a cria\u00e7\u00e3o de novos threads em aplica\u00e7\u00f5es com requisitos de desempenho, e reclicl\u00e1-los pode ser uma boa estrat\u00e9gia. Thread pool Para reciclarmos threads, podemos criar pools , um balde de threads que s\u00e3o usados quando necess\u00e1rio e devolvidos para o balde quando n\u00e3o mais. No cerne desta abordagem, junto com o pool de threads, fica uma fila bloquenante na qual tarefas s\u00e3o inseridas e de onde os threads tentam retir\u00e1-las. Como a fila \u00e9 bloqueante, se estiver vazia, o thread \u00e9 bloqueado e para de consumir recursos. T\u00e3o logo nova tarefa seja inserida, a fila acorda os threads para que a processem. Para garantir a corretude no processamento, a fila deve ser thread-safe , isto \u00e9, que se mantem correta mesmo quando m\u00faltiplos threads operam nela tanto para inserir quanto remover tarefas. Na figura, um thread principal \u00e9 encarregado de receber as requisi\u00e7\u00f5es e colocar na fila bloqueante; se a fila fica cheia, o thread principal fica bloqueado esperando por espa\u00e7o, fazendo com que novas conex\u00f5es tenham que esperar. Os threads do pool removem uma tarefa da fila, a tratam e, ao final do atendimento, pegam nova requisi\u00e7\u00e3o na fila, em um loop infinito; requisi\u00e7\u00f5es que demandam menor processamento liberam o thread mais rapidamente para que pegue nova tarefa. Se todas as tarefas s\u00e3o pequenas, os threds ficar\u00e3o bloqueados por muito tempo. Se todas s\u00e3o grandes, as tarefas se acumular\u00e3o na fila. Por isso \u00e9 importante dimensionar bem o tamanho to pool , ou mesmo torn\u00e1-lo din\u00e2mico para que use menos recursos (threads) quando n\u00e3o necess\u00e1rio e n\u00e3o deixe tarefas pendentes por muito tempo. Se considerarmos que cada tarefa na verdade tem v\u00e1rias partes, \u00e9 poss\u00edvel refinar mais este modelo, quebrando o processamento em v\u00e1rios pools. Est\u00e1gios Na arquitetura baseada em est\u00e1gios, e.g., Staged Event-Driven Architecture , SEDA, cada est\u00e1gio , cada est\u00e1gio \u00e9 respons\u00e1vel por processar uma parte da tarefa, passada adiante at\u00e9 que seja completada. 11 Uma caracter\u00edstica importante deste modelo \u00e9 que cada est\u00e1gio pode ser escalado individualmente de acordo com a demanda uma vez que cada est\u00e1gio tem seu pr\u00f3prio pool . Por exemplo, se um est\u00e1gio faz algum c\u00e1lculo leve, ent\u00e3o poucos threads s\u00e3o necess\u00e1rios ao mesmo. J\u00e1 um est\u00e1gio que precise efetuar E/S talvez precise mais threads , uma vez que estes ficam bloqueandos enquanto a opera\u00e7\u00e3o \u00e9 executada. 12 Desafios Embora a ideia de usar m\u00faltiplos threads seja melhorar desempenho e experi\u00eancia do usu\u00e1rio, faz\u00ea-lo efetivamente \u00e9 n\u00e3o trivial. Vejamos por exemplo o problema do falso compartilhamento; considere o seguinte pseudo-c\u00f3digo: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void threadfunction ( int32 * exclusivo ) { while ( true ) { int32 local = * exclusivo ; local = processa ( local ); * exclusivo = local ; } } ... int32 X ; int32 Y ; thread1 = tread_new ( threadfunction , & X ); thread2 = tread_new ( threadfunction , & Y ); ... Cada um dos threads criados acessa exclusivamente uma das vari\u00e1veis. Logo, n\u00e3o h\u00e1 interfer\u00eancia entre as threads e se cada uma for colocada em um processador diferente, executar\u00e3o no m\u00e1ximo de seu potencial, correto? N\u00e3o exatamente, pois mesmo este c\u00f3digo simpl\u00edssimo podemos sofrer de falso compartilhamento . Isto acontece, por exemplo, se cada linha da cache do sistema onde este programa executa tiver 8 ou mais bytes de comprimento. Como tanto X quanto Y no programa tem 4 bytes, as duas vari\u00e1veis poder\u00e3o ficar na mesma linha da cache e toda vez que uma thread modificar uma vari\u00e1vel a cache da outra ser\u00e1 invalidada para leitura. Para que isto n\u00e3o ocorra, \u00e9 preciso se certificar que as vari\u00e1veis fiquem em linhas diferentes da cache; no exemplo, poderia-se definir X e Y como vetores do tamanho da linha da cache e usar efetivamente apenas a primeira posi\u00e7\u00e3o de cada vetor. Se o compartilhamento for real, por exemplo se ambos os threads usarem a vari\u00e1vel X, ent\u00e3o o problema n\u00e3o ser\u00e1 t\u00e3o facilmente resolv\u00edvel. Neste caso, poder-se-ia definir afinidade entre threads, isto \u00e9, notar quais threads compartilham estado de forma que threads afins sejam colocados nos mesmos processadores e compartilhem as mesmas mem\u00f3rias. Isto torna muito mais f\u00e1cil e eficiente o controle de concorr\u00eancia, do ponto de vista do SO e hardware. Multiprograma\u00e7\u00e3o Fazer esta divis\u00e3o pode ser complicado pois a rela\u00e7\u00e3o de compartilhamento entre threads pode ser complexa em fun\u00e7\u00e3o da tarefa sendo resolvida, por exemplo, se diferentes threads compartilharem diferentes vari\u00e1veis uns com os. Ainda que que uma configura\u00e7\u00e3o \u00f3tima em termos de afinidade exista, encontr\u00e1-la pode ser custo. Ainda assim, precisamos lidar com estado compartilhado e enfrentar condi\u00e7\u00f5es de corrida de forma a n\u00e3o levar a inconsist\u00eancias na executa\u00e7\u00e3o de tarefas, nos referindo a inconsist\u00eancia aqui como qualquer desvio no comportamento do programa daquilo que foi especificado pelo desenvolvedor. Para isso, usamos as primitivas de controle de concorr\u00eancia que estudaram em SO, que tamb\u00e9m tem seus problemas em potencial, como deadlocks e inani\u00e7\u00e3o . Veja o seguinte v\u00eddeo para uma an\u00e1lise de diversos pontos importantes no uso de multithreads. Estado A quest\u00e3o das regi\u00f5es cr\u00edticas est\u00e1 intimamente relacionada \u00e0 quest\u00e3o da manuten\u00e7\u00e3o de estado nos servidores. Quanto a este respeito, podemos classificar servidores como stateful e stateless , dois termos que ouvir\u00e3o frequentemente enquanto trabalhando com SD. O \"state\" nos dois nomes se refere ao estado mantido por um servi\u00e7o para atender a requisi\u00e7\u00f5es. Caso mantenha estado, por exemplo informando em quais arquivos o cliente est\u00e1 interessado, fica mais f\u00e1cil para o servidor continuar o trabalho feito em requisi\u00e7\u00f5es anteriores. Imagine por exemplo que um cliente esteja acessando linhas em um banco de dados, de forma paginada: a cada requisi\u00e7\u00e3o, o cliente recebe \\(n\\) novas linhas para processar e, quando estiver pronto, requisite \\(n\\) novas linhas. Imagine qu\u00e3o infeficiente seria se o servidor seguisse o seguinte fluxo: receba requisi\u00e7\u00e3o informando a \u00faltima linha lida recalcule todas as respostas para consulta salte at\u00e9 a linha informada pelo cliente retorne as pr\u00f3ximas \\(n\\) linhas para o cliente feche o resultado da consulta. Se em vez disso o servidor mantiver um mapa com consultas recentes, em que a chave seja algum identificador do cliente e o valor uma vis\u00e3o dos resultados; a cada nova requisi\u00e7\u00e3o, basta o servidor resgatar a vis\u00e3o usando o identificador do cliente e selecionar as seguintes \\(n\\) entradas da vis\u00e3o. Manter o mapa como estado acelera o processamento e melhora a experi\u00eancia do usu\u00e1rio, neste caso. Por outro lado, considere que m\u00faltiplos clientes fazem consultas concorrentemente: quanto recurso seria necess\u00e1rio para que o servidor mantenha a vis\u00e3o de todos os clientes? Tamb\u00e9m a complexidade do servidor aumenta. Considere as algumas de muitas perguntas poss\u00edveis neste cen\u00e1rio: Como o servidor mant\u00e9m as respostas a novas requisi\u00e7\u00f5es consistentes com as respostas anteriores? E se linhas s\u00e3o removidas ou inseridas no banco de dados? Se m\u00faltiplos servidores existem, como compartilhar os estado entre os mesmos? Se o cliente resolva n\u00e3o fazer mais requisi\u00e7\u00f5es, por exemplo por ter encontrado o que procurava, por quanto tempo o servidor deve manter a vis\u00e3o aberta? Voc\u00ea j\u00e1 deve ter adivinhado que no primeiro exemplo temos um servidor stateless e no segundo um stateful , e percebido que cada um tem suas vantagens e desvantagens. Vejamos mais algumas. Sess\u00e3o Essencialmente, o servidor stateless n\u00e3o mantem informa\u00e7\u00e3o sobre a sess\u00e3o do cliente e requer que a cada nova requisi\u00e7\u00e3o, quaisquer informa\u00e7\u00f5es necess\u00e1rias para realizar a tarefa requisitada sejam novamente fornecidas ao servidor. No caso stateful , o servidor pode se lembrar, como no exemplo anterior, at\u00e9 onde o trabalho j\u00e1 foi executado, quais arquivos o cliente manipulou (e mant\u00ea-los abertos), qual o endere\u00e7o o cliente e enviar-lhe notifica\u00e7\u00f5es importantes (e.g., \"Novo dado inserido!\"). Falhas Enquanto servidores stateful obviamente levam a melhor desempenho no happy path (contanto que recursos suficientes sejam providos), no caso de falhas, servi\u00e7os stateless tendem a voltar ao ar mais rapidamente, uma vez que n\u00e3o h\u00e1 estado que precise ser recuperado. Pela mesma raz\u00e3o, clientes que percebem que um servidor falhou podem rapidamente se dirigir a outros servidores e continuar suas requisi\u00e7\u00f5es de onde estavam, uma vez que s\u00e3o detentores de toda a informa\u00e7\u00e3o necess\u00e1ria para o pr\u00f3ximo passo do processamento. Lidar com falhas tamb\u00e9m introduz outro requisito aos servidores: mem\u00f3ria est\u00e1vel. Para que possa o recuperar o estado anterior \u00e0 falha, o servidor precisa colocar o estado em algum lugar que independa do processo para se manter, por exemplo, nvRAM , SSD ou spindles . A perda deste estado implicaria na incapacidade de prover o servi\u00e7o corretamente. Um projeto stateless n\u00e3o depende deste estado e por isso pode ser mais rapidamente recuperado, replicado ou substitu\u00eddo. Stateless x Stateful N\u00e3o surpreendentemente, a resposta para \"qual abordagem \u00e9 melhor, stateful ou stateless ?\" \u00e9 depende . Ambos as op\u00e7\u00f5es tem suas vantagens e desvantagens e para algums servi\u00e7os apenas uma op\u00e7\u00e3o ser\u00e1 vi\u00e1vel. Se seu servi\u00e7o precisa manter estado (um SGBD, por exemplo), ele ter\u00e1 que manter estado, mesmo que n\u00e3o sobre clientes. Veja um pequeno comparativo das caracter\u00edsticas das duas abordagens. Stateless Stateful Resultado depende da entrada Depende do hist\u00f3rico de entradas Qualquer servidor pode atender Mesmo servidor deve atender N\u00e3o promete notificar o cliente Assina contrato com o cliente Repete opera\u00e7\u00f5es Aproveita resultados anteriores N\u00e3o fica inconsistente com rela\u00e7\u00e3o ao cliente Pode ficar inconsistente se perder estado ou conex\u00e3o feita com outro servidor re-autentica\u00e7\u00e3o (mesmo que simplficada) a cada requisi\u00e7\u00e3o Autentica no come\u00e7o da sess\u00e3o Multithread na pr\u00e1tica POSIX POSIX Threads ou PThreads, s\u00e3o uma defini\u00e7\u00e3o aberta de como threads devem funcionar em sistemas operacionais. V\u00e1rias implementa\u00e7\u00f5es desta especifica\u00e7\u00e3o est\u00e3o dispon\u00edveis tanto para sistemas Unix, compat\u00edveis com especifi\u00e7\u00f5es POSIX, mas tamb\u00e9m para Windows, via subsistemas. Al\u00e9m disso, mesmo implementa\u00e7\u00f5es n\u00e3o POSIX tem funcionalidade equivalentes e, por este motivo, entender POSIX servir\u00e1 de base para entender quaisquer API para programa\u00e7\u00e3o multi-threaded . Para se definir um thread , \u00e9 necess\u00e1rio definir uma fun\u00e7\u00e3o de entrada, que ser\u00e1 para o thread como a fun\u00e7\u00e3o main \u00e9 para o processo em si. No exemplo a seguir a fun\u00e7\u00e3o foi definida com retorno void * e com \u00fanico par\u00e2metro tambem void * ; esta \u00e9 uma obrigatoriedade para fun\u00e7\u00f5es de entrata PThread. Observe contudo que void * pode ser tratado como um blob para mascarar outros tipos de dado, por exemplo um vetor, um enumera\u00e7\u00e3o ou uma struct . 1 2 3 4 5 6 7 8 9 10 11 #include <stdio.h> #include <stdlib.h> #include <pthread.h> int thread_count ; void * hello ( void * rank ) { long my_rank = ( long ) rank ; printf ( \"Hello from thread %ld of %d \\n \" , my_rank , thread_count ); return NULL ; } Um thread \u00e9 criado pela fun\u00e7\u00e3o pthread_create , que coloca em um pthread_t um handle para o thread . A fun\u00e7\u00e3o recebe como par\u00e2metros op\u00e7\u00f5es para configura\u00e7\u00e3o, a fun\u00e7\u00e3o de entrada, e o par\u00e2metro do tipo void * . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int main ( int argc , char * argv []) { long thread ; pthread_t * thread_handles ; if ( argc < 2 ) { printf ( \"usage: %s <number of threads>\" , argv [ 0 ]); return 1 ; } thread_count = strtol ( argv [ 1 ], NULL , 10 ); thread_handles = malloc ( thread_count * sizeof ( pthread_t )); for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_create ( & thread_handles [ thread ], NULL , hello , ( void * ) thread ); printf ( \"Hello from the main thread \\n \" ); O handle do thread deve ser alocado previamente \u00e0 fun\u00e7\u00e3o de cria\u00e7\u00e3o e liberado ap\u00f3s o fim da execu\u00e7\u00e3o do thread . \u00c9 poss\u00edvel esperar pelo fim da execu\u00e7\u00e3o usando o pthread_join , que recebe como par\u00e2metro o handle do thread e um ponteiro para onde o resultado da fun\u00e7\u00e3o de entrada deve ser colocado, do tipo void ** . 1 2 3 4 for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_join ( thread_handles [ thread ], NULL ); free ( thread_handles ); Para executar um programa PThread, compile com 1 gcc -pthread teste.c -o teste e execute com 1 ./teste 5 e observe que a sa\u00edda das threads \u00e9 ordenada . Agora experimente 1 ./teste 200 Observe que a sa\u00edda \u00e9 desordenada (pode ser necess\u00e1rio executar m\u00faltiplas vezes ou aumentar de 200 para, digamos, 1000 para observar a desordem. Isto acontece porqu\u00ea a execu\u00e7\u00e3o das threads independe da ordem de cria\u00e7\u00e3o. De fato, usando PThreads, temos pouco controle sobre os threads que criamos. Mas isto n\u00e3o quer dizer que estamos \"\u00f3rf\u00e3os\" de API; v\u00e1rias outras opera\u00e7\u00f5es podem ser executadas, e podem ser encontradas a partir do manual de pthread_create . Alguns exemplos interessantes: pthread_tryjoin - espera thread terminar pthread_exit - termina a thread e retorna resultado An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function's return value serves as the thread's exit status. Manual de pthread_exit . pthread_attr_setaffinity_np - ajusta afinidade dos threads. Python Em Python, como seria de se esperar, h\u00e1 v\u00e1rias formas de se trabalhar com threads . O exemplo a seguir usa o pacote thread e \u00e9 essencialmente um env\u00f3lucro POSIX. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/usr/bin/python import thread import time # Define a function for the thread def print_time ( threadName , delay ): count = 0 while count < 5 : time . sleep ( delay ) count += 1 print \" %s : %s \" % ( threadName , time . ctime ( time . time ()) ) # Create two threads as follows try : thread . start_new_thread ( print_time , ( \"Thread-1\" , 2 , ) ) thread . start_new_thread ( print_time , ( \"Thread-2\" , 4 , ) ) except : print \"Error: unable to start thread\" while True : pass J\u00e1 o pr\u00f3ximo exemplo usa o pacote threading e uma abordagem orientada a objetos. Observe que h\u00e1 momentos distintos no ciclo de vida do thread em que acontece a cria\u00e7\u00e3o e o in\u00edcio da execu\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/usr/bin/python import threading import time exitFlag = 0 class myThread ( threading . Thread ): def __init__ ( self , threadID , name , counter ): threading . Thread . __init__ ( self ) self . threadID = threadID self . name = name self . counter = counter def run ( self ): print \"Starting \" + self . name print_time ( self . name , self . counter , 5 ) print \"Exiting \" + self . name def print_time ( threadName , counter , delay ): while counter : if exitFlag : threadName . exit () time . sleep ( delay ) print \" %s : %s \" % ( threadName , time . ctime ( time . time ())) counter -= 1 # Create new threads thread1 = myThread ( 1 , \"Thread-1\" , 1 ) thread2 = myThread ( 2 , \"Thread-2\" , 2 ) # Start new Threads thread1 . start () thread2 . start () print \"Exiting Main Thread\" Uma consequ\u00eancia desta divis\u00e3o \u00e9 que um mesmo objeto do tipo Thread pode ser reciclado e executado v\u00e1rias vezes. Leia mais Threads em Python Java Outro exemplo importante de API para multithreading \u00e9 a Java. Em Java, h\u00e1 essencialmente duas formas de se conseguir concorr\u00eancia. A primeira \u00e9 via inst\u00e2ncias expl\u00edcitas da classe Thread e, a segunda, via abstra\u00e7\u00f5es de mais alto n\u00edvel, os Executors . Java tamb\u00e9m prov\u00ea diversas estruturas para comunica\u00e7\u00e3o e coordena\u00e7\u00e3o de threads no pacote java.util.concurrent . Aqui nos focaremos em aspectos b\u00e1sicos de concorr\u00eancia na linguagem, mas esteja ciente de que a mesma \u00e9 muito rica neste t\u00f3pico e uma \u00f3tima documenta\u00e7\u00e3o \u00e9 dispobinilizada pela pr\u00f3pria Oracle . H\u00e1 duas formas b\u00e1sicas de definir um novo thread em Java, via extens\u00e3o da classe Thread , como no primeiro exemplo, ou ou via implementa\u00e7\u00e3o da interface Runnable , como no segundo, a seguir. Thread 1 2 3 4 5 6 7 8 9 10 public class HelloThread extends Thread { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new HelloThread (); t . start (); } } Runnable 1 2 3 4 5 6 7 8 9 10 public class HelloRunnable implements Runnable { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); t . start (); } } Observe que nos dois exemplos, um m\u00e9todo run() \u00e9 implementado com o c\u00f3digo a ser executado pelo thread . Em nenhum dos exemplos, contudo, o m\u00e9todo \u00e9 invocado diretamente. Em vez disto, o m\u00e9todo start() , sim, \u00e9 invocado. Isto ocorre porqu\u00ea antes de executar as instru\u00e7\u00f5es definidas pelo pelo programador no m\u00e9todo run() , a m\u00e1quina virtual precisa executar alguma \"m\u00e1gica\" por baixo dos panos como, por exemplo, solicitar ao sistema operacional a cria\u00e7\u00e3o de um thread do SO, que servir\u00e1 de hospedeiro para o thread Java. Isto acontece dentro do start() , que em algum ponto de sua execu\u00e7\u00e3o levar\u00e1 \u00e0 invoca\u00e7\u00e3o do m\u00e9todo run() . A classe Thread tamb\u00e9m prov\u00ea uma s\u00e9rie de m\u00e9todos que permitem gerenciar a vida do thread criado. Por exemplo, o m\u00e9todo de classe Thread.sleep() permite bloquear o thread no qual a invoca\u00e7\u00e3o aconteceu por um determinado per\u00edodo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class HelloRunnable implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ) { System . out . println ( \"Hello at instant \" + i ); try { Thread . sleep ( 1000 ); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); t . start (); } } Observe que a chamada a sleep() est\u00e1 dentro de um bloco try/catch . Isto \u00e9 necess\u00e1rio pois \u00e9 permitido \u00e0 JVM acordar o thread em qualquer instante, antes ou ap\u00f3s o tempo especificado. Assim, embora normalmente o tempo \"dormido\" seja pr\u00f3ximo ao especificado, se h\u00e1 requisitos de precis\u00e3o, \u00e9 necess\u00e1rio que o thread , ao acordar, verifique se j\u00e1 dormiu o suficiente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class HelloRunnable implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ) { System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 1000 ; while ( before + timeout > System . currentTimeMillis ()) { try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); t . start (); } } Quando um thread est\u00e1 sendo executado, outros podem ter que esperar at\u00e9 que complete. Por exemplo, no caso de um navegador Web, o thread que faz a renderiza\u00e7\u00e3o da p\u00e1gina n\u00e3o pode come\u00e7ar a trabalhar enquanto o thread que solicitou o HTML do servidor n\u00e3o receber sua resposta. Um thread indica a inten\u00e7\u00e3o de esperar por outro usando o m\u00e9todo join() . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class HelloRunnable implements Runnable { public void run () { Random rand = new Random (); for ( int i = 0 ; i < 10 ; i ++ ) { System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 901 + rand . nextInt ( 200 ); while ( before + timeout > System . currentTimeMillis ()) { try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); //t.setDaemon(true); t . start (); try { t . join (); //t.join(10000); } catch ( InterruptedException ie ) { System . out . println ( \"Waiting was interrupted\" ); } if ( t . isAlive ()) System . out . println ( \"Got tired of waiting\" ); else System . out . println ( \"Wait is over\" ); } } Invocar t.join() far\u00e1 com que o thread corrente, neste caso o principal, espere indefinidamente at\u00e9 que t termine de executar. Caso seja necess\u00e1rio limitar o tempo de espera, o tempo pode ser especificado como na linha comentada. Caso a espera termine por causa de um timeout , \u00e9 poss\u00edvel testar o estado atual do thread com Thread.isAlive() . Outro m\u00e9todo interessante, Thread.setDaemon() , especifica que o thread pode ser terminado quando a thread principal terminar. Descomente a invoca\u00e7\u00e3o e teste o efeito. Exerc\u00edcio: contador Fa\u00e7amos um exerc\u00edcio simples do uso de threads . Considere a classe e siga as instru\u00e7\u00f5es abaixo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Counter { private int c = 0 ; public int increment () { return ++ c ; } public int decrement () { return -- c ; } public int value () { return c ; } } Instancie um programa que gere 10 threads . Todos os threads devem compartilhar uma mesma inst\u00e2ncia de Counter Cada thread deve executar um loop em que incrementa o valor do contador 20 vezes a cada vez, imprime o resultado precedido do identificador do thread (use Thread.getName() ou Thread.currentThread().getName() ) A thread principal deve esperar todas as outras terminarem antes de terminar (use Thread.join() ). Analise a sa\u00edda do programa observando a ordem de execu\u00e7\u00e3o dos threads . An\u00e1lise \u00c9 f\u00e1cil observar que a sa\u00edda do programa \u00e9 aleat\u00f3ria nos identificadores e tende a ser incremental nos contadores, mas nem sempre isso \u00e9 verdade. Isso acontece porqu\u00ea a execu\u00e7\u00e3o dos threads \u00e9 n\u00e3o determin\u00edstica; uma vez que estejam prontos para executar, cabe ao escalonador do sistema operacional a decis\u00e3o sobre qual processo e em qual processador dever\u00e1 executar. Todo Melhorar explica\u00e7\u00e3o abaixo Al\u00e9m de extens\u00e3o de Thread e implementa\u00e7\u00e3o de Runnable , Java disponibiliza tamb\u00e9m Executor como abstra\u00e7\u00e3o de mais alto n\u00edvel para execu\u00e7\u00e3o de tarefas concorrentes. Executor ExecutorService ScheduledExecutorService 1 2 3 Executor e = ...; Runnable r = ...; e . execute ( r ); Executors normalmente implementam thread pools , que podem ser de diferentes tipos. O mais simples \u00e9 o de tamanho fixo em que h\u00e1 um n\u00famero inicial de threads criados e que, no caso de algum ser terminado, por exemplo por causa de uma exce\u00e7\u00e3o n\u00e3o tratada, cria substitutos para manter o n\u00famero constante. Executor e = java . util . concurrent . Executors . newFixedThreadPool (); newCachedThreadPool() - expandable thread pool newSingleThreadExecutor() - single task at a time e outras vers\u00f5es ForkJoinPool 1 2 3 4 5 if (my portion of the work is small enough) do the work directly else split my work into two pieces invoke the two pieces and wait for the results Coordena\u00e7\u00e3o Como visto no exerc\u00edcio anterior, a execu\u00e7\u00e3o de threads \u00e9 n\u00e3o determin\u00edstica. Contudo, estas execu\u00e7\u00f5es frequentemente precisam ser coordenadas para que n\u00e3o pisem uns nos calcanhares dos outros, por exemplo, decidindo quem deve ser o pr\u00f3ximo a entrar em uma regi\u00e3o cr\u00edtica ou ser\u00e1 o respons\u00e1vel por uma determinada tarefa. H\u00e1 v\u00e1rias astra\u00e7\u00f5es que podem ser usadas para coordenar as opera\u00e7\u00f5es de threads , como deve se lembrar no estudo de Sistemas Operacionais. Alguns exemplos s\u00e3o locks , vari\u00e1veis de condi\u00e7\u00e3o e sem\u00e1foros. Especificamente em Java, provavelmente a abstra\u00e7\u00e3o mais simples s\u00e3o os blocos synchronized . synchronized Ao definir m\u00e9todos como synchronized , garante-se que os mesmos nunca ser\u00e3o executados concorrentemente. Observe a classe a seguir, que modifica o contador do exerc\u00edcio anterior. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class SynchronizedCounter { private int c = 0 ; public synchronized int increment () { return ++ c ; } public synchronized int decrement () { return -- c ; } public synchronized int value () { return c ; } } Caso dois threads invoquem os m\u00e9todos increment e decrement ao mesmo tempo, por exemplo, a JVM far\u00e1 com que um dos threads pare sua execu\u00e7\u00e3o at\u00e9 que o outro tenha completado a invoca\u00e7\u00e3o. Isto n\u00e3o quer dizer que executar o exerc\u00edcio anterior com esta vers\u00e3o do contador levar\u00e1 a sa\u00eddas com incrementos completamente sequenciais, pois um thread poderia parar de ser executado logo ap\u00f3s incrementar o contador, depois de terminado o m\u00e9todo increment , e s\u00f3 voltar a executar depois que outro tenha incrementado e impresso na tela o valor obtido. O que quer dizer \u00e9 que, mesmo que sa\u00eddas estranhas existam, cada m\u00e9todo foi executada integralmente antes da opera\u00e7\u00e3o seguinte. Exerc\u00edcio: synchronized Modifique o c\u00f3digo do exerc\u00edcio anterior para usar a vers\u00e3o synchronized do contador. Depois de execut\u00e1-lo, adicione um println(\"Dentro: \" + c) dentro do m\u00e9todo de incremento para verificar que estas sa\u00eddas acontecem ordenadamente. synchronized funciona porqu\u00ea limita a concorr\u00eancia, mas \u00e9 problem\u00e1tico exatamente pela mesma raz\u00e3o. Por isso, \u00e9 essencial que o synchronized seja o mais limitado poss\u00edvel em termos de escopo, o que nos leva ao uso de synchronized em blocos de c\u00f3digo menores que m\u00e9todos. Por exemplo: 1 2 3 4 5 6 7 8 9 10 11 12 public class Namer { String lastName = null ; int nameCount = 0 ; public void addName ( String name ) { lastName = name ; synchronized ( this ) { nameCount ++ ; } nameList . add ( name ); } } Neste caso, blocos sincronizados no mesmo objeto , n\u00e3o s\u00e3o executados concorrentemente, mas outros blocos sim. Exerc\u00edcio: bloco synchronized Neste exerc\u00edcio, use dois objetos para travar o acesso a dois contadores. Instancie um programa com dois threads tal que: executem um loop 1000 vezes em que o primeiro thread primeiro invoca inc1 e depois inc2 o segundo thread primeiro invoca inc2 e depois inc1 ambos os threads imprimem o valor de c1 e c2 An\u00e1lise 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class MsLunch { private long c1 = 0 ; private long c2 = 0 ; private Object lock1 = new Object (); private Object lock2 = new Object (); public void inc1 () { synchronized ( lock1 ) { c1 ++ ; } } public void inc2 () { synchronized ( lock2 ) { c2 ++ ; } } } Sinaliza\u00e7\u00e3o Usados corretamente, o bloco synchronized \u00e9 executado de forma at\u00f4mica, isto \u00e9, indivis\u00edvel. Algumas opera\u00e7\u00f5es muito simples s\u00e3o naturalmente at\u00f4micas, e n\u00e3o precisam ser \"protegidas\" pelo synchronized . Por exemplo, leituras e escritas de tipos b\u00e1sicos como int , char e byte , mas n\u00e3o long ou double , pois usam mais de uma palavra em algumas arquiteturas, ou vari\u00e1veis declaradas volatile . Usando estas vari\u00e1veis, \u00e9 poss\u00edvel coordenar threads , como no exemplo a seguir. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 boolean condicao = false ; ... public void espereCondicao () { while ( ! condicao ) {} System . out . println ( \"condicao alcancada.\" ); } ... public void satisfacaCondicao () { condicao = true ; } Embora correta, esta abordagem, conhecida como espera ocupada , n\u00e3o \u00e9 eficiente pois desperdi\u00e7a computa\u00e7\u00e3o. Felizmente, em Java, todos os objetos implementam os m\u00e9todos wait e notify/notifyAll , que podem ser usados para sincronizar eficientemente threads . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Sync { Object synch = new Object (); boolean condicao = false ; public void espereCondicao () { while ( ! condicao ) { try { synchronized ( synch ){ synch . wait (); } } catch ( InterruptedException e ) {} } System . out . println ( \"Condicao alcancada\" ); } ... public void satisfacaCondicao () { condicao = true ; synchronized ( synch ){ synch . notifyAll (); } } } Neste exemplo a execu\u00e7\u00e3o da fun\u00e7\u00e3o espereCondicao \u00e9 \"pausada\" por synch . wait () at\u00e9 que uma notifica\u00e7\u00e3o seja enviada via sync . notifiyAll () , na fun\u00e7\u00e3o satisfacaCondicao () . Observe que estas opera\u00e7\u00f5es s\u00f3 podem ocorrer dentro de blocos sincronizados na vari\u00e1vel usada na sinaliza\u00e7\u00e3o. Locks Outras abstra\u00e7\u00f5es para coordena\u00e7\u00e3o de threads est\u00e3o dispon\u00edveis no pacote java.util.concurrent . As mais simples delas s\u00e3o java.util.concurrent.locks.Lock e java.util.concurrent.locks.ReentrantLock . Veja um exemplo de uso, notando o idioma de uso dentro de block try/catch/finally , que garante que o lock ser\u00e1 liberado a despeito de exce\u00e7\u00f5es no bloco. 1 2 3 4 5 6 7 Lock l = new ReentrantLock (); l . lock (); try { // access the resource protected by this lock } finally { l . unlock (); } Como bem sabido, o uso dos \"locks\" em ordens diferentes pode levar a um deadlock pois um ciclo de depend\u00eancias pode ser formado entre locks, detentores de locks e interessados em locks. O grafo de depend\u00eancia seguinte exemplifica o cen\u00e1rio, em que o thread T1 obteve o lock2 e tenta obter o lock1, e o thread T2 obteve o lock1 e tenta obter o lock2. graph LR T1 --> lock1 --> T2 --> lock2 --> T1 Estruturas thread-safe Finalmente, Java tamb\u00e9m disponibiliza estruturas de dados que podem ser acessadas concorrentemente por m\u00faltiplos threads sem risco de corrup\u00e7\u00e3o, denominadas thread-safe . BlockingQueue - bloquei threads se n\u00e3o houver elementos na filq. ConcurrentMap/ConcurrentHashMap - opera\u00e7\u00f5es at\u00f4micas; if (!m.containsKey(k)) m.put(k,v); vOld = m.putIfAbsent(k,v); Tipos At\u00f4micos 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import java.util.concurrent.atomic.AtomicInteger ; class AtomicCounter { private AtomicInteger c = new AtomicInteger ( 0 ); public void increment () { c . incrementAndGet (); } public void decrement () { c . decrementAndGet (); } public int value () { return c . get (); } } ThreadLocal 1 2 3 4 5 6 7 8 9 private static ThreadLocal < Integer > myId = new ThreadLocal < Integer > () { public Integer initialValue () { return new Random (). nexInt (); } }; public static Integer getMyId () { return myId . get (); } Exerc\u00edcio - Anel Multithread Usando uma linguagem de alto-n\u00edvel como C/C++/Java, escrever um programa que crie 30 threads e fa\u00e7a com que uma mensagem circule entre os mesmos. A mensagem \u00e9 uma string aleat\u00f3ria de pelo menos 80 caracteres. A cada vez que um thread recebe a mensagem ele a imprime, modifica o primeiro caractere min\u00fasculo para mai\u00fasculo, caso exista, dorme por 1 segundo, e repassa a mensagem. Quando todos os caracteres forem mai\u00fasculos, o processo repassa a mensagem e ent\u00e3o termina. Antes de terminar, o processo deve imprimir a mensagem resultante. Refer\u00eancias Sockets UDP em Python UDP em Python Multicast em Java Multicast em Python Beej's Guide to Network Programming - Using Internet Sockets Concorr\u00eancia em Java Java Concurrency in Practice The Well-Grounded Java Developer Concorr\u00eancia em Java Futures e Promises Locks Tipos At\u00f4micos Estado Uma vis\u00e3o interessante sobre estado \u00e9 apresentada em On stateless software design . Observe que n\u00e3o necessariamente eu concordo com tudo o que est\u00e1 escrito aqui, principalmente a quest\u00e3o sobre stateful ser sempre mais complexo. A discrep\u00e2ncia de vis\u00e3o est\u00e1 no fato de parte da complexidade ser levada para o cliente, no caso dos servidores stateless , mas n\u00e3o necessariamente ser eliminada. Sobre IO n\u00e3o bloqueante em Java. Annual failure rates - servers \u21a9 Os recursos compartilhados v\u00e3o desde alguns \u00f3bvios, como capacidade de armazenamento e de processamento , a pr\u00f3pria localiza\u00e7\u00e3o de um n\u00f3, que pode ser geograficamente mais pr\u00f3xima e de menor lat\u00eancia at\u00e9 um ponto de interesse, ou at\u00e9 mesmo a disponibilidade de uma conex\u00e3o f\u00edsica com um recurso especial, como uma impressora. \u21a9 Lembrem-se que tamb\u00e9m e voc\u00ea n\u00e3o quer que seu sistema seja como ogros, temperamentais e mal-cheirosos. Logo, planeje bem suas camadas de abstra\u00e7\u00e3o. \u21a9 By User:Ludovic.ferre - Internet Connectivity Distribution&Core.svg, CC BY-SA 3.0, ( https://commons.wikimedia.org/w/index.php?curid=10030716 ) \u21a9 Endere\u00e7os IP n\u00e3o p\u00fablicos n\u00e3o servem como identificadores \u00fanicos na Internet. \u21a9 Voc\u00ea pode usar outro nome, desde que n\u00e3o seja socket.py , e que adapte o comando para sua execu\u00e7\u00e3o. \u21a9 O programa telnet \u00e9 normalmente instalado por padr\u00e3o tanto no Windows, OSX quanto no Linux. J\u00e1 o netcat normalmente precisa ser instalado por voc\u00ea. Em alguns sistemas, em vez de netcat o comando \u00e9 o nc ]. \u21a9 Understanding IP Multicast \u21a9 IP-Multicast em IPv6 \u21a9 Um bom ponto de partida para o t\u00f3pico \u00e9 a sua entrada na wikipedia . \u21a9 O artigo SEDA: An Architecture for Well-Conditioned, Scalable Internet Services descreve em detalhes a arquitetura SEDA. \u21a9 Pode-se argumentar que E/S ass\u00edncrona resolveria o problema aqui, mas isso n\u00e3o vem ao caso. \u21a9","title":"Fundamentos"},{"location":"basics/#fundamentos","text":"Uma vez que estejam convencidos de que n\u00e3o temos alternativas \u00e0 distribui\u00e7\u00e3o se queremos sistemas escal\u00e1veis e tolerantes a falhas, o pr\u00f3ximo passo \u00e9 entender como podemos implement\u00e1-los e quais desafios encontraremos. O primeiro desafio \u00e9 entender o ambiente no qual est\u00e3o inseridos, suas limita\u00e7\u00f5es e fragilidades. Isto \u00e9, precisamos definir um modelo computacional , sabendo que alguns problemas tem solu\u00e7\u00f5es triviais ou inexistentes, dependendo do modelo.","title":"Fundamentos"},{"location":"basics/#modelos-computacionais","text":"Antes de distribuir nosso sistema, isto \u00e9, dividir a computa\u00e7\u00e3o/armazenamento em diversas m\u00e1quinas, e coordenar suas a\u00e7\u00f5es para que sejam consistentes com a especifica\u00e7\u00e3o, de forma a minimizar o tempo que o servi\u00e7o fica fora do ar, entregando o servi\u00e7o de acordo com expectativas especificadas, precisamos responder a algumas perguntas: Qual a probabilidade de um n\u00f3 parar de funcionar? Como os n\u00f3s se comunicam? Eles compartilham um espa\u00e7o de endere\u00e7amento ou enviam mensagens uns para os outros? A quais atrasos a comunica\u00e7\u00e3o est\u00e1 sujeita? Pode haver atrasos infinitos? A comunica\u00e7\u00e3o pode ser corrompida? Os rel\u00f3gios dos hospedeiros marcam o mesmo valor no mesmo instante, ou melhor, s\u00e3o sincronizados? H\u00e1 agentes que possam querer perturbar o sistema, por exemplo para ganhar acesso a mais recursos do que seria justo? Modelos Comunica\u00e7\u00e3o Sincronismo Falhas Estas perguntas s\u00e3o normalmente divididas em tr\u00eas eixos, Comunica\u00e7\u00e3o , Sincronismo e Falhas , e a combina\u00e7\u00e3o das respostas define o modelo computacional adotado.","title":"Modelos computacionais"},{"location":"basics/#comunicacao","text":"De uma forma ou de outra, sistemas distribu\u00eddos tem \u00e0 sua disposi\u00e7\u00e3o m\u00faltiplos processadores e permitem o desenvolvimento de aplica\u00e7\u00f5es paralelas, isto \u00e9, onde m\u00faltiplas tarefas s\u00e3o executadas ao mesmo tempo ou paralelamente . Contudo, por um lado, quando falamos em sistemas multiprocessados, normalmente estamos falando de sistemas em que os processadores est\u00e3o pr\u00f3ximos e compartilham um mesmo espa\u00e7o de endere\u00e7amento, sejam computadores com m\u00faltiplos processadores ou sejam clusters de computadores conectados por um barramento de comunica\u00e7\u00e3o de alt\u00edssima largura de banda, como Infiniband que abstraiam m\u00faltiplos segmentos de mem\u00f3ria como um \u00fanico espa\u00e7o de endere\u00e7amento. Seja como for, estes sistemas com mem\u00f3ria compartilhada s\u00e3o normalmente usados para aplica\u00e7\u00f5es de computa\u00e7\u00e3o intensiva e em cujo os componentes s\u00e3o mais fortemente acoplados e melhor estudados em um curso de computa\u00e7\u00e3o paralela. Comunica\u00e7\u00e3o mem\u00f3ria compartilhada troca de mensagens Por outro lado, estamos mais interessados aqui em sistemas de maior escala geogr\u00e1fica, o que se adequa melhor ao modelo de troca de mensagens, isto \u00e9, onde cada n\u00f3 mantem controle total do seu espa\u00e7o de endere\u00e7amento e s\u00f3 exp\u00f5e seu estado via mensagens enviadas para os outros n\u00f3s. Este modelo \u00e9 mais adequado ao desenvolvimento de aplica\u00e7\u00f5es com componentes fracamente acoplados , em que atrasos de comunica\u00e7\u00e3o e ocorr\u00eancia de falhas independentes s\u00e3o intr\u00ednsecas. Mem\u00f3ria Compartilhada Distribu\u00edda (DSM, do ingl\u00eas, Distributed Shared Memory ) \u00e9 uma abordagem h\u00edbrida que tenta integrar a facilidade de se programar usando um \u00fanico espa\u00e7o de endere\u00e7amento mas com o n\u00edvel de distribui\u00e7\u00e3o necess\u00e1ria a aplica\u00e7\u00f5es de larga escala, inclusive geogr\u00e1fica. Considere uma poss\u00edvel implementa\u00e7\u00e3o em software da DSM, apresentada na pr\u00f3xima figura. Nesta abordagem, cada host contribui uma por\u00e7\u00e3o de sua mem\u00f3ria para um pool global. Processos acessam o pool via gerentes de mem\u00f3ria , que traduzem os endere\u00e7os de um espa\u00e7o de endere\u00e7amento virtual para um host e um endere\u00e7o local a tal host, e usam message passing para implementar o acesso. Esta abordagem resulta em uma arquitetura NUMA, isto \u00e9, Non-Uniform Memory Access , j\u00e1 que os acessos a endere\u00e7os locais s\u00e3o mais r\u00e1pidos que aos remotos.","title":"Comunica\u00e7\u00e3o"},{"location":"basics/#sincronismo","text":"Sincronismo opera\u00e7\u00f5es comunica\u00e7\u00e3o rel\u00f3gio sincroniza\u00e7\u00e3o Quanto ao sincronismo, considera-se os processos tem a capacidade de medir a passagem de tempo, isto \u00e9, tem a acesso a rel\u00f3gios, o qu\u00e3o acurazes este s\u00e3o e o qu\u00e3o sincronizados s\u00e3o estes rel\u00f3gios uns com os outros. Al\u00e9m disso, considera-se a exist\u00eancia de limites de tempo para execu\u00e7\u00e3o de opera\u00e7\u00f5es, por exemplo, o tempo um processador leva para executar uma opera\u00e7\u00e3o de soma de dois inteiros, ou o tempo necess\u00e1rio para a entrega de uma mensagem ou acesso a uma regi\u00e3o de mem\u00f3ria.","title":"Sincronismo"},{"location":"basics/#falhas","text":"Quanto \u00e0s falhas, primeiro \u00e9 preciso aceitar o fato de que componentes independentes podem falhar independentemente e que quanto mais hosts , maior \u00e9 a probabilidade de que pelo menos um deles tenha uma CPU, disco, fonte, ou que quer que seja, falhando; e estejam certos, estas falhas acontecem o tempo todo. 1 Isto \u00e9 importante pois se em sistemas monol\u00edticos uma falha pode facilmente fazer com que o sistema todo pare e, portanto, n\u00e3o tente progredir na aus\u00eancia de um componente, em um sistema distribu\u00eddo queremos exatamente o contr\u00e1rio, isto \u00e9, que apesar da falha de um componente, os outros continuem prestando o servi\u00e7o, mesmo de forma deteriorada e sem comprometer a corretude do sistema. Falhas detect\u00e1vel temporiza\u00e7\u00e3o quebras maliciosas perda e corrup\u00e7\u00e3o de mensagens Para lidar com falhas, precisamos entender quais s\u00e3o suas poss\u00edveis formas, isto \u00e9, se o levam componentes falhos a parar de funcionar totalmente e de forma identific\u00e1vel por outros ou n\u00e3o, se h\u00e1 falhas \"maliciosas\", se os limites de tempo estabelecidos acima podem ser violados, se mensagens podem ser perdidas ou corrompidas.","title":"Falhas"},{"location":"basics/#modelo-assumido","text":"Outros carga de trabalho Embora modelos cl\u00e1ssicos sejam normalmente definidos em termos dos fatores acima, outras quest\u00f5es s\u00e3o tamb\u00e9m importantes, como o padr\u00e3o da carga de trabalho do sistema (maior carga \u00e0 noite? Na hora do almo\u00e7o? Black friday ?). Al\u00e9m de ignorarmos estes outros fatores, por enquanto assumiremos um modelo computacional n\u00e3o amig\u00e1vel, com comunica\u00e7\u00e3o por troca de mensagens, rel\u00f3gios e limites de tempo para opera\u00e7\u00f5es, mesmo que desconhecidos. Tamb\u00e9m assumiremos aus\u00eancia de falhas, a n\u00e3o ser quando quisermos provocar a an\u00e1lise de situa\u00e7\u00f5es mais interessantes. Este modelo ser\u00e1 ajustado na medida em que avan\u00e7armos, para tornar nossas an\u00e1lises mais realistas.","title":"Modelo Assumido"},{"location":"basics/#sd-sao-como-cebolas","text":"Uma vez definido o modelo computacional e identificado os algoritmos adequados aos problemas que queremos resolver, passamos \u00e0 implementa\u00e7\u00e3o. Distribuir \u00e9 dividir a computa\u00e7\u00e3o/armazenamento em diversos componentes, possivelmente geograficamente distantes , e coordenar suas a\u00e7\u00f5es para que resolvam a tarefa em quest\u00e3o de forma correta. Com a distribui\u00e7\u00e3o objetiva-se usar recursos dispon\u00edveis nos hosts onde os componentes s\u00e3o executados 2 e usar de redund\u00e2ncia para garantir que o servi\u00e7o sofra degrada\u00e7\u00e3o graciosa em caso de falhas, ou seja, fazer com que o servi\u00e7o continue funcionando, mesmo que com vaz\u00e3o reduzida , lat\u00eancia aumentada , menor capacidade de tratamento de requisi\u00e7\u00f5es concorrentes, ou com funcionalidades desabilitadas . Abstra\u00e7\u00f5es Comunica\u00e7\u00e3o Ordena\u00e7\u00e3o Confiabilidade Invoca\u00e7\u00e3o de procedimentos remotos Heterogeneidade Linguagens Arquiteturas Sistemas Operacionais Times Para colaborar, as diversas partes do sistema distribu\u00eddo devem se comunicar, o que pode pode ser feito de diversas formas e em diversos n\u00edveis de abstra\u00e7\u00e3o. Por exemplo, no caso troca de mensagens, estas podem ser desde pacotes de bytes entregues pelo IP/UDP como por troca de mensagens ordenadas, fluxos de dados , ou invoca\u00e7\u00e3o remota de procedimentos . Implementar estas abstra\u00e7\u00f5es em si j\u00e1 \u00e9 uma tarefa complicada, pois \u00e9 preciso levar em considera\u00e7\u00e3o que os componentes de um sistema distribu\u00eddo falham independentemente , executam em hosts com rel\u00f3gios dessincronizados , s\u00e3o desenvolvidos usando-se linguagens diversas , sistemas operacionais distintos , com arquiteturas diferentes e por times independentes . Apesar de tantas vari\u00e1veis, as abstra\u00e7\u00f5es precisam permitir que as aplica\u00e7\u00f5es que as usem possam se coordenar nos m\u00ednimos detalhes. Dado que a complexidade de se implementar estas abstra\u00e7\u00f5es j\u00e1 \u00e9 grande por si s\u00f3, se formos reinventar a roda a cada novo sistema, n\u00e3o faremos muitos avan\u00e7os. Mas, como voc\u00eas bem sabem, camadas de abstra\u00e7\u00e3o s\u00e3o a chave para se lidar com complexidade. Assim, sistemas distribu\u00eddos s\u00e3o como cebolas, cheias de camadas e que nos fazem chorar quando precisamos descasc\u00e1-las. 3 Felizmente, para cada problema que tenha que resolver, h\u00e1 uma boa probabilidade de que algu\u00e9m j\u00e1 o tenha atacado e disponibilizado uma solu\u00e7\u00e3o, de forma comercial ou n\u00e3o.","title":"SD s\u00e3o como cebolas!"},{"location":"basics/#comunicacao_1","text":"As camadas de abstra\u00e7\u00e3o mais b\u00e1sicas est\u00e3o na rede de computadores que serve de substrato a todo e qualquer sistema distribu\u00eddo, afinal, a pedra fundamental da constru\u00e7\u00e3o de sistemas distribu\u00eddos \u00e9 a capacidade de comunica\u00e7\u00e3o entre seus componentes. Tamb\u00e9m importantes, de um ponto de vista pr\u00e1tico do desenvolvimento, s\u00e3o os conceitos de concorr\u00eancia e paralelismo, pois componentes pode necessitar manter v\u00e1rias \"conversas\" em paralelo com m\u00faltiplos outros componentes.","title":"Comunica\u00e7\u00e3o"},{"location":"basics/#canais-e-protocolos","text":"Para que os componentes de um sistema distribu\u00eddo se comuniquem, \u00e9 necess\u00e1rio que seus hosts possuam interfaces de rede e que estas interfaces estejam ligadas a uma rede com capacidade de roteamento de dados, estabelecendo um canal de comunica\u00e7\u00e3o entre os componentes. Al\u00e9m do canal, \u00e9 tamb\u00e9m necess\u00e1rio que se estabele\u00e7a um protocolo de comunica\u00e7\u00e3o , que define as regras para que a comunica\u00e7\u00e3o aconte\u00e7a, por exemplo, a gram\u00e1tica para forma\u00e7\u00e3o de mensagens. Por exemplo, quando voc\u00ea fala com uma pessoa, cara-a-cara, o meio de comunica\u00e7\u00e3o \u00e9 o ar e o protocolo utilizado \u00e9 a linguagem conhecida pelas duas partes, o Portugu\u00eas por exemplo. Na pr\u00e1tica, canais de comunica\u00e7\u00e3o podem ter diversas topologias e caracter\u00edsticas, por exemplo: Ponto-a-ponto Barramento Compartilhado Token Ring Sem colis\u00f5es Com colis\u00f5es Sem colis\u00f5es Roteamento trivial Roteamento complexo Roteamento simples Caro (exponencial) Barato (linear) Barato (linear) Nas redes atuais, pode se dizer que o meio mais utilizado \u00e9 provido pela arquitetura Ethernet , que trata da comunica\u00e7\u00e3o entre n\u00f3s usando um barramento compartilhado , mesmo que este esteja por vezes escondido. Sobre este meio, s\u00e3o usados protocolos para, por exemplo, Controle de acesso ao meio Transmiss\u00e3o de mensagens Evitar e tratar colis\u00f5es As redes Ethernet, contudo, cobrem pequenas \u00e1reas e para se ter conversas mais \"abrangentes\", \u00e9 necess\u00e1rio que se conecte diversas destas redes. A conversa ent\u00e3o \u00e9 feita por meio de intermedi\u00e1rios, gateways que conectam duas ou mais redes, permitindo que mensagens de um interlocutor sejam roteadas para o outro, via tais intermedi\u00e1rios. Um exemplo interessante das quest\u00f5es ligadas \u00e0 manuten\u00e7\u00e3o da conversa entre dois pontos \u00e9 a decis\u00e3o sobre o uso de comuta\u00e7\u00e3o de pacotes ( packet switching ) ou de circuitos ( circuit switching ). Comuta\u00e7\u00e3o de pacotes Comuta\u00e7\u00e3o de circuito Cada pacote viaja independentemente Todo pacote viaja por caminho predefinido Lat\u00eancia vari\u00e1vel Lat\u00eancia mais constante Banda n\u00e3o reservada Banda reservada Banda n\u00e3o desperdi\u00e7ada Banda desperdi\u00e7ada Outro fator importante \u00e9 a unidade m\u00e1xima de transmiss\u00e3o ( maximum transmission unit , MTU), o tamanho m\u00e1ximo de um pacote em determinada rede. \u00c9 necess\u00e1rio entender que qualquer quantidade de dados maior que o MTU precisar\u00e1 ser dividida em m\u00faltiplos pacotes. Tamb\u00e9m \u00e9 importante perceber que redes s\u00e3o heterog\u00eaneas, e que o v\u00e1rios segmentos no caminho entre origem e destino podem ter MTU diferentes, levando \u00e0 fragmenta\u00e7\u00e3o de pacotes em tr\u00e2nsito e, possivelmente, entrega desordenada dos mesmos. Finalmente, h\u00e1 uma quest\u00e3o importante relativa \u00e0 confiabilidade na transmiss\u00e3o dos elementos da conversa, isto \u00e9, se a rede deve garantir ou n\u00e3o que algo \"dito\" por um interlocutor deve garantidamente ser \"ouvido\" pelo outro, ou se a mensagem pode ser perdida no meio. Felizmente boa parte da complexidade da resolu\u00e7\u00e3o destas quest\u00f5es \u00e9 abstra\u00edda do desenvolvedor dos sistemas distribu\u00eddos , isto \u00e9, voc\u00ea, lhe cabendo apenas a decis\u00e3o de qual protocolo utilizar. Nas redes atuais, a conversa em componentes ser\u00e1 feita, em algum n\u00edvel, por meio dos protocolos da arquitetura Internet .","title":"Canais e Protocolos"},{"location":"basics/#a-internet","text":"A Internet tem este nome por usar o protocolo de interconex\u00e3o de redes independentes, o internetworking protocol , ou IP. Para a aplica\u00e7\u00e3o usando o IP, todas as redes se comportam como uma \u00fanica e coerente rede, exceto por alguns detalhes. Os elementos que conectam as diversas redes s\u00e3o denominados roteadores e fazem um melhor esfor\u00e7o para encaminhar os pacotes de dados do remetente ao destinat\u00e1rio. 4 Se voc\u00ea se lembrar da pilha de protocolos de comunica\u00e7\u00e3o de refer\u00eancia OSI, lembrar\u00e1 que h\u00e1 uma organiza\u00e7\u00e3o em camadas em que cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel e serve de funda\u00e7\u00e3o para a funcionalidade da camada de cima, isto \u00e9, cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel de abstra\u00e7\u00e3o que serve de base para o n\u00edvel imediatamente superior: O protocolo de cada camada inclui cabe\u00e7alhos ( header ) e carga ( payload ) e o conjunto de cabe\u00e7alho + carga de uma camada \u00e9 considerado carga da camada inferior. Assim, embora tenha-se a impress\u00e3o de que cada camada conversa com a equivalente do outro lado da comunica\u00e7\u00e3o, na pr\u00e1tica, a comunica\u00e7\u00e3o desce e sobe a pilha. S\u00e3o sete as camadas: F\u00edsica: Bits Enlace: Frames/quadros; controle de fluxo; acesso ao meio. Rede: Datagramas/pacotes; roteamento Transporte: Controle de fluxo; fim a fim; confiabilidade; tcp e udp Sess\u00e3o: Streams/fluxos; conex\u00f5es l\u00f3gicas; restart; checkpoint; http, ssl Apresenta\u00e7\u00e3o: Objetos; json, xml; criptografia Aplica\u00e7\u00e3o: Aplica\u00e7\u00f5es; http, pop, ftp Embora o IP se refira estritamente ao protocolo da camada 3 da pilha, nos referimos \u00e0 pilha que usa este protocolo como a pilha IP. Comparada \u00e0 pilha OSI, a IP \u00e9 mais simples, como se v\u00ea na figura, pois as camadas 5 e 6 n\u00e3o est\u00e3o presentes na pilha IP e as funcionalidades correspondentes s\u00e3o implementadas na camada 7, de aplica\u00e7ao. Contudo, n\u00e3o tema! Estas funcionalidades podem se normalmente implementadas por meio de frameworks ou do middleware em uso. Alguns exemplos de tais funcionalidades s\u00e3o (De)Serializa\u00e7\u00e3o - convers\u00e3o de estruturas complexas, e.g., objetos e estruturas, em sequ\u00eancia de bytes. Nomeamento - identifica\u00e7\u00e3o de hosts Criptografia - oculta\u00e7\u00e3o dos dados trafegados Replica\u00e7\u00e3o - comunica\u00e7\u00e3o com m\u00faltiplos interlocutores Invoca\u00e7\u00e3o remota de procedimentos - abstra\u00e7\u00e3o de protocolos de comunica\u00e7\u00e3o A grande vantagem desta abordagem \u00e9 que se pode implementar exatamente e somente as funcionalidades desejadas. Este caracter\u00edstica \u00e9 conhecida como o argumento fim-a-fim no projeto de sistemas ; uma an\u00e1lise recente deste argumento foi feita aqui . Como usu\u00e1rios da pilha IP, temos que entender como a camada 3 funciona, mas dificilmente interagiremos com algo al\u00e9m da camada 4, a camada de transporte .","title":"A Internet"},{"location":"basics/#sockets","text":"Na pr\u00e1tica, para implementarmos a comunica\u00e7\u00e3o entre processos, usamos sockets . Para se definir um socket a partir de um host \u00e9 necess\u00e1rio identificar o outro fim da comunica\u00e7\u00e3o, isto \u00e9, o outro host , ou melhor, uma de suas interfaces de rede. Os sockets s\u00e3o ent\u00e3o a abstra\u00e7\u00e3o dos canais de comunica\u00e7\u00e3o, mas como dito antes, \u00e9 necess\u00e1rio definir tamb\u00e9m os protocolos usados por estes sockets. O primeiro protocolo \u00e9 o de endere\u00e7amento, que define qual pilha de protocolos usar, na camada 3. No caso da pilha IP, usa-se o protocolo AF_INET ou PF_INET. Escolhido o protocolo, cada interface tem um endere\u00e7o MAC, na camada 2, que a identifica entre as interfaces na mesma rede local, e cada interface tem um endere\u00e7o IPv4/IPv6 de 32/128 bits, que o indentifica entre todos os hosts na Internet. 5 Mas dentro de um host , podem haver diversas aplica\u00e7\u00f5es sendo executadas. Como identificar exatamente com qual se quer conversar? Isto \u00e9 feito pela defini\u00e7\u00e3o uma porta: Porta: inteiro de 16 bits Associadas a servi\u00e7os pela Internet Assigned Numbers Authority , IANA. Portas \"Bem conhecidas\": 0-1023 Portas Propriet\u00e1rias: 49151 Portas Din\u00e2micas: 65535 Tamb\u00e9m \u00e9 necess\u00e1rio definir o protocolo de transporte dos dados, na camada 4. Novamente, no caso da pilha IP, pode-se usar TCP ( SOCK_STREAM ) ou UDP ( SOCK_DGRAM ). A API usada para estabelecer a conversa via socket tem v\u00e1rias chamadas, que devem ser executadas na ordem certa no processo iniciando a conversa e naquele que aceita participar da mesma. Comecemos estudando o TCP.","title":"Sockets"},{"location":"basics/#tcp","text":"O fluxograma da cria\u00e7\u00e3o de um socket TCP \u00e9 apresentado na seguinte figura: stateDiagram-v2 Servidor --> Entrada/Sa\u00edda Cliente --> Entrada/Sa\u00edda Entrada/Sa\u00edda --> Encerramento state Servidor { ss: Cria socket sb: Associa porta sl: Escuta conex\u00f5es sa: Aceita conex\u00f5es ss --> sb sb --> sl sl --> sa } state Entrada/Sa\u00edda { leitura --> escrita escrita --> leitura } state Cliente { cs: Cria socket cc: Inicia conex\u00e3o cs --> cc } state Encerramento { sc: Fecha conex\u00e3o } Estabelecido o socket, o mesmo pode ser usado como um arquivo , isto \u00e9, lendo-se e escrevendo-se bytes. O que exatamente deve ser escrito e como o que \u00e9 lido deve ser interpretado \u00e9 o protocolo da camada 7, sua responsabilidade . Vejamos um exemplo do uso de sockets, em Python, descrito no arquivo server.py . 6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #server.py #!/usr/bin/python # This is server.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . bind (( host , port )) # Bind to the port s . listen ( 5 ) # Now wait for client connections. while True : c , addr = s . accept () # Establish connection with client. print ( 'Got connection from' , addr ) c . send ( 'Thank you for connecting' . encode ()) c . close () # Close the connection Para execut\u00e1-lo, execute o seguinte comando em um terminal. 1 python server.py Em outro terminal, execute um dos dois comandos a seguir. 7 1 telnet localhost 12345 1 netcat localhost 12345 No segundo terminal a mensagem Thank you for connecting ser\u00e1 impressa, enquanto no primeiro veremos algo como ('Got connection from', ('127.0.0.1', 57801)) O que est\u00e1 acontecendo aqui \u00e9 um processo criou um socket e ficou aguardando uma conex\u00e3o, usando o c\u00f3digo em Python. Tanto o telnet quando o netcat s\u00e3o programas gen\u00e9ricos para se conversar com outro processo usando TCP/IP. Aqui, estes programas simplesmente se conectaram e imprimiram o que quer que o primeiro processo lhes tenha enviado, assumindo que correspondia a uma string, o que neste caso \u00e9 correto. Simples, n\u00e3o \u00e9 mesmo? Duas observa\u00e7\u00f5es importantes a serem feitas aqui. A primeira \u00e9 que, em geral, denominamos o processo que fica aguardando a conex\u00e3o de servidor e o processo que se conecta de cliente . Isto por qu\u00ea, em geral, o servidor executa alguma tarefa, serve, o cliente, embora isto n\u00e3o seja necessariamente verdade. Por completude, vamos tamb\u00e9m escrever o c\u00f3digo do cliente, agora que voc\u00ea j\u00e1 sabe que o servidor funciona. Do lado cliente, estabelece-se uma conex\u00e3o apontando-se para onde est\u00e1 o servidor. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #client.py #!/usr/bin/python # This is client.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . connect (( host , port )) data = s . recv ( 1024 ) print ( data . decode ()) s . close () # Close the socket when done E para se executar o cliente, fa\u00e7a: 1 python client.py Observe que o socket.close() encerra a conex\u00e3o do lado de quem invoca. Na contraparte, invoca\u00e7\u00f5es a socket.recv() retornam com 0 bytes lidos. A t\u00edtulo de compara\u00e7\u00e3o, em Java, a cria\u00e7\u00e3o do socket do lado do servidor seria muito mais simples, consistindo apenas em: 1 Socket s = new ServerSocket ( port ); O cliente em Java tamb\u00e9m \u00e9 simplificado. 1 Socket s = new Socket ( hostname , port ); Exerc\u00edcio: M\u00faltiplos Pacotes Fa\u00e7amos agora uma modifica\u00e7\u00e3o no c\u00f3digo do servidor para que envie n\u00e3o uma, mas duas mensagens para o cliente. Isto \u00e9, modifique seu servidor assim 1 2 3 4 ... c . send ( 'Thank you for connecting' . encode ()) c . send ( 'Come back often' . encode ()) ... Agora execute novamente o cliente e veja o que acontece. Consegue explicar o fen\u00f4meno? Modifiquemos o cliente agora, para que tenha dois recv , assim. 1 2 3 4 5 6 7 8 ... print ( \"1\" ) data = s . recv ( 1024 ) print ( data . decode ()) print ( \"2\" ) data = s . recv ( 1024 ) print ( data . decode ()) ... E agora, o que acontece? A sa\u00edda \u00e9 como esperava? Como explica este fen\u00f4meno e como poderia corrig\u00ed-lo? Exerc\u00edcio: Ping-Pong Modifique cliente e servidor tal que o cliente envie uma mensagem passada na linha de comando ao servidor e fique esperando uma resposta, e tal que o servidor fique esperando uma mensagem e ent\u00e3o solicite ao operador que digite uma resposta e a envie para o cliente. O loop continua at\u00e9 que o usu\u00e1rio digite SAIR, e a conex\u00e3o seja encerrada. Terminal 1 Terminal 2 python server.py python client.py Esperando conex\u00e3o. conectando-se ao servidor Conectado Conectado Esperando mensagem Digite mensagem: lalala Mensagem enviada Mensagem recebida: lalala Esperando resposta Digite resposta: lelele Resposta enviada. Resposta recebida: lelele Digite mensagem: SAIR Desconectando. Conex\u00e3o encerrada. Esperando conex\u00e3o. Observe que para ler do teclado em Python 2 voc\u00ea deve usar x = raw_input () , enquanto que em Python 3 seria x = input () . Al\u00e9m disso, em Python 2, voc\u00ea deve remover as invoca\u00e7\u00f5es para encode e decode .","title":"TCP"},{"location":"basics/#udp","text":"No exemplo anterior, usamos o protocolo TCP (o padr\u00e3o da API). Caso quis\u00e9ssemos usar UDP, precisar\u00edamos nos atentar a alguns detalhes. A cria\u00e7\u00e3o do socket \u00e9 feita explicitando-se o uso de datagramas : s = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) Um servidor UDP n\u00e3o executa listen ou accept e, em Python, simplesmente executa data , addr = sock . recvfrom ( 4096 ) para receber o datagrama, onde data \u00e9 o conte\u00fado recebido e addr o endere\u00e7o de quem enviou o datagrama. Neste caso, um mesmo socket \u00e9 usado para manter comunica\u00e7\u00e3o com m\u00faltiplos interlocutores. Para enviar uma resposta a um interlocutor em espec\u00edfico, addr \u00e9 usado: sent = sock . sendto ( data , addr ) , onde sent \u00e9 a quantidade de bytes enviados. Al\u00e9m deste detalhe, \u00e9 importante manter em mente outras caracter\u00edsticas do UDP: falta de ordem falta de confiabilidade menos dados lidos que enviados. mais dados lidos que enviados (pode acontecer tamb\u00e9m no TCP) Com tantas dificuldades para se usar o UDP, fica a quest\u00e3o: para que serve UDP? Exerc\u00edcio: Ping-Pong UDP Modifique o c\u00f3digo do exerc\u00edcio Ping-Pong para usar UDP em vez de TCP na comunica\u00e7\u00e3o entre n\u00f3s. Execute m\u00faltiplos clientes ao mesmo tempo. Como o seu servidor lida com isso? Modifique-o para mandar um \"eco\" da mensagem recebida de volta ao remetente.","title":"UDP"},{"location":"basics/#ip-multicast","text":"Imagine que voc\u00ea tenha que enviar um stream de v\u00eddeo para um amigo mostrando como voc\u00ea est\u00e1 jogando o mais novo jogo da velha no mercado. Qual protocolo de transporte voc\u00ea usaria? TCP, provavelmente, j\u00e1 que garante a entrega ordenada dos pacotes do v\u00eddeo. Como voc\u00ea j\u00e1 sabe, o TCP envia confirma\u00e7\u00f5es de pacotes recebidos e usa uma janela deslizante para determinar quais pacotes reenviar, o que pode causar interrup\u00e7\u00f5es na execu\u00e7\u00e3o do v\u00eddeo. Al\u00e9m do mais, as pessoas provavelmente preferir\u00e3o perder alguns quadros que perder a sincronia com sua excitante partida. Parece que uma op\u00e7\u00e3o melhor seria ent\u00e3o usar UDP, correto? Imagine agora que os mesmos dados devam ser enviados para m\u00faltiplos destinat\u00e1rios (voc\u00ea est\u00e1 ficando famoso!) Com m\u00faltiplos destinat\u00e1rios, m\u00faltiplos controles precisariam ser mantidos no TCP, o que pode se tornar custoso; mais uma raz\u00e3o para usar UDP! Para terminar, lhe darei uma raz\u00e3o final: IP-Multicast! Multicast, em oposi\u00e7\u00e3o ao Unicast, \u00e9 a capacidade de enviar mensagens para um grupo de destinat\u00e1rios, em vez de apenas um. IP-Multicast \u00e9 uma implementa\u00e7\u00e3o desta ideia, usando umaa configura\u00e7\u00e3o espec\u00edfica do UDP, associada a recursos dos comutadores de rede, para otimizar o envio dos mesmos dados a m\u00faltiplos destinat\u00e1rios. Grupos s\u00e3o identificados por endere\u00e7os IP especiais, conhecidos como Classe D (224.0.0.0-239.255.255.255), e propagados pela rede. A seguinte tabela descreve os usos das sub-faixas de endere\u00e7os. 8 Endere\u00e7o Uso 224.0.0.0-224.0.0.255 Multicast local - Usado por protocolos L2, como EIGRP e OSPF 224.0.1.0-224.0.1.255 Multicast roteaddo - Usado por protocolos L3 232.0.0.0-232.255.255.255 Source Specific Multicast - Receptores definem fontes confi\u00e1veis 233.0.0.0-233.255.255.255 Reservado para detentores Autonomous Systems 239.0.0.0-239.255.255.255 Reservado para IANA Resto Uso geral Quando um pacote \u00e9 enviado para o endere\u00e7o do grupo, todos os membros do grupo recebem tal mensagem. Melhor dizendo, todos os membros podem receber a mensagem, mas como estamos falando de UDP, \u00e9 poss\u00edvel que alguns n\u00e3o recebam . Al\u00e9m disso, n\u00e3o h\u00e1 garantia qualquer sobre a ordem de recep\u00e7\u00e3o das mensagens . Apenas refor\u00e7ando, IP-Multicast s\u00f3 funciona com UDP, pois lidar com retransmiss\u00f5es em um grupo grande levaria a um estado imenso sendo mantido na origem dos dados. Outro ponto importante \u00e9 que pelo podencial desestabilizador do IP-Multicast, ele \u00e9 normalemente limitado \u00e0 pequenas se\u00e7\u00f5es das redes. Mas experimentemos com esta tecnologia na pr\u00e1tica. Criemos um programa que criar Socket UDP , associa-o a um grupo , e recebe pacotes destinados ao grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // MReceiver.java import java.io.* ; import java.net.* ; public class MReceiver { public static void main ( String [] args ) { byte [] inBuf = new byte [ 256 ] ; try { MulticastSocket socket = new MulticastSocket ( 8888 ); InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); socket . joinGroup ( address ); while ( true ) { DatagramPacket inPacket = new DatagramPacket ( inBuf , inBuf . length ); socket . receive ( inPacket ); String msg = new String ( inBuf , 0 , inPacket . getLength ()); System . out . println ( \"From \" + inPacket . getAddress () + \" Msg : \" + msg ); } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Instancie m\u00faltiplos processos deste, na mesma m\u00e1quina e em m\u00e1quinas distintas. Agora criemos um programa que envia pacotes para o dito grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // MSender.java import java.io.* ; import java.net.* ; public class MSender { public static void main ( String [] args ) { byte [] outBuf ; final int PORT = 8888 ; try { DatagramSocket socket = new DatagramSocket (); long counter = 0 ; InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); while ( true ) { counter ++ ; outBuf = ( \"Multicast numero \" + counter + \" \" + address ). getBytes (); DatagramPacket outPacket = new DatagramPacket ( outBuf , outBuf . length , address , PORT ); socket . send ( outPacket ); try { Thread . sleep ( 500 ); } catch ( InterruptedException ie ) {} } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Observe como a mesma mensagem \u00e9 recebida pelos v\u00e1rios membros e que como diferentes fontes tem seus pacotes recebidos. A t\u00edtulo de curiosidade, IP-Multicast tamb\u00e9m est\u00e1 presente em IPv6, mas com algumas pequenas diferen\u00e7as IP-Multicast em IPv6 9 In IPv6, the left-most bits of an address are used to determine its type. For a multicast address, the first 8 bits are all ones, i.e. FF00::/8. Further, bit 113-116 represent the scope of the address, which can be either one of the following 4: Global, Site-local, Link-local, Node-local. In addition to unicast and multicast, IPv6 also supports anycast, in which a packet can be sent to any member of the group, but need not be sent to all members.'' Exerc\u00edcio: IP-Multicast Implemente e teste o seguinte receiver , colocando v\u00e1rias inst\u00e2ncias para executar em m\u00faltiplos terminais, ao mesmo tempo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import socket import struct MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) sock . bind (( '' , MCAST_PORT )) mreq = struct . pack ( \"=4sl\" , socket . inet_aton ( MCAST_GRP ), socket . INADDR_ANY ) #4 bytes (4s) seguidos de um long (l), usando ordem nativa (=) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_ADD_MEMBERSHIP , mreq ) while True : print ( sock . recv ( 10240 ) . decode ()) Implemente e teste o seguinte sender . 1 2 3 4 5 6 7 8 import socket MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_MULTICAST_TTL , 2 ) sock . sendto ( input () . encode (), ( MCAST_GRP , MCAST_PORT ))","title":"IP-Multicast"},{"location":"basics/#concorrencia","text":"\u00c9 imposs\u00edvel pensar em sistemas distribu\u00eddos sem pensar em concorr\u00eancia na forma de m\u00faltiplos processos executando (normalmente) em hosts distintos e em termos de m\u00faltiplos threads nos processos. Os exemplos apresentados at\u00e9 agora, consistem todos em um processo cliente requisitando a\u00e7\u00f5es de algum processo servidor. Apesar disso, a intera\u00e7\u00e3o entre tais processos aconteceu sempre de forma sincronizada, lock-step , em que o cliente requisitava o servi\u00e7o e ficava bloqueado esperando a resposta do servidor para ent\u00e3o prosseguir em seu processamento, e o servidor fica bloqueado esperando requisi\u00e7\u00f5es que atende e ent\u00e3o volta a dormir. Este cen\u00e1rio, apresentado na figura a seguir, mostra que apesar do uso de processadores distintos e da concorr\u00eancia na execu\u00e7\u00e3o dos processos, temos um baixo grau de efetivo paralelismo; a requisi\u00e7\u00e3o (2) s\u00f3 \u00e9 processada depois que a resposta (1) \u00e9 enviada. sequenceDiagram activate Cliente note left of Cliente: Ativo gerando requisi\u00e7\u00e3o note right of Servidor: Inativo esperando requisi\u00e7\u00e3o activate Cliente2 note right of Cliente2: Ativo gerando requisi\u00e7\u00e3o Cliente->>+Servidor: Request (1) deactivate Cliente note left of Cliente: Inativo esperando resposta Cliente2-->>Servidor: Request (2) deactivate Cliente2 note right of Cliente2: Inativo esperando resposta note right of Servidor: Ativo processando requisi\u00e7\u00e3o (1) Servidor->>-Cliente: Response (1) activate Cliente activate Servidor note left of Cliente: Ativo processando resposta (1) note right of Servidor: Ativo processando requisi\u00e7\u00e3o (2) Servidor-->>Cliente2: Response (2) deactivate Servidor activate Cliente2 note right of Servidor: Inativo esperando requisi\u00e7\u00e3o note right of Cliente2: Ativo processando resposta (2) deactivate Cliente deactivate Cliente2 Este modelo de sincroniza\u00e7\u00e3o entre as partes comunicantes \u00e9 um exemplo de E/S bloqueante . O principal ponto positivo desta estrat\u00e9gia \u00e9 a simplicidade do c\u00f3digo e o principal ponto negativo \u00e9 a limita\u00e7\u00e3o do paralelismo no uso de recursos, uma das raz\u00f5es de ser da computa\u00e7\u00e3o distribu\u00edda. Para usarmos melhor os recursos dispon\u00edveis, tanto do lado dos clientes quanto servidores, temos ent\u00e3o que pensar em termos de eventos sendo disparados entre os componentes, que devem ser tratados assim que recebidos ou t\u00e3o logo haja recursos para faz\u00ea-lo. Estes eventos correspondem tanto a requisi\u00e7\u00f5es quanto a respostas (efetivamente tornando dif\u00edcil a distin\u00e7\u00e3o). No modelo bloqueante, quando um evento \u00e9 disparado (no exemplo, a requisi\u00e7\u00e3o), o sistema fica bloqueado at\u00e9 que um evento espec\u00edfico seja observado (no exemplo, a chegada da resposta). Sempre que poss\u00edvel, um componente n\u00e3o deve ficar esperando por eventos em espec\u00edfico, aproveitando a chance executar outras tarefas; quando eventos s\u00e3o recebidos, s\u00e3o ent\u00e3o atendidos. Esta \u00e9 a forma de fazer E/S ass\u00edncrona . Dada que processos interagem com a rede usando sockets, cuja interface mais simples para opera\u00e7\u00f5es de leitura \u00e9 bloqueante, neste curso n\u00e3o falaremos especificamene sobre E/S ass\u00edncrono 10 e por isso, para vermos como aumentar a concorr\u00eancia no sistema, \u00e9 necess\u00e1rio falar de multithreading e as v\u00e1rias formas em que aparecem nos sistemas. H\u00e1 duas raz\u00f5es claras para estudarmos multithreading . A primeira, de ordem pr\u00e1tica, \u00e9 a discutida acima: permitir o desenvolvimento de componentes que utilizem \"melhormente\" os recursos em um host. A segunda, did\u00e1tica, \u00e9 o fato que muitos dos problemas que aparecem em programa\u00e7\u00e3o multithread , aparecem em programa\u00e7\u00e3o multi-processo (como nos sistemas distribu\u00eddos), apenas em um grau de complexidade maior. Para relembrar, h\u00e1 v\u00e1rias diferen\u00e7as entre threads e processos, mas a abstra\u00e7\u00e3o \u00e9 essencialmente a mesma: Processo Thread Defini\u00e7\u00e3o Inst\u00e2ncia de um programa \"Processo leve\" Fun\u00e7\u00e3o de entrada main fun\u00e7\u00e3o \"qualquer\" Compartilhamento de c\u00f3digo e dados Privado ao processo Compartilhado pelos threads Estado C\u00f3digo, Stack, Heap, descritores (e.g, file descriptors), controle de acesso Stack, vari\u00e1veis locais Comunica\u00e7\u00e3o IPC ( Inter Process Communication ): sockets, FIFO, mem\u00f3ria compartilhada, etc IPC, mutex, vari\u00e1veis de condi\u00e7\u00e3o, sem\u00e1foros, etc N\u00edvel da implementa\u00e7\u00e3o Sistema operacional Diferentes implementa\u00e7\u00f5es API Posix, C++, Java, ... Bloqueio Mudan\u00e7a de contexto para outro thread mesmo sem terminar quantum Mudan\u00e7a de contexto para outro thread do mesmo processo Tempo de cria\u00e7\u00e3o, termina\u00e7\u00e3o e mudan\u00e7a de contexto Demora mais Demora menos Vejamos como o uso de m\u00faltiplos threads podem melhorar o desenvolvimento de sistemas distribu\u00eddos na pr\u00e1tica. Considere os exemplos de clientes e servidores vistos anteriormente . Imagine que em vez do servi\u00e7o simples feito no exemplo, o servidor retorne uma p\u00e1gina Web. Detalhes do protocolo seguido por navegadores e servidores ser\u00e3o vistos mais tarde. Por agora, considere apenas que uma requisi\u00e7\u00e3o GET arquivo.html ser\u00e1 enviada para o servidor que ler\u00e1 o arquivo especificado do sistema de arquivos; como voc\u00ea sabe, ler um arquivo \u00e9 uma opera\u00e7\u00e3o lenta e que n\u00e3o requer CPU.","title":"Concorr\u00eancia"},{"location":"basics/#cliente","text":"Do ponto de vista do cliente, a vantagem do uso de m\u00faltiplos threads s\u00e3o claras: permite lidar com v\u00e1rias tarefas concorrentemente , por exemplo solicitar CSS, HTML e imagens concorrentemente, escondendo lat\u00eancia das v\u00e1rias opera\u00e7\u00f5es, e permite organizar c\u00f3digo em blocos/m\u00f3dulos. Se voc\u00ea usar o console de desenvolvimento do navegador, ver\u00e1 como m\u00faltiplos arquivos s\u00e3o baixados em paralelo quando acessa um s\u00edtio. A figura a seguir mostra a carga do s\u00edtio da Facom . O primeiro arquivo, index.html \u00e9 baixado individualmente, mas uma vez que isso acontece e s\u00e3o determinados quais os demais arquivos necess\u00e1rios, requisi\u00e7\u00f5es concorrentes s\u00e3o disparadas, minimizando o tempo total da opera\u00e7\u00e3o. Como outros exemplos, considere um formul\u00e1rio online em que a valida\u00e7\u00e3o de um campo \u00e9 executada enquanto o campo seguinte est\u00e1 sendo preenchido, ou um servi\u00e7o de email em que arquivos s\u00e3o carregados enquanto a mensagem \u00e9 confeccionada.","title":"Cliente"},{"location":"basics/#servidor","text":"Do lado dos servidores h\u00e1 diversas possibilidades de uso de threads para aumentar o paralelismo no processamento de requisi\u00e7\u00f5es, melhor utilizando recursos dispon\u00edveis e melhorando a experi\u00eancia do usu\u00e1rio.","title":"Servidor"},{"location":"basics/#single-threaded","text":"A estrat\u00e9gia mais simples de se implementar \u00e9 a de usar apenas um thread, como temos feito at\u00e9 agora. Considere um servidor Web com esta esta caracter\u00edstica; o fluxo no tratamento de uma requisi\u00e7\u00e3o \u00e9 exemplificado na pela figura a seguir: O servidor \u00e9 iniciado, criando o socket e invocando accept o cliente envia a requisi\u00e7\u00e3o para o servidor o servidor aceita a conex\u00e3o em seu \u00fanico thread uma tarefa \u00e9 gerada para ler o arquivo o arquivo \u00e9 lido, de forma bloqueante, e uma resposta para o cliente \u00e9 preparada a resposta \u00e9 enviada para o cliente, de forma bloqueante a requisi\u00e7\u00e3o \u00e9 descartada o thread do servidor volta a esperar uma nova requisi\u00e7\u00e3o Se novas requisi\u00e7\u00f5es forem recebidas enquanto o servidor est\u00e1 executando os passos de 2 a 6, sejam requisi\u00e7\u00f5es paralelas do mesmo cliente ou de um outro cliente, estas ficar\u00e3o bloqueadas. A espera ser\u00e1 maior quanto mais o servidor demorar para atender \u00e0 primeira requisi\u00e7\u00e3o, por exemplo, se precisar consultar um banco de dados ou carregar o arquivo requisitado do disco. Para evitar que isto ocorra, o servidor pode usar mais threads.","title":"Single-threaded"},{"location":"basics/#thread-per-request","text":"O servidor pode criar um novo thread para cada nova requisi\u00e7\u00e3o, permitindo que m\u00faltiplas requisi\u00e7\u00f5es sejam tratadas concorrentemente. Isto \u00e9, mesmo que um thread do servidor seja bloqueado por muito tempo, somente um cliente ter\u00e1 sua resposta atrasada (excluindo-se necessidades de coordena\u00e7\u00e3o entre m\u00faltiplos threads) e outros clientes podem continuar sendo atendidos normalmente, como mostrado na figura a seguir. Lembre-se, entretanto, que o n\u00famero de threads que se pode criar em um SO \u00e9 limitado, pois cada thread usa recursos do SO. Al\u00e9m disso, a cria\u00e7\u00e3o e destrui\u00e7\u00e3o de threads \u00e9 cara pois \u00e9 feita por meio de uma chamada de sistema, pelo kernel, e portanto implica em alternar entre modo usu\u00e1rio e modo protegido. Se poss\u00edvel, devemos evitar a cria\u00e7\u00e3o de novos threads em aplica\u00e7\u00f5es com requisitos de desempenho, e reclicl\u00e1-los pode ser uma boa estrat\u00e9gia.","title":"Thread per request"},{"location":"basics/#thread-pool","text":"Para reciclarmos threads, podemos criar pools , um balde de threads que s\u00e3o usados quando necess\u00e1rio e devolvidos para o balde quando n\u00e3o mais. No cerne desta abordagem, junto com o pool de threads, fica uma fila bloquenante na qual tarefas s\u00e3o inseridas e de onde os threads tentam retir\u00e1-las. Como a fila \u00e9 bloqueante, se estiver vazia, o thread \u00e9 bloqueado e para de consumir recursos. T\u00e3o logo nova tarefa seja inserida, a fila acorda os threads para que a processem. Para garantir a corretude no processamento, a fila deve ser thread-safe , isto \u00e9, que se mantem correta mesmo quando m\u00faltiplos threads operam nela tanto para inserir quanto remover tarefas. Na figura, um thread principal \u00e9 encarregado de receber as requisi\u00e7\u00f5es e colocar na fila bloqueante; se a fila fica cheia, o thread principal fica bloqueado esperando por espa\u00e7o, fazendo com que novas conex\u00f5es tenham que esperar. Os threads do pool removem uma tarefa da fila, a tratam e, ao final do atendimento, pegam nova requisi\u00e7\u00e3o na fila, em um loop infinito; requisi\u00e7\u00f5es que demandam menor processamento liberam o thread mais rapidamente para que pegue nova tarefa. Se todas as tarefas s\u00e3o pequenas, os threds ficar\u00e3o bloqueados por muito tempo. Se todas s\u00e3o grandes, as tarefas se acumular\u00e3o na fila. Por isso \u00e9 importante dimensionar bem o tamanho to pool , ou mesmo torn\u00e1-lo din\u00e2mico para que use menos recursos (threads) quando n\u00e3o necess\u00e1rio e n\u00e3o deixe tarefas pendentes por muito tempo. Se considerarmos que cada tarefa na verdade tem v\u00e1rias partes, \u00e9 poss\u00edvel refinar mais este modelo, quebrando o processamento em v\u00e1rios pools.","title":"Thread pool"},{"location":"basics/#estagios","text":"Na arquitetura baseada em est\u00e1gios, e.g., Staged Event-Driven Architecture , SEDA, cada est\u00e1gio , cada est\u00e1gio \u00e9 respons\u00e1vel por processar uma parte da tarefa, passada adiante at\u00e9 que seja completada. 11 Uma caracter\u00edstica importante deste modelo \u00e9 que cada est\u00e1gio pode ser escalado individualmente de acordo com a demanda uma vez que cada est\u00e1gio tem seu pr\u00f3prio pool . Por exemplo, se um est\u00e1gio faz algum c\u00e1lculo leve, ent\u00e3o poucos threads s\u00e3o necess\u00e1rios ao mesmo. J\u00e1 um est\u00e1gio que precise efetuar E/S talvez precise mais threads , uma vez que estes ficam bloqueandos enquanto a opera\u00e7\u00e3o \u00e9 executada. 12","title":"Est\u00e1gios"},{"location":"basics/#desafios","text":"Embora a ideia de usar m\u00faltiplos threads seja melhorar desempenho e experi\u00eancia do usu\u00e1rio, faz\u00ea-lo efetivamente \u00e9 n\u00e3o trivial. Vejamos por exemplo o problema do falso compartilhamento; considere o seguinte pseudo-c\u00f3digo: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void threadfunction ( int32 * exclusivo ) { while ( true ) { int32 local = * exclusivo ; local = processa ( local ); * exclusivo = local ; } } ... int32 X ; int32 Y ; thread1 = tread_new ( threadfunction , & X ); thread2 = tread_new ( threadfunction , & Y ); ... Cada um dos threads criados acessa exclusivamente uma das vari\u00e1veis. Logo, n\u00e3o h\u00e1 interfer\u00eancia entre as threads e se cada uma for colocada em um processador diferente, executar\u00e3o no m\u00e1ximo de seu potencial, correto? N\u00e3o exatamente, pois mesmo este c\u00f3digo simpl\u00edssimo podemos sofrer de falso compartilhamento . Isto acontece, por exemplo, se cada linha da cache do sistema onde este programa executa tiver 8 ou mais bytes de comprimento. Como tanto X quanto Y no programa tem 4 bytes, as duas vari\u00e1veis poder\u00e3o ficar na mesma linha da cache e toda vez que uma thread modificar uma vari\u00e1vel a cache da outra ser\u00e1 invalidada para leitura. Para que isto n\u00e3o ocorra, \u00e9 preciso se certificar que as vari\u00e1veis fiquem em linhas diferentes da cache; no exemplo, poderia-se definir X e Y como vetores do tamanho da linha da cache e usar efetivamente apenas a primeira posi\u00e7\u00e3o de cada vetor. Se o compartilhamento for real, por exemplo se ambos os threads usarem a vari\u00e1vel X, ent\u00e3o o problema n\u00e3o ser\u00e1 t\u00e3o facilmente resolv\u00edvel. Neste caso, poder-se-ia definir afinidade entre threads, isto \u00e9, notar quais threads compartilham estado de forma que threads afins sejam colocados nos mesmos processadores e compartilhem as mesmas mem\u00f3rias. Isto torna muito mais f\u00e1cil e eficiente o controle de concorr\u00eancia, do ponto de vista do SO e hardware. Multiprograma\u00e7\u00e3o Fazer esta divis\u00e3o pode ser complicado pois a rela\u00e7\u00e3o de compartilhamento entre threads pode ser complexa em fun\u00e7\u00e3o da tarefa sendo resolvida, por exemplo, se diferentes threads compartilharem diferentes vari\u00e1veis uns com os. Ainda que que uma configura\u00e7\u00e3o \u00f3tima em termos de afinidade exista, encontr\u00e1-la pode ser custo. Ainda assim, precisamos lidar com estado compartilhado e enfrentar condi\u00e7\u00f5es de corrida de forma a n\u00e3o levar a inconsist\u00eancias na executa\u00e7\u00e3o de tarefas, nos referindo a inconsist\u00eancia aqui como qualquer desvio no comportamento do programa daquilo que foi especificado pelo desenvolvedor. Para isso, usamos as primitivas de controle de concorr\u00eancia que estudaram em SO, que tamb\u00e9m tem seus problemas em potencial, como deadlocks e inani\u00e7\u00e3o . Veja o seguinte v\u00eddeo para uma an\u00e1lise de diversos pontos importantes no uso de multithreads.","title":"Desafios"},{"location":"basics/#estado","text":"A quest\u00e3o das regi\u00f5es cr\u00edticas est\u00e1 intimamente relacionada \u00e0 quest\u00e3o da manuten\u00e7\u00e3o de estado nos servidores. Quanto a este respeito, podemos classificar servidores como stateful e stateless , dois termos que ouvir\u00e3o frequentemente enquanto trabalhando com SD. O \"state\" nos dois nomes se refere ao estado mantido por um servi\u00e7o para atender a requisi\u00e7\u00f5es. Caso mantenha estado, por exemplo informando em quais arquivos o cliente est\u00e1 interessado, fica mais f\u00e1cil para o servidor continuar o trabalho feito em requisi\u00e7\u00f5es anteriores. Imagine por exemplo que um cliente esteja acessando linhas em um banco de dados, de forma paginada: a cada requisi\u00e7\u00e3o, o cliente recebe \\(n\\) novas linhas para processar e, quando estiver pronto, requisite \\(n\\) novas linhas. Imagine qu\u00e3o infeficiente seria se o servidor seguisse o seguinte fluxo: receba requisi\u00e7\u00e3o informando a \u00faltima linha lida recalcule todas as respostas para consulta salte at\u00e9 a linha informada pelo cliente retorne as pr\u00f3ximas \\(n\\) linhas para o cliente feche o resultado da consulta. Se em vez disso o servidor mantiver um mapa com consultas recentes, em que a chave seja algum identificador do cliente e o valor uma vis\u00e3o dos resultados; a cada nova requisi\u00e7\u00e3o, basta o servidor resgatar a vis\u00e3o usando o identificador do cliente e selecionar as seguintes \\(n\\) entradas da vis\u00e3o. Manter o mapa como estado acelera o processamento e melhora a experi\u00eancia do usu\u00e1rio, neste caso. Por outro lado, considere que m\u00faltiplos clientes fazem consultas concorrentemente: quanto recurso seria necess\u00e1rio para que o servidor mantenha a vis\u00e3o de todos os clientes? Tamb\u00e9m a complexidade do servidor aumenta. Considere as algumas de muitas perguntas poss\u00edveis neste cen\u00e1rio: Como o servidor mant\u00e9m as respostas a novas requisi\u00e7\u00f5es consistentes com as respostas anteriores? E se linhas s\u00e3o removidas ou inseridas no banco de dados? Se m\u00faltiplos servidores existem, como compartilhar os estado entre os mesmos? Se o cliente resolva n\u00e3o fazer mais requisi\u00e7\u00f5es, por exemplo por ter encontrado o que procurava, por quanto tempo o servidor deve manter a vis\u00e3o aberta? Voc\u00ea j\u00e1 deve ter adivinhado que no primeiro exemplo temos um servidor stateless e no segundo um stateful , e percebido que cada um tem suas vantagens e desvantagens. Vejamos mais algumas.","title":"Estado"},{"location":"basics/#sessao","text":"Essencialmente, o servidor stateless n\u00e3o mantem informa\u00e7\u00e3o sobre a sess\u00e3o do cliente e requer que a cada nova requisi\u00e7\u00e3o, quaisquer informa\u00e7\u00f5es necess\u00e1rias para realizar a tarefa requisitada sejam novamente fornecidas ao servidor. No caso stateful , o servidor pode se lembrar, como no exemplo anterior, at\u00e9 onde o trabalho j\u00e1 foi executado, quais arquivos o cliente manipulou (e mant\u00ea-los abertos), qual o endere\u00e7o o cliente e enviar-lhe notifica\u00e7\u00f5es importantes (e.g., \"Novo dado inserido!\").","title":"Sess\u00e3o"},{"location":"basics/#falhas_1","text":"Enquanto servidores stateful obviamente levam a melhor desempenho no happy path (contanto que recursos suficientes sejam providos), no caso de falhas, servi\u00e7os stateless tendem a voltar ao ar mais rapidamente, uma vez que n\u00e3o h\u00e1 estado que precise ser recuperado. Pela mesma raz\u00e3o, clientes que percebem que um servidor falhou podem rapidamente se dirigir a outros servidores e continuar suas requisi\u00e7\u00f5es de onde estavam, uma vez que s\u00e3o detentores de toda a informa\u00e7\u00e3o necess\u00e1ria para o pr\u00f3ximo passo do processamento. Lidar com falhas tamb\u00e9m introduz outro requisito aos servidores: mem\u00f3ria est\u00e1vel. Para que possa o recuperar o estado anterior \u00e0 falha, o servidor precisa colocar o estado em algum lugar que independa do processo para se manter, por exemplo, nvRAM , SSD ou spindles . A perda deste estado implicaria na incapacidade de prover o servi\u00e7o corretamente. Um projeto stateless n\u00e3o depende deste estado e por isso pode ser mais rapidamente recuperado, replicado ou substitu\u00eddo.","title":"Falhas"},{"location":"basics/#stateless-x-stateful","text":"N\u00e3o surpreendentemente, a resposta para \"qual abordagem \u00e9 melhor, stateful ou stateless ?\" \u00e9 depende . Ambos as op\u00e7\u00f5es tem suas vantagens e desvantagens e para algums servi\u00e7os apenas uma op\u00e7\u00e3o ser\u00e1 vi\u00e1vel. Se seu servi\u00e7o precisa manter estado (um SGBD, por exemplo), ele ter\u00e1 que manter estado, mesmo que n\u00e3o sobre clientes. Veja um pequeno comparativo das caracter\u00edsticas das duas abordagens. Stateless Stateful Resultado depende da entrada Depende do hist\u00f3rico de entradas Qualquer servidor pode atender Mesmo servidor deve atender N\u00e3o promete notificar o cliente Assina contrato com o cliente Repete opera\u00e7\u00f5es Aproveita resultados anteriores N\u00e3o fica inconsistente com rela\u00e7\u00e3o ao cliente Pode ficar inconsistente se perder estado ou conex\u00e3o feita com outro servidor re-autentica\u00e7\u00e3o (mesmo que simplficada) a cada requisi\u00e7\u00e3o Autentica no come\u00e7o da sess\u00e3o","title":"Stateless x Stateful"},{"location":"basics/#multithread-na-pratica","text":"","title":"Multithread na pr\u00e1tica"},{"location":"basics/#posix","text":"POSIX Threads ou PThreads, s\u00e3o uma defini\u00e7\u00e3o aberta de como threads devem funcionar em sistemas operacionais. V\u00e1rias implementa\u00e7\u00f5es desta especifica\u00e7\u00e3o est\u00e3o dispon\u00edveis tanto para sistemas Unix, compat\u00edveis com especifi\u00e7\u00f5es POSIX, mas tamb\u00e9m para Windows, via subsistemas. Al\u00e9m disso, mesmo implementa\u00e7\u00f5es n\u00e3o POSIX tem funcionalidade equivalentes e, por este motivo, entender POSIX servir\u00e1 de base para entender quaisquer API para programa\u00e7\u00e3o multi-threaded . Para se definir um thread , \u00e9 necess\u00e1rio definir uma fun\u00e7\u00e3o de entrada, que ser\u00e1 para o thread como a fun\u00e7\u00e3o main \u00e9 para o processo em si. No exemplo a seguir a fun\u00e7\u00e3o foi definida com retorno void * e com \u00fanico par\u00e2metro tambem void * ; esta \u00e9 uma obrigatoriedade para fun\u00e7\u00f5es de entrata PThread. Observe contudo que void * pode ser tratado como um blob para mascarar outros tipos de dado, por exemplo um vetor, um enumera\u00e7\u00e3o ou uma struct . 1 2 3 4 5 6 7 8 9 10 11 #include <stdio.h> #include <stdlib.h> #include <pthread.h> int thread_count ; void * hello ( void * rank ) { long my_rank = ( long ) rank ; printf ( \"Hello from thread %ld of %d \\n \" , my_rank , thread_count ); return NULL ; } Um thread \u00e9 criado pela fun\u00e7\u00e3o pthread_create , que coloca em um pthread_t um handle para o thread . A fun\u00e7\u00e3o recebe como par\u00e2metros op\u00e7\u00f5es para configura\u00e7\u00e3o, a fun\u00e7\u00e3o de entrada, e o par\u00e2metro do tipo void * . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int main ( int argc , char * argv []) { long thread ; pthread_t * thread_handles ; if ( argc < 2 ) { printf ( \"usage: %s <number of threads>\" , argv [ 0 ]); return 1 ; } thread_count = strtol ( argv [ 1 ], NULL , 10 ); thread_handles = malloc ( thread_count * sizeof ( pthread_t )); for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_create ( & thread_handles [ thread ], NULL , hello , ( void * ) thread ); printf ( \"Hello from the main thread \\n \" ); O handle do thread deve ser alocado previamente \u00e0 fun\u00e7\u00e3o de cria\u00e7\u00e3o e liberado ap\u00f3s o fim da execu\u00e7\u00e3o do thread . \u00c9 poss\u00edvel esperar pelo fim da execu\u00e7\u00e3o usando o pthread_join , que recebe como par\u00e2metro o handle do thread e um ponteiro para onde o resultado da fun\u00e7\u00e3o de entrada deve ser colocado, do tipo void ** . 1 2 3 4 for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_join ( thread_handles [ thread ], NULL ); free ( thread_handles ); Para executar um programa PThread, compile com 1 gcc -pthread teste.c -o teste e execute com 1 ./teste 5 e observe que a sa\u00edda das threads \u00e9 ordenada . Agora experimente 1 ./teste 200 Observe que a sa\u00edda \u00e9 desordenada (pode ser necess\u00e1rio executar m\u00faltiplas vezes ou aumentar de 200 para, digamos, 1000 para observar a desordem. Isto acontece porqu\u00ea a execu\u00e7\u00e3o das threads independe da ordem de cria\u00e7\u00e3o. De fato, usando PThreads, temos pouco controle sobre os threads que criamos. Mas isto n\u00e3o quer dizer que estamos \"\u00f3rf\u00e3os\" de API; v\u00e1rias outras opera\u00e7\u00f5es podem ser executadas, e podem ser encontradas a partir do manual de pthread_create . Alguns exemplos interessantes: pthread_tryjoin - espera thread terminar pthread_exit - termina a thread e retorna resultado An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function's return value serves as the thread's exit status. Manual de pthread_exit . pthread_attr_setaffinity_np - ajusta afinidade dos threads.","title":"POSIX"},{"location":"basics/#python","text":"Em Python, como seria de se esperar, h\u00e1 v\u00e1rias formas de se trabalhar com threads . O exemplo a seguir usa o pacote thread e \u00e9 essencialmente um env\u00f3lucro POSIX. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/usr/bin/python import thread import time # Define a function for the thread def print_time ( threadName , delay ): count = 0 while count < 5 : time . sleep ( delay ) count += 1 print \" %s : %s \" % ( threadName , time . ctime ( time . time ()) ) # Create two threads as follows try : thread . start_new_thread ( print_time , ( \"Thread-1\" , 2 , ) ) thread . start_new_thread ( print_time , ( \"Thread-2\" , 4 , ) ) except : print \"Error: unable to start thread\" while True : pass J\u00e1 o pr\u00f3ximo exemplo usa o pacote threading e uma abordagem orientada a objetos. Observe que h\u00e1 momentos distintos no ciclo de vida do thread em que acontece a cria\u00e7\u00e3o e o in\u00edcio da execu\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/usr/bin/python import threading import time exitFlag = 0 class myThread ( threading . Thread ): def __init__ ( self , threadID , name , counter ): threading . Thread . __init__ ( self ) self . threadID = threadID self . name = name self . counter = counter def run ( self ): print \"Starting \" + self . name print_time ( self . name , self . counter , 5 ) print \"Exiting \" + self . name def print_time ( threadName , counter , delay ): while counter : if exitFlag : threadName . exit () time . sleep ( delay ) print \" %s : %s \" % ( threadName , time . ctime ( time . time ())) counter -= 1 # Create new threads thread1 = myThread ( 1 , \"Thread-1\" , 1 ) thread2 = myThread ( 2 , \"Thread-2\" , 2 ) # Start new Threads thread1 . start () thread2 . start () print \"Exiting Main Thread\" Uma consequ\u00eancia desta divis\u00e3o \u00e9 que um mesmo objeto do tipo Thread pode ser reciclado e executado v\u00e1rias vezes. Leia mais Threads em Python","title":"Python"},{"location":"basics/#java","text":"Outro exemplo importante de API para multithreading \u00e9 a Java. Em Java, h\u00e1 essencialmente duas formas de se conseguir concorr\u00eancia. A primeira \u00e9 via inst\u00e2ncias expl\u00edcitas da classe Thread e, a segunda, via abstra\u00e7\u00f5es de mais alto n\u00edvel, os Executors . Java tamb\u00e9m prov\u00ea diversas estruturas para comunica\u00e7\u00e3o e coordena\u00e7\u00e3o de threads no pacote java.util.concurrent . Aqui nos focaremos em aspectos b\u00e1sicos de concorr\u00eancia na linguagem, mas esteja ciente de que a mesma \u00e9 muito rica neste t\u00f3pico e uma \u00f3tima documenta\u00e7\u00e3o \u00e9 dispobinilizada pela pr\u00f3pria Oracle . H\u00e1 duas formas b\u00e1sicas de definir um novo thread em Java, via extens\u00e3o da classe Thread , como no primeiro exemplo, ou ou via implementa\u00e7\u00e3o da interface Runnable , como no segundo, a seguir. Thread 1 2 3 4 5 6 7 8 9 10 public class HelloThread extends Thread { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new HelloThread (); t . start (); } } Runnable 1 2 3 4 5 6 7 8 9 10 public class HelloRunnable implements Runnable { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); t . start (); } } Observe que nos dois exemplos, um m\u00e9todo run() \u00e9 implementado com o c\u00f3digo a ser executado pelo thread . Em nenhum dos exemplos, contudo, o m\u00e9todo \u00e9 invocado diretamente. Em vez disto, o m\u00e9todo start() , sim, \u00e9 invocado. Isto ocorre porqu\u00ea antes de executar as instru\u00e7\u00f5es definidas pelo pelo programador no m\u00e9todo run() , a m\u00e1quina virtual precisa executar alguma \"m\u00e1gica\" por baixo dos panos como, por exemplo, solicitar ao sistema operacional a cria\u00e7\u00e3o de um thread do SO, que servir\u00e1 de hospedeiro para o thread Java. Isto acontece dentro do start() , que em algum ponto de sua execu\u00e7\u00e3o levar\u00e1 \u00e0 invoca\u00e7\u00e3o do m\u00e9todo run() . A classe Thread tamb\u00e9m prov\u00ea uma s\u00e9rie de m\u00e9todos que permitem gerenciar a vida do thread criado. Por exemplo, o m\u00e9todo de classe Thread.sleep() permite bloquear o thread no qual a invoca\u00e7\u00e3o aconteceu por um determinado per\u00edodo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class HelloRunnable implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ) { System . out . println ( \"Hello at instant \" + i ); try { Thread . sleep ( 1000 ); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); t . start (); } } Observe que a chamada a sleep() est\u00e1 dentro de um bloco try/catch . Isto \u00e9 necess\u00e1rio pois \u00e9 permitido \u00e0 JVM acordar o thread em qualquer instante, antes ou ap\u00f3s o tempo especificado. Assim, embora normalmente o tempo \"dormido\" seja pr\u00f3ximo ao especificado, se h\u00e1 requisitos de precis\u00e3o, \u00e9 necess\u00e1rio que o thread , ao acordar, verifique se j\u00e1 dormiu o suficiente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class HelloRunnable implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ) { System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 1000 ; while ( before + timeout > System . currentTimeMillis ()) { try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); t . start (); } } Quando um thread est\u00e1 sendo executado, outros podem ter que esperar at\u00e9 que complete. Por exemplo, no caso de um navegador Web, o thread que faz a renderiza\u00e7\u00e3o da p\u00e1gina n\u00e3o pode come\u00e7ar a trabalhar enquanto o thread que solicitou o HTML do servidor n\u00e3o receber sua resposta. Um thread indica a inten\u00e7\u00e3o de esperar por outro usando o m\u00e9todo join() . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class HelloRunnable implements Runnable { public void run () { Random rand = new Random (); for ( int i = 0 ; i < 10 ; i ++ ) { System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 901 + rand . nextInt ( 200 ); while ( before + timeout > System . currentTimeMillis ()) { try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new HelloRunnable ()); //t.setDaemon(true); t . start (); try { t . join (); //t.join(10000); } catch ( InterruptedException ie ) { System . out . println ( \"Waiting was interrupted\" ); } if ( t . isAlive ()) System . out . println ( \"Got tired of waiting\" ); else System . out . println ( \"Wait is over\" ); } } Invocar t.join() far\u00e1 com que o thread corrente, neste caso o principal, espere indefinidamente at\u00e9 que t termine de executar. Caso seja necess\u00e1rio limitar o tempo de espera, o tempo pode ser especificado como na linha comentada. Caso a espera termine por causa de um timeout , \u00e9 poss\u00edvel testar o estado atual do thread com Thread.isAlive() . Outro m\u00e9todo interessante, Thread.setDaemon() , especifica que o thread pode ser terminado quando a thread principal terminar. Descomente a invoca\u00e7\u00e3o e teste o efeito. Exerc\u00edcio: contador Fa\u00e7amos um exerc\u00edcio simples do uso de threads . Considere a classe e siga as instru\u00e7\u00f5es abaixo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Counter { private int c = 0 ; public int increment () { return ++ c ; } public int decrement () { return -- c ; } public int value () { return c ; } } Instancie um programa que gere 10 threads . Todos os threads devem compartilhar uma mesma inst\u00e2ncia de Counter Cada thread deve executar um loop em que incrementa o valor do contador 20 vezes a cada vez, imprime o resultado precedido do identificador do thread (use Thread.getName() ou Thread.currentThread().getName() ) A thread principal deve esperar todas as outras terminarem antes de terminar (use Thread.join() ). Analise a sa\u00edda do programa observando a ordem de execu\u00e7\u00e3o dos threads . An\u00e1lise \u00c9 f\u00e1cil observar que a sa\u00edda do programa \u00e9 aleat\u00f3ria nos identificadores e tende a ser incremental nos contadores, mas nem sempre isso \u00e9 verdade. Isso acontece porqu\u00ea a execu\u00e7\u00e3o dos threads \u00e9 n\u00e3o determin\u00edstica; uma vez que estejam prontos para executar, cabe ao escalonador do sistema operacional a decis\u00e3o sobre qual processo e em qual processador dever\u00e1 executar. Todo Melhorar explica\u00e7\u00e3o abaixo Al\u00e9m de extens\u00e3o de Thread e implementa\u00e7\u00e3o de Runnable , Java disponibiliza tamb\u00e9m Executor como abstra\u00e7\u00e3o de mais alto n\u00edvel para execu\u00e7\u00e3o de tarefas concorrentes. Executor ExecutorService ScheduledExecutorService 1 2 3 Executor e = ...; Runnable r = ...; e . execute ( r ); Executors normalmente implementam thread pools , que podem ser de diferentes tipos. O mais simples \u00e9 o de tamanho fixo em que h\u00e1 um n\u00famero inicial de threads criados e que, no caso de algum ser terminado, por exemplo por causa de uma exce\u00e7\u00e3o n\u00e3o tratada, cria substitutos para manter o n\u00famero constante. Executor e = java . util . concurrent . Executors . newFixedThreadPool (); newCachedThreadPool() - expandable thread pool newSingleThreadExecutor() - single task at a time e outras vers\u00f5es ForkJoinPool 1 2 3 4 5 if (my portion of the work is small enough) do the work directly else split my work into two pieces invoke the two pieces and wait for the results","title":"Java"},{"location":"basics/#coordenacao","text":"Como visto no exerc\u00edcio anterior, a execu\u00e7\u00e3o de threads \u00e9 n\u00e3o determin\u00edstica. Contudo, estas execu\u00e7\u00f5es frequentemente precisam ser coordenadas para que n\u00e3o pisem uns nos calcanhares dos outros, por exemplo, decidindo quem deve ser o pr\u00f3ximo a entrar em uma regi\u00e3o cr\u00edtica ou ser\u00e1 o respons\u00e1vel por uma determinada tarefa. H\u00e1 v\u00e1rias astra\u00e7\u00f5es que podem ser usadas para coordenar as opera\u00e7\u00f5es de threads , como deve se lembrar no estudo de Sistemas Operacionais. Alguns exemplos s\u00e3o locks , vari\u00e1veis de condi\u00e7\u00e3o e sem\u00e1foros. Especificamente em Java, provavelmente a abstra\u00e7\u00e3o mais simples s\u00e3o os blocos synchronized .","title":"Coordena\u00e7\u00e3o"},{"location":"basics/#referencias","text":"Sockets UDP em Python UDP em Python Multicast em Java Multicast em Python Beej's Guide to Network Programming - Using Internet Sockets Concorr\u00eancia em Java Java Concurrency in Practice The Well-Grounded Java Developer Concorr\u00eancia em Java Futures e Promises Locks Tipos At\u00f4micos Estado Uma vis\u00e3o interessante sobre estado \u00e9 apresentada em On stateless software design . Observe que n\u00e3o necessariamente eu concordo com tudo o que est\u00e1 escrito aqui, principalmente a quest\u00e3o sobre stateful ser sempre mais complexo. A discrep\u00e2ncia de vis\u00e3o est\u00e1 no fato de parte da complexidade ser levada para o cliente, no caso dos servidores stateless , mas n\u00e3o necessariamente ser eliminada. Sobre IO n\u00e3o bloqueante em Java. Annual failure rates - servers \u21a9 Os recursos compartilhados v\u00e3o desde alguns \u00f3bvios, como capacidade de armazenamento e de processamento , a pr\u00f3pria localiza\u00e7\u00e3o de um n\u00f3, que pode ser geograficamente mais pr\u00f3xima e de menor lat\u00eancia at\u00e9 um ponto de interesse, ou at\u00e9 mesmo a disponibilidade de uma conex\u00e3o f\u00edsica com um recurso especial, como uma impressora. \u21a9 Lembrem-se que tamb\u00e9m e voc\u00ea n\u00e3o quer que seu sistema seja como ogros, temperamentais e mal-cheirosos. Logo, planeje bem suas camadas de abstra\u00e7\u00e3o. \u21a9 By User:Ludovic.ferre - Internet Connectivity Distribution&Core.svg, CC BY-SA 3.0, ( https://commons.wikimedia.org/w/index.php?curid=10030716 ) \u21a9 Endere\u00e7os IP n\u00e3o p\u00fablicos n\u00e3o servem como identificadores \u00fanicos na Internet. \u21a9 Voc\u00ea pode usar outro nome, desde que n\u00e3o seja socket.py , e que adapte o comando para sua execu\u00e7\u00e3o. \u21a9 O programa telnet \u00e9 normalmente instalado por padr\u00e3o tanto no Windows, OSX quanto no Linux. J\u00e1 o netcat normalmente precisa ser instalado por voc\u00ea. Em alguns sistemas, em vez de netcat o comando \u00e9 o nc ]. \u21a9 Understanding IP Multicast \u21a9 IP-Multicast em IPv6 \u21a9 Um bom ponto de partida para o t\u00f3pico \u00e9 a sua entrada na wikipedia . \u21a9 O artigo SEDA: An Architecture for Well-Conditioned, Scalable Internet Services descreve em detalhes a arquitetura SEDA. \u21a9 Pode-se argumentar que E/S ass\u00edncrona resolveria o problema aqui, mas isso n\u00e3o vem ao caso. \u21a9","title":"Refer\u00eancias"},{"location":"comm/","text":"Comunica\u00e7\u00e3o O desenvolvimento de sistemas distribu\u00eddos usando diretamente Sockets como forma de comunica\u00e7\u00e3o entre componentes n\u00e3o \u00e9 para os fracos de cora\u00e7\u00e3o. Sua grande vantagem est\u00e1 no acesso baixo n\u00edvel \u00e0 rede , e todo o ganho de desempenho que isso pode trazer. Suas desvantagens, entretanto, s\u00e3o v\u00e1rias: interface de \"arquivo\" para se ler e escrever bytes; controle de fluxo de \"objetos\" \u00e9 por conta da aplica\u00e7\u00e3o, isto \u00e9, a aplica\u00e7\u00e3o precisa sinalizar quantos bytes ser\u00e3o escritos de um lado, para que o outro saiba quanto ler para obter um \"objeto\" correto; logo, a serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o de objetos \u00e9 tamb\u00e9m por conta da aplica\u00e7\u00e3o; tratamento de desconex\u00f5es e eventuais reconex\u00f5es tamb\u00e9m \u00e9 gerenciado pela aplica\u00e7\u00e3o e nem a t\u00e3o famosa confiabilidade do TCP ajuda. Enquanto se poderia argumentar que algumas destas desvantagens podem ser descartadas em fun\u00e7\u00e3o da discuss\u00e3o de incluir ou n\u00e3o API na comunica\u00e7\u00e3o fim-a-fim , \u00e9 certo que algumas funcionalidades s\u00e3o ub\u00edquas em aplica\u00e7\u00f5es distribu\u00eddas. Aqui discutiremos algumas destas funcionalidades e como podem e s\u00e3o implementadas por frameworks de comunica\u00e7\u00e3o de mais alto n\u00edvel. No mundo dos sistemas distribu\u00eddos, estes frameworks s\u00e3o conhecidos como middleware . Middleware Middleware software hardware/OS aplica\u00e7\u00e3o diversas funcionalidades De acordo com Tanenbaum & Van Steen , middleware \u00e9 ... the software layer that lies between the operating system and applications on each side of a distributed computing system in a network. Isto \u00e9, o middleware \u00e9 a camada ware que fica no middle , entre, o software e o hardware . Software, no caso, \u00e9 a aplica\u00e7\u00e3o distribu\u00edda sendo desenvolvida e hardware \u00e9 a abstra\u00e7\u00e3o do host em que se executam os componentes, provida pelo sistema operacional. Uso aqui o termo abstra\u00e7\u00e3o porqu\u00ea o sistema operacional pode encapsular hardware real, mas tamb\u00e9m pode encapsular outra abstra\u00e7\u00e3o de hardware , por exemplo, uma m\u00e1quina virtual ou cont\u00eainer. A figura seguinte mostra um exemplo com tr\u00eas aplica\u00e7\u00f5es executando sobre um middleware , que por sua vez \u00e9 executado sobre diferentes sistemas operacionais, em hosts conectados por uma rede de comunica\u00e7\u00e3o. 1 Com este cen\u00e1rio em mente, \u00e9 importante entender o que diz Sacha Krakowiak quando afirma que as principais fun\u00e7\u00f5es do middleware s\u00e3o: esconder a distribui\u00e7\u00e3o e o fato de que um aplica\u00e7\u00e3o \u00e9 geralmente composta por m\u00faltiplas partes, executando em localiza\u00e7\u00f5es geograficamente distintas, esconder a heterogeneidade dos v\u00e1rios componentes de hardware, sistemas operacionais e protocolos de comunica\u00e7\u00e3o prover interfaces uniformes, de alto n\u00edvel e padronizadas para os desenvolvedores de aplica\u00e7\u00e3o e integradores, de forma que aplica\u00e7\u00f5es possam ser facilmente compostas, reusadas, portadas e feitas interoper\u00e1veis. Assim, os middleware facilitam a conex\u00e3o entre componentes e permitem o uso de protocolos mais abstratos que as opera\u00e7\u00f5es de write(byte[]) e read(): byte[] dos protocolos de baixo n\u00edvel, escondendo a complexidade da coordena\u00e7\u00e3o de sistemas independentes. Desenvolver sistemas distribu\u00eddos sem usar um middleware \u00e9 como desenvolver um aplicativo sem usar quaisquer bibliotecas: poss\u00edvel, mas complicado, e estar\u00e1 certamente reinventando a roda. Isto \u00e9, voc\u00ea praticamente tem que refazer o middleware antes de desenvolver o sistema em si. Idealmente, com o middleware , o desenvolvedor conseguiria facilmente implementar uma aplica\u00e7\u00e3o em que a distribui\u00e7\u00e3o fosse totalmente transparente, levando o sistema, uma cole\u00e7\u00e3o de sistemas computacionais (software ou hardware) independentes, a se apresentar para o usu\u00e1rio como um sistema \u00fanico , monol\u00edtico. Pense no browser e na WWW, por exemplo: o quanto voc\u00ea sabe sobre as p\u00e1ginas estarem particionadas em milh\u00f5es de servidores? Isso \u00e9 o que chamamos de transpar\u00eancia . Transpar\u00eancia Transpar\u00eancia Total Acesso + Localiza\u00e7\u00e3o + Reloca\u00e7\u00e3o + Migra\u00e7\u00e3o + Replica\u00e7\u00e3o + Falha Se n\u00e3o h\u00e1 qualquer ind\u00edcio de que a aplica\u00e7\u00e3o \u00e9 distribu\u00edda, ent\u00e3o temos transpar\u00eancia total . Podemos quebrar esta transpar\u00eancia total em v\u00e1rias transpar\u00eancias mais simples: Acesso , Localiza\u00e7\u00e3o , Reloca\u00e7\u00e3o , Migra\u00e7\u00e3o , Replica\u00e7\u00e3o , e Falha . Vejamos cada uma destas separadamente. Transpar\u00eancia de Acesso Transpar\u00eancia de Acesso como se apresenta representa\u00e7\u00e3o de dados arquitetura OS linguagem padr\u00f5es abertos e bem conhecidos. A transpar\u00eancia de acesso diz respeito \u00e0 representa\u00e7\u00e3o de dados e mecanismos de invoca\u00e7\u00e3o (arquitetura, formatos, linguagens...). Cada computador tem uma arquitetura e uma forma de representar seus dados. Por exemplo, considere os padr\u00f5es para representa\u00e7\u00e3o de n\u00fameros em ponto flutuante IEEE e IBM. Ambos dividem os bits em sinal, expoente e mantissa, mas com tamanhos diferentes. IEEE 2 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Half 16 1 5 10 Single 32 1 8 23 Double 64 1 11 52 Quadruple 128 1 15 112 IBM 3 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Single 32 1 7 24 Double 64 1 7 56 Quadruple 128 1 7 112 (8b ignorados) E se dois componentes de um SD executam em m\u00e1quinas com arquiteturas diferentes, como trocam n\u00fameros em ponto flutuante? \u00c9 preciso que usem um padr\u00e3o conhecido por ambos os hosts , seja o padr\u00e3o a arquitetura \"nativa\" do host ou um padr\u00e3o intermedi\u00e1rio, definido pelo middleware . A mesma quest\u00e3o \u00e9 v\u00e1lida para representa\u00e7\u00f5es de strings e classes, e diferen\u00e7as de sistemas operacionais e linguagens. No caso espec\u00edfico das strings, pense em um programa escrito em linguagem C e que este programa deva comunicar-se com um outro, escrito em Java, e trocar strings com o mesmo. Enquanto em C uma string \u00e9 uma sequ\u00eancia de bytes imprim\u00edveis terminadas por um \\0 , em Java uma string \u00e9 uma classe que encapsula uma sequ\u00eancia de chars, sendo que cada char \u00e9 um c\u00f3digo 16 bits representativo de um c\u00f3digo Unicode 4 . Como transferir strings entre duas plataformas? N\u00e3o faz\u00ea-lo? Simplificar a string Java? Estender a string C? Para se tentar obter transpar\u00eancia de acesso, \u00e9 importante que se use padr\u00f5es implementados em m\u00faltiplas arquiteturas, abertos e bem conhecidos, com interfaces bem definidas . Transpar\u00eancia de Localiza\u00e7\u00e3o Transpar\u00eancia de localiza\u00e7\u00e3o onde est\u00e1 o objeto lat\u00eancia cache paralelismo programa\u00e7\u00e3o ass\u00edncrona arquiteturas reativas A transpar\u00eancia de localiza\u00e7\u00e3o diz respeito a onde est\u00e1 o objeto acessado pela aplica\u00e7\u00e3o, seja um BD, p\u00e1gina Web ou servi\u00e7o de echo: pouco importa ao usu\u00e1rio, se est\u00e1 dentro da mesma m\u00e1quina de onde executa o acesso, se na sala ao lado ou em um servidor do outro lado do globo, desde que o servi\u00e7o seja provido de forma r\u00e1pida e confi\u00e1vel. A esta transpar\u00eancia \u00e9 essencial uma boa distribui\u00e7\u00e3o do servi\u00e7o, sobre uma rede com baixa lat\u00eancia, ou o uso de t\u00e9cnicas que permitam esconder a lat\u00eancia. Escondendo a Lat\u00eancia Para se esconder a lat\u00eancia, v\u00e1rias t\u00e1ticas s\u00e3o utiliz\u00e1veis: Caching de dados Em vez de sempre buscar os dados no servidor, mantenha c\u00f3pias locais dos dados que mudam menos (e.g., o CSS do stack overflow ). Use paralelismo Em vez de validar formul\u00e1rio ap\u00f3s preenchimento de cada campo, valide em paralelo enquanto usu\u00e1rio preenche o campo seguinte. Use callbacks para indicar campos com problemas a serem corrigidos. Saiba que nem todo problema \u00e9 paraleliz\u00e1vel, por exemplo, autentica\u00e7\u00e3o Use programa\u00e7\u00e3o ass\u00edncrona AsyncIO C# await/async Futures e Promises Outra forma de diminuir lat\u00eancia \u00e9 trazer para pr\u00f3ximo do usu\u00e1rio parte da computa\u00e7\u00e3o. Isto \u00e9 comumente feito com a interface com usu\u00e1rio, mas pode ser usado tamb\u00e9m para outras partes do sistema. Como exemplo do primeiro, pense em consoles de video-game que fazem o processamento gr\u00e1fico pesado de jogos online na casa do usu\u00e1rio 5 . Como exemplo do segundo, pense em aplicativos que mant\u00e9m os dados em celulares at\u00e9 que uma boa conex\u00e3o, por exemplo WiFi, esteja dispon\u00edvel para sincronizar com o servidor. De forma geral, pense em esconder lat\u00eancia pelos seguintes passos: Distribua tarefas Delegue computa\u00e7\u00e3o aos clientes (e.g., JavaScript e Applets Java) Particione dados entre servidores (e.g., Domain Name Service e World Wide Web) para dividir a carga e aumentar a vaz\u00e3o Aproxime dados dos clientes Mantenha c\u00f3pias de dados em m\u00faltiplos lugares. Atualize dados de acordo com necessidade (e.g., cache do navegador, com c\u00f3digo do google.com sendo atualizado a cada 4 dias) Transpar\u00eancia de Reloca\u00e7\u00e3o Transpar\u00eancia de reloca\u00e7\u00e3o como se movimenta visto por clientes As vezes componentes do sistema distribu\u00eddo precisam ser movimentados de uma localiza\u00e7\u00e3o \u00e0 outra, por exemplo porqu\u00ea um novo host foi contratado. Se implementadas corretamente, as t\u00e9cnicas que entregam transpar\u00eancia de localiza\u00e7\u00e3o n\u00e3o deixam que o cliente perceba a movimenta\u00e7\u00e3o, no que chamamos transpar\u00eancia de Reloca\u00e7\u00e3o. Rede de baixa lat\u00eancia Distribui\u00e7\u00e3o inteligente E.g: Servi\u00e7os de nome M\u00faltiplas c\u00f3pias C\u00f3pias tempor\u00e1rias Transpar\u00eancia de Migra\u00e7\u00e3o Transpar\u00eancia de migra\u00e7\u00e3o como se movimenta visto por si mesmo Do ponto de vista do pr\u00f3prio servi\u00e7o, n\u00e3o perceber que se est\u00e1 sendo movimentado \u00e9 chamado transpar\u00eancia de Migra\u00e7\u00e3o. Um servi\u00e7o com esta propriedade, n\u00e3o precisa ser parado e reconfigurado quando a mudan\u00e7a acontece. Uma das formas de se implementar esta propriedade \u00e9 atrav\u00e9s da migra\u00e7\u00e3o provida por m\u00e1quinas virtuais, usado, por exemplo, para consolidar o uso de servidores em nuvens computacionais. Veja o exemplo do VMotion da VMware. Na verdade, a movimenta\u00e7\u00e3o neste cen\u00e1rio, \u00e9 uma c\u00f3pia da m\u00e1quina virtual. Uma vez que a c\u00f3pia esteja pr\u00f3xima do fim, a imagem original \u00e9 congelada, a c\u00f3pia conclu\u00edda, e h\u00e1 um chaveamento na rede para se direcionar toda comunica\u00e7\u00e3o para nova c\u00f3pia. O m\u00e1quina original \u00e9 ent\u00e3o descartada. Transpar\u00eancia de Replica\u00e7\u00e3o Transpar\u00eancia de replica\u00e7\u00e3o redund\u00e2ncia visto por clientes A capacidade de ter c\u00f3pias de um servi\u00e7o e de direcionar trabalho de uma para outra \u00e9 tamb\u00e9m \u00fatil para se obter transpar\u00eancia no caso de falhas. Isto porqu\u00ea para se manter um servi\u00e7o funcional a despeito de falhas, \u00e9 preciso ter m\u00faltiplas c\u00f3pias, prontas para funcionar a qualquer momento. Dependendo das garantias desejadas na manuten\u00e7\u00e3o da consist\u00eancia entre as c\u00f3pias, o custo pode variar muito, de forma que para se ter um custo menor, tem-se garantias mais fracas, por exemplo, que as r\u00e9plicas tem um atraso entre elas de no m\u00e1ximo \\(X\\) minutos. Este \u00e9 um dilema parecido com o TCP x UDP, em que mais garantias implicam em maior custo de comunica\u00e7\u00e3o. Algumas aplica\u00e7\u00f5es toleram inconsist\u00eancias e podem viver com menores custos. Um exemplo famoso \u00e9 o dos \"carrinhos de compra\" da Amazon.com , que podem fechar pedidos com conte\u00fado diferente do desejado pelo cliente. Outras aplica\u00e7\u00f5es s\u00e3o normalmente constru\u00eddas com requisitos de consist\u00eancia forte entre as r\u00e9plicas, como sistemas financeiros. Para estas aplica\u00e7\u00f5es, uma t\u00e9cnica importante para se conseguir replica\u00e7\u00e3o \u00e9 o uso de frameworks de comunica\u00e7\u00e3o em grupo , que entregam para m\u00faltiplas inst\u00e2ncias de um mesmo servi\u00e7o, as mesmas mensagens, permitindo que elas se mantenham como c\u00f3pias. Esta t\u00e9cnica funciona se os servi\u00e7os forem m\u00e1quinas de estado determin\u00edsticas, que consideram como eventos as mensagens entregues pelo protocolo de comunica\u00e7\u00e3o em grupo e \u00e9 denominada replica\u00e7\u00e3o de m\u00e1quinas de estado . Replica\u00e7\u00e3o de M\u00e1quina de Estados determin\u00edstica mesmo estado inicial mesmos eventos mesmo estado final atraso entre r\u00e9plicas stateDiagram ei: Estado Inicial e1: Estado 1 e2: Estado 2 e3: Estado 3 en: Estado N ei --> e1 e1 --> e2 e2 --> e1 e2 --> e3 e3 --> e2 e1 --> en e3 --> en Todo Figura com state machine replication Novamente \u00e9 preciso chamar \u00e0 aten\u00e7\u00e3o a quest\u00e3o dos custos desta t\u00e9cnica. Replica\u00e7\u00e3o de M\u00e1quinas de Estados \u00e9 muito custosa e por isso faz-se um esfor\u00e7o para n\u00e3o utiliz\u00e1-la ou para utiliz\u00e1-la em \"cantinhos\" do sistema onde inconsist\u00eancias s\u00e3o absolutamente caras demais para sere permitidas. Isto porqu\u00ea manter m\u00faltiplas c\u00f3pias \\(\\Rightarrow\\) sincroniza\u00e7\u00e3o \\(\\Rightarrow\\) custos. Se houver mudan\u00e7as frequentes nos dados, tal custo precisa ser pago tamb\u00e9m frequentemente. Mitiga\u00e7\u00f5es incluem uso de r\u00e9plicas tempor\u00e1rias, protocolos de invalida\u00e7\u00e3o de cache, contrata\u00e7\u00e3o de redes com mais largura de banda e menor lat\u00eancia, sendo que estes \u00faltimos esbarram em limita\u00e7\u00f5es financeiras e f\u00edsicas. Transpar\u00eancia de Concorr\u00eancia Transpar\u00eancia de concorr\u00eancia obliviedade a outros servi\u00e7os visto por clientes Outra transpar\u00eancia almej\u00e1vel \u00e9 de concorr\u00eancia, isto \u00e9, imperceptibilidade quanto ao fato de que o servi\u00e7o est\u00e1 executando concorrentemente a outros servi\u00e7os e sendo acessado por outros clientes. Isto \u00e9 importante tanto em termos de seguran\u00e7a, no sentido de que um cliente n\u00e3o deveria acessar os dados do outro, caso isso seja um requisito do sistema, quanto tem termos de desempenho. Nuvens computacionais s\u00e3o um exemplo de onde este tipo de transpar\u00eancia \u00e9 essencial. Considere um servi\u00e7o de banco de dados em uma nuvem qualquer. Para prover a mesma interface com a qual usu\u00e1rios est\u00e3o acostumados a anos, \u00e9 poss\u00edvel que este servi\u00e7o seja simplesmente um wrapper ao redor do SGBD que se comprava e instalava in-house anteriormente. Para se tornar vi\u00e1vel, contudo, uma mesma inst\u00e2ncia deve servir m\u00faltiplos clientes, os tenants , sem que a carga de trabalho introduzida por um, interfira no desempenho do outro. No meio, chamamos esta propriedade de multi-tenancy , mas \u00e9 apenas um exemplo de transpar\u00eancia de concorr\u00eancia. Esta transpar\u00eancia est\u00e1 fundamentalmente ligada \u00e0 escalabilidade, isto \u00e9, \u00e0 adequa\u00e7\u00e3o dos pool de recursos \u00e0s demandas dos clientes: se mais clientes est\u00e3o presentes, ent\u00e3o aumente a quantidade de servidores ( scale up ) e separe as cargas ( sharding ); se menos clientes est\u00e3o presentes, ent\u00e3o desligue algumas m\u00e1quinas ( scale down ) e consolide recursos. Desafios para se obter transpar\u00eancia Apesar de desej\u00e1veis, as transpar\u00eancia discutidas s\u00e3o dif\u00edceis de se conseguir, principalmente se em conjunto. Isto porqu\u00ea, do ponto de vista de usu\u00e1rios espalhados pelo globo, atr\u00e1s de redes heterog\u00eaneas e com possibilidade de erros, acontecer\u00e3o atrasos e perdas na comunica\u00e7\u00e3o, denunciando a distribui\u00e7\u00e3o. Do ponto de vista do desenvolvedor , \u00e9 preciso tomar decis\u00f5es baseado em premissas ligadas \u00e0 realidade da rede. Por exemplo, se uma requisi\u00e7\u00e3o n\u00e3o foi respondida, quanto tempo um cliente deve esperar antes de reenvi\u00e1-la, possivelmente para outro servidor, sem incorrer em risco significativo da requisi\u00e7\u00e3o ser processada duas vezes? A resposta para esta pergunta \u00e9 muito mais complicada do que pode parecer. De forma geral , qualquer aumento de transpar\u00eancia tem um custo, seja em termos monet\u00e1rios (e.g., contrata\u00e7\u00e3o de enlace dedicado ou de host em outra posi\u00e7\u00e3o geogr\u00e1fica), ou em termos de desempenho (e.g., coordenar a entrega de mensagens em sistemas de comunica\u00e7\u00e3o em grupo). Provavelmente os maiores obst\u00e1culos para se alcan\u00e7ar os diversos tipos de transpar\u00eancia s\u00e3o impostos pela parte da infraestrutura que torna o sistema distribu\u00eddo poss\u00edvel, a rede. Para entender o porqu\u00ea, vejamos algumas premissas normalmente assumidas sobre a rede que n\u00e3o s\u00e3o, definitivamente, verdade: A lat\u00eancia \u00e9 zero. A largura de banda \u00e9 infinita. A rede \u00e9 confi\u00e1vel. A rede \u00e9 segura. A rede \u00e9 homog\u00eanea. A rede \u00e9 est\u00e1tica. A rede tem acesso gr\u00e1tis. A rede \u00e9 administrada por voc\u00ea ou algu\u00e9m acess\u00edvel. Representa\u00e7\u00e3o de dados Exceto por aplica\u00e7\u00f5es muito simples, processos em um sistema distribu\u00eddo trocam dados complexos, por exemplo estruturas ou classes com diversos campos, incluindo valores num\u00e9ricos de diversos tipos, strings e vetores de bytes, com diversos n\u00edveis de aninhamento e somando v\u00e1rios KB. Neste cen\u00e1rio, v\u00e1rios fatores precisam ser levados em considera\u00e7\u00e3o na hora de colocar esta estrutura no fio , como: varia\u00e7\u00f5es de defini\u00e7\u00f5es de tipos, por exemplo, inteiro : 8: 16, 32, ou 64 bits? varia\u00e7\u00f5es na representa\u00e7\u00e3o de dados complexos: classe x estrutura conjunto de caracteres diferentes: ASCII x UTF little endian, como x64 e IA-32, ou big endian como SPARC (< V9), Motorola e PowerPC? ou aidna, flex\u00edvel como ARM, MIPS ou IA-64? fim de linha com crlf (DOS) x lf (Unix)? fragmenta\u00e7\u00e3o de dados na rede Representa\u00e7\u00e3o Textual Uma abordagem comumente usada \u00e9 a representa\u00e7\u00e3o em formato textual \"amig\u00e1vel a humanos\". Veja o exemplo de como o protocolo HTTP requisita e recebe uma p\u00e1gina HTML. 1 2 3 4 5 6 telnet www.google.com 80 Trying 187.72.192.217... Connected to www.google.com. Escape character is '^]'. GET / HTTP/1.1 host: www.google.com As linhas 5 e 6 s\u00e3o entradas pelo cliente para requisitar a p\u00e1gina raiz do s\u00edtio www.google.com . A linha 7, vazia, indica ao servidor que a requisi\u00e7\u00e3o est\u00e1 terminada. Em resposta a esta requisi\u00e7\u00e3o, o servidor envia o seguinte, em que as primeiras linhas trazem metadados da p\u00e1gina requisitada e, ap\u00f3s a linha em branco, vem a resposta em HTML \u00e0 requisi\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 HTTP/1.1 302 Found Location: http://www.google.com.br/?gws_rd=cr & ei=HTDqWJ3BDYe-wATs_a3ACA Cache-Control: private Content-Type: text/html; charset=UTF-8 P3P: CP=\"This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info.\" Date: Sun, 09 Apr 2017 12:59:09 GMT Server: gws Content-Length: 262 X-XSS-Protection: 1; mode=block X-Frame-Options: SAMEORIGIN Set-Cookie: NID=100=NB_AruuFWL0hXk2-h7VDduHO_UkjAr6RaqgG7VbccTsfLzFfhxEKx21Xpa2EH7IgshgczE9vU4W1TyKsa07wQeuZosl5DbyZluR1ViDRf0C-5lRpd9cCpCD5JXXjy-UE; expires=Mon, 09-Oct-2017 12:59:09 GMT; path=/; domain=.google.com; HttpOnly < HTML >< HEAD >< meta http-equiv = \"content-type\" content = \"text/html;charset=utf-8\" > < TITLE > 302 Moved </ TITLE ></ HEAD >< BODY > < H1 > 302 Moved </ H1 > The document has moved < A HREF = \"http://www.google.com.br/?gws_rd=cr&amp;ei=HTDqWJ3BDYe-wATs_a3ACA\" > here </ A > . </ BODY ></ HTML > Representa\u00e7\u00f5es textuais s\u00e3o usadas em diversos protocolos como SMTP, POP, e telnet. Algumas destas representa\u00e7\u00f5es seguem padr\u00f5es formalizados, o que facilita a gera\u00e7\u00e3o e interpreta\u00e7\u00e3o dos dados. Dois padr\u00f5es bem conhecidas s\u00e3o XML e JSON. XML \u00e9 o acr\u00f4nimo para Extensible Markup Language , ou seja, uma linguagem marca\u00e7\u00e3o que pode ser estendida para representar diferentes tipos de informa\u00e7\u00e3o. A HTML, por exemplo, \u00e9 uma inst\u00e2ncia de XML destinada \u00e0 representa\u00e7\u00e3o de hipertexto (A bem da verdade, XML foi uma generaliza\u00e7\u00e3o de HTML). Por exemplo, para representarmos os dados relativos \u00e0 uma pessoa, podemos ter uma inst\u00e2ncia XML assim: 1 2 3 4 5 6 7 8 9 <person> <name> John Doe </name> <id> 112234556 </id> <email> jdoe@example.com </email> <telephones> <telephone type= \"mobile\" > 123 321 123 </telephone> <telephone type= \"home\" > 321 123 321 </telephone> </telephones> </person> Uma das grandes vantagens do uso de XML \u00e9 a possibilidade de se formalizar o que pode ou n\u00e3o estar em um arquivo para um certo dom\u00ednio utilizando um XML Domain Object Model . H\u00e1, por exemplo, modelos para representa\u00e7\u00e3o de documentos de texto, governos eletr\u00f4nicos, representa\u00e7\u00e3o de conhecimento, etc . Sua maior desvantagem \u00e9 que \u00e9 muito verborr\u00e1gico e por vezes complicado de se usar, abrindo alas para o seu mais famoso concorrente, JSON. JSON \u00e9 o acr\u00f4nimo de Javascript Object Notation , isto \u00e9, o formato para representa\u00e7\u00e3o de objetos da linguagem Javascript. Devido \u00e0 sua simplicidade e versatilidade, entretanto, foi adotado como forma de representa\u00e7\u00e3o de dados em sistemas desenvolvidos nas mais diferentes linguagens. O mesmo exemplo visto anteriormente, em XML, \u00e9 representado em JSON assim: 1 2 3 4 5 6 7 8 9 { \"name\" : \"John Doe\" , \"id\" : 112234556 , \"email\" : \"jdoe@example.com\" , \"telephones\" : [ { \"type\" : \"mobile\" , \"number\" : \"123 321 123\" }, { \"type\" : \"home\" , \"number\" : \"321 123 321\" }, ] } Em Python, por exemplo, JSON s\u00e3o gerados e interpretados nativamente, sem a necessidade de frameworks externos, facilitando seu uso. Mas de fato, a op\u00e7\u00e3o final por XML ou JSON \u00e9 quest\u00e3o de prefer\u00eancia, uma vez que os dois formatos s\u00e3o, de fato, equivalentes na quest\u00e3o da representa\u00e7\u00e3o de informa\u00e7\u00e3o. Outros formatos, bin\u00e1rios, oferecem vantagens no uso de espa\u00e7o para armazenar e transmitir dados, e por isso s\u00e3o frequentemente usados como forma de serializa\u00e7\u00e3o de dados em sistemas distribu\u00eddos, isto \u00e9, na transforma\u00e7\u00e3o de TAD para sequ\u00eancias de bytes que seguir\u00e3o \"no fio\". ASN.1 (Abstract Syntax Notation), pela ISO XDR (eXternal Data Representation) Java serialization Google Protocol Buffers Thrift ASN.1 e XDR s\u00e3o de interesse hist\u00f3rico, mas n\u00e3o os discutiremos aqui. Quanto \u00e0 serializa\u00e7\u00e3o feita nativamente pelo Java, por meio de ObjectOutputStreams , como neste exemplo , embora seja tentadora para quem usa Java, \u00e9 necess\u00e1rio saber que ela \u00e9 restrita \u00e0 JVM e que usa muito espa\u00e7o, embora minimize riscos de uma desserializa\u00e7\u00e3o para uma classe diferente. Nos foquemos nas autras alternativas listadas, ProtoBuffers e Thrift, que podem levar a representa\u00e7\u00f5es bin\u00e1rias e textuais. ProtoBuffers Nas palavras dos criadores , Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Por meio de protobuffers, \u00e9 poss\u00edvel estruturar dados e gerar o c\u00f3digo correspondente em diversas linguagens, for forma compartilh\u00e1vel entre as mesmas. Veja o exemplo a seguir, que especifica os dados referentes a uma pessoa. Observe a presen\u00e7a de campos de preenchimento opcional ( optional ), de enumera\u00e7\u00f5es ( enum ), e de cole\u00e7\u00f5es ( repeated ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 message Person { required string name = 1 ; required int32 id = 2 ; optional string email = 3 ; enum PhoneType { MOBILE = 0 ; HOME = 1 ; WORK = 2 ; } message PhoneNumber { required string number = 1 ; optional PhoneType type = 2 [ default = HOME ]; } repeated PhoneNumber phone = 4 ; } Com tal defini\u00e7\u00e3o \u00e9 poss\u00edvel gerar c\u00f3digo como o seguinte, em C++, que serializa os dados para escrita em um arquivo... 1 2 3 4 5 6 Person person ; person . set_name ( \"John Doe\" ); person . set_id ( 1234 ); person . set_email ( \"jdoe@example.com\" ); fstream output ( \"myfile\" , ios :: out | ios :: binary ); person . SerializeToOstream ( & output ); e l\u00ea do arquivo e desserializa para hidratar um novo objeto. 1 2 3 4 5 fstream input ( \"myfile\" , ios :: in | ios :: binary ); Person person ; person . ParseFromIstream ( & input ); cout << \"Name: \" << person . name () << endl ; cout << \"E-mail: \" << person . email () << endl ; De acordo com benchmarks do pr\u00f3prio projeto , a opera\u00e7\u00e3o em XML seria mais ordens de grandeza mais lenta e ocuparia mais espa\u00e7o. When this message is encoded to the protocol buffer binary format, it would probably be 28 bytes long and take around 100-200 nanoseconds to parse. The XML version is at least 69 bytes if you remove whitespace, and would take around 5,000-10,000 nanoseconds to parse. Thrift TODO Thrift como forma de representa\u00e7\u00e3o de dados: Thrift type system Invoca\u00e7\u00e3o Remota de Procedimentos - RPC Em 1984, Birrel e Nelson 6 introduziram o mecanismo de Invoca\u00e7\u00e3o Remota de Procedimentos ( Remote Procedure Calls ), que permite que processos fa\u00e7am, pasmem, invoca\u00e7\u00f5es de procedimentos remotos! \u00d3bvio, a inova\u00e7\u00e3o n\u00e3o est\u00e1 na capacidade de uma m\u00e1quina conversar com outra, mas em como esta conversa acontece, do ponto de vista do programador. Por exemplo, RPC permita que se procure a substring \"teste\" dentro da string apontada por a , a partir da posi\u00e7\u00e3o 3, usando x = substring(a,3,\"teste\"); , mas com o invocador da fun\u00e7\u00e3o em um processo e a implementa\u00e7\u00e3o da fun\u00e7\u00e3o propriamente dita, em outro, possivelmente em outra m\u00e1quina. Stubs Antes de nos aprofundarmos, vejamos como uma invoca\u00e7\u00e3o de fun\u00e7\u00f5es acontece normalmente dentro de um \u00fanico processo 7 . O c\u00f3digo x = substring(a,3,\"teste\"); , que procura \"teste\" em *a , \u00e9 traduzido nos seguintes passos em linguagem de m\u00e1quina: coloque o endere\u00e7o de \"teste\" na pilha coloque 3 na pilha coloque o valor de a na pilha coloque o endere\u00e7o de retorno na pilha (junto com outros dados de controle) salte para substring ajustando o instruction pointer ... procure substring ... coloque o resultado no acumulador limpe a pilha salte de volta recuperando o endere\u00e7o de retorno da pilha e ajustando o IP coloque resultado em x Se o que queremos \u00e9 colocar o c\u00f3digo da fun\u00e7\u00e3o substring em um outro processo e execut\u00e1-lo como se estiv\u00e9ssemos no mesmo processo que faz a invoca\u00e7\u00e3o, precisamos pensar em v\u00e1rias quest\u00f5es relativas ao fluxo mostrado acima. Claramente n\u00e3o podemos usar o mesmo fluxo para invocar uma fun\u00e7\u00e3o, mas precisamos de c\u00f3digo de simule a invoca\u00e7\u00e3o local mas que, por baixo do cap\u00f4, use sockets para se comunicar com o processo remoto. Estq simula\u00e7\u00e3o usar\u00e1 c\u00f3digo extra, que finge implementar substring para o invocador mas delega ao c\u00f3digo remoto o trabalho real da busca. Este c\u00f3digo extra \u00e9 conhecido como stub , ou para ser mais preciso, stub cliente , que faz parte do processo invocando a opera\u00e7\u00e3o, e stub servidor, que faz parte do processo executando a opera\u00e7\u00e3o invocada 8 . Assim, o cliente invoca fun\u00e7\u00e3o no stub cliente, achando que \u00e9 a fun\u00e7\u00e3o que quer executar. Stub cliente faz o marshaling 9 dos par\u00e2metros e usa o SO para transferir os dados via rede para o stub servidor. Quando recebe a resposta do servidor, o stub cliente retorna a mesma resposta, como se tivesse calculado localmente. Stub cliente Implementa uma fun\u00e7\u00e3o substring(char*, int, char*) que abre socket para servidor envia par\u00e2metros especifica fun\u00e7\u00e3o espera resposta retorna resultado J\u00e1 o stub servidor fica esperando o contato do cliente. Quando acontece, faz o \"unmarshalling\" dos dados, invoca a fun\u00e7\u00e3o localmente na aplica\u00e7\u00e3o servidor e pega o resultado, que retona ao cliente. Stub servidor espera conex\u00e3o recebe par\u00e2metros recebe especifica\u00e7\u00e3o da fun\u00e7\u00e3o invoca fun\u00e7\u00e3o localmente envia resultado para cliente Transpar\u00eancia \u00c9 para o programador a grande vantagem do uso de RPC, pois se pode escrever c\u00f3digo distribu\u00eddo \"igual\" ao centralizado, certo? Isto \u00e9, interface baseada em procedimentos e sem a necessidade de detalhar portas, sockets, e representa\u00e7\u00e3o de dados . Ou seja, tudo \u00e9 transparente! Como j\u00e1 discutimos, v\u00e1rios fatores trabalham contra a transpar\u00eancia em sistemas distribu\u00eddos . Em espec\u00edfico quanto \u00e0 transpar\u00eancia dada pelo RPC, tamb\u00e9m temos limita\u00e7\u00f5es. O problema \u00e9 que h\u00e1 uma distin\u00e7\u00e3o clara em pelo menos dois processos e se pensarmos no c\u00f3digo descrito acima, temos que entender que processos independentes n\u00e3o compartilham um espa\u00e7o de endere\u00e7amento, e processos independentes n\u00e3o compartilham uma pilha. Assim, como fica a passagem de par\u00e2metro por refer\u00eancia , uma vez que o stub servidor n\u00e3o pode usar endere\u00e7os do espa\u00e7o de endere\u00e7amento do cliente? Algumas abordagens para simular a passagem por refer\u00eancia s\u00e3o poss\u00edveis. Por exemplo, o valor apontado pelo ponteiro \u00e9 passado para o servidor , que armazena o valor e alguma posi\u00e7\u00e3o de mem\u00f3ria e passa o endere\u00e7o de tal posi\u00e7\u00e3o para a fun\u00e7\u00e3o invocada. Contudo, a modifica\u00e7\u00e3o do valor pela fun\u00e7\u00e3o n\u00e3o reflete imediatamente no invocador; tais valores tem que ser copiados novamente e usados para sobrescrever o valor original no cliente. Al\u00e9m disso, esta abordagem s\u00f3 \u00e9 poss\u00edvel se o valor apontado for delimitado, o que nem sempre \u00e9 f\u00e1cil de determinar. Por exemplo, se o ponteiro for para o primeiro elemento de uma lista, o que deve ser copiado para o servidor? S\u00f3 o primeiro elemento? Toda a lista? Como ensinar para o framework RPC o que \u00e9 \"toda\" a lista? Java \"resolve\" o problema da passagem de par\u00e2metro por refer\u00eancia passando todo o grafo do objeto passado como par\u00e2metro para o servidor. Isto \u00e9, al\u00e9m de serializar o objeto apontado no par\u00e2metro, se o mesmo aponta para outros objetos, estes tamb\u00e9m ser\u00e3o serializados e transferidos; o servidor ir\u00e1 ent\u00e3o reconstruir todo o grafo e passar para o m\u00e9todo sendo invocado. \u00c9 muito f\u00e1cil ver que esta abordagem pode se tornar invi\u00e1vel rapidamente. Quando for o caso, Java permite marcar objetos como remotos e, em vez de serializar este objeto e enviar para o servidor, envia informa\u00e7\u00e3o suficiente para que o servidor possa invocar m\u00e9todos em tal objeto no cliente, tornando nebulosa a defini\u00e7\u00e3o de quem \u00e9 quem. Outros fatores tamb\u00e9m trabalham contra a transpar\u00eancia para o desenvolvedor. Vejamos alguns Descoberta de Servi\u00e7os Por exemplo, mesmo que o socket seja ocultado, ele ainda existe e precisa de informa\u00e7\u00f5es sobre onde se conectar (endere\u00e7o e porta), que de alguma forma deve ser passada para o framework de RPC. Esta informa\u00e7\u00e3o pode ser configurada a priori por um administrador de sistemas, mas requer atualiza\u00e7\u00f5es sempre que a localiza\u00e7\u00e3o do servi\u00e7o for alterada ou novos servidores adicionados. Mais interessante seria um mecanismo que permitisse uma indire\u00e7\u00e3o para o servi\u00e7o; o pr\u00f3prio DNS pode ser uma op\u00e7\u00e3o inicial, mas um servi\u00e7o dedicado pode ser mais apropriado, pois permite descobrir servi\u00e7os e n\u00e3o apenas servidores. Birrel e Nelson propuseram um servi\u00e7o de P\u00e1ginas Amarelas , no qual clientes podem questionar quem oferece um certo servi\u00e7o e serem redirecionados automaticamente. Esta abordagem tem seus pr\u00f3prios problemas, como por exemplo determinar quem administra o servi\u00e7o para incluir novos servidores. E como determinar qual servi\u00e7o acessar, caso hajam m\u00faltiplas op\u00e7\u00f5es de servidores . Apesar dos problemas, p\u00e1ginas amarelas foram usadas em abordagens muito mais recentes para descobertas de servi\u00e7os, por exemplo Web Services Discovery , que permite a descoberta de Web Services em escala global, e Java Remote Object Registry que permite a descoberta de objetos remotos Java. Tratamento de Exce\u00e7\u00f5es Uma vez que a invoca\u00e7\u00e3o \u00e9 remota, h\u00e1 sempre o risco de problemas de comunica\u00e7\u00e3o entre cliente e servidor. Logo, \u00e9 necess\u00e1ria a introdu\u00e7\u00e3o de c\u00f3digo para tratamento de erros deste tipo, o que absolutamente n\u00e3o era necess\u00e1rio no caso do c\u00f3digo centralizado. Assim, o que era um simples x = substring(a,3,\"teste\"); passa para algo assim (em uma linguagem fict\u00edcia): 1 2 3 4 5 6 7 8 9 10 11 12 13 int x = -2 ; try { x = substring ( a , 3 , \"teste\" ); ` } catch ( CommunicationFailureException cfe ) { log_error ( \"Como pode substring falhar? Desespero!!!\" ); } if ( x == -2 ) system_exit ( -2 ) else if ( x == -1 ) //n\u00e3o achou else //achou \"teste\" na posi\u00e7\u00e3o x O que nos leva novamente ao ponto sobre n\u00e3o haver transpar\u00eancia total em sistemas distribu\u00eddos... e esta falta de transpar\u00eancia pode ser muito mais complicada do que simplesmente adicionar try e catch ao seu c\u00f3digo. Mais que isso, imagine que a opera\u00e7\u00e3o sendo executada altere algum estado no servidor. Se esta fosse uma operac\u00e3o local, cada invoca\u00e7\u00e3o da opera\u00e7\u00e3o corresponderia a exatamente uma execu\u00e7\u00e3o da opera\u00e7\u00e3o, na aus\u00eancia de falhas. No caso de falhas, se o processo quebra como um todo, no seu rein\u00edcio, pode-se identificar se a opera\u00e7\u00e3o foi ou n\u00e3o executada e aplicar a\u00e7\u00f5es corretivas. Mas e no caso remoto? Reexecu\u00e7\u00f5es No caso da opera\u00e7\u00e3o distribu\u00edda, se o servidor quebra, isso levar\u00e1 a um erro ser percebido do lado do cliente como uma falha na conex\u00e3o . Se o cliente havia invocado uma opera\u00e7\u00e3o mas percebeu o erro antes de receber uma confirma\u00e7\u00e3o de sua execu\u00e7\u00e3o, isto pode indicar que: (i) ou a requisi\u00e7\u00e3o nunca foi recebida pelo servidor e, portanto, n\u00e3o foi executada, (ii) ou a execu\u00e7\u00e3o foi recebida e executada, mas a resposta n\u00e3o foi enviada. O cliente tem que tratar o erro, mas como? Se a opera\u00e7\u00e3o precisa ser executada a qualquer custo , o cliente pode retent\u00e1-la quando conseguir novo contato com o servidor (ou mesmo com outro). Neste caso, se o que de fato aconteceu foi a situa\u00e7\u00e3o (i), ent\u00e3o retentar garantir\u00e1 que a opera\u00e7\u00e3o seja executada pelo servidor, mesmo que v\u00e1rias tentativas sejam necess\u00e1rias. Contudo, se o que o ocorreu foi a situa\u00e7\u00e3o (ii), ent\u00e3o reenviar a opera\u00e7\u00e3o levar\u00e1 a mesma a ser executada m\u00faltiplas vezes, o que pode ou n\u00e3o ser ok. Esta abordagem \u00e9 garantir\u00e1 que a execu\u00e7\u00e3o acontece pelo menos 1 vez . Imagine que a opera\u00e7\u00e3o se tratasse de uma transfer\u00eancia de saldo, ou a encomenda de de um caminh\u00e3o carregado de algum produto caro. Neste caso, reexecutar n\u00e3o parece ser uma op\u00e7\u00e3o. Neste caso, talvez a melhor op\u00e7\u00e3o seja n\u00e3o retentar a opera\u00e7\u00e3o, o que levar\u00e1 a zero execu\u00e7\u00f5es na situa\u00e7\u00e3o (ii) e uma execu\u00e7\u00e3o na situa\u00e7\u00e3o, ou seja, a no m\u00e1ximo uma execu\u00e7\u00e3o. Uma situa\u00e7\u00e3o em que esta abordagem \u00e9 claramente prefer\u00edvel \u00e9 a entrega de quadros em um stream de v\u00eddeo ou \u00e1udio, devido \u00e0 import\u00e2ncia da opera\u00e7\u00e3o ser atrelada ao momento de sua execu\u00e7\u00e3o. Nenhuma destas abordagens \u00e9 igual ao que \u00e9 garantido na vers\u00e3o centralizada e que \u00e9 provelmente o que todo desenvolvedor desejaria para suas invoca\u00e7\u00f5es de m\u00e9todos, que fossem executados exatamente uma vez. Garantir esta sem\u00e2ntica na comunica\u00e7\u00e3o \u00e9 muito dif\u00edcil, pois \u00e9 imposs\u00edvel ter certeza de que uma mensagem n\u00e3o foi processada pelo servidor ainda. De fato, \u00e9 imposs\u00edvel ter certeza se o servidor falhou; pode ter sido apenas uma falha na comunica\u00e7\u00e3o. Quantidade de execu\u00e7\u00f5es No m\u00e1ximo uma - n\u00e3o retentar Exatamente uma - impedir que falhas aconte\u00e7am :/ Pelo menos uma - retentar at\u00e9 ter confirma\u00e7\u00e3o Como \u00e9 imposs\u00edvel evitar falhas, se uma opera\u00e7\u00e3o deve executada, ela deve ser retentada. Mas ela n\u00e3o pode ser repetida, ent\u00e3o a alternativa \u00e9 tornar as opera\u00e7\u00f5es idempotentes , o que quer dizer que o efeito desejado \u00e9 alcan\u00e7ado pela primeira execu\u00e7\u00e3o e que execu\u00e7\u00f5es seguintes n\u00e3o alteram o estado. Opera\u00e7\u00f5es idempotentes M\u00faltiplas execu\u00e7\u00f5es tem o mesmo efeito uma execu\u00e7\u00e3o. Exemplo: x = 10 Anti-exemplo: x = x+1 . Infelizmente n\u00e3o \u00e9 trivial programar para idempot\u00eancia, principalmente se o servidor for acessado concorrentemente por m\u00faltiplos clientes, tornando seu estado uam regi\u00e3o cr\u00edtica. Concorr\u00eancia no servidor \u00c9 importante notar que um servidor n\u00e3o est\u00e1 obrigado a atender requisi\u00e7\u00f5es de somente um cliente. Logo, se m\u00faltiplos clientes acessam o mesmo servidor, o estado do servidor ser\u00e1 \"compartilhado\" pelos v\u00e1rios clientes e passos s\u00e3o necess\u00e1rios para que o comportamento no acesso deste estado seja coerente com a especifica\u00e7\u00e3o. Pense por exemplo em um servidor que conta o n\u00famero de acessos feitos por clientes. O incremento do contador deve ser considerado uma regi\u00e3o cr\u00edtica, caso m\u00faltiplos threads tratem as requisi\u00e7\u00f5es dos clientes, o que j\u00e1 vimos ser uma boa idia. Claro que dificilmente seu servidor seria algo t\u00e3o simples assim. Em vez disso, ele provavelmente executar\u00e1 l\u00f3gicas complicadas, como por exemplo, armazenar o estado de contas banc\u00e1rias e, neste caso, as fun\u00e7\u00f5es expostas por RPC incluir\u00edam a opera\u00e7\u00e3o transferir saldo de A para B , o que nos leva a mais um problema interessante, o do risco de reexecu\u00e7\u00f5es. Al\u00e9m disso, o servidor provavelmente suportar\u00e1 diversas opera\u00e7\u00f5es e por isso dever\u00e1 identificar qual a opera\u00e7\u00e3o sendo requisitada. Isto \u00e9 feito por um dispatcher , que demultiplexa as opera\u00e7\u00f5es requisitadas; o dispatcher pode, em algumas arquiteturas, ser independente do skeleton em si. Interface Definition Language - IDL H\u00e1 diversas op\u00e7\u00f5es de frameworks para RPC, com diferentes caracter\u00edsticas, focos, e garantias. Alguns s\u00e3o parte da linguagem e outros s\u00e3o implementados como bibliotecas. Alguns suportam m\u00faltiplas linguagens e alguns apenas uma. Suporte a RPC na linguagem Sem RPC: C, C++, Java < 5.0 (1.5), Python Com RPC: Java, Go, Erlang, Scala, Haskell Ambientes heterog\u00eaneos: Thrift, gRPC, Akka, SOAP Frameworks mais modernos permitem escolher a forma de serializa\u00e7\u00e3o dos dados, se leg\u00edvel para humanos ou bin\u00e1rio, se o transporte \u00e9 via HTTP ou protocolo mais baixo n\u00edvel, se os dados trafegam abertamente ou se faz uso de comunica\u00e7\u00e3o criptografada (SSL). Outros permitem escolher sem\u00e2ntica de execu\u00e7\u00e3o entre no m\u00e1ximo uma e pelo menos uma , e h\u00e1 at\u00e9 quem prometa exatamente uma . Mas todos os frameworks tem algumas caracter\u00edsticas em comum e uma delas \u00e9 o uso de uma Linguagem de Defini\u00e7\u00e3o de Interface (IDL). Uma IDL \u00e9 a linguagem pela qual desenvolvedor define quais as opera\u00e7\u00f5es (fun\u00e7\u00f5es, procedimentos, m\u00e9todos) ser\u00e3o acess\u00edveis via RPC e quais os seus operandos. H\u00e1 v\u00e1rias IDL definidas, para os diversos frameworks dispon\u00edveis. A imagem a seguir mostra um exemplo gen\u00e9rico da cria\u00e7\u00e3o cliente e servidor usando um framework RPC gen\u00e9rico, inclusive o processamento da defini\u00e7\u00e3o feita em IDL do servi\u00e7o e a jun\u00e7\u00e3o deste c\u00f3digo gerado ao c\u00f3digo escrito pelo desenvolvedor. O fluxo de processamento \u00e9 o seguinte: Arquivo em IDL \u00e9 compilado por um compilador IDL e gera diversos arquivos: stub cliente - c\u00f3digo que implementa a interface, com c\u00f3digo para repassar invoca\u00e7\u00f5es para o servidor. stub servidor ( skeleton ) - c\u00f3digo que atende a conex\u00f5es do stub cliente e repassa para a implementa\u00e7\u00e3o pr\u00f3pria da fun\u00e7\u00e3o. convers\u00e3o de dados - c\u00f3digo que serializa e deserializa dados para serem trafegados de e para o servidor cabe\u00e7alhos - defini\u00e7\u00f5es da interface na linguagem de desenvolvimento da aplica\u00e7\u00e3o; se linguagem C, por exemplo, estes ser\u00e3o arquivos .h , se em Java, ent\u00e3o estes ser\u00e3o arquivos .java , com defini\u00e7\u00e3o de interface . O c\u00f3digo cliente \u00e9 compilado e gera o cliente, que deve inicializar a infraestrutura RPC Tipo de transporte SSL? Localizar servidor Lidar com falhas O c\u00f3digo servidor \u00e9 compilado e gera o servidor, que deve exportar e localizar servi\u00e7os (servi\u00e7o de nomea\u00e7\u00e3o) Gerenciamento de portas Conex\u00f5es Mas para entendermos melhor o fluxo, vejamos algumas ferramentas reais. Estudo de Caso RPC: gRPC gRPC \u00e9 um framework para invoca\u00e7\u00e3o remota de procedimentos multi-linguagem e sistema operacional, usando internamente pelo Google h\u00e1 v\u00e1rios anos para implementar sua arquitetura de micro-servi\u00e7os. Inicialmente desenvolvido pelo Google, o gRPC \u00e9 hoje de c\u00f3digo livre encubado pela Cloud Native Computing Foundation. O s\u00edtio gRPC.io documenta muito bem o gRPC, inclusive os princ\u00edpios que nortearam seu projeto. O seu uso segue, em linhas gerais, o modelo discutido nas se\u00e7\u00f5es anteriores, isto \u00e9, inicia-se pela defini\u00e7\u00e3o de estruturas de dados e servi\u00e7os, \"compila-se\" a defini\u00e7\u00e3o para gerar stubs na linguagem desejada, e compila-se os stubs juntamente com os c\u00f3digos cliente e servidor para gerar os bin\u00e1rios correspondentes. Vejamos a seguir um tutorial passo a passo, em Java, baseado no quickstart guide . Instala\u00e7\u00e3o Os procedimentos de instala\u00e7\u00e3o dependem da linguagem em que pretende usar o gRPC, tanto para cliente quanto para servidor. No caso do Java , n\u00e3o h\u00e1 instala\u00e7\u00e3o propriamente dita . Exemplo Java Observe que o reposit\u00f3rio base apontado no tutorial serve de exemplo para diversas linguagens e diversos servi\u00e7os, ent\u00e3o sua estrutura \u00e9 meio complicada. N\u00f3s nos focaremos aqui no exemplo mais simples, uma esp\u00e9cie de \"hello word\" do RPC. Pegando o c\u00f3digo Para usar os exemplos, voc\u00ea precisa clonar o reposit\u00f3rio com o tutorial, usando o comando a seguir. 1 git clone -b v1.33.0 https://github.com/grpc/grpc-java Uma vez clonado, entre na pasta de exemplo do Java e certifique-se que est\u00e1 na vers\u00e3o 1.33, usada neste tutorial. 1 2 cd grpc-java \\e xamples git checkout v1.33.0 Compilando e executando O projeto usa gradle para gerenciar as depend\u00eancias. Para, use o wrapper do gradle como se segue. 1 ./gradlew installDist Caso esteja na UFU, coloque tamb\u00e9m informa\u00e7\u00e3o sobre o proxy no comando. 1 ./gradlew -Dhttp.proxyHost = proxy.ufu.br -Dhttp.proxyPort = 3128 -Dhttps.proxyHost = proxy.ufu.br -Dhttps.proxyPort = 3128 installDist Como quando usamos sockets diretamente, para usar o servi\u00e7o definido neste exemplo, primeiros temos que executar o servidor. 1 ./build/install/examples/bin/hello-world-server Agora, em um terminal distinto e a partir da mesma localiza\u00e7\u00e3o, execute o cliente, quantas vezes quiser. 1 ./build/install/examples/bin/hello-world-client O servi\u00e7o O exemplo n\u00e3o \u00e9 muito excitante, pois tudo o que o servi\u00e7o faz \u00e9 enviar uma sauda\u00e7\u00e3o aos clientes. O servi\u00e7o \u00e9 definido no seguinte arquivo .proto , localizado em ./src/main/proto/helloworld.proto . 1 2 3 4 5 6 7 8 9 10 11 12 13 message HelloRequest { string name = 1; } message HelloReply { string message = 1; } // The greeting service definition. service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {} } No arquivo, inicialmente s\u00e3o definidas duas mensagens, usadas como requisi\u00e7\u00e3o (cliente para servidor) e outra como resposta (servidor para cliente) do servi\u00e7o definido em seguida. A mensagem HelloRequest tem apenas um campo denominado name , do tipo string . Esta mensagem conter\u00e1 o nome do cliente, usado na resposta gerada pelo servidor. A mensagem HelloReply tamb\u00e9m tem um campo do tipo string , denominado message , que conter\u00e1 a resposta do servidor. O servi\u00e7o dispon\u00edvel \u00e9 definido pela palavra chave service e de nome Greeter ; \u00e9 importante entender que este nome ser\u00e1 usado em todo o c\u00f3digo gerado pelo compilador gRPC e que se for mudado, todas as refer\u00eancias ao c\u00f3digo gerado devem ser atualizadas. O servi\u00e7o possui apenas uma opera\u00e7\u00e3o, SayHello , que recebe como entrada uma mensagem HelloRequest e gera como resposta uma mensagem HelloReply . Caso a opera\u00e7\u00e3o precisasse de mais do que o conte\u00fado de name para executar, a mensagem HelloRequest deveria ser estendida, pois n\u00e3o h\u00e1 passar mais de uma mensagem para a opera\u00e7\u00e3o. Por outro lado, embora seja poss\u00edvel passar zero mensagens, esta n\u00e3o \u00e9 uma pr\u00e1tica recomendada. Isto porqu\u00ea caso o servi\u00e7o precisasse ser modificado no futuro, embora seja poss\u00edvel estender uma mensagem, n\u00e3o \u00e9 poss\u00edvel modificar a assinatura do servi\u00e7o. Assim, caso n\u00e3o haja a necessidade de se passar qualquer informa\u00e7\u00e3o para a opera\u00e7\u00e3o, recomenda-se que seja usada uma mensagem de entrada vazia, que poderia ser estendida no futuro. O mesmo se aplica ao resultado da opera\u00e7\u00e3o. Observe tamb\u00e9m que embora o servi\u00e7o de exemplo tenha apenas uma opera\u00e7\u00e3o, poderia ter m\u00faltiplas. Por exemplo, para definir uma vers\u00e3o em portugu\u00eas da opera\u00e7\u00e3o SayHello , podemos fazer da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 message HelloRequest { string name = 1 ; } message HelloReply { string message = 1 ; } message OlaRequest { // <<<<<==== string name = 1 ; } message OlaReply { // <<<<<==== string message = 1 ; } service Greeter { rpc SayHello ( HelloRequest ) returns ( HelloReply ) {} rpc DigaOla ( OlaRequest ) returns ( OlaReply ) {} // <<<<<==== } ... Observe que a nova opera\u00e7\u00e3o recebe como entrada mensagens OlaRequest e OlaReply , que tem defini\u00e7\u00f5es exatamente iguais a HellorRequest e HelloReply . Logo, em vez de definir novas mensagens, poder\u00edamos ter usado as j\u00e1 definidas. Novamente, esta n\u00e3o \u00e9 uma boa pr\u00e1tica, pois caso fosse necess\u00e1rio evoluir uma das opera\u00e7\u00f5es para atender a novos requisitos e estender suas mensagens, n\u00e3o ser\u00e1 necess\u00e1rio tocar o restante do servi\u00e7o. Apenas refor\u00e7ando, \u00e9 boa pr\u00e1tica definir requests e responses para cada m\u00e9todo, a n\u00e3o ser que n\u00e3o haja d\u00favida de que ser\u00e3o para sempre iguais. Implementando um servi\u00e7o Agora modifique o arquivo .proto como acima, para incluir a opera\u00e7\u00e3o DigaOla , recompile e reexecute o servi\u00e7o. N\u00e3o d\u00e1 certo, n\u00e3o \u00e9 mesmo? Isto porqu\u00ea voc\u00ea adicionou a defini\u00e7\u00e3o de uma nova opera\u00e7\u00e3o, mas n\u00e3o incluiu o c\u00f3digo para implement\u00e1-la. Fa\u00e7amos ent\u00e3o a modifica\u00e7\u00e3o do c\u00f3digo, come\u00e7ando por ./src/main/java/io/grpc/examples/helloworld/HelloWorldServer.java . Este arquivo define a classe que implementa o servi\u00e7o Greeter , GreeterImpl , com um m\u00e9todo para cada uma das opera\u00e7\u00f5es definidas. Para confirmar, procure por sayHello para encontrar a implementa\u00e7\u00e3o de SayHello ; observe que a diferen\u00e7a do casing vem das boas pr\u00e1ticas de Java, de definir m\u00e9todos e vari\u00e1veis em Camel casing . Para que sua vers\u00e3o estendida do servi\u00e7o Greeter funcione, defina um m\u00e9todo correspondendo \u00e0 DigaOla , sem consultar o c\u00f3digo exemplo abaixo, mas usando o c\u00f3digo de sayHello como base; n\u00e3o se importe por enquanto com os m\u00e9todos sendo invocados. Note que os ... indicam que parte do c\u00f3digo, que n\u00e3o sofreu modifica\u00e7\u00f5es, foi omitido. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... private class GreeterImpl extends GreeterGrpc . GreeterImplBase { ... @Override public void sayHello ( HelloRequest req , StreamObserver < HelloReply > responseObserver ) { ... } @Override public void digaOla ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( \"Ola \" + req . getName ()). build (); responseObserver . onNext ( reply ); responseObserver . onCompleted (); } } Se voc\u00ea recompilar e reexecutar o c\u00f3digo, n\u00e3o perceber\u00e1 qualquer mudan\u00e7a na sa\u00edda do programa. Isto porqu\u00ea embora tenha definido um novo servi\u00e7o, voc\u00ea n\u00e3o o utilizou. Para tanto, agora modifique o cliente, em src/main/java/io/grpc/examples/helloworld/HelloWorldClient.java , novamente se baseando no c\u00f3digo existente e n\u00e3o se preocupando com \"detalhes\". 1 2 3 4 5 6 7 8 9 10 11 12 13 public void greet ( String name ) { logger . info ( \"Will try to greet \" + name + \" ...\" ); ... OlaRequest request2 = OlaRequest . newBuilder (). setName ( name ). build (); OlaReply response2 ; try { response2 = blockingStub . digaOla ( request2 ); } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } logger . info ( \"Greeting: \" + response2 . getMessage ()); } Agora sim, voc\u00ea pode reexecutar cliente e servidor. 1 2 3 ./gradlew installDist ./build/install/examples/bin/hello-world-server & ./build/install/examples/bin/hello-world-client Percebeu como foi f\u00e1cil adicionar uma opera\u00e7\u00e3o ao servi\u00e7o? Agora nos foquemos nos detalhes. Stub do servidor Como criar o servidor Como definir o servi\u00e7o Como \"startar\" o servidor. Stub do cliente Stub bloqueante Stub n\u00e3o bloqueante IDL gRPC Outras caracter\u00edsticas da IDL do gRPC Tipos b\u00e1sicos bool: boolean (true/false) double: 64-bit; ponto-flutuante float: 32-bit; ponto-flutuante i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado siXX: signed uiXX: unsigned sfixedXX: codifica\u00e7\u00e3o de tamanho fixo bytes: 8-bit; inteiro sinalizado string: string UTF-8 ou ASCII 7-bit Any: tipo indefinido Diferentes tradu\u00e7\u00f5es Cole\u00e7\u00f5es Defina e implemente uma opera\u00e7\u00e3o DigaOlas em que uma lista de nomes \u00e9 enviada ao servidor e tal que o servidor responda com uma longa string cumprimentando todos os nomes, um ap;os o outro. Streams Do lado do servidor 1 2 3 4 5 6 7 8 9 10 11 List < String > listOfHi = Arrays . asList ( \"e aih\" , \"ola\" , \"ciao\" , \"bao\" , \"howdy\" , \"s'up\" ); @Override public void digaOlas ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { for ( String hi : listOfHi ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( hi + \", \" req . getName ()). build (); responseObserver . onNext ( reply ); } responseObserver . onCompleted (); } Do lado do cliente 1 2 3 4 5 6 7 8 9 10 11 OlaRequest request = OlaRequest . newBuilder (). setName ( name ). build (); try { Iterator < OlaReply > it = blockingStub . digaOlas ( request ); while ( it . hasNext ()){ OlaReply response = it . next (); logger . info ( \"Greeting: \" + response . getMessage ()); } } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } Exemplo Python 1 2 3 4 5 6 7 8 9 10 apt-get install python3 apt-get install python3-pip python3 -m pip install --upgrade pip python3 -m pip install grpcio python3 -m pip install grpcio-tools git clone -b v1.10.x https://github.com/grpc/grpc cd grpc/examples/python/helloworld python3 greeter \\_ server.py python3 greeter \\_ client.py Para recompilar os stubs, fa\u00e7a 1 python3 -m grpc_tools.protoc -I../../protos --python_out = . --grpc_python_out = . ../../protos/helloworld.proto Modifique o servidor 1 2 def DigaOla ( self , request , context ): return helloworld_pb2 . OlaReply ( message = 'Ola, %s !' + request . name ) Modifique o cliente 1 2 response = stub . DigaOla ( helloworld_pb2 . OlaRequest ( name = 'zelelele' )) print ( \"Greeter client received: \" + response . message ) Estudo de Caso RPC: Thrift Thrift Instala\u00e7\u00e3o Baixe e compile o thrift ou instale-o usando apt-get, por exemplo. apt-get install thrift-compiler execute \"thrift\" na linha de comando. Para thrift com Java, tamb\u00e9m precisar\u00e3o dos seguintes arquivos slf4j libthrift0.13.0.jar coloque-os na pasta jars IDL Thrift Tipos b\u00e1sicos bool: boolean (true/false) byte: 8-bit; inteiro sinalizado i16: 16-bit; inteiro sinalizado i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado double: 64-bit; ponto-flutuante string: string UTF-8 binary: sequ\u00eancia de bytes Estruturas 1 2 3 4 5 6 struct Example { 1 : i32 number , 2 : i64 bigNumber , 3 : double decimals , 4 : string name = \"thrifty\" } Servi\u00e7os 1 2 3 4 5 service ChaveValor { void set ( 1 : i32 key , 2 : string value ), string get ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), void delete ( 1 : i32 key ) } N\u00e3o se pode retornar NULL!!! Exce\u00e7\u00f5es 1 2 3 4 exception KeyNotFound { 1 : i64 hora r , 2 : string chaveProcurada = \"thrifty\" } Containers List Map Set Exemplo: chavevalor.thrift 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } Compila\u00e7\u00e3o thrift --gen java chavevalor.thrift thrift --gen py chavevalor.thrift ChaveValorHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } package chavevalor ; import org.apache.thrift.TException ; import java.util.HashMap ; import chavevalor.* ; public class ChaveValorHandler implements ChaveValor . Iface { private HashMap < Integer , String > kv = new HashMap <> (); @Override public String getKV ( int key ) throws TException { if ( kv . containsKey ( key )) return kv . get ( key ); else throw new KeyNotFound (); } @Override public boolean setKV ( int key , String valor ) throws TException { kv . put ( key , valor ); return true ; } @Override public void delKV ( int key ) throws TException { kv . remove ( key ); } } Arquitetura Runtime library -- componentes podem ser selecionados em tempo de execu\u00e7\u00e3o e implementa\u00e7\u00f5es podem ser trocadas Protocol -- respons\u00e1vel pela serializa\u00e7\u00e3oo dos dados TBinaryProtocol TJSONProtocol TDebugProtocol ... Transport -- I/O no ``fio'' TSocket TFramedTransport (non-blocking server) TFileTransport TMemoryTransport Processor -- Conecta protocolos de entrada e sa\u00edda com o \\emph{handler} Handler -- Implementa\u00e7\u00e3o das opera\u00e7\u00f5es oferecidas Server -- Escuta portas e repassa dados (protocolo) para o processors TSimpleServer TThreadPool TNonBlockingChannel Classpath 1 2 3 javac -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java -d . *.java java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorServer java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorClient Refer\u00eancias Tutorial Estudo de Caso RPC: RMI TODO Como usar RMI. Comunica\u00e7\u00e3o orientada a Mensagens TODO MOM Enterprise Message Bus To Message Bus or Not: distributed system design O foco aqui \u00e9 na descri\u00e7\u00e3o da tecnologia, mas n\u00e3o das arquiteturas resultantes, que ser\u00e3o vistas no cap\u00edtulo seguinte. Publish/Subscribe O padr\u00e3o publish/subscribe (ou pub/sub ) se apresenta como uma alternativa \u00e0 arquitetura cliente-servidor. Enquanto no modelo client-servidor, o cliente se comunica diretamente com um endpoint representado pelo servidor, no padr\u00e3o pub/sub temos clientes que enviam mensagens, ou publishers , e clientes que recebem as mensagens, ou subscribers . Esses dois tipos de clientes nunca se comunicam diretamente e n\u00e3o precisam nem saber da exist\u00eancia do outro. Um agente especial, denominado broker , gerencia a conex\u00e3o, armazena e filtrando as mensagens, al\u00e9m de distribu\u00ed-las corretamente aos subscribers . Desacoplamento Um dos aspectos mais importantes proporciados pelo padr\u00e3o pub/sub \u00e9 o desacoplamento entre as partes envolvidas, o qual ocorre em v\u00e1rias dimens\u00f5es: Espa\u00e7o: publishers e subscribers n\u00e3o precisam se conhecer (por exemplo, n\u00e3o h\u00e1 necessidade de informar endere\u00e7o IP e porta de cada um). Tempo: publishers e subscribers n\u00e3o precisam nem estar em execu\u00e7\u00e3o ao mesmo tempo. Sincroniza\u00e7\u00e3o: opera\u00e7\u00f5es em cada componente n\u00e3o precisa ser interrompida durante a publica\u00e7\u00e3o ou recebimento. Filtragem O broker tem um papel fundamental pois permite a especifica\u00e7\u00e3o de diversos n\u00edveis de filtragem: Baseada em assunto: subscribers se registram para receber mensagens de um ou mais t\u00f3picos de interesse. Em geral esses t\u00f3picos s\u00e3o strings com um formato hier\u00e1rquico, por exemplo /devices/sensor/+/temperature . Baseada em conte\u00fado: baseada em linguagem de filtragem de conte\u00fado espec\u00edfica. Downside: mensagem n\u00e3o pode ser criptografada. Baseada em tipo: leva em considera\u00e7\u00e3o o tipo ou classe de uma mensagem ou evento, como o tipo Exception e subtipos, por exemplo. MQTT MQTT \u00e9 um protocolo de transporte para publish/subscribe do tipo cliente-servidor. \u00c9 leve, aberto e f\u00e1cil de implementar, ideal para comunica\u00e7\u00e3o Machine to Machine (M2M) e uso no contexto de Internet das Coisas ( Internet of Things - I0T ). MQTT is a very light weight and binary protocol, and due to its minimal packet overhead, MQTT excels when transferring data over the wire in comparison to protocols like HTTP. Another important aspect of the protocol is that MQTT is extremely easy to implement on the client side. Ease of use was a key concern in the development of MQTT and makes it a perfect fit for constrained devices with limited resources today. O padr\u00e3o \u00e9 definido pela OASIS, uma organiza\u00e7\u00e3o aberta respons\u00e1vel por padr\u00f5es como SAML e DocBook. A especifica\u00e7\u00e3o atual \u00e9 a de n\u00famero 5, lan\u00e7ada em mar\u00e7o de 2019. Refer\u00eancia MQTT Essentials Estudo de caso: MosQuiTTo Eclipse Mosquitto is an open source (EPL/EDL licensed) message broker that implements the MQTT protocol versions 5.0, 3.1.1 and 3.1. Mosquitto is lightweight and is suitable for use on all devices from low power single board computers to full servers. Instala\u00e7\u00e3o 1 2 apt-get install mosquitto # Ubuntu brew install mosquitto # MacOS Inicializando o servi\u00e7o O arquivo mosquito.conf cont\u00e9m as configura\u00e7\u00f5es para o broker . As configura\u00e7\u00f5es funcionam bem para o nosso caso. O broker aceita requisi\u00e7\u00f5es na porta 1883 e publishers e subscribers tamb\u00e9m utilizam essa porta por padr\u00e3o. Basta iniciar o broker com a op\u00e7\u00e3o -v para ter mais detalhes sobre o que ocorre internamente. 1 mosquitto -v Publicando Para publicar uma mensagem, o publisher deve indicar um host, porta, t\u00f3pico e mensagem. Caso o host e porta sejam omitidos, assume-se localhost:1883 . 1 2 3 # publicando valor de 40 para t\u00f3picos 'sensor/temperature/1' e 'sensor/temperature/2' mosquitto_pub -t sensor/temperature/1 -m 40 mosquitto_pub -t sensor/temperature/2 -m 32 Caso o subscriber n\u00e3o esteja em execu\u00e7\u00e3o, adicione a op\u00e7\u00e3o -r para que o broker retenha a mensagem. Consumindo O consumidor funciona de maneira semelhante, informando o t\u00f3pico de interesse: 1 2 # consumindo mensagens de t\u00f3pico /sensor/temperature/* mosquito_pub -t sensor/temperature/+ Programando Existem tamb\u00e9m APIs em diversas linguagem para desenvolvimento de aplica\u00e7\u00f5es que utilizem o Mosquitto. A biblioteca pode ser baixada aqui . Exemplo de Publisher 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import org.eclipse.paho.client.mqttv3.MqttClient ; import org.eclipse.paho.client.mqttv3.MqttConnectOptions ; import org.eclipse.paho.client.mqttv3.MqttException ; import org.eclipse.paho.client.mqttv3.MqttMessage ; import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence ; public class MqttPublishSample { public static void main ( String [] args ) { String topic = \"MQTT Examples\" ; String content = \"Message from MqttPublishSample\" ; int qos = 2 ; String broker = \"tcp://mqtt.eclipse.org:1883\" ; String clientId = \"JavaSample\" ; MemoryPersistence persistence = new MemoryPersistence (); try { MqttClient sampleClient = new MqttClient ( broker , clientId , persistence ); MqttConnectOptions connOpts = new MqttConnectOptions (); connOpts . setCleanSession ( true ); System . out . println ( \"Connecting to broker: \" + broker ); sampleClient . connect ( connOpts ); System . out . println ( \"Connected\" ); System . out . println ( \"Publishing message: \" + content ); MqttMessage message = new MqttMessage ( content . getBytes ()); message . setQos ( qos ); sampleClient . publish ( topic , message ); System . out . println ( \"Message published\" ); sampleClient . disconnect (); System . out . println ( \"Disconnected\" ); System . exit ( 0 ); } catch ( MqttException me ) { System . out . println ( \"reason \" + me . getReasonCode ()); System . out . println ( \"msg \" + me . getMessage ()); System . out . println ( \"loc \" + me . getLocalizedMessage ()); System . out . println ( \"cause \" + me . getCause ()); System . out . println ( \"excep \" + me ); me . printStackTrace (); } } } TODO Diferenciar de MOM Exerc\u00edcios - RPC e Publish/Subscribe Usando thrift e a linguagem Java, extenda o servi\u00e7o ChaveValor para retornar o valor antigo de uma determinada chave na opera\u00e7\u00e3o setKV() caso a chave j\u00e1 exista. Usando o broker mosquitto instalado localmente, fa\u00e7a em Java um publisher que simula um sensor de temperatura e publica valores aleat\u00f3rios entre 15 e 45 a cada segundo. Fa\u00e7a o subscriber que ir\u00e1 consumir esses dados de temperatura. Message Passing Interface Para facilitar a comunica\u00e7\u00e3o entre as partes do dom\u00ednio, s\u00e3o normalmente utilizadas API como a Message Passing Interface (MPI), que prov\u00ea fun\u00e7\u00f5es para distribui\u00e7\u00e3o e agrega\u00e7\u00e3o de dados entre os v\u00e1rios processos. A fun\u00e7\u00e3o broadcast, por exemplo, envia o mesmo conte\u00fado para diversos destinat\u00e1rios e a fun\u00e7\u00e3o scatter particiona o dado de acordo com o n\u00famero de destinat\u00e1rios e envia uma parcela para cada um. Protocolos Epid\u00eamicos Distributed Systems: Principles and Paradigms. Cap\u00edtulo 1, Figura 1. \u21a9 IEEE Floating Point \u21a9 IBM Floating Point \u21a9 Simplifica\u00e7\u00f5es s\u00e3o poss\u00edveis, mas introduzem outras complexidades. \u21a9 O Google stadia \u00e9 uma plataforma de jogos que vai na contram\u00e3o desta ideia, levando todo o processamento pesado para a nuvem. \u21a9 Implementing RPC \u21a9 Omitirei alguns detalhes aqui, em nome da generalidade, mas voc\u00eas podem recuper\u00e1-los em seus livros de Arquitetura de Computadores. \u21a9 O stub do servidor tamb\u00e9m \u00e9 conhecido como skeleton . \u21a9 Marshalling: representar par\u00e2metros de forma pr\u00f3pria para transmiss\u00e3o \"no fio\". \u21a9","title":"Comunica\u00e7\u00e3o"},{"location":"comm/#comunicacao","text":"O desenvolvimento de sistemas distribu\u00eddos usando diretamente Sockets como forma de comunica\u00e7\u00e3o entre componentes n\u00e3o \u00e9 para os fracos de cora\u00e7\u00e3o. Sua grande vantagem est\u00e1 no acesso baixo n\u00edvel \u00e0 rede , e todo o ganho de desempenho que isso pode trazer. Suas desvantagens, entretanto, s\u00e3o v\u00e1rias: interface de \"arquivo\" para se ler e escrever bytes; controle de fluxo de \"objetos\" \u00e9 por conta da aplica\u00e7\u00e3o, isto \u00e9, a aplica\u00e7\u00e3o precisa sinalizar quantos bytes ser\u00e3o escritos de um lado, para que o outro saiba quanto ler para obter um \"objeto\" correto; logo, a serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o de objetos \u00e9 tamb\u00e9m por conta da aplica\u00e7\u00e3o; tratamento de desconex\u00f5es e eventuais reconex\u00f5es tamb\u00e9m \u00e9 gerenciado pela aplica\u00e7\u00e3o e nem a t\u00e3o famosa confiabilidade do TCP ajuda. Enquanto se poderia argumentar que algumas destas desvantagens podem ser descartadas em fun\u00e7\u00e3o da discuss\u00e3o de incluir ou n\u00e3o API na comunica\u00e7\u00e3o fim-a-fim , \u00e9 certo que algumas funcionalidades s\u00e3o ub\u00edquas em aplica\u00e7\u00f5es distribu\u00eddas. Aqui discutiremos algumas destas funcionalidades e como podem e s\u00e3o implementadas por frameworks de comunica\u00e7\u00e3o de mais alto n\u00edvel. No mundo dos sistemas distribu\u00eddos, estes frameworks s\u00e3o conhecidos como middleware .","title":"Comunica\u00e7\u00e3o"},{"location":"comm/#middleware","text":"Middleware software hardware/OS aplica\u00e7\u00e3o diversas funcionalidades De acordo com Tanenbaum & Van Steen , middleware \u00e9 ... the software layer that lies between the operating system and applications on each side of a distributed computing system in a network. Isto \u00e9, o middleware \u00e9 a camada ware que fica no middle , entre, o software e o hardware . Software, no caso, \u00e9 a aplica\u00e7\u00e3o distribu\u00edda sendo desenvolvida e hardware \u00e9 a abstra\u00e7\u00e3o do host em que se executam os componentes, provida pelo sistema operacional. Uso aqui o termo abstra\u00e7\u00e3o porqu\u00ea o sistema operacional pode encapsular hardware real, mas tamb\u00e9m pode encapsular outra abstra\u00e7\u00e3o de hardware , por exemplo, uma m\u00e1quina virtual ou cont\u00eainer. A figura seguinte mostra um exemplo com tr\u00eas aplica\u00e7\u00f5es executando sobre um middleware , que por sua vez \u00e9 executado sobre diferentes sistemas operacionais, em hosts conectados por uma rede de comunica\u00e7\u00e3o. 1 Com este cen\u00e1rio em mente, \u00e9 importante entender o que diz Sacha Krakowiak quando afirma que as principais fun\u00e7\u00f5es do middleware s\u00e3o: esconder a distribui\u00e7\u00e3o e o fato de que um aplica\u00e7\u00e3o \u00e9 geralmente composta por m\u00faltiplas partes, executando em localiza\u00e7\u00f5es geograficamente distintas, esconder a heterogeneidade dos v\u00e1rios componentes de hardware, sistemas operacionais e protocolos de comunica\u00e7\u00e3o prover interfaces uniformes, de alto n\u00edvel e padronizadas para os desenvolvedores de aplica\u00e7\u00e3o e integradores, de forma que aplica\u00e7\u00f5es possam ser facilmente compostas, reusadas, portadas e feitas interoper\u00e1veis. Assim, os middleware facilitam a conex\u00e3o entre componentes e permitem o uso de protocolos mais abstratos que as opera\u00e7\u00f5es de write(byte[]) e read(): byte[] dos protocolos de baixo n\u00edvel, escondendo a complexidade da coordena\u00e7\u00e3o de sistemas independentes. Desenvolver sistemas distribu\u00eddos sem usar um middleware \u00e9 como desenvolver um aplicativo sem usar quaisquer bibliotecas: poss\u00edvel, mas complicado, e estar\u00e1 certamente reinventando a roda. Isto \u00e9, voc\u00ea praticamente tem que refazer o middleware antes de desenvolver o sistema em si. Idealmente, com o middleware , o desenvolvedor conseguiria facilmente implementar uma aplica\u00e7\u00e3o em que a distribui\u00e7\u00e3o fosse totalmente transparente, levando o sistema, uma cole\u00e7\u00e3o de sistemas computacionais (software ou hardware) independentes, a se apresentar para o usu\u00e1rio como um sistema \u00fanico , monol\u00edtico. Pense no browser e na WWW, por exemplo: o quanto voc\u00ea sabe sobre as p\u00e1ginas estarem particionadas em milh\u00f5es de servidores? Isso \u00e9 o que chamamos de transpar\u00eancia .","title":"Middleware"},{"location":"comm/#transparencia","text":"Transpar\u00eancia Total Acesso + Localiza\u00e7\u00e3o + Reloca\u00e7\u00e3o + Migra\u00e7\u00e3o + Replica\u00e7\u00e3o + Falha Se n\u00e3o h\u00e1 qualquer ind\u00edcio de que a aplica\u00e7\u00e3o \u00e9 distribu\u00edda, ent\u00e3o temos transpar\u00eancia total . Podemos quebrar esta transpar\u00eancia total em v\u00e1rias transpar\u00eancias mais simples: Acesso , Localiza\u00e7\u00e3o , Reloca\u00e7\u00e3o , Migra\u00e7\u00e3o , Replica\u00e7\u00e3o , e Falha . Vejamos cada uma destas separadamente.","title":"Transpar\u00eancia"},{"location":"comm/#transparencia-de-acesso","text":"Transpar\u00eancia de Acesso como se apresenta representa\u00e7\u00e3o de dados arquitetura OS linguagem padr\u00f5es abertos e bem conhecidos. A transpar\u00eancia de acesso diz respeito \u00e0 representa\u00e7\u00e3o de dados e mecanismos de invoca\u00e7\u00e3o (arquitetura, formatos, linguagens...). Cada computador tem uma arquitetura e uma forma de representar seus dados. Por exemplo, considere os padr\u00f5es para representa\u00e7\u00e3o de n\u00fameros em ponto flutuante IEEE e IBM. Ambos dividem os bits em sinal, expoente e mantissa, mas com tamanhos diferentes. IEEE 2 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Half 16 1 5 10 Single 32 1 8 23 Double 64 1 11 52 Quadruple 128 1 15 112 IBM 3 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Single 32 1 7 24 Double 64 1 7 56 Quadruple 128 1 7 112 (8b ignorados) E se dois componentes de um SD executam em m\u00e1quinas com arquiteturas diferentes, como trocam n\u00fameros em ponto flutuante? \u00c9 preciso que usem um padr\u00e3o conhecido por ambos os hosts , seja o padr\u00e3o a arquitetura \"nativa\" do host ou um padr\u00e3o intermedi\u00e1rio, definido pelo middleware . A mesma quest\u00e3o \u00e9 v\u00e1lida para representa\u00e7\u00f5es de strings e classes, e diferen\u00e7as de sistemas operacionais e linguagens. No caso espec\u00edfico das strings, pense em um programa escrito em linguagem C e que este programa deva comunicar-se com um outro, escrito em Java, e trocar strings com o mesmo. Enquanto em C uma string \u00e9 uma sequ\u00eancia de bytes imprim\u00edveis terminadas por um \\0 , em Java uma string \u00e9 uma classe que encapsula uma sequ\u00eancia de chars, sendo que cada char \u00e9 um c\u00f3digo 16 bits representativo de um c\u00f3digo Unicode 4 . Como transferir strings entre duas plataformas? N\u00e3o faz\u00ea-lo? Simplificar a string Java? Estender a string C? Para se tentar obter transpar\u00eancia de acesso, \u00e9 importante que se use padr\u00f5es implementados em m\u00faltiplas arquiteturas, abertos e bem conhecidos, com interfaces bem definidas .","title":"Transpar\u00eancia de Acesso"},{"location":"comm/#transparencia-de-localizacao","text":"Transpar\u00eancia de localiza\u00e7\u00e3o onde est\u00e1 o objeto lat\u00eancia cache paralelismo programa\u00e7\u00e3o ass\u00edncrona arquiteturas reativas A transpar\u00eancia de localiza\u00e7\u00e3o diz respeito a onde est\u00e1 o objeto acessado pela aplica\u00e7\u00e3o, seja um BD, p\u00e1gina Web ou servi\u00e7o de echo: pouco importa ao usu\u00e1rio, se est\u00e1 dentro da mesma m\u00e1quina de onde executa o acesso, se na sala ao lado ou em um servidor do outro lado do globo, desde que o servi\u00e7o seja provido de forma r\u00e1pida e confi\u00e1vel. A esta transpar\u00eancia \u00e9 essencial uma boa distribui\u00e7\u00e3o do servi\u00e7o, sobre uma rede com baixa lat\u00eancia, ou o uso de t\u00e9cnicas que permitam esconder a lat\u00eancia.","title":"Transpar\u00eancia de Localiza\u00e7\u00e3o"},{"location":"comm/#transparencia-de-relocacao","text":"Transpar\u00eancia de reloca\u00e7\u00e3o como se movimenta visto por clientes As vezes componentes do sistema distribu\u00eddo precisam ser movimentados de uma localiza\u00e7\u00e3o \u00e0 outra, por exemplo porqu\u00ea um novo host foi contratado. Se implementadas corretamente, as t\u00e9cnicas que entregam transpar\u00eancia de localiza\u00e7\u00e3o n\u00e3o deixam que o cliente perceba a movimenta\u00e7\u00e3o, no que chamamos transpar\u00eancia de Reloca\u00e7\u00e3o. Rede de baixa lat\u00eancia Distribui\u00e7\u00e3o inteligente E.g: Servi\u00e7os de nome M\u00faltiplas c\u00f3pias C\u00f3pias tempor\u00e1rias","title":"Transpar\u00eancia de Reloca\u00e7\u00e3o"},{"location":"comm/#transparencia-de-migracao","text":"Transpar\u00eancia de migra\u00e7\u00e3o como se movimenta visto por si mesmo Do ponto de vista do pr\u00f3prio servi\u00e7o, n\u00e3o perceber que se est\u00e1 sendo movimentado \u00e9 chamado transpar\u00eancia de Migra\u00e7\u00e3o. Um servi\u00e7o com esta propriedade, n\u00e3o precisa ser parado e reconfigurado quando a mudan\u00e7a acontece. Uma das formas de se implementar esta propriedade \u00e9 atrav\u00e9s da migra\u00e7\u00e3o provida por m\u00e1quinas virtuais, usado, por exemplo, para consolidar o uso de servidores em nuvens computacionais. Veja o exemplo do VMotion da VMware. Na verdade, a movimenta\u00e7\u00e3o neste cen\u00e1rio, \u00e9 uma c\u00f3pia da m\u00e1quina virtual. Uma vez que a c\u00f3pia esteja pr\u00f3xima do fim, a imagem original \u00e9 congelada, a c\u00f3pia conclu\u00edda, e h\u00e1 um chaveamento na rede para se direcionar toda comunica\u00e7\u00e3o para nova c\u00f3pia. O m\u00e1quina original \u00e9 ent\u00e3o descartada.","title":"Transpar\u00eancia de Migra\u00e7\u00e3o"},{"location":"comm/#transparencia-de-replicacao","text":"Transpar\u00eancia de replica\u00e7\u00e3o redund\u00e2ncia visto por clientes A capacidade de ter c\u00f3pias de um servi\u00e7o e de direcionar trabalho de uma para outra \u00e9 tamb\u00e9m \u00fatil para se obter transpar\u00eancia no caso de falhas. Isto porqu\u00ea para se manter um servi\u00e7o funcional a despeito de falhas, \u00e9 preciso ter m\u00faltiplas c\u00f3pias, prontas para funcionar a qualquer momento. Dependendo das garantias desejadas na manuten\u00e7\u00e3o da consist\u00eancia entre as c\u00f3pias, o custo pode variar muito, de forma que para se ter um custo menor, tem-se garantias mais fracas, por exemplo, que as r\u00e9plicas tem um atraso entre elas de no m\u00e1ximo \\(X\\) minutos. Este \u00e9 um dilema parecido com o TCP x UDP, em que mais garantias implicam em maior custo de comunica\u00e7\u00e3o. Algumas aplica\u00e7\u00f5es toleram inconsist\u00eancias e podem viver com menores custos. Um exemplo famoso \u00e9 o dos \"carrinhos de compra\" da Amazon.com , que podem fechar pedidos com conte\u00fado diferente do desejado pelo cliente. Outras aplica\u00e7\u00f5es s\u00e3o normalmente constru\u00eddas com requisitos de consist\u00eancia forte entre as r\u00e9plicas, como sistemas financeiros. Para estas aplica\u00e7\u00f5es, uma t\u00e9cnica importante para se conseguir replica\u00e7\u00e3o \u00e9 o uso de frameworks de comunica\u00e7\u00e3o em grupo , que entregam para m\u00faltiplas inst\u00e2ncias de um mesmo servi\u00e7o, as mesmas mensagens, permitindo que elas se mantenham como c\u00f3pias. Esta t\u00e9cnica funciona se os servi\u00e7os forem m\u00e1quinas de estado determin\u00edsticas, que consideram como eventos as mensagens entregues pelo protocolo de comunica\u00e7\u00e3o em grupo e \u00e9 denominada replica\u00e7\u00e3o de m\u00e1quinas de estado . Replica\u00e7\u00e3o de M\u00e1quina de Estados determin\u00edstica mesmo estado inicial mesmos eventos mesmo estado final atraso entre r\u00e9plicas stateDiagram ei: Estado Inicial e1: Estado 1 e2: Estado 2 e3: Estado 3 en: Estado N ei --> e1 e1 --> e2 e2 --> e1 e2 --> e3 e3 --> e2 e1 --> en e3 --> en Todo Figura com state machine replication Novamente \u00e9 preciso chamar \u00e0 aten\u00e7\u00e3o a quest\u00e3o dos custos desta t\u00e9cnica. Replica\u00e7\u00e3o de M\u00e1quinas de Estados \u00e9 muito custosa e por isso faz-se um esfor\u00e7o para n\u00e3o utiliz\u00e1-la ou para utiliz\u00e1-la em \"cantinhos\" do sistema onde inconsist\u00eancias s\u00e3o absolutamente caras demais para sere permitidas. Isto porqu\u00ea manter m\u00faltiplas c\u00f3pias \\(\\Rightarrow\\) sincroniza\u00e7\u00e3o \\(\\Rightarrow\\) custos. Se houver mudan\u00e7as frequentes nos dados, tal custo precisa ser pago tamb\u00e9m frequentemente. Mitiga\u00e7\u00f5es incluem uso de r\u00e9plicas tempor\u00e1rias, protocolos de invalida\u00e7\u00e3o de cache, contrata\u00e7\u00e3o de redes com mais largura de banda e menor lat\u00eancia, sendo que estes \u00faltimos esbarram em limita\u00e7\u00f5es financeiras e f\u00edsicas.","title":"Transpar\u00eancia de Replica\u00e7\u00e3o"},{"location":"comm/#transparencia-de-concorrencia","text":"Transpar\u00eancia de concorr\u00eancia obliviedade a outros servi\u00e7os visto por clientes Outra transpar\u00eancia almej\u00e1vel \u00e9 de concorr\u00eancia, isto \u00e9, imperceptibilidade quanto ao fato de que o servi\u00e7o est\u00e1 executando concorrentemente a outros servi\u00e7os e sendo acessado por outros clientes. Isto \u00e9 importante tanto em termos de seguran\u00e7a, no sentido de que um cliente n\u00e3o deveria acessar os dados do outro, caso isso seja um requisito do sistema, quanto tem termos de desempenho. Nuvens computacionais s\u00e3o um exemplo de onde este tipo de transpar\u00eancia \u00e9 essencial. Considere um servi\u00e7o de banco de dados em uma nuvem qualquer. Para prover a mesma interface com a qual usu\u00e1rios est\u00e3o acostumados a anos, \u00e9 poss\u00edvel que este servi\u00e7o seja simplesmente um wrapper ao redor do SGBD que se comprava e instalava in-house anteriormente. Para se tornar vi\u00e1vel, contudo, uma mesma inst\u00e2ncia deve servir m\u00faltiplos clientes, os tenants , sem que a carga de trabalho introduzida por um, interfira no desempenho do outro. No meio, chamamos esta propriedade de multi-tenancy , mas \u00e9 apenas um exemplo de transpar\u00eancia de concorr\u00eancia. Esta transpar\u00eancia est\u00e1 fundamentalmente ligada \u00e0 escalabilidade, isto \u00e9, \u00e0 adequa\u00e7\u00e3o dos pool de recursos \u00e0s demandas dos clientes: se mais clientes est\u00e3o presentes, ent\u00e3o aumente a quantidade de servidores ( scale up ) e separe as cargas ( sharding ); se menos clientes est\u00e3o presentes, ent\u00e3o desligue algumas m\u00e1quinas ( scale down ) e consolide recursos.","title":"Transpar\u00eancia de Concorr\u00eancia"},{"location":"comm/#desafios-para-se-obter-transparencia","text":"Apesar de desej\u00e1veis, as transpar\u00eancia discutidas s\u00e3o dif\u00edceis de se conseguir, principalmente se em conjunto. Isto porqu\u00ea, do ponto de vista de usu\u00e1rios espalhados pelo globo, atr\u00e1s de redes heterog\u00eaneas e com possibilidade de erros, acontecer\u00e3o atrasos e perdas na comunica\u00e7\u00e3o, denunciando a distribui\u00e7\u00e3o. Do ponto de vista do desenvolvedor , \u00e9 preciso tomar decis\u00f5es baseado em premissas ligadas \u00e0 realidade da rede. Por exemplo, se uma requisi\u00e7\u00e3o n\u00e3o foi respondida, quanto tempo um cliente deve esperar antes de reenvi\u00e1-la, possivelmente para outro servidor, sem incorrer em risco significativo da requisi\u00e7\u00e3o ser processada duas vezes? A resposta para esta pergunta \u00e9 muito mais complicada do que pode parecer. De forma geral , qualquer aumento de transpar\u00eancia tem um custo, seja em termos monet\u00e1rios (e.g., contrata\u00e7\u00e3o de enlace dedicado ou de host em outra posi\u00e7\u00e3o geogr\u00e1fica), ou em termos de desempenho (e.g., coordenar a entrega de mensagens em sistemas de comunica\u00e7\u00e3o em grupo). Provavelmente os maiores obst\u00e1culos para se alcan\u00e7ar os diversos tipos de transpar\u00eancia s\u00e3o impostos pela parte da infraestrutura que torna o sistema distribu\u00eddo poss\u00edvel, a rede. Para entender o porqu\u00ea, vejamos algumas premissas normalmente assumidas sobre a rede que n\u00e3o s\u00e3o, definitivamente, verdade: A lat\u00eancia \u00e9 zero. A largura de banda \u00e9 infinita. A rede \u00e9 confi\u00e1vel. A rede \u00e9 segura. A rede \u00e9 homog\u00eanea. A rede \u00e9 est\u00e1tica. A rede tem acesso gr\u00e1tis. A rede \u00e9 administrada por voc\u00ea ou algu\u00e9m acess\u00edvel.","title":"Desafios para se obter transpar\u00eancia"},{"location":"comm/#representacao-de-dados","text":"Exceto por aplica\u00e7\u00f5es muito simples, processos em um sistema distribu\u00eddo trocam dados complexos, por exemplo estruturas ou classes com diversos campos, incluindo valores num\u00e9ricos de diversos tipos, strings e vetores de bytes, com diversos n\u00edveis de aninhamento e somando v\u00e1rios KB. Neste cen\u00e1rio, v\u00e1rios fatores precisam ser levados em considera\u00e7\u00e3o na hora de colocar esta estrutura no fio , como: varia\u00e7\u00f5es de defini\u00e7\u00f5es de tipos, por exemplo, inteiro : 8: 16, 32, ou 64 bits? varia\u00e7\u00f5es na representa\u00e7\u00e3o de dados complexos: classe x estrutura conjunto de caracteres diferentes: ASCII x UTF little endian, como x64 e IA-32, ou big endian como SPARC (< V9), Motorola e PowerPC? ou aidna, flex\u00edvel como ARM, MIPS ou IA-64? fim de linha com crlf (DOS) x lf (Unix)? fragmenta\u00e7\u00e3o de dados na rede","title":"Representa\u00e7\u00e3o de dados"},{"location":"comm/#representacao-textual","text":"Uma abordagem comumente usada \u00e9 a representa\u00e7\u00e3o em formato textual \"amig\u00e1vel a humanos\". Veja o exemplo de como o protocolo HTTP requisita e recebe uma p\u00e1gina HTML. 1 2 3 4 5 6 telnet www.google.com 80 Trying 187.72.192.217... Connected to www.google.com. Escape character is '^]'. GET / HTTP/1.1 host: www.google.com As linhas 5 e 6 s\u00e3o entradas pelo cliente para requisitar a p\u00e1gina raiz do s\u00edtio www.google.com . A linha 7, vazia, indica ao servidor que a requisi\u00e7\u00e3o est\u00e1 terminada. Em resposta a esta requisi\u00e7\u00e3o, o servidor envia o seguinte, em que as primeiras linhas trazem metadados da p\u00e1gina requisitada e, ap\u00f3s a linha em branco, vem a resposta em HTML \u00e0 requisi\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 HTTP/1.1 302 Found Location: http://www.google.com.br/?gws_rd=cr & ei=HTDqWJ3BDYe-wATs_a3ACA Cache-Control: private Content-Type: text/html; charset=UTF-8 P3P: CP=\"This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info.\" Date: Sun, 09 Apr 2017 12:59:09 GMT Server: gws Content-Length: 262 X-XSS-Protection: 1; mode=block X-Frame-Options: SAMEORIGIN Set-Cookie: NID=100=NB_AruuFWL0hXk2-h7VDduHO_UkjAr6RaqgG7VbccTsfLzFfhxEKx21Xpa2EH7IgshgczE9vU4W1TyKsa07wQeuZosl5DbyZluR1ViDRf0C-5lRpd9cCpCD5JXXjy-UE; expires=Mon, 09-Oct-2017 12:59:09 GMT; path=/; domain=.google.com; HttpOnly < HTML >< HEAD >< meta http-equiv = \"content-type\" content = \"text/html;charset=utf-8\" > < TITLE > 302 Moved </ TITLE ></ HEAD >< BODY > < H1 > 302 Moved </ H1 > The document has moved < A HREF = \"http://www.google.com.br/?gws_rd=cr&amp;ei=HTDqWJ3BDYe-wATs_a3ACA\" > here </ A > . </ BODY ></ HTML > Representa\u00e7\u00f5es textuais s\u00e3o usadas em diversos protocolos como SMTP, POP, e telnet. Algumas destas representa\u00e7\u00f5es seguem padr\u00f5es formalizados, o que facilita a gera\u00e7\u00e3o e interpreta\u00e7\u00e3o dos dados. Dois padr\u00f5es bem conhecidas s\u00e3o XML e JSON. XML \u00e9 o acr\u00f4nimo para Extensible Markup Language , ou seja, uma linguagem marca\u00e7\u00e3o que pode ser estendida para representar diferentes tipos de informa\u00e7\u00e3o. A HTML, por exemplo, \u00e9 uma inst\u00e2ncia de XML destinada \u00e0 representa\u00e7\u00e3o de hipertexto (A bem da verdade, XML foi uma generaliza\u00e7\u00e3o de HTML). Por exemplo, para representarmos os dados relativos \u00e0 uma pessoa, podemos ter uma inst\u00e2ncia XML assim: 1 2 3 4 5 6 7 8 9 <person> <name> John Doe </name> <id> 112234556 </id> <email> jdoe@example.com </email> <telephones> <telephone type= \"mobile\" > 123 321 123 </telephone> <telephone type= \"home\" > 321 123 321 </telephone> </telephones> </person> Uma das grandes vantagens do uso de XML \u00e9 a possibilidade de se formalizar o que pode ou n\u00e3o estar em um arquivo para um certo dom\u00ednio utilizando um XML Domain Object Model . H\u00e1, por exemplo, modelos para representa\u00e7\u00e3o de documentos de texto, governos eletr\u00f4nicos, representa\u00e7\u00e3o de conhecimento, etc . Sua maior desvantagem \u00e9 que \u00e9 muito verborr\u00e1gico e por vezes complicado de se usar, abrindo alas para o seu mais famoso concorrente, JSON. JSON \u00e9 o acr\u00f4nimo de Javascript Object Notation , isto \u00e9, o formato para representa\u00e7\u00e3o de objetos da linguagem Javascript. Devido \u00e0 sua simplicidade e versatilidade, entretanto, foi adotado como forma de representa\u00e7\u00e3o de dados em sistemas desenvolvidos nas mais diferentes linguagens. O mesmo exemplo visto anteriormente, em XML, \u00e9 representado em JSON assim: 1 2 3 4 5 6 7 8 9 { \"name\" : \"John Doe\" , \"id\" : 112234556 , \"email\" : \"jdoe@example.com\" , \"telephones\" : [ { \"type\" : \"mobile\" , \"number\" : \"123 321 123\" }, { \"type\" : \"home\" , \"number\" : \"321 123 321\" }, ] } Em Python, por exemplo, JSON s\u00e3o gerados e interpretados nativamente, sem a necessidade de frameworks externos, facilitando seu uso. Mas de fato, a op\u00e7\u00e3o final por XML ou JSON \u00e9 quest\u00e3o de prefer\u00eancia, uma vez que os dois formatos s\u00e3o, de fato, equivalentes na quest\u00e3o da representa\u00e7\u00e3o de informa\u00e7\u00e3o. Outros formatos, bin\u00e1rios, oferecem vantagens no uso de espa\u00e7o para armazenar e transmitir dados, e por isso s\u00e3o frequentemente usados como forma de serializa\u00e7\u00e3o de dados em sistemas distribu\u00eddos, isto \u00e9, na transforma\u00e7\u00e3o de TAD para sequ\u00eancias de bytes que seguir\u00e3o \"no fio\". ASN.1 (Abstract Syntax Notation), pela ISO XDR (eXternal Data Representation) Java serialization Google Protocol Buffers Thrift ASN.1 e XDR s\u00e3o de interesse hist\u00f3rico, mas n\u00e3o os discutiremos aqui. Quanto \u00e0 serializa\u00e7\u00e3o feita nativamente pelo Java, por meio de ObjectOutputStreams , como neste exemplo , embora seja tentadora para quem usa Java, \u00e9 necess\u00e1rio saber que ela \u00e9 restrita \u00e0 JVM e que usa muito espa\u00e7o, embora minimize riscos de uma desserializa\u00e7\u00e3o para uma classe diferente. Nos foquemos nas autras alternativas listadas, ProtoBuffers e Thrift, que podem levar a representa\u00e7\u00f5es bin\u00e1rias e textuais.","title":"Representa\u00e7\u00e3o Textual"},{"location":"comm/#protobuffers","text":"Nas palavras dos criadores , Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Por meio de protobuffers, \u00e9 poss\u00edvel estruturar dados e gerar o c\u00f3digo correspondente em diversas linguagens, for forma compartilh\u00e1vel entre as mesmas. Veja o exemplo a seguir, que especifica os dados referentes a uma pessoa. Observe a presen\u00e7a de campos de preenchimento opcional ( optional ), de enumera\u00e7\u00f5es ( enum ), e de cole\u00e7\u00f5es ( repeated ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 message Person { required string name = 1 ; required int32 id = 2 ; optional string email = 3 ; enum PhoneType { MOBILE = 0 ; HOME = 1 ; WORK = 2 ; } message PhoneNumber { required string number = 1 ; optional PhoneType type = 2 [ default = HOME ]; } repeated PhoneNumber phone = 4 ; } Com tal defini\u00e7\u00e3o \u00e9 poss\u00edvel gerar c\u00f3digo como o seguinte, em C++, que serializa os dados para escrita em um arquivo... 1 2 3 4 5 6 Person person ; person . set_name ( \"John Doe\" ); person . set_id ( 1234 ); person . set_email ( \"jdoe@example.com\" ); fstream output ( \"myfile\" , ios :: out | ios :: binary ); person . SerializeToOstream ( & output ); e l\u00ea do arquivo e desserializa para hidratar um novo objeto. 1 2 3 4 5 fstream input ( \"myfile\" , ios :: in | ios :: binary ); Person person ; person . ParseFromIstream ( & input ); cout << \"Name: \" << person . name () << endl ; cout << \"E-mail: \" << person . email () << endl ; De acordo com benchmarks do pr\u00f3prio projeto , a opera\u00e7\u00e3o em XML seria mais ordens de grandeza mais lenta e ocuparia mais espa\u00e7o. When this message is encoded to the protocol buffer binary format, it would probably be 28 bytes long and take around 100-200 nanoseconds to parse. The XML version is at least 69 bytes if you remove whitespace, and would take around 5,000-10,000 nanoseconds to parse.","title":"ProtoBuffers"},{"location":"comm/#thrift","text":"TODO Thrift como forma de representa\u00e7\u00e3o de dados: Thrift type system","title":"Thrift"},{"location":"comm/#invocacao-remota-de-procedimentos-rpc","text":"Em 1984, Birrel e Nelson 6 introduziram o mecanismo de Invoca\u00e7\u00e3o Remota de Procedimentos ( Remote Procedure Calls ), que permite que processos fa\u00e7am, pasmem, invoca\u00e7\u00f5es de procedimentos remotos! \u00d3bvio, a inova\u00e7\u00e3o n\u00e3o est\u00e1 na capacidade de uma m\u00e1quina conversar com outra, mas em como esta conversa acontece, do ponto de vista do programador. Por exemplo, RPC permita que se procure a substring \"teste\" dentro da string apontada por a , a partir da posi\u00e7\u00e3o 3, usando x = substring(a,3,\"teste\"); , mas com o invocador da fun\u00e7\u00e3o em um processo e a implementa\u00e7\u00e3o da fun\u00e7\u00e3o propriamente dita, em outro, possivelmente em outra m\u00e1quina.","title":"Invoca\u00e7\u00e3o Remota de Procedimentos - RPC"},{"location":"comm/#stubs","text":"Antes de nos aprofundarmos, vejamos como uma invoca\u00e7\u00e3o de fun\u00e7\u00f5es acontece normalmente dentro de um \u00fanico processo 7 . O c\u00f3digo x = substring(a,3,\"teste\"); , que procura \"teste\" em *a , \u00e9 traduzido nos seguintes passos em linguagem de m\u00e1quina: coloque o endere\u00e7o de \"teste\" na pilha coloque 3 na pilha coloque o valor de a na pilha coloque o endere\u00e7o de retorno na pilha (junto com outros dados de controle) salte para substring ajustando o instruction pointer ... procure substring ... coloque o resultado no acumulador limpe a pilha salte de volta recuperando o endere\u00e7o de retorno da pilha e ajustando o IP coloque resultado em x Se o que queremos \u00e9 colocar o c\u00f3digo da fun\u00e7\u00e3o substring em um outro processo e execut\u00e1-lo como se estiv\u00e9ssemos no mesmo processo que faz a invoca\u00e7\u00e3o, precisamos pensar em v\u00e1rias quest\u00f5es relativas ao fluxo mostrado acima. Claramente n\u00e3o podemos usar o mesmo fluxo para invocar uma fun\u00e7\u00e3o, mas precisamos de c\u00f3digo de simule a invoca\u00e7\u00e3o local mas que, por baixo do cap\u00f4, use sockets para se comunicar com o processo remoto. Estq simula\u00e7\u00e3o usar\u00e1 c\u00f3digo extra, que finge implementar substring para o invocador mas delega ao c\u00f3digo remoto o trabalho real da busca. Este c\u00f3digo extra \u00e9 conhecido como stub , ou para ser mais preciso, stub cliente , que faz parte do processo invocando a opera\u00e7\u00e3o, e stub servidor, que faz parte do processo executando a opera\u00e7\u00e3o invocada 8 . Assim, o cliente invoca fun\u00e7\u00e3o no stub cliente, achando que \u00e9 a fun\u00e7\u00e3o que quer executar. Stub cliente faz o marshaling 9 dos par\u00e2metros e usa o SO para transferir os dados via rede para o stub servidor. Quando recebe a resposta do servidor, o stub cliente retorna a mesma resposta, como se tivesse calculado localmente. Stub cliente Implementa uma fun\u00e7\u00e3o substring(char*, int, char*) que abre socket para servidor envia par\u00e2metros especifica fun\u00e7\u00e3o espera resposta retorna resultado J\u00e1 o stub servidor fica esperando o contato do cliente. Quando acontece, faz o \"unmarshalling\" dos dados, invoca a fun\u00e7\u00e3o localmente na aplica\u00e7\u00e3o servidor e pega o resultado, que retona ao cliente. Stub servidor espera conex\u00e3o recebe par\u00e2metros recebe especifica\u00e7\u00e3o da fun\u00e7\u00e3o invoca fun\u00e7\u00e3o localmente envia resultado para cliente","title":"Stubs"},{"location":"comm/#transparencia_1","text":"\u00c9 para o programador a grande vantagem do uso de RPC, pois se pode escrever c\u00f3digo distribu\u00eddo \"igual\" ao centralizado, certo? Isto \u00e9, interface baseada em procedimentos e sem a necessidade de detalhar portas, sockets, e representa\u00e7\u00e3o de dados . Ou seja, tudo \u00e9 transparente! Como j\u00e1 discutimos, v\u00e1rios fatores trabalham contra a transpar\u00eancia em sistemas distribu\u00eddos . Em espec\u00edfico quanto \u00e0 transpar\u00eancia dada pelo RPC, tamb\u00e9m temos limita\u00e7\u00f5es. O problema \u00e9 que h\u00e1 uma distin\u00e7\u00e3o clara em pelo menos dois processos e se pensarmos no c\u00f3digo descrito acima, temos que entender que processos independentes n\u00e3o compartilham um espa\u00e7o de endere\u00e7amento, e processos independentes n\u00e3o compartilham uma pilha. Assim, como fica a passagem de par\u00e2metro por refer\u00eancia , uma vez que o stub servidor n\u00e3o pode usar endere\u00e7os do espa\u00e7o de endere\u00e7amento do cliente? Algumas abordagens para simular a passagem por refer\u00eancia s\u00e3o poss\u00edveis. Por exemplo, o valor apontado pelo ponteiro \u00e9 passado para o servidor , que armazena o valor e alguma posi\u00e7\u00e3o de mem\u00f3ria e passa o endere\u00e7o de tal posi\u00e7\u00e3o para a fun\u00e7\u00e3o invocada. Contudo, a modifica\u00e7\u00e3o do valor pela fun\u00e7\u00e3o n\u00e3o reflete imediatamente no invocador; tais valores tem que ser copiados novamente e usados para sobrescrever o valor original no cliente. Al\u00e9m disso, esta abordagem s\u00f3 \u00e9 poss\u00edvel se o valor apontado for delimitado, o que nem sempre \u00e9 f\u00e1cil de determinar. Por exemplo, se o ponteiro for para o primeiro elemento de uma lista, o que deve ser copiado para o servidor? S\u00f3 o primeiro elemento? Toda a lista? Como ensinar para o framework RPC o que \u00e9 \"toda\" a lista? Java \"resolve\" o problema da passagem de par\u00e2metro por refer\u00eancia passando todo o grafo do objeto passado como par\u00e2metro para o servidor. Isto \u00e9, al\u00e9m de serializar o objeto apontado no par\u00e2metro, se o mesmo aponta para outros objetos, estes tamb\u00e9m ser\u00e3o serializados e transferidos; o servidor ir\u00e1 ent\u00e3o reconstruir todo o grafo e passar para o m\u00e9todo sendo invocado. \u00c9 muito f\u00e1cil ver que esta abordagem pode se tornar invi\u00e1vel rapidamente. Quando for o caso, Java permite marcar objetos como remotos e, em vez de serializar este objeto e enviar para o servidor, envia informa\u00e7\u00e3o suficiente para que o servidor possa invocar m\u00e9todos em tal objeto no cliente, tornando nebulosa a defini\u00e7\u00e3o de quem \u00e9 quem. Outros fatores tamb\u00e9m trabalham contra a transpar\u00eancia para o desenvolvedor. Vejamos alguns","title":"Transpar\u00eancia"},{"location":"comm/#descoberta-de-servicos","text":"Por exemplo, mesmo que o socket seja ocultado, ele ainda existe e precisa de informa\u00e7\u00f5es sobre onde se conectar (endere\u00e7o e porta), que de alguma forma deve ser passada para o framework de RPC. Esta informa\u00e7\u00e3o pode ser configurada a priori por um administrador de sistemas, mas requer atualiza\u00e7\u00f5es sempre que a localiza\u00e7\u00e3o do servi\u00e7o for alterada ou novos servidores adicionados. Mais interessante seria um mecanismo que permitisse uma indire\u00e7\u00e3o para o servi\u00e7o; o pr\u00f3prio DNS pode ser uma op\u00e7\u00e3o inicial, mas um servi\u00e7o dedicado pode ser mais apropriado, pois permite descobrir servi\u00e7os e n\u00e3o apenas servidores. Birrel e Nelson propuseram um servi\u00e7o de P\u00e1ginas Amarelas , no qual clientes podem questionar quem oferece um certo servi\u00e7o e serem redirecionados automaticamente. Esta abordagem tem seus pr\u00f3prios problemas, como por exemplo determinar quem administra o servi\u00e7o para incluir novos servidores. E como determinar qual servi\u00e7o acessar, caso hajam m\u00faltiplas op\u00e7\u00f5es de servidores . Apesar dos problemas, p\u00e1ginas amarelas foram usadas em abordagens muito mais recentes para descobertas de servi\u00e7os, por exemplo Web Services Discovery , que permite a descoberta de Web Services em escala global, e Java Remote Object Registry que permite a descoberta de objetos remotos Java.","title":"Descoberta de Servi\u00e7os"},{"location":"comm/#tratamento-de-excecoes","text":"Uma vez que a invoca\u00e7\u00e3o \u00e9 remota, h\u00e1 sempre o risco de problemas de comunica\u00e7\u00e3o entre cliente e servidor. Logo, \u00e9 necess\u00e1ria a introdu\u00e7\u00e3o de c\u00f3digo para tratamento de erros deste tipo, o que absolutamente n\u00e3o era necess\u00e1rio no caso do c\u00f3digo centralizado. Assim, o que era um simples x = substring(a,3,\"teste\"); passa para algo assim (em uma linguagem fict\u00edcia): 1 2 3 4 5 6 7 8 9 10 11 12 13 int x = -2 ; try { x = substring ( a , 3 , \"teste\" ); ` } catch ( CommunicationFailureException cfe ) { log_error ( \"Como pode substring falhar? Desespero!!!\" ); } if ( x == -2 ) system_exit ( -2 ) else if ( x == -1 ) //n\u00e3o achou else //achou \"teste\" na posi\u00e7\u00e3o x O que nos leva novamente ao ponto sobre n\u00e3o haver transpar\u00eancia total em sistemas distribu\u00eddos... e esta falta de transpar\u00eancia pode ser muito mais complicada do que simplesmente adicionar try e catch ao seu c\u00f3digo. Mais que isso, imagine que a opera\u00e7\u00e3o sendo executada altere algum estado no servidor. Se esta fosse uma operac\u00e3o local, cada invoca\u00e7\u00e3o da opera\u00e7\u00e3o corresponderia a exatamente uma execu\u00e7\u00e3o da opera\u00e7\u00e3o, na aus\u00eancia de falhas. No caso de falhas, se o processo quebra como um todo, no seu rein\u00edcio, pode-se identificar se a opera\u00e7\u00e3o foi ou n\u00e3o executada e aplicar a\u00e7\u00f5es corretivas. Mas e no caso remoto?","title":"Tratamento de Exce\u00e7\u00f5es"},{"location":"comm/#reexecucoes","text":"No caso da opera\u00e7\u00e3o distribu\u00edda, se o servidor quebra, isso levar\u00e1 a um erro ser percebido do lado do cliente como uma falha na conex\u00e3o . Se o cliente havia invocado uma opera\u00e7\u00e3o mas percebeu o erro antes de receber uma confirma\u00e7\u00e3o de sua execu\u00e7\u00e3o, isto pode indicar que: (i) ou a requisi\u00e7\u00e3o nunca foi recebida pelo servidor e, portanto, n\u00e3o foi executada, (ii) ou a execu\u00e7\u00e3o foi recebida e executada, mas a resposta n\u00e3o foi enviada. O cliente tem que tratar o erro, mas como? Se a opera\u00e7\u00e3o precisa ser executada a qualquer custo , o cliente pode retent\u00e1-la quando conseguir novo contato com o servidor (ou mesmo com outro). Neste caso, se o que de fato aconteceu foi a situa\u00e7\u00e3o (i), ent\u00e3o retentar garantir\u00e1 que a opera\u00e7\u00e3o seja executada pelo servidor, mesmo que v\u00e1rias tentativas sejam necess\u00e1rias. Contudo, se o que o ocorreu foi a situa\u00e7\u00e3o (ii), ent\u00e3o reenviar a opera\u00e7\u00e3o levar\u00e1 a mesma a ser executada m\u00faltiplas vezes, o que pode ou n\u00e3o ser ok. Esta abordagem \u00e9 garantir\u00e1 que a execu\u00e7\u00e3o acontece pelo menos 1 vez . Imagine que a opera\u00e7\u00e3o se tratasse de uma transfer\u00eancia de saldo, ou a encomenda de de um caminh\u00e3o carregado de algum produto caro. Neste caso, reexecutar n\u00e3o parece ser uma op\u00e7\u00e3o. Neste caso, talvez a melhor op\u00e7\u00e3o seja n\u00e3o retentar a opera\u00e7\u00e3o, o que levar\u00e1 a zero execu\u00e7\u00f5es na situa\u00e7\u00e3o (ii) e uma execu\u00e7\u00e3o na situa\u00e7\u00e3o, ou seja, a no m\u00e1ximo uma execu\u00e7\u00e3o. Uma situa\u00e7\u00e3o em que esta abordagem \u00e9 claramente prefer\u00edvel \u00e9 a entrega de quadros em um stream de v\u00eddeo ou \u00e1udio, devido \u00e0 import\u00e2ncia da opera\u00e7\u00e3o ser atrelada ao momento de sua execu\u00e7\u00e3o. Nenhuma destas abordagens \u00e9 igual ao que \u00e9 garantido na vers\u00e3o centralizada e que \u00e9 provelmente o que todo desenvolvedor desejaria para suas invoca\u00e7\u00f5es de m\u00e9todos, que fossem executados exatamente uma vez. Garantir esta sem\u00e2ntica na comunica\u00e7\u00e3o \u00e9 muito dif\u00edcil, pois \u00e9 imposs\u00edvel ter certeza de que uma mensagem n\u00e3o foi processada pelo servidor ainda. De fato, \u00e9 imposs\u00edvel ter certeza se o servidor falhou; pode ter sido apenas uma falha na comunica\u00e7\u00e3o. Quantidade de execu\u00e7\u00f5es No m\u00e1ximo uma - n\u00e3o retentar Exatamente uma - impedir que falhas aconte\u00e7am :/ Pelo menos uma - retentar at\u00e9 ter confirma\u00e7\u00e3o Como \u00e9 imposs\u00edvel evitar falhas, se uma opera\u00e7\u00e3o deve executada, ela deve ser retentada. Mas ela n\u00e3o pode ser repetida, ent\u00e3o a alternativa \u00e9 tornar as opera\u00e7\u00f5es idempotentes , o que quer dizer que o efeito desejado \u00e9 alcan\u00e7ado pela primeira execu\u00e7\u00e3o e que execu\u00e7\u00f5es seguintes n\u00e3o alteram o estado. Opera\u00e7\u00f5es idempotentes M\u00faltiplas execu\u00e7\u00f5es tem o mesmo efeito uma execu\u00e7\u00e3o. Exemplo: x = 10 Anti-exemplo: x = x+1 . Infelizmente n\u00e3o \u00e9 trivial programar para idempot\u00eancia, principalmente se o servidor for acessado concorrentemente por m\u00faltiplos clientes, tornando seu estado uam regi\u00e3o cr\u00edtica.","title":"Reexecu\u00e7\u00f5es"},{"location":"comm/#concorrencia-no-servidor","text":"\u00c9 importante notar que um servidor n\u00e3o est\u00e1 obrigado a atender requisi\u00e7\u00f5es de somente um cliente. Logo, se m\u00faltiplos clientes acessam o mesmo servidor, o estado do servidor ser\u00e1 \"compartilhado\" pelos v\u00e1rios clientes e passos s\u00e3o necess\u00e1rios para que o comportamento no acesso deste estado seja coerente com a especifica\u00e7\u00e3o. Pense por exemplo em um servidor que conta o n\u00famero de acessos feitos por clientes. O incremento do contador deve ser considerado uma regi\u00e3o cr\u00edtica, caso m\u00faltiplos threads tratem as requisi\u00e7\u00f5es dos clientes, o que j\u00e1 vimos ser uma boa idia. Claro que dificilmente seu servidor seria algo t\u00e3o simples assim. Em vez disso, ele provavelmente executar\u00e1 l\u00f3gicas complicadas, como por exemplo, armazenar o estado de contas banc\u00e1rias e, neste caso, as fun\u00e7\u00f5es expostas por RPC incluir\u00edam a opera\u00e7\u00e3o transferir saldo de A para B , o que nos leva a mais um problema interessante, o do risco de reexecu\u00e7\u00f5es. Al\u00e9m disso, o servidor provavelmente suportar\u00e1 diversas opera\u00e7\u00f5es e por isso dever\u00e1 identificar qual a opera\u00e7\u00e3o sendo requisitada. Isto \u00e9 feito por um dispatcher , que demultiplexa as opera\u00e7\u00f5es requisitadas; o dispatcher pode, em algumas arquiteturas, ser independente do skeleton em si.","title":"Concorr\u00eancia no servidor"},{"location":"comm/#interface-definition-language-idl","text":"H\u00e1 diversas op\u00e7\u00f5es de frameworks para RPC, com diferentes caracter\u00edsticas, focos, e garantias. Alguns s\u00e3o parte da linguagem e outros s\u00e3o implementados como bibliotecas. Alguns suportam m\u00faltiplas linguagens e alguns apenas uma. Suporte a RPC na linguagem Sem RPC: C, C++, Java < 5.0 (1.5), Python Com RPC: Java, Go, Erlang, Scala, Haskell Ambientes heterog\u00eaneos: Thrift, gRPC, Akka, SOAP Frameworks mais modernos permitem escolher a forma de serializa\u00e7\u00e3o dos dados, se leg\u00edvel para humanos ou bin\u00e1rio, se o transporte \u00e9 via HTTP ou protocolo mais baixo n\u00edvel, se os dados trafegam abertamente ou se faz uso de comunica\u00e7\u00e3o criptografada (SSL). Outros permitem escolher sem\u00e2ntica de execu\u00e7\u00e3o entre no m\u00e1ximo uma e pelo menos uma , e h\u00e1 at\u00e9 quem prometa exatamente uma . Mas todos os frameworks tem algumas caracter\u00edsticas em comum e uma delas \u00e9 o uso de uma Linguagem de Defini\u00e7\u00e3o de Interface (IDL). Uma IDL \u00e9 a linguagem pela qual desenvolvedor define quais as opera\u00e7\u00f5es (fun\u00e7\u00f5es, procedimentos, m\u00e9todos) ser\u00e3o acess\u00edveis via RPC e quais os seus operandos. H\u00e1 v\u00e1rias IDL definidas, para os diversos frameworks dispon\u00edveis. A imagem a seguir mostra um exemplo gen\u00e9rico da cria\u00e7\u00e3o cliente e servidor usando um framework RPC gen\u00e9rico, inclusive o processamento da defini\u00e7\u00e3o feita em IDL do servi\u00e7o e a jun\u00e7\u00e3o deste c\u00f3digo gerado ao c\u00f3digo escrito pelo desenvolvedor. O fluxo de processamento \u00e9 o seguinte: Arquivo em IDL \u00e9 compilado por um compilador IDL e gera diversos arquivos: stub cliente - c\u00f3digo que implementa a interface, com c\u00f3digo para repassar invoca\u00e7\u00f5es para o servidor. stub servidor ( skeleton ) - c\u00f3digo que atende a conex\u00f5es do stub cliente e repassa para a implementa\u00e7\u00e3o pr\u00f3pria da fun\u00e7\u00e3o. convers\u00e3o de dados - c\u00f3digo que serializa e deserializa dados para serem trafegados de e para o servidor cabe\u00e7alhos - defini\u00e7\u00f5es da interface na linguagem de desenvolvimento da aplica\u00e7\u00e3o; se linguagem C, por exemplo, estes ser\u00e3o arquivos .h , se em Java, ent\u00e3o estes ser\u00e3o arquivos .java , com defini\u00e7\u00e3o de interface . O c\u00f3digo cliente \u00e9 compilado e gera o cliente, que deve inicializar a infraestrutura RPC Tipo de transporte SSL? Localizar servidor Lidar com falhas O c\u00f3digo servidor \u00e9 compilado e gera o servidor, que deve exportar e localizar servi\u00e7os (servi\u00e7o de nomea\u00e7\u00e3o) Gerenciamento de portas Conex\u00f5es Mas para entendermos melhor o fluxo, vejamos algumas ferramentas reais.","title":"Interface Definition Language - IDL"},{"location":"comm/#estudo-de-caso-rpc-grpc","text":"gRPC \u00e9 um framework para invoca\u00e7\u00e3o remota de procedimentos multi-linguagem e sistema operacional, usando internamente pelo Google h\u00e1 v\u00e1rios anos para implementar sua arquitetura de micro-servi\u00e7os. Inicialmente desenvolvido pelo Google, o gRPC \u00e9 hoje de c\u00f3digo livre encubado pela Cloud Native Computing Foundation. O s\u00edtio gRPC.io documenta muito bem o gRPC, inclusive os princ\u00edpios que nortearam seu projeto. O seu uso segue, em linhas gerais, o modelo discutido nas se\u00e7\u00f5es anteriores, isto \u00e9, inicia-se pela defini\u00e7\u00e3o de estruturas de dados e servi\u00e7os, \"compila-se\" a defini\u00e7\u00e3o para gerar stubs na linguagem desejada, e compila-se os stubs juntamente com os c\u00f3digos cliente e servidor para gerar os bin\u00e1rios correspondentes. Vejamos a seguir um tutorial passo a passo, em Java, baseado no quickstart guide .","title":"Estudo de Caso RPC: gRPC"},{"location":"comm/#instalacao","text":"Os procedimentos de instala\u00e7\u00e3o dependem da linguagem em que pretende usar o gRPC, tanto para cliente quanto para servidor. No caso do Java , n\u00e3o h\u00e1 instala\u00e7\u00e3o propriamente dita .","title":"Instala\u00e7\u00e3o"},{"location":"comm/#exemplo-java","text":"Observe que o reposit\u00f3rio base apontado no tutorial serve de exemplo para diversas linguagens e diversos servi\u00e7os, ent\u00e3o sua estrutura \u00e9 meio complicada. N\u00f3s nos focaremos aqui no exemplo mais simples, uma esp\u00e9cie de \"hello word\" do RPC.","title":"Exemplo Java"},{"location":"comm/#pegando-o-codigo","text":"Para usar os exemplos, voc\u00ea precisa clonar o reposit\u00f3rio com o tutorial, usando o comando a seguir. 1 git clone -b v1.33.0 https://github.com/grpc/grpc-java Uma vez clonado, entre na pasta de exemplo do Java e certifique-se que est\u00e1 na vers\u00e3o 1.33, usada neste tutorial. 1 2 cd grpc-java \\e xamples git checkout v1.33.0","title":"Pegando o c\u00f3digo"},{"location":"comm/#compilando-e-executando","text":"O projeto usa gradle para gerenciar as depend\u00eancias. Para, use o wrapper do gradle como se segue. 1 ./gradlew installDist Caso esteja na UFU, coloque tamb\u00e9m informa\u00e7\u00e3o sobre o proxy no comando. 1 ./gradlew -Dhttp.proxyHost = proxy.ufu.br -Dhttp.proxyPort = 3128 -Dhttps.proxyHost = proxy.ufu.br -Dhttps.proxyPort = 3128 installDist Como quando usamos sockets diretamente, para usar o servi\u00e7o definido neste exemplo, primeiros temos que executar o servidor. 1 ./build/install/examples/bin/hello-world-server Agora, em um terminal distinto e a partir da mesma localiza\u00e7\u00e3o, execute o cliente, quantas vezes quiser. 1 ./build/install/examples/bin/hello-world-client","title":"Compilando e executando"},{"location":"comm/#o-servico","text":"O exemplo n\u00e3o \u00e9 muito excitante, pois tudo o que o servi\u00e7o faz \u00e9 enviar uma sauda\u00e7\u00e3o aos clientes. O servi\u00e7o \u00e9 definido no seguinte arquivo .proto , localizado em ./src/main/proto/helloworld.proto . 1 2 3 4 5 6 7 8 9 10 11 12 13 message HelloRequest { string name = 1; } message HelloReply { string message = 1; } // The greeting service definition. service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {} } No arquivo, inicialmente s\u00e3o definidas duas mensagens, usadas como requisi\u00e7\u00e3o (cliente para servidor) e outra como resposta (servidor para cliente) do servi\u00e7o definido em seguida. A mensagem HelloRequest tem apenas um campo denominado name , do tipo string . Esta mensagem conter\u00e1 o nome do cliente, usado na resposta gerada pelo servidor. A mensagem HelloReply tamb\u00e9m tem um campo do tipo string , denominado message , que conter\u00e1 a resposta do servidor. O servi\u00e7o dispon\u00edvel \u00e9 definido pela palavra chave service e de nome Greeter ; \u00e9 importante entender que este nome ser\u00e1 usado em todo o c\u00f3digo gerado pelo compilador gRPC e que se for mudado, todas as refer\u00eancias ao c\u00f3digo gerado devem ser atualizadas. O servi\u00e7o possui apenas uma opera\u00e7\u00e3o, SayHello , que recebe como entrada uma mensagem HelloRequest e gera como resposta uma mensagem HelloReply . Caso a opera\u00e7\u00e3o precisasse de mais do que o conte\u00fado de name para executar, a mensagem HelloRequest deveria ser estendida, pois n\u00e3o h\u00e1 passar mais de uma mensagem para a opera\u00e7\u00e3o. Por outro lado, embora seja poss\u00edvel passar zero mensagens, esta n\u00e3o \u00e9 uma pr\u00e1tica recomendada. Isto porqu\u00ea caso o servi\u00e7o precisasse ser modificado no futuro, embora seja poss\u00edvel estender uma mensagem, n\u00e3o \u00e9 poss\u00edvel modificar a assinatura do servi\u00e7o. Assim, caso n\u00e3o haja a necessidade de se passar qualquer informa\u00e7\u00e3o para a opera\u00e7\u00e3o, recomenda-se que seja usada uma mensagem de entrada vazia, que poderia ser estendida no futuro. O mesmo se aplica ao resultado da opera\u00e7\u00e3o. Observe tamb\u00e9m que embora o servi\u00e7o de exemplo tenha apenas uma opera\u00e7\u00e3o, poderia ter m\u00faltiplas. Por exemplo, para definir uma vers\u00e3o em portugu\u00eas da opera\u00e7\u00e3o SayHello , podemos fazer da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 message HelloRequest { string name = 1 ; } message HelloReply { string message = 1 ; } message OlaRequest { // <<<<<==== string name = 1 ; } message OlaReply { // <<<<<==== string message = 1 ; } service Greeter { rpc SayHello ( HelloRequest ) returns ( HelloReply ) {} rpc DigaOla ( OlaRequest ) returns ( OlaReply ) {} // <<<<<==== } ... Observe que a nova opera\u00e7\u00e3o recebe como entrada mensagens OlaRequest e OlaReply , que tem defini\u00e7\u00f5es exatamente iguais a HellorRequest e HelloReply . Logo, em vez de definir novas mensagens, poder\u00edamos ter usado as j\u00e1 definidas. Novamente, esta n\u00e3o \u00e9 uma boa pr\u00e1tica, pois caso fosse necess\u00e1rio evoluir uma das opera\u00e7\u00f5es para atender a novos requisitos e estender suas mensagens, n\u00e3o ser\u00e1 necess\u00e1rio tocar o restante do servi\u00e7o. Apenas refor\u00e7ando, \u00e9 boa pr\u00e1tica definir requests e responses para cada m\u00e9todo, a n\u00e3o ser que n\u00e3o haja d\u00favida de que ser\u00e3o para sempre iguais.","title":"O servi\u00e7o"},{"location":"comm/#implementando-um-servico","text":"Agora modifique o arquivo .proto como acima, para incluir a opera\u00e7\u00e3o DigaOla , recompile e reexecute o servi\u00e7o. N\u00e3o d\u00e1 certo, n\u00e3o \u00e9 mesmo? Isto porqu\u00ea voc\u00ea adicionou a defini\u00e7\u00e3o de uma nova opera\u00e7\u00e3o, mas n\u00e3o incluiu o c\u00f3digo para implement\u00e1-la. Fa\u00e7amos ent\u00e3o a modifica\u00e7\u00e3o do c\u00f3digo, come\u00e7ando por ./src/main/java/io/grpc/examples/helloworld/HelloWorldServer.java . Este arquivo define a classe que implementa o servi\u00e7o Greeter , GreeterImpl , com um m\u00e9todo para cada uma das opera\u00e7\u00f5es definidas. Para confirmar, procure por sayHello para encontrar a implementa\u00e7\u00e3o de SayHello ; observe que a diferen\u00e7a do casing vem das boas pr\u00e1ticas de Java, de definir m\u00e9todos e vari\u00e1veis em Camel casing . Para que sua vers\u00e3o estendida do servi\u00e7o Greeter funcione, defina um m\u00e9todo correspondendo \u00e0 DigaOla , sem consultar o c\u00f3digo exemplo abaixo, mas usando o c\u00f3digo de sayHello como base; n\u00e3o se importe por enquanto com os m\u00e9todos sendo invocados. Note que os ... indicam que parte do c\u00f3digo, que n\u00e3o sofreu modifica\u00e7\u00f5es, foi omitido. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... private class GreeterImpl extends GreeterGrpc . GreeterImplBase { ... @Override public void sayHello ( HelloRequest req , StreamObserver < HelloReply > responseObserver ) { ... } @Override public void digaOla ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( \"Ola \" + req . getName ()). build (); responseObserver . onNext ( reply ); responseObserver . onCompleted (); } } Se voc\u00ea recompilar e reexecutar o c\u00f3digo, n\u00e3o perceber\u00e1 qualquer mudan\u00e7a na sa\u00edda do programa. Isto porqu\u00ea embora tenha definido um novo servi\u00e7o, voc\u00ea n\u00e3o o utilizou. Para tanto, agora modifique o cliente, em src/main/java/io/grpc/examples/helloworld/HelloWorldClient.java , novamente se baseando no c\u00f3digo existente e n\u00e3o se preocupando com \"detalhes\". 1 2 3 4 5 6 7 8 9 10 11 12 13 public void greet ( String name ) { logger . info ( \"Will try to greet \" + name + \" ...\" ); ... OlaRequest request2 = OlaRequest . newBuilder (). setName ( name ). build (); OlaReply response2 ; try { response2 = blockingStub . digaOla ( request2 ); } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } logger . info ( \"Greeting: \" + response2 . getMessage ()); } Agora sim, voc\u00ea pode reexecutar cliente e servidor. 1 2 3 ./gradlew installDist ./build/install/examples/bin/hello-world-server & ./build/install/examples/bin/hello-world-client Percebeu como foi f\u00e1cil adicionar uma opera\u00e7\u00e3o ao servi\u00e7o? Agora nos foquemos nos detalhes.","title":"Implementando um servi\u00e7o"},{"location":"comm/#stub-do-servidor","text":"Como criar o servidor Como definir o servi\u00e7o Como \"startar\" o servidor.","title":"Stub do servidor"},{"location":"comm/#stub-do-cliente","text":"Stub bloqueante Stub n\u00e3o bloqueante","title":"Stub do cliente"},{"location":"comm/#idl-grpc","text":"Outras caracter\u00edsticas da IDL do gRPC Tipos b\u00e1sicos bool: boolean (true/false) double: 64-bit; ponto-flutuante float: 32-bit; ponto-flutuante i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado siXX: signed uiXX: unsigned sfixedXX: codifica\u00e7\u00e3o de tamanho fixo bytes: 8-bit; inteiro sinalizado string: string UTF-8 ou ASCII 7-bit Any: tipo indefinido Diferentes tradu\u00e7\u00f5es Cole\u00e7\u00f5es Defina e implemente uma opera\u00e7\u00e3o DigaOlas em que uma lista de nomes \u00e9 enviada ao servidor e tal que o servidor responda com uma longa string cumprimentando todos os nomes, um ap;os o outro. Streams Do lado do servidor 1 2 3 4 5 6 7 8 9 10 11 List < String > listOfHi = Arrays . asList ( \"e aih\" , \"ola\" , \"ciao\" , \"bao\" , \"howdy\" , \"s'up\" ); @Override public void digaOlas ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { for ( String hi : listOfHi ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( hi + \", \" req . getName ()). build (); responseObserver . onNext ( reply ); } responseObserver . onCompleted (); } Do lado do cliente 1 2 3 4 5 6 7 8 9 10 11 OlaRequest request = OlaRequest . newBuilder (). setName ( name ). build (); try { Iterator < OlaReply > it = blockingStub . digaOlas ( request ); while ( it . hasNext ()){ OlaReply response = it . next (); logger . info ( \"Greeting: \" + response . getMessage ()); } } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; }","title":"IDL gRPC"},{"location":"comm/#exemplo-python","text":"1 2 3 4 5 6 7 8 9 10 apt-get install python3 apt-get install python3-pip python3 -m pip install --upgrade pip python3 -m pip install grpcio python3 -m pip install grpcio-tools git clone -b v1.10.x https://github.com/grpc/grpc cd grpc/examples/python/helloworld python3 greeter \\_ server.py python3 greeter \\_ client.py Para recompilar os stubs, fa\u00e7a 1 python3 -m grpc_tools.protoc -I../../protos --python_out = . --grpc_python_out = . ../../protos/helloworld.proto Modifique o servidor 1 2 def DigaOla ( self , request , context ): return helloworld_pb2 . OlaReply ( message = 'Ola, %s !' + request . name ) Modifique o cliente 1 2 response = stub . DigaOla ( helloworld_pb2 . OlaRequest ( name = 'zelelele' )) print ( \"Greeter client received: \" + response . message )","title":"Exemplo Python"},{"location":"comm/#estudo-de-caso-rpc-thrift","text":"Thrift","title":"Estudo de Caso RPC: Thrift"},{"location":"comm/#instalacao_1","text":"Baixe e compile o thrift ou instale-o usando apt-get, por exemplo. apt-get install thrift-compiler execute \"thrift\" na linha de comando. Para thrift com Java, tamb\u00e9m precisar\u00e3o dos seguintes arquivos slf4j libthrift0.13.0.jar coloque-os na pasta jars","title":"Instala\u00e7\u00e3o"},{"location":"comm/#idl-thrift","text":"Tipos b\u00e1sicos bool: boolean (true/false) byte: 8-bit; inteiro sinalizado i16: 16-bit; inteiro sinalizado i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado double: 64-bit; ponto-flutuante string: string UTF-8 binary: sequ\u00eancia de bytes Estruturas 1 2 3 4 5 6 struct Example { 1 : i32 number , 2 : i64 bigNumber , 3 : double decimals , 4 : string name = \"thrifty\" } Servi\u00e7os 1 2 3 4 5 service ChaveValor { void set ( 1 : i32 key , 2 : string value ), string get ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), void delete ( 1 : i32 key ) } N\u00e3o se pode retornar NULL!!! Exce\u00e7\u00f5es 1 2 3 4 exception KeyNotFound { 1 : i64 hora r , 2 : string chaveProcurada = \"thrifty\" } Containers List Map Set Exemplo: chavevalor.thrift 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } Compila\u00e7\u00e3o thrift --gen java chavevalor.thrift thrift --gen py chavevalor.thrift ChaveValorHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } package chavevalor ; import org.apache.thrift.TException ; import java.util.HashMap ; import chavevalor.* ; public class ChaveValorHandler implements ChaveValor . Iface { private HashMap < Integer , String > kv = new HashMap <> (); @Override public String getKV ( int key ) throws TException { if ( kv . containsKey ( key )) return kv . get ( key ); else throw new KeyNotFound (); } @Override public boolean setKV ( int key , String valor ) throws TException { kv . put ( key , valor ); return true ; } @Override public void delKV ( int key ) throws TException { kv . remove ( key ); } }","title":"IDL Thrift"},{"location":"comm/#arquitetura","text":"Runtime library -- componentes podem ser selecionados em tempo de execu\u00e7\u00e3o e implementa\u00e7\u00f5es podem ser trocadas Protocol -- respons\u00e1vel pela serializa\u00e7\u00e3oo dos dados TBinaryProtocol TJSONProtocol TDebugProtocol ... Transport -- I/O no ``fio'' TSocket TFramedTransport (non-blocking server) TFileTransport TMemoryTransport Processor -- Conecta protocolos de entrada e sa\u00edda com o \\emph{handler} Handler -- Implementa\u00e7\u00e3o das opera\u00e7\u00f5es oferecidas Server -- Escuta portas e repassa dados (protocolo) para o processors TSimpleServer TThreadPool TNonBlockingChannel","title":"Arquitetura"},{"location":"comm/#classpath","text":"1 2 3 javac -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java -d . *.java java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorServer java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorClient","title":"Classpath"},{"location":"comm/#referencias","text":"Tutorial","title":"Refer\u00eancias"},{"location":"comm/#estudo-de-caso-rpc-rmi","text":"TODO Como usar RMI.","title":"Estudo de Caso RPC: RMI"},{"location":"comm/#comunicacao-orientada-a-mensagens","text":"TODO MOM Enterprise Message Bus To Message Bus or Not: distributed system design O foco aqui \u00e9 na descri\u00e7\u00e3o da tecnologia, mas n\u00e3o das arquiteturas resultantes, que ser\u00e3o vistas no cap\u00edtulo seguinte.","title":"Comunica\u00e7\u00e3o orientada a Mensagens"},{"location":"comm/#publishsubscribe","text":"O padr\u00e3o publish/subscribe (ou pub/sub ) se apresenta como uma alternativa \u00e0 arquitetura cliente-servidor. Enquanto no modelo client-servidor, o cliente se comunica diretamente com um endpoint representado pelo servidor, no padr\u00e3o pub/sub temos clientes que enviam mensagens, ou publishers , e clientes que recebem as mensagens, ou subscribers . Esses dois tipos de clientes nunca se comunicam diretamente e n\u00e3o precisam nem saber da exist\u00eancia do outro. Um agente especial, denominado broker , gerencia a conex\u00e3o, armazena e filtrando as mensagens, al\u00e9m de distribu\u00ed-las corretamente aos subscribers .","title":"Publish/Subscribe"},{"location":"comm/#desacoplamento","text":"Um dos aspectos mais importantes proporciados pelo padr\u00e3o pub/sub \u00e9 o desacoplamento entre as partes envolvidas, o qual ocorre em v\u00e1rias dimens\u00f5es: Espa\u00e7o: publishers e subscribers n\u00e3o precisam se conhecer (por exemplo, n\u00e3o h\u00e1 necessidade de informar endere\u00e7o IP e porta de cada um). Tempo: publishers e subscribers n\u00e3o precisam nem estar em execu\u00e7\u00e3o ao mesmo tempo. Sincroniza\u00e7\u00e3o: opera\u00e7\u00f5es em cada componente n\u00e3o precisa ser interrompida durante a publica\u00e7\u00e3o ou recebimento.","title":"Desacoplamento"},{"location":"comm/#filtragem","text":"O broker tem um papel fundamental pois permite a especifica\u00e7\u00e3o de diversos n\u00edveis de filtragem: Baseada em assunto: subscribers se registram para receber mensagens de um ou mais t\u00f3picos de interesse. Em geral esses t\u00f3picos s\u00e3o strings com um formato hier\u00e1rquico, por exemplo /devices/sensor/+/temperature . Baseada em conte\u00fado: baseada em linguagem de filtragem de conte\u00fado espec\u00edfica. Downside: mensagem n\u00e3o pode ser criptografada. Baseada em tipo: leva em considera\u00e7\u00e3o o tipo ou classe de uma mensagem ou evento, como o tipo Exception e subtipos, por exemplo.","title":"Filtragem"},{"location":"comm/#mqtt","text":"MQTT \u00e9 um protocolo de transporte para publish/subscribe do tipo cliente-servidor. \u00c9 leve, aberto e f\u00e1cil de implementar, ideal para comunica\u00e7\u00e3o Machine to Machine (M2M) e uso no contexto de Internet das Coisas ( Internet of Things - I0T ). MQTT is a very light weight and binary protocol, and due to its minimal packet overhead, MQTT excels when transferring data over the wire in comparison to protocols like HTTP. Another important aspect of the protocol is that MQTT is extremely easy to implement on the client side. Ease of use was a key concern in the development of MQTT and makes it a perfect fit for constrained devices with limited resources today. O padr\u00e3o \u00e9 definido pela OASIS, uma organiza\u00e7\u00e3o aberta respons\u00e1vel por padr\u00f5es como SAML e DocBook. A especifica\u00e7\u00e3o atual \u00e9 a de n\u00famero 5, lan\u00e7ada em mar\u00e7o de 2019.","title":"MQTT"},{"location":"comm/#referencia","text":"MQTT Essentials","title":"Refer\u00eancia"},{"location":"comm/#estudo-de-caso-mosquitto","text":"Eclipse Mosquitto is an open source (EPL/EDL licensed) message broker that implements the MQTT protocol versions 5.0, 3.1.1 and 3.1. Mosquitto is lightweight and is suitable for use on all devices from low power single board computers to full servers.","title":"Estudo de caso: MosQuiTTo"},{"location":"comm/#instalacao_2","text":"1 2 apt-get install mosquitto # Ubuntu brew install mosquitto # MacOS","title":"Instala\u00e7\u00e3o"},{"location":"comm/#inicializando-o-servico","text":"O arquivo mosquito.conf cont\u00e9m as configura\u00e7\u00f5es para o broker . As configura\u00e7\u00f5es funcionam bem para o nosso caso. O broker aceita requisi\u00e7\u00f5es na porta 1883 e publishers e subscribers tamb\u00e9m utilizam essa porta por padr\u00e3o. Basta iniciar o broker com a op\u00e7\u00e3o -v para ter mais detalhes sobre o que ocorre internamente. 1 mosquitto -v","title":"Inicializando o servi\u00e7o"},{"location":"comm/#publicando","text":"Para publicar uma mensagem, o publisher deve indicar um host, porta, t\u00f3pico e mensagem. Caso o host e porta sejam omitidos, assume-se localhost:1883 . 1 2 3 # publicando valor de 40 para t\u00f3picos 'sensor/temperature/1' e 'sensor/temperature/2' mosquitto_pub -t sensor/temperature/1 -m 40 mosquitto_pub -t sensor/temperature/2 -m 32 Caso o subscriber n\u00e3o esteja em execu\u00e7\u00e3o, adicione a op\u00e7\u00e3o -r para que o broker retenha a mensagem.","title":"Publicando"},{"location":"comm/#consumindo","text":"O consumidor funciona de maneira semelhante, informando o t\u00f3pico de interesse: 1 2 # consumindo mensagens de t\u00f3pico /sensor/temperature/* mosquito_pub -t sensor/temperature/+","title":"Consumindo"},{"location":"comm/#programando","text":"Existem tamb\u00e9m APIs em diversas linguagem para desenvolvimento de aplica\u00e7\u00f5es que utilizem o Mosquitto. A biblioteca pode ser baixada aqui .","title":"Programando"},{"location":"comm/#exemplo-de-publisher","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import org.eclipse.paho.client.mqttv3.MqttClient ; import org.eclipse.paho.client.mqttv3.MqttConnectOptions ; import org.eclipse.paho.client.mqttv3.MqttException ; import org.eclipse.paho.client.mqttv3.MqttMessage ; import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence ; public class MqttPublishSample { public static void main ( String [] args ) { String topic = \"MQTT Examples\" ; String content = \"Message from MqttPublishSample\" ; int qos = 2 ; String broker = \"tcp://mqtt.eclipse.org:1883\" ; String clientId = \"JavaSample\" ; MemoryPersistence persistence = new MemoryPersistence (); try { MqttClient sampleClient = new MqttClient ( broker , clientId , persistence ); MqttConnectOptions connOpts = new MqttConnectOptions (); connOpts . setCleanSession ( true ); System . out . println ( \"Connecting to broker: \" + broker ); sampleClient . connect ( connOpts ); System . out . println ( \"Connected\" ); System . out . println ( \"Publishing message: \" + content ); MqttMessage message = new MqttMessage ( content . getBytes ()); message . setQos ( qos ); sampleClient . publish ( topic , message ); System . out . println ( \"Message published\" ); sampleClient . disconnect (); System . out . println ( \"Disconnected\" ); System . exit ( 0 ); } catch ( MqttException me ) { System . out . println ( \"reason \" + me . getReasonCode ()); System . out . println ( \"msg \" + me . getMessage ()); System . out . println ( \"loc \" + me . getLocalizedMessage ()); System . out . println ( \"cause \" + me . getCause ()); System . out . println ( \"excep \" + me ); me . printStackTrace (); } } } TODO Diferenciar de MOM Exerc\u00edcios - RPC e Publish/Subscribe Usando thrift e a linguagem Java, extenda o servi\u00e7o ChaveValor para retornar o valor antigo de uma determinada chave na opera\u00e7\u00e3o setKV() caso a chave j\u00e1 exista. Usando o broker mosquitto instalado localmente, fa\u00e7a em Java um publisher que simula um sensor de temperatura e publica valores aleat\u00f3rios entre 15 e 45 a cada segundo. Fa\u00e7a o subscriber que ir\u00e1 consumir esses dados de temperatura.","title":"Exemplo de Publisher"},{"location":"comm/#message-passing-interface","text":"Para facilitar a comunica\u00e7\u00e3o entre as partes do dom\u00ednio, s\u00e3o normalmente utilizadas API como a Message Passing Interface (MPI), que prov\u00ea fun\u00e7\u00f5es para distribui\u00e7\u00e3o e agrega\u00e7\u00e3o de dados entre os v\u00e1rios processos. A fun\u00e7\u00e3o broadcast, por exemplo, envia o mesmo conte\u00fado para diversos destinat\u00e1rios e a fun\u00e7\u00e3o scatter particiona o dado de acordo com o n\u00famero de destinat\u00e1rios e envia uma parcela para cada um.","title":"Message Passing Interface"},{"location":"comm/#protocolos-epidemicos","text":"Distributed Systems: Principles and Paradigms. Cap\u00edtulo 1, Figura 1. \u21a9 IEEE Floating Point \u21a9 IBM Floating Point \u21a9 Simplifica\u00e7\u00f5es s\u00e3o poss\u00edveis, mas introduzem outras complexidades. \u21a9 O Google stadia \u00e9 uma plataforma de jogos que vai na contram\u00e3o desta ideia, levando todo o processamento pesado para a nuvem. \u21a9 Implementing RPC \u21a9 Omitirei alguns detalhes aqui, em nome da generalidade, mas voc\u00eas podem recuper\u00e1-los em seus livros de Arquitetura de Computadores. \u21a9 O stub do servidor tamb\u00e9m \u00e9 conhecido como skeleton . \u21a9 Marshalling: representar par\u00e2metros de forma pr\u00f3pria para transmiss\u00e3o \"no fio\". \u21a9","title":"Protocolos Epid\u00eamicos"},{"location":"coord/","text":"Coordena\u00e7\u00e3o Como visto na se\u00e7\u00e3o sobre Multiprograma\u00e7\u00e3o , diversas tarefas exigem coordena\u00e7\u00e3o entre threads em uma aplica\u00e7\u00e3o monol\u00edtica em que se faz uso de concorr\u00eancia para melhor uso de recursos computacionais, obten\u00e7\u00e3o de melhor desempenho, e modulariza\u00e7\u00e3o do c\u00f3digo. Sistemas distribu\u00eddos levam concorr\u00eancia a um novo patamar de complexidade, fazendo uso de m\u00faltiplos processos, cada um com possivelmente m\u00faltiplos threads , ainda por cima, espalhados geograficamente. Outras solu\u00e7\u00f5es e abstra\u00e7\u00f5es s\u00e3o portanto necess\u00e1rias. Exclus\u00e3o M\u00fatua Um dos problemas enfrentados em sistemas que fazem uso de concorr\u00eancia, distribu\u00eddos ou n\u00e3o, \u00e9 a exclus\u00e3o m\u00fatua. Em um sistema monol\u00edtico, uma vari\u00e1vel global, um lock, ou outra primitiva de sincroniza\u00e7\u00e3o podem ser usadas na sincroniza\u00e7\u00e3o, mas em um sistema distribu\u00eddo, primitivas simples como estas provavelmente n\u00e3o estar\u00e3o dispon\u00edveis ou o sistema ser\u00e1 muito restrito. Como, ent\u00e3o, controlar o acesso de m\u00faltiplos processos a um recurso compartilhado, garantindo que cada processo controla exclusivamente aquele recurso durante seu acesso? Qualquer solu\u00e7\u00e3o que se proponha a este problema de exclus\u00e3o m\u00fatua, precisa ter as propriedades 1, 2, 3, e, idealmente, a 4, a seguir: Exclus\u00e3o M\u00fatua exclus\u00e3o m\u00fatua - somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks - se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o-inani\u00e7\u00e3o - todos os processos interessados conseguem, em algum momento, acessar o recurso; espera limitada - idealmente, o tempo de espera pelo recurso \u00e9 limitado. H\u00e1 diversas solu\u00e7\u00f5es para exclus\u00e3o m\u00fatua em sistemas distribu\u00eddos, em diversos cen\u00e1rios, com seus pr\u00f3s e contras. Tr\u00eas das mais simples, e que ilustram o universo de solu\u00e7\u00f5es s\u00e3o via um processo centralizador, em um anel em que a vez \u00e9 circulada, e baseada em quoruns. Coordenador Enquanto em um sistema monol\u00edtico h\u00e1 um sistema operacional que prov\u00ea abstra\u00e7\u00f5es simples para os processos a serem coordenados, em um sistema distribu\u00eddo, n\u00e3o h\u00e1 naturalmente tal entidade. Uma poss\u00edvel solu\u00e7\u00e3o para o problema de exclus\u00e3o m\u00fatua em um ambiente distribu\u00eddo \u00e9 justamente dar um passo para tr\u00e1s e introduzir um coordenador. Nesta abordagem, os processos que precisam acessar a regi\u00e3o cr\u00edtica s\u00e3o denominados participantes e um dos processos assume o papel de coordenador . \u00c9 poss\u00edvel que um mesmo processo atue nos dois pap\u00e9is sem nenhum preju\u00edzo. Os processos executam o seguinte protocolo: Participante Envia requisi\u00e7\u00e3o de acesso ao coordenador Espera por resposta do coordenador Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o, marca o recurso como livre Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado O diagrama a seguir apresenta uma execu\u00e7\u00e3o deste protocolo em um cen\u00e1rio com tr\u00eas participantes. O estado do coordenador mostra se o recurso est\u00e1 livre ou ocupado e quais processos esperam por permiss\u00e3o de acesso. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Part2->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part3] Coordenador->>Part2: ResponseFree note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Este algoritmo satisfaz as caracter\u00edsticas elencadas acima. Exclus\u00e3o m\u00fatua - se o coordenador autoriza um participante X, somente ap\u00f3s o participante X liberar o recurso \u00e9 que outro participante poder\u00e1 obter nova autoriza\u00e7\u00e3o. Aus\u00eancia de deadlocks - Todo processo que requisitar o recurso, entrar\u00e1 em uma fila, em apenas uma posi\u00e7\u00e3o; assim, a fila prover\u00e1 uma ordem total para os acessos, sem a possibilidade de circularidade nesta ordem. N\u00e3o-inani\u00e7\u00e3o - Dado que ningu\u00e9m fura a fila e que a cada vez que o recurso \u00e9 liberado a fila anda, em algum momento a vez do processo chegar\u00e1. Espera limitada - Dado que a posi\u00e7\u00e3o na fila pode apenas decrementar, seria poss\u00edvel estimar quanto tempo o participante precisa esperar para acessar o recurso. Outra vantagem deste algoritmo \u00e9 sua simplicidade e, consequentemente, facilidade de implementa\u00e7\u00e3o. Contudo, este algoritmo tem tamb\u00e9m desvantagens, por exemplo, se muitas requisi\u00e7\u00f5es de acesso forem feitas, o coordenador pode ser sobrecarregado e se tornar um gargalo no acesso \u00e0 regi\u00e3o cr\u00edtica. Mais s\u00e9rio ainda \u00e9 a quest\u00e3o de como lidar com falhas, por exemplo, se ou o coordenador ou o participante que detem o direito de acesso ao recurso para de funcionar, ent\u00e3o nenhum outro processo conseguir\u00e1 acesso. Estes aspectos nos permitem mergulhar na \u00e1rea de toler\u00e2ncia a falhas, e o faremos, mas mais tarde. Por enquanto, consideraremos toler\u00e2ncia a falhas de forma superficial, ap\u00f3s discutirmos outra abordagem. Anel Nesta abordagem, os processos se organizam em um anel l\u00f3gico, com um processo antes e outro depois. Um dos processos \u00e9 iniciado com um token que d\u00e1 acesso ao recurso e o token \u00e9 passado adiante no anel; sempre que estiver de posse do token, o processo pode acessar o recurso. Ou seja, todos os participantes executam o seguinte protocolo: Participante Ao receber o token de acesso, se quiser acessar o recurso, acessa. Envia o token para o pr\u00f3ximo n\u00f3 do anel. O diagrama adiante mostra uma execu\u00e7\u00e3o do algoritmo em que apenas os participantes 1 e 3 acessam o recurso. sequenceDiagram Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso note over Part1: Acessa o recurso Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso Como o algoritmo centralizado, o algoritmo do anel tamb\u00e9m garante as propriedades 1, 2, 3 e 4, al\u00e9m de ser f\u00e1cil de implementar, testar e entender. Diferente do algoritmo centralizado, o algoritmo do anel n\u00e3o sofre com problemas de gargalo, pois nenhum processo precisa participar em todos os acessos, como o coordenador. Contudo, o algoritmo do anel desperdi\u00e7a tempo passando o token para quem n\u00e3o necessariamente quer acessar a regi\u00e3o cr\u00edtica. Tamb\u00e9m importante \u00e9 que este algoritmo tamb\u00e9m sofre com falhas: se um participante falha enquanto com o token , levando-o para al\u00e9m. Lidando com Falhas Em ambos os algoritmos, centralizado e do anel, se um processo falhar, o algoritmo pode ficar \"travado\". Vejamos alguns casos espec\u00edficos: No algoritmo centralizado, se o coordenador falha antes de liberar o acesso para algum processo, ele leva consigo a permiss\u00e3o. Em ambos os algoritmos, se o processo acessando o recurso falha, a permiss\u00e3o \u00e9 perdida e os demais processos sofrer\u00e3o inani\u00e7\u00e3o. No algoritmo do anel, se qualquer outro processo falha, o anel \u00e9 interrompido o anel n\u00e3o conseguir\u00e1 circular. Observe que nem falamos de falhas dos canais e j\u00e1 temos diversos cen\u00e1rios a serem resolvidos, para os quais se lhes pedir uma solu\u00e7\u00e3o, tenho certeza absoluta de que me oferecer\u00e3o alguma baseada em timeouts . Por exemplo, se o processo n\u00e3o devolver a permiss\u00e3o de acesso antes de que uma certa quantidade de tempo tenha passado, um timeout , ent\u00e3o assuma que o mesmo parou de funcionar e n\u00e3o voltar\u00e1 mais, e gere uma nova permiss\u00e3o a ser passada a outros requisitantes. Aplicada esta ideia do timeout no algoritmo com coordenador, teremos o efeito ilustrado a seguir. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>Part2: ResponseOK activate Part2 note over Coordenador: Recurso=ocupado/Fila = [Part3] note over Part2: \ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80 deactivate Part2 Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree O problema desta e outras \"solu\u00e7\u00f5es\" baseadas em timeouts est\u00e1 no assumir que o processo parou de funcionar , pois caso isso n\u00e3o seja verdade, teremos agora duas autoriza\u00e7\u00f5es ao mesmo tempo no sistema, podendo levar \u00e0 viola\u00e7\u00e3o da propriedade de exclus\u00e3o m\u00fatua. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] rect rgb(200, 0, 0) Coordenador->>+Part3: ResponseOK Part2->>-Coordenador: RequestFree Part3->>-Coordenador: RequestFree end note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Por mais que se ajuste o valor do temporizador, em um sistema distribu\u00eddo ass\u00edncrono, mesmo que aumentado com um rel\u00f3gio para medir a passagem do tempo local, o mesmo pode sempre estar errado. Impossibilidade de detec\u00e7\u00e3o de falhas Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir um processo falho de um processo lento. Mais tarde discutiremos as implica\u00e7\u00f5es desta impossibilidade. Por agora, tentemos responder \u00e0 seguinte quest\u00e3o. Question Qual deve ser um timeout razo\u00e1vel para o meu sistema? A resposta depende de mais perguntas, como: Qual o custo \\(E\\) de esperar por mais tempo? Qual o custo \\(C\\) de cometer um engano? Qual a probabilidade \\(p\\) de cometer um engano? O custo esperado por causa dos erros, isto \u00e9, a esperan\u00e7a matem\u00e1tica da vari\u00e1vel aleat\u00f3ria custo, \u00e9 menor que o custo de se esperar por mais tempo, isto \u00e9, \\(C * p < E\\) ? Embora esta an\u00e1lise possa ser feita para estes algoritmos, a verdade \u00e9 que s\u00e3o realmente limitados e outras abordagens seriam melhor destino dos seus esfor\u00e7os. Por exemplo, podemos partir para a an\u00e1lise de algoritmos probabil\u00edsticos, pois afinal, como disse certa vez Werner Vogels, CTO da Amazon Se o mundo \u00e9 probabil\u00edstico, porqu\u00ea meus algoritmos devem ser determin\u00edsticos?\" Uma abordagem probabil\u00edstica interessante \u00e9 baseada em qu\u00f3runs. Qu\u00f3rum De acordo com o Dicion\u00e1rio Priberam da L\u00edngua Portuguesa, consultado em 17-04-2019 , \"qu\u00f3rum\" \u00e9 o N\u00famero de pessoas imprescind\u00edvel para a realiza\u00e7\u00e3o de algo. Aqui, este este algo ser\u00e1 a libera\u00e7\u00e3o de acesso ao recurso almejado pelos processos no sistema distribu\u00eddo. Esta abordagem \u00e9 semelhante em v\u00e1rios aspectos \u00e0 coordenada. De fato, um dos pap\u00e9is na abordagem \u00e9 o de coordenador, que executa o mesmo protocolo que antes. Entretanto, em vez de apenas um coordenador no sistema, temos \\(n\\) , dos quais o participante precisa obter \\(m > n/2\\) autoriza\u00e7\u00f5es antes de acessar o recurso; \\(m\\) \u00e9 o qu\u00f3rum do sistema. Qu\u00f3rum \\(n\\) coordenadores. \\(m > n/2\\) coordenadores J\u00e1 os demais participantes devem agora considerar todo o conjunto de coordenadores antes de assumir que tem acesso a um recurso. O algoritmo completo \u00e9 o seguinte: Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o, marca o recurso como livre Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado Participante Envia requisi\u00e7\u00e3o de acesso aos \\(n\\) coordenadores Espera por resposta de \\(m\\) coordenadores Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Al\u00e9m disso, para tornamos o problema mais interessante e demonstrar o potencial deste algoritmo, consideremos que as autoriza\u00e7\u00f5es s\u00e3o armazenadas somente em mem\u00f3ria, e que coordenadores, ao falhar e ent\u00e3o resumir suas atividades, esqueceme das autoriza\u00e7\u00f5es j\u00e1 atribu\u00eddas. Perda de mem\u00f3ria Quando um coordenador falha, esquece que deu ok e reinicia seu estado. Vejamos uma execu\u00e7\u00e3o bem sucedida destes algoritmo: TODO Construir execu\u00e7\u00e3o bem sucedida. Este algoritmo \u00e9 bom? Suponhamos o seguinte cen\u00e1rio: Coordenadores = { \\(c_1,c_2,c_3,c_4,c_5,c_6,c_7\\) } \\(n = 7\\) \\(m = 4\\) Participante \\(p_1\\) consegue autoriza\u00e7\u00e3o de { \\(c_1,c_2,c_3,c_4\\) } e entra na regi\u00e3o cr\u00edtica. Coordenador \\(c_4\\) falha e se recupera Participante \\(p_2\\) consegue autoriza\u00e7\u00e3o de { \\(c_4,c_5,c_6,c_7\\) } e entra na regi\u00e3o cr\u00edtica. Neste cen\u00e1rio, a propriedade de Exclus\u00e3o M\u00fatua \u00e9 violada. Isto porqu\u00ea, dados os dois qu\u00f3runs, todos os processos na interse\u00e7\u00e3o foram reinicidaos. Mas de forma geral, qual a probabilidade de isso acontecer? Ou seja, dados dois quoruns, de tamanho \\(m\\) , que se sobrepoem em \\(k\\) processos, qual a probabilidade \\(P_v\\) de que os \\(k\\) processos na interse\u00e7\u00e3o sejam reiniciados e levem \u00e0 viola\u00e7\u00e3o? Seja a \\(P\\) a probabilidade de um coordenador em espec\u00edfico falhar e se recuperar dentro de uma janela de tempo \\(\\delta t\\) . Temos Probabilidade de falha de exatamente 1 coordenador: \\(P^1(1-P)^{n-1}\\) Probabilidade de \\(k\\) coordenadores falharem: \\(P^k(1-P)^{n-k}\\) Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem: \\(\\binom{m}{k} P^k(1-P)^{m-k}\\) Mas qual \u00e9 o tamanho \\(k\\) da interse\u00e7\u00e3o? \\(\\left| A \\cup B\\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cap B \\right| \\Rightarrow n = m + m - k\\) \\(\\left| A \\cap B \\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cup B\\right| \\Rightarrow k = m + m - n = 2m - n\\) At\u00e9 agora consideramos que a \\(k\\) corresponde \u00e0 cardinalidade da interse\u00e7\u00e3o dos dois quoruns, mas se mais do que a interse\u00e7\u00e3o forem reiniciados, tamb\u00e9m teremos problemas. Assim, se \\(k\\) assume qualquer valor entre o tamanho da interse\u00e7\u00e3o e o n\u00famero total de coordenadores, teremos problemas. Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem, para qualquer \\(k\\) variando de \\(2m-n\\) a \\(n\\) : \\(P_v = \\sum_{k=2m-n}^n \\binom{m}{k} P^k(1-P)^{m-k}\\) Para facilitar o entendimento desta grandeza, considere o exemplo: \\(P=0.0001\\) (1 minuto a cada 10 dias) \\(n = 32\\) \\(m = 0.75n\\) \\(P_v < 10^{-40}\\) ( Curiosidade sobre \\(10^{40}\\) ) A probabilidade de viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua, neste caso, \u00e9 muito pequena, a despeito de suportar falhas dos coordenadores. Pr\u00f3 Tolera falhas de coordenadores, com probabilidade controlada de viola\u00e7\u00e3o de exclus\u00e3o m\u00fatua. Mas e as outras propriedades desej\u00e1veis do algoritmo de exclus\u00e3o m\u00fatua, s\u00e3o alcan\u00e7adas? Relembrando: Contras Exclus\u00e3o M\u00fatua probabil\u00edstica: \\(1 - P_v\\) N\u00e3o-inani\u00e7\u00e3o E se cada participante obtiver o ok de um coordenador? Temporizador para quebrar o deadlock ? Espera limitada Aborts podem levar a espera infinita. Assim, este agoritmo tamb\u00e9m pode n\u00e3o ser adequado para certas situa\u00e7\u00f5es. Vamos tentar reacessar os problemas da primeira abordagem. Por um lado, o uso de um l\u00edder para coordenar a\u00e7\u00f5es em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto \u00fanico de falha, como no algoritmo de exclus\u00e3o m\u00fatua centralizado. Mas e se substitu\u00edssemos o coordenador no caso de falhas? Este \u00e9 o problema conhecido como elei\u00e7\u00e3o de l\u00edderes. TODO Maekawa - Diminui n\u00famero de votos necess\u00e1rios ( descri\u00e7\u00e3o ) Lamport - Usa rel\u00f3gios l\u00f3gicos, mas \u00e9 poss\u00edvel entender sem este background ( descri\u00e7ao ) Ricart-Agrawala - Melhora algoritmo de Lamport ( descri\u00e7\u00e3o ) Distributed-Mutual-Exclusion-slides Elei\u00e7\u00e3o de L\u00edderes O problema da escolha de um processo centralizador, ou l\u00edder, pode ser posto informalmente como o procedimento pelo qual um processo \u00e9 escolhido dentre os demais processos, sendo que o processo escolhido \u00e9 ciente da escolha e todos os demais processos o identificam como eleito . Uma nova elei\u00e7\u00e3o deve acontecer sempre que o l\u00edder se tornar indispon\u00edvel . Formalmente, um algoritmo de elei\u00e7\u00e3o de l\u00edderes deve satisfazer as seguintes condi\u00e7\u00f5es. Elei\u00e7\u00e3o de L\u00edderes 1 Termina\u00e7\u00e3o: algum processo deve se considerar l\u00edder em algum momento. Unicidade: somente um processo se considera l\u00edder. Acordo: todos os outros processos sabem quem foi eleito l\u00edder. Para entendermos melhor o problema, tentemos desenvolver um protocolo simples para escolhermos um l\u00edder, por exemplo, em sua turma da disciplina de Sistemas Distribu\u00eddos. Vejamos algumas quest\u00f5es importantes. Candidatos: s\u00e3o todos os membros eleg\u00edveis ou apenas um subconjunto dos mesmos? Comunica\u00e7\u00e3o: todos se conhecem e se falam diretamente ou h\u00e1 grupos incomunic\u00e1veis dentro da turma? Estabilidade: de que adianta eleger um dos colegas se frequentemente falta n\u00e3o est\u00e1 presente quando necess\u00e1rio? Em termos computacionais, estas quest\u00f5es s\u00e3o relevantes pois todos os processoes n\u00e3o nascem iguais; alguns residem em m\u00e1quinas com mais mem\u00f3ria, mais poder de processamento, melhor conex\u00e3o com o resto do mundo ou maior grau de conectividade. Talvez este processo seja um l\u00edder mais \u00fatil que os demais. Al\u00e9m disso, se o processo est\u00e1 frequentemente desconectado, mesmo que bem servido de recursos, n\u00e3o ser\u00e1 um bom l\u00edder. Ainda que assumamos um conjunto de processos indiferenci\u00e1veis entre si, com acesso equivalente a recursos e que estejam sempre dispon\u00edves, ou exatamente por isso, temos um problem mais fundamental para resolver: para eleger um l\u00edder, precisamos diferenciar processos. Dentro de uma \u00fanica m\u00e1quina, identificamos processos facilmente usando seu PID , ou process id , um inteiro associado a cada processo instanciado pelo sistema operacional; o PID \u00e9 v\u00e1lido enquanto o processo estiver executando e pode ser reciclado uma vez que o processo para de executar, o que pode ser um problema. Al\u00e9m disso, se o host \u00e9 reiniciado, os PID tamb\u00e9m s\u00e3o, e portanto esta identifica\u00e7\u00e3o n\u00e3o \u00e9 duradoura. Mais importante, o PID s\u00f3 faz sentido dentro de uma \u00fanica m\u00e1quina e n\u00e3o em um sistema distribu\u00eddo. Se apenas uma inst\u00e2ncia do processo executa em um mesmo host , ent\u00e3o o identificador do host (e.g., endere\u00e7o IP) em si \u00e9 suficiente e, de fato, comumente utilizado. Se mais de um processo executa no mesmo host , ent\u00e3o cabe ao desenvolvedor criar um esquema que permita diferenciar os processos, e n\u00e3o precisa ser nada complicado; pode ser apenas um par\u00e2metro passado na inicializa\u00e7\u00e3o do processo ou a combina\u00e7\u00e3o IP/porta . Assumindo que um esquema de nomea\u00e7\u00e3o est\u00e1 dispon\u00edvel e que todos os processos se conhecem, voltemos ao problema de eleger um l\u00edder para sua turma. Uma abordagem que pode funcionar \u00e9 colocar todos os candidatos para brigar e quem sobrar em p\u00e9 no final, \u00e9 o novo l\u00edder. A despeito desta op\u00e7\u00e3o gerar um l\u00edder n\u00e3o muito popular, o algoritmo do brig\u00e3o \u00e9 um cl\u00e1ssico. Algoritmo do Brig\u00e3o ( Bully ) No algoritmo do brig\u00e3o, alguma caracter\u00edsticas compar\u00e1vel dos processos \u00e9 escolhida e aquele processo funcional com o valor de tal caracter\u00edstica mais vantajoso para um l\u00edder \u00e9 escolhido como tal. Por exemplo, pode ser vantajoso ter um l\u00edder com maior quantidade de mem\u00f3ria, frequ\u00eancia da CPU ou largura de banda da conex\u00e3o com a Internet; no caso de empate, o identificador do processo pode ser usado para gerar uma ordem total entre os processos. Para simplificar, vamos assumir que o identificador do processo reflete as qualidades do mesmo para a lideran\u00e7a, tal que o processo com maior identificador seja o melhor candidato. Os maiores processos, os \"brig\u00f5es\", eliminam os processos menores da competi\u00e7\u00e3o, sempre que uma elei\u00e7\u00e3o acontecer. O algoritmo \u00e9 apresentado a seguir, onde \\(p\\) e \\(q\\) s\u00e3o usados para representar tanto identificadores de processos quando os processos em si. Algoritmo do Brig\u00e3o Quando \\(p\\) suspeita que o l\u00edder n\u00e3o est\u00e1 presente (muito tempo se receber mensagens do mesmo) \\(p\\) envia mensagem (ELEICAO, \\(p\\) ) para todos os processos com identificador maior que \\(p\\) Inicia temporizador de respostas Quando temporizador de respostas expira Envia (COORD, \\(p\\) ) para todos os processos Quando recebe (Ok, \\(p\\) ) Para temporizador de resposta Quando \\(p\\) recebe (ELEICAO, \\(q\\) ), \\(q < p\\) Envia (OK, \\(q\\) ) Quando um processo falho se recupera Inicia uma elei\u00e7\u00e3o Observe como o algoritmo foi descrito em termos de eventos e n\u00e3o de forma sequencial. Este tipo de especifica\u00e7\u00e3o \u00e9 comum para algoritmos paralelos e distribu\u00eddos, pois n\u00e3o h\u00e1 uma sequ\u00eancia pr\u00e9-estabelecida de passos a serem executados por todos os processos, apenas alguns pontos de coordena\u00e7\u00e3o. No exemplo a seguir, temos 5 processos, com identificadores de 1 a 5, passando por 7 passos at\u00e9 que a elei\u00e7\u00e3o se complete. Observe que os processos n\u00e3o sabem a priori como os eventos aconteceram e apenas reagem aos eventos de recep\u00e7\u00e3o de mensagens e expira\u00e7\u00e3o de temporizadores . o l\u00edder j\u00e1 \u00e9 o processo 5 (em rosa). os processos 2 e 3 (amarelo) se \"cansaram\" de esperar por 5, que falhou (em cinza, e se candidataram a l\u00edder, enviando (ELEICAO,2) e (ELEICAO,3), respectivamente, (verde). 4 responde a 2 a 3 com (OK,2) e (OK,3) como resposta a 2 e 3, respectivamente, e 3 envia (OK,2) para 2. 1 se candidata com enviando (ELEICAO,1). 2, 3 e 4 respondem com (OK,1). 4 se candidata enviando (ELEICAO,4) para 5, que n\u00e3o responde, j\u00e1 que est\u00e1 falho. 4 se declara l\u00edder e envia (COORD,4) a todos os processos. Como j\u00e1 discutido antes, a escolha do valor temporizador \u00e9 fundamental para o bom funcionamento do algoritmo. Se o temporizador usado pelos processos para esperar pelo l\u00edder for ajustado de forma agressiva, frequentemente ser\u00e3o iniciadas elei\u00e7\u00f5es mesmo que o l\u00edder n\u00e3o tenha falhado. J\u00e1 se o valor do temporizador for muito grande, o sistema demorar\u00e1 a eleger um novo l\u00edder . Da mesma forma, se o tempo esperado por um candidato antes de se declarar l\u00edder for muito curto, mais de um processo pode se declarar l\u00edder , uma situa\u00e7\u00e3o conhecida como split-brain . Idealmente, um processo deveria esperar por outro enquanto o outro estiver apto a responder, mas isso requer saber quando o outro processo n\u00e3o est\u00e1 mais apto, isto \u00e9, falhou. Como identificar exatamente quando isso aconteceu \u00e9 imposs\u00edvel em sistemas distribu\u00eddos ass\u00edncronos, o algoritmo do brig\u00e3o n\u00e3o resolve o problema neste ambiente. Mas se delimitarmos melhor o ambiente, podemos chegar a solu\u00e7\u00f5es melhores. Algoritmos em An\u00e9is Consideremos processos organizados em um anel l\u00f3gico em que processos troquem mensagens apenas com processos \u00e0 \"esquerda\" e \u00e0 \"direita\". Considere tamb\u00e9m que todos os processos s\u00e3o exatamente id\u00eanticos, inclusive n\u00e3o possuindo identificadores pr\u00f3prios. Suponha o seguinte algoritmo de elei\u00e7\u00e3o neste anel, em que um processo inicialmente Seguidor se torna Candidato, ent\u00e3o se declara Eleito, avisa a seus pares e, finalmente, se declara Empossado. Algoritmo do Anel 1 Organize os n\u00f3s em um anel l\u00f3gico \\(C \\gets\\) Seguidor Quando um processo acha que o l\u00edder est\u00e1 morto \\(C \\gets\\) Candidato Envia (VoteEmMim) para \"a direita\" no anel. Quando um processo recebe (VoteEmMim) Se \\(C =\\) Seguidor envia (VoteEmMim) para a direita Se \\(C =\\) Candidato \\(C \\gets\\) Eleito envia (HabemosLeader) para a direita Quando um processo recebe (HabemosLeader) Se \\(C =\\) Seguidor envia (HabemosLeader) para a direita Se \\(C =\\) Eleito \\(C \\gets\\) Empossado Imagine um cen\u00e1rio com dois processos, como na imagem a seguir. Os nomes dos processos s\u00e3o apenas para facilitar o entendimento do fluxo dem mensagens e n\u00e3o est\u00e3o acess\u00edveis aos processos. Executando o algoritmo Anel 1, os processos enviam ( \\(\\rightarrow\\) ) e recebem ( \\(\\leftarrow\\) ) as seguintes mensagens e ajustam \\(C\\) da seguinte forma. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado Agora imagine que por um acaso, tanto processo 1 quanto o 2 se candidatassem ao mesmo tempo. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado \\(C \\gets\\) Empossado Como n\u00e3o h\u00e1 nada que diferencie os processos entre si, este cen\u00e1rio \u00e9 perfeitamente v\u00e1lido, e se no primeiro cen\u00e1rio o algoritmo estava correto ao eleger o processo 1, ent\u00e3o no segundo cen\u00e1rio o 1 tamb\u00e9m deve ser eleito, j\u00e1 que a sequ\u00eancia de evento observadas \u00e9 exatamente a mesma. Mas o processo 2 tamb\u00e9m v\u00ea a mesma sequ\u00eancia, ent\u00e3o tamb\u00e9m deve ser eleito. Assim, violamos a propriedade da Unicidade. Para quebrar essa simetria entre os processo, podemos permitir que saibam seus identificadores. No algoritmo seguinte, permitimos que os processos conhe\u00e7am seus identificadores e um processo que suspeite do l\u00edder atual, envia uma mensagem no anel para coletar os identificadores de todos os processos. Algoritmo do Anel 2 Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem [ \\(p\\) ] \"\u00e0 direita\". Quando \\(p\\) recebe \\(l\\) Se \\(p \\not \\in l\\) Envia \\([p:l]\\) para a direita. Se \\(p \\in l\\) Escolhe menor id em \\(l\\) como l\u00edder. Este algoritmo envia at\u00e9 \\(n^2\\) mensagens, se todos iniciarem a elei\u00e7\u00e3o ao mesmo tempo, e as mensagens crescem at\u00e9 o tamanho \\(n\\) . O algoritmo de Chang e Robert 2 limita o tamanho das mensagens ao pr\u00e9-selecionar candidatos vi\u00e1veis. Algoritmo de Chang e Robert Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem \\((p)\\) \u00e0 direita Quando \\(p\\) recebe \\((q)\\) Se \\(p = q\\) \\(p\\) se declara l\u00edder Sen\u00e3o e se \\(q > p\\) Envia \\((q)\\) para a direita. Neste algoritmo, todas as mensagens tem tamanho \\(O(1)\\) e somente uma mensagem d\u00e1 uma volta completa do anel; todas as outras s\u00e3o descartadas no meio do caminho. Apesar disso, pode-se demonstrar que o pior caso em termos de n\u00famero de mensagens do algoritmo at\u00e9 que algu\u00e9m se declare l\u00edder \u00e9 \\(O(n^2)\\) . Exerc\u00edcio: Quantidade de mensagens O pior caso em termos de n\u00famero de mensagens at\u00e9 que algu\u00e9m seja eleito \u00e9 \\(O(n^2)\\) . Descreva como os n\u00f3s devem estar organizados para que esta situa\u00e7\u00e3o ocorra. Observe que no algoritmo um processo apenas se \"declara l\u00edder\", mas os outros n\u00e3o necessariamente ficam sabendo disso. Como voc\u00ea o corrigiria para que terminasse? Diversos outros algoritmos existem para a topologia em anel. O algoritmo de Franklin \u00e9 um dos que prop\u00f5e melhorias para reduzir quantidade de mensagens usadas na elei\u00e7\u00e3o. Ele faz isso em rodadas, comparando identificadores com outros processos ativos tanto \u00e0 esquerda quanto \u00e0 direita e desativando os processos n\u00e3o vi\u00e1veis. Algoritmo de Franklin Organize os n\u00f3s em um anel l\u00f3gico Ativo \\(\\gets 1\\) Quando \\(p\\) acha que o l\u00edder est\u00e1 morto e se Ativo$ = 1$: Envia mensagem \\((p)\\) \u00e0 direita e \u00e0 esquerda Quando \\(p\\) recebe \\(e\\) e \\(d\\) , da esquerda e da direita, respectivamente: Se Ativo \\(=1\\) Se \\(max(e,d) < p\\) Envia mensagem \\(p\\) \u00e0 direita e \u00e0 esquerda Se \\(max(q,r) > p\\) Ativo \\(\\gets 0\\) Envia mensagem \\(-p\\) \u00e0 direita e \u00e0 esquerda Se \\(max(q,r) = p\\) \\(p\\) se declara l\u00edder. Se Ativo \\(=0\\) Repassa cada messagem para o outro lado. No exemplo na figura, os n\u00f3s brancos s\u00e3o ativos e os amarelos inativos. Observe o papel do n\u00f3 no centro, supondo que tem o maior identificador entre todos os processos. Inicialmente ele envia as mensagens em verde para os lados, que levam seus vizinhos imediatos a se inativarem. Na segunda rodada, as mensagens s\u00e3o repassadas para os vizinhos dos vizinhos, que tamb\u00e9m se inativam. Observe o seguinte: Em cada fase, para qualquer par de vizinhos ativos, pelos um dos dois \u00e9 inativado e, portanto, o n\u00famero de ativos cai pela metade; logo h\u00e1 no m\u00e1ximo \\(O(log n)\\) fases. Na primeira fase, cada processo ativo leva a \\(4\\) mensagens serem enviadas na rede (sem nenhuma otimiza\u00e7\u00e3o). Dado que s\u00e3o \\(n\\) processos, temos \\(4n\\) mensagens, \\(O(n)\\) Na segunda fase, cada processo ativo leva a 8 mensagens. Contudo, metade dos processos, pelo menos, foram inativados na primeira fase. Logo, temos \\(8n \\times n/2, O(n)\\) Assim, no m\u00e1ximo \\(O(n log n)\\) mensagens s\u00e3o enviadas em uma execu\u00e7\u00e3o do algoritmo. Algoritmo do YoYo Saindo da topologia em anel, vejamos o algoritmo do Yoyo, que funciona em qualquer topologia conexa, mesmo se processos n\u00e3o puderem se falar diretamente. Inicialmente as arestas do formado pelos processos e seus canais de comunica\u00e7\u00e3o s\u00e3o n\u00e3o direcionadas, mas na medida em que o protocolo \u00e9 executado, as arestas s\u00e3o marcadas como tendo um ou outro sentido. Esta marca\u00e7\u00e3o \u00e9 apenas l\u00f3gica e mensagens fluem em ambos os sentidos. De acordo com o tipo de arestas que um processo tem, ele \u00e9 classificado como um de tr\u00eas tipos: Fonte (source) - processo que s\u00f3 tem arestas de sa\u00edda Vertedouro (sink) - processo que s\u00f3 tem arestas de chegada Interno - processo que tem arestas de chegada e de sa\u00edda O algoritmo executa em duas fases. Na primera, cada processo marca sua arestas como apondando para o maior dentre si pr\u00f3prio e seus vizinhos. Na segunda fase, mensagens \"v\u00e3o e voltam\", o que d\u00e1 o nome ao algoritmo. Na \"ida\", as mensagens v\u00e3o das fontes para os vertedouros, que identificam quais fontes tem os menores identificadores e sinalizam para que continuem fontes na pr\u00f3xima etapa com mensagens de volta. As mensagens de volta reordenam as arestas para garantir este comportamento. Vejamos o algoritmo em mais detalhes. Algoritmo do YoYo Fase 1 \\(p\\) envia seu identificador para seus vizinhos. Quando \\(p\\) recebe \\(q\\) Se \\(p>q\\) Marca a aresta em que recebeu \\(q\\) como sendo de chegada ( \\(p\\leftarrow q\\) ) Sen\u00e3o Marca a aresta em que recebeu \\(q\\) como sendo de sa\u00edda ( \\(q\\leftarrow p\\) ) Se \\(p\\) \u00e9 uma fonte \\(p\\) envia seu identificador em todas as suas arestas de sa\u00edda. Quando \\(p\\) receber \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda Se recebeu apenas \\(S\\) Executa fase 2 novamente Fase 2 Se \\(p\\) \u00e9 um n\u00f3 interno * Quando \\(p\\) receber identificadores em todas as suas arestas de entrada * escolhe o menor id recebido \\(m\\) * envia \\(m\\) em todas as suas arestas de sa\u00edda * Quando \\(p\\) recebeu \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda * Se recebeu algum \\(S\\) * envia \\(S\\) para vizinhos de onde recebeu \\(m\\) * envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) * Se n\u00e3o recebeu \\(S\\) * envia \\(N\\) para vizinhos de onde recebeu algum id. Se \\(p\\) \u00e9 um vertedouro * Quando \\(p\\) receber identificadores em todas as suas arestas de entrada * escolhe o menor id recebido \\(m\\) * envia \\(S\\) para vizinhos de onde recebeu \\(m\\) * envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) N inverte a dire\u00e7\u00e3o das arestas em que trafega. Fonte Veja um exemplo com 3 processos em destaque, uma fonte, um interno e um vertedouro. Veja o seguinte exemplo, em que cada figura mostra um est\u00e1gio da resolu\u00e7\u00e3o do problema de elei\u00e7\u00e3o de l\u00edderes. a) A rede em seu estado inicial. b) Rede orientada pela primera fase c) Propaga\u00e7\u00e3o de Fontes d) Propaga\u00e7\u00e3o de Vertedouros e) Inativa\u00e7\u00e3o dos vertedouros Exemplo: Embora interessante, este algoritmo tamb\u00e9m tem problemas, sendo um dos mais cr\u00edticos a forma de lidar com falhas, mesmo sem considerar falhas de processos. Suponha que o canal de comunica\u00e7\u00e3o entre os processos 2 e 10 pare de funcionar. O que acontecer\u00e1? Esta \u00e9 uma situa\u00e7\u00e3o que denominamos particionamento da rede e que neste caso levar\u00e1 a duas elei\u00e7\u00f5es concorrentes acontecerem e, consequentemente, a dois l\u00edderes sendo eleitos, o que \u00e9 conhecido na \u00e1rea como split-brain . Vejamos esta e outras situa\u00e7\u00f5es problem\u00e1ticas em elei\u00e7\u00e3o de l\u00edderes. Quest\u00f5es importantes Split-brain Se o algoritmo viola a propridade de unicidade, ent\u00e3o fica com split-brain , em que parte da rede v\u00ea um processo como l\u00edder e parte v\u00ea outro. Se o l\u00edder \u00e9 o respons\u00e1vel por coordenar o acesso a uma regi\u00e3o cr\u00edtica, como visto no algoritmo coordenado de exclus\u00e3o m\u00fatua, ent\u00e3o ter dois l\u00edderes poder\u00e1 levar a dois processos na regi\u00e3o cr\u00edtica e portanto viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua. Uma das formas de evitar split-brain \u00e9 atribuir um \"peso\" para cada processo e s\u00f3 aceitar que um l\u00edder seja declarado se o mesmo seus votos carregarem mais da metade do peso do sistema. Ainda assim, temos problemas, pois \u00e9 necess\u00e1rio que rodadas sucessivas do algoritmo invalidem as elei\u00e7\u00f5es anteriores. O algoritmo Raft de difus\u00e3o at\u00f4mica, que estudaremos adiante, define mandatos e garante, com pesos, que somente um l\u00edder existe em cada mandato. Devido \u00e0 natureza ass\u00edncrona do sistema, processos podem se achar em mandatos distintos e, por isso, o mandato \u00e9 associado a todas as comunica\u00e7\u00f5es; mensagens recebidas de mandatos anteriores s\u00e3o sumariamente descartadas. Mas por qu\u00ea precisamos de mandatos sucessivos? Para substituir um l\u00edder que tenha falhado. O que nos leva a outros dois problemas, o da detec\u00e7\u00e3o de falhas e o da estabilidade do l\u00edder. Estabilidade Dizemos que um algoritmo de elei\u00e7\u00e3o de l\u00edderes \u00e9 est\u00e1vel se uma vez que um l\u00edder \u00e9 eleito, uma nova elei\u00e7\u00e3o s\u00f3 acontece se o l\u00edder falha. Considere o algoritmo do brig\u00e3o. Imagine, no exemplo apresentado, que o processo 5 teve problemas de comunica\u00e7\u00e3o e foi percebido como falho pelos demais. Neste caso, o 4 seria eleito l\u00edder. Mas se o problema que aflige 5 \u00e9 tempor\u00e1rio, 5 voltar\u00e1 e executar\u00e1 nova elei\u00e7\u00e3o, tornando-se l\u00edder novamente. Se este cen\u00e1rio se repente indefinidamente, o sistema poder\u00e1 ser seriamente comprometido em seu desempenho. Uma vers\u00e3o est\u00e1vel do algoritmo tentaria, por exemplo, associar ao peso do processo o tempo de exe\u00e7\u00e3o ininterrupta do mesmo. Assim, quanto mais tempo um processo execute, maior ser\u00e1 seu peso e sua capacidade de manter a lideran\u00e7a. Se o mesmo falhar, ent\u00e3o seu peso ser\u00e1 drasticamente reduzido e suas chances de ser eleito l\u00edder reduzidas temporariamente. Observe que os problemas enfrentados s\u00e3o ligados \u00e0 detec\u00e7\u00e3o e contorna\u00e7\u00e3o de falhas. Detec\u00e7\u00e3o de falhas Como j\u00e1 mencionado antes, detec\u00e7\u00e3o de falhas \u00e9 o mecanismo pelo qual um processo monitora e percebe se outro falhou. Pensemos em como um processo monitora o outro em um sitema distribu\u00eddo. Claramente, por meio de troca de mensagens e temporizadores. Mas se estamos falando de sistemas distribu\u00eddos ass\u00edncronos, ent\u00e3o mensagens podem ser atrasadas indefinidamente ou rel\u00f3gios podem ser atrasados, ent\u00e3o n\u00e3o se pode confiar na falta de recep\u00e7\u00e3o de uma mensagem como garantia de que um processo parou de funcionar. Aprofundemo-nos nos pr\u00f3ximos cap\u00edtulo nos conceitos de tempo e toler\u00e2ncia a falhas, mas enquanto isso, fiquemos com o seguinte resultado. Detec\u00e7\u00e3o de falhas Detec\u00e7\u00e3o de falhas perfeita \u00e9 imposs\u00edvel... em sistemas distribu\u00eddos ass\u00edncronos (Internet) sujeitos \u00e0 parti\u00e7\u00f5es (Internet) com requisitos de disponibilidade total. A Probabilistically Correct Leader Election Protocol for Large Groups \u21a9 An improved algorithm for decentralized extrema-finding in circular configurations of processes . \u21a9","title":"Coordena\u00e7\u00e3o"},{"location":"coord/#coordenacao","text":"Como visto na se\u00e7\u00e3o sobre Multiprograma\u00e7\u00e3o , diversas tarefas exigem coordena\u00e7\u00e3o entre threads em uma aplica\u00e7\u00e3o monol\u00edtica em que se faz uso de concorr\u00eancia para melhor uso de recursos computacionais, obten\u00e7\u00e3o de melhor desempenho, e modulariza\u00e7\u00e3o do c\u00f3digo. Sistemas distribu\u00eddos levam concorr\u00eancia a um novo patamar de complexidade, fazendo uso de m\u00faltiplos processos, cada um com possivelmente m\u00faltiplos threads , ainda por cima, espalhados geograficamente. Outras solu\u00e7\u00f5es e abstra\u00e7\u00f5es s\u00e3o portanto necess\u00e1rias.","title":"Coordena\u00e7\u00e3o"},{"location":"coord/#exclusao-mutua","text":"Um dos problemas enfrentados em sistemas que fazem uso de concorr\u00eancia, distribu\u00eddos ou n\u00e3o, \u00e9 a exclus\u00e3o m\u00fatua. Em um sistema monol\u00edtico, uma vari\u00e1vel global, um lock, ou outra primitiva de sincroniza\u00e7\u00e3o podem ser usadas na sincroniza\u00e7\u00e3o, mas em um sistema distribu\u00eddo, primitivas simples como estas provavelmente n\u00e3o estar\u00e3o dispon\u00edveis ou o sistema ser\u00e1 muito restrito. Como, ent\u00e3o, controlar o acesso de m\u00faltiplos processos a um recurso compartilhado, garantindo que cada processo controla exclusivamente aquele recurso durante seu acesso? Qualquer solu\u00e7\u00e3o que se proponha a este problema de exclus\u00e3o m\u00fatua, precisa ter as propriedades 1, 2, 3, e, idealmente, a 4, a seguir: Exclus\u00e3o M\u00fatua exclus\u00e3o m\u00fatua - somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks - se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o-inani\u00e7\u00e3o - todos os processos interessados conseguem, em algum momento, acessar o recurso; espera limitada - idealmente, o tempo de espera pelo recurso \u00e9 limitado. H\u00e1 diversas solu\u00e7\u00f5es para exclus\u00e3o m\u00fatua em sistemas distribu\u00eddos, em diversos cen\u00e1rios, com seus pr\u00f3s e contras. Tr\u00eas das mais simples, e que ilustram o universo de solu\u00e7\u00f5es s\u00e3o via um processo centralizador, em um anel em que a vez \u00e9 circulada, e baseada em quoruns.","title":"Exclus\u00e3o M\u00fatua"},{"location":"coord/#coordenador","text":"Enquanto em um sistema monol\u00edtico h\u00e1 um sistema operacional que prov\u00ea abstra\u00e7\u00f5es simples para os processos a serem coordenados, em um sistema distribu\u00eddo, n\u00e3o h\u00e1 naturalmente tal entidade. Uma poss\u00edvel solu\u00e7\u00e3o para o problema de exclus\u00e3o m\u00fatua em um ambiente distribu\u00eddo \u00e9 justamente dar um passo para tr\u00e1s e introduzir um coordenador. Nesta abordagem, os processos que precisam acessar a regi\u00e3o cr\u00edtica s\u00e3o denominados participantes e um dos processos assume o papel de coordenador . \u00c9 poss\u00edvel que um mesmo processo atue nos dois pap\u00e9is sem nenhum preju\u00edzo. Os processos executam o seguinte protocolo: Participante Envia requisi\u00e7\u00e3o de acesso ao coordenador Espera por resposta do coordenador Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o, marca o recurso como livre Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado O diagrama a seguir apresenta uma execu\u00e7\u00e3o deste protocolo em um cen\u00e1rio com tr\u00eas participantes. O estado do coordenador mostra se o recurso est\u00e1 livre ou ocupado e quais processos esperam por permiss\u00e3o de acesso. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Part2->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part3] Coordenador->>Part2: ResponseFree note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Este algoritmo satisfaz as caracter\u00edsticas elencadas acima. Exclus\u00e3o m\u00fatua - se o coordenador autoriza um participante X, somente ap\u00f3s o participante X liberar o recurso \u00e9 que outro participante poder\u00e1 obter nova autoriza\u00e7\u00e3o. Aus\u00eancia de deadlocks - Todo processo que requisitar o recurso, entrar\u00e1 em uma fila, em apenas uma posi\u00e7\u00e3o; assim, a fila prover\u00e1 uma ordem total para os acessos, sem a possibilidade de circularidade nesta ordem. N\u00e3o-inani\u00e7\u00e3o - Dado que ningu\u00e9m fura a fila e que a cada vez que o recurso \u00e9 liberado a fila anda, em algum momento a vez do processo chegar\u00e1. Espera limitada - Dado que a posi\u00e7\u00e3o na fila pode apenas decrementar, seria poss\u00edvel estimar quanto tempo o participante precisa esperar para acessar o recurso. Outra vantagem deste algoritmo \u00e9 sua simplicidade e, consequentemente, facilidade de implementa\u00e7\u00e3o. Contudo, este algoritmo tem tamb\u00e9m desvantagens, por exemplo, se muitas requisi\u00e7\u00f5es de acesso forem feitas, o coordenador pode ser sobrecarregado e se tornar um gargalo no acesso \u00e0 regi\u00e3o cr\u00edtica. Mais s\u00e9rio ainda \u00e9 a quest\u00e3o de como lidar com falhas, por exemplo, se ou o coordenador ou o participante que detem o direito de acesso ao recurso para de funcionar, ent\u00e3o nenhum outro processo conseguir\u00e1 acesso. Estes aspectos nos permitem mergulhar na \u00e1rea de toler\u00e2ncia a falhas, e o faremos, mas mais tarde. Por enquanto, consideraremos toler\u00e2ncia a falhas de forma superficial, ap\u00f3s discutirmos outra abordagem.","title":"Coordenador"},{"location":"coord/#anel","text":"Nesta abordagem, os processos se organizam em um anel l\u00f3gico, com um processo antes e outro depois. Um dos processos \u00e9 iniciado com um token que d\u00e1 acesso ao recurso e o token \u00e9 passado adiante no anel; sempre que estiver de posse do token, o processo pode acessar o recurso. Ou seja, todos os participantes executam o seguinte protocolo: Participante Ao receber o token de acesso, se quiser acessar o recurso, acessa. Envia o token para o pr\u00f3ximo n\u00f3 do anel. O diagrama adiante mostra uma execu\u00e7\u00e3o do algoritmo em que apenas os participantes 1 e 3 acessam o recurso. sequenceDiagram Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso note over Part1: Acessa o recurso Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso Como o algoritmo centralizado, o algoritmo do anel tamb\u00e9m garante as propriedades 1, 2, 3 e 4, al\u00e9m de ser f\u00e1cil de implementar, testar e entender. Diferente do algoritmo centralizado, o algoritmo do anel n\u00e3o sofre com problemas de gargalo, pois nenhum processo precisa participar em todos os acessos, como o coordenador. Contudo, o algoritmo do anel desperdi\u00e7a tempo passando o token para quem n\u00e3o necessariamente quer acessar a regi\u00e3o cr\u00edtica. Tamb\u00e9m importante \u00e9 que este algoritmo tamb\u00e9m sofre com falhas: se um participante falha enquanto com o token , levando-o para al\u00e9m.","title":"Anel"},{"location":"coord/#lidando-com-falhas","text":"Em ambos os algoritmos, centralizado e do anel, se um processo falhar, o algoritmo pode ficar \"travado\". Vejamos alguns casos espec\u00edficos: No algoritmo centralizado, se o coordenador falha antes de liberar o acesso para algum processo, ele leva consigo a permiss\u00e3o. Em ambos os algoritmos, se o processo acessando o recurso falha, a permiss\u00e3o \u00e9 perdida e os demais processos sofrer\u00e3o inani\u00e7\u00e3o. No algoritmo do anel, se qualquer outro processo falha, o anel \u00e9 interrompido o anel n\u00e3o conseguir\u00e1 circular. Observe que nem falamos de falhas dos canais e j\u00e1 temos diversos cen\u00e1rios a serem resolvidos, para os quais se lhes pedir uma solu\u00e7\u00e3o, tenho certeza absoluta de que me oferecer\u00e3o alguma baseada em timeouts . Por exemplo, se o processo n\u00e3o devolver a permiss\u00e3o de acesso antes de que uma certa quantidade de tempo tenha passado, um timeout , ent\u00e3o assuma que o mesmo parou de funcionar e n\u00e3o voltar\u00e1 mais, e gere uma nova permiss\u00e3o a ser passada a outros requisitantes. Aplicada esta ideia do timeout no algoritmo com coordenador, teremos o efeito ilustrado a seguir. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>Part2: ResponseOK activate Part2 note over Coordenador: Recurso=ocupado/Fila = [Part3] note over Part2: \ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80 deactivate Part2 Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree O problema desta e outras \"solu\u00e7\u00f5es\" baseadas em timeouts est\u00e1 no assumir que o processo parou de funcionar , pois caso isso n\u00e3o seja verdade, teremos agora duas autoriza\u00e7\u00f5es ao mesmo tempo no sistema, podendo levar \u00e0 viola\u00e7\u00e3o da propriedade de exclus\u00e3o m\u00fatua. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] rect rgb(200, 0, 0) Coordenador->>+Part3: ResponseOK Part2->>-Coordenador: RequestFree Part3->>-Coordenador: RequestFree end note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Por mais que se ajuste o valor do temporizador, em um sistema distribu\u00eddo ass\u00edncrono, mesmo que aumentado com um rel\u00f3gio para medir a passagem do tempo local, o mesmo pode sempre estar errado. Impossibilidade de detec\u00e7\u00e3o de falhas Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir um processo falho de um processo lento. Mais tarde discutiremos as implica\u00e7\u00f5es desta impossibilidade. Por agora, tentemos responder \u00e0 seguinte quest\u00e3o. Question Qual deve ser um timeout razo\u00e1vel para o meu sistema? A resposta depende de mais perguntas, como: Qual o custo \\(E\\) de esperar por mais tempo? Qual o custo \\(C\\) de cometer um engano? Qual a probabilidade \\(p\\) de cometer um engano? O custo esperado por causa dos erros, isto \u00e9, a esperan\u00e7a matem\u00e1tica da vari\u00e1vel aleat\u00f3ria custo, \u00e9 menor que o custo de se esperar por mais tempo, isto \u00e9, \\(C * p < E\\) ? Embora esta an\u00e1lise possa ser feita para estes algoritmos, a verdade \u00e9 que s\u00e3o realmente limitados e outras abordagens seriam melhor destino dos seus esfor\u00e7os. Por exemplo, podemos partir para a an\u00e1lise de algoritmos probabil\u00edsticos, pois afinal, como disse certa vez Werner Vogels, CTO da Amazon Se o mundo \u00e9 probabil\u00edstico, porqu\u00ea meus algoritmos devem ser determin\u00edsticos?\" Uma abordagem probabil\u00edstica interessante \u00e9 baseada em qu\u00f3runs.","title":"Lidando com Falhas"},{"location":"coord/#quorum","text":"De acordo com o Dicion\u00e1rio Priberam da L\u00edngua Portuguesa, consultado em 17-04-2019 , \"qu\u00f3rum\" \u00e9 o N\u00famero de pessoas imprescind\u00edvel para a realiza\u00e7\u00e3o de algo. Aqui, este este algo ser\u00e1 a libera\u00e7\u00e3o de acesso ao recurso almejado pelos processos no sistema distribu\u00eddo. Esta abordagem \u00e9 semelhante em v\u00e1rios aspectos \u00e0 coordenada. De fato, um dos pap\u00e9is na abordagem \u00e9 o de coordenador, que executa o mesmo protocolo que antes. Entretanto, em vez de apenas um coordenador no sistema, temos \\(n\\) , dos quais o participante precisa obter \\(m > n/2\\) autoriza\u00e7\u00f5es antes de acessar o recurso; \\(m\\) \u00e9 o qu\u00f3rum do sistema. Qu\u00f3rum \\(n\\) coordenadores. \\(m > n/2\\) coordenadores J\u00e1 os demais participantes devem agora considerar todo o conjunto de coordenadores antes de assumir que tem acesso a um recurso. O algoritmo completo \u00e9 o seguinte: Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o, marca o recurso como livre Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado Participante Envia requisi\u00e7\u00e3o de acesso aos \\(n\\) coordenadores Espera por resposta de \\(m\\) coordenadores Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Al\u00e9m disso, para tornamos o problema mais interessante e demonstrar o potencial deste algoritmo, consideremos que as autoriza\u00e7\u00f5es s\u00e3o armazenadas somente em mem\u00f3ria, e que coordenadores, ao falhar e ent\u00e3o resumir suas atividades, esqueceme das autoriza\u00e7\u00f5es j\u00e1 atribu\u00eddas. Perda de mem\u00f3ria Quando um coordenador falha, esquece que deu ok e reinicia seu estado. Vejamos uma execu\u00e7\u00e3o bem sucedida destes algoritmo: TODO Construir execu\u00e7\u00e3o bem sucedida. Este algoritmo \u00e9 bom? Suponhamos o seguinte cen\u00e1rio: Coordenadores = { \\(c_1,c_2,c_3,c_4,c_5,c_6,c_7\\) } \\(n = 7\\) \\(m = 4\\) Participante \\(p_1\\) consegue autoriza\u00e7\u00e3o de { \\(c_1,c_2,c_3,c_4\\) } e entra na regi\u00e3o cr\u00edtica. Coordenador \\(c_4\\) falha e se recupera Participante \\(p_2\\) consegue autoriza\u00e7\u00e3o de { \\(c_4,c_5,c_6,c_7\\) } e entra na regi\u00e3o cr\u00edtica. Neste cen\u00e1rio, a propriedade de Exclus\u00e3o M\u00fatua \u00e9 violada. Isto porqu\u00ea, dados os dois qu\u00f3runs, todos os processos na interse\u00e7\u00e3o foram reinicidaos. Mas de forma geral, qual a probabilidade de isso acontecer? Ou seja, dados dois quoruns, de tamanho \\(m\\) , que se sobrepoem em \\(k\\) processos, qual a probabilidade \\(P_v\\) de que os \\(k\\) processos na interse\u00e7\u00e3o sejam reiniciados e levem \u00e0 viola\u00e7\u00e3o? Seja a \\(P\\) a probabilidade de um coordenador em espec\u00edfico falhar e se recuperar dentro de uma janela de tempo \\(\\delta t\\) . Temos Probabilidade de falha de exatamente 1 coordenador: \\(P^1(1-P)^{n-1}\\) Probabilidade de \\(k\\) coordenadores falharem: \\(P^k(1-P)^{n-k}\\) Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem: \\(\\binom{m}{k} P^k(1-P)^{m-k}\\) Mas qual \u00e9 o tamanho \\(k\\) da interse\u00e7\u00e3o? \\(\\left| A \\cup B\\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cap B \\right| \\Rightarrow n = m + m - k\\) \\(\\left| A \\cap B \\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cup B\\right| \\Rightarrow k = m + m - n = 2m - n\\) At\u00e9 agora consideramos que a \\(k\\) corresponde \u00e0 cardinalidade da interse\u00e7\u00e3o dos dois quoruns, mas se mais do que a interse\u00e7\u00e3o forem reiniciados, tamb\u00e9m teremos problemas. Assim, se \\(k\\) assume qualquer valor entre o tamanho da interse\u00e7\u00e3o e o n\u00famero total de coordenadores, teremos problemas. Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem, para qualquer \\(k\\) variando de \\(2m-n\\) a \\(n\\) : \\(P_v = \\sum_{k=2m-n}^n \\binom{m}{k} P^k(1-P)^{m-k}\\) Para facilitar o entendimento desta grandeza, considere o exemplo: \\(P=0.0001\\) (1 minuto a cada 10 dias) \\(n = 32\\) \\(m = 0.75n\\) \\(P_v < 10^{-40}\\) ( Curiosidade sobre \\(10^{40}\\) ) A probabilidade de viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua, neste caso, \u00e9 muito pequena, a despeito de suportar falhas dos coordenadores. Pr\u00f3 Tolera falhas de coordenadores, com probabilidade controlada de viola\u00e7\u00e3o de exclus\u00e3o m\u00fatua. Mas e as outras propriedades desej\u00e1veis do algoritmo de exclus\u00e3o m\u00fatua, s\u00e3o alcan\u00e7adas? Relembrando: Contras Exclus\u00e3o M\u00fatua probabil\u00edstica: \\(1 - P_v\\) N\u00e3o-inani\u00e7\u00e3o E se cada participante obtiver o ok de um coordenador? Temporizador para quebrar o deadlock ? Espera limitada Aborts podem levar a espera infinita. Assim, este agoritmo tamb\u00e9m pode n\u00e3o ser adequado para certas situa\u00e7\u00f5es. Vamos tentar reacessar os problemas da primeira abordagem. Por um lado, o uso de um l\u00edder para coordenar a\u00e7\u00f5es em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto \u00fanico de falha, como no algoritmo de exclus\u00e3o m\u00fatua centralizado. Mas e se substitu\u00edssemos o coordenador no caso de falhas? Este \u00e9 o problema conhecido como elei\u00e7\u00e3o de l\u00edderes. TODO Maekawa - Diminui n\u00famero de votos necess\u00e1rios ( descri\u00e7\u00e3o ) Lamport - Usa rel\u00f3gios l\u00f3gicos, mas \u00e9 poss\u00edvel entender sem este background ( descri\u00e7ao ) Ricart-Agrawala - Melhora algoritmo de Lamport ( descri\u00e7\u00e3o ) Distributed-Mutual-Exclusion-slides","title":"Qu\u00f3rum"},{"location":"coord/#eleicao-de-lideres","text":"O problema da escolha de um processo centralizador, ou l\u00edder, pode ser posto informalmente como o procedimento pelo qual um processo \u00e9 escolhido dentre os demais processos, sendo que o processo escolhido \u00e9 ciente da escolha e todos os demais processos o identificam como eleito . Uma nova elei\u00e7\u00e3o deve acontecer sempre que o l\u00edder se tornar indispon\u00edvel . Formalmente, um algoritmo de elei\u00e7\u00e3o de l\u00edderes deve satisfazer as seguintes condi\u00e7\u00f5es. Elei\u00e7\u00e3o de L\u00edderes 1 Termina\u00e7\u00e3o: algum processo deve se considerar l\u00edder em algum momento. Unicidade: somente um processo se considera l\u00edder. Acordo: todos os outros processos sabem quem foi eleito l\u00edder. Para entendermos melhor o problema, tentemos desenvolver um protocolo simples para escolhermos um l\u00edder, por exemplo, em sua turma da disciplina de Sistemas Distribu\u00eddos. Vejamos algumas quest\u00f5es importantes. Candidatos: s\u00e3o todos os membros eleg\u00edveis ou apenas um subconjunto dos mesmos? Comunica\u00e7\u00e3o: todos se conhecem e se falam diretamente ou h\u00e1 grupos incomunic\u00e1veis dentro da turma? Estabilidade: de que adianta eleger um dos colegas se frequentemente falta n\u00e3o est\u00e1 presente quando necess\u00e1rio? Em termos computacionais, estas quest\u00f5es s\u00e3o relevantes pois todos os processoes n\u00e3o nascem iguais; alguns residem em m\u00e1quinas com mais mem\u00f3ria, mais poder de processamento, melhor conex\u00e3o com o resto do mundo ou maior grau de conectividade. Talvez este processo seja um l\u00edder mais \u00fatil que os demais. Al\u00e9m disso, se o processo est\u00e1 frequentemente desconectado, mesmo que bem servido de recursos, n\u00e3o ser\u00e1 um bom l\u00edder. Ainda que assumamos um conjunto de processos indiferenci\u00e1veis entre si, com acesso equivalente a recursos e que estejam sempre dispon\u00edves, ou exatamente por isso, temos um problem mais fundamental para resolver: para eleger um l\u00edder, precisamos diferenciar processos. Dentro de uma \u00fanica m\u00e1quina, identificamos processos facilmente usando seu PID , ou process id , um inteiro associado a cada processo instanciado pelo sistema operacional; o PID \u00e9 v\u00e1lido enquanto o processo estiver executando e pode ser reciclado uma vez que o processo para de executar, o que pode ser um problema. Al\u00e9m disso, se o host \u00e9 reiniciado, os PID tamb\u00e9m s\u00e3o, e portanto esta identifica\u00e7\u00e3o n\u00e3o \u00e9 duradoura. Mais importante, o PID s\u00f3 faz sentido dentro de uma \u00fanica m\u00e1quina e n\u00e3o em um sistema distribu\u00eddo. Se apenas uma inst\u00e2ncia do processo executa em um mesmo host , ent\u00e3o o identificador do host (e.g., endere\u00e7o IP) em si \u00e9 suficiente e, de fato, comumente utilizado. Se mais de um processo executa no mesmo host , ent\u00e3o cabe ao desenvolvedor criar um esquema que permita diferenciar os processos, e n\u00e3o precisa ser nada complicado; pode ser apenas um par\u00e2metro passado na inicializa\u00e7\u00e3o do processo ou a combina\u00e7\u00e3o IP/porta . Assumindo que um esquema de nomea\u00e7\u00e3o est\u00e1 dispon\u00edvel e que todos os processos se conhecem, voltemos ao problema de eleger um l\u00edder para sua turma. Uma abordagem que pode funcionar \u00e9 colocar todos os candidatos para brigar e quem sobrar em p\u00e9 no final, \u00e9 o novo l\u00edder. A despeito desta op\u00e7\u00e3o gerar um l\u00edder n\u00e3o muito popular, o algoritmo do brig\u00e3o \u00e9 um cl\u00e1ssico.","title":"Elei\u00e7\u00e3o de L\u00edderes"},{"location":"coord/#algoritmo-do-brigao-bully","text":"No algoritmo do brig\u00e3o, alguma caracter\u00edsticas compar\u00e1vel dos processos \u00e9 escolhida e aquele processo funcional com o valor de tal caracter\u00edstica mais vantajoso para um l\u00edder \u00e9 escolhido como tal. Por exemplo, pode ser vantajoso ter um l\u00edder com maior quantidade de mem\u00f3ria, frequ\u00eancia da CPU ou largura de banda da conex\u00e3o com a Internet; no caso de empate, o identificador do processo pode ser usado para gerar uma ordem total entre os processos. Para simplificar, vamos assumir que o identificador do processo reflete as qualidades do mesmo para a lideran\u00e7a, tal que o processo com maior identificador seja o melhor candidato. Os maiores processos, os \"brig\u00f5es\", eliminam os processos menores da competi\u00e7\u00e3o, sempre que uma elei\u00e7\u00e3o acontecer. O algoritmo \u00e9 apresentado a seguir, onde \\(p\\) e \\(q\\) s\u00e3o usados para representar tanto identificadores de processos quando os processos em si. Algoritmo do Brig\u00e3o Quando \\(p\\) suspeita que o l\u00edder n\u00e3o est\u00e1 presente (muito tempo se receber mensagens do mesmo) \\(p\\) envia mensagem (ELEICAO, \\(p\\) ) para todos os processos com identificador maior que \\(p\\) Inicia temporizador de respostas Quando temporizador de respostas expira Envia (COORD, \\(p\\) ) para todos os processos Quando recebe (Ok, \\(p\\) ) Para temporizador de resposta Quando \\(p\\) recebe (ELEICAO, \\(q\\) ), \\(q < p\\) Envia (OK, \\(q\\) ) Quando um processo falho se recupera Inicia uma elei\u00e7\u00e3o Observe como o algoritmo foi descrito em termos de eventos e n\u00e3o de forma sequencial. Este tipo de especifica\u00e7\u00e3o \u00e9 comum para algoritmos paralelos e distribu\u00eddos, pois n\u00e3o h\u00e1 uma sequ\u00eancia pr\u00e9-estabelecida de passos a serem executados por todos os processos, apenas alguns pontos de coordena\u00e7\u00e3o. No exemplo a seguir, temos 5 processos, com identificadores de 1 a 5, passando por 7 passos at\u00e9 que a elei\u00e7\u00e3o se complete. Observe que os processos n\u00e3o sabem a priori como os eventos aconteceram e apenas reagem aos eventos de recep\u00e7\u00e3o de mensagens e expira\u00e7\u00e3o de temporizadores . o l\u00edder j\u00e1 \u00e9 o processo 5 (em rosa). os processos 2 e 3 (amarelo) se \"cansaram\" de esperar por 5, que falhou (em cinza, e se candidataram a l\u00edder, enviando (ELEICAO,2) e (ELEICAO,3), respectivamente, (verde). 4 responde a 2 a 3 com (OK,2) e (OK,3) como resposta a 2 e 3, respectivamente, e 3 envia (OK,2) para 2. 1 se candidata com enviando (ELEICAO,1). 2, 3 e 4 respondem com (OK,1). 4 se candidata enviando (ELEICAO,4) para 5, que n\u00e3o responde, j\u00e1 que est\u00e1 falho. 4 se declara l\u00edder e envia (COORD,4) a todos os processos. Como j\u00e1 discutido antes, a escolha do valor temporizador \u00e9 fundamental para o bom funcionamento do algoritmo. Se o temporizador usado pelos processos para esperar pelo l\u00edder for ajustado de forma agressiva, frequentemente ser\u00e3o iniciadas elei\u00e7\u00f5es mesmo que o l\u00edder n\u00e3o tenha falhado. J\u00e1 se o valor do temporizador for muito grande, o sistema demorar\u00e1 a eleger um novo l\u00edder . Da mesma forma, se o tempo esperado por um candidato antes de se declarar l\u00edder for muito curto, mais de um processo pode se declarar l\u00edder , uma situa\u00e7\u00e3o conhecida como split-brain . Idealmente, um processo deveria esperar por outro enquanto o outro estiver apto a responder, mas isso requer saber quando o outro processo n\u00e3o est\u00e1 mais apto, isto \u00e9, falhou. Como identificar exatamente quando isso aconteceu \u00e9 imposs\u00edvel em sistemas distribu\u00eddos ass\u00edncronos, o algoritmo do brig\u00e3o n\u00e3o resolve o problema neste ambiente. Mas se delimitarmos melhor o ambiente, podemos chegar a solu\u00e7\u00f5es melhores.","title":"Algoritmo do Brig\u00e3o (Bully)"},{"location":"coord/#algoritmos-em-aneis","text":"Consideremos processos organizados em um anel l\u00f3gico em que processos troquem mensagens apenas com processos \u00e0 \"esquerda\" e \u00e0 \"direita\". Considere tamb\u00e9m que todos os processos s\u00e3o exatamente id\u00eanticos, inclusive n\u00e3o possuindo identificadores pr\u00f3prios. Suponha o seguinte algoritmo de elei\u00e7\u00e3o neste anel, em que um processo inicialmente Seguidor se torna Candidato, ent\u00e3o se declara Eleito, avisa a seus pares e, finalmente, se declara Empossado. Algoritmo do Anel 1 Organize os n\u00f3s em um anel l\u00f3gico \\(C \\gets\\) Seguidor Quando um processo acha que o l\u00edder est\u00e1 morto \\(C \\gets\\) Candidato Envia (VoteEmMim) para \"a direita\" no anel. Quando um processo recebe (VoteEmMim) Se \\(C =\\) Seguidor envia (VoteEmMim) para a direita Se \\(C =\\) Candidato \\(C \\gets\\) Eleito envia (HabemosLeader) para a direita Quando um processo recebe (HabemosLeader) Se \\(C =\\) Seguidor envia (HabemosLeader) para a direita Se \\(C =\\) Eleito \\(C \\gets\\) Empossado Imagine um cen\u00e1rio com dois processos, como na imagem a seguir. Os nomes dos processos s\u00e3o apenas para facilitar o entendimento do fluxo dem mensagens e n\u00e3o est\u00e3o acess\u00edveis aos processos. Executando o algoritmo Anel 1, os processos enviam ( \\(\\rightarrow\\) ) e recebem ( \\(\\leftarrow\\) ) as seguintes mensagens e ajustam \\(C\\) da seguinte forma. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado Agora imagine que por um acaso, tanto processo 1 quanto o 2 se candidatassem ao mesmo tempo. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado \\(C \\gets\\) Empossado Como n\u00e3o h\u00e1 nada que diferencie os processos entre si, este cen\u00e1rio \u00e9 perfeitamente v\u00e1lido, e se no primeiro cen\u00e1rio o algoritmo estava correto ao eleger o processo 1, ent\u00e3o no segundo cen\u00e1rio o 1 tamb\u00e9m deve ser eleito, j\u00e1 que a sequ\u00eancia de evento observadas \u00e9 exatamente a mesma. Mas o processo 2 tamb\u00e9m v\u00ea a mesma sequ\u00eancia, ent\u00e3o tamb\u00e9m deve ser eleito. Assim, violamos a propriedade da Unicidade. Para quebrar essa simetria entre os processo, podemos permitir que saibam seus identificadores. No algoritmo seguinte, permitimos que os processos conhe\u00e7am seus identificadores e um processo que suspeite do l\u00edder atual, envia uma mensagem no anel para coletar os identificadores de todos os processos. Algoritmo do Anel 2 Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem [ \\(p\\) ] \"\u00e0 direita\". Quando \\(p\\) recebe \\(l\\) Se \\(p \\not \\in l\\) Envia \\([p:l]\\) para a direita. Se \\(p \\in l\\) Escolhe menor id em \\(l\\) como l\u00edder. Este algoritmo envia at\u00e9 \\(n^2\\) mensagens, se todos iniciarem a elei\u00e7\u00e3o ao mesmo tempo, e as mensagens crescem at\u00e9 o tamanho \\(n\\) . O algoritmo de Chang e Robert 2 limita o tamanho das mensagens ao pr\u00e9-selecionar candidatos vi\u00e1veis. Algoritmo de Chang e Robert Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem \\((p)\\) \u00e0 direita Quando \\(p\\) recebe \\((q)\\) Se \\(p = q\\) \\(p\\) se declara l\u00edder Sen\u00e3o e se \\(q > p\\) Envia \\((q)\\) para a direita. Neste algoritmo, todas as mensagens tem tamanho \\(O(1)\\) e somente uma mensagem d\u00e1 uma volta completa do anel; todas as outras s\u00e3o descartadas no meio do caminho. Apesar disso, pode-se demonstrar que o pior caso em termos de n\u00famero de mensagens do algoritmo at\u00e9 que algu\u00e9m se declare l\u00edder \u00e9 \\(O(n^2)\\) . Exerc\u00edcio: Quantidade de mensagens O pior caso em termos de n\u00famero de mensagens at\u00e9 que algu\u00e9m seja eleito \u00e9 \\(O(n^2)\\) . Descreva como os n\u00f3s devem estar organizados para que esta situa\u00e7\u00e3o ocorra. Observe que no algoritmo um processo apenas se \"declara l\u00edder\", mas os outros n\u00e3o necessariamente ficam sabendo disso. Como voc\u00ea o corrigiria para que terminasse? Diversos outros algoritmos existem para a topologia em anel. O algoritmo de Franklin \u00e9 um dos que prop\u00f5e melhorias para reduzir quantidade de mensagens usadas na elei\u00e7\u00e3o. Ele faz isso em rodadas, comparando identificadores com outros processos ativos tanto \u00e0 esquerda quanto \u00e0 direita e desativando os processos n\u00e3o vi\u00e1veis. Algoritmo de Franklin Organize os n\u00f3s em um anel l\u00f3gico Ativo \\(\\gets 1\\) Quando \\(p\\) acha que o l\u00edder est\u00e1 morto e se Ativo$ = 1$: Envia mensagem \\((p)\\) \u00e0 direita e \u00e0 esquerda Quando \\(p\\) recebe \\(e\\) e \\(d\\) , da esquerda e da direita, respectivamente: Se Ativo \\(=1\\) Se \\(max(e,d) < p\\) Envia mensagem \\(p\\) \u00e0 direita e \u00e0 esquerda Se \\(max(q,r) > p\\) Ativo \\(\\gets 0\\) Envia mensagem \\(-p\\) \u00e0 direita e \u00e0 esquerda Se \\(max(q,r) = p\\) \\(p\\) se declara l\u00edder. Se Ativo \\(=0\\) Repassa cada messagem para o outro lado. No exemplo na figura, os n\u00f3s brancos s\u00e3o ativos e os amarelos inativos. Observe o papel do n\u00f3 no centro, supondo que tem o maior identificador entre todos os processos. Inicialmente ele envia as mensagens em verde para os lados, que levam seus vizinhos imediatos a se inativarem. Na segunda rodada, as mensagens s\u00e3o repassadas para os vizinhos dos vizinhos, que tamb\u00e9m se inativam. Observe o seguinte: Em cada fase, para qualquer par de vizinhos ativos, pelos um dos dois \u00e9 inativado e, portanto, o n\u00famero de ativos cai pela metade; logo h\u00e1 no m\u00e1ximo \\(O(log n)\\) fases. Na primeira fase, cada processo ativo leva a \\(4\\) mensagens serem enviadas na rede (sem nenhuma otimiza\u00e7\u00e3o). Dado que s\u00e3o \\(n\\) processos, temos \\(4n\\) mensagens, \\(O(n)\\) Na segunda fase, cada processo ativo leva a 8 mensagens. Contudo, metade dos processos, pelo menos, foram inativados na primeira fase. Logo, temos \\(8n \\times n/2, O(n)\\) Assim, no m\u00e1ximo \\(O(n log n)\\) mensagens s\u00e3o enviadas em uma execu\u00e7\u00e3o do algoritmo.","title":"Algoritmos em An\u00e9is"},{"location":"coord/#algoritmo-do-yoyo","text":"Saindo da topologia em anel, vejamos o algoritmo do Yoyo, que funciona em qualquer topologia conexa, mesmo se processos n\u00e3o puderem se falar diretamente. Inicialmente as arestas do formado pelos processos e seus canais de comunica\u00e7\u00e3o s\u00e3o n\u00e3o direcionadas, mas na medida em que o protocolo \u00e9 executado, as arestas s\u00e3o marcadas como tendo um ou outro sentido. Esta marca\u00e7\u00e3o \u00e9 apenas l\u00f3gica e mensagens fluem em ambos os sentidos. De acordo com o tipo de arestas que um processo tem, ele \u00e9 classificado como um de tr\u00eas tipos: Fonte (source) - processo que s\u00f3 tem arestas de sa\u00edda Vertedouro (sink) - processo que s\u00f3 tem arestas de chegada Interno - processo que tem arestas de chegada e de sa\u00edda O algoritmo executa em duas fases. Na primera, cada processo marca sua arestas como apondando para o maior dentre si pr\u00f3prio e seus vizinhos. Na segunda fase, mensagens \"v\u00e3o e voltam\", o que d\u00e1 o nome ao algoritmo. Na \"ida\", as mensagens v\u00e3o das fontes para os vertedouros, que identificam quais fontes tem os menores identificadores e sinalizam para que continuem fontes na pr\u00f3xima etapa com mensagens de volta. As mensagens de volta reordenam as arestas para garantir este comportamento. Vejamos o algoritmo em mais detalhes. Algoritmo do YoYo Fase 1 \\(p\\) envia seu identificador para seus vizinhos. Quando \\(p\\) recebe \\(q\\) Se \\(p>q\\) Marca a aresta em que recebeu \\(q\\) como sendo de chegada ( \\(p\\leftarrow q\\) ) Sen\u00e3o Marca a aresta em que recebeu \\(q\\) como sendo de sa\u00edda ( \\(q\\leftarrow p\\) ) Se \\(p\\) \u00e9 uma fonte \\(p\\) envia seu identificador em todas as suas arestas de sa\u00edda. Quando \\(p\\) receber \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda Se recebeu apenas \\(S\\) Executa fase 2 novamente Fase 2 Se \\(p\\) \u00e9 um n\u00f3 interno * Quando \\(p\\) receber identificadores em todas as suas arestas de entrada * escolhe o menor id recebido \\(m\\) * envia \\(m\\) em todas as suas arestas de sa\u00edda * Quando \\(p\\) recebeu \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda * Se recebeu algum \\(S\\) * envia \\(S\\) para vizinhos de onde recebeu \\(m\\) * envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) * Se n\u00e3o recebeu \\(S\\) * envia \\(N\\) para vizinhos de onde recebeu algum id. Se \\(p\\) \u00e9 um vertedouro * Quando \\(p\\) receber identificadores em todas as suas arestas de entrada * escolhe o menor id recebido \\(m\\) * envia \\(S\\) para vizinhos de onde recebeu \\(m\\) * envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) N inverte a dire\u00e7\u00e3o das arestas em que trafega. Fonte Veja um exemplo com 3 processos em destaque, uma fonte, um interno e um vertedouro. Veja o seguinte exemplo, em que cada figura mostra um est\u00e1gio da resolu\u00e7\u00e3o do problema de elei\u00e7\u00e3o de l\u00edderes. a) A rede em seu estado inicial. b) Rede orientada pela primera fase c) Propaga\u00e7\u00e3o de Fontes d) Propaga\u00e7\u00e3o de Vertedouros e) Inativa\u00e7\u00e3o dos vertedouros Exemplo: Embora interessante, este algoritmo tamb\u00e9m tem problemas, sendo um dos mais cr\u00edticos a forma de lidar com falhas, mesmo sem considerar falhas de processos. Suponha que o canal de comunica\u00e7\u00e3o entre os processos 2 e 10 pare de funcionar. O que acontecer\u00e1? Esta \u00e9 uma situa\u00e7\u00e3o que denominamos particionamento da rede e que neste caso levar\u00e1 a duas elei\u00e7\u00f5es concorrentes acontecerem e, consequentemente, a dois l\u00edderes sendo eleitos, o que \u00e9 conhecido na \u00e1rea como split-brain . Vejamos esta e outras situa\u00e7\u00f5es problem\u00e1ticas em elei\u00e7\u00e3o de l\u00edderes.","title":"Algoritmo do YoYo"},{"location":"coord/#questoes-importantes","text":"","title":"Quest\u00f5es importantes"},{"location":"coord/#split-brain","text":"Se o algoritmo viola a propridade de unicidade, ent\u00e3o fica com split-brain , em que parte da rede v\u00ea um processo como l\u00edder e parte v\u00ea outro. Se o l\u00edder \u00e9 o respons\u00e1vel por coordenar o acesso a uma regi\u00e3o cr\u00edtica, como visto no algoritmo coordenado de exclus\u00e3o m\u00fatua, ent\u00e3o ter dois l\u00edderes poder\u00e1 levar a dois processos na regi\u00e3o cr\u00edtica e portanto viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua. Uma das formas de evitar split-brain \u00e9 atribuir um \"peso\" para cada processo e s\u00f3 aceitar que um l\u00edder seja declarado se o mesmo seus votos carregarem mais da metade do peso do sistema. Ainda assim, temos problemas, pois \u00e9 necess\u00e1rio que rodadas sucessivas do algoritmo invalidem as elei\u00e7\u00f5es anteriores. O algoritmo Raft de difus\u00e3o at\u00f4mica, que estudaremos adiante, define mandatos e garante, com pesos, que somente um l\u00edder existe em cada mandato. Devido \u00e0 natureza ass\u00edncrona do sistema, processos podem se achar em mandatos distintos e, por isso, o mandato \u00e9 associado a todas as comunica\u00e7\u00f5es; mensagens recebidas de mandatos anteriores s\u00e3o sumariamente descartadas. Mas por qu\u00ea precisamos de mandatos sucessivos? Para substituir um l\u00edder que tenha falhado. O que nos leva a outros dois problemas, o da detec\u00e7\u00e3o de falhas e o da estabilidade do l\u00edder.","title":"Split-brain"},{"location":"coord/#estabilidade","text":"Dizemos que um algoritmo de elei\u00e7\u00e3o de l\u00edderes \u00e9 est\u00e1vel se uma vez que um l\u00edder \u00e9 eleito, uma nova elei\u00e7\u00e3o s\u00f3 acontece se o l\u00edder falha. Considere o algoritmo do brig\u00e3o. Imagine, no exemplo apresentado, que o processo 5 teve problemas de comunica\u00e7\u00e3o e foi percebido como falho pelos demais. Neste caso, o 4 seria eleito l\u00edder. Mas se o problema que aflige 5 \u00e9 tempor\u00e1rio, 5 voltar\u00e1 e executar\u00e1 nova elei\u00e7\u00e3o, tornando-se l\u00edder novamente. Se este cen\u00e1rio se repente indefinidamente, o sistema poder\u00e1 ser seriamente comprometido em seu desempenho. Uma vers\u00e3o est\u00e1vel do algoritmo tentaria, por exemplo, associar ao peso do processo o tempo de exe\u00e7\u00e3o ininterrupta do mesmo. Assim, quanto mais tempo um processo execute, maior ser\u00e1 seu peso e sua capacidade de manter a lideran\u00e7a. Se o mesmo falhar, ent\u00e3o seu peso ser\u00e1 drasticamente reduzido e suas chances de ser eleito l\u00edder reduzidas temporariamente. Observe que os problemas enfrentados s\u00e3o ligados \u00e0 detec\u00e7\u00e3o e contorna\u00e7\u00e3o de falhas.","title":"Estabilidade"},{"location":"coord/#deteccao-de-falhas","text":"Como j\u00e1 mencionado antes, detec\u00e7\u00e3o de falhas \u00e9 o mecanismo pelo qual um processo monitora e percebe se outro falhou. Pensemos em como um processo monitora o outro em um sitema distribu\u00eddo. Claramente, por meio de troca de mensagens e temporizadores. Mas se estamos falando de sistemas distribu\u00eddos ass\u00edncronos, ent\u00e3o mensagens podem ser atrasadas indefinidamente ou rel\u00f3gios podem ser atrasados, ent\u00e3o n\u00e3o se pode confiar na falta de recep\u00e7\u00e3o de uma mensagem como garantia de que um processo parou de funcionar. Aprofundemo-nos nos pr\u00f3ximos cap\u00edtulo nos conceitos de tempo e toler\u00e2ncia a falhas, mas enquanto isso, fiquemos com o seguinte resultado. Detec\u00e7\u00e3o de falhas Detec\u00e7\u00e3o de falhas perfeita \u00e9 imposs\u00edvel... em sistemas distribu\u00eddos ass\u00edncronos (Internet) sujeitos \u00e0 parti\u00e7\u00f5es (Internet) com requisitos de disponibilidade total. A Probabilistically Correct Leader Election Protocol for Large Groups \u21a9 An improved algorithm for decentralized extrema-finding in circular configurations of processes . \u21a9","title":"Detec\u00e7\u00e3o de falhas"},{"location":"disdb/","text":"Bancos de Dados Distribu\u00eddos Bancos de Dados Falar em bancos de dados distribu\u00eddos implica falar em bancos transacionais e P2P. Opera\u00e7\u00f5es At\u00f4micas Falar em bancos de dados distribu\u00eddos implica falar em bancos Relacionais/Transactionais e P2P. Falar em bancos transacionais, implica falar ACID! Atomicidade -- Todas as opera\u00e7\u00f5es ou nenhuma. Consist\u00eancia -- Os dados transitam de estado v\u00e1lido para estado v\u00e1lido. Isolamento -- Transa\u00e7\u00f5es n\u00e3o interferem umas nas outras. Durabilidade -- Efeitos n\u00e3o s\u00e3o esquecidos. No modelo de M\u00e1quinas de Estados Replicadas, opera\u00e7\u00f5es s\u00e3o enviadas para as r\u00e9plicas, que as executam em ordem, deterministicamente e tamb\u00e9m atomicamente . Isto \u00e9, cada opera\u00e7\u00e3o \u00e9 ou executada independentemente das outras e por completo, ou n\u00e3o \u00e9 executada. Conjuntos de Opera\u00e7\u00f5es Mesmo com Opera\u00e7\u00f5es At\u00f4micas, frequentemente queremos/precisamos agrupar opera\u00e7\u00f5es tal que todas ou nenhuma sejam executadas mesmo na presen\u00e7a de falhas. Atomicidade Mem\u00f3ria Est\u00e1vel Para que os efeitos de opera\u00e7\u00f5es n\u00e3o sejam esquecidos, eles precisam ser armazenados em mem\u00f3ria est\u00e1vel como HD -- Hard Drives SSD -- Solid State Drives NVRAM -- Non Volatile RAM Durabilidade O Banco Conta C 1 2 C.getSaldo() C.setSaldo(montante) Transa\u00e7\u00e3o Mova 10% do saldo de B, de A para B. 1 2 3 4 5 T1: a -> b sB = b.getSaldo() b.setSaldo(sB*1.1) sA = a.getSaldo() a.setSaldo(sA-sB*0.1) Transa\u00e7\u00e3o Qual o saldo total das contas? 1 2 3 4 T2: a + b sA = a.getSaldo() sB = b.getSaldo() sT = sA + sB Execu\u00e7\u00e3o Concorrente Execu\u00e7\u00e3o concorrente de T1 e T2? 1 2 3 4 5 6 7 8 T1 T2 sB = b.getSaldo() sA = a.getSaldo() b.setSaldo(sB*1.1) . sB = b.getSaldo() sA = a.getSaldo() a.setSaldo(sA-sB*0.1) sT = sA+sB Dados n\u00e3o finais \"vazaram\". Dirty Read . Falta Isolamento . Pode levar a mais que um resultado errado. Pode deixar o BD em estado inv\u00e1lido. Execu\u00e7\u00e3o Concorrente Mova 10% do saldo de B, de A para B. 1 2 3 4 5 6 7 8 9 T1 T1 sB = b.getSaldo() sB = b.getSaldo() b.setSaldo(sB*1.1) b.setSaldo(sB*1.1) sA = a.getSaldo() a.setSaldo(sA-sB*0.1) sA = a.getSaldo() a.setSaldo(sA-sB*0.1) sB*0.1 foi perdido. Lost Update Perdeu Consist\u00eancia Solu\u00e7\u00e3o?! Para garantir Isolamento Execu\u00e7\u00f5es dos conjuntos n\u00e3o podem se sobrepor. Execute um conjunto de opera\u00e7\u00f5es por vez, serialmente! Garantir\u00e1 tamb\u00e9m Consist\u00eancia Que tal? Limite a concorr\u00eancia de transa\u00e7\u00f5es. Equival\u00eancia Serial Concorr\u00eancia Al\u00e9m de ACID, queremos o m\u00e1ximo de concorr\u00eancia para garantir o melhor desempenho . Queremos uma execu\u00e7\u00e3o das transa\u00e7\u00f5es semelhante \u00e0 serial, mas com o desempenho de concorrente. N\u00e3o queremos uma execu\u00e7\u00e3o serial, mas uma Equival\u00eancia Serial , isto \u00e9, que os efeitos das transa\u00e7\u00f5es, executadas concorrentemente, sejam equivalentes aos de alguma execu\u00e7\u00e3o serial destas transa\u00e7\u00f5es. Equival\u00eancia Serial Preocupe-se com Opera\u00e7\u00f5es Conflitantes Transa\u00e7\u00f5es diferentes Uma \u00e9 escrita Mesmo dado Duas execu\u00e7\u00f5es (de transa\u00e7\u00f5es) s\u00e3o equivalentes se as transa\u00e7\u00f5es tem as mesmas opera\u00e7\u00f5es quaisquer duas opera\u00e7\u00f5es conflitantes s\u00e3o executadas na mesma ordem nas duas execu\u00e7\u00f5es Uma execu\u00e7\u00e3o tem Equival\u00eancia Serial se \u00e9 equivalente a alguma execu\u00e7\u00e3o serial das transa\u00e7\u00f5es. Escalone opera\u00e7\u00f5es concorrentemente, de forma a obter o melhor desempenho, mas de forma a manter Equival\u00eancia Serial. Esta defini\u00e7\u00e3o dif\u00edcil de ser testada. Algo mais simples? Como demonstrar Equival\u00eancia Serial? Tenho que testar todas as execu\u00e7\u00f5es seriais e ver se uma casa com o que planejo fazer? \u00c9 caro fazer este planejamento. \u00c9 mais eficiente garantir por constru\u00e7\u00e3o. Simplifica\u00e7\u00e3o: A execu\u00e7\u00e3o de duas transa\u00e7\u00f5es tem Equival\u00eancia Serial se todos os pares de opera\u00e7\u00f5es conflitantes entre as transa\u00e7\u00f5es s\u00e3o executados na mesma ordem. Lost Update Mova 10% do saldo de X, de Y para X. 1 2 3 4 5 6 7 a -> b c -> b s = b.getSaldo() [1] [2]s = b.getSaldo() [3] b.setSaldo(s*1.1) b.setSaldo(s*1.1)[4] c.setSaldo(s*0.1) a.setSaldo(s*0.1) Conflitos: 1x3: \\(\\rightarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\) Consist\u00eancia -- s*0.1 foi perdido Mova 10% do saldo de X, de Y para X. 1 2 3 4 5 6 7 a -> b c -> b [2] s = b.getSaldo() [3] b.setSaldo(s*1.1) s = b.getSaldo() [1] b.setSaldo(s*1.1)[4] c.setSaldo(s*0.1) a.setSaldo(saldo*0.1) Conflitos: 1x3: \\(\\leftarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\) Dirty Read Saldo total? 1 2 3 4 5 6 7 8 9 a -> b a -> b s = b.getSaldo() b.setSaldo(s*1.1) b.setSaldo(s*1.1) a.saque(s*0.1) s = b.getSaldo() b.setSaldo(s*1.1) b.setSaldo(s*1.1) a.saque(s*0.1) Tem Equival\u00eancia Serial. Exceto se 1 abortTransaction() Nenhuma transa\u00e7\u00e3o que fez uma dirty read pode comitar. Logo, aborte a transa\u00e7\u00e3o da direita. Aborto em Cascata T1 faz uma escrita. T2 l\u00ea o que T1 escreveu e faz outra escrita. T3 l\u00ea o que T2 escreveu e faz outra escrita. T4 l\u00ea o que... T1 aborta . Dirty Read Como lidar? Suspenda a transa\u00e7\u00e3o quando esta fizer dirty read. Se transa\u00e7\u00e3o foi abortada, todas as suspensas (que leram dela) devem ser abortadas. Repita passo anterior. E se evitarmos dirty reads em vez de tratarmos? Suspenda antes de fazer dirty read. Quando transa\u00e7\u00e3o for terminada, continue execu\u00e7\u00e3o. Abordagem leva a menor concorr\u00eancia. Para nos permitir identificar transa\u00e7\u00f5es, vamos usar o seguinte framework para oper\u00e1-las. Transa\u00e7\u00f5es beginTransaction( ) opera\u00e7\u00f5es commitTransaction(): Ok/NOk abortTransaction() Escrita Prematura 1 2 3 4 5 6 Saldo inicial: 100 a.setSaldo(105) a.setSaldo(110) commitTransaction() abortTransaction() A transa\u00e7\u00e3o da direita n\u00e3o le, apenas escreve. O resultado? O saldo volta para 100. Strict Execution Leituras e Escritas devem ser atrasadas at\u00e9 que todas as transa\u00e7\u00f5es anteriores que contenham escritas sejam commitadas ou abortadas. Execu\u00e7\u00e3o estrita garante Isolamento. Como implementar eficientemente? Controle de Concorr\u00eancia Como locks (pessimista): simples, mas problem\u00e1tico multi-vers\u00e3o (otimista): custo se h\u00e1 muitos conflitos timestamp: time \u00e9 algo complicado Locks Tranque todos os objetos para que outras transa\u00e7\u00f5es n\u00e3o consigam ler ou escrev\u00ea-los. Destranque quando n\u00e3o mais necess\u00e1rios. Sofre de dirty reads e escritas prematuras. Strict Two Phase Locking tranque quando necess\u00e1rio destranque ao final da transa\u00e7\u00e3o termine a transa\u00e7\u00e3o Como aumentar a concorr\u00eancia? Read-Write Locks dois n\u00edveis de acesso m\u00faltiplos leitores \u00fanico escritor reads por ser transformados em locks writes n\u00e3o podem se transformados em reads (violaria Strict Two-Phase Locking) Lock -- por que evitar? pessimista overhead mesmo se n\u00e3o h\u00e1 conflitos ou restritivo ou risco de deadlock lock liberado somente no final, para evitar dirty reads/escrita prematura. Abordagem mais otimista? modifique uma c\u00f3pia privada dos dados na hora de terminar a transa\u00e7\u00e3o, verifique se nenhuma transa\u00e7\u00e3o modificou o dado, isto \u00e9, se a c\u00f3pia privada ainda \u00e9 v\u00e1lida substitua a c\u00f3pia p\u00fablica pela privada Esta t\u00e9cnica \u00e9 conhecida como deferred update , pois o update dos dados s\u00f3 ocorre no final, se a valida\u00e7\u00e3o passar. Abordagem otimista baixo overhead, se n\u00e3o houver conflitos valida\u00e7\u00e3o \u00e9 r\u00e1pida update \u00e9 simples Se houver muitos conflitos, o trabalho da transa\u00e7\u00e3o \u00e9 todo desperdi\u00e7ado. Valida\u00e7\u00e3o read e write sets de quaisquer transa\u00e7\u00f5es concorrentes deve ser disjuntos. t1 n\u00e3o deve ler dados escritos por t2 t2 n\u00e3o deve ler dados escritos por t1 t1/t2 n\u00e3o deve escrever dados escritos por t2/t1 Backward validation t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o j\u00e1 comitada. t1 n\u00e3o deve ler dados escritos por t2 Em caso de n\u00e3o valida\u00e7\u00e3o, aborte t1 Forward validation t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o ainda em execu\u00e7\u00e3o t2 n\u00e3o deve ler dados escritos por t1 Em caso de n\u00e3o valida\u00e7\u00e3o, aborte t1, possivelmente nunca terminando uma transa\u00e7\u00e3o. ou aborte t2. Timestamping transa\u00e7\u00e3o recebe um timestamp no in\u00edcio opera\u00e7\u00f5es s\u00e3o validadas na execu\u00e7\u00e3o leia somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver escrito e comitado escreva somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver lido e comitado transa\u00e7\u00f5es \"executam na ordem do timestamp\" Como implementar? Como implementar objetos tem valores tentativos , n\u00e3o comitados objetos tem vers\u00f5es em que foram escritos em que foram comitados e em que foram lidos consist\u00eancia \u00e9 testado na execu\u00e7\u00e3o da opera\u00e7\u00e3o Como implementar -- escrita escritas tem sucesso somente se vers\u00e3o sendo escrita \u00e9 maior que vers\u00f5es lidas se vers\u00e3o sendo escrita \u00e9 menor que vers\u00e3o j\u00e1 escrita, ignore e continue como implementar -- leitura leitura com vers\u00e3o v tem sucesso se maior vers\u00e3o \u00e9 comitada e menor que v ou alguma n\u00e3o comitada leitura com vers\u00e3o v \u00e9 suspensa se maior vers\u00e3o \u00e9 n\u00e3o comitada e menor que v leitura com vers\u00e3o v \u00e9 abortada se maior vers\u00e3o comitada \u00e9 maior que v Refer\u00eancias Inspirado nas notas de aula de johan montelius e vladimir vlassov, da disciplina id2201 distributed systems, kth royal institute of technology. imagens copiadas descaradamente de seus slides. Tamb\u00e9m aqui, https://www.cs.ucy.ac.cy/~dzeina/courses/epl446/lectures/16.pdf Bancos de dados distribu\u00eddos bancos de dados transacionais distribu\u00eddos Agora que relembramos como transa\u00e7\u00f5es funcionam e temos uma no\u00e7\u00e3o de como podem ser implementadas em um sistema centralizado, vamos tentar entender como faz\u00ea-lo em um sistema distribu\u00eddo. m\u00faltiplos servidores transa\u00e7\u00f5es em cada servidor transa\u00e7\u00f5es distribu\u00eddas como obter equival\u00eancia serial em transa\u00e7\u00f5es distribu\u00eddas Transa\u00e7\u00e3o distribu\u00edda begintransaction(): tid (transaction id) operation(tid,op) endtransaction(tid): ok/nok aborttransaction(tid) Pap\u00e9is cliente servidor: resource managers servidor: transaction monitor/manager Localmente, cada bd funciona como um sistema centralizado normal, usando abordagens otimistas ou pessimista para garantir consist\u00eancia. O grande problema no bd distribu\u00eddo \u00e9 garantir o acordo na termina\u00e7\u00e3o. Comprometimento distribu\u00eddo atomicidade O problema... transa\u00e7\u00e3o \\(t\\) acessa recursos nos resource managers (rm) terminar com sucessos \\(t\\) em todos os rm -- commit -- ou abortar \\(t\\) em todos os rm ainda que enlaces de comunica\u00e7\u00e3o, n\u00f3s e rm falhem, antes ou durante a termina\u00e7\u00e3o da transa\u00e7\u00e3o. 2PC - 2 Phase Commit participante -- resource manager \"tocados\" pela transa\u00e7\u00e3o coordenador -- transaction manager Premissas Cliente decide quando iniciar o commit. Cada participante faz commit ou abort da transa\u00e7\u00e3o local. pode retornar ok ou nok. Coordenador n\u00e3o come\u00e7a a commit at\u00e9 que a \\(t\\) tenha terminado em todos os participantes e cliente tenha solicitado. Participantes falham por parada. 1PC cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes \"comitarem\" e se um participante retornar nok? % enquanto outros retornam ok? e se um participante n\u00e3o responder? 2PC cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes se prepararem para terminar coordenador espera que todos se preparem ou digam se n\u00e3o podem coordenador envia ordem de termina\u00e7\u00e3o Comprometimento um participante \\(p\\) est\u00e1 pronto para commit se tiver todos os valores modificados por \\(t\\) em mem\u00f3ria est\u00e1vel e nenhuma raz\u00e3o para abortar a transa\u00e7\u00e3o (outras transa\u00e7\u00f5es conflituosas fizeram commit?) o coordenador n\u00e3o pode come\u00e7ar a termina\u00e7\u00e3o at\u00e9 que todos os participantes estejam prontos. se algum participante aborta, o coordenador deve abortar. Problema de acordo, mas n\u00e3o igual ao consenso. 2PC -- o protocolo fase 1 a: coordenador envia vote-request para participantes. b: participante responde com vote-commit ou vote-abort para o coordenador; se vote-abort, aborta localmente. fase 2 a: coordenador coleta votos de todos os processos; se forem todos vote-commit, envia global-commit para os participantes e ok para o cliente b: participantes esperam por global-commit ou global-abort Coordenador Participante Falha no Participante Participante falha no estado \\(S\\) e, ao se recuperar, identifica tal fato ao reprocessar o log de opera\u00e7\u00f5es em mem\u00f3ria dur\u00e1vel. Se est\u00e1 no estado INIT: nem sabia que a termina\u00e7\u00e3o come\u00e7ou. Aborta unilateralmente, pois ou j\u00e1 abortaram ou v\u00e3o abortar. ABORT: havia votado abort ou recebido global-abort -- continua protocolo. COMMIT: estava pronto para terminar a transa\u00e7\u00e3o com sucesso -- continua protocolo. READY: estava esperando por commit ou abort. Precisa saber se coordenador enviou global-commit ou global-abort -- consulta coordenador. 2PC Por que \u00e9 dif\u00edcil? E se \\(R_i\\) falhar depois de ter se preparado? E se \\(R_i\\) falhar mas \\(R_j\\) continuar funcionando? E se todos estiverem desligados quando \\(R_i\\) se recuperar? E se \\(R_i\\) estiver lento e parecer que a transa\u00e7\u00e3o falhou? Falha no Participante READY: esperando por commit ou abort. Precisa saber se coordenador enviou global-commit our global-abort -- consulta coordenador. E se coordenador n\u00e3o estiver presente? Assumindo que participantes se conhecem, contate participante \\(Q\\) Se \\(Q\\) em COMMIT , vai para COMMIT Se \\(Q\\) em ABORT , vai para ABORT Se \\(Q\\) em INIT , ordena que Q aborte e, se confirmado, veja passo anterior Se \\(Q\\) em READY , consulta outro participante. Se todos os participantes em READY? Possivelmente o coordenador j\u00e1 respondeu ao cliente. Precisa esperar pelo coordenador. Falha no Coordenador O problema principal \u00e9: e se ningu\u00e9m ouviu a decis\u00e3o final do coordenador? Neste caso, o protocolo n\u00e3o pode continuar, enquanto o coordenador n\u00e3o retornar, pois se os RM abortarem, podem estar contradizendo algo dito ao cliente, por exemplo, \"Sim, ATM, pode entregar o dinheiro\", ou executando um comando que o cliente v\u00ea como anulado, como \"Reenvie o pedido de mais 27 carros \u00e0 f\u00e1brica.\" Recupera\u00e7\u00e3o do Coordenador Ao se recuperar, o coordenador: sabe se come\u00e7ou a termina\u00e7\u00e3o de alguma transa\u00e7\u00e3o sabe se j\u00e1 enviou alguma resposta final para as transa\u00e7\u00f5es inacabadas sabe se j\u00e1 recebeu a confirma\u00e7\u00e3o de todos os participantes (se transa\u00e7\u00e3o n\u00e3o estiver em aberto) reenvia a \u00faltima mensagem das transa\u00e7\u00f5es em aberto. Otimiza\u00e7\u00f5es Participantes \"somente-leitura\" N\u00e3o se importa com a decis\u00e3o; termina ap\u00f3s fase 1. Responde com vote-commit-ro Abort presumido Se ocorrer timeout, coordenador envia global-abort a todos e esquece transa\u00e7\u00e3o Se questionado, responde com global-abort. Transfer\u00eancia de coordena\u00e7\u00e3o se houver somente um participante... vote-request-transfer participante responde com global-commit/global-abort Coleta de Lixo Mesmo quando somente um participante falha... Ap\u00f3s receber decis\u00e3o, o participante pode concluir e esquecer a transa\u00e7\u00e3o. Mas e se o participante falho precisar se recuperar e todos os outros envolvidos tiverem esquecido a transa\u00e7\u00e3o? Coleta de lixo s\u00f3 pode ser feita quando todos tiverem confirmado a execu\u00e7\u00e3o da transa\u00e7\u00e3o e, por isso, Fase 2b \u00e9 necess\u00e1ria. 3-PC Estende o protocolo para permitir contornar falha do coordenador. O Protocolo Fase 1a -- Coordenador envia vote-request para participantes. Fase 1b -- Participante responde com vote-commit ou vote-abort para o coordenador; se vote-abort, aborta localmente. Fase 2a -- Coordenador coleta votos de todos os processos; se forem todos vote-commit, envia prepare-commit para os participantes; se n\u00e3o, global-abort e para. Fase 2b -- Participantes esperam por prepare-commit ou global-abort; se o primeiro, respondem com ready-commit ; se o segundo, param. Fase 3a -- coordenador espera por ready-commit de todos e ent\u00e3o envia global-commit. Fase 3b -- participantes esperam por global-commit. Coordenador Participante Falha no Participante \\(P\\) consegue saber o que fazer ap\u00f3s se recuperar da falha no estado READY ou PRE-COMMIT Participantes e coordenador n\u00e3o distam mais que um estado. Se algu\u00e9m em READY, o coordenador n\u00e3o mandou global-commit ainda; Aborte. Se todos em PRE-COMMIT, \u00e9 poss\u00edvel comitar, comite. A execu\u00e7\u00e3o dos passos anteriores tem que anular o poder do coordenador. Se todos os participantes em READY? 3PC x 2PC 3PC -- Aumenta disponibilidade 2PC -- Falha do coordenador \u00e9 \"corner case\" 3PC -- Aumenta o custo do \"caminho feliz\" e por isso n\u00e3o \u00e9 usado na pr\u00e1tica Nenhum escala e n\u00e3o us\u00e1-los \u00e9 uma das raz\u00f5es para o surgimento dos sistemas NoSQL Paxos-Commit Usa inst\u00e2ncias de Consenso Distribu\u00eddo para votar. Se o consenso \u00e9 tolerante a falhas e consistente, todos v\u00eaem o mesmo resultado na transa\u00e7\u00e3o. O protocolo Para terminar a transa\u00e7\u00e3o \\(T\\) , o coordenador envia request-commit a todos os participantes. Um participante \\(P\\) prop\u00f5e seu voto na inst\u00e2ncia \\(T_P\\) de consenso. Todo participante \\(P\\) espera pelas decis\u00f5es das inst\u00e2ncias de consenso \\(T_i\\) para todos os participantes \\(i\\) , inclusive si mesmo; se todas as decis\u00f5es forem commit, o participante comita a transa\u00e7\u00e3o. Se cansar de esperar por \\(T_Q\\) , o participante prop\u00f5e abort em \\(T_Q\\) . Falha no Participante Se o participante falha antes de votar, ent\u00e3o algu\u00e9m votar\u00e1 abort por ele. Se o participante \\(P\\) falha, ou \u00e9 suspeito de, ent\u00e3o \u00e9 poss\u00edvel que dois votos diferentes tenham sido propostos em \\(T_P\\) ; isso n\u00e3o \u00e9 um problema pois a decis\u00e3o \u00e9 a mesma para todos observando a inst\u00e2ncia. Ap\u00f3s se recuperar, o participante recupera as decis\u00f5es de todas as inst\u00e2ncias \\(T_i\\) e termina apropriadamente. Log Recuper\u00e1vel Como garantir que o log poder\u00e1 ser lido para recuperar o processo? Disco Duplicado Dois discos iguais? Dados diferentes, mas ambos bons? Um bom outro estragado? Ambos estragados? Estruturas de Dados para SD Qualquer que seja a escolha de algoritmo para fazer o particionamento dos dados entre servidores, sobra ainda a quest\u00e3o de como manipular os dados dentro do servidor. Idealmente, toda opera\u00e7\u00e3o seria executada a partir da mem\u00f3ria principal, tendo assim a menor lat\u00eancia poss\u00edvel. Contudo, para que se tenha tamb\u00e9m durabilidade das opera\u00e7\u00f5es executadas, para que os dados manipulados sobrevivam a reinicializa\u00e7\u00f5es do servidor, intencionais ou n\u00e3o, \u00e9 preciso armazenar os dados em mem\u00f3ria est\u00e1vel , da qual a mais comum s\u00e3o os discos r\u00edgidos . \u00c9 not\u00f3rio que escritas em disco s\u00e3o muito mais lentas que em mem\u00f3ria principal, mas o que exatamente \u00e9 lento no acesso ao disco? Essencialmente, o posicionamento da cabeca de leitura/escrita na trilha correta do disco, pois esta opera\u00e7\u00e3o \u00e9 mec\u00e2nica. Por esta raz\u00e3o, acessos aleat\u00f3rios s\u00e3o mais custosos que acessos sequenciais, pois neste o custo de posicionamento \u00e9 pago apenas uma vez. Por este motivo, muitos bancos de dados, especialmente DHT pois tem seu uso focado em quantidades muito grandes de dados, gerados e acessados com grande velocidade, tentam acessar o disco sempre de forma sequencial. Alguns bancos de dados, como o Cassandra, armazenam os dados na forma de uma Log Structured Merge Tree , ou LSMT. Log Structured Merge Tree Uma Log Structured Merge Tree \u00e9 uma forma de se armazenar dados em disco de forma de forma quase sempre sequencial, minimizando assim os o impacto da durabilidade no desempenho do sistema. Considere um banco armazenando uma pequena quantidade de dados, que cabe em mem\u00f3ria principal. Na LSMT, opera\u00e7\u00f5es de escrita s\u00e3o adicionadas a um commit log , em disco, e somente ent\u00e3o s\u00e3o executadas em mem\u00f3ria principal e confirmadas para o cliente; a estrutura que armazena os dados em mem\u00f3ria \u00e9 denominada memory table , ou simplesmente memtable . Neste cen\u00e1rio o acesso ao disco na escrita \u00e9 sequencial, o melhor que se pode ter em um disco, e a recupera\u00e7\u00e3o dos dados \u00e9 feita diretamente da mem\u00f3ria, r\u00e1pida. No caso de uma reinicializa\u00e7\u00e3o do processo, a reexecu\u00e7\u00e3o do commit log restaurar\u00e1 o estado da memtable. Contudo, se o commit log for extenso, reexecut\u00e1-lo demandar\u00e1 um tempo significativo. Uma forma de acelerar o processo \u00e9 fazer snapshots da memtable de forma sincronizada com a escrita no log. Isto \u00e9, digamos que todas as opera\u00e7\u00f5es de escrita, at\u00e9 a d\u00e9cima, est\u00e3o salvas no commit log e refletidas na memtable. Digamos tamb\u00e9m que todas as opera\u00e7\u00f5es s\u00e3o modifica\u00e7\u00f5es da mesma linha do banco de dados em mem\u00f3ria. Se um snapshot \u00e9 tomado, ele ser\u00e1 correspondente ao commit log, isto \u00e9, conter\u00e1 o efeito de exatamente as mesmas 10 opera\u00e7\u00f5es, mas de forma mais compacta que o log, uma vez que o log conter\u00e1 dez opera\u00e7\u00f5es e o snapshot somente uma linha de dados. Ap\u00f3s o snapshot ser conclu\u00eddo, o log correspondente pode ser apagado. Novas opera\u00e7\u00f5es de escrita devem ser armazenadas em um novo log e, no caso de uma reinicializa\u00e7\u00e3o, primeiro se deve restaurar o snapshot e ent\u00e3o o novo log. Para lidar com corrup\u00e7\u00f5es de arquivo no sistema, pode ser uma boa ideia manter mais do que o \u00faltimo log e snapshot , j\u00e1 que a recupera\u00e7\u00e3o do estado exigiria voltar mais atr\u00e1s na reexecu\u00e7\u00e3o de opera\u00e7\u00f5es. Observe que, al\u00e9m da escrita dos logs, todos os outros acessos ao disco tamb\u00e9m s\u00e3o sequenciais, seja o flush das memtables, ou a leitura dos snapshots para recupera\u00e7\u00e3o e do commit log para reexecu\u00e7\u00e3o, e j\u00e1 que opera\u00e7\u00f5es de leitura s\u00e3o todas respondidas da mem\u00f3ria, o sistema ter\u00e1 um excelente desempenho. Contudo, h\u00e1 outro limitante de desempenho importante, relacionado \u00e0 premissa pouco realista de que os dados cabem todos em mem\u00f3ria. Isto \u00e9, se os dados n\u00e3o cabem em mem\u00f3ria, snapshots ser\u00e3o importantes n\u00e3o somente para permitir coletar lixo dos logs, isto \u00e9, dados obsoletos, mas tamb\u00e9m, para usar a capacidade de armazenamento dos discos. Consideremos ent\u00e3o um cen\u00e1rio em que a memtable cabe apenas n entradas; quando a opera\u00e7\u00e3o para adicionar \\(n+1\\) -\u00e9sima entrada \u00e0 memtable \u00e9 recebida, um flushs dos dados para um novo snapshot \u00e9 feito e a memtable \u00e9 resetada , liberando espa\u00e7o em mem\u00f3ria. Para melhorar o desempenho, estas descargas podem ser feitas proativamente antes da chegada de novas entradas e fora do caminho cr\u00edtico da opera\u00e7\u00e3o de escrita, mas isto \u00e9 apenas uma otimiza\u00e7\u00e3o e portanto n\u00e3o a consideraremos aqui. Neste novo fluxo, os arquivos em disco n\u00e3o correspondem mais a snapshots do banco de dados, ent\u00e3o nos referiremos a eles como stable storage tables , ou sstables , em oposi\u00e7\u00e3o \u00e0s memtables , pelo menos por enquanto. Compacta\u00e7\u00f5es Apesar deste novo fluxo de escrita aumentar a capacidade de armazenamento do nosso banco de dados, ele traz problemas para o fluxo de leitura. Digamos que a chave \\(k\\) teve um valor atribu\u00eddo e descarregado em uma sstable em diversas ocasi\u00f5es. O primeiro problema aqui \u00e9 que h\u00e1 v\u00e1rios valores antigos associados a \\(k\\) , inutilmente e ocupando espa\u00e7o, isto \u00e9, lixo. O segundo \u00e9 que caso o valor associado a \\(k\\) seja requisitado, o sistema dever\u00e1 retornar a \u00faltima vers\u00e3o, que pode estar em diversos arquivos. Para lidar com ambos os problemas, podemos compactar as sstables juntas, eliminados dados obsoletos e minimizando o n\u00famero de arquivos a serem pesquisados no caso de leitura. Caso a sstables estejam ordenadas, o procedimento de compacta\u00e7\u00e3o pode ser feito como a uni\u00e3o de dois segmentos de dados no merge sort , isto \u00e9, iterando-se paralelamente nos dois arquivos e escolhendo sempre a menor chave da vez e movendo-a para um novo segmento que conter\u00e1 a uni\u00e3o dos dados. A figura a seguir mostra um exemplo que v\u00e1rias sstables de n\u00edvel 0, aquelas geradas por flushs , s\u00e3o unidas gerando sstables de n\u00edvel 1 e assim sucessivamente. Observe como as compacta\u00e7\u00f5es geram uma \u00e1rvore (na verdade, uma floresta), raz\u00e3o do nome merge tree . No caso de uma pesquisa, somente as tabelas mais \u00e0 direita e de n\u00edvel mais alto precisam ser consultadas e portanto as sstables j\u00e1 usadas como entrada podem ser eliminadas como lixo do sistema. Ainda assim, no caso de uma leitura, diversas sstables potencialmente cont\u00e9m o dado a ser retornado. O problema se agrava em sistemas em que partes do dado possam ser gravadas independentemente, como no CassandraDB, em que cada coluna \u00e9 independente das outras. Diversas propostas poderiam ser feitas para se identificar mais rapidamente se uma sstable cont\u00e9m uma chave. Por exemplo, pode-se associar a cada tabela um bitmap indicando a presen\u00e7a ou n\u00e3o de uma certa chave, mas esta abordagem obviamente falha se o espa\u00e7o de chaves for grande. Outra possibilidade \u00e9 lembrar a faixa de chaves contida na tabela. Esta estrat\u00e9gia pode ser \u00fatil caso haja localidade no espa\u00e7o de chaves no momento da escrita, mas falhar\u00e1 miseravelmente se o espa\u00e7o de chaves for usado uniformemente, resultando em faixas grandes entre a menor e maior chaves de cada tabela. Como acelerar a identifica\u00e7\u00e3o das sstables pertinentes? Entram em cena os filtros de Bloom . Filtros de Bloom De acordo com nossa fonte mais que confi\u00e1vel, a Wikipedia Bloom Filter A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not, thus a Bloom filter has a 100% recall rate. In other words, a query returns either \"possibly in set\" or \"definitely not in set\" . Se associarmos a cada sstable um filtro de Bloom, ent\u00e3o s\u00f3 ser\u00e1 preciso l\u00ea-la se o filtro correspondente disser que a chave possivelmente est\u00e1 contida, como no seguinte exemplo. Mas como exatamente constru\u00edmos um filtro de Bloom? Iniciamos com um vetor de bits inicialmente zerados e um conjunto finito de fun\u00e7\u00f5es de hash cujo resultado seja uniformemente distribu\u00eddo no tamanho do vetor de bits. Para cada elemento colocado no conjunto a ser refletido pelo filtro, aplicamos cada uma das fun\u00e7\u00f5es hash e colocamos o bit 1 na posi\u00e7\u00e3o do vetor igual ao resultado da fun\u00e7\u00e3o. No exemplo a seguir, inserimos os elementos x, y e z e usamos tr\u00eas fun\u00e7\u00f5es hash. Na consulta , cada elemento passa por pelas mesmas fun\u00e7\u00f5es hash. Se algum dos \u00edndices apontados n\u00e3o estiver com um 1, como no caso do c, no exemplo, o elemento n\u00e3o pertence ao conjunto. Caso contr\u00e1rio, o filtro responder\u00e1 que \u00e9 poss\u00edvel que perten\u00e7a. Mas qu\u00e3o bom \u00e9 um filtro de Bloom na identifica\u00e7\u00e3o do das sstables? Ou, de outra forma, quais fatores influenciam na taxa de falsos positivos do filtro? o n\u00famero \\(n\\) de elementos no conjunto, uma vez que quanto mais elementos, mais bits 1; o n\u00famero \\(k\\) de hashes, pois quanto mais hashes, mais bits transformados em 1; e, o n\u00famero \\(m\\) de bits no vetor, pois quanto menos bits, mais colis\u00f5es de bits. De forma mais precisa, a probabilidade de setar um certo bit na inser\u00e7\u00e3o de um elemento \u00e9 \\(1/m\\) , e a probabilidade de n\u00e3o setar tal bit \u00e9 \\(1 - 1/m\\) ; a probabilidade de \\(k\\) hashes n\u00e3o setarem um bit \u00e9 \\((1 - 1/m)^k\\) ; a probabilidade de n\u00e3o setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\((1 - 1/m)^{kn}\\) ; a probabilidade de setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\(1 - (1 - 1/m)^{kn}\\) Logo, a probabilidade de falso positivo \\(p = (1 - (1 - 1/m)^{kn})^k \\approx (1 - e^{-kn/m})^k\\) O que nos permite chegar \u00e0 rela\u00e7\u00e3o \\(m/n = - 1.44\\log_2 p\\) , em que podemos calcular \\(m\\) em fun\u00e7\u00e3o do \\(n\\) esperado e do \\(p\\) desejado. E podemos tamb\u00e9m identificar o \\(k\\) \u00f3timo para a situa\u00e7\u00e3o, pela equa\u00e7\u00e3o \\(k = - \\frac{\\ln p}{\\ln 2} = - \\log_2 p\\) Uma forma \"simples\" de visualizar este resultado \u00e9 dada pela figura a seguir, em que o eixo Y d\u00e1 a taxa de falsos positivos do filtro em fun\u00e7\u00e3o do n\u00famero de elementos inseridos, indicado no eixo X, para diversas configura\u00e7\u00f5es, apresentadas como curvas. Por exemplo, com um filtro com \\(m = 2^{24}b = 2MB\\) , ap\u00f3s 1 milh\u00e3o de inser\u00e7\u00f5es, tem-se probabilidade de falsos positivo \\(p = 0,0001\\) . Refer\u00eancias Modern Algorithms and Data Structures: Bloom-Filter TODO Mover ED SD de Tecnologias para c\u00e1 Combinar https://adambcomer.com/blog/simple-database/motivation-design.html https://adambcomer.com/blog/simple-database/memtable.html https://adambcomer.com/blog/simple-database/wal.html https://www.jasondavies.com/bloomfilter/ Modelos de Consist\u00eancia Motiva\u00e7\u00e3o Content Delivery Network Conte\u00fado \u00e9 colocado pr\u00f3ximo aos clientes. Conte\u00fado est\u00e1tico ou majoritariamente determin\u00edstico. Um pequeno atraso na replica\u00e7\u00e3o \u00e9 tolerado. Atualiza\u00e7\u00e3o acontece infrequentemente. Fonte: https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/ RAFT Considere um sistema replicado usando RAFT. Ap\u00f3s cada opera\u00e7\u00e3o que modifica o estado, todas as r\u00e9plicas tem o mesmo valor. Fonte: http://thesecretlivesofdata.com/raft/ Caso um cliente queira apenas ler o estado, o que deve fazer? Requisitar o valor do l\u00edder: o valor lido ser\u00e1 o \u00faltimo valor escrito. Requisitar o valor de alguma r\u00e9plica: o valor lido ser\u00e1 um valor escrito, n\u00e3o necessariamente o \u00faltimo. Mais tempo implica maior a probabilidade de ser o valor escrito. Se em vez de difus\u00e3o at\u00f4mica us\u00e1ssemos IP-Multicast? Alguns valores escritos poderiam nunca ser vistos. Replica\u00e7\u00e3o: solu\u00e7\u00e3o ou problema? Replica\u00e7\u00e3o aumenta disponibilidade mas tem custo em desempenho e, possivelmente, inconsist\u00eancias tempor\u00e1rias nos dados. Conflitos O problema da replica\u00e7\u00e3o est\u00e1 em como lidar com conflitos nas opera\u00e7\u00f5es dos clientes. Leitura-Leitura : N\u00e3o h\u00e1 conflitos. Qualquer quantidade de clientes. Replicar \"... \u00e9 f\u00e1cil, extremamente f\u00e1cil ...\" Leitura-Escrita : Clientes querem ler dados corretos e, geralmente, a \u00faltima vers\u00e3o escrita. Como atualizar rapidamente as r\u00e9plicas? Escrita-Escrita : Dados sendo atualizados em m\u00faltiplos lugares ao mesmo tempo. Necessidade de ordena\u00e7\u00e3o/compatibiliza\u00e7\u00e3o das escritas. Ordena\u00e7\u00e3o total das opera\u00e7\u00f5es pode ser custosa demais. Solu\u00e7\u00e3o? Enfraquecer os requisitos de consist\u00eancia dos sistema. Tipos de consist\u00eancia Diferentes formas de propaga\u00e7\u00e3o e recupera\u00e7\u00e3o resultam em diferentes garantias, diferentes modelos de consist\u00eancia . Consist\u00eancia forte: todas a r\u00e9plicas tem o mesmo valor dentro de um pequena janela de tempo. Alto custo. Consist\u00eancia eventual: r\u00e9plicas um dia ter\u00e3o o mesmo valor. Demora em sincronizar. Consist\u00eancia fraca: n\u00e3o h\u00e1 garantia da replica\u00e7\u00e3o. Yay!!! Diferentes modelos com nomes parecidos ou at\u00e9 iguais. \u00c9 preciso conhecer o que cada sistema est\u00e1 entregando para poder utiliz\u00e1-lo da forma correta. Defini\u00e7\u00e3o Contrato entre uma data-store (distribu\u00edda) em que se especifica os resultados de opera\u00e7\u00f5es de leitura e escrita na presen\u00e7a de concorr\u00eancia. Modelos Modelos Centrados nos Dados vs. Modelos Centrados nos Clientes Em um, os dados s\u00e3o mantidos consistentes. No outro, inconsist\u00eancias n\u00e3o s\u00e3o vistas pelo cliente. Modelo Centrado nos Dados Data store Modelo Computacional Consist\u00eancia Forte : opera\u00e7\u00f5es s\u00e3o sincronizadas Estrita (Strict): segue a linha do tempo. Sequencial: bancos de dados transacionais (quase). Causal: opera\u00e7\u00f5es com depend\u00eancia causal s\u00e3o ordenadas FIFO: ordem dos comandos de um mesmo cliente. Consist\u00eancia Fraca : sincroniza\u00e7\u00e3o acontece quando necess\u00e1rio. Consist\u00eancia fraca geral Consist\u00eancia de entrada Quanto mais fraco, mais escal\u00e1vel. Nota\u00e7\u00e3o A leitura de x em (a) retorna a A primeira leitura de x em (b) retorna Nil A segunda leitura de x em (b) retorna a Consist\u00eancia Estrita Qualquer leitura de um objeto \\(X\\) retorna o valor gravado em \\(X\\) pela opera\u00e7\u00e3o de escrita mais recente em \\(X\\) . O que quer dizer \"mais recente\" em um sistema distribu\u00eddo ass\u00edncrono? Todas as opera\u00e7\u00f5es de escrita s\u00e3o instantaneamente vis\u00edveis a todos os processos tempo global \u00e9 respeitado. Comportamento observado em um sistema sem conflitos ou centralizado Em qual(is) cen\u00e1rio(s) temos consist\u00eancia estrita? Consist\u00eancia Sequencial O resultado de qualquer execu\u00e7\u00e3o \u00e9 equivalente a alguma execu\u00e7\u00e3o sequencial dos processos, e as opera\u00e7\u00f5es da cada processo aparecem nesta execu\u00e7\u00e3o sequencial na ordem especificada por seu programa. P2, P3, P4, P1, P4, P3 P1 ou P2, qual veio primeiro? Consist\u00eancia Causal Escritas com potencial rela\u00e7\u00e3o causal s\u00e3o vistas por todos os processos na mesma ordem. Escritas concorrentes (n\u00e3o causalmente relacionadas) podem se vistas em ordens diferentes por processos diferentes. W(x)b depende de R(x)a que depende de W(x)a W(x)c e W(x)b s\u00e3o concorrentes. W(x)b depende de R(x)a que depende de W(x)a. W(x)a deve ser ordenado com W(x)b. P3 n\u00e3o pode ter lido b e depois a. Consist\u00eancia FIFO Escritas de um processo s\u00e3o vistas por todos os outros processos na ordem em que foram feitas. Escritas de diferentes processos podem ser vistas em ordens diferentes. Opera\u00e7\u00f5es Simples Modelos desenvolvidos para processamento paralelo, especificando a ordem de execu\u00e7\u00e3o de opera\u00e7\u00f5es em m\u00faltiplos threads/processos. Grupos de Opera\u00e7\u00f5es Efeito de um grupo de opera\u00e7\u00f5es se torna vis\u00edvel a outros processos ao mesmo tempo. Efeitos de opera\u00e7\u00f5es individuais em um grupo n\u00e3o s\u00e3o vis\u00edveis. Vari\u00e1veis de sincroniza\u00e7\u00e3o Acesso \u00e0s vari\u00e1veis de sincroniza\u00e7\u00e3o da datastore \u00e9 sequencialmente consistente. Acesso \u00e0 vari\u00e1vel de sincroniza\u00e7\u00e3o n\u00e3o \u00e9 permitido at\u00e9 que todas as escritas das anteriores tenham sido executadas em todos os lugares. Acesso aos dados n\u00e3o \u00e9 permitido at\u00e9 que todas as vari\u00e1veis de sincroniza\u00e7\u00e3o tenham sido liberadas. Vari\u00e1veis de sincroniza\u00e7\u00e3o Materializando vari\u00e1veis de sincroniza\u00e7\u00e3o na forma de locks Consist\u00eancia de Entrada Lock de leitura s\u00f3 retorna quando todas as mudan\u00e7as guardadas por aquele lock tiverem sido executadas no processo. Lock de escrita s\u00f3 retorna quando nenhum outro processo tiver um lock, de leitura ou escrita. Para ler uma vari\u00e1vel, processo deve primeiro contactar o dono atual do lock cercando a vari\u00e1vel, para pegar as mais recentes atualiza\u00e7\u00f5es. Transa\u00e7\u00f5es Tornam o trancamento/destrancamento de vari\u00e1veis transparente. Modelos Centrados nos Clientes Ideia b\u00e1sica Evitar sincroniza\u00e7\u00e3o global focando-se no que os clientes v\u00eaem do sistema. Se para os clientes parecer consistente, tudo bem. Consist\u00eancia Eventual Se nenhuma escrita ocorrer em per\u00edodo consider\u00e1vel de tempo, os clientes gradualmente se sincronizar\u00e3o e ficar\u00e3o consistentes. Se clientes sempre acessarem as mesmas r\u00e9plicas, ter\u00e3o impress\u00e3o de consist\u00eancia. Garantias s\u00e3o do ponto de vista de um cliente. Leituras monot\u00f4nicas Escrita monot\u00f4nicas Leia suas escritas Escritas seguem leituras. Modelo de Sistema Cliente pode se mover antes de sua \u00faltima opera\u00e7\u00e3o ter replicado do servidor onde estava para o novo servidor. Leituras Monot\u00f4nicas Garantia Se um processo l\u00ea o valor de um item \\(x\\) , qualquer leitura sucessiva de \\(x\\) retornar\u00e1 o mesmo valor ou um mais recente. Toda vez que se conecta a um servidor de email, seu cliente l\u00ea novas mensagens, caso haja. O cliente nunca esquece uma mensagem, mesmo que ainda n\u00e3o esteja no servidor conectado por \u00faltimo. WS( \\(x_i\\) ) -- opera\u00e7\u00f5es de escrita ( write set ) que levaram a vari\u00e1vel \\(x\\) a ter o valor \\(x_i\\) . WS( \\(x_i;x_j\\) ) -- opera\u00e7\u00f5es de escrita relativas a \\(x_j\\) incluem opera\u00e7\u00f5es de escrita relativas a \\(x_i\\) Escritas Monot\u00f4nicas Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o esta opera\u00e7\u00e3o deve terminar antes que qualquer escrita sucessiva em \\(x\\) possa ser executada pelo mesmo processo. Em um sistema de arquivos na rede, a escrita do conte\u00fado de um arquivo, em certa posi\u00e7\u00e3o, s\u00f3 pode ser feita se escritas anteriores j\u00e1 est\u00e3o registradas no arquivo, independentemente de o cliente contactar novo servidor de arquivos. Leia suas Escritas Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o leituras sucessivas no mesmo item pelo mesmo processo devem refletir tal escrita. Atualizar c\u00f3digo fonte de uma p\u00e1gina e exigir que o navegador carrega a nova vers\u00e3o. Escritas seguem Leituras Garantia: Se um processo l\u00ea um item \\(x\\) , ent\u00e3o escritas sucessivas no mesmo item s\u00f3 podem ser completadas se o mesmo reflete o valor lido anteriormente. S\u00f3 \u00e9 permitido enviar uma resposta a uma mensagem se a mensagem em si \u00e9 vista, independentemente do cliente ter se movimentado. Mais informa\u00e7\u00f5es: Aqui e aqui Posicionamento de R\u00e9plicas Onde colocar r\u00e9plicas para conseguir melhor escalabilidade do sistema? Menor custo de comunica\u00e7\u00e3o? Objetos (c\u00f3digo/dados) Permanente Sob demanda do servidor -- por exemplo em uma CDN Sob demanda do cliente -- por exemplo um cache. Sob demanda do Servidor \\(Q\\) conta acessos ao arquivo \\(F\\) Agrega acessos por poss\u00edvel r\u00e9plica mais pr\u00f3xima ( \\(P\\) ) N\u00famero de acessos acima de limiar \\(R\\) , replica para \\(P\\) N\u00famero de acessos abaixo de \\(D\\) , apaga de \\(P\\) \\(D < R\\) Se n\u00e3o \u00e9 alto o suficiente para replicar nem baixo o suficiente para ignorar (entre \\(D\\) e \\(R\\) ), considera migrar. Propaga\u00e7\u00e3o de Atualiza\u00e7\u00f5es R\u00e9plicas precisam ser atualizadas. Propagar dados -- n\u00e3o reexecuta opera\u00e7\u00f5es. Propagar opera\u00e7\u00f5es -- n\u00e3o copia todos os dados modificados. Propagar notifica\u00e7\u00f5es -- r\u00e9plica precisa solicitar atualiza\u00e7\u00e3o. Usado em caches. Melhor op\u00e7\u00e3o depende do custo das opera\u00e7\u00f5es, dados manipulados, e taxa de leitura/escrita dos dados. Propaga\u00e7\u00e3o de Atualiza\u00e7\u00f5es R\u00e9plicas precisam ser atualizadas. Propagar dados raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o caras Propagar opera\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o baratas Propagar notifica\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 pequena pouco uso da rede Proativo/Push ou Reativo/Pull Proativo Mant\u00e9m r\u00e9plicas consistentes Desnecess\u00e1rio se leitura \\(<<\\) escrita. Reativo R\u00e9plicas s\u00f3 se tornam consistentes quando necess\u00e1rio. Lento se leitura \\(>>\\) escrita Qual \u00e9 melhor? H\u00edbrido: Lease R\u00e9plica se registra para receber atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es por um per\u00edodo. Estado sobre r\u00e9plicas \u00e9 mantido enquanto poss\u00edvel, pelo per\u00edodo contratado. Em caso de sobrecarga, deixa de mandar atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es. Em caso de lease antigo n\u00e3o renovado, deixa de mandar atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es. Em caso de renova\u00e7\u00f5es frequentes, aumenta o per\u00edodo do lease. Recupera\u00e7\u00e3o & Checkpoint Recupera\u00e7\u00e3o Suponha que uma s\u00e9rie de erros aconteceram no sistema, e que n\u00e3o \u00e9 poss\u00edvel continuar o processamento como o sistema est\u00e1. Neste cen\u00e1rio, \u00e9 necess\u00e1rio ou avan\u00e7ar para um novo estado, livre de erros, ou retroceder a um estado correto anterior. Voltar a um estado correto parece ser a solu\u00e7\u00e3o mais f\u00e1cil. Para isso, precisamos de Pontos de Recupera\u00e7\u00e3o Snapshots Podem ser usados na: Recupera\u00e7\u00e3o do sistema. Coleta de lixo (remover objetos n\u00e3o referenciados em nenhum outro processo). Detec\u00e7\u00e3o de deadlocks. Depura\u00e7\u00e3o (pausar o sistema). Pontos de Recupera\u00e7\u00e3o Ponto de Recupera\u00e7\u00e3o v\u00e1lidos s\u00e3o a uni\u00e3o de backups locais que formam um Estado Global Consistente . Estado Global Consistente O qu\u00ea? Conjunto com um estado local de cada processo no sistema tal que toda mensagem recebida no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do processo remetente. Linha de recupera\u00e7\u00e3o O mais recente Estado Global Consistente Comunica\u00e7\u00e3o Confi\u00e1vel Se o sistema prov\u00ea comunica\u00e7\u00e3o confi\u00e1vel, ent\u00e3o toda mensagem enviada no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do destinat\u00e1rio. Rollback em Cascata Bad timing Se estados locais s\u00e3o capturados na \"hora errada\", a linha de recupera\u00e7\u00e3o pode ser o estado inicial. Armazenamento em Disco Segue a t\u00e9cnica j\u00e1 estudada. Checkpoint Checkpointing independente Cada processo faz o checkpoint local independentemente, incorrendo no risco de um rollback em cascata. Seja \\(C_i^m\\) o \\(m\\) -\u00e9simo checkpoint do processo \\(p_i\\) . Seja \\(I_i^m\\) o intervalo entre \\(C_i^{m-1}\\) e \\(C_i^m\\) . Quando o processo \\(p_i\\) envia a mensagem no intervalo \\(I_i^m\\) , envia \\((i,m)\\) em piggyback Quando o processo \\(p_j\\) recebe a mensagem no intervalo \\(I_j^n\\) , grava a depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) A depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) \u00e9 salva junto com o checkpoint \\(C_j^n\\) Restri\u00e7\u00e3o Se o processo \\(p_j\\) \u00e9 revertido para o estado \\(C_j^n\\) , ent\u00e3o o \\(p_i\\) n\u00e3o pode reverter para nenhum estado anterior a \\(C_i^m\\) , ou n\u00e3o teria enviado as mensagens recebidas por \\(p_j\\) 4 inclusas em \\(C_j^n\\) . ou Se o processo \\(p_i\\) \u00e9 revertido para o estado \\(C_i^{m-1}\\) , ent\u00e3o o \\(p_j\\) tem que ser revertido pelo menos at\u00e9 \\(C_j^{n-1}\\) , ou incluiria mensagens ainda n\u00e3o enviadas por \\(p_i\\) . Como implementar a recupera\u00e7\u00e3o? Caso patol\u00f3gico \\(p_i\\) e \\(p_j\\) no estado inicial ( \\(C_i^0, C_j^0\\) ) \\(p_i\\) manda mensagens para \\(p_j\\) ( \\(C_i^1 \\rightarrow C_j^1\\) ) \\(C_j^1\\) \\(p_j\\) manda mensagens para \\(p_i\\) \\(C_j^2 \\rightarrow C_i^1\\) \\(C_i^1\\) \\(p_i\\) manda mensagens para \\(p_j\\) \\(C_i^2 \\rightarrow C_j^2\\) \\(C_j^2\\) \\(p_j\\) manda mensagens para \\(p_i\\) \\(C_j^3 \\rightarrow C_i^2\\) \\(C_i^2\\) ... Checkpointing coordenado Processos se coordenam por troca de mensagem para executar checkpointing \"simultaneamente\". Qual a vantagem sobre o n\u00e3o coordenado? Bloqueio em duas fases Um coordenador faz multicast da mensagem \"checkpoint-request\" Quando um participante recebe \"checkpoint-request\" faz um checkpoint local para de mandar mensagens da aplica\u00e7\u00e3o responde com \"checkpoint-taken\" Quando \"checkpoint-taken\" recebido de todos os participantes, multicast \"checkpoint-done\" Quando receber \"checkpoint-done\", retoma computa\u00e7\u00e3o normal Por qu\u00ea funciona? Impede forma\u00e7\u00e3o de depend\u00eancias circulares. Todos os processos precisam participar? Somente os que dependem da recupera\u00e7\u00e3o do coordenador. Pontos negativos? Duas fases? J\u00e1 vi isso antes... Se o coordenador falha, outros processos ficam bloqueados? Timeout! Como eleger outro coordenador? E se dois aparecerem juntos? Pode ser resolvido com um protocolo de elei\u00e7\u00e3o como o do RAFT. N\u00e3o \u00e9 garantido, mas aumenta as chances de sucesso. Chandy-Lamport N\u00e3o interfere na aplica\u00e7\u00e3o Cada processo grava snapshot independentemente Observador (iniciador do snapshot) Salva o pr\u00f3prio estado Envia uma mensagem \"snapshot\" aos outros processos em cada canal de sa\u00edda Grava as mensagens chegando em cada canal at\u00e9 que receba uma mensagem \"snapshot\" naquele canal. Um processo \\(p\\) que receba \"snapshot\" de um processo \\(q\\) grava estado local \\(S_p\\) grava estado do canal \\(C_{q,p} =\\emptyset\\) Envia uma mensagem \"snapshot\" aos outros processos em cada canal de sa\u00edda Grava as mensagens chegando em cada canal at\u00e9 que receba uma mensagem \"snapshot\" naquele canal (excluindo \\(C_{q,p}\\) ) Protocolo termina para o processo \\(p\\) quando tiver recebido marcador \"snapshot\" em cada um de seus canais. O estado global consiste dos snapshots + estado em cada um dos canais. Exige canais FIFO Message Logging Em vez de checkpoints frequentes, crie um log da comunica\u00e7\u00e3o e o re-execute a partir do \u00faltimo checkpoint. Ideia b\u00e1sica: A computa\u00e7\u00e3o \u00e9 determinada pela troca de mensagens (eventos n\u00e3o determin\u00edsticos). Ao se enviar a mesma mensagem a partir de um certo estado, a computa\u00e7\u00e3o desencadeada \u00e9 sempre a mesma. Realista este modelo? H\u00e1 outros eventos n\u00e3o determin\u00edsticos no sistema? Nota\u00e7\u00e3o \\(Hdr(m)\\) Cabe\u00e7alho da mensagem \\(m\\) contendo fonte, destino, n\u00famero de sequ\u00eancia e n\u00famero de entrega. O cabe\u00e7alho cont\u00e9m a informa\u00e7\u00e3o necess\u00e1ria para reenviar e re-receber a mensagem na ordem certa (dados devem ser reproduzidos para aplica\u00e7\u00e3o). A mensagem \\(m\\) \u00e9 est\u00e1vel se \\(Hdr(m)\\) estiver em mem\u00f3ria est\u00e1vel. \\(Dep(m)\\) : o conjunto de processos a quem \\(m\\) ou mensagens que dependem de \\(m\\) foram entregues. \\(Copy(m)\\) : o conjunto de processos que tem uma c\u00f3pia de \\(Hdr(m)\\) em mem\u00f3ria vol\u00e1til. \u00d3rf\u00e3os Defini\u00e7\u00e3o Se \\(C\\) \u00e9 um conjunto de processos falhos, ent\u00e3o \\(Q\\not\\in C\\) \u00e9 um \u00f3rf\u00e3o se existe uma mensagem \\(m\\) tal que \\(Q \\in Dep(m)\\) e \\(Copy(m)\\subseteq C\\) Se os processos em \\(C\\) forem reiniciados, ent\u00e3o a computa\u00e7\u00e3o seguir\u00e1 um caminho possivelmente distinto do que levou \\(Q\\) a receber \\(m\\) ou um mensagem causalmente dependente de \\(m\\) . Protocolo Pessimista Para cada mensagem \\(m\\) n\u00e3o est\u00e1vel, h\u00e1 no m\u00e1ximo um processo dependente em \\(m\\) ( \\(Dep(m) \\leq 1\\) ) Uma mensagem n\u00e3o est\u00e1vel, no protocolo pessimista, deve ser estabilizada antes do envio da pr\u00f3xima mensagem. Toda mensagem \u00e9 precedida por uma escrita em disco. Para cada mensagem \\(m\\) n\u00e3o est\u00e1vel, ent\u00e3o devemos garantir que se \\(Copy(m) \\subseteq C\\) , ent\u00e3o eventually \\(Dep(m) \\subseteq C\\) , onde \\(C\\) \u00e9 o conjunto de processos que falharam. Para garantir que \\(Dep(m) \\subseteq C\\) , fazemos um rollback de cada \u00f3rf\u00e3o \\(Q\\) at\u00e9 que \\(Q \\not\\in Dep(m)\\) Isto \u00e9, for\u00e7amos \\(Q\\) a ser recuperado mesmo que n\u00e3o tenha falhado.","title":"Bancos de Dados"},{"location":"disdb/#bancos-de-dados-distribuidos","text":"","title":"Bancos de Dados Distribu\u00eddos"},{"location":"disdb/#bancos-de-dados","text":"Falar em bancos de dados distribu\u00eddos implica falar em bancos transacionais e P2P.","title":"Bancos de Dados"},{"location":"disdb/#operacoes-atomicas","text":"Falar em bancos de dados distribu\u00eddos implica falar em bancos Relacionais/Transactionais e P2P. Falar em bancos transacionais, implica falar ACID! Atomicidade -- Todas as opera\u00e7\u00f5es ou nenhuma. Consist\u00eancia -- Os dados transitam de estado v\u00e1lido para estado v\u00e1lido. Isolamento -- Transa\u00e7\u00f5es n\u00e3o interferem umas nas outras. Durabilidade -- Efeitos n\u00e3o s\u00e3o esquecidos. No modelo de M\u00e1quinas de Estados Replicadas, opera\u00e7\u00f5es s\u00e3o enviadas para as r\u00e9plicas, que as executam em ordem, deterministicamente e tamb\u00e9m atomicamente . Isto \u00e9, cada opera\u00e7\u00e3o \u00e9 ou executada independentemente das outras e por completo, ou n\u00e3o \u00e9 executada.","title":"Opera\u00e7\u00f5es At\u00f4micas"},{"location":"disdb/#conjuntos-de-operacoes","text":"Mesmo com Opera\u00e7\u00f5es At\u00f4micas, frequentemente queremos/precisamos agrupar opera\u00e7\u00f5es tal que todas ou nenhuma sejam executadas mesmo na presen\u00e7a de falhas. Atomicidade","title":"Conjuntos de Opera\u00e7\u00f5es"},{"location":"disdb/#memoria-estavel","text":"Para que os efeitos de opera\u00e7\u00f5es n\u00e3o sejam esquecidos, eles precisam ser armazenados em mem\u00f3ria est\u00e1vel como HD -- Hard Drives SSD -- Solid State Drives NVRAM -- Non Volatile RAM Durabilidade","title":"Mem\u00f3ria Est\u00e1vel"},{"location":"disdb/#o-banco","text":"Conta C 1 2 C.getSaldo() C.setSaldo(montante)","title":"O Banco"},{"location":"disdb/#transacao","text":"Mova 10% do saldo de B, de A para B. 1 2 3 4 5 T1: a -> b sB = b.getSaldo() b.setSaldo(sB*1.1) sA = a.getSaldo() a.setSaldo(sA-sB*0.1)","title":"Transa\u00e7\u00e3o"},{"location":"disdb/#transacao_1","text":"Qual o saldo total das contas? 1 2 3 4 T2: a + b sA = a.getSaldo() sB = b.getSaldo() sT = sA + sB","title":"Transa\u00e7\u00e3o"},{"location":"disdb/#execucao-concorrente","text":"Execu\u00e7\u00e3o concorrente de T1 e T2? 1 2 3 4 5 6 7 8 T1 T2 sB = b.getSaldo() sA = a.getSaldo() b.setSaldo(sB*1.1) . sB = b.getSaldo() sA = a.getSaldo() a.setSaldo(sA-sB*0.1) sT = sA+sB Dados n\u00e3o finais \"vazaram\". Dirty Read . Falta Isolamento . Pode levar a mais que um resultado errado. Pode deixar o BD em estado inv\u00e1lido.","title":"Execu\u00e7\u00e3o Concorrente"},{"location":"disdb/#execucao-concorrente_1","text":"Mova 10% do saldo de B, de A para B. 1 2 3 4 5 6 7 8 9 T1 T1 sB = b.getSaldo() sB = b.getSaldo() b.setSaldo(sB*1.1) b.setSaldo(sB*1.1) sA = a.getSaldo() a.setSaldo(sA-sB*0.1) sA = a.getSaldo() a.setSaldo(sA-sB*0.1) sB*0.1 foi perdido. Lost Update Perdeu Consist\u00eancia","title":"Execu\u00e7\u00e3o Concorrente"},{"location":"disdb/#solucao","text":"Para garantir Isolamento Execu\u00e7\u00f5es dos conjuntos n\u00e3o podem se sobrepor. Execute um conjunto de opera\u00e7\u00f5es por vez, serialmente! Garantir\u00e1 tamb\u00e9m Consist\u00eancia Que tal? Limite a concorr\u00eancia de transa\u00e7\u00f5es.","title":"Solu\u00e7\u00e3o?!"},{"location":"disdb/#equivalencia-serial","text":"","title":"Equival\u00eancia Serial"},{"location":"disdb/#concorrencia","text":"Al\u00e9m de ACID, queremos o m\u00e1ximo de concorr\u00eancia para garantir o melhor desempenho . Queremos uma execu\u00e7\u00e3o das transa\u00e7\u00f5es semelhante \u00e0 serial, mas com o desempenho de concorrente. N\u00e3o queremos uma execu\u00e7\u00e3o serial, mas uma Equival\u00eancia Serial , isto \u00e9, que os efeitos das transa\u00e7\u00f5es, executadas concorrentemente, sejam equivalentes aos de alguma execu\u00e7\u00e3o serial destas transa\u00e7\u00f5es.","title":"Concorr\u00eancia"},{"location":"disdb/#equivalencia-serial_1","text":"Preocupe-se com Opera\u00e7\u00f5es Conflitantes Transa\u00e7\u00f5es diferentes Uma \u00e9 escrita Mesmo dado Duas execu\u00e7\u00f5es (de transa\u00e7\u00f5es) s\u00e3o equivalentes se as transa\u00e7\u00f5es tem as mesmas opera\u00e7\u00f5es quaisquer duas opera\u00e7\u00f5es conflitantes s\u00e3o executadas na mesma ordem nas duas execu\u00e7\u00f5es Uma execu\u00e7\u00e3o tem Equival\u00eancia Serial se \u00e9 equivalente a alguma execu\u00e7\u00e3o serial das transa\u00e7\u00f5es. Escalone opera\u00e7\u00f5es concorrentemente, de forma a obter o melhor desempenho, mas de forma a manter Equival\u00eancia Serial. Esta defini\u00e7\u00e3o dif\u00edcil de ser testada. Algo mais simples? Como demonstrar Equival\u00eancia Serial? Tenho que testar todas as execu\u00e7\u00f5es seriais e ver se uma casa com o que planejo fazer? \u00c9 caro fazer este planejamento. \u00c9 mais eficiente garantir por constru\u00e7\u00e3o. Simplifica\u00e7\u00e3o: A execu\u00e7\u00e3o de duas transa\u00e7\u00f5es tem Equival\u00eancia Serial se todos os pares de opera\u00e7\u00f5es conflitantes entre as transa\u00e7\u00f5es s\u00e3o executados na mesma ordem.","title":"Equival\u00eancia Serial"},{"location":"disdb/#lost-update","text":"Mova 10% do saldo de X, de Y para X. 1 2 3 4 5 6 7 a -> b c -> b s = b.getSaldo() [1] [2]s = b.getSaldo() [3] b.setSaldo(s*1.1) b.setSaldo(s*1.1)[4] c.setSaldo(s*0.1) a.setSaldo(s*0.1) Conflitos: 1x3: \\(\\rightarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\) Consist\u00eancia -- s*0.1 foi perdido Mova 10% do saldo de X, de Y para X. 1 2 3 4 5 6 7 a -> b c -> b [2] s = b.getSaldo() [3] b.setSaldo(s*1.1) s = b.getSaldo() [1] b.setSaldo(s*1.1)[4] c.setSaldo(s*0.1) a.setSaldo(saldo*0.1) Conflitos: 1x3: \\(\\leftarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\)","title":"Lost Update"},{"location":"disdb/#dirty-read","text":"Saldo total? 1 2 3 4 5 6 7 8 9 a -> b a -> b s = b.getSaldo() b.setSaldo(s*1.1) b.setSaldo(s*1.1) a.saque(s*0.1) s = b.getSaldo() b.setSaldo(s*1.1) b.setSaldo(s*1.1) a.saque(s*0.1) Tem Equival\u00eancia Serial. Exceto se 1 abortTransaction() Nenhuma transa\u00e7\u00e3o que fez uma dirty read pode comitar. Logo, aborte a transa\u00e7\u00e3o da direita.","title":"Dirty Read"},{"location":"disdb/#aborto-em-cascata","text":"T1 faz uma escrita. T2 l\u00ea o que T1 escreveu e faz outra escrita. T3 l\u00ea o que T2 escreveu e faz outra escrita. T4 l\u00ea o que... T1 aborta .","title":"Aborto em Cascata"},{"location":"disdb/#dirty-read_1","text":"Como lidar? Suspenda a transa\u00e7\u00e3o quando esta fizer dirty read. Se transa\u00e7\u00e3o foi abortada, todas as suspensas (que leram dela) devem ser abortadas. Repita passo anterior. E se evitarmos dirty reads em vez de tratarmos? Suspenda antes de fazer dirty read. Quando transa\u00e7\u00e3o for terminada, continue execu\u00e7\u00e3o. Abordagem leva a menor concorr\u00eancia. Para nos permitir identificar transa\u00e7\u00f5es, vamos usar o seguinte framework para oper\u00e1-las.","title":"Dirty Read"},{"location":"disdb/#transacoes","text":"beginTransaction( ) opera\u00e7\u00f5es commitTransaction(): Ok/NOk abortTransaction()","title":"Transa\u00e7\u00f5es"},{"location":"disdb/#escrita-prematura","text":"1 2 3 4 5 6 Saldo inicial: 100 a.setSaldo(105) a.setSaldo(110) commitTransaction() abortTransaction() A transa\u00e7\u00e3o da direita n\u00e3o le, apenas escreve. O resultado? O saldo volta para 100.","title":"Escrita Prematura"},{"location":"disdb/#strict-execution","text":"Leituras e Escritas devem ser atrasadas at\u00e9 que todas as transa\u00e7\u00f5es anteriores que contenham escritas sejam commitadas ou abortadas. Execu\u00e7\u00e3o estrita garante Isolamento. Como implementar eficientemente?","title":"Strict Execution"},{"location":"disdb/#controle-de-concorrencia","text":"","title":"Controle de Concorr\u00eancia"},{"location":"disdb/#como","text":"locks (pessimista): simples, mas problem\u00e1tico multi-vers\u00e3o (otimista): custo se h\u00e1 muitos conflitos timestamp: time \u00e9 algo complicado","title":"Como"},{"location":"disdb/#locks","text":"Tranque todos os objetos para que outras transa\u00e7\u00f5es n\u00e3o consigam ler ou escrev\u00ea-los. Destranque quando n\u00e3o mais necess\u00e1rios. Sofre de dirty reads e escritas prematuras.","title":"Locks"},{"location":"disdb/#strict-two-phase-locking","text":"tranque quando necess\u00e1rio destranque ao final da transa\u00e7\u00e3o termine a transa\u00e7\u00e3o Como aumentar a concorr\u00eancia?","title":"Strict Two Phase Locking"},{"location":"disdb/#read-write-locks","text":"dois n\u00edveis de acesso m\u00faltiplos leitores \u00fanico escritor reads por ser transformados em locks writes n\u00e3o podem se transformados em reads (violaria Strict Two-Phase Locking)","title":"Read-Write Locks"},{"location":"disdb/#lock-por-que-evitar","text":"pessimista overhead mesmo se n\u00e3o h\u00e1 conflitos ou restritivo ou risco de deadlock lock liberado somente no final, para evitar dirty reads/escrita prematura.","title":"Lock -- por que evitar?"},{"location":"disdb/#abordagem-mais-otimista","text":"modifique uma c\u00f3pia privada dos dados na hora de terminar a transa\u00e7\u00e3o, verifique se nenhuma transa\u00e7\u00e3o modificou o dado, isto \u00e9, se a c\u00f3pia privada ainda \u00e9 v\u00e1lida substitua a c\u00f3pia p\u00fablica pela privada Esta t\u00e9cnica \u00e9 conhecida como deferred update , pois o update dos dados s\u00f3 ocorre no final, se a valida\u00e7\u00e3o passar.","title":"Abordagem mais otimista?"},{"location":"disdb/#abordagem-otimista","text":"baixo overhead, se n\u00e3o houver conflitos valida\u00e7\u00e3o \u00e9 r\u00e1pida update \u00e9 simples Se houver muitos conflitos, o trabalho da transa\u00e7\u00e3o \u00e9 todo desperdi\u00e7ado.","title":"Abordagem otimista"},{"location":"disdb/#validacao","text":"read e write sets de quaisquer transa\u00e7\u00f5es concorrentes deve ser disjuntos. t1 n\u00e3o deve ler dados escritos por t2 t2 n\u00e3o deve ler dados escritos por t1 t1/t2 n\u00e3o deve escrever dados escritos por t2/t1","title":"Valida\u00e7\u00e3o"},{"location":"disdb/#backward-validation","text":"t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o j\u00e1 comitada. t1 n\u00e3o deve ler dados escritos por t2 Em caso de n\u00e3o valida\u00e7\u00e3o, aborte t1","title":"Backward validation"},{"location":"disdb/#forward-validation","text":"t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o ainda em execu\u00e7\u00e3o t2 n\u00e3o deve ler dados escritos por t1 Em caso de n\u00e3o valida\u00e7\u00e3o, aborte t1, possivelmente nunca terminando uma transa\u00e7\u00e3o. ou aborte t2.","title":"Forward validation"},{"location":"disdb/#timestamping","text":"transa\u00e7\u00e3o recebe um timestamp no in\u00edcio opera\u00e7\u00f5es s\u00e3o validadas na execu\u00e7\u00e3o leia somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver escrito e comitado escreva somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver lido e comitado transa\u00e7\u00f5es \"executam na ordem do timestamp\" Como implementar?","title":"Timestamping"},{"location":"disdb/#como-implementar","text":"objetos tem valores tentativos , n\u00e3o comitados objetos tem vers\u00f5es em que foram escritos em que foram comitados e em que foram lidos consist\u00eancia \u00e9 testado na execu\u00e7\u00e3o da opera\u00e7\u00e3o","title":"Como implementar"},{"location":"disdb/#como-implementar-escrita","text":"escritas tem sucesso somente se vers\u00e3o sendo escrita \u00e9 maior que vers\u00f5es lidas se vers\u00e3o sendo escrita \u00e9 menor que vers\u00e3o j\u00e1 escrita, ignore e continue","title":"Como implementar -- escrita"},{"location":"disdb/#como-implementar-leitura","text":"leitura com vers\u00e3o v tem sucesso se maior vers\u00e3o \u00e9 comitada e menor que v ou alguma n\u00e3o comitada leitura com vers\u00e3o v \u00e9 suspensa se maior vers\u00e3o \u00e9 n\u00e3o comitada e menor que v leitura com vers\u00e3o v \u00e9 abortada se maior vers\u00e3o comitada \u00e9 maior que v","title":"como implementar -- leitura"},{"location":"disdb/#referencias","text":"Inspirado nas notas de aula de johan montelius e vladimir vlassov, da disciplina id2201 distributed systems, kth royal institute of technology. imagens copiadas descaradamente de seus slides. Tamb\u00e9m aqui, https://www.cs.ucy.ac.cy/~dzeina/courses/epl446/lectures/16.pdf","title":"Refer\u00eancias"},{"location":"disdb/#bancos-de-dados-distribuidos_1","text":"","title":"Bancos de dados distribu\u00eddos"},{"location":"disdb/#bancos-de-dados-transacionais-distribuidos","text":"Agora que relembramos como transa\u00e7\u00f5es funcionam e temos uma no\u00e7\u00e3o de como podem ser implementadas em um sistema centralizado, vamos tentar entender como faz\u00ea-lo em um sistema distribu\u00eddo. m\u00faltiplos servidores transa\u00e7\u00f5es em cada servidor transa\u00e7\u00f5es distribu\u00eddas como obter equival\u00eancia serial em transa\u00e7\u00f5es distribu\u00eddas","title":"bancos de dados transacionais distribu\u00eddos"},{"location":"disdb/#transacao-distribuida","text":"begintransaction(): tid (transaction id) operation(tid,op) endtransaction(tid): ok/nok aborttransaction(tid)","title":"Transa\u00e7\u00e3o distribu\u00edda"},{"location":"disdb/#papeis","text":"cliente servidor: resource managers servidor: transaction monitor/manager Localmente, cada bd funciona como um sistema centralizado normal, usando abordagens otimistas ou pessimista para garantir consist\u00eancia. O grande problema no bd distribu\u00eddo \u00e9 garantir o acordo na termina\u00e7\u00e3o.","title":"Pap\u00e9is"},{"location":"disdb/#comprometimento-distribuido","text":"","title":"Comprometimento distribu\u00eddo"},{"location":"disdb/#atomicidade","text":"O problema... transa\u00e7\u00e3o \\(t\\) acessa recursos nos resource managers (rm) terminar com sucessos \\(t\\) em todos os rm -- commit -- ou abortar \\(t\\) em todos os rm ainda que enlaces de comunica\u00e7\u00e3o, n\u00f3s e rm falhem, antes ou durante a termina\u00e7\u00e3o da transa\u00e7\u00e3o.","title":"atomicidade"},{"location":"disdb/#2pc-2-phase-commit","text":"participante -- resource manager \"tocados\" pela transa\u00e7\u00e3o coordenador -- transaction manager","title":"2PC - 2 Phase Commit"},{"location":"disdb/#premissas","text":"Cliente decide quando iniciar o commit. Cada participante faz commit ou abort da transa\u00e7\u00e3o local. pode retornar ok ou nok. Coordenador n\u00e3o come\u00e7a a commit at\u00e9 que a \\(t\\) tenha terminado em todos os participantes e cliente tenha solicitado. Participantes falham por parada.","title":"Premissas"},{"location":"disdb/#1pc","text":"cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes \"comitarem\" e se um participante retornar nok? % enquanto outros retornam ok? e se um participante n\u00e3o responder?","title":"1PC"},{"location":"disdb/#2pc","text":"cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes se prepararem para terminar coordenador espera que todos se preparem ou digam se n\u00e3o podem coordenador envia ordem de termina\u00e7\u00e3o","title":"2PC"},{"location":"disdb/#comprometimento","text":"um participante \\(p\\) est\u00e1 pronto para commit se tiver todos os valores modificados por \\(t\\) em mem\u00f3ria est\u00e1vel e nenhuma raz\u00e3o para abortar a transa\u00e7\u00e3o (outras transa\u00e7\u00f5es conflituosas fizeram commit?) o coordenador n\u00e3o pode come\u00e7ar a termina\u00e7\u00e3o at\u00e9 que todos os participantes estejam prontos. se algum participante aborta, o coordenador deve abortar. Problema de acordo, mas n\u00e3o igual ao consenso.","title":"Comprometimento"},{"location":"disdb/#2pc-o-protocolo","text":"fase 1 a: coordenador envia vote-request para participantes. b: participante responde com vote-commit ou vote-abort para o coordenador; se vote-abort, aborta localmente. fase 2 a: coordenador coleta votos de todos os processos; se forem todos vote-commit, envia global-commit para os participantes e ok para o cliente b: participantes esperam por global-commit ou global-abort Coordenador Participante","title":"2PC -- o protocolo"},{"location":"disdb/#falha-no-participante","text":"Participante falha no estado \\(S\\) e, ao se recuperar, identifica tal fato ao reprocessar o log de opera\u00e7\u00f5es em mem\u00f3ria dur\u00e1vel. Se est\u00e1 no estado INIT: nem sabia que a termina\u00e7\u00e3o come\u00e7ou. Aborta unilateralmente, pois ou j\u00e1 abortaram ou v\u00e3o abortar. ABORT: havia votado abort ou recebido global-abort -- continua protocolo. COMMIT: estava pronto para terminar a transa\u00e7\u00e3o com sucesso -- continua protocolo. READY: estava esperando por commit ou abort. Precisa saber se coordenador enviou global-commit ou global-abort -- consulta coordenador.","title":"Falha no Participante"},{"location":"disdb/#2pc_1","text":"Por que \u00e9 dif\u00edcil? E se \\(R_i\\) falhar depois de ter se preparado? E se \\(R_i\\) falhar mas \\(R_j\\) continuar funcionando? E se todos estiverem desligados quando \\(R_i\\) se recuperar? E se \\(R_i\\) estiver lento e parecer que a transa\u00e7\u00e3o falhou?","title":"2PC"},{"location":"disdb/#falha-no-participante_1","text":"READY: esperando por commit ou abort. Precisa saber se coordenador enviou global-commit our global-abort -- consulta coordenador. E se coordenador n\u00e3o estiver presente? Assumindo que participantes se conhecem, contate participante \\(Q\\) Se \\(Q\\) em COMMIT , vai para COMMIT Se \\(Q\\) em ABORT , vai para ABORT Se \\(Q\\) em INIT , ordena que Q aborte e, se confirmado, veja passo anterior Se \\(Q\\) em READY , consulta outro participante. Se todos os participantes em READY? Possivelmente o coordenador j\u00e1 respondeu ao cliente. Precisa esperar pelo coordenador.","title":"Falha no Participante"},{"location":"disdb/#falha-no-coordenador","text":"O problema principal \u00e9: e se ningu\u00e9m ouviu a decis\u00e3o final do coordenador? Neste caso, o protocolo n\u00e3o pode continuar, enquanto o coordenador n\u00e3o retornar, pois se os RM abortarem, podem estar contradizendo algo dito ao cliente, por exemplo, \"Sim, ATM, pode entregar o dinheiro\", ou executando um comando que o cliente v\u00ea como anulado, como \"Reenvie o pedido de mais 27 carros \u00e0 f\u00e1brica.\"","title":"Falha no Coordenador"},{"location":"disdb/#recuperacao-do-coordenador","text":"Ao se recuperar, o coordenador: sabe se come\u00e7ou a termina\u00e7\u00e3o de alguma transa\u00e7\u00e3o sabe se j\u00e1 enviou alguma resposta final para as transa\u00e7\u00f5es inacabadas sabe se j\u00e1 recebeu a confirma\u00e7\u00e3o de todos os participantes (se transa\u00e7\u00e3o n\u00e3o estiver em aberto) reenvia a \u00faltima mensagem das transa\u00e7\u00f5es em aberto.","title":"Recupera\u00e7\u00e3o do Coordenador"},{"location":"disdb/#otimizacoes","text":"Participantes \"somente-leitura\" N\u00e3o se importa com a decis\u00e3o; termina ap\u00f3s fase 1. Responde com vote-commit-ro Abort presumido Se ocorrer timeout, coordenador envia global-abort a todos e esquece transa\u00e7\u00e3o Se questionado, responde com global-abort. Transfer\u00eancia de coordena\u00e7\u00e3o se houver somente um participante... vote-request-transfer participante responde com global-commit/global-abort","title":"Otimiza\u00e7\u00f5es"},{"location":"disdb/#coleta-de-lixo","text":"Mesmo quando somente um participante falha... Ap\u00f3s receber decis\u00e3o, o participante pode concluir e esquecer a transa\u00e7\u00e3o. Mas e se o participante falho precisar se recuperar e todos os outros envolvidos tiverem esquecido a transa\u00e7\u00e3o? Coleta de lixo s\u00f3 pode ser feita quando todos tiverem confirmado a execu\u00e7\u00e3o da transa\u00e7\u00e3o e, por isso, Fase 2b \u00e9 necess\u00e1ria.","title":"Coleta de Lixo"},{"location":"disdb/#3-pc","text":"Estende o protocolo para permitir contornar falha do coordenador.","title":"3-PC"},{"location":"disdb/#o-protocolo","text":"Fase 1a -- Coordenador envia vote-request para participantes. Fase 1b -- Participante responde com vote-commit ou vote-abort para o coordenador; se vote-abort, aborta localmente. Fase 2a -- Coordenador coleta votos de todos os processos; se forem todos vote-commit, envia prepare-commit para os participantes; se n\u00e3o, global-abort e para. Fase 2b -- Participantes esperam por prepare-commit ou global-abort; se o primeiro, respondem com ready-commit ; se o segundo, param. Fase 3a -- coordenador espera por ready-commit de todos e ent\u00e3o envia global-commit. Fase 3b -- participantes esperam por global-commit. Coordenador Participante","title":"O Protocolo"},{"location":"disdb/#falha-no-participante_2","text":"\\(P\\) consegue saber o que fazer ap\u00f3s se recuperar da falha no estado READY ou PRE-COMMIT Participantes e coordenador n\u00e3o distam mais que um estado. Se algu\u00e9m em READY, o coordenador n\u00e3o mandou global-commit ainda; Aborte. Se todos em PRE-COMMIT, \u00e9 poss\u00edvel comitar, comite. A execu\u00e7\u00e3o dos passos anteriores tem que anular o poder do coordenador. Se todos os participantes em READY?","title":"Falha no Participante"},{"location":"disdb/#3pc-x-2pc","text":"3PC -- Aumenta disponibilidade 2PC -- Falha do coordenador \u00e9 \"corner case\" 3PC -- Aumenta o custo do \"caminho feliz\" e por isso n\u00e3o \u00e9 usado na pr\u00e1tica Nenhum escala e n\u00e3o us\u00e1-los \u00e9 uma das raz\u00f5es para o surgimento dos sistemas NoSQL","title":"3PC x 2PC"},{"location":"disdb/#paxos-commit","text":"Usa inst\u00e2ncias de Consenso Distribu\u00eddo para votar. Se o consenso \u00e9 tolerante a falhas e consistente, todos v\u00eaem o mesmo resultado na transa\u00e7\u00e3o.","title":"Paxos-Commit"},{"location":"disdb/#o-protocolo_1","text":"Para terminar a transa\u00e7\u00e3o \\(T\\) , o coordenador envia request-commit a todos os participantes. Um participante \\(P\\) prop\u00f5e seu voto na inst\u00e2ncia \\(T_P\\) de consenso. Todo participante \\(P\\) espera pelas decis\u00f5es das inst\u00e2ncias de consenso \\(T_i\\) para todos os participantes \\(i\\) , inclusive si mesmo; se todas as decis\u00f5es forem commit, o participante comita a transa\u00e7\u00e3o. Se cansar de esperar por \\(T_Q\\) , o participante prop\u00f5e abort em \\(T_Q\\) .","title":"O protocolo"},{"location":"disdb/#falha-no-participante_3","text":"Se o participante falha antes de votar, ent\u00e3o algu\u00e9m votar\u00e1 abort por ele. Se o participante \\(P\\) falha, ou \u00e9 suspeito de, ent\u00e3o \u00e9 poss\u00edvel que dois votos diferentes tenham sido propostos em \\(T_P\\) ; isso n\u00e3o \u00e9 um problema pois a decis\u00e3o \u00e9 a mesma para todos observando a inst\u00e2ncia. Ap\u00f3s se recuperar, o participante recupera as decis\u00f5es de todas as inst\u00e2ncias \\(T_i\\) e termina apropriadamente.","title":"Falha no Participante"},{"location":"disdb/#log-recuperavel","text":"Como garantir que o log poder\u00e1 ser lido para recuperar o processo?","title":"Log Recuper\u00e1vel"},{"location":"disdb/#disco-duplicado","text":"Dois discos iguais? Dados diferentes, mas ambos bons? Um bom outro estragado? Ambos estragados?","title":"Disco Duplicado"},{"location":"disdb/#estruturas-de-dados-para-sd","text":"Qualquer que seja a escolha de algoritmo para fazer o particionamento dos dados entre servidores, sobra ainda a quest\u00e3o de como manipular os dados dentro do servidor. Idealmente, toda opera\u00e7\u00e3o seria executada a partir da mem\u00f3ria principal, tendo assim a menor lat\u00eancia poss\u00edvel. Contudo, para que se tenha tamb\u00e9m durabilidade das opera\u00e7\u00f5es executadas, para que os dados manipulados sobrevivam a reinicializa\u00e7\u00f5es do servidor, intencionais ou n\u00e3o, \u00e9 preciso armazenar os dados em mem\u00f3ria est\u00e1vel , da qual a mais comum s\u00e3o os discos r\u00edgidos . \u00c9 not\u00f3rio que escritas em disco s\u00e3o muito mais lentas que em mem\u00f3ria principal, mas o que exatamente \u00e9 lento no acesso ao disco? Essencialmente, o posicionamento da cabeca de leitura/escrita na trilha correta do disco, pois esta opera\u00e7\u00e3o \u00e9 mec\u00e2nica. Por esta raz\u00e3o, acessos aleat\u00f3rios s\u00e3o mais custosos que acessos sequenciais, pois neste o custo de posicionamento \u00e9 pago apenas uma vez. Por este motivo, muitos bancos de dados, especialmente DHT pois tem seu uso focado em quantidades muito grandes de dados, gerados e acessados com grande velocidade, tentam acessar o disco sempre de forma sequencial. Alguns bancos de dados, como o Cassandra, armazenam os dados na forma de uma Log Structured Merge Tree , ou LSMT.","title":"Estruturas de Dados para SD"},{"location":"disdb/#log-structured-merge-tree","text":"Uma Log Structured Merge Tree \u00e9 uma forma de se armazenar dados em disco de forma de forma quase sempre sequencial, minimizando assim os o impacto da durabilidade no desempenho do sistema. Considere um banco armazenando uma pequena quantidade de dados, que cabe em mem\u00f3ria principal. Na LSMT, opera\u00e7\u00f5es de escrita s\u00e3o adicionadas a um commit log , em disco, e somente ent\u00e3o s\u00e3o executadas em mem\u00f3ria principal e confirmadas para o cliente; a estrutura que armazena os dados em mem\u00f3ria \u00e9 denominada memory table , ou simplesmente memtable . Neste cen\u00e1rio o acesso ao disco na escrita \u00e9 sequencial, o melhor que se pode ter em um disco, e a recupera\u00e7\u00e3o dos dados \u00e9 feita diretamente da mem\u00f3ria, r\u00e1pida. No caso de uma reinicializa\u00e7\u00e3o do processo, a reexecu\u00e7\u00e3o do commit log restaurar\u00e1 o estado da memtable. Contudo, se o commit log for extenso, reexecut\u00e1-lo demandar\u00e1 um tempo significativo. Uma forma de acelerar o processo \u00e9 fazer snapshots da memtable de forma sincronizada com a escrita no log. Isto \u00e9, digamos que todas as opera\u00e7\u00f5es de escrita, at\u00e9 a d\u00e9cima, est\u00e3o salvas no commit log e refletidas na memtable. Digamos tamb\u00e9m que todas as opera\u00e7\u00f5es s\u00e3o modifica\u00e7\u00f5es da mesma linha do banco de dados em mem\u00f3ria. Se um snapshot \u00e9 tomado, ele ser\u00e1 correspondente ao commit log, isto \u00e9, conter\u00e1 o efeito de exatamente as mesmas 10 opera\u00e7\u00f5es, mas de forma mais compacta que o log, uma vez que o log conter\u00e1 dez opera\u00e7\u00f5es e o snapshot somente uma linha de dados. Ap\u00f3s o snapshot ser conclu\u00eddo, o log correspondente pode ser apagado. Novas opera\u00e7\u00f5es de escrita devem ser armazenadas em um novo log e, no caso de uma reinicializa\u00e7\u00e3o, primeiro se deve restaurar o snapshot e ent\u00e3o o novo log. Para lidar com corrup\u00e7\u00f5es de arquivo no sistema, pode ser uma boa ideia manter mais do que o \u00faltimo log e snapshot , j\u00e1 que a recupera\u00e7\u00e3o do estado exigiria voltar mais atr\u00e1s na reexecu\u00e7\u00e3o de opera\u00e7\u00f5es. Observe que, al\u00e9m da escrita dos logs, todos os outros acessos ao disco tamb\u00e9m s\u00e3o sequenciais, seja o flush das memtables, ou a leitura dos snapshots para recupera\u00e7\u00e3o e do commit log para reexecu\u00e7\u00e3o, e j\u00e1 que opera\u00e7\u00f5es de leitura s\u00e3o todas respondidas da mem\u00f3ria, o sistema ter\u00e1 um excelente desempenho. Contudo, h\u00e1 outro limitante de desempenho importante, relacionado \u00e0 premissa pouco realista de que os dados cabem todos em mem\u00f3ria. Isto \u00e9, se os dados n\u00e3o cabem em mem\u00f3ria, snapshots ser\u00e3o importantes n\u00e3o somente para permitir coletar lixo dos logs, isto \u00e9, dados obsoletos, mas tamb\u00e9m, para usar a capacidade de armazenamento dos discos. Consideremos ent\u00e3o um cen\u00e1rio em que a memtable cabe apenas n entradas; quando a opera\u00e7\u00e3o para adicionar \\(n+1\\) -\u00e9sima entrada \u00e0 memtable \u00e9 recebida, um flushs dos dados para um novo snapshot \u00e9 feito e a memtable \u00e9 resetada , liberando espa\u00e7o em mem\u00f3ria. Para melhorar o desempenho, estas descargas podem ser feitas proativamente antes da chegada de novas entradas e fora do caminho cr\u00edtico da opera\u00e7\u00e3o de escrita, mas isto \u00e9 apenas uma otimiza\u00e7\u00e3o e portanto n\u00e3o a consideraremos aqui. Neste novo fluxo, os arquivos em disco n\u00e3o correspondem mais a snapshots do banco de dados, ent\u00e3o nos referiremos a eles como stable storage tables , ou sstables , em oposi\u00e7\u00e3o \u00e0s memtables , pelo menos por enquanto.","title":"Log Structured Merge Tree"},{"location":"disdb/#compactacoes","text":"Apesar deste novo fluxo de escrita aumentar a capacidade de armazenamento do nosso banco de dados, ele traz problemas para o fluxo de leitura. Digamos que a chave \\(k\\) teve um valor atribu\u00eddo e descarregado em uma sstable em diversas ocasi\u00f5es. O primeiro problema aqui \u00e9 que h\u00e1 v\u00e1rios valores antigos associados a \\(k\\) , inutilmente e ocupando espa\u00e7o, isto \u00e9, lixo. O segundo \u00e9 que caso o valor associado a \\(k\\) seja requisitado, o sistema dever\u00e1 retornar a \u00faltima vers\u00e3o, que pode estar em diversos arquivos. Para lidar com ambos os problemas, podemos compactar as sstables juntas, eliminados dados obsoletos e minimizando o n\u00famero de arquivos a serem pesquisados no caso de leitura. Caso a sstables estejam ordenadas, o procedimento de compacta\u00e7\u00e3o pode ser feito como a uni\u00e3o de dois segmentos de dados no merge sort , isto \u00e9, iterando-se paralelamente nos dois arquivos e escolhendo sempre a menor chave da vez e movendo-a para um novo segmento que conter\u00e1 a uni\u00e3o dos dados. A figura a seguir mostra um exemplo que v\u00e1rias sstables de n\u00edvel 0, aquelas geradas por flushs , s\u00e3o unidas gerando sstables de n\u00edvel 1 e assim sucessivamente. Observe como as compacta\u00e7\u00f5es geram uma \u00e1rvore (na verdade, uma floresta), raz\u00e3o do nome merge tree . No caso de uma pesquisa, somente as tabelas mais \u00e0 direita e de n\u00edvel mais alto precisam ser consultadas e portanto as sstables j\u00e1 usadas como entrada podem ser eliminadas como lixo do sistema. Ainda assim, no caso de uma leitura, diversas sstables potencialmente cont\u00e9m o dado a ser retornado. O problema se agrava em sistemas em que partes do dado possam ser gravadas independentemente, como no CassandraDB, em que cada coluna \u00e9 independente das outras. Diversas propostas poderiam ser feitas para se identificar mais rapidamente se uma sstable cont\u00e9m uma chave. Por exemplo, pode-se associar a cada tabela um bitmap indicando a presen\u00e7a ou n\u00e3o de uma certa chave, mas esta abordagem obviamente falha se o espa\u00e7o de chaves for grande. Outra possibilidade \u00e9 lembrar a faixa de chaves contida na tabela. Esta estrat\u00e9gia pode ser \u00fatil caso haja localidade no espa\u00e7o de chaves no momento da escrita, mas falhar\u00e1 miseravelmente se o espa\u00e7o de chaves for usado uniformemente, resultando em faixas grandes entre a menor e maior chaves de cada tabela. Como acelerar a identifica\u00e7\u00e3o das sstables pertinentes? Entram em cena os filtros de Bloom .","title":"Compacta\u00e7\u00f5es"},{"location":"disdb/#filtros-de-bloom","text":"De acordo com nossa fonte mais que confi\u00e1vel, a Wikipedia Bloom Filter A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not, thus a Bloom filter has a 100% recall rate. In other words, a query returns either \"possibly in set\" or \"definitely not in set\" . Se associarmos a cada sstable um filtro de Bloom, ent\u00e3o s\u00f3 ser\u00e1 preciso l\u00ea-la se o filtro correspondente disser que a chave possivelmente est\u00e1 contida, como no seguinte exemplo. Mas como exatamente constru\u00edmos um filtro de Bloom? Iniciamos com um vetor de bits inicialmente zerados e um conjunto finito de fun\u00e7\u00f5es de hash cujo resultado seja uniformemente distribu\u00eddo no tamanho do vetor de bits. Para cada elemento colocado no conjunto a ser refletido pelo filtro, aplicamos cada uma das fun\u00e7\u00f5es hash e colocamos o bit 1 na posi\u00e7\u00e3o do vetor igual ao resultado da fun\u00e7\u00e3o. No exemplo a seguir, inserimos os elementos x, y e z e usamos tr\u00eas fun\u00e7\u00f5es hash. Na consulta , cada elemento passa por pelas mesmas fun\u00e7\u00f5es hash. Se algum dos \u00edndices apontados n\u00e3o estiver com um 1, como no caso do c, no exemplo, o elemento n\u00e3o pertence ao conjunto. Caso contr\u00e1rio, o filtro responder\u00e1 que \u00e9 poss\u00edvel que perten\u00e7a. Mas qu\u00e3o bom \u00e9 um filtro de Bloom na identifica\u00e7\u00e3o do das sstables? Ou, de outra forma, quais fatores influenciam na taxa de falsos positivos do filtro? o n\u00famero \\(n\\) de elementos no conjunto, uma vez que quanto mais elementos, mais bits 1; o n\u00famero \\(k\\) de hashes, pois quanto mais hashes, mais bits transformados em 1; e, o n\u00famero \\(m\\) de bits no vetor, pois quanto menos bits, mais colis\u00f5es de bits. De forma mais precisa, a probabilidade de setar um certo bit na inser\u00e7\u00e3o de um elemento \u00e9 \\(1/m\\) , e a probabilidade de n\u00e3o setar tal bit \u00e9 \\(1 - 1/m\\) ; a probabilidade de \\(k\\) hashes n\u00e3o setarem um bit \u00e9 \\((1 - 1/m)^k\\) ; a probabilidade de n\u00e3o setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\((1 - 1/m)^{kn}\\) ; a probabilidade de setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\(1 - (1 - 1/m)^{kn}\\) Logo, a probabilidade de falso positivo \\(p = (1 - (1 - 1/m)^{kn})^k \\approx (1 - e^{-kn/m})^k\\) O que nos permite chegar \u00e0 rela\u00e7\u00e3o \\(m/n = - 1.44\\log_2 p\\) , em que podemos calcular \\(m\\) em fun\u00e7\u00e3o do \\(n\\) esperado e do \\(p\\) desejado. E podemos tamb\u00e9m identificar o \\(k\\) \u00f3timo para a situa\u00e7\u00e3o, pela equa\u00e7\u00e3o \\(k = - \\frac{\\ln p}{\\ln 2} = - \\log_2 p\\) Uma forma \"simples\" de visualizar este resultado \u00e9 dada pela figura a seguir, em que o eixo Y d\u00e1 a taxa de falsos positivos do filtro em fun\u00e7\u00e3o do n\u00famero de elementos inseridos, indicado no eixo X, para diversas configura\u00e7\u00f5es, apresentadas como curvas. Por exemplo, com um filtro com \\(m = 2^{24}b = 2MB\\) , ap\u00f3s 1 milh\u00e3o de inser\u00e7\u00f5es, tem-se probabilidade de falsos positivo \\(p = 0,0001\\) .","title":"Filtros de Bloom"},{"location":"disdb/#referencias_1","text":"Modern Algorithms and Data Structures: Bloom-Filter TODO Mover ED SD de Tecnologias para c\u00e1 Combinar https://adambcomer.com/blog/simple-database/motivation-design.html https://adambcomer.com/blog/simple-database/memtable.html https://adambcomer.com/blog/simple-database/wal.html https://www.jasondavies.com/bloomfilter/","title":"Refer\u00eancias"},{"location":"disdb/#modelos-de-consistencia","text":"","title":"Modelos de Consist\u00eancia"},{"location":"disdb/#motivacao","text":"","title":"Motiva\u00e7\u00e3o"},{"location":"disdb/#content-delivery-network","text":"Conte\u00fado \u00e9 colocado pr\u00f3ximo aos clientes. Conte\u00fado est\u00e1tico ou majoritariamente determin\u00edstico. Um pequeno atraso na replica\u00e7\u00e3o \u00e9 tolerado. Atualiza\u00e7\u00e3o acontece infrequentemente. Fonte: https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/","title":"Content Delivery Network"},{"location":"disdb/#raft","text":"Considere um sistema replicado usando RAFT. Ap\u00f3s cada opera\u00e7\u00e3o que modifica o estado, todas as r\u00e9plicas tem o mesmo valor. Fonte: http://thesecretlivesofdata.com/raft/ Caso um cliente queira apenas ler o estado, o que deve fazer? Requisitar o valor do l\u00edder: o valor lido ser\u00e1 o \u00faltimo valor escrito. Requisitar o valor de alguma r\u00e9plica: o valor lido ser\u00e1 um valor escrito, n\u00e3o necessariamente o \u00faltimo. Mais tempo implica maior a probabilidade de ser o valor escrito. Se em vez de difus\u00e3o at\u00f4mica us\u00e1ssemos IP-Multicast? Alguns valores escritos poderiam nunca ser vistos.","title":"RAFT"},{"location":"disdb/#replicacao-solucao-ou-problema","text":"Replica\u00e7\u00e3o aumenta disponibilidade mas tem custo em desempenho e, possivelmente, inconsist\u00eancias tempor\u00e1rias nos dados.","title":"Replica\u00e7\u00e3o: solu\u00e7\u00e3o ou problema?"},{"location":"disdb/#conflitos","text":"O problema da replica\u00e7\u00e3o est\u00e1 em como lidar com conflitos nas opera\u00e7\u00f5es dos clientes. Leitura-Leitura : N\u00e3o h\u00e1 conflitos. Qualquer quantidade de clientes. Replicar \"... \u00e9 f\u00e1cil, extremamente f\u00e1cil ...\" Leitura-Escrita : Clientes querem ler dados corretos e, geralmente, a \u00faltima vers\u00e3o escrita. Como atualizar rapidamente as r\u00e9plicas? Escrita-Escrita : Dados sendo atualizados em m\u00faltiplos lugares ao mesmo tempo. Necessidade de ordena\u00e7\u00e3o/compatibiliza\u00e7\u00e3o das escritas. Ordena\u00e7\u00e3o total das opera\u00e7\u00f5es pode ser custosa demais. Solu\u00e7\u00e3o? Enfraquecer os requisitos de consist\u00eancia dos sistema.","title":"Conflitos"},{"location":"disdb/#tipos-de-consistencia","text":"Diferentes formas de propaga\u00e7\u00e3o e recupera\u00e7\u00e3o resultam em diferentes garantias, diferentes modelos de consist\u00eancia . Consist\u00eancia forte: todas a r\u00e9plicas tem o mesmo valor dentro de um pequena janela de tempo. Alto custo. Consist\u00eancia eventual: r\u00e9plicas um dia ter\u00e3o o mesmo valor. Demora em sincronizar. Consist\u00eancia fraca: n\u00e3o h\u00e1 garantia da replica\u00e7\u00e3o. Yay!!! Diferentes modelos com nomes parecidos ou at\u00e9 iguais. \u00c9 preciso conhecer o que cada sistema est\u00e1 entregando para poder utiliz\u00e1-lo da forma correta.","title":"Tipos de consist\u00eancia"},{"location":"disdb/#definicao","text":"Contrato entre uma data-store (distribu\u00edda) em que se especifica os resultados de opera\u00e7\u00f5es de leitura e escrita na presen\u00e7a de concorr\u00eancia.","title":"Defini\u00e7\u00e3o"},{"location":"disdb/#modelos","text":"Modelos Centrados nos Dados vs. Modelos Centrados nos Clientes Em um, os dados s\u00e3o mantidos consistentes. No outro, inconsist\u00eancias n\u00e3o s\u00e3o vistas pelo cliente.","title":"Modelos"},{"location":"disdb/#modelo-centrado-nos-dados","text":"","title":"Modelo Centrado nos Dados"},{"location":"disdb/#data-store","text":"Modelo Computacional Consist\u00eancia Forte : opera\u00e7\u00f5es s\u00e3o sincronizadas Estrita (Strict): segue a linha do tempo. Sequencial: bancos de dados transacionais (quase). Causal: opera\u00e7\u00f5es com depend\u00eancia causal s\u00e3o ordenadas FIFO: ordem dos comandos de um mesmo cliente. Consist\u00eancia Fraca : sincroniza\u00e7\u00e3o acontece quando necess\u00e1rio. Consist\u00eancia fraca geral Consist\u00eancia de entrada Quanto mais fraco, mais escal\u00e1vel. Nota\u00e7\u00e3o A leitura de x em (a) retorna a A primeira leitura de x em (b) retorna Nil A segunda leitura de x em (b) retorna a","title":"Data store"},{"location":"disdb/#consistencia-estrita","text":"Qualquer leitura de um objeto \\(X\\) retorna o valor gravado em \\(X\\) pela opera\u00e7\u00e3o de escrita mais recente em \\(X\\) . O que quer dizer \"mais recente\" em um sistema distribu\u00eddo ass\u00edncrono? Todas as opera\u00e7\u00f5es de escrita s\u00e3o instantaneamente vis\u00edveis a todos os processos tempo global \u00e9 respeitado. Comportamento observado em um sistema sem conflitos ou centralizado Em qual(is) cen\u00e1rio(s) temos consist\u00eancia estrita?","title":"Consist\u00eancia Estrita"},{"location":"disdb/#consistencia-sequencial","text":"O resultado de qualquer execu\u00e7\u00e3o \u00e9 equivalente a alguma execu\u00e7\u00e3o sequencial dos processos, e as opera\u00e7\u00f5es da cada processo aparecem nesta execu\u00e7\u00e3o sequencial na ordem especificada por seu programa. P2, P3, P4, P1, P4, P3 P1 ou P2, qual veio primeiro?","title":"Consist\u00eancia Sequencial"},{"location":"disdb/#consistencia-causal","text":"Escritas com potencial rela\u00e7\u00e3o causal s\u00e3o vistas por todos os processos na mesma ordem. Escritas concorrentes (n\u00e3o causalmente relacionadas) podem se vistas em ordens diferentes por processos diferentes. W(x)b depende de R(x)a que depende de W(x)a W(x)c e W(x)b s\u00e3o concorrentes. W(x)b depende de R(x)a que depende de W(x)a. W(x)a deve ser ordenado com W(x)b. P3 n\u00e3o pode ter lido b e depois a.","title":"Consist\u00eancia Causal"},{"location":"disdb/#consistencia-fifo","text":"Escritas de um processo s\u00e3o vistas por todos os outros processos na ordem em que foram feitas. Escritas de diferentes processos podem ser vistas em ordens diferentes.","title":"Consist\u00eancia FIFO"},{"location":"disdb/#operacoes-simples","text":"Modelos desenvolvidos para processamento paralelo, especificando a ordem de execu\u00e7\u00e3o de opera\u00e7\u00f5es em m\u00faltiplos threads/processos.","title":"Opera\u00e7\u00f5es Simples"},{"location":"disdb/#grupos-de-operacoes","text":"Efeito de um grupo de opera\u00e7\u00f5es se torna vis\u00edvel a outros processos ao mesmo tempo. Efeitos de opera\u00e7\u00f5es individuais em um grupo n\u00e3o s\u00e3o vis\u00edveis. Vari\u00e1veis de sincroniza\u00e7\u00e3o Acesso \u00e0s vari\u00e1veis de sincroniza\u00e7\u00e3o da datastore \u00e9 sequencialmente consistente. Acesso \u00e0 vari\u00e1vel de sincroniza\u00e7\u00e3o n\u00e3o \u00e9 permitido at\u00e9 que todas as escritas das anteriores tenham sido executadas em todos os lugares. Acesso aos dados n\u00e3o \u00e9 permitido at\u00e9 que todas as vari\u00e1veis de sincroniza\u00e7\u00e3o tenham sido liberadas.","title":"Grupos de Opera\u00e7\u00f5es"},{"location":"disdb/#variaveis-de-sincronizacao","text":"Materializando vari\u00e1veis de sincroniza\u00e7\u00e3o na forma de locks","title":"Vari\u00e1veis de sincroniza\u00e7\u00e3o"},{"location":"disdb/#consistencia-de-entrada","text":"Lock de leitura s\u00f3 retorna quando todas as mudan\u00e7as guardadas por aquele lock tiverem sido executadas no processo. Lock de escrita s\u00f3 retorna quando nenhum outro processo tiver um lock, de leitura ou escrita. Para ler uma vari\u00e1vel, processo deve primeiro contactar o dono atual do lock cercando a vari\u00e1vel, para pegar as mais recentes atualiza\u00e7\u00f5es.","title":"Consist\u00eancia de Entrada"},{"location":"disdb/#transacoes_1","text":"Tornam o trancamento/destrancamento de vari\u00e1veis transparente.","title":"Transa\u00e7\u00f5es"},{"location":"disdb/#modelos-centrados-nos-clientes","text":"Ideia b\u00e1sica Evitar sincroniza\u00e7\u00e3o global focando-se no que os clientes v\u00eaem do sistema. Se para os clientes parecer consistente, tudo bem. Consist\u00eancia Eventual Se nenhuma escrita ocorrer em per\u00edodo consider\u00e1vel de tempo, os clientes gradualmente se sincronizar\u00e3o e ficar\u00e3o consistentes. Se clientes sempre acessarem as mesmas r\u00e9plicas, ter\u00e3o impress\u00e3o de consist\u00eancia. Garantias s\u00e3o do ponto de vista de um cliente. Leituras monot\u00f4nicas Escrita monot\u00f4nicas Leia suas escritas Escritas seguem leituras.","title":"Modelos Centrados nos Clientes"},{"location":"disdb/#modelo-de-sistema","text":"Cliente pode se mover antes de sua \u00faltima opera\u00e7\u00e3o ter replicado do servidor onde estava para o novo servidor.","title":"Modelo de Sistema"},{"location":"disdb/#leituras-monotonicas","text":"Garantia Se um processo l\u00ea o valor de um item \\(x\\) , qualquer leitura sucessiva de \\(x\\) retornar\u00e1 o mesmo valor ou um mais recente. Toda vez que se conecta a um servidor de email, seu cliente l\u00ea novas mensagens, caso haja. O cliente nunca esquece uma mensagem, mesmo que ainda n\u00e3o esteja no servidor conectado por \u00faltimo. WS( \\(x_i\\) ) -- opera\u00e7\u00f5es de escrita ( write set ) que levaram a vari\u00e1vel \\(x\\) a ter o valor \\(x_i\\) . WS( \\(x_i;x_j\\) ) -- opera\u00e7\u00f5es de escrita relativas a \\(x_j\\) incluem opera\u00e7\u00f5es de escrita relativas a \\(x_i\\)","title":"Leituras Monot\u00f4nicas"},{"location":"disdb/#escritas-monotonicas","text":"Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o esta opera\u00e7\u00e3o deve terminar antes que qualquer escrita sucessiva em \\(x\\) possa ser executada pelo mesmo processo. Em um sistema de arquivos na rede, a escrita do conte\u00fado de um arquivo, em certa posi\u00e7\u00e3o, s\u00f3 pode ser feita se escritas anteriores j\u00e1 est\u00e3o registradas no arquivo, independentemente de o cliente contactar novo servidor de arquivos.","title":"Escritas Monot\u00f4nicas"},{"location":"disdb/#leia-suas-escritas","text":"Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o leituras sucessivas no mesmo item pelo mesmo processo devem refletir tal escrita. Atualizar c\u00f3digo fonte de uma p\u00e1gina e exigir que o navegador carrega a nova vers\u00e3o.","title":"Leia suas Escritas"},{"location":"disdb/#escritas-seguem-leituras","text":"Garantia: Se um processo l\u00ea um item \\(x\\) , ent\u00e3o escritas sucessivas no mesmo item s\u00f3 podem ser completadas se o mesmo reflete o valor lido anteriormente. S\u00f3 \u00e9 permitido enviar uma resposta a uma mensagem se a mensagem em si \u00e9 vista, independentemente do cliente ter se movimentado.","title":"Escritas seguem Leituras"},{"location":"disdb/#mais-informacoes","text":"Aqui e aqui","title":"Mais informa\u00e7\u00f5es:"},{"location":"disdb/#posicionamento-de-replicas","text":"Onde colocar r\u00e9plicas para conseguir melhor escalabilidade do sistema? Menor custo de comunica\u00e7\u00e3o? Objetos (c\u00f3digo/dados) Permanente Sob demanda do servidor -- por exemplo em uma CDN Sob demanda do cliente -- por exemplo um cache.","title":"Posicionamento de R\u00e9plicas"},{"location":"disdb/#sob-demanda-do-servidor","text":"\\(Q\\) conta acessos ao arquivo \\(F\\) Agrega acessos por poss\u00edvel r\u00e9plica mais pr\u00f3xima ( \\(P\\) ) N\u00famero de acessos acima de limiar \\(R\\) , replica para \\(P\\) N\u00famero de acessos abaixo de \\(D\\) , apaga de \\(P\\) \\(D < R\\) Se n\u00e3o \u00e9 alto o suficiente para replicar nem baixo o suficiente para ignorar (entre \\(D\\) e \\(R\\) ), considera migrar.","title":"Sob demanda do Servidor"},{"location":"disdb/#propagacao-de-atualizacoes","text":"R\u00e9plicas precisam ser atualizadas. Propagar dados -- n\u00e3o reexecuta opera\u00e7\u00f5es. Propagar opera\u00e7\u00f5es -- n\u00e3o copia todos os dados modificados. Propagar notifica\u00e7\u00f5es -- r\u00e9plica precisa solicitar atualiza\u00e7\u00e3o. Usado em caches. Melhor op\u00e7\u00e3o depende do custo das opera\u00e7\u00f5es, dados manipulados, e taxa de leitura/escrita dos dados.","title":"Propaga\u00e7\u00e3o de Atualiza\u00e7\u00f5es"},{"location":"disdb/#propagacao-de-atualizacoes_1","text":"R\u00e9plicas precisam ser atualizadas. Propagar dados raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o caras Propagar opera\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o baratas Propagar notifica\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 pequena pouco uso da rede","title":"Propaga\u00e7\u00e3o de Atualiza\u00e7\u00f5es"},{"location":"disdb/#proativopush-ou-reativopull","text":"Proativo Mant\u00e9m r\u00e9plicas consistentes Desnecess\u00e1rio se leitura \\(<<\\) escrita. Reativo R\u00e9plicas s\u00f3 se tornam consistentes quando necess\u00e1rio. Lento se leitura \\(>>\\) escrita Qual \u00e9 melhor?","title":"Proativo/Push ou Reativo/Pull"},{"location":"disdb/#hibrido-lease","text":"R\u00e9plica se registra para receber atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es por um per\u00edodo. Estado sobre r\u00e9plicas \u00e9 mantido enquanto poss\u00edvel, pelo per\u00edodo contratado. Em caso de sobrecarga, deixa de mandar atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es. Em caso de lease antigo n\u00e3o renovado, deixa de mandar atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es. Em caso de renova\u00e7\u00f5es frequentes, aumenta o per\u00edodo do lease.","title":"H\u00edbrido: Lease"},{"location":"disdb/#recuperacao-checkpoint","text":"","title":"Recupera\u00e7\u00e3o &amp; Checkpoint"},{"location":"disdb/#recuperacao","text":"Suponha que uma s\u00e9rie de erros aconteceram no sistema, e que n\u00e3o \u00e9 poss\u00edvel continuar o processamento como o sistema est\u00e1. Neste cen\u00e1rio, \u00e9 necess\u00e1rio ou avan\u00e7ar para um novo estado, livre de erros, ou retroceder a um estado correto anterior. Voltar a um estado correto parece ser a solu\u00e7\u00e3o mais f\u00e1cil. Para isso, precisamos de Pontos de Recupera\u00e7\u00e3o","title":"Recupera\u00e7\u00e3o"},{"location":"disdb/#snapshots","text":"Podem ser usados na: Recupera\u00e7\u00e3o do sistema. Coleta de lixo (remover objetos n\u00e3o referenciados em nenhum outro processo). Detec\u00e7\u00e3o de deadlocks. Depura\u00e7\u00e3o (pausar o sistema).","title":"Snapshots"},{"location":"disdb/#pontos-de-recuperacao","text":"Ponto de Recupera\u00e7\u00e3o v\u00e1lidos s\u00e3o a uni\u00e3o de backups locais que formam um Estado Global Consistente .","title":"Pontos de Recupera\u00e7\u00e3o"},{"location":"disdb/#estado-global-consistente","text":"O qu\u00ea? Conjunto com um estado local de cada processo no sistema tal que toda mensagem recebida no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do processo remetente. Linha de recupera\u00e7\u00e3o O mais recente Estado Global Consistente Comunica\u00e7\u00e3o Confi\u00e1vel Se o sistema prov\u00ea comunica\u00e7\u00e3o confi\u00e1vel, ent\u00e3o toda mensagem enviada no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do destinat\u00e1rio.","title":"Estado Global Consistente"},{"location":"disdb/#rollback-em-cascata","text":"Bad timing Se estados locais s\u00e3o capturados na \"hora errada\", a linha de recupera\u00e7\u00e3o pode ser o estado inicial.","title":"Rollback em Cascata"},{"location":"disdb/#armazenamento-em-disco","text":"Segue a t\u00e9cnica j\u00e1 estudada.","title":"Armazenamento em Disco"},{"location":"disdb/#checkpoint","text":"","title":"Checkpoint"},{"location":"disdb/#checkpointing-independente","text":"Cada processo faz o checkpoint local independentemente, incorrendo no risco de um rollback em cascata. Seja \\(C_i^m\\) o \\(m\\) -\u00e9simo checkpoint do processo \\(p_i\\) . Seja \\(I_i^m\\) o intervalo entre \\(C_i^{m-1}\\) e \\(C_i^m\\) . Quando o processo \\(p_i\\) envia a mensagem no intervalo \\(I_i^m\\) , envia \\((i,m)\\) em piggyback Quando o processo \\(p_j\\) recebe a mensagem no intervalo \\(I_j^n\\) , grava a depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) A depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) \u00e9 salva junto com o checkpoint \\(C_j^n\\)","title":"Checkpointing independente"},{"location":"disdb/#restricao","text":"Se o processo \\(p_j\\) \u00e9 revertido para o estado \\(C_j^n\\) , ent\u00e3o o \\(p_i\\) n\u00e3o pode reverter para nenhum estado anterior a \\(C_i^m\\) , ou n\u00e3o teria enviado as mensagens recebidas por \\(p_j\\) 4 inclusas em \\(C_j^n\\) . ou Se o processo \\(p_i\\) \u00e9 revertido para o estado \\(C_i^{m-1}\\) , ent\u00e3o o \\(p_j\\) tem que ser revertido pelo menos at\u00e9 \\(C_j^{n-1}\\) , ou incluiria mensagens ainda n\u00e3o enviadas por \\(p_i\\) . Como implementar a recupera\u00e7\u00e3o?","title":"Restri\u00e7\u00e3o"},{"location":"disdb/#caso-patologico","text":"\\(p_i\\) e \\(p_j\\) no estado inicial ( \\(C_i^0, C_j^0\\) ) \\(p_i\\) manda mensagens para \\(p_j\\) ( \\(C_i^1 \\rightarrow C_j^1\\) ) \\(C_j^1\\) \\(p_j\\) manda mensagens para \\(p_i\\) \\(C_j^2 \\rightarrow C_i^1\\) \\(C_i^1\\) \\(p_i\\) manda mensagens para \\(p_j\\) \\(C_i^2 \\rightarrow C_j^2\\) \\(C_j^2\\) \\(p_j\\) manda mensagens para \\(p_i\\) \\(C_j^3 \\rightarrow C_i^2\\) \\(C_i^2\\) ...","title":"Caso patol\u00f3gico"},{"location":"disdb/#checkpointing-coordenado","text":"Processos se coordenam por troca de mensagem para executar checkpointing \"simultaneamente\". Qual a vantagem sobre o n\u00e3o coordenado?","title":"Checkpointing coordenado"},{"location":"disdb/#bloqueio-em-duas-fases","text":"Um coordenador faz multicast da mensagem \"checkpoint-request\" Quando um participante recebe \"checkpoint-request\" faz um checkpoint local para de mandar mensagens da aplica\u00e7\u00e3o responde com \"checkpoint-taken\" Quando \"checkpoint-taken\" recebido de todos os participantes, multicast \"checkpoint-done\" Quando receber \"checkpoint-done\", retoma computa\u00e7\u00e3o normal Por qu\u00ea funciona? Impede forma\u00e7\u00e3o de depend\u00eancias circulares. Todos os processos precisam participar? Somente os que dependem da recupera\u00e7\u00e3o do coordenador. Pontos negativos? Duas fases? J\u00e1 vi isso antes... Se o coordenador falha, outros processos ficam bloqueados? Timeout! Como eleger outro coordenador? E se dois aparecerem juntos? Pode ser resolvido com um protocolo de elei\u00e7\u00e3o como o do RAFT. N\u00e3o \u00e9 garantido, mas aumenta as chances de sucesso.","title":"Bloqueio em duas fases"},{"location":"disdb/#chandy-lamport","text":"N\u00e3o interfere na aplica\u00e7\u00e3o Cada processo grava snapshot independentemente Observador (iniciador do snapshot) Salva o pr\u00f3prio estado Envia uma mensagem \"snapshot\" aos outros processos em cada canal de sa\u00edda Grava as mensagens chegando em cada canal at\u00e9 que receba uma mensagem \"snapshot\" naquele canal. Um processo \\(p\\) que receba \"snapshot\" de um processo \\(q\\) grava estado local \\(S_p\\) grava estado do canal \\(C_{q,p} =\\emptyset\\) Envia uma mensagem \"snapshot\" aos outros processos em cada canal de sa\u00edda Grava as mensagens chegando em cada canal at\u00e9 que receba uma mensagem \"snapshot\" naquele canal (excluindo \\(C_{q,p}\\) ) Protocolo termina para o processo \\(p\\) quando tiver recebido marcador \"snapshot\" em cada um de seus canais. O estado global consiste dos snapshots + estado em cada um dos canais. Exige canais FIFO","title":"Chandy-Lamport"},{"location":"disdb/#message-logging","text":"Em vez de checkpoints frequentes, crie um log da comunica\u00e7\u00e3o e o re-execute a partir do \u00faltimo checkpoint. Ideia b\u00e1sica: A computa\u00e7\u00e3o \u00e9 determinada pela troca de mensagens (eventos n\u00e3o determin\u00edsticos). Ao se enviar a mesma mensagem a partir de um certo estado, a computa\u00e7\u00e3o desencadeada \u00e9 sempre a mesma. Realista este modelo? H\u00e1 outros eventos n\u00e3o determin\u00edsticos no sistema?","title":"Message Logging"},{"location":"disdb/#notacao","text":"\\(Hdr(m)\\) Cabe\u00e7alho da mensagem \\(m\\) contendo fonte, destino, n\u00famero de sequ\u00eancia e n\u00famero de entrega. O cabe\u00e7alho cont\u00e9m a informa\u00e7\u00e3o necess\u00e1ria para reenviar e re-receber a mensagem na ordem certa (dados devem ser reproduzidos para aplica\u00e7\u00e3o). A mensagem \\(m\\) \u00e9 est\u00e1vel se \\(Hdr(m)\\) estiver em mem\u00f3ria est\u00e1vel. \\(Dep(m)\\) : o conjunto de processos a quem \\(m\\) ou mensagens que dependem de \\(m\\) foram entregues. \\(Copy(m)\\) : o conjunto de processos que tem uma c\u00f3pia de \\(Hdr(m)\\) em mem\u00f3ria vol\u00e1til.","title":"Nota\u00e7\u00e3o"},{"location":"disdb/#orfaos","text":"Defini\u00e7\u00e3o Se \\(C\\) \u00e9 um conjunto de processos falhos, ent\u00e3o \\(Q\\not\\in C\\) \u00e9 um \u00f3rf\u00e3o se existe uma mensagem \\(m\\) tal que \\(Q \\in Dep(m)\\) e \\(Copy(m)\\subseteq C\\) Se os processos em \\(C\\) forem reiniciados, ent\u00e3o a computa\u00e7\u00e3o seguir\u00e1 um caminho possivelmente distinto do que levou \\(Q\\) a receber \\(m\\) ou um mensagem causalmente dependente de \\(m\\) .","title":"\u00d3rf\u00e3os"},{"location":"disdb/#protocolo-pessimista","text":"Para cada mensagem \\(m\\) n\u00e3o est\u00e1vel, h\u00e1 no m\u00e1ximo um processo dependente em \\(m\\) ( \\(Dep(m) \\leq 1\\) ) Uma mensagem n\u00e3o est\u00e1vel, no protocolo pessimista, deve ser estabilizada antes do envio da pr\u00f3xima mensagem. Toda mensagem \u00e9 precedida por uma escrita em disco. Para cada mensagem \\(m\\) n\u00e3o est\u00e1vel, ent\u00e3o devemos garantir que se \\(Copy(m) \\subseteq C\\) , ent\u00e3o eventually \\(Dep(m) \\subseteq C\\) , onde \\(C\\) \u00e9 o conjunto de processos que falharam. Para garantir que \\(Dep(m) \\subseteq C\\) , fazemos um rollback de cada \u00f3rf\u00e3o \\(Q\\) at\u00e9 que \\(Q \\not\\in Dep(m)\\) Isto \u00e9, for\u00e7amos \\(Q\\) a ser recuperado mesmo que n\u00e3o tenha falhado.","title":"Protocolo Pessimista"},{"location":"disfs/","text":"Sistemas de Arquivos Distribu\u00eddos Em constru\u00e7\u00e3o. Leitura Conceitos b\u00e1sicos Google File System Google file system","title":"Sistemas de Arquivos"},{"location":"disfs/#sistemas-de-arquivos-distribuidos","text":"Em constru\u00e7\u00e3o.","title":"Sistemas de Arquivos Distribu\u00eddos"},{"location":"disfs/#leitura","text":"Conceitos b\u00e1sicos","title":"Leitura"},{"location":"disfs/#google-file-system","text":"Google file system","title":"Google File System"},{"location":"fault/","text":"Toler\u00e2ncia a Falhas Dependabilidade N\u00f3s escrevemos software para que resolvam problemas de espectro bem amplo, indo, do controle de bra\u00e7os rob\u00f3ticos em cirurgias remotas \u00e0 sistemas de com\u00e9rcio eletr\u00f4nico, do controle de usinas hidroel\u00e9tricas \u00e0 jogos de truco online. Independentemente do problema sendo resolvido, gostar\u00edamos de poder contar com o sistema, de poder depender nele para executar sua tarefa. Desta situa\u00e7\u00e3o, surge a ideia de dependabilidade, isto \u00e9, de um sistema ter a propriedade de se poder depender do mesmo. Dizemos que um componente \\(C\\) depende de um componente \\(C'\\) se a corretude do comportamento de \\(C\\) depende da corretude do componente \\(C'\\) . E que um componente \u00e9 \"depend\u00e1vel\" ( dependable ) na medida em que outros podem depender dele. A dependabilidade \u00e9 essencial aos componentes de sistemas distribu\u00eddos, afinal, \"uma corrente \u00e9 t\u00e3o forte quanto seu elo mais fraco.\" De acordo com Avizienis et al , tem-se dependabilidade quando os seguintes atributos est\u00e3o presentes. Disponibilidade ( Availability ) - Prontid\u00e3o para uso. Confiabilidade/Fiabilidade ( Reliability ) - Continuidade do servi\u00e7o. Seguran\u00e7a ( Safety ) - Toler\u00e2ncia a cat\u00e1strofes. Integridade ( Integrity ) - Toler\u00e2ncia a modifica\u00e7\u00f5es. Manutenabilidade ( Maintainability ) - Facilidade de reparo. Outra propriedade importante neste contexto \u00e9 a Confidencialidade ( Confidentiality ), a garantia de que a informa\u00e7\u00e3o somente \u00e9 acess\u00edvel a quem \u00e9 devido. A combina\u00e7\u00e3o de Disponibilidade , Integridade e Confidencialidade \u00e9 tamb\u00e9m chamada de Seguran\u00e7a ( Security ). Mas o que significa, na pr\u00e1tica, ser depend\u00e1vel e seguro ( secure )? Para respondermos a esta quest\u00e3o, primeiro precisamos entender os tipos de problemas que aparecem em v\u00e1rios n\u00edveis, desde o seu desenvolvimento at\u00e9 seu uso. Falhas, Erros e Defeitos No n\u00edvel mais b\u00e1sico dos problemas a serem contornados para se obter dependabilidade, temos as falhas ( defect , fault , para alguns, falta), que \u00e9 um erro no desenvolvimento do sistema, como bugs ou defeitos de fabrica\u00e7\u00e3o, que o leva a ficar diferente do que foi especificado. Uma falha existe mesmo se for raramente ativada e mesmo se seus efeitos nunca forem percebidos. Por exemplo, se o c\u00f3digo tem um <= em vez de < na especifica\u00e7\u00e3o de uma itera\u00e7\u00e3o, mas se uma condi\u00e7\u00e3o faz com que a itera\u00e7\u00e3o seja interrompida antes, o c\u00f3digo ainda tem uma falha. No segundo n\u00edvel, temos o erro ( error ), que \u00e9 a manifesta\u00e7\u00e3o da falha levando a algum comportamento indevido. No exemplo acima, um erro seria quando a itera\u00e7\u00e3o passasse do ponto correto por causa do <= , por exemplo, na hora de escrever uma string em um array, estourando o limite do array na pilha mas sobrescrevendo uma vari\u00e1vel que n\u00e3o seja mais usada. O erro pode passar despercebido, mas ainda assim \u00e9 um erro. Finalmente, no terceiro n\u00edvel, temos os defeitos ( failure , para alguns, falha), um erro percebido pelo usu\u00e1rio. Continuando o exemplo, um stack overflow que leva a uma falha de segmenta\u00e7\u00e3o, leva a um defeito. Quando um componente manifesta um defeito, outros componentes que dele dependem, internalizar\u00e3o entradas indevidas, uma falha externa, o que levar\u00e1 a seu pr\u00f3prio estado interno a estar err\u00f4neo e possivelmente tamb\u00e9m manifestar um defeito. Esta cadeia pode levar cen\u00e1rios catastr\u00f3ficos. Falhas Famosas Ariane 5 O Ariane 5 foi um foguete desenvolvido pela agencia espacial europ\u00e9ia que explodiu durante o lan\u00e7amento. The Explosion of the Ariane 5 On June 4, 1996 an unmanned Ariane 5 rocket launched by the European Space Agency exploded just forty seconds after its lift-off [...] after a decade of development costing $7B. The destroyed rocket and its cargo were valued at $500M. [...] the failure was a software error [...] a 64 bit floating point number [...] was converted to a 16 bit signed integer. The number was larger than 32,767, the largest integer storeable in a 16 bit signed integer, and thus the conversion failed. O erro gerado foi tratado como input, causando outros erros, que geraram instabilidade e que levou o sistema a se auto-destruir. 787 Dreamliner O avi\u00e3o 787 dreamliner, da Boeing, tem um problema que tornar necess\u00e1rio reiniciar o sistema el\u00e9trico a cada 248 dias, ou o mesmo pode ter uma pane. Quote The plane\u2019s electrical generators fall into a failsafe mode if kept continuously powered on for 248 days. The 787 has four such main generator-control units that, if powered on at the same time, could fail simultaneously and cause a complete electrical shutdown. Segundo as \"m\u00e1s l\u00ednguas\", o problema \u00e9 que acontece um overflow em um contador de tempo Quote 248 days == 2^31 100ths of a second. even in 2015, our airplanes have integer overflow bugs https://t.co/6Z8d4y9gjM \u2014 Fiora @ \u65e5\u672c\u8a9e\u3067FF14 (@FioraAeterna) May 1, 2015 737 Max Neste outro caso envolvendo a Boeing, um sensor \u00e9 usado para detectar se o avi\u00e3o estava subindo r\u00e1pido demais e correndo o risco de perder sustenta\u00e7\u00e3o, um comportamento que se verificou comum no 737 Max por causa dos grandes motores usados nele e que o diferenciam do 737 original. Se o risco \u00e9 detectado, um sistema automatizado for\u00e7a o nariz do avi\u00e3o para baixo para corrigir o problema. Contudo, no 737 Max apenas um sensor \u00e9 usado e no caso de falha do mesmo, o avi\u00e3o \u00e9 for\u00e7ado para baixo e em dire\u00e7\u00e3o ao solo, o que levou \u00e0 morte de centenas de pessoas. 1 Subaru SUV Em 2018 a Subaru fez um recall gigante, de mais de 1 milh\u00e3o de unidades de um seus modelos de SUV, porqu\u00ea uma falha em um software fez com que soldagens fossem feitas incorretamente no chassis dos ve\u00edculos. O erro era irrepar\u00e1vel, levando a grandes preju\u00edzos. Root cause analysis Quando defeitos aparecem, \u00e9 importante identificar suas causas, isto \u00e9, a cadeia de eventos que o levou a acontecer. Algumas empresas publicam a root cause analysis ou a an\u00e1lise post-mortem para a comunidade como forma de compartilhar conhecimento e tamb\u00e9m por quest\u00f5es de transpar\u00eancia. Veja esta compila\u00e7\u00e3o para uma extensa lista de an\u00e1lises. Como alcan\u00e7ar dependabilidade Falhas s\u00e3o um fato da vida, uma constante no desenvolvimento de sistemas. Mas se o objetivo \u00e9 a dependabilidade, precisamos de formas de lidar com falhas, previnindo , removendo e tolerando -as. A preven\u00e7\u00e3o de falhas acontece por meio de t\u00e9cnicas bem estabelecidas de engenharia. No caso de sistemas de software, modulariza\u00e7\u00e3o, linguagens de programa\u00e7\u00e3o fortemente tipadas e encapsulamento s\u00e3o passos essencias. Uso de especifica\u00e7\u00f5es formais, testadas ou provadas corretas, s\u00e3o outro passo neste sentido. Por exemplo, diversas empresas usam a linguagem TLA \\(^+\\) para verificar a corretude de seus algoritmos 2 . Outras t\u00e9cnicas envolvidas na preven\u00e7\u00e3o de falhas s\u00e3o an\u00e1lise est\u00e1tica, prova de teoremas, execu\u00e7\u00e3o simb\u00f3lica, teste de modelos, etc. Mesmo uma especifica\u00e7\u00e3o correta pode produzir um sistema com falhas pois a tradu\u00e7\u00e3o de especifica\u00e7\u00f5es formais para c\u00f3digo \u00e9 um passo complexo. Testes e manuten\u00e7\u00e3o do sistema permitem a remo\u00e7\u00e3o de falhas que passarem despercebidas pelas tentativas de preven\u00e7\u00e3o. Testes, contudo, apenas aumentam a confian\u00e7a no sistema, n\u00e3o sendo capazes de certificar a aus\u00eancia de problemas. Assim, tenta-se desenvolver os sistemas de forma que, mesmo se falhas ainda estiverem presentes, seus efeitos n\u00e3o sejam percebidos como defeitos, isto \u00e9, sistemas que tenha toler\u00e2ncia a falhas (ou preven\u00e7\u00e3o de defeitos ). Para se alcan\u00e7ar toler\u00e2ncia a falhas \u00e9 necess\u00e1rio detectar e se recuperar de erros. Por exemplo, um sistema de arquivos com journal , como o Ext v3 , armazena informa\u00e7\u00e3o redundantemente e, quando detecta que os dados em sua forma principal est\u00e3o corrompidos, usa o journal para recuperar os dados, mascarando o erro. De acordo como Avizienis et al, temos as seguintes t\u00e9cnicas para tolerar falhas: Um sistema que sofra de falhas recorrentes \u00e9 um bom candidato a previs\u00e3o de falhas, em que se estima quando uma falha ocorrer\u00e1 baseado no hist\u00f3rico. Por exemplo, um sistema que sofra falha por uso excessivo de mem\u00f3ria a cada dez dias em uso, pode ser reiniciado no nono dia, em condi\u00e7\u00f5es controladas, para evitar problemas maiores enquanto a raz\u00e3o do uso excessivo de mem\u00f3ria \u00e9 corrigido. Classes de Defeitos Para previnirmos e toleramos com falhas, precisamos entender como se manifestam e, para isso, uma classifica\u00e7\u00e3o \u00e9 essencial. Quebra Falhas de quebra ( crash ) s\u00e3o falhas em que o componente para de funcionar, irreversivelmente. Uma vez que o componente cessa seu funcionamento, qualquer comunica\u00e7\u00e3o com o mesmo \u00e9 interrompida e pode dar bons indicativos da falha aos outros componentes. Em um sistema ass\u00edncrono, contudo, n\u00e3o h\u00e1 garantias de que esta detec\u00e7\u00e3o do defeito ser\u00e1 correta. Alguns sistemas, denominados fail-stop , for\u00e7am-se a parar de funcionar quando percebem um defeito, imitando uma quebra, e implementando um comportamento fail-fast . 3 Estes sistemas podem emitir um \"canto do cisne\" para permitir que outros componentes detectem o defeito. Ap\u00f3s pararem, alguns sistemas podem aplicar passos de recupera\u00e7\u00e3o e voltar a funcionar, no que \u00e9 denominado fail-recover . Ao retornar \u00e0 opera\u00e7\u00e3o, o processo poderia assumir uma nova identidade. Omiss\u00e3o Em um defeito de omiss\u00e3o ( omission failure ), um componente n\u00e3o executa alguma a\u00e7\u00e3o. Por exemplo, uma requisi\u00e7\u00e3o recebida por um servidor n\u00e3o \u00e9 executada, um disco n\u00e3o armazena os dados no meio magn\u00e9tico, ou uma mensagem n\u00e3o \u00e9 transmitida. Este tipo de defeito \u00e9 dif\u00edcil de ser identificado pois outros componentes n\u00e3o necessariamente tem acesso direto ao resultado da opera\u00e7\u00e3o. Por exemplo, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem, ent\u00e3o houve um defeito de omiss\u00e3o. Mas se a mensagem \u00e9 retransmitida at\u00e9 que tenha sua entrega confirmada, ent\u00e3o o defeito \u00e9 mascarado. Temporiza\u00e7\u00e3o Em sistemas em que h\u00e1 limites de tempo para a execu\u00e7\u00e3o de a\u00e7\u00f5es, uma viola\u00e7\u00e3o destes limites \u00e9 defeito de temporiza\u00e7\u00e3o . Por exemplo, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem, ent\u00e3o houve uma falha de omiss\u00e3o. Novamente considerando problemas de transmiss\u00e3o de mensagens, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem que deveria ser entregue dentro de 3ms, ent\u00e3o houve um defeito de omiss\u00e3o. Mas se a mensagem \u00e9 retransmitida at\u00e9 que tenha sua entrega confirmada, mas a mesma \u00e9 entregue com 5ms, ent\u00e3o o mesmo que ap\u00f3s o limite para ent\u00e3o o defeito \u00e9 mascarado como um defeito de temporiza\u00e7\u00e3o. Arbitr\u00e1rios Um defeito arbitr\u00e1rio ou bizantino \u00e9 um no qual qualquer comportamento pode acontecer. Por exemplo, uma mensagem pode ser modificada, um servidor pode reiniciar-se constantemente, todos os dados podem ser apagados, ou acesso pode ser dado a quem n\u00e3o \u00e9 devido. Estes defeitos podem ser causados por agentes mal intencionados, como hackers e v\u00edrus. Hierarquia Fail-stop \\(\\subset\\) Quebra \\(\\subset\\) Omiss\u00e3o \\(\\subset\\) Temporiza\u00e7\u00e3o \\(\\subset\\) Arbitr\u00e1ria Falhas intermitentes Algumas falhas fogem \u00e0 classifica\u00e7\u00e3o acima por terem um comportamento especial, se manifestando de forma intermitente, por causa de eventos esparsos como picos de energia, ou pelo comportamento emergente da intera\u00e7\u00e3o com outros sistemas. Heisenbug The name may seem to rhyme well with Heisenberg, but the Heisenbug is actually \"a bug that disappears or alters its behavior when one attempts to probe or isolate it.\" The Freenet Project describes a Heisenbug in certain Java virtual machines. Bohrbug The Bohrbug is a sort of antonym of the Heisenbug, as this bug does not disappear or alter its characteristics when it is researched. Mandelbug The Mandelbug, named after Benoit Mandelbrot (think Mandelbrot set), is a bug whose underlying causes are so complex and obscure as to make its behavior appear chaotic. Schroedinbug The Schroedinbug is a design or implementation bug in a program that doesn't manifest until someone reading source or using the program in an unusual way notices that it never should have worked, at which point the program promptly stops working for everybody until fixed. Here, an Office developer describes \"stupid SQL tricks\" to get rid of a \"classic Schroedinbug.\" Correla\u00e7\u00e3o entre falhas Algumas falhas s\u00e3o ativadas por entradas e, neste caso, mesmo que se tenha v\u00e1rias c\u00f3pias do mesmo sistema, todas falhar\u00e3o uma vez que a entrada problem\u00e1tica acontecer. Este \u00e9 um cen\u00e1rio em que as falhas n\u00e3o s\u00e3o independentes, mas correlatas. Para evit\u00e1-lo, podemos usar n-version programming , que consiste basicamente em ter m\u00faltiplas implement\u00e7\u00f5es do mesmo sistema desenvolvidas de forma independente, isto \u00e9, fazendo uso de um ou mais da seguintes op\u00e7\u00f5es: m\u00faltiplos times m\u00faltiplos sistemas operacionais m\u00faltiplas linguagens de programa\u00e7\u00e3o. Esta t\u00e9cnica \u00e9 interessante mais raramente usada, basicamente pelo seu alto custo. Al\u00e9m disso, erros de especifica\u00e7\u00e3o s\u00e3o reproduzidos e levam times diferentes a produzir erros iguais. Redund\u00e2ncia de Processos Se remover todas as possbilidades de defeitos de um componente \u00e9 algo dif\u00edcil, apostemos na toler\u00e2ncia a falhas. De forma geral, toler\u00e2ncia a falhas \u00e9 obtida por algum tipo de redund\u00e2ncia . Redund\u00e2ncia pode ser aplicada em v\u00e1rios n\u00edveis, por exemplo, gastando mais tempo na especifica\u00e7\u00e3o do projeto , ou montando um laborat\u00f3rio de testes mais pr\u00f3ximo do ambiente de produ\u00e7\u00e3o. Outra forma \u00f3bvia de redund\u00e2ncia \u00e9 a replica\u00e7\u00e3o de componentes. Por exemplo, pense no pneu estepe de um carro, no gerador de eletricidade de um hospital. Replica\u00e7\u00e3o permite remover os pontos \u00fanicos de falha (SPOF, Single Point of Failure ), ou seja, componentes n\u00e3o depend\u00e1veis. Seja como for, redund\u00e2ncia implica em mais custos, ent\u00e3o o grau de redund\u00e2ncia a ser utilizado depende de uma an\u00e1lise custo x benef\u00edcio. No caso de um sistema distribu\u00eddo, quando falamos em redund\u00e2ncia, normalmente falamos em processos redundantes, c\u00f3pias ou r\u00e9plicas, mesmo que n\u00e3o desevolvidos usando n-version programming Assim, com m\u00faltiplas c\u00f3pias, quando um processo apresenta um defeito, outro podem continuar executando o servi\u00e7o. Dois modos cl\u00e1ssicos de replica\u00e7\u00e3o s\u00e3o o prim\u00e1rio/c\u00f3pia e ativo . No caso da replica\u00e7\u00e3o prim\u00e1rio/c\u00f3pia , tamb\u00e9m conhecida como mestre/escravo , o prim\u00e1rio \u00e9 respons\u00e1vel por lidar com clientes e por informar c\u00f3pias das modifica\u00e7\u00f5es de estado. Como as atualiza\u00e7\u00f5es de estado fluem do prim\u00e1rio para a c\u00f3pia, \u00e9 poss\u00edvel que a c\u00f3pia n\u00e3o tenha o estado mais atual. Para visualizarmos melhor esta situa\u00e7\u00e3o, vejamos a replica\u00e7\u00e3o em cadeia , uma generaliza\u00e7\u00e3o de prim\u00e1rio/c\u00f3pia em que os processos se organizam em um sequ\u00eancia para executar opera\u00e7\u00f5es. Atualiza\u00e7\u00f5es no sistema s\u00e3o sempre direcionadas ao prim\u00e1rio , a cabe\u00e7a da sequ\u00eancia. Leituras , se absolutamente necessitarem dos dados escritos mais recentemente, tamb\u00e9m devem ser direcionadas \u00e0 cabe\u00e7a . Caso contr\u00e1rio, podem ser direcionadas aos processos na cauda , diminuindo a carga de trabalho na cabe\u00e7a. No caso da replica\u00e7\u00e3o ativa, as v\u00e1rias c\u00f3pias executam todos os comandos enviados para o sistema, estando assim todas aptas a continuar a executar o servi\u00e7o. A t\u00e9cnica de replica\u00e7\u00e3o de m\u00e1quinas de estados vista no cap\u00edtulo anterior \u00e9 uma materializa\u00e7\u00e3o da replica\u00e7\u00e3o ativa. Como vimos anteriormente, replica\u00e7\u00e3o de m\u00e1quinas de estados utiliza primitivas de comunica\u00e7\u00e3o em grupo, mas as vistas anteriormente n\u00e3o s\u00e3o funcionais principalmente por n\u00e3o serem tolerantes a falhas. Vejamos a porqu\u00ea \u00e9 dif\u00edcil desenvolver primitivas tolerantes a falhas. Problemas de Acordo H\u00e1 diversas primitivas de comunica\u00e7\u00e3o em grupo, das quais se destaca a difus\u00e3o at\u00f4mica , primitiva pela qual se pode facilmente implementar replica\u00e7\u00e3o de m\u00e1quina de estados. Difus\u00e3o at\u00f4mica, por sua vez, \u00e9 equivalente ao problema do consenso distribu\u00eddo , que est\u00e1 no cora\u00e7\u00e3o da classe de problemas de acordo . Problemas de acordo s\u00e3o aqueles em que processos devem concordar em quais a\u00e7\u00f5es executar. Dependendo do modelo computacional em que o problema deve ser resolvido, solu\u00e7\u00f5es v\u00e3o de triviais a imposs\u00edveis. Vejamos um exemplo. Uma hist\u00f3ria de tr\u00eas ex\u00e9rcitos Era uma vez uma cidade estado no alto de uma montanha. A despeito de sofrer de falta de \u00e1gua, afinal, estava no alto de uma montanha, a cidade era invejada pelos vizinhos. Como a cidade era muito bem fortificada, ela poderia se defender de qualquer ataque em uma \u00fanica frente . Se atacada em duas frentes , contudo, cairia. Sabendo disso, o rei de uma das cidades vizinhas resolveu tomar a cidade e repartiu suas for\u00e7as em dois ex\u00e9rcitos sob o comando de Alice (a sociedade \u00e9 muito feminista naquela \u00e9poca) e Basti\u00e3o (sim, Basti\u00e3o, n\u00e3o Bob). 4 Um complicador no ataque \u00e9 que a comunica\u00e7\u00e3o entre os dois ex\u00e9rcitos \u00e9 feita por mensageiros que devem contornar a montanha para alcan\u00e7ar o outro ex\u00e9rcito. O trajeto \u00e9 complexo e cheio de armadilhas e por isso mensageiros podem se perder e demorar um longo tempo para chegar ou at\u00e9 mesmo serem mortos e nunca entregarem suas mensagens. Alice, a comandante mais s\u00eanior, deve decidir quando atacar, pode exemplo simplesmente ordenando \" Atacar no dia 3, ao nascer do sol. \" Basti\u00e3o obedecer\u00e1 a ordem de atacar contanto que esteja certo de que Alice tamb\u00e9m atacar\u00e1, e \u00e9 justamente da\u00ed que vem a dificuldade do problema. Se mensagens podem ser perdidas, Alice n\u00e3o tem garantias de que Basti\u00e3o recebeu o comando e por isso n\u00e3o pode simplesmente considerar como certo o ataque de Basti\u00e3o. Como o problema pode ser resolvido? Uma resposta natural \u00e9 usar mensagens de confirma\u00e7\u00e3o . Isto \u00e9, quando Basti\u00e3o recebe uma ordem, envia um mensageiro de volta para Alice com uma confirma\u00e7\u00e3o da recep\u00e7\u00e3o. Alice ao receber tal mensagem, sabe que Basti\u00e3o executar\u00e1 a ordem, correto? Mas n\u00e3o \u00e9 t\u00e3o simples assim no caso da ordem de atacar. Lembre-se que qualquer ex\u00e9rcito que ataque sozinho, perder\u00e1, seja Alice ou Basti\u00e3o. Por isso, ao enviar uma mensagem de confirma\u00e7\u00e3o do ataque, Basti\u00e3o precisa estar certo de que Alice a recebeu, ou atacar\u00e1 sozinho. Novamente podemos apelar para uma mensagem de confirma\u00e7\u00e3o ou, neste caso, uma confirma\u00e7\u00e3o da confirma\u00e7\u00e3o. E o problema se reinicia... Paradoxo dos 2 Ex\u00e9rcitos \\(A\\) e \\(B\\) devem concordar na hora do ataque. \\(A\\) ataca se estiver certo que \\(B\\) atacar\u00e1. \\(B\\) ataca se estiver certo que \\(A\\) atacar\u00e1. A comunica\u00e7\u00e3o por troca de mensagens. Mensagens podem ser arbitrariamente atrasadas. Mensagens podem ser perdidas. Como um ex\u00e9rcito tem certeza que o outro ir\u00e1 atacar? Suponhamos que h\u00e1 um algoritmo correto que executa uma sequ\u00eancia finita de troca de mensagens em que ao final tanto Alice quanto Basti\u00e3o est\u00e3o seguros, e corretos em sua seguran\u00e7a, de que o outro tamb\u00e9m atacar\u00e1. Seja \\(n\\) o n\u00famero m\u00e1ximo de mensagens trocadas. Em uma execu\u00e7\u00e3o em que todas as \\(n\\) mensagens poss\u00edveis s\u00e3o usadas, suponha sem perda de generalidade que Alice enviou a \\(n\\) -\u00e9sima mensagem. Observe que, do ponto de vista de Alice, uma execu\u00e7\u00e3o do algoritmo em que a nenhuma mensagem \u00e9 perdida, \u00e9 indistingu\u00edvel de uma execu\u00e7\u00e3o em que a \\(n\\) -\u00e9sima mensagem \u00e9 perdida. Dado que ao final da primeira execu\u00e7\u00e3o completa Alice ataca , no final da execu\u00e7\u00e3o onde a mensagem \\(n\\) \u00e9 perdida, Alice tamb\u00e9m deve atacar. Mas se o algoritmo \u00e9 correto, ent\u00e3o tamb\u00e9m Basti\u00e3o ataca , mesmo sem ter recebido a en\u00e9sima mensagem. Logo, a en\u00e9sima mensagem \u00e9 desnecess\u00e1ria ao algoritmo, que deve funcionar com \\(n-1\\) mensagens. Repetindo-se o argumento mais \\(n-1\\) vezes, temos que o algoritmo deve funcionar com zero mensagens, o que \u00e9 um absurdo . Logo n\u00e3o existem algoritmos corretos para o problema como definido, isto \u00e9, em que mensagens podem ser perdidas; \u00e9 imposs\u00edvel resolver o problema. Apesar de ser imposs\u00edvel resolver este problema aparentemente simples, devemos faz\u00ea-lo frequentemente no mundo real. Como reconciliar estes dois fatos? Impossibilidade Quando dizemos que \u00e9 imposs\u00edvel resolver um problema queremos dizer que \u00e9 imposs\u00edvel produzir um algoritmo que sempre levar\u00e1 a uma resposta correta . Isto quer dizer que podemos produzir algoritmos, mas ou eles \u00e0s vezes levar\u00e3o a respostas incorretas ou eles \u00e0s vezes n\u00e3o levar\u00e3o a respostas ; ambos podem ser \u00fateis na pr\u00e1tica. Por exemplo, ainda no problema dos ex\u00e9rcitos tentando tomar a cidade, suponha que em vez de mandar um \u00fanico mensageiro com a ordem de ataque, Alice envie 100, ou 200, ou 1000. A confian\u00e7a de Alice de que Basti\u00e3o tamb\u00e9m atcaria, seria muito maior e n\u00e3o precisaria receber uma confirma\u00e7\u00e3o de entrega de mensagens. Esta abordagem faria com com que o ataque funcionasse com uma certa probabilidade , mas com uma pequena probabilidade \\(P\\) de levar a um ataque fracassado, onde \\(P\\) pode ser feita t\u00e3o pequena quanto se \"queira\" . Resultados de impossibilidade abundam na \u00e1rea de computa\u00e7\u00e3o distribu\u00edda 5 e n\u00e3o podem nos desencorajar de continuar a buscar solu\u00e7\u00f5es pr\u00e1ticas. Consenso O problema que os comandantes est\u00e3o tentando resolver \u00e9, essencialmente, o problema do Consenso Distribu\u00eddo. Neste problema, cada um de um conjunto de processos prop\u00f5e um \u00fanico valor, sua proposta . O objetivo \u00e9 decidir um dentre os valores propostos, garantindo as seguintes propriedades. Validade: Somente um valor proposto pode ser decidido. Acordo: Se um processo decide-se por \\(v\\) e outro por \\(w\\) , ent\u00e3o \\(v = w\\) Termina\u00e7\u00e3o: Todo processo n\u00e3o defeituoso decide-se. Um processo \u00e9 defeituoso se apresentou um defeito; como estamos considerando apenas defeitos do tipo quebra, um processo \u00e9 defeituso se ele parou de funcionar. Um processo que n\u00e3o \u00e9 defeituoso \u00e9 um processo correto. \u00c9 imposs\u00edvel resolver deterministicamente o problema do consenso em sistema ass\u00edncrono sujeito a falhas 6 . Mas o consenso \u00e9 resolvido frequentemente em sistemas ass\u00edncronos sujeitos a falhas. Isso porque normalmente estes sistemas se comportam sincronamente. H\u00e1 diversos algoritmos de consenso que terminam quando o sistema se comporta bem, sendo os mais famosos, atualmente, Raft e Paxos A grande raz\u00e3o para que seja imposs\u00edvel chegar a um acordo entre processos neste modelo \u00e9 a impossibilidade de diferenciar processos defeituosos de processos corretos mas lentos. Em termos do paradoxo dos 2 generais, a resposta do comandante n\u00e3o chegou porqu\u00ea ele morreu ou porqu\u00ea ele est\u00e1 demorando para responder? Os detectores de defeito abstraem este problema. Detectores de Defeitos de Defeito n\u00e3o Confi\u00e1veis Chandra e Toueg 7 introduziram o conceito de Detectores de Defeitos . Um detector de defeitos pode ser visto como or\u00e1culo distribu\u00eddo , com m\u00f3dulos acoplados aos processos do sistema e que trabalha determinando o estado funcional dos outros processos. Todo figura igual \u00e0 da disserta\u00e7\u00e3o. Chandra e Toueg classificaram os detectores de defeitos segundo suas caracter\u00edsticas de completude ( completeness ) e acur\u00e1cia ( accuracy ), ou seja, a capacidade de suspeitar de um processo defeituoso e a capacidade de n\u00e3o suspeitar de um processo correto, respectivamente. Alguns n\u00edveis destas propriedades s\u00e3o descritos a seguir: Completude Forte - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por todos os processos corretos. Completude Fraca - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por algum processo correto. Precis\u00e3o Forte - Todos os processos s\u00e3o suspeitos somente ap\u00f3s terem apresentado defeito. Precis\u00e3o Fraca - Algum processo correto nunca \u00e9 suspeito de ter apresentado defeito. Precis\u00e3o Eventual Forte - A partir de algum instante futuro, todos os processos s\u00e3o suspeitos somente ap\u00f3s apresentarem defeito. Precis\u00e3o Eventual Fraca - A partir de algum instante futuro, algum processo ativo nunca \u00e9 suspeito antes de ter apresentado defeito. Um detector ideal seria um com Completude Forte e Precis\u00e3o Forte, pois detectaria somente processos defeituosos e todos os processos defeituosos. Este detector \u00e9 conhecido como \\(P\\) ou Perfect . Infelizmente os detectores perfeitos s\u00f3 podem ser implementados em sistemas s\u00edncronos, onde se pode confiar que a falta de uma mensagem implica em que a mensagem n\u00e3o ser\u00e1 entregue por qu\u00ea o remetente deve ser defeituosos. Assim, \u00e9 preciso se focar em detectores n\u00e3o perfeitos ou n\u00e3o confi\u00e1veis . Em ambientes parcialmente s\u00edncronos , ou seja, ass\u00edncronos aumentados com algum tipo de sincronia, j\u00e1 poss\u00edvel implementar detectores n\u00e3o confi\u00e1veis. Por exemplo, se os processos disp\u00f5em de temporizadores precisos, um detector pode contar a passagem do tempo nos intervalos de comunica\u00e7\u00e3o com outros processos e, considerando um limite de tempo para estes intervalos, tentar determinar se tais processos encontram-se defeituosos ou n\u00e3o. Esta determina\u00e7\u00e3o \u00e9 por certo imprecisa, e os detectores podem voltar atr\u00e1s em suas suspeitas t\u00e3o logo percebam um erro. Entretanto, a despeito desta incerteza, a informa\u00e7\u00e3o provida por estes detectores j\u00e1 pode ser suficiente para que se alcance o consenso, salvo uma restri\u00e7\u00e3o de que a maioria dos processos n\u00e3o sofra defeitos. Maioria Adicionar prova. Chandra, Hadzilacos e Toueg demonstram que detector mais fraco com o qual se pode resolver consenso tem as propriedades de Completude Fraca e Acur\u00e1cia Eventual Fraca. 8 Este detector, conhecido como \\(\\Diamond W\\) , ou Eventual Weak , e \u00e9 implement\u00e1vel em sistemas nos quais h\u00e1 um limite superior de tempo para a transmiss\u00e3o de mensagens, mesmo que este limite seja desconhecido . V\u00e1rios protocolos de consenso utilizam o detector equivalente, \\(\\Diamond S\\) , equivalente ao \\(\\Diamond W\\) mas com completude forte. Estes protocolos s\u00e3o escritos de forma que se o limite superior n\u00e3o existe, o protocolo n\u00e3o termina e um resultado errado nunca \u00e9 alcan\u00e7ado . Difus\u00e3o Totalmente Ordenada Se pudermos resolver o consenso, podemos ent\u00e3o resolver o problema da difus\u00e3o at\u00f4mica e com ela implementar a replica\u00e7\u00e3o de m\u00e1quinas de estados. Relembrando, na difus\u00e3o Totalmente Ordenada (Total Order Multicast) temos que: Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem. Para fazermos isso, precisamos primeiro formalizar as primitivas em v\u00e1rios n\u00edveis da resolu\u00e7\u00e3o do problema. No n\u00edvel do canal de comunica\u00e7\u00e3o, da rede, processos enviam e recebem mensagens. No n\u00edvel do consenso, processos fazem propostas e aprendem um valor decidido. Para chegar a uma \u00fanica decis\u00e3o, v\u00e1rias mensagens podem ser enviadas e recebidas. No n\u00edvel da difus\u00e3o at\u00f4mica, mensagens s\u00e3o difundidas e entregues . Se implementado sobre o consenso, para uma difus\u00e3o ser bem sucedida, uma inst\u00e2ncia de consenso \u00e9 necess\u00e1ria. Primitivas de comunica\u00e7\u00e3o enviar & receber ( send & receive ) - rede propor & decidir ( propose & decide ) - consenso difundir & entregar ( broadcast & deliver ) - difus\u00e3o Dado infinitas inst\u00e2ncias de consenso, pode-se us\u00e1-las para resolver difus\u00e3o at\u00f4mica usando o seguinte procedimento: Ordene as inst\u00e2ncias de consenso. Para difundir mensagem \\(m\\) , proponha a mensagem na menor inst\u00e2ncia \\(i\\) em que n\u00e3o tiver visto uma decis\u00e3o. Se a decis\u00e3o de \\(i\\) n\u00e3o \u00e9 \\(m\\) , volte para o passo anterior. Entregue as decis\u00f5es na ordem das inst\u00e2ncias. No exemplo a seguir, duas mensagens, \\(m\\) e \\(m'\\) foram difundidas pelas aplica\u00e7\u00f5es App1 e App2, respectivamente, por meio do m\u00f3dulo de difus\u00e3o at\u00f4mica junto a cada aplica\u00e7\u00e3o. O m\u00f3dulo de difus\u00e3o determina qual a menor inst\u00e2ncia de consenso ainda n\u00e3o decidida, azul, em que prop\u00f5em as mensagens. Ao final da inst\u00e2ncia de conseno, \\(m\\) \u00e9 decidida e \u00e9 entregue pelos m\u00f3dulos de difus\u00e3o. O m\u00f3dulo ABCast2 insiste na difus\u00e3o de \\(m'\\) , propondo-a na pr\u00f3xima inst\u00e2ncia, vermelha, que decide \\(m'\\) e leva esta mensagem a ser entregue. sequenceDiagram participant App1 participant ABCast1 participant Cons1 participant Cons3 participant Cons2 participant ABCast2 participant App2 App1 -->>+ ABCast1: difundir m App2 -->>+ ABCast2: difundir m' rect rgb(100,255,255) ABCast1 ->>+ Cons1: propor m na inst 1 ABCast2 ->>+ Cons2: propor m' na inst 1 Cons1 ->>- ABCast1: decidir m Cons2 ->>- ABCast2: decidir m end ABCast1 -->>- App1: entregar m ABCast2 -->> App2: entregar m rect rgba(255,0,0,.5) ABCast2 ->>+ Cons2: propor m' na inst 2 Cons1 ->> ABCast1: decidir m' Cons2 ->>- ABCast2: decidir m' end ABCast1 -->> App1: entregar m' ABCast2 -->>- App2: entregar m' Ambas as aplica\u00e7\u00f5es, embora tivessem inten\u00e7\u00f5es diferentes sobre qual deveria ser a pr\u00f3xima mensagem entregue, entregam-nas na mesma ordem, isto \u00e9, primeiro \\(m\\) e depois \\(m'\\) . Se forem usadas como entrada para algum processamento, na ordem em que foram entregues, as aplica\u00e7\u00f5es chegar\u00e3o ao mesmo estado, em algum momento. Estudo de Caso do Raft Raft \u00e9 um protocolo de difus\u00e3o at\u00f4mica associado a um protocolo de elei\u00e7\u00e3o de l\u00edderes. L\u00edderes s\u00e3o eleitos para mandatos pelo voto de uma maioria de processos, o que garante que nunca existir\u00e3o dois l\u00edderes para um mesmo mandato. Um mandato se estende enquanto o l\u00edder mantiver seus seguidores cientes de sua presen\u00e7a, o que faz pelo envio peri\u00f3dico de heartbeats . Atrasos na comunica\u00e7\u00e3o ou a falha do l\u00edder atual levam a uma suspeita de que o l\u00edder falhou, levando a nova elei\u00e7\u00e3o e novo mandado. A comunica\u00e7\u00e3o necess\u00e1ria para implementar a difus\u00e3o at\u00f4mica acontece em piggyback nos heartbeats . No tutorial The Secret lives of data , podemos ver com mais detalhes como o protocolo funciona. O tutorial, entretando, foge da nomenclatura padr\u00e3o da \u00e1rea usando log-replication no lugar de difus\u00e3o at\u00f4mica (ou totalmente ordenada). Estudo de Caso: Paxos Paxos S\u00ednodo (Synod): consenso Paxos: Difus\u00e3o At\u00f4mica Outras Ordena\u00e7\u00f5es Como colocado diversas vezes, se todos os processos executam a mesma sequ\u00eancia de comandos determin\u00edsticos, todos avan\u00e7am pelos mesmos estados, implementando a t\u00e9cnica da replica\u00e7\u00e3o de m\u00e1quinas de estados. Se usada em um sistema de arquivos, por exemplo, a seguinte sequ\u00eancia de comandos levar\u00e1 sempre ao estado final em que h\u00e1 um arquivo /tmp/file2 e uma pasta denominada /dir1 . touch /tmp/file1 echo \"teste testando\" >> /tmp/file2 rm /tmp/file1 mkdir /dir1 H\u00e1 outras ordens dos mesmos comandos que levariam ao mesmo efeito, como a seguinte. Alguns protocolos de replica\u00e7\u00e3o de m\u00e1quinas de estados permitem que reordena\u00e7\u00f5es ocorram, desde que n\u00e3o afetem o resultado final dos comandos. Contudo, estes protocolos s\u00e3o mais complexos de se implementar e por isso raramente usados. echo \"teste testando\" >> /tmp/file2 mkdir /dir1 touch /tmp/file1 rm /tmp/file1 Arcabou\u00e7os para coordena\u00e7\u00e3o H\u00e1 muitas formas de se usar algoritmos de acordo em uma aplica\u00e7\u00e3o, embora se recomente que seu escopo seja minimizado a um n\u00facleo onde a consist\u00eancia forte \u00e9 absolutamente necess\u00e1ria e que este n\u00facleo seja usado para suportar outras partes do sistema 10 . Seja implementando a replica\u00e7\u00e3o de m\u00e1quinas de estados, seja implementando um core, ou qualquer outra abstra\u00e7\u00e3o sobre algoritmos de acordo ou comunica\u00e7\u00e3o em grupo, voc\u00ea tem a op\u00e7\u00e3o de implementar o protocolo zero, uma tarefa ingrata 9 . Felizmente, tamb\u00e9m tem a op\u00e7\u00e3o de usar arcabou\u00e7os prontos tanto para para comunica\u00e7\u00e3o em grupo quanto para diversos outros problemas de coordena\u00e7\u00e3o comuns em sistemas distribu\u00eddos. Estudo de caso: Copycat Copycat \u00e9 um arcabou\u00e7o de replica\u00e7\u00e3o de m\u00e1quinas de estados implementada pela P\u00e1gina Web Atomix. Na base do Copycat est\u00e1 uma implementa\u00e7\u00e3o do Raft. Sobre o Raft, uma API simples permite a cria\u00e7\u00e3o de m\u00e1quinas de estados replicadas usando uma API simples mas moderna, com uso pesado de lambdas , futures , e do estilo fluent de encadeamento de invoca\u00e7\u00f5es. Lambda Classe com um \u00fanico m\u00e9todo. 1 2 3 4 5 6 7 8 class Tarefa implements Runnable { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } } new Thread ( new Tarefa ()). start (); Classe an\u00f4nima - uso \u00fanico 1 2 3 4 5 6 new Thread ( new Runnable () { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } }). start (); Lambda 1 2 3 4 new Thread (() -> { while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); }). start (); Fluent Encadeamento 1 2 3 4 5 Collection < Pessoa > c = ...; c . stream () . filter ( p -> p . idade > 33 ) . map ( Pessoa :: sobrenomeNome ) //.map(p -> p.sobrenomeNome()) . forEach ( s -> System . out . println ( s )); Future Promessa de computa\u00e7\u00e3o e resultado. 1 2 ExecutorService executor = Executors . newSingleThreadExecutor (); Future < Integer > futFib = executor . submit (() -> { return Fibonacci ( 217 )}; Quando ser\u00e1 executado? Em algum momento. Como pegar o resultado? 1 2 3 4 while ( ! futFib . isDone ()) System . out . println ( \"tah calculando...\" ); int fib217 = futFib . get (); Em qual thread? Em algum thread. Depende do Executor Service usado. H\u00e1 v\u00e1rias vers\u00f5es do Copycat dispon\u00edveis, com vantagens e desvantagens. Vers\u00f5es Vers\u00e3o 1.1.4 Baseado em http://atomix.io/copycat/docs/getting-started/ e https://www.baeldung.com/atomix C\u00f3digo funcional em https://github.com/pluxos/atomix_labs Documenta\u00e7\u00e3o oficial removida Vers\u00e3o >= 2 Melhor desempenho Documenta\u00e7\u00e3o ruim ou inexistente https://github.com/atomix/atomix Vers\u00e3o 3 em Go evolu\u00e7\u00e3o r\u00e1pida Aqui usaremos a vers\u00e3o 1.1.4, que apesar de antiga, \u00e9 a melhor documentada atualmente, pelo tutorial referenciado acima. Clone e compile o projeto Instale depend\u00eancias: git maven JDK >= 1.8 git clone https://github.com/pluxos/atomix_labs cd atomix_labs cd replication mvn compile mvn test Voc\u00ea deve ver uma sa\u00edda semelhante \u00e0 seguinte, o que quer dizer que seu c\u00f3digo est\u00e1 compilando perfeitamente. 1 2 3 4 5 6 7 8 9 Tests run: 1 , Failures: 0 , Errors: 0 , Skipped: 0 [ INFO ] --------------------------------------- [ INFO ] BUILD SUCCESS [ INFO ] --------------------------------------- [ INFO ] Total time: 6 .898 s [ INFO ] Finished at: 2017 -10-25T08:38:08-02:00 [ INFO ] Final Memory: 15M/159M [ INFO ] --------------------------------------- Antes de come\u00e7ar a escrever suas pr\u00f3rpia m\u00e1quinas de estado, familiarize-se com a estrutura do projeto em https://github.com/pluxos/atomix_labs/tree/master/replication/src/main/java/atomix_lab/state_machine Observe que h\u00e1 tr\u00eas pastas: type - tipos dos dados mantidos pela replica (Edge e Vertex) Os tipos s\u00e3o serializable para que o Java saiba como transform\u00e1-los em bytes. command - estruturas que cont\u00eam informa\u00e7\u00f5es para modificar os tipos Os comandos ser\u00e3o enviadas do cliente para o cluster e s\u00e3o naturalmente serializable. client - cria comandos e os envia para serem executados no cluster Respostas podem ser esperadas s\u00edncrona ou assincronamente. server - recebe os comandos na ordem definida pelo Raft e os executa O projeto foi constru\u00eddo seguindo as instru\u00e7\u00f5es no tutorial mencionado antes, saltando-se a parte dos snapshots, isto \u00e9: crie um projeto maven eclipse tem template para isso adicione depend\u00eancias no pom.xml como so criei um projeto, coloquei as depend\u00eancias tanto do cliente quando do servidor defina Command que modifiquem o estado das r\u00e9plicas defina Queries que consultem o estado das r\u00e9plicas implemente a r\u00e9plica para lidar com os comandos implemente o cliente para emitir comandos Para executar um servidor, voc\u00ea precisa passar diversos par\u00e2metros identificador do processo (inteiro) IP do processo com identificador 0 porta do processo com identificar 0 IP do processo com identificador 1 porta do processo com identificar 1 ... Sabendo seu identificador, o servidor sabe em qual porta escutar e em quais IP/porta se conectar para se comunicar com os outros servidores. Para testar o projeto, execute tr\u00eas servidores, em tr\u00eas terminais distintos. Usando o maven, da linha de comando, basta executar os seguintes comandos[^\\]: 1 2 3 4 5 6 7 8 9 10 11 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"0 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"1 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"2 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" O cliente n\u00e3o precisa de um identificador, apenas dos pares IP/porta dos servidores. Por exemplo, use o comando: 1 2 3 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.client.GraphClient\" \\\\ -Dexec.args = \"127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" Exerc\u00edcio Uma vez executado o projeto, modifique-o para incluir uma nova opera\u00e7\u00e3o ( Command ) e nova consulta ( Query ), de sua escolha. Estudo de caso: Ratis Ratis \u00e9 um arcabou\u00e7o de coordena\u00e7\u00e3o atualmente encubado como um projeto no Apache . Embora mal documentado, o projeto tem alguns exemplos que demonstram como usar abstra\u00e7\u00f5es j\u00e1 implementadas. A seguir veremos um passo-a-passo, baseado nestes exemplos, de como usar o Ratis para implementar uma m\u00e1quina de estados replicada. Crie um novo projeto Maven com o nome ChaveValor (eu estou usando IntelliJ, mas as instru\u00e7\u00f5es devem ser semelhantes para Eclipse). Abra o arquivo pom.xml do seu projeto e adicione o seguinte trecho, com as depend\u00eancias do projeto, incluindo o pr\u00f3prio Ratis. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 <dependencies> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-server --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-server </artifactId> <version> 1.0.0 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-netty --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-netty </artifactId> <version> 1.0.0 </version> </dependency> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-grpc </artifactId> <version> 1.0.0 </version> </dependency> <dependency> <groupId> com.beust </groupId> <artifactId> jcommander </artifactId> <version> 1.78 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> 1.7.25 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-log4j12 </artifactId> <version> 1.7.25 </version> <scope> compile </scope> </dependency> <dependency> <groupId> log4j </groupId> <artifactId> log4j </artifactId> <version> 1.2.17 </version> </dependency> </dependencies> Adicione tamb\u00e9m o plugin Maven e o plugin para gerar um .jar com todas as depend\u00eancias. Observe que estou usando Java 14, mas voc\u00ea pode mudar para a sua vers\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> ${maven.compiler.version} </version> <configuration> <source> 14 </source> <target> 14 </target> </configuration> </plugin> <plugin> <artifactId> maven-assembly-plugin </artifactId> <executions> <execution> <phase> package </phase> <goals> <goal> single </goal> </goals> </execution> </executions> <configuration> <descriptorRefs> <descriptorRef> jar-with-dependencies </descriptorRef> </descriptorRefs> </configuration> </plugin> </plugins> </build> Crie uma nova classe denominada Cliente no arquivo Cliente.java . Nesta classe, iremos criar um objeto RaftClient que ser\u00e1 usado para enviar opera\u00e7\u00f5es para os servidores. Esta classe \u00e9 importada juntamente com outras v\u00e1rias depend\u00eancias, adicionadas no pom.xml , que devemos instanciar antes do RaftClient . Neste exemplo eu coloco praticamente todos os par\u00e2metros de configura\u00e7\u00e3o do Ratis hardcoded para simplificar o c\u00f3digo. Obviamente que voce deveria ser estes par\u00e2metros como argumentos para o programa ou de um arquivo de configura\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.apache.ratis.client.RaftClient ; import org.apache.ratis.conf.Parameters ; import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcFactory ; import org.apache.ratis.protocol.* ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.nio.charset.Charset ; import java.util.HashMap ; import java.util.Map ; public class Cliente { O campo raftGroupId identifica um cluster Ratis; isso quer dizer que um memsmo processo pode participar de v\u00e1rios clusters , mas aqui nos focaremos em apenas um. O valor do campo deve ter exatamente caracteres, o que soma 32 bytes em java, e ser\u00e1 interpretado como um UUID . id2addr \u00e9 um mapa do identificador de cada processo no cluster para seu endere\u00e7o IP + Porta. Aqui usei v\u00e1rias portas distintas porqu\u00ea todos os processos est\u00e3o rodando na mesma m\u00e1quina, mas se estivesse executando em m\u00e1quinas distintas, com IP distintos, poderia usar a mesma porta em todos. addresses \u00e9 uma lista de RaftPeer constru\u00edda a parti de id2addr . O campo raftGroup \u00e9 uma refer\u00eancia a todos os servidores, associados ao identificador do grupo, raftGroupId . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void main ( String args [] ) throws IOException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> new RaftPeer ( RaftPeerId . valueOf ( e . getKey ()), e . getValue ())) . collect ( Collectors . toList ()); final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), addresses ); Uma vez criado o grupo, criamos o cliente usando a f\u00e1brica retornada por RaftClient.newBuilder() . A f\u00e1brica deve ser configurada com os dados do grupo e o tipo de transporte, neste caso gRPC. Tamb\u00e9m \u00e9 necess\u00e1rio o identificador do processo que est\u00e1 se conectando ao grupo; neste caso, usamos um identificador aleat\u00f3rio qualquer, diferente do que faremos com os servidores. 1 2 3 4 5 6 7 8 RaftProperties raftProperties = new RaftProperties (); RaftClient client = RaftClient . newBuilder () . setProperties ( raftProperties ) . setRaftGroup ( raftGroup ) . setClientRpc ( new GrpcFactory ( new Parameters ()) . newRaftClientRpc ( ClientId . randomId (), raftProperties )) . build (); Uma vez criado o cliente, podemos fazer invoca\u00e7\u00f5es de opera\u00e7\u00f5es nos servidores. Cada opera\u00e7\u00e3o ser\u00e1 invocada em todos os servidores, na mesma ordem. Este prot\u00f3tipo suporta duas opera\u00e7\u00f5es, add e get . A opera\u00e7\u00e3o add \u00e9 codificada como uma String , add:k:v , onde k e v s\u00e3o do tipo String . add:k:v adiciona uma entrada em um mapa implementado pelo nosso servidor com chave k e valor v . J\u00e1 a opera\u00e7\u00e3o get:k recupera o valor v associado \u00e0 chave k , se presente no mapa. O m\u00e9todo RaftClient::send \u00e9 usado para enviar modifica\u00e7\u00f5es para as r\u00e9plicas e deve, necessariament, passar pelo protocolo Raft. J\u00e1 o m\u00e9todo RaftClient::sendReadOnly \u00e9 usado para enviar consultas a qualquer das r\u00e9plicas. Ambos os m\u00e9todos codificam o comando sendo enviado ( add:k:v ou get:k ) no formato interno do Ratis para as r\u00e9plicas e retorna um objeto RaftClientReply , que pode ser usado para pegar a resposta da opera\u00e7\u00e3o. O c\u00f3digo \u00e9 auto explicativo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 RaftClientReply getValue ; String response ; switch ( args [ 0 ] ){ case \"add\" : getValue = client . send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"get\" : getValue = client . sendReadOnly ( Message . valueOf ( \"get:\" + args [ 1 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; default : System . out . println ( \"comando inv\u00e1lido\" ); } client . close (); } } Um vez criado o cliente, crie a classe Servidor , no arquivo Servidor.java ; a parte inicial do c\u00f3digo \u00e9 semelhante \u00e0 do cliente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcConfigKeys ; import org.apache.ratis.protocol.RaftGroup ; import org.apache.ratis.protocol.RaftGroupId ; import org.apache.ratis.protocol.RaftPeer ; import org.apache.ratis.protocol.RaftPeerId ; import org.apache.ratis.server.RaftServer ; import org.apache.ratis.server.RaftServerConfigKeys ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import org.apache.ratis.util.LifeCycle ; import java.io.File ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.util.Collections ; import java.util.HashMap ; import java.util.Map ; import java.util.concurrent.TimeUnit ; public class Servidor { //Parametros: myId public static void main ( String args [] ) throws IOException , InterruptedException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. //Setup for node all nodes. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> new RaftPeer ( RaftPeerId . valueOf ( e . getKey ()), e . getValue ())) . collect ( Collectors . toList ()); A primeira diferen\u00e7a vem na necessidade de identificar o servidor dentro do conjunto de servidores, o que \u00e9 feito com um RaftPeerId . Como cada servidor deve usar um identificador \u00fanico, do conjunto pr\u00e9-determinado em id2addr , o identificador \u00e9 passado como argumento para o programa, obrigatoriamente. 1 2 3 4 5 6 7 8 //Setup for this node. RaftPeerId myId = RaftPeerId . valueOf ( args [ 0 ] ); if ( addresses . stream (). noneMatch ( p -> p . getId (). equals ( myId ))) { System . out . println ( \"Identificador \" + args [ 0 ] + \" \u00e9 inv\u00e1lido.\" ); System . exit ( 1 ); } Encare a se\u00e7\u00e3o seguinte como uma receita, mas observe que o m\u00e9todo RaftServerConfigKeys.setStorageDir recebe o nome de uma pasta como argumento, que ser\u00e1 usada para armazenar o estado da m\u00e1quina de estados. Se voc\u00ea executar o servidor m\u00faltiplas vezes, a cada nova execu\u00e7\u00e3o o estado anterior do sistema ser\u00e1 recuperado desta pasta. Para limpar o estado, apague as pastas de cada servidor. 1 2 3 4 RaftProperties properties = new RaftProperties (); properties . setInt ( GrpcConfigKeys . OutputStream . RETRY_TIMES_KEY , Integer . MAX_VALUE ); GrpcConfigKeys . Server . setPort ( properties , 1000 ); RaftServerConfigKeys . setStorageDir ( properties , Collections . singletonList ( new File ( \"/tmp/\" + myId ))); A m\u00e1quina de estados em si \u00e9 especificada no pr\u00f3ximo excerto, em setStateMachine , que veremos a seguir. 1 2 3 4 5 6 7 8 //Join the group of processes. final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), id2addr ); RaftServer raftServer = RaftServer . newBuilder () . setServerId ( myId ) . setStateMachine ( new MaquinaDeEstados ()). setProperties ( properties ) . setGroup ( raftGroup ) . build (); raftServer . start (); Uma vez iniciado o servidor, basta esperar que ele termine antes de sair do programa. 1 2 3 4 5 while ( raftServer . getLifeCycleState () != LifeCycle . State . CLOSED ) { TimeUnit . SECONDS . sleep ( 1 ); } } } Vamos agora para a defini\u00e7\u00e3o da classe MaquinaDeEstados , no arquivo MaquinaDeEstados.java . Esta classe deve implementar a interface org.apache.ratis.statemachine.StateMachine e seus v\u00e1rios m\u00e9todos ou, mais simples, estende org.apache.ratis.statemachine.impl.BaseStateMachine , a abordagem que usaremos aqui. 1 2 public class MaquinaDeEstados extends BaseStateMachine { Por enquanto, ignoraremos o armazenamento do estado em disco, mantendo-o simplesmente em mem\u00f3ria no campo key2values , e simplesmente implementaremos o processamento de comandos, come\u00e7ando pela implementa\u00e7\u00e3o do m\u00e9todo query . Este m\u00e9todo \u00e9 repons\u00e1vel por implementar opera\u00e7\u00f5es que n\u00e3o alteram o estado da m\u00e1quina de estados, enviadas com o m\u00e9todo RaftClient::sendReadOnly . A \u00fanica query no nosso sistema \u00e9 o get . No c\u00f3digo, o conte\u00fado da requisi\u00e7\u00e3o enviada pelo cliente deve ser recuperado em quebrado em opera\u00e7\u00e3o ( get ) e chave , usando : como delimitador. Recuperado o valor associado \u00e0 chave, o mesmo \u00e9 colocado em um CompletableFuture e retornado. 1 2 3 4 5 6 7 8 9 10 private final Map < String , String > key2values = new ConcurrentHashMap <> (); @Override public CompletableFuture < Message > query ( Message request ) { final String [] opKey = request . getContent (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKey [ 0 ]+ \":\" + key2values . get ( opKey [ 1 ] ); LOG . debug ( \"{}: {} = {}\" , opKey [ 0 ] , opKey [ 1 ] , result ); return CompletableFuture . completedFuture ( Message . valueOf ( result )); } O m\u00e9todo applyTransaction implementa opera\u00e7\u00f5es que alteram o estado, como add , enviadas com o m\u00e9todo RaftClient::send . Da mesma forma que em get , a opera\u00e7\u00e3o deve ser recuperada em quebrada em opera\u00e7\u00e3o ( add ), chave e valor, usando : como delimitador. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableFuture < Message > applyTransaction ( TransactionContext trx ) { final RaftProtos . LogEntryProto entry = trx . getLogEntry (); final String [] opKeyValue = entry . getStateMachineLogEntry (). getLogData (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKeyValue [ 0 ]+ \":\" + key2values . put ( opKeyValue [ 1 ] , opKeyValue [ 2 ] ); final CompletableFuture < Message > f = CompletableFuture . completedFuture ( Message . valueOf ( result )); final RaftProtos . RaftPeerRole role = trx . getServerRole (); LOG . info ( \"{}:{} {} {}={}\" , role , getId (), opKeyValue [ 0 ] , opKeyValue [ 1 ] , opKeyValue [ 2 ] ); return f ; } Pronto, voc\u00ea j\u00e1 tem uma m\u00e1quina de estados replicada, bastando agora apenas compil\u00e1-la e execut\u00e1-la. Para compilar, de raiz do projeto execute o comando mvn package . A primeira vez que faz isso pode demorar um pouco pois v\u00e1rias depend\u00eancias s\u00e3o baixadas da Internet. Ao final da execu\u00e7\u00e3o do comando voc\u00ea deveria ver algo semelhante ao seguinte 1 2 3 4 5 6 7 ... INFO ] ------------------------------------------------------------------------ [ INFO ] BUILD SUCCESS [ INFO ] ------------------------------------------------------------------------ [ INFO ] Total time: 4 .793 s [ INFO ] Finished at: 2020 -12-06T23:06:32-03:00 [ INFO ] ------------------------------------------------------------------------ Ent\u00e3o, em tr\u00eas terminais diferentes, execute os seguintes comandos: 1 2 3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p2 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p3 Para executar o cliente, em um outro terminal, fa\u00e7a, por exemplo, 1 2 3 4 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k1 testek1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get k1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k2 testek2 Todo o c\u00f3digo est\u00e1 dispon\u00edvel no Github Exer\u00edcio Adicionar opera\u00e7\u00f5es Passar opera\u00e7\u00e3o como par\u00e2metro do cliente. Estudo de caso: Zookeeper Porqu\u00ea sistemas distribu\u00eddos s\u00e3o como zool\u00f3gicos, com animais de diversas esp\u00e9cies, sendo obrigados a conviver de forma anti-natural, foi criado o Zookeeper . Vis\u00e3o Geral O qu\u00ea? ZooKeeper is a centralized service for maintaining configuration information, naming , providing distributed synchronization , and providing group services . All of these kinds of services are used in some form or another by distributed applications . Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them, which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed. O arcabou\u00e7o foi criado pelo Yahoo! para servir como pe\u00e7a na constru\u00e7\u00e3o de sistemas distribu\u00eddos dentro da empresa. Por qu\u00ea? Coordination services are notoriously hard to get right. They are especially prone to errors such as race conditions and deadlock. The motivation behind ZooKeeper is to relieve distributed applications the responsibility of implementing coordination services from scratch. Mais tarde o sistema tornou-se Open Source e tornou-se parte de diversos projetos, tamb\u00e9m abertos e propriet\u00e1rios. A raz\u00e3o de seu sucesso, arrisco dizer, \u00e9 a simplicidade de sua API, semelhante a um sistema de arquivos. Como? ZooKeeper is a distributed , open-source coordination service for distributed applications . It exposes a simple set of primitives that distributed applications can build upon to implement higher level services for synchronization, configuration maintenance, and groups and naming. It is designed to be easy to program to, and uses a data model styled after the familiar directory tree structure of file systems*. It runs in Java and has bindings for both **Java and C . ZooKeeper allows distributed processes to coordinate with each other through a shared hierarchal namespace which is organized similarly to a standard file system . The name space consists of data registers - called znodes , in ZooKeeper parlance - and these are similar to files and directories . Unlike a typical file system, which is designed for storage, ZooKeeper data is kept in-memory , which means ZooKeeper can achieve high throughput and low latency numbers. O sistema de arquivos do Zookeeper tem n\u00f3s denominados znodes , em refer\u00eancia aos i-nodes do mundo Unix. O znode raiz \u00e9 denominado / e um filho da raiz nomeado teste \u00e9 referido como /teste . Cada znode pode ser visto como arquivo e diret\u00f3rio ao mesmo tempo. O sistema de arquivos do Zookeeper \u00e9 replicado em v\u00e1rios n\u00f3s. Znodes s\u00e3o manipulados, essencialmente, por 4 opera\u00e7\u00f5es C: create R: get U: set D: delete ls *: get children Znodes s\u00e3o lidos e escritos sempre integralmente. Isto \u00e9, n\u00e3o se pode escrever apenas parte do conte\u00fado do \"arquivo\". Por isso, recomenda-se que os arquivos sejam sempre pequenos, onde pequeno \u00e9 relativo. Os comandos que atualizam dados, como create e delete s\u00e3o enviados para todas as r\u00e9plicas via o protocolo ZAB, Zookeeper Atomic Broadcast, que entrega as mensagens de forma totalmente ordenada. O sistema de arquivos \u00e9, portanto, uma m\u00e1quina de estados replicada. J\u00e1 comandos de leitura s\u00e3o executados direto na r\u00e9plica que os recebe. Por causa do custo em termos de mensagens trocadas entre os processos para mensagens de atualiza\u00e7\u00e3o e pelo baixo custo das mensagens de leitura, o zookeeper \u00e9 recomendado para cargas de trabalho com poucas escritas. Desempenho ZooKeeper is fast [...] and it performs best where reads are more common than writes, at ratios of around 10:1. O gr\u00e1fico seguinte mostra como o desempenho do sistema varia com o n\u00famero de processos. No eixo Y, a quantidade de requisi\u00e7\u00f5es processadas por segundo, ou seja, a vaz\u00e3o. No eixo X, a percentagem das requisi\u00e7\u00f5es do teste que s\u00e3o leituras e, portanto, repondidas na r\u00e9plica em que s\u00e3o recebidas. As diferentes curvas mostram diferentes configura\u00e7\u00f5es do sistema, indo de 3 a 12 r\u00e9plicas. Em geral, todas as configura\u00e7\u00f5es apresentam melhor desempenho quando h\u00e1 uma percentagem maior de leituras. Mas observe como as curvas se invertem, se focando primeiro na curva para 3 servidores: quando todas as opera\u00e7\u00f5es s\u00e3o de escrita, e portanto precisam passar pelo protocolo de difus\u00e3o at\u00f4mica, esta curva apresenta os melhores resultados. Isto ocorre porqu\u00ea o overhead de executar o protocolo \u00e9 mais baixo entre 3 servidores que entre 13. Em compensa\u00e7\u00e3o, quando temos mais leituras, que n\u00e3o precisam de sincroniza\u00e7\u00e3o, ent\u00e3o ter mais servidores \u00e9 mais vantajoso pois sobre menos carga de trabalho para cada servidor. Laborat\u00f3rio Instale o Zookeeper em sua m\u00e1quina seguindo estas instru\u00e7\u00f5es. Baixe: wget www-eu.apache.org/dist/zookeeper/zookeeper-3.6.2 Descomprima: tar xvzf zookeeper*.tgz Entre na pasta criada. Configure: copie o arquivo conf/zoo_sample.cfg para conf/zoo.cfg Execute ./bin/zkServer.sh start-foreground em um terminal ./bin/zkCli.sh -server 127.0.0.1:2181 em outro terminal Do shell do programa cliente (executado por \u00faltimo), digite help e enter para ver uma lista de todos os comandos dispon\u00edveis. Vejamos alguns exemplos b\u00e1sicos. ls / - lista os n\u00f3s filhos da raiz. create /teste lala - cria o n\u00f3 /teste com conte\u00fado lala get /teste - pega o conte\u00fado do arquivo set /teste lele - atualiza o conte\u00fado do arquivo delete /teste - apaga o arquivo Outros comandos interessantes s\u00e3o: stat /teste - mostra medatados do arquivo, por exemplo vers\u00e3o, e timestamps set -v V /teste lili - faz um update condiciona, isto \u00e9, atualiza o conte\u00fado do arquivo se a vers\u00e3o do mesmo, como mostrada pelo comando stat , for igual a V N\u00f3s Ef\u00eameros e Watches O Zookeeper tem muitas funcionalidades interessantes, mas chamarei a aten\u00e7\u00e3o a duas que s\u00e3o particularmente \u00fateis: N\u00f3s ef\u00eameros , criados com a flag -e , p.e., create -ef /teste/noefemero efemero , s\u00e3o automaticamente destru\u00eddos quando o cliente que os criou se desconecta do servidor. E watches avisam ao cliente quando uma opera\u00e7\u00e3o em um certo znode ou em seus filhos acontece. Para ser avisado quando os dados de um n\u00f3 forem alterados, use a op\u00e7\u00e3o -w do get, por exemplo, get -w /teste . Para monitorar altera\u00e7\u00f5es no conjunto de filhos de um n\u00f3, use -w no ls , por exemplo, ls -w /teste . N\u00f3s Ef\u00eameros e Watches Crie um zNode /teste Debaixo de /teste, crie tr\u00eas outros, sequenciais Crie um zNode /teste2 Crie um zNode ef\u00eamero Conecte-se com outro cliente Coloque um watch em /teste2 Desconecte o primeiro cliente Observe o evento gerado no segundo cliente Reconecte o primeiro cliente Cluster tolerante a falhas Observe que voc\u00ea est\u00e1 executando o Zookeeper em apenas um n\u00f3, ou seja, n\u00e3o h\u00e1 toler\u00e2ncia a falhas alguma aqui. Para tolerar falhas, voc\u00ea precisa de um cluster multi-n\u00f3s, mesmo que seja em uma \u00fanica m\u00e1quina. Neste caso, crie tr\u00eas arquivos de configura\u00e7\u00e3o, zoo1.cfg , zoo2.cfg e zoo3.cfg . O arquivo zooX.cfg , onde 1 <= X <= 3 , fica assim: dataDir=/tmp/lasaro/zooX #Substitua o X pelo valor correto server.1=zoo1:2888:3888 server.2=zoo2:2889:3889 server.3=zoo3:2890:3890 clientPort=218X #Substitua o X pelo valor correto Crie diret\u00f3rios e arquivos de identifica\u00e7\u00e3o. mkdir /tmp/lasaro/zooX echo X > /tmp/lasaro/zooX/myid Execute servidores. ./bin/zkServer.sh start conf/zooX.cfg Ainda que tenha tr\u00eas servidores executando em uma mesma m\u00e1quina, seu cluster parar\u00e1 de funcionar se a m\u00e1quina parar de funcionar. O ideal \u00e9 que cada servidor execute em uma m\u00e1quina distinta. Receitas \u00c9 poss\u00edvel resolver diversos problemas encontrados em sistemas distribu\u00eddos usando-se o ZooKeeper, por exemplo, o problema de descoberta de processos. Rendezvous Ponto de encontro de processos. Defina um zNode raiz a ser usado: /rendezvous/app1/ Cada filho de /rendezvous/app1 corresponde a um processo: IP Porta N\u00famero de processadores ... Processo p ao ser iniciado: procura /rendezvous/app1/p se achar, continua se n\u00e3o achar, cria /rendezvous/app1/p lista os filhos de /rendezvous/app1 Como lidar com sa\u00edda de processos? Fa\u00e7a todos os zNodes s\u00e3o ef\u00eameros. Quando um n\u00f3 \u00e9 desconectado, o zNode correspondente ser\u00e1 destru\u00eddo. Como detectar mudan\u00e7as no grupo de processos? Monitore os filhos de /rendezvous/app1 Sempre que receber notifica\u00e7\u00f5es, refa\u00e7a o c\u00e1lculo do membership . Elei\u00e7\u00e3o de L\u00edderes Rendezvous. Fa\u00e7a os zNodes sequenciais. Ordene os zNodes e escolha o primeiro. Monitore o zNode. Se ele sumir, eleja outro l\u00edder. Exclus\u00e3o M\u00fatua Construa uma fila usando n\u00f3s ef\u00eameros e sequenciais. O processo na cabe\u00e7a da fila tem direito de acesso. Em caso de falhas, o processo \u00e9 removido da cabe\u00e7a da fila. V\u00e1rias outras receitas podem ser facilmente encontradas no s\u00edtio do projeto : Lock distribu\u00eddo Filas, e.g. de prioridades Barreira Servi\u00e7o de nomes Termina\u00e7\u00e3o em duas fases Contador at\u00f4mico Al\u00e9m destas, outro projeto, o Curator se dedica apenas a colecionar implementa\u00e7\u00f5es corretas de receitas para o Zookeeper. Estudo de caso: Etcd Todo descrever o etcd Todo falhas bizantinas <!-- \\subsection{Toler\u00e2ncia a Falhas} \\begin{frame}{O qu\u00ea?} Manter dados/servi\u00e7os dispon\u00edveis a despeito de falhas. \\end{frame} \\[\\begin{frame}{Replica\u00e7\u00e3o} No Kafka, o \\alert{Replication Factor} determina quantas c\u00f3pias de cada t\u00f3pico (todas as parti\u00e7\u00f5es no t\u00f3pico). \\end{frame}\\] \\[\\begin{frame}{L\u00edder e Seguidor} \\begin{itemize} * Produtor conversa com l\u00edder. L\u00edder grava localmente e envia ack ao produtor. * Consumidor conversa com l\u00edder. L\u00edder envia dados ao consumidor. * L\u00edder replica dados para seguidores. \\end{itemize} \\end{frame}\\] \\begin{frame}{Replicar} Passo 6 ensina a criar um sistema com m\u00faltiplos brokers. \\begin{itemize} * Identificador * Porta (mesmo servidor) * \\alert{Log directory} \\end{itemize} \\end{frame} \\[\\begin{frame}{Replicar} \\begin{itemize} * Crie um novo t\u00f3pico, com RF = 3 e duas parti\u00e7\u00f5es * \\lstinline|bin/kafka-topics.sh --list --zookeeper localhost:2181 --describe --topic <topico>| * Lista de r\u00e9plicas * Lista de r\u00e9plicas sincronizadas: \\emph{list of \\alert{i}n \\alert{s}ync \\alert{r}eplicas} \\end{itemize} \\end{frame}\\] \\[\\begin{frame}{Zookeeper} \\begin{itemize} * Permite que n\u00f3s do cluster se descubram * Elege l\u00edder \\end{itemize} \\end{frame}\\] \\[\\begin{frame}{Armazenamento} \\begin{itemize} * Dado deve ser removido depois de um tempo de ``reten\u00e7\u00e3o'' * Pode definir reten\u00e7\u00e3o por tamanho (por parti\u00e7\u00e3o, n\u00e3o t\u00f3pico) \\end{itemize} \\end{frame}\\] \\subsection{Produtor} \\[\\begin{frame}{Produtor} \\begin{itemize} * Produtor envia mensagens para os brokers * Producer API * \\href{https://github.com/LearningJournal/ApacheKafkaTutorials}{Learning Journal} \\end{itemize} \\end{frame}\\] \\begin{frame}[fragile]{SimpleProducer.java} \\begin{lstlisting}[language=Java] import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; import java.util.Properties; public class SimpleProducer { public static void main(String[] args) { String topicName = \"SimpleProducerTopic\"; String key = \"Chave\"; String value = \"Valor\"; Properties props = new Properties(); props.put(\"bootstrap.servers\", \"localhost:9092, localhost:9093\"); props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); Producer producer = new KafkaProducer (props); ProducerRecord record = new ProducerRecord (topicName, key, value); producer.send(record); producer.close(); System.out.println(\"SimpleProducer Completed.\"); } } \\end{lstlisting} \\end{frame} \\begin{frame}{Workflow} \\includegraphics[width=.8\\textwidth]{images/kafka6} \\begin{itemize} * Particionador default \\begin{itemize} * Partition * Hash da ``chave'' * Round robin \\end{itemize} * Retry autom\u00e1tico \\end{itemize} \\end{frame} \\[\\begin{frame}{Fire and Forget} Envia a mensagem e n\u00e3o se importa com o resultado. \\end{frame}\\] \\begin{frame}[fragile]{Synchronous Call} Envia a mensagem e espera para saber se foi entregue ou n\u00e3o. \\begin{lstlisting}[language=Java] try{ RecordMetadata metadata = producer.send(record).get(); System.out.println(\"Message is sent to Partition no \" + metadata.partition() + \" and offset \" + metadata.offset()); System.out.println(\"SynchronousProducer Completed with success.\"); }catch (Exception e) { e.printStackTrace(); System.out.println(\"SynchronousProducer failed with an exception\"); }finally{ producer.close(); } \\end{lstlisting} \\begin{itemize} * Future \\end{itemize} \\end{frame} \\begin{frame}[fragile]{Callback} Envia a mensagem e \u00e9 invocado depois de receber um ACK \\begin{lstlisting}[language=Java] producer.send(record, new MyProducerCallback()); ... class MyProducerCallback implements Callback{ @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) { if (e != null) System.out.println(\"AsynchronousProducer failed with an exception\"); else System.out.println(\"AsynchronousProducer call Success:\"); } } \\end{lstlisting} \\begin{itemize} * max.in.flight.requests.per.connection \\end{itemize} \\end{frame} \\begin{frame}{Default Partitioner} \\includegraphics[width=.8\\textwidth]{images/kafka6} \\[\\begin{itemize} * Partition * Hash da ``chave'' \\% \\#partition * Round robin \\end{itemize}\\] \\href{ https://github.com/LearningJournal/ApacheKafkaTutorials/blob/master/ProducerExamples/SensorPartitioner.java}{Exemplo de Custom Partitioner} \\end{frame} \\subsection{Consumidor} \\[\\begin{frame}{Consumer Groups} \\begin{itemize} * M\u00faltiplos consumidores processam dados em paralelo * Grupo de consumidores de t\u00f3picos * Grupo pertence \u00e0 mesma aplica\u00e7\u00e3o \\includegraphics[width=.6\\textwidth]{images/kafka7} * Duplicate reads? Consumidores n\u00e3o compartilham parti\u00e7\u00f5es * Group coordinator (broker eleito): lista de consumidores * Group l\u00edder: rebalanceamento \\end{itemize} \\end{frame}\\] \\begin{frame}[fragile, allowframebreaks]{Consumer} \\begin{lstlisting}[language=Java] import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import java.io.IOException; import java.util.Arrays; import java.util.Properties; public class SimpleConsumer { public static void main(String[] args) throws IOException { String topicName = \"SimpleProducerTopic\"; String groupName = \"SupplierTopicGroup\"; Properties props = new Properties(); props.put(\"bootstrap.servers\", \"localhost:9092,localhost:9093\"); props.put(\"group.id\", groupName); props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer consumer = null; try { consumer = new KafkaConsumer (props); consumer.subscribe(Arrays.asList(topicName)); while (true) { ConsumerRecords records = consumer.poll(100); 1 2 for (ConsumerRecord<String, String> record: records) System.out.println(\"Key = \" + record.key() + \" Value = \" + record.value()); } } catch (Exception ex) { ex.printStackTrace(); } finally { consumer.close(); } } } \\end{lstlisting} \\begin{itemize} * Se n\u00e3o definir grupo, ser\u00e1 novo grupo, e ler\u00e1 todas as mensagens dispon\u00edveis \\end{itemize} \\end{frame} \\[\\begin{frame}{Poll} \\begin{itemize} * poll tamb\u00e9m envia hearbeat * executar a cada 3s, no m\u00ednimo * Current offset: a cada poll, broker incrementa current offset * Commited offset: o consumidor informa quais \u00edndices foram processados \\begin{itemize} * Auto Commit \\begin{itemize} * enable.auto.commit * auto.commit.interval.ms * Pode causar reprocessamento de mensagens \\end{itemize} * Manual Commit \\begin{itemize} * CommitSync * CommitAsync \\end{itemize} \\end{itemize} \\end{itemize} \\end{frame}\\] \\subsection{Arquitetura} %\\begin{frame}{L\u00edder} %\\end{frame} %mensagens s\u00e3o ack depois de copiadas para todas as r\u00e9plicas %replicas lentas s\u00e3o removidas se lentas ou falhas %at least once, at most once, exactly one (nao suportado) %rolling upgrade %tls security %rest %CRUD Falhas Bizantinas Uma hist\u00f3ria de tr\u00eas ex\u00e9rcitos -- Vers\u00e3o 2} Ex\u00e9rcitos est\u00e3o \u00e0s portas de Biz\u00e2ncio, aka Constantinopla, aka Istambul. Todos os ex\u00e9rcitos tem que atacar em conjunto ou se retirar em conjunto. Cada ex\u00e9rcito \u00e9 comandado por um General. Alguns destes preferem atacar, enquanto outros preferem se retirar. Alguns generais podem ter sido comprados, e mandar mensagens discrepantes para os outros, ou simplesmente n\u00e3o mandar mensagens. Fonte: \\href{ http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf}{Lamport , L.; Shostak, R.; Pease, M. (1982). \"The Byzantine Generals Problem\" (PDF). ACM Transactions on Programming Languages and Systems. 4 (3): 382\u2013401. doi:10.1145/357172.357176.} Generais e Tenentes Problema pode ser mudado para: 1 2 3 * Comandante envia ordem. * Todos os tenentes leais executam ordem recebida. * Comandante pode ser traidor. Generais e Tenentes Suponha 3 ex\u00e9rcitos. \\ Comandante (traidor) diz \"Ataque!\" Tenente A e \"Retirada!\" tenente B.\\ Ou \\ Comandante diz \"Ataque!\" a ambos. Tenente A segue a ordem mas B se retira. E se os tenentes trocarem informa\u00e7\u00f5es? Como diferenciar casos em que Comandante ou Tenente \u00e9 traidor? Generais e Tenentes S\u00f3 h\u00e1 solu\u00e7\u00e3o se mais de \\(\\frac{2}{3}\\) dos Generais/Tenentes s\u00e3o leais. % http://www.drdobbs.com/cpp/the-byzantine-generals-problem/206904396?pgno=5 Comunica\u00e7\u00e3o} 1 2 * Toda mensagem enviada \u00e9 entregue corretamente. * A aus\u00eancia de mensagem pode ser detectada (mensagem Null \u00e9 entregue no lugar) (Sistema s\u00edncrono) 4/0} General manda ordens. Aus\u00eancia de ordem = Retirada Tenente repassa ordens Maioria de comandos \u00e9 comando a ser seguido 4/0} General manda ordens. Aus\u00eancia de ordem = Retirada Tenente repassa ordens Maioria de comandos \u00e9 comando a ser seguido Comunica\u00e7\u00e3o} 1 2 3 * Toda mensagem enviada \u00e9 entregue corretamente. * Toda mensagem \u00e9 assinada. * A aus\u00eancia de mensagem pode ser detectada (mensagem Null \u00e9 entregue no lugar) (Sistema s\u00edncrono) \u00c9 poss\u00edvel detectar inconsist\u00eancias e processos bizantinos. % http://cs.brown.edu/courses/cs138/s16/lectures/19consen-notes.pdf \\section{Outros t\u00f3picos} %TODO \\subsection{Detectores de Falhas} \\subsection{Reconfigura\u00e7\u00e3o} Reconfigura\u00e7\u00e3o da Aplica\u00e7\u00e3o} Na segunda entrega do projeto, voc\u00ea distribuiu a carga do seu banco de dados entre v\u00e1rios n\u00f3s. Caso um n\u00f3 falhe, parte dos seus dados ser\u00e1 perdida. Para corrigir esta defici\u00eancia, na terceira entrega, cada n\u00f3 ser\u00e1 replicado em tr\u00eas vias e, assim, caso um n\u00f3 falhe, outros dois continuar\u00e3o a manter o dado. Reconfigura\u00e7\u00e3o da Aplica\u00e7\u00e3o} Ainda assim, h\u00e1 problemas. E se mais de um, de um mesmo conjunto de r\u00e9plicas, falhar? Embora seja pequena a probabilidade de dois n\u00f3s de um mesmo grupo falharem em instantes pr\u00f3ximos, dado tempo suficiente, qualquer evento com probabilidade diferente de 0 acontecer\u00e1. Precisamos de uma forma de trocar n\u00f3s da aplica\u00e7\u00e3o que falharam por novos n\u00f3s. Este \u00e9 problema denominado Pertin\u00eancia de Grupo ou \\emph{Group Membership} Group Membership} Para n\u00e3o correr o risco, retire o processo falhos do grupo e coloque outro no lugar! I.e., mude a vis\u00e3o que o sistema de quem \u00e9 o grupo. Vis\u00f5es} \\includegraphics[width=.7\\textwidth]{images/vc} Fonte: \\href{ https://www.cs.rutgers.edu/~pxk/417/notes/virtual_synchrony.html}{Paul Krzyzanowski} \\(G\\) \u00e9 o grupo de processos participando do sistema, \u00e9 a Vis\u00e3o do Sistema. Inicialmente, \\(G\\) consiste de apenas o processo \\(p\\) , como o processo que cria o cluster no Atomix. Na sequ\u00eancia, outros processo v\u00e3o se unindo ao grupo atrav\u00e9s de View Changes. Uma vez que \\(p\\) e \\(q\\) est\u00e3o no grupo, inicia-se a comunica\u00e7\u00e3o entre eles. Quando \\(r, s\\) e \\(t\\) aparecem, tamb\u00e9m entram no grupo por meio de uma nova vis\u00e3o. Finalmente, quando ambos \\(p\\) e \\(q\\) falham, os outros processo os excluem da vis\u00e3o, e continuam funcionando normalmente. Impossibilidade de Detec\u00e7\u00e3o de Falhas} Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir com toda certeza um processo falho (parou de funcionar) de um que est\u00e1 lento. Como decidir se mudar ou n\u00e3o de vis\u00e3o? Ou aceita a imprecis\u00e3o e muda quando suspeitar de uma falha, ou corre o risco de ficar esperando \\emph{ad eternum} e n\u00e3o mudar, mesmo quando uma falha aconteceu. Uma ``solu\u00e7\u00e3o''!} Quando suspeitar de falha, reporte suspeita a outros processos, que tamb\u00e9m passar\u00e3o a suspeitar. Tome decis\u00e3o baseado na suspeita, isto \u00e9, troque de vis\u00e3o quando houver suspeita. Pague o pre\u00e7o de uma suspeita errada, isto \u00e9, quando um processo for removido da vis\u00e3o indevidamente, adicione-o novamente. Sincronismos Virtual} Gerenciamento de Grupo/Group Membership e Comunica\u00e7\u00e3o em Grupo 1 2 3 4 5 6 * Processos se unem ao grupo * Processos saem do grupo * Processos enviam mensagens para o grupo * Diferentes ordena\u00e7\u00f5es * Atomic Multicast Vis\u00e3o de Grupo} 1 2 3 4 * Vis\u00e3o: conjunto de processos no sistema. * Multicast feito para processos na vis\u00e3o. * Vis\u00e3o \u00e9 consistente entre os processos. * Entrada e sa\u00edda de processos muda a vis\u00e3o. Eventos} 1 2 3 * Mensagem * Mudan\u00e7a de Vis\u00e3o * Checkpoint Vis\u00f5es} \\includegraphics[width=.7\\textwidth]{images/vc} Fonte: \\href{ https://www.cs.rutgers.edu/~pxk/417/notes/virtual_synchrony.html}{Paul Krzyzanowski} Sincronismo Virtual} Deve satisfazer 1 2 3 4 * Se uma mensagem \u00e9 enviada em uma vis\u00e3o, ela s\u00f3 pode ser entregue naquela vis\u00e3o. * Se uma mensagem \u00e9 entregue a um processo correto em uma vis\u00e3o, ent\u00e3o \u00e9 entregue a todos os processos corretos naquela vis\u00e3o. * Se um processo n\u00e3o recebe a mensagem, ele n\u00e3o estar\u00e1 na pr\u00f3xima vis\u00e3o. * Ao entrar em uma vis\u00e3o, o processo recebe o estado dos outros processos e seu estado se torna equivalente ao de um processo que recebeu todas as mensagens j\u00e1 entregues. A troca de Vis\u00e3o \u00e9 uma barreira. ISIS Toolkit} Sistema de Sincronismo Virtual tolerante a falhas desenvolvido por Ken Birman, Cornell University (\\url{ http://www.cs.cornell.edu/Info/Projects/Isis/ })\\ ISIS: An Environment for Constructing Fault-Tolerant Distributed Systems. Kenneth Birman, D. Skeen, A. El Abbadi, W. C. Dietrich and T. Raeuchle. May 1983. 1 2 3 4 5 6 7 * 100.000's/s * Em uso at\u00e9 2009 * NY Stock Exchange * Swiss Exchange * US Navy * Precursos de sistemas como Zookeeker * Totem, ISIS, Horus, Transis (Parti\u00e7\u00f5es), \\alert{Spread}, \\alert{Ensamble}, \\alert{JGroups}, Appia, QuickSilver, vSynch (n\u00e9e ISIS 2) Difus\u00e3o Totalmente Ordenada} 1 2 3 4 5 6 7 * Corretude: Se um processo $p$ envia uma mensagem $m$ para processos no grupo $G$, ent\u00e3o se $p$ n\u00e3o falha, todos os processos corretos em $G$ recebem a mensagem. * Acordo: Se um processo correto em $G$ recebe uma mensagem $m$, ent\u00e3o todo processo correto em $G$ recebe $m$ * Ordena\u00e7\u00e3o: Se um processo recebe mensagem $m$ e depois $n$, ent\u00e3o qualquer processo que receba a mensagem $n$ deve primeiro receber $m$ * Validade: Somente mensagens difundidas s\u00e3o entregues. E se mandarmos mensagens do tipo ``A partir da entrega desta mensagem, o grupo de processos \u00e9 \\(G\\) .'' Sincronismo Virtual} Deve satisfazer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 * Se uma mensagem \u00e9 enviada em uma vis\u00e3o, ela s\u00f3 pode ser entregue naquela vis\u00e3o.\\\\ Mensagens de troca de vis\u00e3o podem incrementar um contador\\\\ Mensagens normais carregam o valor atual do contador\\\\ Mensagem descartada se valor na mensagem \u00e9 maior contador no destinat\u00e1rio * Se uma mensagem \u00e9 entregue a um processo correto em uma vis\u00e3o, ent\u00e3o \u00e9 entregue a todos os processos corretos naquela vis\u00e3o.\\\\ Pela difus\u00e3o, se a mensagem de troca for entregue para um processo, ser\u00e1 entregue para todos os corretos, na mesma ordem Se mensagem comum for entregue antes para algum, ser\u00e1 entregue ante para todos. * Se um processo n\u00e3o recebe a mensagem, ele n\u00e3o estar\u00e1 na pr\u00f3xima vis\u00e3o.\\\\ Se um processo n\u00e3o recebe uma mensagem comum que foi entregue pelos outros, ent\u00e3o ele n\u00e3o troca de vis\u00e3o. * Ao entrar em uma vis\u00e3o, o processo recebe o estado dos outros processos e seu estado se torna equivalente ao de um processo que recebeu todas as mensagens j\u00e1 entregues.\\\\ Caso contr\u00e1rio, n\u00e3o haveria porqu\u00ea trocar os processos State Transfer} \\includegraphics[width=.7\\textwidth]{images/state_transfer} \\href{ http://www.gsd.inesc-id.pt/~ler/docencia/tfd0405/bib/BSRNA.pdf}{Building Secure and Reliable Network Applications} Difus\u00e3o At\u00f4mica \\(\\equiv\\) Sincronismo Virtual?} Seria uma boa aproxima\u00e7\u00e3o, mas que poderia ser relaxada. Em certas aplica\u00e7\u00f5es, FIFO ou Causal seriam suficientes dentro da vis\u00e3o, desde que a mensagem de mudan\u00e7a da vis\u00e3o seja totalmente ordenada com as comuns. Particionamento} E se dois subconjuntos mutuamente exclusivos se formarem e criarem vis\u00f5es independentes? \\emph{Primary Partition Model} -- Somente a parti\u00e7\u00e3o prim\u00e1ria pode mudar de vis\u00e3o. Lembram-se que no Raft somente uma parti\u00e7\u00e3o com uma maioria de processo pode decidir? \u00c9 exatamente a mesma situa\u00e7\u00e3o, pois os processos est\u00e3o chegando a um Consenso sobre quem \u00e9 a nova vis\u00e3o. Extended Virtual Synchrony} \\emph{Primary Partition Model} -- N\u00e3o \u00e9 adequado a uma rede geograficamente distribu\u00edda (Internet scale). Lembram-se que no Raft somente uma parti\u00e7\u00e3o com uma maioria de processo pode decidir? \u00c9 exatamente a mesma situa\u00e7\u00e3o, pois os processos est\u00e3o chegando a um Consenso sobre quem \u00e9 a nova vis\u00e3o. \u00c9 poss\u00edvel que no trabalho dois, alguns de voc\u00eas tenham tentado gerar locks do sistema para manipular objetos distribu\u00eddos no sistema. Esse locks s\u00e3o perigosos por qu\u00ea processos pode travar/quebrar/falhar e nunca liberarem os locks. O uso de um algoritmo VS poderia ser usado para resolver o problema.\\right Swim http://courses.cs.vt.edu/cs5204/fall05-gback/lectures/Lecture8.pdf Estudo de caso: Kafka Todo Boeing 737 Max: why was it grounded, what has been fixed and is it enough? \u21a9 Using TLA+ in the Real World to Understand a Glibc Bug \u21a9 Fail Fast Is Failing\u2026 Fast! \u21a9 Esta \u00e9 uma varia\u00e7\u00e3o do problema de coordena\u00e7\u00e3o de gangsters apresentado no em Some constraints and trade-offs in the design of network communications \u21a9 Hundred Impossibility Proofs for Distributed Computing , Impossibility Results for Distributed Computing \u21a9 Impossibility of Distributed Consensus with One Faulty Process . Uma explica\u00e7\u00e3o da prova est\u00e1 dispon\u00edvel no Paper Trail \u21a9 Unreliable Failure Detectors for Reliable Distributed Systems \u21a9 The Weakest Failure Detector for Solving Consensus \u21a9 Um exemplo de como traduzir um algoritmo complexo para c\u00f3digo pode se ingrato \u00e9 reportado em Paxos Made Live - An Engineering Perspective . \u21a9 Consistent Core \u21a9 O \\\\ no final da linha \u00e9 s\u00f3 para mostrar que o comando continua na pr\u00f3xima e facilitar a visualiza\u00e7\u00e3o. Na hora de executar, use apenas uma linha, sem o \\\\ . \u21a9","title":"Toler\u00e2ncia a Falhas"},{"location":"fault/#tolerancia-a-falhas","text":"","title":"Toler\u00e2ncia a Falhas"},{"location":"fault/#dependabilidade","text":"N\u00f3s escrevemos software para que resolvam problemas de espectro bem amplo, indo, do controle de bra\u00e7os rob\u00f3ticos em cirurgias remotas \u00e0 sistemas de com\u00e9rcio eletr\u00f4nico, do controle de usinas hidroel\u00e9tricas \u00e0 jogos de truco online. Independentemente do problema sendo resolvido, gostar\u00edamos de poder contar com o sistema, de poder depender nele para executar sua tarefa. Desta situa\u00e7\u00e3o, surge a ideia de dependabilidade, isto \u00e9, de um sistema ter a propriedade de se poder depender do mesmo. Dizemos que um componente \\(C\\) depende de um componente \\(C'\\) se a corretude do comportamento de \\(C\\) depende da corretude do componente \\(C'\\) . E que um componente \u00e9 \"depend\u00e1vel\" ( dependable ) na medida em que outros podem depender dele. A dependabilidade \u00e9 essencial aos componentes de sistemas distribu\u00eddos, afinal, \"uma corrente \u00e9 t\u00e3o forte quanto seu elo mais fraco.\" De acordo com Avizienis et al , tem-se dependabilidade quando os seguintes atributos est\u00e3o presentes. Disponibilidade ( Availability ) - Prontid\u00e3o para uso. Confiabilidade/Fiabilidade ( Reliability ) - Continuidade do servi\u00e7o. Seguran\u00e7a ( Safety ) - Toler\u00e2ncia a cat\u00e1strofes. Integridade ( Integrity ) - Toler\u00e2ncia a modifica\u00e7\u00f5es. Manutenabilidade ( Maintainability ) - Facilidade de reparo. Outra propriedade importante neste contexto \u00e9 a Confidencialidade ( Confidentiality ), a garantia de que a informa\u00e7\u00e3o somente \u00e9 acess\u00edvel a quem \u00e9 devido. A combina\u00e7\u00e3o de Disponibilidade , Integridade e Confidencialidade \u00e9 tamb\u00e9m chamada de Seguran\u00e7a ( Security ). Mas o que significa, na pr\u00e1tica, ser depend\u00e1vel e seguro ( secure )? Para respondermos a esta quest\u00e3o, primeiro precisamos entender os tipos de problemas que aparecem em v\u00e1rios n\u00edveis, desde o seu desenvolvimento at\u00e9 seu uso.","title":"Dependabilidade"},{"location":"fault/#falhas-erros-e-defeitos","text":"No n\u00edvel mais b\u00e1sico dos problemas a serem contornados para se obter dependabilidade, temos as falhas ( defect , fault , para alguns, falta), que \u00e9 um erro no desenvolvimento do sistema, como bugs ou defeitos de fabrica\u00e7\u00e3o, que o leva a ficar diferente do que foi especificado. Uma falha existe mesmo se for raramente ativada e mesmo se seus efeitos nunca forem percebidos. Por exemplo, se o c\u00f3digo tem um <= em vez de < na especifica\u00e7\u00e3o de uma itera\u00e7\u00e3o, mas se uma condi\u00e7\u00e3o faz com que a itera\u00e7\u00e3o seja interrompida antes, o c\u00f3digo ainda tem uma falha. No segundo n\u00edvel, temos o erro ( error ), que \u00e9 a manifesta\u00e7\u00e3o da falha levando a algum comportamento indevido. No exemplo acima, um erro seria quando a itera\u00e7\u00e3o passasse do ponto correto por causa do <= , por exemplo, na hora de escrever uma string em um array, estourando o limite do array na pilha mas sobrescrevendo uma vari\u00e1vel que n\u00e3o seja mais usada. O erro pode passar despercebido, mas ainda assim \u00e9 um erro. Finalmente, no terceiro n\u00edvel, temos os defeitos ( failure , para alguns, falha), um erro percebido pelo usu\u00e1rio. Continuando o exemplo, um stack overflow que leva a uma falha de segmenta\u00e7\u00e3o, leva a um defeito. Quando um componente manifesta um defeito, outros componentes que dele dependem, internalizar\u00e3o entradas indevidas, uma falha externa, o que levar\u00e1 a seu pr\u00f3prio estado interno a estar err\u00f4neo e possivelmente tamb\u00e9m manifestar um defeito. Esta cadeia pode levar cen\u00e1rios catastr\u00f3ficos. Falhas Famosas Ariane 5 O Ariane 5 foi um foguete desenvolvido pela agencia espacial europ\u00e9ia que explodiu durante o lan\u00e7amento. The Explosion of the Ariane 5 On June 4, 1996 an unmanned Ariane 5 rocket launched by the European Space Agency exploded just forty seconds after its lift-off [...] after a decade of development costing $7B. The destroyed rocket and its cargo were valued at $500M. [...] the failure was a software error [...] a 64 bit floating point number [...] was converted to a 16 bit signed integer. The number was larger than 32,767, the largest integer storeable in a 16 bit signed integer, and thus the conversion failed. O erro gerado foi tratado como input, causando outros erros, que geraram instabilidade e que levou o sistema a se auto-destruir. 787 Dreamliner O avi\u00e3o 787 dreamliner, da Boeing, tem um problema que tornar necess\u00e1rio reiniciar o sistema el\u00e9trico a cada 248 dias, ou o mesmo pode ter uma pane. Quote The plane\u2019s electrical generators fall into a failsafe mode if kept continuously powered on for 248 days. The 787 has four such main generator-control units that, if powered on at the same time, could fail simultaneously and cause a complete electrical shutdown. Segundo as \"m\u00e1s l\u00ednguas\", o problema \u00e9 que acontece um overflow em um contador de tempo Quote 248 days == 2^31 100ths of a second. even in 2015, our airplanes have integer overflow bugs https://t.co/6Z8d4y9gjM \u2014 Fiora @ \u65e5\u672c\u8a9e\u3067FF14 (@FioraAeterna) May 1, 2015 737 Max Neste outro caso envolvendo a Boeing, um sensor \u00e9 usado para detectar se o avi\u00e3o estava subindo r\u00e1pido demais e correndo o risco de perder sustenta\u00e7\u00e3o, um comportamento que se verificou comum no 737 Max por causa dos grandes motores usados nele e que o diferenciam do 737 original. Se o risco \u00e9 detectado, um sistema automatizado for\u00e7a o nariz do avi\u00e3o para baixo para corrigir o problema. Contudo, no 737 Max apenas um sensor \u00e9 usado e no caso de falha do mesmo, o avi\u00e3o \u00e9 for\u00e7ado para baixo e em dire\u00e7\u00e3o ao solo, o que levou \u00e0 morte de centenas de pessoas. 1 Subaru SUV Em 2018 a Subaru fez um recall gigante, de mais de 1 milh\u00e3o de unidades de um seus modelos de SUV, porqu\u00ea uma falha em um software fez com que soldagens fossem feitas incorretamente no chassis dos ve\u00edculos. O erro era irrepar\u00e1vel, levando a grandes preju\u00edzos.","title":"Falhas, Erros e Defeitos"},{"location":"fault/#root-cause-analysis","text":"Quando defeitos aparecem, \u00e9 importante identificar suas causas, isto \u00e9, a cadeia de eventos que o levou a acontecer. Algumas empresas publicam a root cause analysis ou a an\u00e1lise post-mortem para a comunidade como forma de compartilhar conhecimento e tamb\u00e9m por quest\u00f5es de transpar\u00eancia. Veja esta compila\u00e7\u00e3o para uma extensa lista de an\u00e1lises.","title":"Root cause analysis"},{"location":"fault/#como-alcancar-dependabilidade","text":"Falhas s\u00e3o um fato da vida, uma constante no desenvolvimento de sistemas. Mas se o objetivo \u00e9 a dependabilidade, precisamos de formas de lidar com falhas, previnindo , removendo e tolerando -as. A preven\u00e7\u00e3o de falhas acontece por meio de t\u00e9cnicas bem estabelecidas de engenharia. No caso de sistemas de software, modulariza\u00e7\u00e3o, linguagens de programa\u00e7\u00e3o fortemente tipadas e encapsulamento s\u00e3o passos essencias. Uso de especifica\u00e7\u00f5es formais, testadas ou provadas corretas, s\u00e3o outro passo neste sentido. Por exemplo, diversas empresas usam a linguagem TLA \\(^+\\) para verificar a corretude de seus algoritmos 2 . Outras t\u00e9cnicas envolvidas na preven\u00e7\u00e3o de falhas s\u00e3o an\u00e1lise est\u00e1tica, prova de teoremas, execu\u00e7\u00e3o simb\u00f3lica, teste de modelos, etc. Mesmo uma especifica\u00e7\u00e3o correta pode produzir um sistema com falhas pois a tradu\u00e7\u00e3o de especifica\u00e7\u00f5es formais para c\u00f3digo \u00e9 um passo complexo. Testes e manuten\u00e7\u00e3o do sistema permitem a remo\u00e7\u00e3o de falhas que passarem despercebidas pelas tentativas de preven\u00e7\u00e3o. Testes, contudo, apenas aumentam a confian\u00e7a no sistema, n\u00e3o sendo capazes de certificar a aus\u00eancia de problemas. Assim, tenta-se desenvolver os sistemas de forma que, mesmo se falhas ainda estiverem presentes, seus efeitos n\u00e3o sejam percebidos como defeitos, isto \u00e9, sistemas que tenha toler\u00e2ncia a falhas (ou preven\u00e7\u00e3o de defeitos ). Para se alcan\u00e7ar toler\u00e2ncia a falhas \u00e9 necess\u00e1rio detectar e se recuperar de erros. Por exemplo, um sistema de arquivos com journal , como o Ext v3 , armazena informa\u00e7\u00e3o redundantemente e, quando detecta que os dados em sua forma principal est\u00e3o corrompidos, usa o journal para recuperar os dados, mascarando o erro. De acordo como Avizienis et al, temos as seguintes t\u00e9cnicas para tolerar falhas: Um sistema que sofra de falhas recorrentes \u00e9 um bom candidato a previs\u00e3o de falhas, em que se estima quando uma falha ocorrer\u00e1 baseado no hist\u00f3rico. Por exemplo, um sistema que sofra falha por uso excessivo de mem\u00f3ria a cada dez dias em uso, pode ser reiniciado no nono dia, em condi\u00e7\u00f5es controladas, para evitar problemas maiores enquanto a raz\u00e3o do uso excessivo de mem\u00f3ria \u00e9 corrigido.","title":"Como alcan\u00e7ar dependabilidade"},{"location":"fault/#classes-de-defeitos","text":"Para previnirmos e toleramos com falhas, precisamos entender como se manifestam e, para isso, uma classifica\u00e7\u00e3o \u00e9 essencial.","title":"Classes de Defeitos"},{"location":"fault/#quebra","text":"Falhas de quebra ( crash ) s\u00e3o falhas em que o componente para de funcionar, irreversivelmente. Uma vez que o componente cessa seu funcionamento, qualquer comunica\u00e7\u00e3o com o mesmo \u00e9 interrompida e pode dar bons indicativos da falha aos outros componentes. Em um sistema ass\u00edncrono, contudo, n\u00e3o h\u00e1 garantias de que esta detec\u00e7\u00e3o do defeito ser\u00e1 correta. Alguns sistemas, denominados fail-stop , for\u00e7am-se a parar de funcionar quando percebem um defeito, imitando uma quebra, e implementando um comportamento fail-fast . 3 Estes sistemas podem emitir um \"canto do cisne\" para permitir que outros componentes detectem o defeito. Ap\u00f3s pararem, alguns sistemas podem aplicar passos de recupera\u00e7\u00e3o e voltar a funcionar, no que \u00e9 denominado fail-recover . Ao retornar \u00e0 opera\u00e7\u00e3o, o processo poderia assumir uma nova identidade.","title":"Quebra"},{"location":"fault/#omissao","text":"Em um defeito de omiss\u00e3o ( omission failure ), um componente n\u00e3o executa alguma a\u00e7\u00e3o. Por exemplo, uma requisi\u00e7\u00e3o recebida por um servidor n\u00e3o \u00e9 executada, um disco n\u00e3o armazena os dados no meio magn\u00e9tico, ou uma mensagem n\u00e3o \u00e9 transmitida. Este tipo de defeito \u00e9 dif\u00edcil de ser identificado pois outros componentes n\u00e3o necessariamente tem acesso direto ao resultado da opera\u00e7\u00e3o. Por exemplo, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem, ent\u00e3o houve um defeito de omiss\u00e3o. Mas se a mensagem \u00e9 retransmitida at\u00e9 que tenha sua entrega confirmada, ent\u00e3o o defeito \u00e9 mascarado.","title":"Omiss\u00e3o"},{"location":"fault/#temporizacao","text":"Em sistemas em que h\u00e1 limites de tempo para a execu\u00e7\u00e3o de a\u00e7\u00f5es, uma viola\u00e7\u00e3o destes limites \u00e9 defeito de temporiza\u00e7\u00e3o . Por exemplo, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem, ent\u00e3o houve uma falha de omiss\u00e3o. Novamente considerando problemas de transmiss\u00e3o de mensagens, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem que deveria ser entregue dentro de 3ms, ent\u00e3o houve um defeito de omiss\u00e3o. Mas se a mensagem \u00e9 retransmitida at\u00e9 que tenha sua entrega confirmada, mas a mesma \u00e9 entregue com 5ms, ent\u00e3o o mesmo que ap\u00f3s o limite para ent\u00e3o o defeito \u00e9 mascarado como um defeito de temporiza\u00e7\u00e3o.","title":"Temporiza\u00e7\u00e3o"},{"location":"fault/#arbitrarios","text":"Um defeito arbitr\u00e1rio ou bizantino \u00e9 um no qual qualquer comportamento pode acontecer. Por exemplo, uma mensagem pode ser modificada, um servidor pode reiniciar-se constantemente, todos os dados podem ser apagados, ou acesso pode ser dado a quem n\u00e3o \u00e9 devido. Estes defeitos podem ser causados por agentes mal intencionados, como hackers e v\u00edrus.","title":"Arbitr\u00e1rios"},{"location":"fault/#hierarquia","text":"Fail-stop \\(\\subset\\) Quebra \\(\\subset\\) Omiss\u00e3o \\(\\subset\\) Temporiza\u00e7\u00e3o \\(\\subset\\) Arbitr\u00e1ria","title":"Hierarquia"},{"location":"fault/#falhas-intermitentes","text":"Algumas falhas fogem \u00e0 classifica\u00e7\u00e3o acima por terem um comportamento especial, se manifestando de forma intermitente, por causa de eventos esparsos como picos de energia, ou pelo comportamento emergente da intera\u00e7\u00e3o com outros sistemas. Heisenbug The name may seem to rhyme well with Heisenberg, but the Heisenbug is actually \"a bug that disappears or alters its behavior when one attempts to probe or isolate it.\" The Freenet Project describes a Heisenbug in certain Java virtual machines. Bohrbug The Bohrbug is a sort of antonym of the Heisenbug, as this bug does not disappear or alter its characteristics when it is researched. Mandelbug The Mandelbug, named after Benoit Mandelbrot (think Mandelbrot set), is a bug whose underlying causes are so complex and obscure as to make its behavior appear chaotic. Schroedinbug The Schroedinbug is a design or implementation bug in a program that doesn't manifest until someone reading source or using the program in an unusual way notices that it never should have worked, at which point the program promptly stops working for everybody until fixed. Here, an Office developer describes \"stupid SQL tricks\" to get rid of a \"classic Schroedinbug.\"","title":"Falhas intermitentes"},{"location":"fault/#correlacao-entre-falhas","text":"Algumas falhas s\u00e3o ativadas por entradas e, neste caso, mesmo que se tenha v\u00e1rias c\u00f3pias do mesmo sistema, todas falhar\u00e3o uma vez que a entrada problem\u00e1tica acontecer. Este \u00e9 um cen\u00e1rio em que as falhas n\u00e3o s\u00e3o independentes, mas correlatas. Para evit\u00e1-lo, podemos usar n-version programming , que consiste basicamente em ter m\u00faltiplas implement\u00e7\u00f5es do mesmo sistema desenvolvidas de forma independente, isto \u00e9, fazendo uso de um ou mais da seguintes op\u00e7\u00f5es: m\u00faltiplos times m\u00faltiplos sistemas operacionais m\u00faltiplas linguagens de programa\u00e7\u00e3o. Esta t\u00e9cnica \u00e9 interessante mais raramente usada, basicamente pelo seu alto custo. Al\u00e9m disso, erros de especifica\u00e7\u00e3o s\u00e3o reproduzidos e levam times diferentes a produzir erros iguais.","title":"Correla\u00e7\u00e3o entre falhas"},{"location":"fault/#redundancia-de-processos","text":"Se remover todas as possbilidades de defeitos de um componente \u00e9 algo dif\u00edcil, apostemos na toler\u00e2ncia a falhas. De forma geral, toler\u00e2ncia a falhas \u00e9 obtida por algum tipo de redund\u00e2ncia . Redund\u00e2ncia pode ser aplicada em v\u00e1rios n\u00edveis, por exemplo, gastando mais tempo na especifica\u00e7\u00e3o do projeto , ou montando um laborat\u00f3rio de testes mais pr\u00f3ximo do ambiente de produ\u00e7\u00e3o. Outra forma \u00f3bvia de redund\u00e2ncia \u00e9 a replica\u00e7\u00e3o de componentes. Por exemplo, pense no pneu estepe de um carro, no gerador de eletricidade de um hospital. Replica\u00e7\u00e3o permite remover os pontos \u00fanicos de falha (SPOF, Single Point of Failure ), ou seja, componentes n\u00e3o depend\u00e1veis. Seja como for, redund\u00e2ncia implica em mais custos, ent\u00e3o o grau de redund\u00e2ncia a ser utilizado depende de uma an\u00e1lise custo x benef\u00edcio. No caso de um sistema distribu\u00eddo, quando falamos em redund\u00e2ncia, normalmente falamos em processos redundantes, c\u00f3pias ou r\u00e9plicas, mesmo que n\u00e3o desevolvidos usando n-version programming Assim, com m\u00faltiplas c\u00f3pias, quando um processo apresenta um defeito, outro podem continuar executando o servi\u00e7o. Dois modos cl\u00e1ssicos de replica\u00e7\u00e3o s\u00e3o o prim\u00e1rio/c\u00f3pia e ativo . No caso da replica\u00e7\u00e3o prim\u00e1rio/c\u00f3pia , tamb\u00e9m conhecida como mestre/escravo , o prim\u00e1rio \u00e9 respons\u00e1vel por lidar com clientes e por informar c\u00f3pias das modifica\u00e7\u00f5es de estado. Como as atualiza\u00e7\u00f5es de estado fluem do prim\u00e1rio para a c\u00f3pia, \u00e9 poss\u00edvel que a c\u00f3pia n\u00e3o tenha o estado mais atual. Para visualizarmos melhor esta situa\u00e7\u00e3o, vejamos a replica\u00e7\u00e3o em cadeia , uma generaliza\u00e7\u00e3o de prim\u00e1rio/c\u00f3pia em que os processos se organizam em um sequ\u00eancia para executar opera\u00e7\u00f5es. Atualiza\u00e7\u00f5es no sistema s\u00e3o sempre direcionadas ao prim\u00e1rio , a cabe\u00e7a da sequ\u00eancia. Leituras , se absolutamente necessitarem dos dados escritos mais recentemente, tamb\u00e9m devem ser direcionadas \u00e0 cabe\u00e7a . Caso contr\u00e1rio, podem ser direcionadas aos processos na cauda , diminuindo a carga de trabalho na cabe\u00e7a. No caso da replica\u00e7\u00e3o ativa, as v\u00e1rias c\u00f3pias executam todos os comandos enviados para o sistema, estando assim todas aptas a continuar a executar o servi\u00e7o. A t\u00e9cnica de replica\u00e7\u00e3o de m\u00e1quinas de estados vista no cap\u00edtulo anterior \u00e9 uma materializa\u00e7\u00e3o da replica\u00e7\u00e3o ativa. Como vimos anteriormente, replica\u00e7\u00e3o de m\u00e1quinas de estados utiliza primitivas de comunica\u00e7\u00e3o em grupo, mas as vistas anteriormente n\u00e3o s\u00e3o funcionais principalmente por n\u00e3o serem tolerantes a falhas. Vejamos a porqu\u00ea \u00e9 dif\u00edcil desenvolver primitivas tolerantes a falhas.","title":"Redund\u00e2ncia de Processos"},{"location":"fault/#problemas-de-acordo","text":"H\u00e1 diversas primitivas de comunica\u00e7\u00e3o em grupo, das quais se destaca a difus\u00e3o at\u00f4mica , primitiva pela qual se pode facilmente implementar replica\u00e7\u00e3o de m\u00e1quina de estados. Difus\u00e3o at\u00f4mica, por sua vez, \u00e9 equivalente ao problema do consenso distribu\u00eddo , que est\u00e1 no cora\u00e7\u00e3o da classe de problemas de acordo . Problemas de acordo s\u00e3o aqueles em que processos devem concordar em quais a\u00e7\u00f5es executar. Dependendo do modelo computacional em que o problema deve ser resolvido, solu\u00e7\u00f5es v\u00e3o de triviais a imposs\u00edveis. Vejamos um exemplo.","title":"Problemas de Acordo"},{"location":"fault/#uma-historia-de-tres-exercitos","text":"Era uma vez uma cidade estado no alto de uma montanha. A despeito de sofrer de falta de \u00e1gua, afinal, estava no alto de uma montanha, a cidade era invejada pelos vizinhos. Como a cidade era muito bem fortificada, ela poderia se defender de qualquer ataque em uma \u00fanica frente . Se atacada em duas frentes , contudo, cairia. Sabendo disso, o rei de uma das cidades vizinhas resolveu tomar a cidade e repartiu suas for\u00e7as em dois ex\u00e9rcitos sob o comando de Alice (a sociedade \u00e9 muito feminista naquela \u00e9poca) e Basti\u00e3o (sim, Basti\u00e3o, n\u00e3o Bob). 4 Um complicador no ataque \u00e9 que a comunica\u00e7\u00e3o entre os dois ex\u00e9rcitos \u00e9 feita por mensageiros que devem contornar a montanha para alcan\u00e7ar o outro ex\u00e9rcito. O trajeto \u00e9 complexo e cheio de armadilhas e por isso mensageiros podem se perder e demorar um longo tempo para chegar ou at\u00e9 mesmo serem mortos e nunca entregarem suas mensagens. Alice, a comandante mais s\u00eanior, deve decidir quando atacar, pode exemplo simplesmente ordenando \" Atacar no dia 3, ao nascer do sol. \" Basti\u00e3o obedecer\u00e1 a ordem de atacar contanto que esteja certo de que Alice tamb\u00e9m atacar\u00e1, e \u00e9 justamente da\u00ed que vem a dificuldade do problema. Se mensagens podem ser perdidas, Alice n\u00e3o tem garantias de que Basti\u00e3o recebeu o comando e por isso n\u00e3o pode simplesmente considerar como certo o ataque de Basti\u00e3o. Como o problema pode ser resolvido? Uma resposta natural \u00e9 usar mensagens de confirma\u00e7\u00e3o . Isto \u00e9, quando Basti\u00e3o recebe uma ordem, envia um mensageiro de volta para Alice com uma confirma\u00e7\u00e3o da recep\u00e7\u00e3o. Alice ao receber tal mensagem, sabe que Basti\u00e3o executar\u00e1 a ordem, correto? Mas n\u00e3o \u00e9 t\u00e3o simples assim no caso da ordem de atacar. Lembre-se que qualquer ex\u00e9rcito que ataque sozinho, perder\u00e1, seja Alice ou Basti\u00e3o. Por isso, ao enviar uma mensagem de confirma\u00e7\u00e3o do ataque, Basti\u00e3o precisa estar certo de que Alice a recebeu, ou atacar\u00e1 sozinho. Novamente podemos apelar para uma mensagem de confirma\u00e7\u00e3o ou, neste caso, uma confirma\u00e7\u00e3o da confirma\u00e7\u00e3o. E o problema se reinicia... Paradoxo dos 2 Ex\u00e9rcitos \\(A\\) e \\(B\\) devem concordar na hora do ataque. \\(A\\) ataca se estiver certo que \\(B\\) atacar\u00e1. \\(B\\) ataca se estiver certo que \\(A\\) atacar\u00e1. A comunica\u00e7\u00e3o por troca de mensagens. Mensagens podem ser arbitrariamente atrasadas. Mensagens podem ser perdidas. Como um ex\u00e9rcito tem certeza que o outro ir\u00e1 atacar? Suponhamos que h\u00e1 um algoritmo correto que executa uma sequ\u00eancia finita de troca de mensagens em que ao final tanto Alice quanto Basti\u00e3o est\u00e3o seguros, e corretos em sua seguran\u00e7a, de que o outro tamb\u00e9m atacar\u00e1. Seja \\(n\\) o n\u00famero m\u00e1ximo de mensagens trocadas. Em uma execu\u00e7\u00e3o em que todas as \\(n\\) mensagens poss\u00edveis s\u00e3o usadas, suponha sem perda de generalidade que Alice enviou a \\(n\\) -\u00e9sima mensagem. Observe que, do ponto de vista de Alice, uma execu\u00e7\u00e3o do algoritmo em que a nenhuma mensagem \u00e9 perdida, \u00e9 indistingu\u00edvel de uma execu\u00e7\u00e3o em que a \\(n\\) -\u00e9sima mensagem \u00e9 perdida. Dado que ao final da primeira execu\u00e7\u00e3o completa Alice ataca , no final da execu\u00e7\u00e3o onde a mensagem \\(n\\) \u00e9 perdida, Alice tamb\u00e9m deve atacar. Mas se o algoritmo \u00e9 correto, ent\u00e3o tamb\u00e9m Basti\u00e3o ataca , mesmo sem ter recebido a en\u00e9sima mensagem. Logo, a en\u00e9sima mensagem \u00e9 desnecess\u00e1ria ao algoritmo, que deve funcionar com \\(n-1\\) mensagens. Repetindo-se o argumento mais \\(n-1\\) vezes, temos que o algoritmo deve funcionar com zero mensagens, o que \u00e9 um absurdo . Logo n\u00e3o existem algoritmos corretos para o problema como definido, isto \u00e9, em que mensagens podem ser perdidas; \u00e9 imposs\u00edvel resolver o problema. Apesar de ser imposs\u00edvel resolver este problema aparentemente simples, devemos faz\u00ea-lo frequentemente no mundo real. Como reconciliar estes dois fatos?","title":"Uma hist\u00f3ria de tr\u00eas ex\u00e9rcitos"},{"location":"fault/#impossibilidade","text":"Quando dizemos que \u00e9 imposs\u00edvel resolver um problema queremos dizer que \u00e9 imposs\u00edvel produzir um algoritmo que sempre levar\u00e1 a uma resposta correta . Isto quer dizer que podemos produzir algoritmos, mas ou eles \u00e0s vezes levar\u00e3o a respostas incorretas ou eles \u00e0s vezes n\u00e3o levar\u00e3o a respostas ; ambos podem ser \u00fateis na pr\u00e1tica. Por exemplo, ainda no problema dos ex\u00e9rcitos tentando tomar a cidade, suponha que em vez de mandar um \u00fanico mensageiro com a ordem de ataque, Alice envie 100, ou 200, ou 1000. A confian\u00e7a de Alice de que Basti\u00e3o tamb\u00e9m atcaria, seria muito maior e n\u00e3o precisaria receber uma confirma\u00e7\u00e3o de entrega de mensagens. Esta abordagem faria com com que o ataque funcionasse com uma certa probabilidade , mas com uma pequena probabilidade \\(P\\) de levar a um ataque fracassado, onde \\(P\\) pode ser feita t\u00e3o pequena quanto se \"queira\" . Resultados de impossibilidade abundam na \u00e1rea de computa\u00e7\u00e3o distribu\u00edda 5 e n\u00e3o podem nos desencorajar de continuar a buscar solu\u00e7\u00f5es pr\u00e1ticas.","title":"Impossibilidade"},{"location":"fault/#consenso","text":"O problema que os comandantes est\u00e3o tentando resolver \u00e9, essencialmente, o problema do Consenso Distribu\u00eddo. Neste problema, cada um de um conjunto de processos prop\u00f5e um \u00fanico valor, sua proposta . O objetivo \u00e9 decidir um dentre os valores propostos, garantindo as seguintes propriedades. Validade: Somente um valor proposto pode ser decidido. Acordo: Se um processo decide-se por \\(v\\) e outro por \\(w\\) , ent\u00e3o \\(v = w\\) Termina\u00e7\u00e3o: Todo processo n\u00e3o defeituoso decide-se. Um processo \u00e9 defeituoso se apresentou um defeito; como estamos considerando apenas defeitos do tipo quebra, um processo \u00e9 defeituso se ele parou de funcionar. Um processo que n\u00e3o \u00e9 defeituoso \u00e9 um processo correto. \u00c9 imposs\u00edvel resolver deterministicamente o problema do consenso em sistema ass\u00edncrono sujeito a falhas 6 . Mas o consenso \u00e9 resolvido frequentemente em sistemas ass\u00edncronos sujeitos a falhas. Isso porque normalmente estes sistemas se comportam sincronamente. H\u00e1 diversos algoritmos de consenso que terminam quando o sistema se comporta bem, sendo os mais famosos, atualmente, Raft e Paxos A grande raz\u00e3o para que seja imposs\u00edvel chegar a um acordo entre processos neste modelo \u00e9 a impossibilidade de diferenciar processos defeituosos de processos corretos mas lentos. Em termos do paradoxo dos 2 generais, a resposta do comandante n\u00e3o chegou porqu\u00ea ele morreu ou porqu\u00ea ele est\u00e1 demorando para responder? Os detectores de defeito abstraem este problema.","title":"Consenso"},{"location":"fault/#detectores-de-defeitos-de-defeito-nao-confiaveis","text":"Chandra e Toueg 7 introduziram o conceito de Detectores de Defeitos . Um detector de defeitos pode ser visto como or\u00e1culo distribu\u00eddo , com m\u00f3dulos acoplados aos processos do sistema e que trabalha determinando o estado funcional dos outros processos. Todo figura igual \u00e0 da disserta\u00e7\u00e3o. Chandra e Toueg classificaram os detectores de defeitos segundo suas caracter\u00edsticas de completude ( completeness ) e acur\u00e1cia ( accuracy ), ou seja, a capacidade de suspeitar de um processo defeituoso e a capacidade de n\u00e3o suspeitar de um processo correto, respectivamente. Alguns n\u00edveis destas propriedades s\u00e3o descritos a seguir: Completude Forte - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por todos os processos corretos. Completude Fraca - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por algum processo correto. Precis\u00e3o Forte - Todos os processos s\u00e3o suspeitos somente ap\u00f3s terem apresentado defeito. Precis\u00e3o Fraca - Algum processo correto nunca \u00e9 suspeito de ter apresentado defeito. Precis\u00e3o Eventual Forte - A partir de algum instante futuro, todos os processos s\u00e3o suspeitos somente ap\u00f3s apresentarem defeito. Precis\u00e3o Eventual Fraca - A partir de algum instante futuro, algum processo ativo nunca \u00e9 suspeito antes de ter apresentado defeito. Um detector ideal seria um com Completude Forte e Precis\u00e3o Forte, pois detectaria somente processos defeituosos e todos os processos defeituosos. Este detector \u00e9 conhecido como \\(P\\) ou Perfect . Infelizmente os detectores perfeitos s\u00f3 podem ser implementados em sistemas s\u00edncronos, onde se pode confiar que a falta de uma mensagem implica em que a mensagem n\u00e3o ser\u00e1 entregue por qu\u00ea o remetente deve ser defeituosos. Assim, \u00e9 preciso se focar em detectores n\u00e3o perfeitos ou n\u00e3o confi\u00e1veis . Em ambientes parcialmente s\u00edncronos , ou seja, ass\u00edncronos aumentados com algum tipo de sincronia, j\u00e1 poss\u00edvel implementar detectores n\u00e3o confi\u00e1veis. Por exemplo, se os processos disp\u00f5em de temporizadores precisos, um detector pode contar a passagem do tempo nos intervalos de comunica\u00e7\u00e3o com outros processos e, considerando um limite de tempo para estes intervalos, tentar determinar se tais processos encontram-se defeituosos ou n\u00e3o. Esta determina\u00e7\u00e3o \u00e9 por certo imprecisa, e os detectores podem voltar atr\u00e1s em suas suspeitas t\u00e3o logo percebam um erro. Entretanto, a despeito desta incerteza, a informa\u00e7\u00e3o provida por estes detectores j\u00e1 pode ser suficiente para que se alcance o consenso, salvo uma restri\u00e7\u00e3o de que a maioria dos processos n\u00e3o sofra defeitos. Maioria Adicionar prova. Chandra, Hadzilacos e Toueg demonstram que detector mais fraco com o qual se pode resolver consenso tem as propriedades de Completude Fraca e Acur\u00e1cia Eventual Fraca. 8 Este detector, conhecido como \\(\\Diamond W\\) , ou Eventual Weak , e \u00e9 implement\u00e1vel em sistemas nos quais h\u00e1 um limite superior de tempo para a transmiss\u00e3o de mensagens, mesmo que este limite seja desconhecido . V\u00e1rios protocolos de consenso utilizam o detector equivalente, \\(\\Diamond S\\) , equivalente ao \\(\\Diamond W\\) mas com completude forte. Estes protocolos s\u00e3o escritos de forma que se o limite superior n\u00e3o existe, o protocolo n\u00e3o termina e um resultado errado nunca \u00e9 alcan\u00e7ado .","title":"Detectores de Defeitos de Defeito n\u00e3o Confi\u00e1veis"},{"location":"fault/#difusao-totalmente-ordenada","text":"Se pudermos resolver o consenso, podemos ent\u00e3o resolver o problema da difus\u00e3o at\u00f4mica e com ela implementar a replica\u00e7\u00e3o de m\u00e1quinas de estados. Relembrando, na difus\u00e3o Totalmente Ordenada (Total Order Multicast) temos que: Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem. Para fazermos isso, precisamos primeiro formalizar as primitivas em v\u00e1rios n\u00edveis da resolu\u00e7\u00e3o do problema. No n\u00edvel do canal de comunica\u00e7\u00e3o, da rede, processos enviam e recebem mensagens. No n\u00edvel do consenso, processos fazem propostas e aprendem um valor decidido. Para chegar a uma \u00fanica decis\u00e3o, v\u00e1rias mensagens podem ser enviadas e recebidas. No n\u00edvel da difus\u00e3o at\u00f4mica, mensagens s\u00e3o difundidas e entregues . Se implementado sobre o consenso, para uma difus\u00e3o ser bem sucedida, uma inst\u00e2ncia de consenso \u00e9 necess\u00e1ria. Primitivas de comunica\u00e7\u00e3o enviar & receber ( send & receive ) - rede propor & decidir ( propose & decide ) - consenso difundir & entregar ( broadcast & deliver ) - difus\u00e3o Dado infinitas inst\u00e2ncias de consenso, pode-se us\u00e1-las para resolver difus\u00e3o at\u00f4mica usando o seguinte procedimento: Ordene as inst\u00e2ncias de consenso. Para difundir mensagem \\(m\\) , proponha a mensagem na menor inst\u00e2ncia \\(i\\) em que n\u00e3o tiver visto uma decis\u00e3o. Se a decis\u00e3o de \\(i\\) n\u00e3o \u00e9 \\(m\\) , volte para o passo anterior. Entregue as decis\u00f5es na ordem das inst\u00e2ncias. No exemplo a seguir, duas mensagens, \\(m\\) e \\(m'\\) foram difundidas pelas aplica\u00e7\u00f5es App1 e App2, respectivamente, por meio do m\u00f3dulo de difus\u00e3o at\u00f4mica junto a cada aplica\u00e7\u00e3o. O m\u00f3dulo de difus\u00e3o determina qual a menor inst\u00e2ncia de consenso ainda n\u00e3o decidida, azul, em que prop\u00f5em as mensagens. Ao final da inst\u00e2ncia de conseno, \\(m\\) \u00e9 decidida e \u00e9 entregue pelos m\u00f3dulos de difus\u00e3o. O m\u00f3dulo ABCast2 insiste na difus\u00e3o de \\(m'\\) , propondo-a na pr\u00f3xima inst\u00e2ncia, vermelha, que decide \\(m'\\) e leva esta mensagem a ser entregue. sequenceDiagram participant App1 participant ABCast1 participant Cons1 participant Cons3 participant Cons2 participant ABCast2 participant App2 App1 -->>+ ABCast1: difundir m App2 -->>+ ABCast2: difundir m' rect rgb(100,255,255) ABCast1 ->>+ Cons1: propor m na inst 1 ABCast2 ->>+ Cons2: propor m' na inst 1 Cons1 ->>- ABCast1: decidir m Cons2 ->>- ABCast2: decidir m end ABCast1 -->>- App1: entregar m ABCast2 -->> App2: entregar m rect rgba(255,0,0,.5) ABCast2 ->>+ Cons2: propor m' na inst 2 Cons1 ->> ABCast1: decidir m' Cons2 ->>- ABCast2: decidir m' end ABCast1 -->> App1: entregar m' ABCast2 -->>- App2: entregar m' Ambas as aplica\u00e7\u00f5es, embora tivessem inten\u00e7\u00f5es diferentes sobre qual deveria ser a pr\u00f3xima mensagem entregue, entregam-nas na mesma ordem, isto \u00e9, primeiro \\(m\\) e depois \\(m'\\) . Se forem usadas como entrada para algum processamento, na ordem em que foram entregues, as aplica\u00e7\u00f5es chegar\u00e3o ao mesmo estado, em algum momento.","title":"Difus\u00e3o Totalmente Ordenada"},{"location":"fault/#estudo-de-caso-do-raft","text":"Raft \u00e9 um protocolo de difus\u00e3o at\u00f4mica associado a um protocolo de elei\u00e7\u00e3o de l\u00edderes. L\u00edderes s\u00e3o eleitos para mandatos pelo voto de uma maioria de processos, o que garante que nunca existir\u00e3o dois l\u00edderes para um mesmo mandato. Um mandato se estende enquanto o l\u00edder mantiver seus seguidores cientes de sua presen\u00e7a, o que faz pelo envio peri\u00f3dico de heartbeats . Atrasos na comunica\u00e7\u00e3o ou a falha do l\u00edder atual levam a uma suspeita de que o l\u00edder falhou, levando a nova elei\u00e7\u00e3o e novo mandado. A comunica\u00e7\u00e3o necess\u00e1ria para implementar a difus\u00e3o at\u00f4mica acontece em piggyback nos heartbeats . No tutorial The Secret lives of data , podemos ver com mais detalhes como o protocolo funciona. O tutorial, entretando, foge da nomenclatura padr\u00e3o da \u00e1rea usando log-replication no lugar de difus\u00e3o at\u00f4mica (ou totalmente ordenada).","title":"Estudo de Caso do Raft"},{"location":"fault/#estudo-de-caso-paxos","text":"Paxos S\u00ednodo (Synod): consenso Paxos: Difus\u00e3o At\u00f4mica","title":"Estudo de Caso: Paxos"},{"location":"fault/#outras-ordenacoes","text":"Como colocado diversas vezes, se todos os processos executam a mesma sequ\u00eancia de comandos determin\u00edsticos, todos avan\u00e7am pelos mesmos estados, implementando a t\u00e9cnica da replica\u00e7\u00e3o de m\u00e1quinas de estados. Se usada em um sistema de arquivos, por exemplo, a seguinte sequ\u00eancia de comandos levar\u00e1 sempre ao estado final em que h\u00e1 um arquivo /tmp/file2 e uma pasta denominada /dir1 . touch /tmp/file1 echo \"teste testando\" >> /tmp/file2 rm /tmp/file1 mkdir /dir1 H\u00e1 outras ordens dos mesmos comandos que levariam ao mesmo efeito, como a seguinte. Alguns protocolos de replica\u00e7\u00e3o de m\u00e1quinas de estados permitem que reordena\u00e7\u00f5es ocorram, desde que n\u00e3o afetem o resultado final dos comandos. Contudo, estes protocolos s\u00e3o mais complexos de se implementar e por isso raramente usados. echo \"teste testando\" >> /tmp/file2 mkdir /dir1 touch /tmp/file1 rm /tmp/file1","title":"Outras Ordena\u00e7\u00f5es"},{"location":"fault/#arcaboucos-para-coordenacao","text":"H\u00e1 muitas formas de se usar algoritmos de acordo em uma aplica\u00e7\u00e3o, embora se recomente que seu escopo seja minimizado a um n\u00facleo onde a consist\u00eancia forte \u00e9 absolutamente necess\u00e1ria e que este n\u00facleo seja usado para suportar outras partes do sistema 10 . Seja implementando a replica\u00e7\u00e3o de m\u00e1quinas de estados, seja implementando um core, ou qualquer outra abstra\u00e7\u00e3o sobre algoritmos de acordo ou comunica\u00e7\u00e3o em grupo, voc\u00ea tem a op\u00e7\u00e3o de implementar o protocolo zero, uma tarefa ingrata 9 . Felizmente, tamb\u00e9m tem a op\u00e7\u00e3o de usar arcabou\u00e7os prontos tanto para para comunica\u00e7\u00e3o em grupo quanto para diversos outros problemas de coordena\u00e7\u00e3o comuns em sistemas distribu\u00eddos.","title":"Arcabou\u00e7os para coordena\u00e7\u00e3o"},{"location":"fault/#estudo-de-caso-copycat","text":"Copycat \u00e9 um arcabou\u00e7o de replica\u00e7\u00e3o de m\u00e1quinas de estados implementada pela P\u00e1gina Web Atomix. Na base do Copycat est\u00e1 uma implementa\u00e7\u00e3o do Raft. Sobre o Raft, uma API simples permite a cria\u00e7\u00e3o de m\u00e1quinas de estados replicadas usando uma API simples mas moderna, com uso pesado de lambdas , futures , e do estilo fluent de encadeamento de invoca\u00e7\u00f5es. Lambda Classe com um \u00fanico m\u00e9todo. 1 2 3 4 5 6 7 8 class Tarefa implements Runnable { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } } new Thread ( new Tarefa ()). start (); Classe an\u00f4nima - uso \u00fanico 1 2 3 4 5 6 new Thread ( new Runnable () { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } }). start (); Lambda 1 2 3 4 new Thread (() -> { while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); }). start (); Fluent Encadeamento 1 2 3 4 5 Collection < Pessoa > c = ...; c . stream () . filter ( p -> p . idade > 33 ) . map ( Pessoa :: sobrenomeNome ) //.map(p -> p.sobrenomeNome()) . forEach ( s -> System . out . println ( s )); Future Promessa de computa\u00e7\u00e3o e resultado. 1 2 ExecutorService executor = Executors . newSingleThreadExecutor (); Future < Integer > futFib = executor . submit (() -> { return Fibonacci ( 217 )}; Quando ser\u00e1 executado? Em algum momento. Como pegar o resultado? 1 2 3 4 while ( ! futFib . isDone ()) System . out . println ( \"tah calculando...\" ); int fib217 = futFib . get (); Em qual thread? Em algum thread. Depende do Executor Service usado. H\u00e1 v\u00e1rias vers\u00f5es do Copycat dispon\u00edveis, com vantagens e desvantagens. Vers\u00f5es Vers\u00e3o 1.1.4 Baseado em http://atomix.io/copycat/docs/getting-started/ e https://www.baeldung.com/atomix C\u00f3digo funcional em https://github.com/pluxos/atomix_labs Documenta\u00e7\u00e3o oficial removida Vers\u00e3o >= 2 Melhor desempenho Documenta\u00e7\u00e3o ruim ou inexistente https://github.com/atomix/atomix Vers\u00e3o 3 em Go evolu\u00e7\u00e3o r\u00e1pida Aqui usaremos a vers\u00e3o 1.1.4, que apesar de antiga, \u00e9 a melhor documentada atualmente, pelo tutorial referenciado acima. Clone e compile o projeto Instale depend\u00eancias: git maven JDK >= 1.8 git clone https://github.com/pluxos/atomix_labs cd atomix_labs cd replication mvn compile mvn test Voc\u00ea deve ver uma sa\u00edda semelhante \u00e0 seguinte, o que quer dizer que seu c\u00f3digo est\u00e1 compilando perfeitamente. 1 2 3 4 5 6 7 8 9 Tests run: 1 , Failures: 0 , Errors: 0 , Skipped: 0 [ INFO ] --------------------------------------- [ INFO ] BUILD SUCCESS [ INFO ] --------------------------------------- [ INFO ] Total time: 6 .898 s [ INFO ] Finished at: 2017 -10-25T08:38:08-02:00 [ INFO ] Final Memory: 15M/159M [ INFO ] --------------------------------------- Antes de come\u00e7ar a escrever suas pr\u00f3rpia m\u00e1quinas de estado, familiarize-se com a estrutura do projeto em https://github.com/pluxos/atomix_labs/tree/master/replication/src/main/java/atomix_lab/state_machine Observe que h\u00e1 tr\u00eas pastas: type - tipos dos dados mantidos pela replica (Edge e Vertex) Os tipos s\u00e3o serializable para que o Java saiba como transform\u00e1-los em bytes. command - estruturas que cont\u00eam informa\u00e7\u00f5es para modificar os tipos Os comandos ser\u00e3o enviadas do cliente para o cluster e s\u00e3o naturalmente serializable. client - cria comandos e os envia para serem executados no cluster Respostas podem ser esperadas s\u00edncrona ou assincronamente. server - recebe os comandos na ordem definida pelo Raft e os executa O projeto foi constru\u00eddo seguindo as instru\u00e7\u00f5es no tutorial mencionado antes, saltando-se a parte dos snapshots, isto \u00e9: crie um projeto maven eclipse tem template para isso adicione depend\u00eancias no pom.xml como so criei um projeto, coloquei as depend\u00eancias tanto do cliente quando do servidor defina Command que modifiquem o estado das r\u00e9plicas defina Queries que consultem o estado das r\u00e9plicas implemente a r\u00e9plica para lidar com os comandos implemente o cliente para emitir comandos Para executar um servidor, voc\u00ea precisa passar diversos par\u00e2metros identificador do processo (inteiro) IP do processo com identificador 0 porta do processo com identificar 0 IP do processo com identificador 1 porta do processo com identificar 1 ... Sabendo seu identificador, o servidor sabe em qual porta escutar e em quais IP/porta se conectar para se comunicar com os outros servidores. Para testar o projeto, execute tr\u00eas servidores, em tr\u00eas terminais distintos. Usando o maven, da linha de comando, basta executar os seguintes comandos[^\\]: 1 2 3 4 5 6 7 8 9 10 11 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"0 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"1 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"2 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" O cliente n\u00e3o precisa de um identificador, apenas dos pares IP/porta dos servidores. Por exemplo, use o comando: 1 2 3 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.client.GraphClient\" \\\\ -Dexec.args = \"127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" Exerc\u00edcio Uma vez executado o projeto, modifique-o para incluir uma nova opera\u00e7\u00e3o ( Command ) e nova consulta ( Query ), de sua escolha.","title":"Estudo de caso: Copycat"},{"location":"fault/#estudo-de-caso-ratis","text":"Ratis \u00e9 um arcabou\u00e7o de coordena\u00e7\u00e3o atualmente encubado como um projeto no Apache . Embora mal documentado, o projeto tem alguns exemplos que demonstram como usar abstra\u00e7\u00f5es j\u00e1 implementadas. A seguir veremos um passo-a-passo, baseado nestes exemplos, de como usar o Ratis para implementar uma m\u00e1quina de estados replicada. Crie um novo projeto Maven com o nome ChaveValor (eu estou usando IntelliJ, mas as instru\u00e7\u00f5es devem ser semelhantes para Eclipse). Abra o arquivo pom.xml do seu projeto e adicione o seguinte trecho, com as depend\u00eancias do projeto, incluindo o pr\u00f3prio Ratis. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 <dependencies> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-server --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-server </artifactId> <version> 1.0.0 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-netty --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-netty </artifactId> <version> 1.0.0 </version> </dependency> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-grpc </artifactId> <version> 1.0.0 </version> </dependency> <dependency> <groupId> com.beust </groupId> <artifactId> jcommander </artifactId> <version> 1.78 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> 1.7.25 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-log4j12 </artifactId> <version> 1.7.25 </version> <scope> compile </scope> </dependency> <dependency> <groupId> log4j </groupId> <artifactId> log4j </artifactId> <version> 1.2.17 </version> </dependency> </dependencies> Adicione tamb\u00e9m o plugin Maven e o plugin para gerar um .jar com todas as depend\u00eancias. Observe que estou usando Java 14, mas voc\u00ea pode mudar para a sua vers\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> ${maven.compiler.version} </version> <configuration> <source> 14 </source> <target> 14 </target> </configuration> </plugin> <plugin> <artifactId> maven-assembly-plugin </artifactId> <executions> <execution> <phase> package </phase> <goals> <goal> single </goal> </goals> </execution> </executions> <configuration> <descriptorRefs> <descriptorRef> jar-with-dependencies </descriptorRef> </descriptorRefs> </configuration> </plugin> </plugins> </build> Crie uma nova classe denominada Cliente no arquivo Cliente.java . Nesta classe, iremos criar um objeto RaftClient que ser\u00e1 usado para enviar opera\u00e7\u00f5es para os servidores. Esta classe \u00e9 importada juntamente com outras v\u00e1rias depend\u00eancias, adicionadas no pom.xml , que devemos instanciar antes do RaftClient . Neste exemplo eu coloco praticamente todos os par\u00e2metros de configura\u00e7\u00e3o do Ratis hardcoded para simplificar o c\u00f3digo. Obviamente que voce deveria ser estes par\u00e2metros como argumentos para o programa ou de um arquivo de configura\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.apache.ratis.client.RaftClient ; import org.apache.ratis.conf.Parameters ; import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcFactory ; import org.apache.ratis.protocol.* ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.nio.charset.Charset ; import java.util.HashMap ; import java.util.Map ; public class Cliente { O campo raftGroupId identifica um cluster Ratis; isso quer dizer que um memsmo processo pode participar de v\u00e1rios clusters , mas aqui nos focaremos em apenas um. O valor do campo deve ter exatamente caracteres, o que soma 32 bytes em java, e ser\u00e1 interpretado como um UUID . id2addr \u00e9 um mapa do identificador de cada processo no cluster para seu endere\u00e7o IP + Porta. Aqui usei v\u00e1rias portas distintas porqu\u00ea todos os processos est\u00e3o rodando na mesma m\u00e1quina, mas se estivesse executando em m\u00e1quinas distintas, com IP distintos, poderia usar a mesma porta em todos. addresses \u00e9 uma lista de RaftPeer constru\u00edda a parti de id2addr . O campo raftGroup \u00e9 uma refer\u00eancia a todos os servidores, associados ao identificador do grupo, raftGroupId . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void main ( String args [] ) throws IOException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> new RaftPeer ( RaftPeerId . valueOf ( e . getKey ()), e . getValue ())) . collect ( Collectors . toList ()); final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), addresses ); Uma vez criado o grupo, criamos o cliente usando a f\u00e1brica retornada por RaftClient.newBuilder() . A f\u00e1brica deve ser configurada com os dados do grupo e o tipo de transporte, neste caso gRPC. Tamb\u00e9m \u00e9 necess\u00e1rio o identificador do processo que est\u00e1 se conectando ao grupo; neste caso, usamos um identificador aleat\u00f3rio qualquer, diferente do que faremos com os servidores. 1 2 3 4 5 6 7 8 RaftProperties raftProperties = new RaftProperties (); RaftClient client = RaftClient . newBuilder () . setProperties ( raftProperties ) . setRaftGroup ( raftGroup ) . setClientRpc ( new GrpcFactory ( new Parameters ()) . newRaftClientRpc ( ClientId . randomId (), raftProperties )) . build (); Uma vez criado o cliente, podemos fazer invoca\u00e7\u00f5es de opera\u00e7\u00f5es nos servidores. Cada opera\u00e7\u00e3o ser\u00e1 invocada em todos os servidores, na mesma ordem. Este prot\u00f3tipo suporta duas opera\u00e7\u00f5es, add e get . A opera\u00e7\u00e3o add \u00e9 codificada como uma String , add:k:v , onde k e v s\u00e3o do tipo String . add:k:v adiciona uma entrada em um mapa implementado pelo nosso servidor com chave k e valor v . J\u00e1 a opera\u00e7\u00e3o get:k recupera o valor v associado \u00e0 chave k , se presente no mapa. O m\u00e9todo RaftClient::send \u00e9 usado para enviar modifica\u00e7\u00f5es para as r\u00e9plicas e deve, necessariament, passar pelo protocolo Raft. J\u00e1 o m\u00e9todo RaftClient::sendReadOnly \u00e9 usado para enviar consultas a qualquer das r\u00e9plicas. Ambos os m\u00e9todos codificam o comando sendo enviado ( add:k:v ou get:k ) no formato interno do Ratis para as r\u00e9plicas e retorna um objeto RaftClientReply , que pode ser usado para pegar a resposta da opera\u00e7\u00e3o. O c\u00f3digo \u00e9 auto explicativo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 RaftClientReply getValue ; String response ; switch ( args [ 0 ] ){ case \"add\" : getValue = client . send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"get\" : getValue = client . sendReadOnly ( Message . valueOf ( \"get:\" + args [ 1 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; default : System . out . println ( \"comando inv\u00e1lido\" ); } client . close (); } } Um vez criado o cliente, crie a classe Servidor , no arquivo Servidor.java ; a parte inicial do c\u00f3digo \u00e9 semelhante \u00e0 do cliente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcConfigKeys ; import org.apache.ratis.protocol.RaftGroup ; import org.apache.ratis.protocol.RaftGroupId ; import org.apache.ratis.protocol.RaftPeer ; import org.apache.ratis.protocol.RaftPeerId ; import org.apache.ratis.server.RaftServer ; import org.apache.ratis.server.RaftServerConfigKeys ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import org.apache.ratis.util.LifeCycle ; import java.io.File ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.util.Collections ; import java.util.HashMap ; import java.util.Map ; import java.util.concurrent.TimeUnit ; public class Servidor { //Parametros: myId public static void main ( String args [] ) throws IOException , InterruptedException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. //Setup for node all nodes. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> new RaftPeer ( RaftPeerId . valueOf ( e . getKey ()), e . getValue ())) . collect ( Collectors . toList ()); A primeira diferen\u00e7a vem na necessidade de identificar o servidor dentro do conjunto de servidores, o que \u00e9 feito com um RaftPeerId . Como cada servidor deve usar um identificador \u00fanico, do conjunto pr\u00e9-determinado em id2addr , o identificador \u00e9 passado como argumento para o programa, obrigatoriamente. 1 2 3 4 5 6 7 8 //Setup for this node. RaftPeerId myId = RaftPeerId . valueOf ( args [ 0 ] ); if ( addresses . stream (). noneMatch ( p -> p . getId (). equals ( myId ))) { System . out . println ( \"Identificador \" + args [ 0 ] + \" \u00e9 inv\u00e1lido.\" ); System . exit ( 1 ); } Encare a se\u00e7\u00e3o seguinte como uma receita, mas observe que o m\u00e9todo RaftServerConfigKeys.setStorageDir recebe o nome de uma pasta como argumento, que ser\u00e1 usada para armazenar o estado da m\u00e1quina de estados. Se voc\u00ea executar o servidor m\u00faltiplas vezes, a cada nova execu\u00e7\u00e3o o estado anterior do sistema ser\u00e1 recuperado desta pasta. Para limpar o estado, apague as pastas de cada servidor. 1 2 3 4 RaftProperties properties = new RaftProperties (); properties . setInt ( GrpcConfigKeys . OutputStream . RETRY_TIMES_KEY , Integer . MAX_VALUE ); GrpcConfigKeys . Server . setPort ( properties , 1000 ); RaftServerConfigKeys . setStorageDir ( properties , Collections . singletonList ( new File ( \"/tmp/\" + myId ))); A m\u00e1quina de estados em si \u00e9 especificada no pr\u00f3ximo excerto, em setStateMachine , que veremos a seguir. 1 2 3 4 5 6 7 8 //Join the group of processes. final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), id2addr ); RaftServer raftServer = RaftServer . newBuilder () . setServerId ( myId ) . setStateMachine ( new MaquinaDeEstados ()). setProperties ( properties ) . setGroup ( raftGroup ) . build (); raftServer . start (); Uma vez iniciado o servidor, basta esperar que ele termine antes de sair do programa. 1 2 3 4 5 while ( raftServer . getLifeCycleState () != LifeCycle . State . CLOSED ) { TimeUnit . SECONDS . sleep ( 1 ); } } } Vamos agora para a defini\u00e7\u00e3o da classe MaquinaDeEstados , no arquivo MaquinaDeEstados.java . Esta classe deve implementar a interface org.apache.ratis.statemachine.StateMachine e seus v\u00e1rios m\u00e9todos ou, mais simples, estende org.apache.ratis.statemachine.impl.BaseStateMachine , a abordagem que usaremos aqui. 1 2 public class MaquinaDeEstados extends BaseStateMachine { Por enquanto, ignoraremos o armazenamento do estado em disco, mantendo-o simplesmente em mem\u00f3ria no campo key2values , e simplesmente implementaremos o processamento de comandos, come\u00e7ando pela implementa\u00e7\u00e3o do m\u00e9todo query . Este m\u00e9todo \u00e9 repons\u00e1vel por implementar opera\u00e7\u00f5es que n\u00e3o alteram o estado da m\u00e1quina de estados, enviadas com o m\u00e9todo RaftClient::sendReadOnly . A \u00fanica query no nosso sistema \u00e9 o get . No c\u00f3digo, o conte\u00fado da requisi\u00e7\u00e3o enviada pelo cliente deve ser recuperado em quebrado em opera\u00e7\u00e3o ( get ) e chave , usando : como delimitador. Recuperado o valor associado \u00e0 chave, o mesmo \u00e9 colocado em um CompletableFuture e retornado. 1 2 3 4 5 6 7 8 9 10 private final Map < String , String > key2values = new ConcurrentHashMap <> (); @Override public CompletableFuture < Message > query ( Message request ) { final String [] opKey = request . getContent (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKey [ 0 ]+ \":\" + key2values . get ( opKey [ 1 ] ); LOG . debug ( \"{}: {} = {}\" , opKey [ 0 ] , opKey [ 1 ] , result ); return CompletableFuture . completedFuture ( Message . valueOf ( result )); } O m\u00e9todo applyTransaction implementa opera\u00e7\u00f5es que alteram o estado, como add , enviadas com o m\u00e9todo RaftClient::send . Da mesma forma que em get , a opera\u00e7\u00e3o deve ser recuperada em quebrada em opera\u00e7\u00e3o ( add ), chave e valor, usando : como delimitador. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableFuture < Message > applyTransaction ( TransactionContext trx ) { final RaftProtos . LogEntryProto entry = trx . getLogEntry (); final String [] opKeyValue = entry . getStateMachineLogEntry (). getLogData (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKeyValue [ 0 ]+ \":\" + key2values . put ( opKeyValue [ 1 ] , opKeyValue [ 2 ] ); final CompletableFuture < Message > f = CompletableFuture . completedFuture ( Message . valueOf ( result )); final RaftProtos . RaftPeerRole role = trx . getServerRole (); LOG . info ( \"{}:{} {} {}={}\" , role , getId (), opKeyValue [ 0 ] , opKeyValue [ 1 ] , opKeyValue [ 2 ] ); return f ; } Pronto, voc\u00ea j\u00e1 tem uma m\u00e1quina de estados replicada, bastando agora apenas compil\u00e1-la e execut\u00e1-la. Para compilar, de raiz do projeto execute o comando mvn package . A primeira vez que faz isso pode demorar um pouco pois v\u00e1rias depend\u00eancias s\u00e3o baixadas da Internet. Ao final da execu\u00e7\u00e3o do comando voc\u00ea deveria ver algo semelhante ao seguinte 1 2 3 4 5 6 7 ... INFO ] ------------------------------------------------------------------------ [ INFO ] BUILD SUCCESS [ INFO ] ------------------------------------------------------------------------ [ INFO ] Total time: 4 .793 s [ INFO ] Finished at: 2020 -12-06T23:06:32-03:00 [ INFO ] ------------------------------------------------------------------------ Ent\u00e3o, em tr\u00eas terminais diferentes, execute os seguintes comandos: 1 2 3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p2 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p3 Para executar o cliente, em um outro terminal, fa\u00e7a, por exemplo, 1 2 3 4 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k1 testek1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get k1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k2 testek2 Todo o c\u00f3digo est\u00e1 dispon\u00edvel no Github Exer\u00edcio Adicionar opera\u00e7\u00f5es Passar opera\u00e7\u00e3o como par\u00e2metro do cliente.","title":"Estudo de caso: Ratis"},{"location":"fault/#estudo-de-caso-zookeeper","text":"Porqu\u00ea sistemas distribu\u00eddos s\u00e3o como zool\u00f3gicos, com animais de diversas esp\u00e9cies, sendo obrigados a conviver de forma anti-natural, foi criado o Zookeeper .","title":"Estudo de caso: Zookeeper"},{"location":"fault/#visao-geral","text":"O qu\u00ea? ZooKeeper is a centralized service for maintaining configuration information, naming , providing distributed synchronization , and providing group services . All of these kinds of services are used in some form or another by distributed applications . Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them, which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed. O arcabou\u00e7o foi criado pelo Yahoo! para servir como pe\u00e7a na constru\u00e7\u00e3o de sistemas distribu\u00eddos dentro da empresa. Por qu\u00ea? Coordination services are notoriously hard to get right. They are especially prone to errors such as race conditions and deadlock. The motivation behind ZooKeeper is to relieve distributed applications the responsibility of implementing coordination services from scratch. Mais tarde o sistema tornou-se Open Source e tornou-se parte de diversos projetos, tamb\u00e9m abertos e propriet\u00e1rios. A raz\u00e3o de seu sucesso, arrisco dizer, \u00e9 a simplicidade de sua API, semelhante a um sistema de arquivos. Como? ZooKeeper is a distributed , open-source coordination service for distributed applications . It exposes a simple set of primitives that distributed applications can build upon to implement higher level services for synchronization, configuration maintenance, and groups and naming. It is designed to be easy to program to, and uses a data model styled after the familiar directory tree structure of file systems*. It runs in Java and has bindings for both **Java and C . ZooKeeper allows distributed processes to coordinate with each other through a shared hierarchal namespace which is organized similarly to a standard file system . The name space consists of data registers - called znodes , in ZooKeeper parlance - and these are similar to files and directories . Unlike a typical file system, which is designed for storage, ZooKeeper data is kept in-memory , which means ZooKeeper can achieve high throughput and low latency numbers. O sistema de arquivos do Zookeeper tem n\u00f3s denominados znodes , em refer\u00eancia aos i-nodes do mundo Unix. O znode raiz \u00e9 denominado / e um filho da raiz nomeado teste \u00e9 referido como /teste . Cada znode pode ser visto como arquivo e diret\u00f3rio ao mesmo tempo. O sistema de arquivos do Zookeeper \u00e9 replicado em v\u00e1rios n\u00f3s. Znodes s\u00e3o manipulados, essencialmente, por 4 opera\u00e7\u00f5es C: create R: get U: set D: delete ls *: get children Znodes s\u00e3o lidos e escritos sempre integralmente. Isto \u00e9, n\u00e3o se pode escrever apenas parte do conte\u00fado do \"arquivo\". Por isso, recomenda-se que os arquivos sejam sempre pequenos, onde pequeno \u00e9 relativo. Os comandos que atualizam dados, como create e delete s\u00e3o enviados para todas as r\u00e9plicas via o protocolo ZAB, Zookeeper Atomic Broadcast, que entrega as mensagens de forma totalmente ordenada. O sistema de arquivos \u00e9, portanto, uma m\u00e1quina de estados replicada. J\u00e1 comandos de leitura s\u00e3o executados direto na r\u00e9plica que os recebe. Por causa do custo em termos de mensagens trocadas entre os processos para mensagens de atualiza\u00e7\u00e3o e pelo baixo custo das mensagens de leitura, o zookeeper \u00e9 recomendado para cargas de trabalho com poucas escritas. Desempenho ZooKeeper is fast [...] and it performs best where reads are more common than writes, at ratios of around 10:1. O gr\u00e1fico seguinte mostra como o desempenho do sistema varia com o n\u00famero de processos. No eixo Y, a quantidade de requisi\u00e7\u00f5es processadas por segundo, ou seja, a vaz\u00e3o. No eixo X, a percentagem das requisi\u00e7\u00f5es do teste que s\u00e3o leituras e, portanto, repondidas na r\u00e9plica em que s\u00e3o recebidas. As diferentes curvas mostram diferentes configura\u00e7\u00f5es do sistema, indo de 3 a 12 r\u00e9plicas. Em geral, todas as configura\u00e7\u00f5es apresentam melhor desempenho quando h\u00e1 uma percentagem maior de leituras. Mas observe como as curvas se invertem, se focando primeiro na curva para 3 servidores: quando todas as opera\u00e7\u00f5es s\u00e3o de escrita, e portanto precisam passar pelo protocolo de difus\u00e3o at\u00f4mica, esta curva apresenta os melhores resultados. Isto ocorre porqu\u00ea o overhead de executar o protocolo \u00e9 mais baixo entre 3 servidores que entre 13. Em compensa\u00e7\u00e3o, quando temos mais leituras, que n\u00e3o precisam de sincroniza\u00e7\u00e3o, ent\u00e3o ter mais servidores \u00e9 mais vantajoso pois sobre menos carga de trabalho para cada servidor.","title":"Vis\u00e3o Geral"},{"location":"fault/#laboratorio","text":"Instale o Zookeeper em sua m\u00e1quina seguindo estas instru\u00e7\u00f5es. Baixe: wget www-eu.apache.org/dist/zookeeper/zookeeper-3.6.2 Descomprima: tar xvzf zookeeper*.tgz Entre na pasta criada. Configure: copie o arquivo conf/zoo_sample.cfg para conf/zoo.cfg Execute ./bin/zkServer.sh start-foreground em um terminal ./bin/zkCli.sh -server 127.0.0.1:2181 em outro terminal Do shell do programa cliente (executado por \u00faltimo), digite help e enter para ver uma lista de todos os comandos dispon\u00edveis. Vejamos alguns exemplos b\u00e1sicos. ls / - lista os n\u00f3s filhos da raiz. create /teste lala - cria o n\u00f3 /teste com conte\u00fado lala get /teste - pega o conte\u00fado do arquivo set /teste lele - atualiza o conte\u00fado do arquivo delete /teste - apaga o arquivo Outros comandos interessantes s\u00e3o: stat /teste - mostra medatados do arquivo, por exemplo vers\u00e3o, e timestamps set -v V /teste lili - faz um update condiciona, isto \u00e9, atualiza o conte\u00fado do arquivo se a vers\u00e3o do mesmo, como mostrada pelo comando stat , for igual a V","title":"Laborat\u00f3rio"},{"location":"fault/#cluster-tolerante-a-falhas","text":"Observe que voc\u00ea est\u00e1 executando o Zookeeper em apenas um n\u00f3, ou seja, n\u00e3o h\u00e1 toler\u00e2ncia a falhas alguma aqui. Para tolerar falhas, voc\u00ea precisa de um cluster multi-n\u00f3s, mesmo que seja em uma \u00fanica m\u00e1quina. Neste caso, crie tr\u00eas arquivos de configura\u00e7\u00e3o, zoo1.cfg , zoo2.cfg e zoo3.cfg . O arquivo zooX.cfg , onde 1 <= X <= 3 , fica assim: dataDir=/tmp/lasaro/zooX #Substitua o X pelo valor correto server.1=zoo1:2888:3888 server.2=zoo2:2889:3889 server.3=zoo3:2890:3890 clientPort=218X #Substitua o X pelo valor correto Crie diret\u00f3rios e arquivos de identifica\u00e7\u00e3o. mkdir /tmp/lasaro/zooX echo X > /tmp/lasaro/zooX/myid Execute servidores. ./bin/zkServer.sh start conf/zooX.cfg Ainda que tenha tr\u00eas servidores executando em uma mesma m\u00e1quina, seu cluster parar\u00e1 de funcionar se a m\u00e1quina parar de funcionar. O ideal \u00e9 que cada servidor execute em uma m\u00e1quina distinta.","title":"Cluster tolerante a falhas"},{"location":"fault/#receitas","text":"\u00c9 poss\u00edvel resolver diversos problemas encontrados em sistemas distribu\u00eddos usando-se o ZooKeeper, por exemplo, o problema de descoberta de processos. Rendezvous Ponto de encontro de processos. Defina um zNode raiz a ser usado: /rendezvous/app1/ Cada filho de /rendezvous/app1 corresponde a um processo: IP Porta N\u00famero de processadores ... Processo p ao ser iniciado: procura /rendezvous/app1/p se achar, continua se n\u00e3o achar, cria /rendezvous/app1/p lista os filhos de /rendezvous/app1 Como lidar com sa\u00edda de processos? Fa\u00e7a todos os zNodes s\u00e3o ef\u00eameros. Quando um n\u00f3 \u00e9 desconectado, o zNode correspondente ser\u00e1 destru\u00eddo. Como detectar mudan\u00e7as no grupo de processos? Monitore os filhos de /rendezvous/app1 Sempre que receber notifica\u00e7\u00f5es, refa\u00e7a o c\u00e1lculo do membership . Elei\u00e7\u00e3o de L\u00edderes Rendezvous. Fa\u00e7a os zNodes sequenciais. Ordene os zNodes e escolha o primeiro. Monitore o zNode. Se ele sumir, eleja outro l\u00edder. Exclus\u00e3o M\u00fatua Construa uma fila usando n\u00f3s ef\u00eameros e sequenciais. O processo na cabe\u00e7a da fila tem direito de acesso. Em caso de falhas, o processo \u00e9 removido da cabe\u00e7a da fila. V\u00e1rias outras receitas podem ser facilmente encontradas no s\u00edtio do projeto : Lock distribu\u00eddo Filas, e.g. de prioridades Barreira Servi\u00e7o de nomes Termina\u00e7\u00e3o em duas fases Contador at\u00f4mico Al\u00e9m destas, outro projeto, o Curator se dedica apenas a colecionar implementa\u00e7\u00f5es corretas de receitas para o Zookeeper.","title":"Receitas"},{"location":"fault/#estudo-de-caso-etcd","text":"Todo descrever o etcd Todo falhas bizantinas <!-- \\subsection{Toler\u00e2ncia a Falhas} \\begin{frame}{O qu\u00ea?} Manter dados/servi\u00e7os dispon\u00edveis a despeito de falhas. \\end{frame} \\[\\begin{frame}{Replica\u00e7\u00e3o} No Kafka, o \\alert{Replication Factor} determina quantas c\u00f3pias de cada t\u00f3pico (todas as parti\u00e7\u00f5es no t\u00f3pico). \\end{frame}\\] \\[\\begin{frame}{L\u00edder e Seguidor} \\begin{itemize} * Produtor conversa com l\u00edder. L\u00edder grava localmente e envia ack ao produtor. * Consumidor conversa com l\u00edder. L\u00edder envia dados ao consumidor. * L\u00edder replica dados para seguidores. \\end{itemize} \\end{frame}\\] \\begin{frame}{Replicar} Passo 6 ensina a criar um sistema com m\u00faltiplos brokers. \\begin{itemize} * Identificador * Porta (mesmo servidor) * \\alert{Log directory} \\end{itemize} \\end{frame} \\[\\begin{frame}{Replicar} \\begin{itemize} * Crie um novo t\u00f3pico, com RF = 3 e duas parti\u00e7\u00f5es * \\lstinline|bin/kafka-topics.sh --list --zookeeper localhost:2181 --describe --topic <topico>| * Lista de r\u00e9plicas * Lista de r\u00e9plicas sincronizadas: \\emph{list of \\alert{i}n \\alert{s}ync \\alert{r}eplicas} \\end{itemize} \\end{frame}\\] \\[\\begin{frame}{Zookeeper} \\begin{itemize} * Permite que n\u00f3s do cluster se descubram * Elege l\u00edder \\end{itemize} \\end{frame}\\] \\[\\begin{frame}{Armazenamento} \\begin{itemize} * Dado deve ser removido depois de um tempo de ``reten\u00e7\u00e3o'' * Pode definir reten\u00e7\u00e3o por tamanho (por parti\u00e7\u00e3o, n\u00e3o t\u00f3pico) \\end{itemize} \\end{frame}\\] \\subsection{Produtor} \\[\\begin{frame}{Produtor} \\begin{itemize} * Produtor envia mensagens para os brokers * Producer API * \\href{https://github.com/LearningJournal/ApacheKafkaTutorials}{Learning Journal} \\end{itemize} \\end{frame}\\] \\begin{frame}[fragile]{SimpleProducer.java} \\begin{lstlisting}[language=Java] import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; import java.util.Properties; public class SimpleProducer { public static void main(String[] args) { String topicName = \"SimpleProducerTopic\"; String key = \"Chave\"; String value = \"Valor\"; Properties props = new Properties(); props.put(\"bootstrap.servers\", \"localhost:9092, localhost:9093\"); props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); Producer producer = new KafkaProducer (props); ProducerRecord record = new ProducerRecord (topicName, key, value); producer.send(record); producer.close(); System.out.println(\"SimpleProducer Completed.\"); } } \\end{lstlisting} \\end{frame} \\begin{frame}{Workflow} \\includegraphics[width=.8\\textwidth]{images/kafka6} \\begin{itemize} * Particionador default \\begin{itemize} * Partition * Hash da ``chave'' * Round robin \\end{itemize} * Retry autom\u00e1tico \\end{itemize} \\end{frame} \\[\\begin{frame}{Fire and Forget} Envia a mensagem e n\u00e3o se importa com o resultado. \\end{frame}\\] \\begin{frame}[fragile]{Synchronous Call} Envia a mensagem e espera para saber se foi entregue ou n\u00e3o. \\begin{lstlisting}[language=Java] try{ RecordMetadata metadata = producer.send(record).get(); System.out.println(\"Message is sent to Partition no \" + metadata.partition() + \" and offset \" + metadata.offset()); System.out.println(\"SynchronousProducer Completed with success.\"); }catch (Exception e) { e.printStackTrace(); System.out.println(\"SynchronousProducer failed with an exception\"); }finally{ producer.close(); } \\end{lstlisting} \\begin{itemize} * Future \\end{itemize} \\end{frame} \\begin{frame}[fragile]{Callback} Envia a mensagem e \u00e9 invocado depois de receber um ACK \\begin{lstlisting}[language=Java] producer.send(record, new MyProducerCallback()); ... class MyProducerCallback implements Callback{ @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) { if (e != null) System.out.println(\"AsynchronousProducer failed with an exception\"); else System.out.println(\"AsynchronousProducer call Success:\"); } } \\end{lstlisting} \\begin{itemize} * max.in.flight.requests.per.connection \\end{itemize} \\end{frame} \\begin{frame}{Default Partitioner} \\includegraphics[width=.8\\textwidth]{images/kafka6} \\[\\begin{itemize} * Partition * Hash da ``chave'' \\% \\#partition * Round robin \\end{itemize}\\] \\href{ https://github.com/LearningJournal/ApacheKafkaTutorials/blob/master/ProducerExamples/SensorPartitioner.java}{Exemplo de Custom Partitioner} \\end{frame} \\subsection{Consumidor} \\[\\begin{frame}{Consumer Groups} \\begin{itemize} * M\u00faltiplos consumidores processam dados em paralelo * Grupo de consumidores de t\u00f3picos * Grupo pertence \u00e0 mesma aplica\u00e7\u00e3o \\includegraphics[width=.6\\textwidth]{images/kafka7} * Duplicate reads? Consumidores n\u00e3o compartilham parti\u00e7\u00f5es * Group coordinator (broker eleito): lista de consumidores * Group l\u00edder: rebalanceamento \\end{itemize} \\end{frame}\\] \\begin{frame}[fragile, allowframebreaks]{Consumer} \\begin{lstlisting}[language=Java] import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import java.io.IOException; import java.util.Arrays; import java.util.Properties; public class SimpleConsumer { public static void main(String[] args) throws IOException { String topicName = \"SimpleProducerTopic\"; String groupName = \"SupplierTopicGroup\"; Properties props = new Properties(); props.put(\"bootstrap.servers\", \"localhost:9092,localhost:9093\"); props.put(\"group.id\", groupName); props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer consumer = null; try { consumer = new KafkaConsumer (props); consumer.subscribe(Arrays.asList(topicName)); while (true) { ConsumerRecords records = consumer.poll(100); 1 2 for (ConsumerRecord<String, String> record: records) System.out.println(\"Key = \" + record.key() + \" Value = \" + record.value()); } } catch (Exception ex) { ex.printStackTrace(); } finally { consumer.close(); } } } \\end{lstlisting} \\begin{itemize} * Se n\u00e3o definir grupo, ser\u00e1 novo grupo, e ler\u00e1 todas as mensagens dispon\u00edveis \\end{itemize} \\end{frame} \\[\\begin{frame}{Poll} \\begin{itemize} * poll tamb\u00e9m envia hearbeat * executar a cada 3s, no m\u00ednimo * Current offset: a cada poll, broker incrementa current offset * Commited offset: o consumidor informa quais \u00edndices foram processados \\begin{itemize} * Auto Commit \\begin{itemize} * enable.auto.commit * auto.commit.interval.ms * Pode causar reprocessamento de mensagens \\end{itemize} * Manual Commit \\begin{itemize} * CommitSync * CommitAsync \\end{itemize} \\end{itemize} \\end{itemize} \\end{frame}\\] \\subsection{Arquitetura} %\\begin{frame}{L\u00edder} %\\end{frame} %mensagens s\u00e3o ack depois de copiadas para todas as r\u00e9plicas %replicas lentas s\u00e3o removidas se lentas ou falhas %at least once, at most once, exactly one (nao suportado) %rolling upgrade %tls security %rest %CRUD","title":"Estudo de caso: Etcd"},{"location":"fault/#falhas-bizantinas","text":"Uma hist\u00f3ria de tr\u00eas ex\u00e9rcitos -- Vers\u00e3o 2} Ex\u00e9rcitos est\u00e3o \u00e0s portas de Biz\u00e2ncio, aka Constantinopla, aka Istambul. Todos os ex\u00e9rcitos tem que atacar em conjunto ou se retirar em conjunto. Cada ex\u00e9rcito \u00e9 comandado por um General. Alguns destes preferem atacar, enquanto outros preferem se retirar. Alguns generais podem ter sido comprados, e mandar mensagens discrepantes para os outros, ou simplesmente n\u00e3o mandar mensagens. Fonte: \\href{ http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf}{Lamport , L.; Shostak, R.; Pease, M. (1982). \"The Byzantine Generals Problem\" (PDF). ACM Transactions on Programming Languages and Systems. 4 (3): 382\u2013401. doi:10.1145/357172.357176.} Generais e Tenentes Problema pode ser mudado para: 1 2 3 * Comandante envia ordem. * Todos os tenentes leais executam ordem recebida. * Comandante pode ser traidor. Generais e Tenentes Suponha 3 ex\u00e9rcitos. \\ Comandante (traidor) diz \"Ataque!\" Tenente A e \"Retirada!\" tenente B.\\ Ou \\ Comandante diz \"Ataque!\" a ambos. Tenente A segue a ordem mas B se retira. E se os tenentes trocarem informa\u00e7\u00f5es? Como diferenciar casos em que Comandante ou Tenente \u00e9 traidor? Generais e Tenentes S\u00f3 h\u00e1 solu\u00e7\u00e3o se mais de \\(\\frac{2}{3}\\) dos Generais/Tenentes s\u00e3o leais. % http://www.drdobbs.com/cpp/the-byzantine-generals-problem/206904396?pgno=5 Comunica\u00e7\u00e3o} 1 2 * Toda mensagem enviada \u00e9 entregue corretamente. * A aus\u00eancia de mensagem pode ser detectada (mensagem Null \u00e9 entregue no lugar) (Sistema s\u00edncrono) 4/0} General manda ordens. Aus\u00eancia de ordem = Retirada Tenente repassa ordens Maioria de comandos \u00e9 comando a ser seguido 4/0} General manda ordens. Aus\u00eancia de ordem = Retirada Tenente repassa ordens Maioria de comandos \u00e9 comando a ser seguido Comunica\u00e7\u00e3o} 1 2 3 * Toda mensagem enviada \u00e9 entregue corretamente. * Toda mensagem \u00e9 assinada. * A aus\u00eancia de mensagem pode ser detectada (mensagem Null \u00e9 entregue no lugar) (Sistema s\u00edncrono) \u00c9 poss\u00edvel detectar inconsist\u00eancias e processos bizantinos. % http://cs.brown.edu/courses/cs138/s16/lectures/19consen-notes.pdf \\section{Outros t\u00f3picos} %TODO \\subsection{Detectores de Falhas} \\subsection{Reconfigura\u00e7\u00e3o} Reconfigura\u00e7\u00e3o da Aplica\u00e7\u00e3o} Na segunda entrega do projeto, voc\u00ea distribuiu a carga do seu banco de dados entre v\u00e1rios n\u00f3s. Caso um n\u00f3 falhe, parte dos seus dados ser\u00e1 perdida. Para corrigir esta defici\u00eancia, na terceira entrega, cada n\u00f3 ser\u00e1 replicado em tr\u00eas vias e, assim, caso um n\u00f3 falhe, outros dois continuar\u00e3o a manter o dado. Reconfigura\u00e7\u00e3o da Aplica\u00e7\u00e3o} Ainda assim, h\u00e1 problemas. E se mais de um, de um mesmo conjunto de r\u00e9plicas, falhar? Embora seja pequena a probabilidade de dois n\u00f3s de um mesmo grupo falharem em instantes pr\u00f3ximos, dado tempo suficiente, qualquer evento com probabilidade diferente de 0 acontecer\u00e1. Precisamos de uma forma de trocar n\u00f3s da aplica\u00e7\u00e3o que falharam por novos n\u00f3s. Este \u00e9 problema denominado Pertin\u00eancia de Grupo ou \\emph{Group Membership} Group Membership} Para n\u00e3o correr o risco, retire o processo falhos do grupo e coloque outro no lugar! I.e., mude a vis\u00e3o que o sistema de quem \u00e9 o grupo. Vis\u00f5es} \\includegraphics[width=.7\\textwidth]{images/vc} Fonte: \\href{ https://www.cs.rutgers.edu/~pxk/417/notes/virtual_synchrony.html}{Paul Krzyzanowski} \\(G\\) \u00e9 o grupo de processos participando do sistema, \u00e9 a Vis\u00e3o do Sistema. Inicialmente, \\(G\\) consiste de apenas o processo \\(p\\) , como o processo que cria o cluster no Atomix. Na sequ\u00eancia, outros processo v\u00e3o se unindo ao grupo atrav\u00e9s de View Changes. Uma vez que \\(p\\) e \\(q\\) est\u00e3o no grupo, inicia-se a comunica\u00e7\u00e3o entre eles. Quando \\(r, s\\) e \\(t\\) aparecem, tamb\u00e9m entram no grupo por meio de uma nova vis\u00e3o. Finalmente, quando ambos \\(p\\) e \\(q\\) falham, os outros processo os excluem da vis\u00e3o, e continuam funcionando normalmente. Impossibilidade de Detec\u00e7\u00e3o de Falhas} Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir com toda certeza um processo falho (parou de funcionar) de um que est\u00e1 lento. Como decidir se mudar ou n\u00e3o de vis\u00e3o? Ou aceita a imprecis\u00e3o e muda quando suspeitar de uma falha, ou corre o risco de ficar esperando \\emph{ad eternum} e n\u00e3o mudar, mesmo quando uma falha aconteceu. Uma ``solu\u00e7\u00e3o''!} Quando suspeitar de falha, reporte suspeita a outros processos, que tamb\u00e9m passar\u00e3o a suspeitar. Tome decis\u00e3o baseado na suspeita, isto \u00e9, troque de vis\u00e3o quando houver suspeita. Pague o pre\u00e7o de uma suspeita errada, isto \u00e9, quando um processo for removido da vis\u00e3o indevidamente, adicione-o novamente. Sincronismos Virtual} Gerenciamento de Grupo/Group Membership e Comunica\u00e7\u00e3o em Grupo 1 2 3 4 5 6 * Processos se unem ao grupo * Processos saem do grupo * Processos enviam mensagens para o grupo * Diferentes ordena\u00e7\u00f5es * Atomic Multicast Vis\u00e3o de Grupo} 1 2 3 4 * Vis\u00e3o: conjunto de processos no sistema. * Multicast feito para processos na vis\u00e3o. * Vis\u00e3o \u00e9 consistente entre os processos. * Entrada e sa\u00edda de processos muda a vis\u00e3o. Eventos} 1 2 3 * Mensagem * Mudan\u00e7a de Vis\u00e3o * Checkpoint Vis\u00f5es} \\includegraphics[width=.7\\textwidth]{images/vc} Fonte: \\href{ https://www.cs.rutgers.edu/~pxk/417/notes/virtual_synchrony.html}{Paul Krzyzanowski} Sincronismo Virtual} Deve satisfazer 1 2 3 4 * Se uma mensagem \u00e9 enviada em uma vis\u00e3o, ela s\u00f3 pode ser entregue naquela vis\u00e3o. * Se uma mensagem \u00e9 entregue a um processo correto em uma vis\u00e3o, ent\u00e3o \u00e9 entregue a todos os processos corretos naquela vis\u00e3o. * Se um processo n\u00e3o recebe a mensagem, ele n\u00e3o estar\u00e1 na pr\u00f3xima vis\u00e3o. * Ao entrar em uma vis\u00e3o, o processo recebe o estado dos outros processos e seu estado se torna equivalente ao de um processo que recebeu todas as mensagens j\u00e1 entregues. A troca de Vis\u00e3o \u00e9 uma barreira. ISIS Toolkit} Sistema de Sincronismo Virtual tolerante a falhas desenvolvido por Ken Birman, Cornell University (\\url{ http://www.cs.cornell.edu/Info/Projects/Isis/ })\\ ISIS: An Environment for Constructing Fault-Tolerant Distributed Systems. Kenneth Birman, D. Skeen, A. El Abbadi, W. C. Dietrich and T. Raeuchle. May 1983. 1 2 3 4 5 6 7 * 100.000's/s * Em uso at\u00e9 2009 * NY Stock Exchange * Swiss Exchange * US Navy * Precursos de sistemas como Zookeeker * Totem, ISIS, Horus, Transis (Parti\u00e7\u00f5es), \\alert{Spread}, \\alert{Ensamble}, \\alert{JGroups}, Appia, QuickSilver, vSynch (n\u00e9e ISIS 2) Difus\u00e3o Totalmente Ordenada} 1 2 3 4 5 6 7 * Corretude: Se um processo $p$ envia uma mensagem $m$ para processos no grupo $G$, ent\u00e3o se $p$ n\u00e3o falha, todos os processos corretos em $G$ recebem a mensagem. * Acordo: Se um processo correto em $G$ recebe uma mensagem $m$, ent\u00e3o todo processo correto em $G$ recebe $m$ * Ordena\u00e7\u00e3o: Se um processo recebe mensagem $m$ e depois $n$, ent\u00e3o qualquer processo que receba a mensagem $n$ deve primeiro receber $m$ * Validade: Somente mensagens difundidas s\u00e3o entregues. E se mandarmos mensagens do tipo ``A partir da entrega desta mensagem, o grupo de processos \u00e9 \\(G\\) .'' Sincronismo Virtual} Deve satisfazer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 * Se uma mensagem \u00e9 enviada em uma vis\u00e3o, ela s\u00f3 pode ser entregue naquela vis\u00e3o.\\\\ Mensagens de troca de vis\u00e3o podem incrementar um contador\\\\ Mensagens normais carregam o valor atual do contador\\\\ Mensagem descartada se valor na mensagem \u00e9 maior contador no destinat\u00e1rio * Se uma mensagem \u00e9 entregue a um processo correto em uma vis\u00e3o, ent\u00e3o \u00e9 entregue a todos os processos corretos naquela vis\u00e3o.\\\\ Pela difus\u00e3o, se a mensagem de troca for entregue para um processo, ser\u00e1 entregue para todos os corretos, na mesma ordem Se mensagem comum for entregue antes para algum, ser\u00e1 entregue ante para todos. * Se um processo n\u00e3o recebe a mensagem, ele n\u00e3o estar\u00e1 na pr\u00f3xima vis\u00e3o.\\\\ Se um processo n\u00e3o recebe uma mensagem comum que foi entregue pelos outros, ent\u00e3o ele n\u00e3o troca de vis\u00e3o. * Ao entrar em uma vis\u00e3o, o processo recebe o estado dos outros processos e seu estado se torna equivalente ao de um processo que recebeu todas as mensagens j\u00e1 entregues.\\\\ Caso contr\u00e1rio, n\u00e3o haveria porqu\u00ea trocar os processos State Transfer} \\includegraphics[width=.7\\textwidth]{images/state_transfer} \\href{ http://www.gsd.inesc-id.pt/~ler/docencia/tfd0405/bib/BSRNA.pdf}{Building Secure and Reliable Network Applications} Difus\u00e3o At\u00f4mica \\(\\equiv\\) Sincronismo Virtual?} Seria uma boa aproxima\u00e7\u00e3o, mas que poderia ser relaxada. Em certas aplica\u00e7\u00f5es, FIFO ou Causal seriam suficientes dentro da vis\u00e3o, desde que a mensagem de mudan\u00e7a da vis\u00e3o seja totalmente ordenada com as comuns. Particionamento} E se dois subconjuntos mutuamente exclusivos se formarem e criarem vis\u00f5es independentes? \\emph{Primary Partition Model} -- Somente a parti\u00e7\u00e3o prim\u00e1ria pode mudar de vis\u00e3o. Lembram-se que no Raft somente uma parti\u00e7\u00e3o com uma maioria de processo pode decidir? \u00c9 exatamente a mesma situa\u00e7\u00e3o, pois os processos est\u00e3o chegando a um Consenso sobre quem \u00e9 a nova vis\u00e3o. Extended Virtual Synchrony} \\emph{Primary Partition Model} -- N\u00e3o \u00e9 adequado a uma rede geograficamente distribu\u00edda (Internet scale). Lembram-se que no Raft somente uma parti\u00e7\u00e3o com uma maioria de processo pode decidir? \u00c9 exatamente a mesma situa\u00e7\u00e3o, pois os processos est\u00e3o chegando a um Consenso sobre quem \u00e9 a nova vis\u00e3o. \u00c9 poss\u00edvel que no trabalho dois, alguns de voc\u00eas tenham tentado gerar locks do sistema para manipular objetos distribu\u00eddos no sistema. Esse locks s\u00e3o perigosos por qu\u00ea processos pode travar/quebrar/falhar e nunca liberarem os locks. O uso de um algoritmo VS poderia ser usado para resolver o problema.\\right Swim http://courses.cs.vt.edu/cs5204/fall05-gback/lectures/Lecture8.pdf","title":"Falhas Bizantinas"},{"location":"fault/#estudo-de-caso-kafka","text":"Todo Boeing 737 Max: why was it grounded, what has been fixed and is it enough? \u21a9 Using TLA+ in the Real World to Understand a Glibc Bug \u21a9 Fail Fast Is Failing\u2026 Fast! \u21a9 Esta \u00e9 uma varia\u00e7\u00e3o do problema de coordena\u00e7\u00e3o de gangsters apresentado no em Some constraints and trade-offs in the design of network communications \u21a9 Hundred Impossibility Proofs for Distributed Computing , Impossibility Results for Distributed Computing \u21a9 Impossibility of Distributed Consensus with One Faulty Process . Uma explica\u00e7\u00e3o da prova est\u00e1 dispon\u00edvel no Paper Trail \u21a9 Unreliable Failure Detectors for Reliable Distributed Systems \u21a9 The Weakest Failure Detector for Solving Consensus \u21a9 Um exemplo de como traduzir um algoritmo complexo para c\u00f3digo pode se ingrato \u00e9 reportado em Paxos Made Live - An Engineering Perspective . \u21a9 Consistent Core \u21a9 O \\\\ no final da linha \u00e9 s\u00f3 para mostrar que o comando continua na pr\u00f3xima e facilitar a visualiza\u00e7\u00e3o. Na hora de executar, use apenas uma linha, sem o \\\\ . \u21a9","title":"Estudo de caso: Kafka"},{"location":"intro/","text":"Introdu\u00e7\u00e3o Escrever bons sistemas distribu\u00eddos \u00e9 uma tarefa que esbarra em diversos obst\u00e1culos, sendo a defini\u00e7\u00e3o do que \u00e9 um sistema distribu\u00eddo e do que \u00e9 ser \"bom\" neste contexto sendo nossos primeiros obst\u00e1culos. O qu\u00ea s\u00e3o Sistemas Distribu\u00eddos? Sistemas simples Para atacarmos a primeira quest\u00e3o e entendermos o que \u00e9 um Sistema Distribu\u00eddo, talvez seja mais f\u00e1cil come\u00e7ar pelo que n\u00e3o \u00e9 um sistema n\u00e3o-distribu\u00eddo. Estes s\u00e3o os sistemas que cont\u00e9m em um \u00fanico processo toda a l\u00f3gica de neg\u00f3cio, armazenamento e interface com usu\u00e1rio, mesmo que sejam divididos em v\u00e1rios m\u00f3dulos e usem diferentes bibliotecas e frameworks . Sejam estes sistemas constru\u00eddo com blocos que se encaixam perfeitamente, disponibilizados basicamente pela biblioteca da linguagem que est\u00e1 utilizando; Sistemas n\u00e3o t\u00e3o simples ou desenvolvido por times com diversas pessoas e usando bibliotecas de muitos fornecedores diferentes, aumentando consideravelmente a complexidade do desenvolvimento; o resultado, contudo, continua sendo um artefato s\u00f3, executado como um \u00fanico processo, e por isso os denominaremos sistemas monol\u00edtico . 1 Programar sistemas distribu\u00eddos \u00e9 dar outro salto em complexidade, pois frequentemente temos que usar pe\u00e7as que n\u00e3o foram pensadas para trabalhar juntas, for\u00e7ando-nos a usar um pouco de super-cola e arame. Cable hell! Bem, na verdade, em vez de cola usamos middleware , como logo discutiremos, e, em vez de arame, usamos cabos de rede, o que \u00e9, de fato, a principal caracter\u00edstica de um sistema distribu\u00eddo em rela\u00e7\u00e3o a um n\u00e3o-distribu\u00eddo: separa\u00e7\u00e3o e dispers\u00e3o de suas partes em v\u00e1rios componentes independentes (processos, sensores, atuadores, etc), mas que se coordenam para execu\u00e7\u00e3o de alguma tarefa. Vejamos alguns exemplos de tarefas executadas por sistemas distribu\u00eddos, que voc\u00ea usa hoje. Entregue este email para fulano@knowhere.uni . Envie o item I para o endere\u00e7o E, ap\u00f3s cobran\u00e7a de D dinheiros da conta C. Em um ambiente de simula\u00e7\u00e3o de batalhas em 3D, simule o disparo de um proj\u00e9til na dire\u00e7\u00e3o em que o o avatar est\u00e1 olhando, com velocidade V, enquanto movimenta o avatar A para a esquerda com velocidade W. Autorize a transfer\u00eancia de D dinheiros da conta C para a conta C'. Movimente o bra\u00e7o mec\u00e2nico que est\u00e1 segurando um bisturi, 3cm \u00e0 direita, ent\u00e3o abaixe-o 3mm, e movimente-o 4cm para a esquerda Inclua o coment\u00e1rio ``LOL!!!'' na lista de coment\u00e1rios do item XYZ, com marca de tempo T Leia o valor do sensor de temperatura T e, caso seu valor supere V, emita alarme luminoso vermelho intermitente e alarme sonoro Fica claro por estes exemplos que h\u00e1 comunica\u00e7\u00e3o entre diversos componentes, por exemplo o console de videogame e um servi\u00e7o que mantem uma \"sala\" aberta para um jogo. Assim, uma poss\u00edvel defini\u00e7\u00e3o de Sistema Distribu\u00eddo, que me agrada, \u00e9 a seguinte: Sistema Distribu\u00eddo Cole\u00e7\u00e3o de sistemas computacionais (software ou hardware), independentes mas com alguma forma de comunica\u00e7\u00e3o , que colaboram na execu\u00e7\u00e3o de alguma tarefa . Componentes hospedeiro n\u00f3 No jarg\u00e3o da \u00e1rea, os componentes independentes s\u00e3o denominados n\u00f3s . Frequentemente, cada n\u00f3 do sistema ser\u00e1, na pr\u00e1tica, um processo em um computador hospedeiro, um host , para que possa fazer uso de todos os recursos do hospedeiro e, por isso, frequentemente nos referimos ao pr\u00f3prio host como o n\u00f3. Contudo, nada impede que possivelmente m\u00faltiplos n\u00f3s possam ser executados em um mesmo host ou mesmo que m\u00faltiplos hosts virtuais, sejam m\u00e1quinas virtuais ou containers, executem na mesma m\u00e1quina f\u00edsica; isso n\u00e3o muda o fato de que os componentes s\u00e3o independentes e poderiam ser distanciados. 2 Comunica\u00e7\u00e3o mem\u00f3ria compartilhada mensagens Quanto \u00e0 comunica\u00e7\u00e3o, os n\u00f3s podem compartilhar um espa\u00e7o de endere\u00e7amento comum, seja porqu\u00ea est\u00e3o co-locados no mesmo hospedeiro ou seja porqu\u00ea tem acesso a alguma forma de mem\u00f3ria compartilhada distribu\u00edda, que veremos mais adiante. Eles tamb\u00e9m podem se comunicar por mensagens trocadas via uma rede de comunica\u00e7\u00e3o, como a Internet. Quanto \u00e0 tarefa em comum, veja o seguinte exemplo, em que v\u00e1rios clientes trocam emails por meio de uma m\u00e1quina com a qual se comunicam para entregar mensagens a serem enviadas e receber mensagens a eles destinadas; enquanto aguardam a entrega, mensagens s\u00e3o armazenadas em um Sistema Gerenciador de Banco de Dados (SGBD) em uma outra m\u00e1quina, da qual os usu\u00e1rios n\u00e3o tem ci\u00eancia. Depend\u00eancia Ao colaborarem, criam depend\u00eancia Falha pode parar o sistema Neste exemplo, cada celular, o processo que implementa o servi\u00e7o de email e o servidor de banco de dados, s\u00e3o n\u00f3s do sistema. Observe que o n\u00f3 do servi\u00e7o de email \u00e9 respons\u00e1vel por receber os emails e encaminh\u00e1-los para o banco em um sentido, bem como ler emails do banco e entregar para os destinat\u00e1rios, no outro. Observe tamb\u00e9m que se o banco de dados para de funcionar, o servi\u00e7o de email passa a ser in\u00fatil, uma vez que n\u00e3o pode armazenar novas mensagens e nem recuperar mensagens j\u00e1 armazenadas. Disponibilidade falhas dependabilidade Neste contexto, uma defini\u00e7\u00e3o mais c\u00ednica mas definitivamente realista \u00e9 a de Leslie Lamport , que certa vez disse: A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable. Lamport est\u00e1 correto quanto aos problemas em sistemas distribu\u00eddos, e problemas podem se manifestar em diversas formas. Por exemplo, mesmo que um computador n\u00e3o pare, se ele ficar lento ou se o canal de comunica\u00e7\u00e3o n\u00e3o for confi\u00e1vel, uma aplica\u00e7\u00e3o cr\u00edtica poderia ser inviabilizada, como no exemplo de telecirurgia acima. Algumas aplica\u00e7\u00f5es, contudo, aparentemente conseguem superar estes obst\u00e1culos. Pensemos em algumas aplica\u00e7\u00f5es distribu\u00eddas com as quais interagimos todos os dias e que, por seu sucesso, devem ser bons sistemas distribu\u00eddos. Alguns exemplos \u00f3bvios s\u00e3o Amazon.com , Facebook , e GMail . Estes sistemas rodam em grandes data centers com milhares de m\u00e1quinas , estando constantemente sujeitos a fontes queimadas, discos corruptos, mem\u00f3rias defeituosas, etc 3 . Apesar disto, dificilmente estes servi\u00e7os s\u00e3o reportados como fora do ar, s\u00e3o altamente respons\u00edveis e, goste ou n\u00e3o do que fazem, s\u00e3o bem sucedidos porqu\u00ea cumprem bem suas tarefas. Assim, digamos que um sistema computacional \u00e9 bom se est\u00e1 sempre funcional, com bom desempenho e \u00e9 de baixo custo. Observe que estar sempre funcional implica em continuar provendo o servi\u00e7o mesmo que partes do sistema estejam com problemas, que ter bom desempenho implica que respostas \"r\u00e1pidas\" s\u00e3o dadas para o usu\u00e1rio, e que baixo custo implica em n\u00e3o gastar mais que o necess\u00e1rio para realizar a tarefa para a qual foi constru\u00eddo. Um \"bom\" sistema Dispon\u00edvel Falhas R\u00e1pido Desempenho Proximidade Barato Tamanho apropriado Enquanto subjetiva, nossa defini\u00e7\u00e3o de bom nos permite estabelecer um pano de fundo para delinear as dificuldades de se implementar sistemas distribu\u00eddos. Como veremos adiante, os requisitos para um bom sistema distribu\u00eddo s\u00e3o conflitantes e dif\u00edceis, as vezes imposs\u00edveis, de serem alcan\u00e7ados. Mas se esta \u00e9 a realidade da programa\u00e7\u00e3o distribu\u00edda, por qu\u00ea faz\u00ea-lo? A resposta tem a ver com a colabora\u00e7\u00e3o , na defini\u00e7\u00e3o. Por qu\u00ea desenvolvemos sistemas distribu\u00eddos? A primeira raz\u00e3o \u00e9 o fato \u00e9 que computadores individuais tem capacidade reduzida de processamento e armazenamento, mas nossa necessidade de poder computacional cresce exponencialmente. Assim, precisamos crescer nosso poder computacional, mas aumentar a capacidade de um dispositivo ( scale up ou vertical scaling ), mesmo de forma linear, tem custo exponencial. O que nos resta ent\u00e3o \u00e9 agregar o poder computacional de diversos computadores \"baratos\" ( scale out ou horizontal scaling ) para satisfazer nossas necessidades. 4 Mesmo se pensarmos que a escala com que estes sistemas trabalham deve ser muito diferente daquela dos sistemas que n\u00f3s desenvolvemos, e portanto as t\u00e9cnicas usadas em sua constru\u00e7\u00e3o devem ser muito distintas do que fazemos, a verdade n\u00e3o poderia ser mais longe disto. Com a quantidade de informa\u00e7\u00e3o armazenada a cada acesso a um s\u00edtio, a cada produto vendido, ou a cada consulta feita, praticamente qualquer sistema de informa\u00e7\u00e3o de sucesso necessitar\u00e1 aplicar as t\u00e9cnicas de computa\u00e7\u00e3o distribu\u00edda e superar as mesmas barreiras para conseguir atender ao n\u00famero crescente de clientes (computacionais ou humanos) e aumentar sua \u00e1rea de cobertura, mesmo que n\u00e3o chegue a escala dos exemplos acima, e melhorar ou manter a qualidade do servi\u00e7o que presta. PQ? escalabilidade toler\u00e2ncia a falhas Este \u00faltimo ponto, sobre qualidade do servi\u00e7o, tem a ver com a capacidade de um sistema se manter no ar a despeito de problemas, isto \u00e9, de ser tolerante a falhas. Toler\u00e2ncia a falhas implica em redund\u00e2ncia, em c\u00f3pias, o que fatidicamente implica em distribui\u00e7\u00e3o e em Sistemas Distribu\u00eddos. Assim, podemos concluir que as principais raz\u00f5es para se desenvolver sistemas distribu\u00eddos s\u00e3o alcan\u00e7ar escalabilidade e toler\u00e2ncia a falhas , ambas resultantes da agrega\u00e7\u00e3o (correta) do poder computacional de m\u00faltiplos componentes. Uma vez que tenhamos entendido o porqu\u00ea de desenvolver sistemas distribu\u00eddos, vejamos que tipos de sistemas resultam desta abordagem. Tipos de Sistemas Distribu\u00eddos H\u00e1 quem diga que j\u00e1 somos todos desenvolvedores de sistemas distribu\u00eddos . Ainda assim, \u00e9 importante entender que h\u00e1 v\u00e1rios tipos de sistemas distribu\u00eddos, com diversas finalidades e diversas arquiteturas, pois classifica\u00e7\u00f5es nos ajudam a pensar sobre sistemas e a encontrar e reusar solu\u00e7\u00f5es previamente testadas e depuradas. Sistemas de Computa\u00e7\u00e3o A possibilidade de agregar poder de processamento de muitos computadores via uma rede de comunica\u00e7\u00e3o com alt\u00edssima largura de banda nos permite atacar problemas computacionalmente muito intensos. Clusters como o da imagem a seguir, do High Performance Computing Center de Stuttgart, s\u00e3o compartilhados por pesquisadores resolvendo problemas de \u00e1reas como bio-inform\u00e1tica, engenharia, economia e intelig\u00eancia artificial. Na engenharia, por exemplo, HPC pode ser usada para testar a efici\u00eancia de projetos sem construir prot\u00f3tipos, seja de uma turbina um carro ou uma vaca Os n\u00f3s de um cluster s\u00e3o normalmente divididos em tr\u00eas categorias: administra\u00e7\u00e3o, computa\u00e7\u00e3o e armazenamento. N\u00f3s de administra\u00e7\u00e3o implementam um monitoramento distribu\u00eddo dos demais n\u00f3s, servem de ponto de entrada para usu\u00e1rios e prov\u00eaem interface para submiss\u00e3o de tarefas. O Oscar , por exemplo, \u00e9 uma \u00e9 conjunto de softwares para gerenciamento de clusters. Uma das ferramentas inclusas no Oscar \u00e9 o OpenPBS, pelo qual tarefas s\u00e3o atribu\u00eddas aos diversos n\u00f3s do sistema que estejam alocados para tal tarefa. O OpenPBS portanto \u00e9 tamb\u00e9m um sistema distribu\u00eddo. Finalmente, as tarefas submetidas em si s\u00e3o tamb\u00e9m aplica\u00e7\u00f5es distribu\u00eddas em que cada processo executando em uma m\u00e1quina distinta \u00e9 respons\u00e1vel por resolver uma parte do problema. Este tipo de sistemas distribu\u00eddos s\u00e3o o que chamamos de fortemente acoplados pois a falha em um dos componentes leva normalmente \u00e0 falha de todo o sistema. Do ponto de vista deste curso, estamos mais interessados em sistemas fracamente acoplados . Um outro tipo de sistema, fracamente acoplado, mas com a mesma finalidade de atacar problemas que exigem muita computa\u00e7\u00e3o, s\u00e3o as grades computacionais . Muito usadas at\u00e9 meados da d\u00e9cada passada, neste arranjo, membros de uma associa\u00e7\u00e3o disponibilizam capacidade computacional a um pool . De l\u00e1, os recursos podem ser acessados, seguindo algum crit\u00e9rio de gerenciamento, por quaisquer dos membros da associa\u00e7\u00e3o. Este modelo surgiu de iniciativas como o SETI@home , em que pessoas doavam tempo ocioso do seu computador para analisar sinais de r\u00e1dio recebidos do espa\u00e7o. Ap\u00f3s o sucesso inicial, a computa\u00e7\u00e3o foi movida de computadores de volunt\u00e1rios para os de institui\u00e7\u00f5es com interesses em comum. As grades computacionais s\u00e3o \u00e0s vezes vistas como precursoras da computa\u00e7\u00e3o utilit\u00e1ria , isto \u00e9, o fornecimento de recursos computacionais por provedores em troca de um pagamento proporcional \u00e0 quantidade de recursos utilizados, como no fornecimento de \u00e1gua ou eletricidade. A materializa\u00e7\u00e3o recente da computa\u00e7\u00e3o utilit\u00e1ria s\u00e3o as nuvens computacionais. Este tipo de sistema, embora possa ser pensando como infraestrutura para outros sistemas distribu\u00eddos, s\u00e3o, na verdade, complexas pe\u00e7as de engenharia, com diversos subsistemas respons\u00e1veis por sincroniza\u00e7\u00e3o de rel\u00f3gios, monitora\u00e7\u00e3o de falhas, coleta de logs, roteamento eficiente tolerante a falhas, movimenta\u00e7\u00e3o de recursos virtualizados para consolida\u00e7\u00e3o de recursos f\u00edsicos, armazenamento redundante de dados, etc. O seguinte v\u00eddeo mostra, em 360 graus, um dos datacenters do Google, para que voc\u00ea tenha ideia da escala em que estes sistemas s\u00e3o constru\u00eddos. J\u00e1 este outro s\u00edtio apresenta uma viagem fotogr\u00e1fica por alguns datacenters . Sistemas de Informa\u00e7\u00e3o Provavelmente mais comuns entre os profissionais da computa\u00e7\u00e3o, os sistemas de informa\u00e7\u00e3o distribu\u00eddos s\u00e3o encontrados em diversas formas. De fato, o termo \"sistema de informa\u00e7\u00e3o\" \u00e9 t\u00e3o abrangente, que dificilmente um sistema distribu\u00eddo n\u00e3o estaria nesta classe. O seguinte \u00e9 um exemplo de uma arquitetura em tr\u00eas camadas, onde a primeira implementa a interface com o usu\u00e1rio, a segunda cont\u00e9m a l\u00f3gica do neg\u00f3cio, e a terceira mantem os dados. Pe\u00e7a fundamental desta abordagem, os bancos de dados na terceira camada s\u00e3o frequentemente transacionais. Isto \u00e9, eles prov\u00eaem as garantias na execu\u00e7\u00e3o de transa\u00e7\u00f5es conhecidas como propriedades ACID. ACID Atomicidade: transa\u00e7\u00f5es s\u00e3o tratadas de forma indivis\u00edvel, isto \u00e9, ou tudo ou nada. Consist\u00eancia: transa\u00e7\u00f5es levam banco de um estado consistente a outro. E.g., x == 2*y Isolamento: transa\u00e7\u00f5es n\u00e3o v\u00eaem dados n\u00e3o comitados umas das outras. Durabilidade: os efeitos de uma transa\u00e7\u00e3o comitada devem persistir no sistema a despeito de falhas. Para relembrar no que implica ACID, considere a seguinte sequ\u00eancia de opera\u00e7\u00f5es, onde X e Y s\u00e3o valores guardados pelo banco de dados, a, b e c s\u00e3o vari\u00e1veis definidas no programa, e SELECT e SET s\u00e3o comandos para ler e modificar o banco de dados. 1 2 3 4 5 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: SET Y=b Suponha duas inst\u00e2ncias desta sequ\u00eancia, \\(T_1\\) e \\(T_2\\) , concorrentes, em que as opera\u00e7\u00f5es escalonadas da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 T1 T2 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: a = SELECT X 6: c = a * 2 7: b = c + 10 8: SET X=c 9: SET Y=b 10:SET Y=b Ao final da execu\u00e7\u00e3o, X ter\u00e1 o valor atribu\u00eddo por \\(T_2\\) , mas \\(Y\\) ter\u00e1 o valor de \\(T_1\\) . Este escalonamento violou a consist\u00eancia do banco de dados por qu\u00ea as opera\u00e7\u00f5es n\u00e3o foram executadas isoladamente . Tente imaginar a dificuldade de se implementar um banco de dados distribu\u00eddo. Isto \u00e9, um banco em que v\u00e1rios n\u00f3s mantem os dados, participam de transa\u00e7\u00f5es e, portanto, precisam coordenar-se para manter os dados consistentes. A figura a seguir mostra um cen\u00e1rio com tr\u00eas bancos; imagine que em um deles est\u00e1 uma rela\u00e7\u00e3o com os dados dos clientes, em outro, os dados do estoque e, no terceiro, as ordens de compra. Quando um cliente faz um pedido, o cliente deve ser validado no primeiro n\u00f3, o item \u00e9 removido do estoque no segundo, e uma cobran\u00e7a \u00e9 disparada para o cliente no terceiro. Se qualquer destas tr\u00eas rela\u00e7\u00f5es n\u00e3o for corretamente consultada e alterada, os efeitos podem ser catastr\u00f3ficos para o neg\u00f3cio ou para o cliente. graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B Como implementar ACID neste banco de dados? Embora veremos isso um pouco mais para frente neste material, por enquanto, apenas assuma que n\u00e3o \u00e9 exatamente f\u00e1cil ou barato. Esta dificuldade foi a raz\u00e3o do surgimento dos bancos de dados NOSQL (n\u00e9e NoSQL), dos quais uma pequena amostra \u00e9 dada pela seguinte figura. Tamb\u00e9m discutiremos como estes bancos de dados funcionam, quando falarmos sobre sistemas P2P. Integra\u00e7\u00e3o de Aplica\u00e7\u00f5es Frequentemente \u00e9 necess\u00e1rio integrar sistemas de informa\u00e7\u00e3o legados com sistemas mais modernos, ou simplesmente exp\u00f4-los usando uma interface mais moderna. Nestes casos, \u00e9 poss\u00edvel integrar diversos sistemas usando um middleware que os encapsule. Veremos mais adiante o que \u00e9 um middleware ; por enquanto, pense nele apenas como um camada de software que se interp\u00f5e entre os clientes e um servi\u00e7o oferecido. No exemplo, o middleware pode, por exemplo, se expor via interface REST para os clientes, mas consultar o sistema legado em um padr\u00e3o antigo. Outro exemplo, na imagem seguinte, \u00e9 um sistema que agrega subsistemas de diversos departamentos de uma empresa via troca de mensagens. Observe que nenhum departamento precisa conversar diretamente com os outros, ou mesmo conhec\u00ea-los; eles apenas publicam a mensagem para quem tiver interesse e aguardam um resposta tamb\u00e9m na forma de uma mensagem. Observe que nenhum componente tem que saber da exist\u00eancia do outro ou se torna indispon\u00edvel caso os outros falhem, o que aumenta a escalabilidade do sistema e sua capacidade de tolerar falhas. Sistemas Pervasivos/Ub\u00edquos Segundo Weiser, 1993 Ubiquitous computing is the method of enhancing computer use by making many computers available throughout the physical environment, but making them effectively invisible to the user. Assim, sistemas ub\u00edquos aumentam e otimizam a intera\u00e7\u00e3o do usu\u00e1rio com o ambiente, para que estes foquem-se na tarefa em vez de na ferramenta. Outra forma de se colocar, \u00e9 que sistemas pervasivos devem ajudar as pessoas a realizar suas tarefas, de forma impl\u00edcita, sem ter que pensar em como a tarefa ser\u00e1 executada. Para que seja realizada, a computa\u00e7\u00e3o pervasiva requer que dispositivos detectem o contexto em que est\u00e3o inseridos, combinem-se de forma ad-hoc e compartilhem informa\u00e7\u00f5es. Exemplos fict\u00edcios e reais Smart Life Esta \u00e9 uma vis\u00e3o futur\u00edstica da Microsoft para a integra\u00e7\u00e3o de tecnologias. Amazon Go Este mercado automatiza o pagamento dos itens escolhidos pelo consumidor, utilizando t\u00e9cnicas de processamento digital de imagens, aprendizado de m\u00e1quina e sensores. Reality Check Para quem viu o filme Minority Report e sonhou com as UI do futuro, aqui vai um reality check . Para quem n\u00e3o viu ainda, corrija esta falha em sua forma\u00e7\u00e3o t\u00e9cnica o mais rapidamente poss\u00edvel. Redes de Sensores e Internet das Coisas Eu vou me arriscar colocando Redes de Sensores e Internet das Coisas como uma subsess\u00e3o de Sistemas Pervasivos. Isto porqu\u00ea, a meu ver, as redes de sensores s\u00e3o parte da infraestrutura para se obter sistemas pervasivos; s\u00e3o os sensores que percebem mudan\u00e7as contexto e \"le\u00eam\" o estado do contexto atual e alimentam outros sistemas que reagem a tal estado. A Internet das Coisas (IoT, do ingl\u00eas Internet of Things ) vai tamb\u00e9m na mesma linha, levando \u00e0 integra\u00e7\u00e3o entre sensores, atuadores, e outros dispositivos que nos servem, em um ambiente de computa\u00e7\u00e3o pervasiva. \"Mas se \u00e9 assim, qual o risco?\", voc\u00ea pergunta. Bem, a Internet das Coisas pode ser vista como algo al\u00e9m dos sistemas pervasivos, pois se estes \u00faltimos s\u00e3o focados nos humanos em um certo contexto, a IoT n\u00e3o necessariamente foca-se nos humanos, mas na realiza\u00e7\u00e3o de alguma tarefa. Por exemplo, um sistema de irriga\u00e7\u00e3o que percebe o n\u00edvel de humidade do ar, analisa previs\u00f5es de chuva e decide em quanto irrigar uma planta\u00e7\u00e3o de laranjas provavelmente n\u00e3o se importar\u00e1 com a presen\u00e7a ou n\u00e3o de um humano na planta\u00e7\u00e3o. Alguns exemplos de IoT e redes de sensores Smart grid e lavadora que escolhe hor\u00e1rio Termostatos que percebem movimento Fechaduras que se abrem quando o dono se aproxima Movimenta\u00e7\u00e3o de tropas e de fauna \u00cdndices de polui\u00e7\u00e3o Abalos s\u00edsmicos e predi\u00e7\u00e3o de avalanches link Uma nota sobre privacidade nos sistemas pervasivos \u00c0 medida em que aumentamos o ambiente ao nosso redor ou a n\u00f3s mesmos com dispositivos computacionais, por um lado facilitamos nossa vida pois somos assistidos por tais dispositivos, mas por outro, nos tornamos cada vez mais dependentes nos mesmos, com s\u00e9rios riscos \u00e0 nossa privacidade. Isto ocorre por que para que realizem suas tarefas, os sistemas pervasivos precisam de cada vez mais informa\u00e7\u00f5es sobre n\u00f3s, e h\u00e1 sempre o risco de que estas informa\u00e7\u00f5es sejam usadas de forma que n\u00e3o nos apetece. Exemplos de hacking em IOT Hackers Can Access Pacemakers, but Don\u2019t Panic Just Yet Ethical hacker shows us how easily smart devices can be hacked and give access to your personal info Your Roomba May Be Mapping Your Home, Collecting Data That Could Be Shared . Projeto Como puderam ver at\u00e9 agora, a \u00e1rea de computa\u00e7\u00e3o distribu\u00edda \u00e9 rica aplica\u00e7\u00f5es e desenvolv\u00ea-los \u00e9 topar de frente com v\u00e1rios problemas e decidir como resolv\u00ea-los ou contorn\u00e1-los e, por isto, nada melhor que um projeto para experimentar em primeira m\u00e3o as ang\u00fastias e prazeres da \u00e1rea. Assim, proponho visitarmos o material destas notas \u00e0 luz de uma aplica\u00e7\u00e3o gen\u00e9rica mas real, desenvolvida por voc\u00eas enquanto vemos a teoria. O projeto consiste em uma aplica\u00e7\u00e3o com dois tipos de usu\u00e1rios, os clientes e os administradores. Voc\u00ea pode pensar em termos de compradores e lojistas, pacientes e m\u00e9dicos, ou consumidores e produtores de conte\u00fado. As funcionalidades s\u00e3o expostas para estes usu\u00e1rios via duas aplica\u00e7\u00f5es distintas, o portal do cliente e o portal administrativo , mas ambos manipulam a mesma base de dados. A base de dados \u00e9 particionada usando consistent hashing e as parti\u00e7\u00f5es s\u00e3o mantidas em mem\u00f3ria apenas. Uma terceira camada prov\u00ea persist\u00eancia de dados e toler\u00e2ncia a falhas, replicando os dados. A imagem descreve a aplica\u00e7\u00e3o. Apesar de introduzir complexidade extra, usaremos diversos mecanismos para a comunica\u00e7\u00e3o entre as partes, para que possam experimentar com diversas abordagens. Cliente <-> Portal cliente - Sockets Administrador <-> Portal administrativo - RPC Portais <-> Cache - Publish-Subscribe /Fila de mensagens Cache <-> Banco de dados - Comunica\u00e7\u00e3o em grupo A arquitetura tamb\u00e9m ser\u00e1 h\u00edbrida, contendo um pouco de Cliente/Servidor e Peer-2-Peer, al\u00e9m de ser multicamadas. Etapa 1 - Usu\u00e1rios/Portais Portal Cliente O Cliente possui identificador \u00fanico, CID O Cliente tem um \"saco\" de dados com diversas entradas armazenados no sistema, que podem ser manipuladas individualmente ou em conjunto. inserirTarefa(CID, \"titulo da tarefa\", \"descri\u00e7\u00e3o da tarefa\"): Sucesso/Falha modificarTarefa(CID, \"titulo da tarefa\", \"nova descri\u00e7\u00e3o da tarefa\"): Sucesso/Falha listarTarefas(CID): Lista de tuplas (titulo,Descri\u00e7\u00e3o) apagarTarefas(CID): Sucesso/Falha apagarTarefa(CID, \"titulo da tarefa\"): Sucesso/Falha Os dados s\u00e3o mantidos em uma tabela hash (BigInteger 5 ,Bytes) A comunica\u00e7\u00e3o entre cliente e portal cliente se d\u00e1 por sockets TCP/IP. Portal Administrativo O Administrador gera um CID para cada cliente, baseado em seu nome ou outro atributo \u00fanico. O Administrador manipula clientes inserirCliente(CID, \"dados do cliente\"): Sucesso/Falha modificarCliente(CID, \"novos dados do cliente\"): Sucesso/Falha recuperarCliente(CID): \"dados do cliente\" apagarCliente(CID): Sucesso/Falha Os dados s\u00e3o mantidos em uma tabela hash (BigInteger 5 ,Bytes) A comunica\u00e7\u00e3o entre Administrador e portal Administrativo se d\u00e1 por gRPC. Os portais sicronizam suas bases de dados A sincroniza\u00e7\u00e3o acontece via MQTTP ou Kafka. As bases poder\u00e3o ficar inconsistentes, mas isso ser\u00e1 resolvido na etapa 2. Clientes e Administradores devem ter uma aplica\u00e7\u00e3o para acesso aos portais. Etapa 2 - Cache Nesta segunda etapa voc\u00ea modificar\u00e1 o sistema para que os portais, em vez de armazenar os dados em tabelas hash locais, o fa\u00e7am em uma tabela remota, compartilhada entre os portais. A tabela hash remota \u00e9 particionada para permitir o armazenamento de mais dados do que caberiam em apenas um computador. Isto \u00e9, \u00e9 essencialmente uma Distributed Hash Table, a base dos bancos de dados NoSQL como Redis, Memcached ou Cassandra. Portais Os dados s\u00e3o armazenados no banco distribu\u00eddo A comunica\u00e7\u00e3o com o banco \u00e9 feita via MQTTP ou Kafka Banco As parti\u00e7\u00f5es usam consistent hashing para distribuir os dados Uma requisi\u00e7\u00e3o feita para a parti\u00e7\u00e3o errada deve ser encaminhada para a parti\u00e7\u00e3o correta usando o algoritmo de roteamento Chord. Etapa 3 - Durabilidade Nesta etapa tornaremos todas as opera\u00e7\u00f5es feitas no banco de dados permanentes por meio de um log remoto ou pela replica\u00e7\u00e3o das parti\u00e7\u00f5es. Mais detalhes se seguir\u00e3o. Refer\u00eancias The Log: What every software engineer should know about real-time data's unifying abstraction Vision and challenges for realising the Internet of things Neste ponto, devo estressar que muitos se referem a sistemas n\u00e3o-distribu\u00eddos como centralizados mas preferimos reservar este termo para sistemas distribu\u00eddos que usam um processo centralizador. O termo monol\u00edtico tamb\u00e9m \u00e9 muito usado em contraposi\u00e7\u00e3o \u00e0 arquitetura de micro-servi\u00e7os, mas sentimos que este uso est\u00e1 de acordo com o uso que fazemos aqui. \u21a9 Escolhemos aqui ignorar o argumento muito plaus\u00edvel de que um algoritmo distribu\u00eddo poderia ser executado entre, por exemplo, diversos chips em uma mesma placa. \u21a9 What Can We Learn from Four Years of Data Center Hardware Failures? \u21a9 Mesmo que o custo n\u00e3o fosse um problema, seria imposs\u00edvel implementar scale up funcionalmente al\u00e9m de um certo limite, pois o computador teria que ser t\u00e3o grande que suas partes teriam que ser tratadas independentemente, revertendo a um cen\u00e1rio scale out custoso demais. \u21a9 Inteiro de 64 bits n\u00e3o \u00e9 BigInteger. \u21a9 \u21a9","title":"Introdu\u00e7\u00e3o"},{"location":"intro/#introducao","text":"Escrever bons sistemas distribu\u00eddos \u00e9 uma tarefa que esbarra em diversos obst\u00e1culos, sendo a defini\u00e7\u00e3o do que \u00e9 um sistema distribu\u00eddo e do que \u00e9 ser \"bom\" neste contexto sendo nossos primeiros obst\u00e1culos.","title":"Introdu\u00e7\u00e3o"},{"location":"intro/#o-que-sao-sistemas-distribuidos","text":"Sistemas simples Para atacarmos a primeira quest\u00e3o e entendermos o que \u00e9 um Sistema Distribu\u00eddo, talvez seja mais f\u00e1cil come\u00e7ar pelo que n\u00e3o \u00e9 um sistema n\u00e3o-distribu\u00eddo. Estes s\u00e3o os sistemas que cont\u00e9m em um \u00fanico processo toda a l\u00f3gica de neg\u00f3cio, armazenamento e interface com usu\u00e1rio, mesmo que sejam divididos em v\u00e1rios m\u00f3dulos e usem diferentes bibliotecas e frameworks . Sejam estes sistemas constru\u00eddo com blocos que se encaixam perfeitamente, disponibilizados basicamente pela biblioteca da linguagem que est\u00e1 utilizando; Sistemas n\u00e3o t\u00e3o simples ou desenvolvido por times com diversas pessoas e usando bibliotecas de muitos fornecedores diferentes, aumentando consideravelmente a complexidade do desenvolvimento; o resultado, contudo, continua sendo um artefato s\u00f3, executado como um \u00fanico processo, e por isso os denominaremos sistemas monol\u00edtico . 1 Programar sistemas distribu\u00eddos \u00e9 dar outro salto em complexidade, pois frequentemente temos que usar pe\u00e7as que n\u00e3o foram pensadas para trabalhar juntas, for\u00e7ando-nos a usar um pouco de super-cola e arame. Cable hell! Bem, na verdade, em vez de cola usamos middleware , como logo discutiremos, e, em vez de arame, usamos cabos de rede, o que \u00e9, de fato, a principal caracter\u00edstica de um sistema distribu\u00eddo em rela\u00e7\u00e3o a um n\u00e3o-distribu\u00eddo: separa\u00e7\u00e3o e dispers\u00e3o de suas partes em v\u00e1rios componentes independentes (processos, sensores, atuadores, etc), mas que se coordenam para execu\u00e7\u00e3o de alguma tarefa. Vejamos alguns exemplos de tarefas executadas por sistemas distribu\u00eddos, que voc\u00ea usa hoje. Entregue este email para fulano@knowhere.uni . Envie o item I para o endere\u00e7o E, ap\u00f3s cobran\u00e7a de D dinheiros da conta C. Em um ambiente de simula\u00e7\u00e3o de batalhas em 3D, simule o disparo de um proj\u00e9til na dire\u00e7\u00e3o em que o o avatar est\u00e1 olhando, com velocidade V, enquanto movimenta o avatar A para a esquerda com velocidade W. Autorize a transfer\u00eancia de D dinheiros da conta C para a conta C'. Movimente o bra\u00e7o mec\u00e2nico que est\u00e1 segurando um bisturi, 3cm \u00e0 direita, ent\u00e3o abaixe-o 3mm, e movimente-o 4cm para a esquerda Inclua o coment\u00e1rio ``LOL!!!'' na lista de coment\u00e1rios do item XYZ, com marca de tempo T Leia o valor do sensor de temperatura T e, caso seu valor supere V, emita alarme luminoso vermelho intermitente e alarme sonoro Fica claro por estes exemplos que h\u00e1 comunica\u00e7\u00e3o entre diversos componentes, por exemplo o console de videogame e um servi\u00e7o que mantem uma \"sala\" aberta para um jogo. Assim, uma poss\u00edvel defini\u00e7\u00e3o de Sistema Distribu\u00eddo, que me agrada, \u00e9 a seguinte: Sistema Distribu\u00eddo Cole\u00e7\u00e3o de sistemas computacionais (software ou hardware), independentes mas com alguma forma de comunica\u00e7\u00e3o , que colaboram na execu\u00e7\u00e3o de alguma tarefa . Componentes hospedeiro n\u00f3 No jarg\u00e3o da \u00e1rea, os componentes independentes s\u00e3o denominados n\u00f3s . Frequentemente, cada n\u00f3 do sistema ser\u00e1, na pr\u00e1tica, um processo em um computador hospedeiro, um host , para que possa fazer uso de todos os recursos do hospedeiro e, por isso, frequentemente nos referimos ao pr\u00f3prio host como o n\u00f3. Contudo, nada impede que possivelmente m\u00faltiplos n\u00f3s possam ser executados em um mesmo host ou mesmo que m\u00faltiplos hosts virtuais, sejam m\u00e1quinas virtuais ou containers, executem na mesma m\u00e1quina f\u00edsica; isso n\u00e3o muda o fato de que os componentes s\u00e3o independentes e poderiam ser distanciados. 2 Comunica\u00e7\u00e3o mem\u00f3ria compartilhada mensagens Quanto \u00e0 comunica\u00e7\u00e3o, os n\u00f3s podem compartilhar um espa\u00e7o de endere\u00e7amento comum, seja porqu\u00ea est\u00e3o co-locados no mesmo hospedeiro ou seja porqu\u00ea tem acesso a alguma forma de mem\u00f3ria compartilhada distribu\u00edda, que veremos mais adiante. Eles tamb\u00e9m podem se comunicar por mensagens trocadas via uma rede de comunica\u00e7\u00e3o, como a Internet. Quanto \u00e0 tarefa em comum, veja o seguinte exemplo, em que v\u00e1rios clientes trocam emails por meio de uma m\u00e1quina com a qual se comunicam para entregar mensagens a serem enviadas e receber mensagens a eles destinadas; enquanto aguardam a entrega, mensagens s\u00e3o armazenadas em um Sistema Gerenciador de Banco de Dados (SGBD) em uma outra m\u00e1quina, da qual os usu\u00e1rios n\u00e3o tem ci\u00eancia. Depend\u00eancia Ao colaborarem, criam depend\u00eancia Falha pode parar o sistema Neste exemplo, cada celular, o processo que implementa o servi\u00e7o de email e o servidor de banco de dados, s\u00e3o n\u00f3s do sistema. Observe que o n\u00f3 do servi\u00e7o de email \u00e9 respons\u00e1vel por receber os emails e encaminh\u00e1-los para o banco em um sentido, bem como ler emails do banco e entregar para os destinat\u00e1rios, no outro. Observe tamb\u00e9m que se o banco de dados para de funcionar, o servi\u00e7o de email passa a ser in\u00fatil, uma vez que n\u00e3o pode armazenar novas mensagens e nem recuperar mensagens j\u00e1 armazenadas. Disponibilidade falhas dependabilidade Neste contexto, uma defini\u00e7\u00e3o mais c\u00ednica mas definitivamente realista \u00e9 a de Leslie Lamport , que certa vez disse: A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable. Lamport est\u00e1 correto quanto aos problemas em sistemas distribu\u00eddos, e problemas podem se manifestar em diversas formas. Por exemplo, mesmo que um computador n\u00e3o pare, se ele ficar lento ou se o canal de comunica\u00e7\u00e3o n\u00e3o for confi\u00e1vel, uma aplica\u00e7\u00e3o cr\u00edtica poderia ser inviabilizada, como no exemplo de telecirurgia acima. Algumas aplica\u00e7\u00f5es, contudo, aparentemente conseguem superar estes obst\u00e1culos. Pensemos em algumas aplica\u00e7\u00f5es distribu\u00eddas com as quais interagimos todos os dias e que, por seu sucesso, devem ser bons sistemas distribu\u00eddos. Alguns exemplos \u00f3bvios s\u00e3o Amazon.com , Facebook , e GMail . Estes sistemas rodam em grandes data centers com milhares de m\u00e1quinas , estando constantemente sujeitos a fontes queimadas, discos corruptos, mem\u00f3rias defeituosas, etc 3 . Apesar disto, dificilmente estes servi\u00e7os s\u00e3o reportados como fora do ar, s\u00e3o altamente respons\u00edveis e, goste ou n\u00e3o do que fazem, s\u00e3o bem sucedidos porqu\u00ea cumprem bem suas tarefas. Assim, digamos que um sistema computacional \u00e9 bom se est\u00e1 sempre funcional, com bom desempenho e \u00e9 de baixo custo. Observe que estar sempre funcional implica em continuar provendo o servi\u00e7o mesmo que partes do sistema estejam com problemas, que ter bom desempenho implica que respostas \"r\u00e1pidas\" s\u00e3o dadas para o usu\u00e1rio, e que baixo custo implica em n\u00e3o gastar mais que o necess\u00e1rio para realizar a tarefa para a qual foi constru\u00eddo. Um \"bom\" sistema Dispon\u00edvel Falhas R\u00e1pido Desempenho Proximidade Barato Tamanho apropriado Enquanto subjetiva, nossa defini\u00e7\u00e3o de bom nos permite estabelecer um pano de fundo para delinear as dificuldades de se implementar sistemas distribu\u00eddos. Como veremos adiante, os requisitos para um bom sistema distribu\u00eddo s\u00e3o conflitantes e dif\u00edceis, as vezes imposs\u00edveis, de serem alcan\u00e7ados. Mas se esta \u00e9 a realidade da programa\u00e7\u00e3o distribu\u00edda, por qu\u00ea faz\u00ea-lo? A resposta tem a ver com a colabora\u00e7\u00e3o , na defini\u00e7\u00e3o.","title":"O qu\u00ea s\u00e3o Sistemas Distribu\u00eddos?"},{"location":"intro/#por-que-desenvolvemos-sistemas-distribuidos","text":"A primeira raz\u00e3o \u00e9 o fato \u00e9 que computadores individuais tem capacidade reduzida de processamento e armazenamento, mas nossa necessidade de poder computacional cresce exponencialmente. Assim, precisamos crescer nosso poder computacional, mas aumentar a capacidade de um dispositivo ( scale up ou vertical scaling ), mesmo de forma linear, tem custo exponencial. O que nos resta ent\u00e3o \u00e9 agregar o poder computacional de diversos computadores \"baratos\" ( scale out ou horizontal scaling ) para satisfazer nossas necessidades. 4 Mesmo se pensarmos que a escala com que estes sistemas trabalham deve ser muito diferente daquela dos sistemas que n\u00f3s desenvolvemos, e portanto as t\u00e9cnicas usadas em sua constru\u00e7\u00e3o devem ser muito distintas do que fazemos, a verdade n\u00e3o poderia ser mais longe disto. Com a quantidade de informa\u00e7\u00e3o armazenada a cada acesso a um s\u00edtio, a cada produto vendido, ou a cada consulta feita, praticamente qualquer sistema de informa\u00e7\u00e3o de sucesso necessitar\u00e1 aplicar as t\u00e9cnicas de computa\u00e7\u00e3o distribu\u00edda e superar as mesmas barreiras para conseguir atender ao n\u00famero crescente de clientes (computacionais ou humanos) e aumentar sua \u00e1rea de cobertura, mesmo que n\u00e3o chegue a escala dos exemplos acima, e melhorar ou manter a qualidade do servi\u00e7o que presta. PQ? escalabilidade toler\u00e2ncia a falhas Este \u00faltimo ponto, sobre qualidade do servi\u00e7o, tem a ver com a capacidade de um sistema se manter no ar a despeito de problemas, isto \u00e9, de ser tolerante a falhas. Toler\u00e2ncia a falhas implica em redund\u00e2ncia, em c\u00f3pias, o que fatidicamente implica em distribui\u00e7\u00e3o e em Sistemas Distribu\u00eddos. Assim, podemos concluir que as principais raz\u00f5es para se desenvolver sistemas distribu\u00eddos s\u00e3o alcan\u00e7ar escalabilidade e toler\u00e2ncia a falhas , ambas resultantes da agrega\u00e7\u00e3o (correta) do poder computacional de m\u00faltiplos componentes. Uma vez que tenhamos entendido o porqu\u00ea de desenvolver sistemas distribu\u00eddos, vejamos que tipos de sistemas resultam desta abordagem.","title":"Por qu\u00ea desenvolvemos sistemas distribu\u00eddos?"},{"location":"intro/#tipos-de-sistemas-distribuidos","text":"H\u00e1 quem diga que j\u00e1 somos todos desenvolvedores de sistemas distribu\u00eddos . Ainda assim, \u00e9 importante entender que h\u00e1 v\u00e1rios tipos de sistemas distribu\u00eddos, com diversas finalidades e diversas arquiteturas, pois classifica\u00e7\u00f5es nos ajudam a pensar sobre sistemas e a encontrar e reusar solu\u00e7\u00f5es previamente testadas e depuradas.","title":"Tipos de Sistemas Distribu\u00eddos"},{"location":"intro/#sistemas-de-computacao","text":"A possibilidade de agregar poder de processamento de muitos computadores via uma rede de comunica\u00e7\u00e3o com alt\u00edssima largura de banda nos permite atacar problemas computacionalmente muito intensos. Clusters como o da imagem a seguir, do High Performance Computing Center de Stuttgart, s\u00e3o compartilhados por pesquisadores resolvendo problemas de \u00e1reas como bio-inform\u00e1tica, engenharia, economia e intelig\u00eancia artificial. Na engenharia, por exemplo, HPC pode ser usada para testar a efici\u00eancia de projetos sem construir prot\u00f3tipos, seja de uma turbina um carro ou uma vaca Os n\u00f3s de um cluster s\u00e3o normalmente divididos em tr\u00eas categorias: administra\u00e7\u00e3o, computa\u00e7\u00e3o e armazenamento. N\u00f3s de administra\u00e7\u00e3o implementam um monitoramento distribu\u00eddo dos demais n\u00f3s, servem de ponto de entrada para usu\u00e1rios e prov\u00eaem interface para submiss\u00e3o de tarefas. O Oscar , por exemplo, \u00e9 uma \u00e9 conjunto de softwares para gerenciamento de clusters. Uma das ferramentas inclusas no Oscar \u00e9 o OpenPBS, pelo qual tarefas s\u00e3o atribu\u00eddas aos diversos n\u00f3s do sistema que estejam alocados para tal tarefa. O OpenPBS portanto \u00e9 tamb\u00e9m um sistema distribu\u00eddo. Finalmente, as tarefas submetidas em si s\u00e3o tamb\u00e9m aplica\u00e7\u00f5es distribu\u00eddas em que cada processo executando em uma m\u00e1quina distinta \u00e9 respons\u00e1vel por resolver uma parte do problema. Este tipo de sistemas distribu\u00eddos s\u00e3o o que chamamos de fortemente acoplados pois a falha em um dos componentes leva normalmente \u00e0 falha de todo o sistema. Do ponto de vista deste curso, estamos mais interessados em sistemas fracamente acoplados . Um outro tipo de sistema, fracamente acoplado, mas com a mesma finalidade de atacar problemas que exigem muita computa\u00e7\u00e3o, s\u00e3o as grades computacionais . Muito usadas at\u00e9 meados da d\u00e9cada passada, neste arranjo, membros de uma associa\u00e7\u00e3o disponibilizam capacidade computacional a um pool . De l\u00e1, os recursos podem ser acessados, seguindo algum crit\u00e9rio de gerenciamento, por quaisquer dos membros da associa\u00e7\u00e3o. Este modelo surgiu de iniciativas como o SETI@home , em que pessoas doavam tempo ocioso do seu computador para analisar sinais de r\u00e1dio recebidos do espa\u00e7o. Ap\u00f3s o sucesso inicial, a computa\u00e7\u00e3o foi movida de computadores de volunt\u00e1rios para os de institui\u00e7\u00f5es com interesses em comum. As grades computacionais s\u00e3o \u00e0s vezes vistas como precursoras da computa\u00e7\u00e3o utilit\u00e1ria , isto \u00e9, o fornecimento de recursos computacionais por provedores em troca de um pagamento proporcional \u00e0 quantidade de recursos utilizados, como no fornecimento de \u00e1gua ou eletricidade. A materializa\u00e7\u00e3o recente da computa\u00e7\u00e3o utilit\u00e1ria s\u00e3o as nuvens computacionais. Este tipo de sistema, embora possa ser pensando como infraestrutura para outros sistemas distribu\u00eddos, s\u00e3o, na verdade, complexas pe\u00e7as de engenharia, com diversos subsistemas respons\u00e1veis por sincroniza\u00e7\u00e3o de rel\u00f3gios, monitora\u00e7\u00e3o de falhas, coleta de logs, roteamento eficiente tolerante a falhas, movimenta\u00e7\u00e3o de recursos virtualizados para consolida\u00e7\u00e3o de recursos f\u00edsicos, armazenamento redundante de dados, etc. O seguinte v\u00eddeo mostra, em 360 graus, um dos datacenters do Google, para que voc\u00ea tenha ideia da escala em que estes sistemas s\u00e3o constru\u00eddos. J\u00e1 este outro s\u00edtio apresenta uma viagem fotogr\u00e1fica por alguns datacenters .","title":"Sistemas de Computa\u00e7\u00e3o"},{"location":"intro/#sistemas-de-informacao","text":"Provavelmente mais comuns entre os profissionais da computa\u00e7\u00e3o, os sistemas de informa\u00e7\u00e3o distribu\u00eddos s\u00e3o encontrados em diversas formas. De fato, o termo \"sistema de informa\u00e7\u00e3o\" \u00e9 t\u00e3o abrangente, que dificilmente um sistema distribu\u00eddo n\u00e3o estaria nesta classe. O seguinte \u00e9 um exemplo de uma arquitetura em tr\u00eas camadas, onde a primeira implementa a interface com o usu\u00e1rio, a segunda cont\u00e9m a l\u00f3gica do neg\u00f3cio, e a terceira mantem os dados. Pe\u00e7a fundamental desta abordagem, os bancos de dados na terceira camada s\u00e3o frequentemente transacionais. Isto \u00e9, eles prov\u00eaem as garantias na execu\u00e7\u00e3o de transa\u00e7\u00f5es conhecidas como propriedades ACID. ACID Atomicidade: transa\u00e7\u00f5es s\u00e3o tratadas de forma indivis\u00edvel, isto \u00e9, ou tudo ou nada. Consist\u00eancia: transa\u00e7\u00f5es levam banco de um estado consistente a outro. E.g., x == 2*y Isolamento: transa\u00e7\u00f5es n\u00e3o v\u00eaem dados n\u00e3o comitados umas das outras. Durabilidade: os efeitos de uma transa\u00e7\u00e3o comitada devem persistir no sistema a despeito de falhas. Para relembrar no que implica ACID, considere a seguinte sequ\u00eancia de opera\u00e7\u00f5es, onde X e Y s\u00e3o valores guardados pelo banco de dados, a, b e c s\u00e3o vari\u00e1veis definidas no programa, e SELECT e SET s\u00e3o comandos para ler e modificar o banco de dados. 1 2 3 4 5 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: SET Y=b Suponha duas inst\u00e2ncias desta sequ\u00eancia, \\(T_1\\) e \\(T_2\\) , concorrentes, em que as opera\u00e7\u00f5es escalonadas da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 T1 T2 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: a = SELECT X 6: c = a * 2 7: b = c + 10 8: SET X=c 9: SET Y=b 10:SET Y=b Ao final da execu\u00e7\u00e3o, X ter\u00e1 o valor atribu\u00eddo por \\(T_2\\) , mas \\(Y\\) ter\u00e1 o valor de \\(T_1\\) . Este escalonamento violou a consist\u00eancia do banco de dados por qu\u00ea as opera\u00e7\u00f5es n\u00e3o foram executadas isoladamente . Tente imaginar a dificuldade de se implementar um banco de dados distribu\u00eddo. Isto \u00e9, um banco em que v\u00e1rios n\u00f3s mantem os dados, participam de transa\u00e7\u00f5es e, portanto, precisam coordenar-se para manter os dados consistentes. A figura a seguir mostra um cen\u00e1rio com tr\u00eas bancos; imagine que em um deles est\u00e1 uma rela\u00e7\u00e3o com os dados dos clientes, em outro, os dados do estoque e, no terceiro, as ordens de compra. Quando um cliente faz um pedido, o cliente deve ser validado no primeiro n\u00f3, o item \u00e9 removido do estoque no segundo, e uma cobran\u00e7a \u00e9 disparada para o cliente no terceiro. Se qualquer destas tr\u00eas rela\u00e7\u00f5es n\u00e3o for corretamente consultada e alterada, os efeitos podem ser catastr\u00f3ficos para o neg\u00f3cio ou para o cliente. graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B Como implementar ACID neste banco de dados? Embora veremos isso um pouco mais para frente neste material, por enquanto, apenas assuma que n\u00e3o \u00e9 exatamente f\u00e1cil ou barato. Esta dificuldade foi a raz\u00e3o do surgimento dos bancos de dados NOSQL (n\u00e9e NoSQL), dos quais uma pequena amostra \u00e9 dada pela seguinte figura. Tamb\u00e9m discutiremos como estes bancos de dados funcionam, quando falarmos sobre sistemas P2P.","title":"Sistemas de Informa\u00e7\u00e3o"},{"location":"intro/#integracao-de-aplicacoes","text":"Frequentemente \u00e9 necess\u00e1rio integrar sistemas de informa\u00e7\u00e3o legados com sistemas mais modernos, ou simplesmente exp\u00f4-los usando uma interface mais moderna. Nestes casos, \u00e9 poss\u00edvel integrar diversos sistemas usando um middleware que os encapsule. Veremos mais adiante o que \u00e9 um middleware ; por enquanto, pense nele apenas como um camada de software que se interp\u00f5e entre os clientes e um servi\u00e7o oferecido. No exemplo, o middleware pode, por exemplo, se expor via interface REST para os clientes, mas consultar o sistema legado em um padr\u00e3o antigo. Outro exemplo, na imagem seguinte, \u00e9 um sistema que agrega subsistemas de diversos departamentos de uma empresa via troca de mensagens. Observe que nenhum departamento precisa conversar diretamente com os outros, ou mesmo conhec\u00ea-los; eles apenas publicam a mensagem para quem tiver interesse e aguardam um resposta tamb\u00e9m na forma de uma mensagem. Observe que nenhum componente tem que saber da exist\u00eancia do outro ou se torna indispon\u00edvel caso os outros falhem, o que aumenta a escalabilidade do sistema e sua capacidade de tolerar falhas.","title":"Integra\u00e7\u00e3o de Aplica\u00e7\u00f5es"},{"location":"intro/#sistemas-pervasivosubiquos","text":"Segundo Weiser, 1993 Ubiquitous computing is the method of enhancing computer use by making many computers available throughout the physical environment, but making them effectively invisible to the user. Assim, sistemas ub\u00edquos aumentam e otimizam a intera\u00e7\u00e3o do usu\u00e1rio com o ambiente, para que estes foquem-se na tarefa em vez de na ferramenta. Outra forma de se colocar, \u00e9 que sistemas pervasivos devem ajudar as pessoas a realizar suas tarefas, de forma impl\u00edcita, sem ter que pensar em como a tarefa ser\u00e1 executada. Para que seja realizada, a computa\u00e7\u00e3o pervasiva requer que dispositivos detectem o contexto em que est\u00e3o inseridos, combinem-se de forma ad-hoc e compartilhem informa\u00e7\u00f5es. Exemplos fict\u00edcios e reais Smart Life Esta \u00e9 uma vis\u00e3o futur\u00edstica da Microsoft para a integra\u00e7\u00e3o de tecnologias. Amazon Go Este mercado automatiza o pagamento dos itens escolhidos pelo consumidor, utilizando t\u00e9cnicas de processamento digital de imagens, aprendizado de m\u00e1quina e sensores. Reality Check Para quem viu o filme Minority Report e sonhou com as UI do futuro, aqui vai um reality check . Para quem n\u00e3o viu ainda, corrija esta falha em sua forma\u00e7\u00e3o t\u00e9cnica o mais rapidamente poss\u00edvel.","title":"Sistemas Pervasivos/Ub\u00edquos"},{"location":"intro/#redes-de-sensores-e-internet-das-coisas","text":"Eu vou me arriscar colocando Redes de Sensores e Internet das Coisas como uma subsess\u00e3o de Sistemas Pervasivos. Isto porqu\u00ea, a meu ver, as redes de sensores s\u00e3o parte da infraestrutura para se obter sistemas pervasivos; s\u00e3o os sensores que percebem mudan\u00e7as contexto e \"le\u00eam\" o estado do contexto atual e alimentam outros sistemas que reagem a tal estado. A Internet das Coisas (IoT, do ingl\u00eas Internet of Things ) vai tamb\u00e9m na mesma linha, levando \u00e0 integra\u00e7\u00e3o entre sensores, atuadores, e outros dispositivos que nos servem, em um ambiente de computa\u00e7\u00e3o pervasiva. \"Mas se \u00e9 assim, qual o risco?\", voc\u00ea pergunta. Bem, a Internet das Coisas pode ser vista como algo al\u00e9m dos sistemas pervasivos, pois se estes \u00faltimos s\u00e3o focados nos humanos em um certo contexto, a IoT n\u00e3o necessariamente foca-se nos humanos, mas na realiza\u00e7\u00e3o de alguma tarefa. Por exemplo, um sistema de irriga\u00e7\u00e3o que percebe o n\u00edvel de humidade do ar, analisa previs\u00f5es de chuva e decide em quanto irrigar uma planta\u00e7\u00e3o de laranjas provavelmente n\u00e3o se importar\u00e1 com a presen\u00e7a ou n\u00e3o de um humano na planta\u00e7\u00e3o. Alguns exemplos de IoT e redes de sensores Smart grid e lavadora que escolhe hor\u00e1rio Termostatos que percebem movimento Fechaduras que se abrem quando o dono se aproxima Movimenta\u00e7\u00e3o de tropas e de fauna \u00cdndices de polui\u00e7\u00e3o Abalos s\u00edsmicos e predi\u00e7\u00e3o de avalanches link","title":"Redes de Sensores e Internet das Coisas"},{"location":"intro/#uma-nota-sobre-privacidade-nos-sistemas-pervasivos","text":"\u00c0 medida em que aumentamos o ambiente ao nosso redor ou a n\u00f3s mesmos com dispositivos computacionais, por um lado facilitamos nossa vida pois somos assistidos por tais dispositivos, mas por outro, nos tornamos cada vez mais dependentes nos mesmos, com s\u00e9rios riscos \u00e0 nossa privacidade. Isto ocorre por que para que realizem suas tarefas, os sistemas pervasivos precisam de cada vez mais informa\u00e7\u00f5es sobre n\u00f3s, e h\u00e1 sempre o risco de que estas informa\u00e7\u00f5es sejam usadas de forma que n\u00e3o nos apetece. Exemplos de hacking em IOT Hackers Can Access Pacemakers, but Don\u2019t Panic Just Yet Ethical hacker shows us how easily smart devices can be hacked and give access to your personal info Your Roomba May Be Mapping Your Home, Collecting Data That Could Be Shared .","title":"Uma nota sobre privacidade nos sistemas pervasivos"},{"location":"intro/#projeto","text":"Como puderam ver at\u00e9 agora, a \u00e1rea de computa\u00e7\u00e3o distribu\u00edda \u00e9 rica aplica\u00e7\u00f5es e desenvolv\u00ea-los \u00e9 topar de frente com v\u00e1rios problemas e decidir como resolv\u00ea-los ou contorn\u00e1-los e, por isto, nada melhor que um projeto para experimentar em primeira m\u00e3o as ang\u00fastias e prazeres da \u00e1rea. Assim, proponho visitarmos o material destas notas \u00e0 luz de uma aplica\u00e7\u00e3o gen\u00e9rica mas real, desenvolvida por voc\u00eas enquanto vemos a teoria. O projeto consiste em uma aplica\u00e7\u00e3o com dois tipos de usu\u00e1rios, os clientes e os administradores. Voc\u00ea pode pensar em termos de compradores e lojistas, pacientes e m\u00e9dicos, ou consumidores e produtores de conte\u00fado. As funcionalidades s\u00e3o expostas para estes usu\u00e1rios via duas aplica\u00e7\u00f5es distintas, o portal do cliente e o portal administrativo , mas ambos manipulam a mesma base de dados. A base de dados \u00e9 particionada usando consistent hashing e as parti\u00e7\u00f5es s\u00e3o mantidas em mem\u00f3ria apenas. Uma terceira camada prov\u00ea persist\u00eancia de dados e toler\u00e2ncia a falhas, replicando os dados. A imagem descreve a aplica\u00e7\u00e3o. Apesar de introduzir complexidade extra, usaremos diversos mecanismos para a comunica\u00e7\u00e3o entre as partes, para que possam experimentar com diversas abordagens. Cliente <-> Portal cliente - Sockets Administrador <-> Portal administrativo - RPC Portais <-> Cache - Publish-Subscribe /Fila de mensagens Cache <-> Banco de dados - Comunica\u00e7\u00e3o em grupo A arquitetura tamb\u00e9m ser\u00e1 h\u00edbrida, contendo um pouco de Cliente/Servidor e Peer-2-Peer, al\u00e9m de ser multicamadas.","title":"Projeto"},{"location":"intro/#etapa-1-usuariosportais","text":"Portal Cliente O Cliente possui identificador \u00fanico, CID O Cliente tem um \"saco\" de dados com diversas entradas armazenados no sistema, que podem ser manipuladas individualmente ou em conjunto. inserirTarefa(CID, \"titulo da tarefa\", \"descri\u00e7\u00e3o da tarefa\"): Sucesso/Falha modificarTarefa(CID, \"titulo da tarefa\", \"nova descri\u00e7\u00e3o da tarefa\"): Sucesso/Falha listarTarefas(CID): Lista de tuplas (titulo,Descri\u00e7\u00e3o) apagarTarefas(CID): Sucesso/Falha apagarTarefa(CID, \"titulo da tarefa\"): Sucesso/Falha Os dados s\u00e3o mantidos em uma tabela hash (BigInteger 5 ,Bytes) A comunica\u00e7\u00e3o entre cliente e portal cliente se d\u00e1 por sockets TCP/IP. Portal Administrativo O Administrador gera um CID para cada cliente, baseado em seu nome ou outro atributo \u00fanico. O Administrador manipula clientes inserirCliente(CID, \"dados do cliente\"): Sucesso/Falha modificarCliente(CID, \"novos dados do cliente\"): Sucesso/Falha recuperarCliente(CID): \"dados do cliente\" apagarCliente(CID): Sucesso/Falha Os dados s\u00e3o mantidos em uma tabela hash (BigInteger 5 ,Bytes) A comunica\u00e7\u00e3o entre Administrador e portal Administrativo se d\u00e1 por gRPC. Os portais sicronizam suas bases de dados A sincroniza\u00e7\u00e3o acontece via MQTTP ou Kafka. As bases poder\u00e3o ficar inconsistentes, mas isso ser\u00e1 resolvido na etapa 2. Clientes e Administradores devem ter uma aplica\u00e7\u00e3o para acesso aos portais.","title":"Etapa 1 - Usu\u00e1rios/Portais"},{"location":"intro/#etapa-2-cache","text":"Nesta segunda etapa voc\u00ea modificar\u00e1 o sistema para que os portais, em vez de armazenar os dados em tabelas hash locais, o fa\u00e7am em uma tabela remota, compartilhada entre os portais. A tabela hash remota \u00e9 particionada para permitir o armazenamento de mais dados do que caberiam em apenas um computador. Isto \u00e9, \u00e9 essencialmente uma Distributed Hash Table, a base dos bancos de dados NoSQL como Redis, Memcached ou Cassandra. Portais Os dados s\u00e3o armazenados no banco distribu\u00eddo A comunica\u00e7\u00e3o com o banco \u00e9 feita via MQTTP ou Kafka Banco As parti\u00e7\u00f5es usam consistent hashing para distribuir os dados Uma requisi\u00e7\u00e3o feita para a parti\u00e7\u00e3o errada deve ser encaminhada para a parti\u00e7\u00e3o correta usando o algoritmo de roteamento Chord.","title":"Etapa 2 - Cache"},{"location":"intro/#etapa-3-durabilidade","text":"Nesta etapa tornaremos todas as opera\u00e7\u00f5es feitas no banco de dados permanentes por meio de um log remoto ou pela replica\u00e7\u00e3o das parti\u00e7\u00f5es. Mais detalhes se seguir\u00e3o.","title":"Etapa 3 - Durabilidade"},{"location":"intro/#referencias","text":"The Log: What every software engineer should know about real-time data's unifying abstraction Vision and challenges for realising the Internet of things Neste ponto, devo estressar que muitos se referem a sistemas n\u00e3o-distribu\u00eddos como centralizados mas preferimos reservar este termo para sistemas distribu\u00eddos que usam um processo centralizador. O termo monol\u00edtico tamb\u00e9m \u00e9 muito usado em contraposi\u00e7\u00e3o \u00e0 arquitetura de micro-servi\u00e7os, mas sentimos que este uso est\u00e1 de acordo com o uso que fazemos aqui. \u21a9 Escolhemos aqui ignorar o argumento muito plaus\u00edvel de que um algoritmo distribu\u00eddo poderia ser executado entre, por exemplo, diversos chips em uma mesma placa. \u21a9 What Can We Learn from Four Years of Data Center Hardware Failures? \u21a9 Mesmo que o custo n\u00e3o fosse um problema, seria imposs\u00edvel implementar scale up funcionalmente al\u00e9m de um certo limite, pois o computador teria que ser t\u00e3o grande que suas partes teriam que ser tratadas independentemente, revertendo a um cen\u00e1rio scale out custoso demais. \u21a9 Inteiro de 64 bits n\u00e3o \u00e9 BigInteger. \u21a9 \u21a9","title":"Refer\u00eancias"},{"location":"projeto/","text":"no sql cresceram rapidamente em uso e implementacoes.a facilidade e familiaridade do sql tem atrativos fortes. cockroach and yugabyte. entender como funcionam \u00e9 importate para qquer um interessado em SD. In this project we will develop a rudimentary no SQL database and use that many difficulties to implement such a project to introduce concepts and frameworks related to the development of distributing systems. We will start by exploring the Waze stocked each other in a Distributed system. Then we will Dan will be explored different Architectures used to combine the efforts of components in the distributed system. Next we explore the guarantees that databases can provide to their users and how these guarantees are insured. To do move the session to an introductory part with either the preface or introduction itself. O objetivo deste projeto \u00e9 praticar o projeto de sistemas distribu\u00eddos, usando v\u00e1rias arquiteturas e tecnologias. A ideia \u00e9 implementar um banco de dados NoSQL (Not only SQL) rudimentar. Mesmo uma vers\u00e3o simples de um banco de dados distribu\u00eddo \u00e9 um sistema complexo e por isso voc\u00ea dever\u00e1 trabalhar em fases. Infelizmnte enquanto esta abordagem facilita a jornada, ela poder\u00e1 levar a um pouco de retrabalho no final. Para garantir que todo o seu esfor\u00e7o ser\u00e1 concentrado no lugar certo e que sua avalia\u00e7\u00e3o seja justa, atente-se aos detalhes e aos passos na especifica\u00e7\u00e3o abaixo. Etapa 1 - Cliente/Servidor usando RPC Objetivos Hash Table acess\u00edvel remotamente por interface CRUD usando gRPC. Armazenamento em disco com recupera\u00e7\u00e3o de dados no caso de falhas Desafios Especifica\u00e7\u00e3o do protocolo para dados gen\u00e9ricos Armazenamento at\u00f4mico no disco Multithreading para garantir escalabilidade Controle de concorr\u00eancia para garantir corretude nos dados armazenados. Servidor Todos os dados devem ser armazenados em um mapa Chave-Valor (Dicion\u00e1rio) Chave \u00e9 um n\u00famero de precis\u00e3o arbitr\u00e1ria do tipo BigInteger Valor \u00e9 uma tripla (Vers\u00e3o, Timestamp, Dados) Vers\u00e3o \u00e9 um inteiro com 64 bits (long) Timestamp \u00e9 um inteiro com 64 bits (long) Dados \u00e9 um vetor de bytes (byte[]) de tamanho arbitr\u00e1rio O servidor implementa a seguinte API: set(k,ts,d):(e,v') adiciona ao mapa a entrada k-v, caso n\u00e3o exista uma entrada com a chave k, onde v=(1,ts,d) retorna a tupla (e,v') onde e=SUCCESS e v'=NULL se k-v foi inserido retorna a tupla (e,v') onde e=ERROR e v'=(ver,ts,data) se j\u00e1 existia uma entrada no banco de dados com a chave k e vers, ts e data correspondem, respectivamente, \u00e0 vers\u00e3o, timestamp e dados de tal entrada get(k):(e,v') retorna a tupla (e,v') onde e=ERROR e v'=NULL se n\u00e3o h\u00e1 entrada no banco de dados com chave k retorna a tupla (e,v') onde e=SUCCESS e v'=(ver,ts,data) se j\u00e1 existia uma entrada no banco de dados com a chave k e vers, ts e data correspondem, respectivamente, \u00e0 vers\u00e3o, timestamp e dados de tal entrada del(k):(e,v') remove a entrada k-v' do banco de dados se existir retorna a tupla (e,v') onde e=SUCCESS e v'=(ver,ts,data) se j\u00e1 existia uma entrada no banco de dados com a chave k e vers, ts e data correspondem, respectivamente, \u00e0 vers\u00e3o, timestamp e dados de tal entrada retorna a tupla (e,v') onde e=ERROR e v'=NULL se n\u00e3o existia entrada com chave k no banco de dados. del(k,vers):(e,v') remove a entrada k-v' do banco de dados se existir e tiver vers\u00e3o v retorna a tupla (e,v') onde e=SUCCESS e v'=(vers,ts,data) se j\u00e1 existia uma entrada no banco de dados com a chave k e vers e ts e data correspondem, respectivamente, timestamp e dados de tal entrada retorna a tupla (e,v') onde e=ERROR_NE e v'=NULL se n\u00e3o existia entrada com chave k no banco de dados. retorna a tupla (e,v') onde e=ERROR_WV e v'=(ver',ts,data) se j\u00e1 existia uma entrada no banco de dados com a chave k version vers' not equal to vers, e ts e data correspondem, respectivamente, timestamp e dados de tal entrada testAndSet(k,v,vers):(e,v') atualiza o mapa se a vers\u00e3o atual no sistema corresponde \u00e0 vers\u00e3o especificada. retorna a tupla (e,v') onde e=SUCCESS e v'=(ver,ts,data) se j\u00e1 existia uma entrada no banco de dados com a chave k e version vers, e ts e data correspondem, respectivamente, timestamp e dados de tal entrada retorna a tupla (e,v') onde e=ERROR_NE e v'=NULL se n\u00e3o existia uma entrada no banco com chave k; retorna a tupla (e,v') onde e=ERROR_WV e v'=(ver',ts,data) se j\u00e1 existia uma entrada no banco de dados com a chave k version vers' not equal to vers, e ts e data correspondem, respectivamente, timestamp e dados de tal entrada O mapa deve ser salvo em disco Com periodicidade configur\u00e1vel, os dados do mapa devem ser salvos em disco. Os dados em disco devem corresponder a uma vers\u00e3o dos dados em mem\u00f3ria. Para entender, veja a seguinte sequ\u00eancia de eventos, que leva a uma vers\u00e3o em disco que nunca ocorreu em mem\u00f3ria. Dados em mem\u00f3ria (1/lala, 2/lele, 3/lili) C\u00f3pia para disco iniciada Dados em disco (1/lala) Dados em mem\u00f3ria (1/lolo, 2/lele, 3/lili) Dados em disco (1/lala, 2/lele) Dados em mem\u00f3ria (1/lolo, 2/lele, 3/lulu) Dados em disco (1/lala, 2/lele, 3/lulu) Cliente O cliente deve implementar uma UI que permita a intera\u00e7\u00e3o com o banco de dados usando todas as API Testes Um segundo cliente implementar\u00e1 as seguintes baterias de testes no sistema Teste de todas as API levando a todos os tipos de resultados (sucesso e erro) Teste de estresse em que a API seja exercitada pelo menos 1000 vezes e o resultado final deve ser demonstrado como esperado (por exemplo, inserir 1000 entradas com chaves distintas, atualizar a todas as entradas, ler todas a entradas e verificar que o valor, isto \u00e9, vers\u00e3o e dados, correspondem aos esperados. Todos os testes apresentam os resultados esperados mesmo quando m\u00faltiplos clientes de teste s\u00e3o executados em paralelo. Comunica\u00e7\u00e3o Toda a comunica\u00e7\u00e3o entre cliente e servidor deve ser feita usando gRPC Apresenta\u00e7\u00e3o Demonstrar que todos os itens da especifica\u00e7\u00e3o foram seguidos Demonstrar a corretude do sistema frente aos testes Enumerar outros testes e casos cobertos implemententados Demonstrar comportamento quando comunica\u00e7\u00e3o \u00e9 interrompida no meio do teste Etapa 2 - Toler\u00e2ncia a Falhas Objetivos Replicar o servidor para obter toler\u00e2ncia a falhas. Desafios Certificar-se de que o servidor \u00e9 uma m\u00e1quina de estados determin\u00edstica Compreender o uso de Difus\u00e3o At\u00f4mica em n\u00edvel te\u00f3rico Compreender o uso de Difus\u00e3o At\u00f4mica em n\u00edvel pr\u00e1tico (Via Ratis ) Aplicar difus\u00e3o at\u00f4mica na replica\u00e7\u00e3o do servidor Servidor A API permanece a mesma e implementada via gRPC. Requisi\u00e7\u00f5es para o servidor (linha cont\u00ednua) s\u00e3o encaminhadas via Ratis (linha tracejada) para orden\u00e1-las e entregar a todas as r\u00e9plicas (linha pontilhada) para s\u00f3 ent\u00e3o serem executadas e respondidas (pontilhado fino). Dados n\u00e3o s\u00e3o mais armazenados em disco pela sua aplica\u00e7\u00e3o mas somente via Ratis. Cliente Sem altera\u00e7\u00e3o. Testes O mesmo framework de testes deve continuar funcional Comunica\u00e7\u00e3o Entre cliente e servidor, usar gRPC Entre servidores, usar Ratis Apresenta\u00e7\u00e3o Sem altera\u00e7\u00e3o, isto \u00e9, gravar um v\u00eddeo demonstrando que os requisitos foram atendidos.","title":"Index"},{"location":"tech/","text":"Tecnologias O objetivo deste cap\u00edtulo \u00e9 visitar algumas t\u00e9cnicas e tecnologias recentes e interessantes na \u00e1rea de sistemas distribu\u00eddos. N\u00e3o espere ent\u00e3o que as v\u00e1rias se\u00e7\u00f5es sejam conexas umas com as outras. Como sincronizar duas m\u00e1quinas? Abordagem 1 Copie os arquivos da fonte para o destino Abordagem 2 Produza um hash do arquivo Troque o hash com a outra m\u00e1quina Se hashes iguais, pronto. Se hashes diferentes, copie o arquivo para a outra m\u00e1quina. Abordagem 3 - Merkle Tree 1 Divida o arquivo em blocos de mesmo tamanho Fa\u00e7a um hash de cada bloco Se mais de um hash gerado, Concatene hashes duas a duas; cada concatena\u00e7\u00e3o resulta em um novo bloco. Repita o processo; os hashes resultantes correspondem a uma \u00e1rvore Troque hashes da raiz. Se hashes iguais, pronto. Se hashes diferentes troque hashes das raizes das sub\u00e1rvores e execute recursivamente. Se um byte \u00e9 adicionado no meio do arquivo? A conclus\u00e3o \u00e9 que blocos com tamanho pr\u00e9-definido s\u00e3o problem\u00e1ticos e que precisamos de blocos definidos pelo conte\u00fado. Por exemplo, em um texto, uma possibilidade \u00e9 definir um bloco como um per\u00edodo ou um par\u00e1grafo; se uma palavra \u00e9 inserida no texto, , somente o bloco em que foi inserida \u00e9 modificado e somente o hash do mesmo ter\u00e1 novo valor. Mas esta abordagem n\u00e3o \u00e9 gen\u00e9rica, pois qual o correspondente em uma imagem ou um \u00e1udio ou em um arquivo tgz ? Rabin Fingerprinting Rabin Fingerprint Rolling Hash Blockchain Uma cadeia de fornecimento ( supply chain ), temos, em v\u00e1rios n\u00edveis, Clientes , Vendedores e Fornecedores , que estabelecem contratos de bens e servi\u00e7os. A um consumidor seria interessante saber quem produziu o cacho de bananas que est\u00e1 comprando, se a produ\u00e7\u00e3o \u00e9 livre de trabalho escravo, se o transporte foi feito dentro de par\u00e2metros corretos de temperatura, se n\u00e3o violou tratados de rotas mar\u00edtimas para proteger baleias, e assim por diante. Essencialmente, seria interessante rastrear como o bem \"bananas\" foi transferido de m\u00e3o em m\u00e3o at\u00e9 chegar \u00e0 feira livre. H\u00e1 diversos tipos de bens , tang\u00edveis (e.g., casa ) e intang\u00edveis (e.g., patente ), nominais (e.g., promiss\u00f3ria ) e ao portador (e.g., dinheiro \"vivo\" ), etc. As intera\u00e7\u00f5es multipartido podem ser registradas em livros raz\u00e3o mantidos pelos independentemente pelos participantes, registrando cada troca bens envolvendo o participante respons\u00e1vel. Esta abordagem dificilmente permitiria aos participantes ou auditores reconstruir todo o trajeto , que dir\u00e1 um consumidor na ponta, al\u00e9m ser suscet\u00edvel a modifica\u00e7\u00f5es , intencionais ou n\u00e3o. Blockchains prov\u00eaem um \"livro raz\u00e3o\" incorrupt\u00edvel , decentralizado e \"facilmente\" audit\u00e1vel. Desde que Nakamoto introduziu a primeira blockchain 2 , destinada a \"rastrear\" a troca de uma moeda digital, a bitcoin , diversas outras blockchains foram desenvolvidas, para diferentes usos e com diferentes funcionalidades. Algumas caracter\u00edsticas comuns, ou pelo menos desej\u00e1veis, das blockchains s\u00e3o Decentralizado - Replicado usando P2P e n\u00e3o facilmente subjug\u00e1vel. (Hyperledger, da IBM, n\u00e3o \u00e9.) Consenso - acordo na transa\u00e7\u00e3o Proveni\u00eancia - todo o hist\u00f3rico de um bem \u00e9 mantido na blockchain Imutabilidade - entradas n\u00e3o podem ser alteradas Finalidade - entradas n\u00e3o podem ser refutadas Bitcoin Everything you don't understand about money, combined with everything you don't understand about technology. Joh Oliver, Last Week Tonight, Mar\u00e7o 2018. Al\u00e9m disso, no mundo dos neg\u00f3cios, \u00e9 interessante que possa usar a blockchain para diferentes tipos de bens (na bitcoin , s\u00f3 a bitcoin ), que as partes sejam identific\u00e1veis (na bitcoin , os usu\u00e1rios s\u00e3o an\u00f4nimos), e que n\u00e3o gaste muito energia ( bitcoin usa proof-of-work , que gasta muita, muita energia). Vejamos um exemplo de como uma blockchain funciona . Os termos do neg\u00f3cio s\u00e3o mantidos na blockchain: \"Se na data X a entidade E n\u00e3o tiver transferido D dinheiros para a entidade F, ent\u00e3o transfira o asset A de E para F.\" Se quiser saber mais, consulte esta pequena lista artigos sobre blockchain . Todo Smart-contracts proof-of-stake grupos pequenos como certificadores. A Small Piece of Big Data Big-Data Big data is a term for data sets that are so large or complex that traditional data processing application software is inadequate to deal with them. Ciclo convencional: Coleta Armazenamento An\u00e1lise Consulta Compartilhamento Visualiza\u00e7\u00e3o Atualiza\u00e7\u00e3o ... \u00c1reas Grandes massas de dados: Propaganda Astronomia Ci\u00eancia e-governos meteorologia genomics Dados Internet das coisas sensoriamento remoto suas fotos logs de software RFID redes de sensores ... Qu\u00e3o grande \u00e9 ``big'' o suficiente? Depende dos dados, ferramentas, e capacidade de manipul\u00e1-los. Uma vez dado um passo, o alvo passa a ser o pr\u00f3ximo passo. Isso quer dizer que vai de alguns TB at\u00e9 Petabytes, dependendo do problema. Gartner, 2012 Big data is high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization. Volume: incapacidade de armazenar todos os dados; apenas observe e guarde conclus\u00f5es Velocidade: dados passando em ``tempo real'' Variedade: imagens, v\u00eddeos, \u00e1udio, temperatura,... Machine learning para automa\u00e7\u00e3o de extra\u00e7\u00e3o de informa\u00e7\u00e3o, por exemplo, detec\u00e7\u00e3o de padr\u00f5es, sem se preocupar com o porqu\u00ea dos mesmos. Como lidar? Bancos de dados colunares Stream DBs MapReduce ... Google FS Google, 2003 File System Dados recuperados da Internet usados em consultas Milh\u00f5es de arquivos de m\u00faltiplos GB Chunks de 64MB (``blocos do disco'') Opera\u00e7\u00f5es comuns s\u00e3o appends ou reads Servidores/discos/mem\u00f3rias est\u00e3o sempre falhando Centenas de clientes concorrentes no mesmo arquivo Clusters de n\u00f3s ``comuns'' Master node: metadata Chunk servers: data Permite usar um cluster como um \u00fanico HD el\u00e1stico na rede. Fonte Apps recebem \\emph{leases} de acesso direto aos dados Atomic commitment garante consist\u00eancia entre r\u00e9plicas Fonte Consist\u00eancia Application sends the file name and data to the GFS client. GFS Client send the file name and chunk index to master Master sends the identity of the primary and other secondary replicas to the client. Client caches this information. Client contacts master again only when primary is unreachable or it sends a reply saying it does not holds the lease anymore. Considering the network topology the client sends the data to all the replicas.This improves performance. GFS separates data flow from the control flow. Replicas store the data in their LRU buffers till it is used. After all replicas receiving of the data, client sends write request to the primary. Primary decides the mutation order. It applies this order to its local copy. Primary sends the write request to all the secondary replicas. They perform write according to serial order decided by the primary. After completing the operation all secondary acknowledge primary. Primary replies the client about completion of the operation. In case of the errors that is when some of the secondary fail to write client request is supposed to be fail.This leaves modified chunk inconsistent. Client handles this by retrying the failed mutation. Fonte Map Reduce Google, 2004 Processamento distribu\u00eddo Processa arquivos no Google FS Chubby 1 2 * Google, 2006 ![](images/chubby1.png) Hadoop HDFS: Hadoop Distributed File System Map Reduce Yahoo! Open source em 2011, 1.0.0 2012, 2.0.0, 2017, 3.0.0 nov 2018, 2.9.2 Ecosistema Hive: data warehouse Spark: Kafka Yarn Pig: linguagem para especifica\u00e7\u00e3o de data flow. HBase: banco de dados estruturado Sqoop Flume Oozie Avro: serializa\u00e7\u00e3o Mahout: machine learning HDFS Distribu\u00eddo Escal\u00e1vel Cost effective Tolerante a falhas Alta vaz\u00e3o Arquitetura Rack e rack failure Top of rack switch Core switch Name Node: nomes das pastas e arquivos Data Node: conte\u00fado dos arquivos Cliente Arquitetura Crie arquivo: cliente -> name node Escreva um block (e.g., 128MB): cliente Aloque block: cliente -> name node Salve os dados: cliente -> data node Heartbeat block report: data node -> name node Dados s\u00e3o replicados (RF configurado por arquivo): Data node -> data node Name node Dados em memory e edit log. Name node \u00e9 um SPOF? Quorum Journal Manager replica edit log. Standby Name Node Zookeeper usado para decidir quem \u00e9 o l\u00edder Secondary Name Node replica checkpoint da imagem em mem\u00f3ria. MapReduce Programa\u00e7\u00e3o funcional Map: (map length (() (a) (a b c)) = (0 1 3)) Fold/Reduce: (reduce + (1 2 3)) = 6 MapReduce N\u00e3o h\u00e1 depend\u00eancia entre os dados Dados divididos em \\emph{shards} Execu\u00e7\u00e3o paralela e distribu\u00edda Trabalhador recebe um shard Mestre agrega valores Milhares de processos Petabytes de dados MapReduce Shards s\u00e3o arquivos do GFS/HDFS/EC2 Fun\u00e7\u00e3o mapeada a cada shard Resultado \u00e9 lista de chaves e valores Agrega\u00e7\u00e3o acontece por chaves Resultado s\u00e3o arquivos no GFS/HDFS/EC2 MapReduce Exemplo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import ... public class WordCount { public static class TokenizerMapper extends Mapper < Object , Text , Text , IntWritable > { private final static IntWritable one = new IntWritable ( 1 ); private Text word = new Text (); public void map ( Object key , Text value , Context context ) throws IOException , InterruptedException { StringTokenizer itr = new StringTokenizer ( value . toString ()); while ( itr . hasMoreTokens ()) { word . set ( itr . nextToken ()); context . write ( word , one ); } } } ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ... public static class IntSumReducer extends Reducer < Text , IntWritable , Text , IntWritable > { private IntWritable result = new IntWritable (); public void reduce ( Text key , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException { int sum = 0 ; for ( IntWritable val : values ) sum += val . get (); result . set ( sum ); context . write ( key , result ); } } public static void main ( String [] args ) throws Exception { ... } } Fonte https://youtu.be/DJPwV2ge9m0?list=PLkz1SCf5iB4dw3jbRo0SYCk2urRESUA3v Estudo de caso: Kafka ![](images/kafka0.png Quote Kafka is a distributed streaming platform. LinkedIn OpenSource em 2011 Projeto Apache em ???? Producers x Message Broker x Consumers Produtores: enviam dados/mensagens/records (array de bytes) Consumidores: recebem dados Cluster/Broker: distribu\u00eddo e tolerantes a falhas. Conectores: integra\u00e7\u00e3o simplificada com outras aplica\u00e7\u00f5es Stream processors: spark ou outros frameworks; transformam dados Brokers Cluster de brokers Distribu\u00eddo Tolerante a falhas Desacoplamento espacial Desacoplamento temporal T\u00f3picos, n\u00e3o endere\u00e7os T\u00f3picos Nome de uma stream de dados: ordem de servi\u00e7o, exame de sangue, MSFT Quantidade pode ser imensa. Parti\u00e7\u00e3o Subdivis\u00f5es de t\u00f3picos N\u00famero de parti\u00e7\u00f5es \u00e9 definido por usu\u00e1rio Cada parti\u00e7\u00e3o est\u00e1 associada a um \u00fanico servidor Offset \u00cdndice de uma mensagem em uma parti\u00e7\u00e3o \u00cdndices atribu\u00eddos na ordem de chegada Offsets s\u00e3o locais \u00e0s parti\u00e7\u00f5es Mensagens s\u00e3o unicamente identificadas por (t\u00f3pico, parti\u00e7\u00e3o, \u00edndice) Consumer group Carga pode ser muito grande para um consumidor Compartilham o processamento de um t\u00f3pico Cada mensagem \u00e9 processada por um membro do grupo A mesma mensagem pode ser processada por m\u00faltiplos grupos N\u00famero de consumidores \\(\\leq\\) parti\u00e7\u00f5es no t\u00f3pico M\u00e1ximo de dois consumidores por parti\u00e7\u00e3o (mantem pos. de cada um) Siga o tutorial , at\u00e9 o passo 5. Baixe e descompacte Rode o zookeeper (Terminal 1) Rode o Kafka (Terminal 2) Crie um t\u00f3pico (Terminal 3) - Mais de uma parti\u00e7\u00e3o em um servidor Conecte-se ao Zookeeper e d\u00ea uma olhada. O que est\u00e1 vendo? Liste os t\u00f3picos criados Envie algumas mensagens Inicie um consumidor (Terminal 4) Modern Algorithms and Data Structures: Merkle Trees \u21a9 Bitcoin: A Peer-to-Peer Electronic Cash System \u21a9","title":"Tecnologias"},{"location":"tech/#tecnologias","text":"O objetivo deste cap\u00edtulo \u00e9 visitar algumas t\u00e9cnicas e tecnologias recentes e interessantes na \u00e1rea de sistemas distribu\u00eddos. N\u00e3o espere ent\u00e3o que as v\u00e1rias se\u00e7\u00f5es sejam conexas umas com as outras.","title":"Tecnologias"},{"location":"tech/#como-sincronizar-duas-maquinas","text":"Abordagem 1 Copie os arquivos da fonte para o destino Abordagem 2 Produza um hash do arquivo Troque o hash com a outra m\u00e1quina Se hashes iguais, pronto. Se hashes diferentes, copie o arquivo para a outra m\u00e1quina. Abordagem 3 - Merkle Tree 1 Divida o arquivo em blocos de mesmo tamanho Fa\u00e7a um hash de cada bloco Se mais de um hash gerado, Concatene hashes duas a duas; cada concatena\u00e7\u00e3o resulta em um novo bloco. Repita o processo; os hashes resultantes correspondem a uma \u00e1rvore Troque hashes da raiz. Se hashes iguais, pronto. Se hashes diferentes troque hashes das raizes das sub\u00e1rvores e execute recursivamente. Se um byte \u00e9 adicionado no meio do arquivo? A conclus\u00e3o \u00e9 que blocos com tamanho pr\u00e9-definido s\u00e3o problem\u00e1ticos e que precisamos de blocos definidos pelo conte\u00fado. Por exemplo, em um texto, uma possibilidade \u00e9 definir um bloco como um per\u00edodo ou um par\u00e1grafo; se uma palavra \u00e9 inserida no texto, , somente o bloco em que foi inserida \u00e9 modificado e somente o hash do mesmo ter\u00e1 novo valor. Mas esta abordagem n\u00e3o \u00e9 gen\u00e9rica, pois qual o correspondente em uma imagem ou um \u00e1udio ou em um arquivo tgz ?","title":"Como sincronizar duas m\u00e1quinas?"},{"location":"tech/#rabin-fingerprinting","text":"Rabin Fingerprint Rolling Hash","title":"Rabin Fingerprinting"},{"location":"tech/#blockchain","text":"Uma cadeia de fornecimento ( supply chain ), temos, em v\u00e1rios n\u00edveis, Clientes , Vendedores e Fornecedores , que estabelecem contratos de bens e servi\u00e7os. A um consumidor seria interessante saber quem produziu o cacho de bananas que est\u00e1 comprando, se a produ\u00e7\u00e3o \u00e9 livre de trabalho escravo, se o transporte foi feito dentro de par\u00e2metros corretos de temperatura, se n\u00e3o violou tratados de rotas mar\u00edtimas para proteger baleias, e assim por diante. Essencialmente, seria interessante rastrear como o bem \"bananas\" foi transferido de m\u00e3o em m\u00e3o at\u00e9 chegar \u00e0 feira livre. H\u00e1 diversos tipos de bens , tang\u00edveis (e.g., casa ) e intang\u00edveis (e.g., patente ), nominais (e.g., promiss\u00f3ria ) e ao portador (e.g., dinheiro \"vivo\" ), etc. As intera\u00e7\u00f5es multipartido podem ser registradas em livros raz\u00e3o mantidos pelos independentemente pelos participantes, registrando cada troca bens envolvendo o participante respons\u00e1vel. Esta abordagem dificilmente permitiria aos participantes ou auditores reconstruir todo o trajeto , que dir\u00e1 um consumidor na ponta, al\u00e9m ser suscet\u00edvel a modifica\u00e7\u00f5es , intencionais ou n\u00e3o. Blockchains prov\u00eaem um \"livro raz\u00e3o\" incorrupt\u00edvel , decentralizado e \"facilmente\" audit\u00e1vel. Desde que Nakamoto introduziu a primeira blockchain 2 , destinada a \"rastrear\" a troca de uma moeda digital, a bitcoin , diversas outras blockchains foram desenvolvidas, para diferentes usos e com diferentes funcionalidades. Algumas caracter\u00edsticas comuns, ou pelo menos desej\u00e1veis, das blockchains s\u00e3o Decentralizado - Replicado usando P2P e n\u00e3o facilmente subjug\u00e1vel. (Hyperledger, da IBM, n\u00e3o \u00e9.) Consenso - acordo na transa\u00e7\u00e3o Proveni\u00eancia - todo o hist\u00f3rico de um bem \u00e9 mantido na blockchain Imutabilidade - entradas n\u00e3o podem ser alteradas Finalidade - entradas n\u00e3o podem ser refutadas Bitcoin Everything you don't understand about money, combined with everything you don't understand about technology. Joh Oliver, Last Week Tonight, Mar\u00e7o 2018. Al\u00e9m disso, no mundo dos neg\u00f3cios, \u00e9 interessante que possa usar a blockchain para diferentes tipos de bens (na bitcoin , s\u00f3 a bitcoin ), que as partes sejam identific\u00e1veis (na bitcoin , os usu\u00e1rios s\u00e3o an\u00f4nimos), e que n\u00e3o gaste muito energia ( bitcoin usa proof-of-work , que gasta muita, muita energia). Vejamos um exemplo de como uma blockchain funciona . Os termos do neg\u00f3cio s\u00e3o mantidos na blockchain: \"Se na data X a entidade E n\u00e3o tiver transferido D dinheiros para a entidade F, ent\u00e3o transfira o asset A de E para F.\" Se quiser saber mais, consulte esta pequena lista artigos sobre blockchain . Todo Smart-contracts proof-of-stake grupos pequenos como certificadores.","title":"Blockchain"},{"location":"tech/#a-small-piece-of-big-data","text":"Big-Data Big data is a term for data sets that are so large or complex that traditional data processing application software is inadequate to deal with them. Ciclo convencional: Coleta Armazenamento An\u00e1lise Consulta Compartilhamento Visualiza\u00e7\u00e3o Atualiza\u00e7\u00e3o ... \u00c1reas Grandes massas de dados: Propaganda Astronomia Ci\u00eancia e-governos meteorologia genomics Dados Internet das coisas sensoriamento remoto suas fotos logs de software RFID redes de sensores ... Qu\u00e3o grande \u00e9 ``big'' o suficiente? Depende dos dados, ferramentas, e capacidade de manipul\u00e1-los. Uma vez dado um passo, o alvo passa a ser o pr\u00f3ximo passo. Isso quer dizer que vai de alguns TB at\u00e9 Petabytes, dependendo do problema. Gartner, 2012 Big data is high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization. Volume: incapacidade de armazenar todos os dados; apenas observe e guarde conclus\u00f5es Velocidade: dados passando em ``tempo real'' Variedade: imagens, v\u00eddeos, \u00e1udio, temperatura,... Machine learning para automa\u00e7\u00e3o de extra\u00e7\u00e3o de informa\u00e7\u00e3o, por exemplo, detec\u00e7\u00e3o de padr\u00f5es, sem se preocupar com o porqu\u00ea dos mesmos. Como lidar? Bancos de dados colunares Stream DBs MapReduce ... Google FS Google, 2003 File System Dados recuperados da Internet usados em consultas Milh\u00f5es de arquivos de m\u00faltiplos GB Chunks de 64MB (``blocos do disco'') Opera\u00e7\u00f5es comuns s\u00e3o appends ou reads Servidores/discos/mem\u00f3rias est\u00e3o sempre falhando Centenas de clientes concorrentes no mesmo arquivo Clusters de n\u00f3s ``comuns'' Master node: metadata Chunk servers: data Permite usar um cluster como um \u00fanico HD el\u00e1stico na rede. Fonte Apps recebem \\emph{leases} de acesso direto aos dados Atomic commitment garante consist\u00eancia entre r\u00e9plicas Fonte Consist\u00eancia Application sends the file name and data to the GFS client. GFS Client send the file name and chunk index to master Master sends the identity of the primary and other secondary replicas to the client. Client caches this information. Client contacts master again only when primary is unreachable or it sends a reply saying it does not holds the lease anymore. Considering the network topology the client sends the data to all the replicas.This improves performance. GFS separates data flow from the control flow. Replicas store the data in their LRU buffers till it is used. After all replicas receiving of the data, client sends write request to the primary. Primary decides the mutation order. It applies this order to its local copy. Primary sends the write request to all the secondary replicas. They perform write according to serial order decided by the primary. After completing the operation all secondary acknowledge primary. Primary replies the client about completion of the operation. In case of the errors that is when some of the secondary fail to write client request is supposed to be fail.This leaves modified chunk inconsistent. Client handles this by retrying the failed mutation. Fonte Map Reduce Google, 2004 Processamento distribu\u00eddo Processa arquivos no Google FS Chubby 1 2 * Google, 2006 ![](images/chubby1.png) Hadoop HDFS: Hadoop Distributed File System Map Reduce Yahoo! Open source em 2011, 1.0.0 2012, 2.0.0, 2017, 3.0.0 nov 2018, 2.9.2 Ecosistema Hive: data warehouse Spark: Kafka Yarn Pig: linguagem para especifica\u00e7\u00e3o de data flow. HBase: banco de dados estruturado Sqoop Flume Oozie Avro: serializa\u00e7\u00e3o Mahout: machine learning HDFS Distribu\u00eddo Escal\u00e1vel Cost effective Tolerante a falhas Alta vaz\u00e3o Arquitetura Rack e rack failure Top of rack switch Core switch Name Node: nomes das pastas e arquivos Data Node: conte\u00fado dos arquivos Cliente Arquitetura Crie arquivo: cliente -> name node Escreva um block (e.g., 128MB): cliente Aloque block: cliente -> name node Salve os dados: cliente -> data node Heartbeat block report: data node -> name node Dados s\u00e3o replicados (RF configurado por arquivo): Data node -> data node Name node Dados em memory e edit log. Name node \u00e9 um SPOF? Quorum Journal Manager replica edit log. Standby Name Node Zookeeper usado para decidir quem \u00e9 o l\u00edder Secondary Name Node replica checkpoint da imagem em mem\u00f3ria. MapReduce Programa\u00e7\u00e3o funcional Map: (map length (() (a) (a b c)) = (0 1 3)) Fold/Reduce: (reduce + (1 2 3)) = 6 MapReduce N\u00e3o h\u00e1 depend\u00eancia entre os dados Dados divididos em \\emph{shards} Execu\u00e7\u00e3o paralela e distribu\u00edda Trabalhador recebe um shard Mestre agrega valores Milhares de processos Petabytes de dados MapReduce Shards s\u00e3o arquivos do GFS/HDFS/EC2 Fun\u00e7\u00e3o mapeada a cada shard Resultado \u00e9 lista de chaves e valores Agrega\u00e7\u00e3o acontece por chaves Resultado s\u00e3o arquivos no GFS/HDFS/EC2 MapReduce Exemplo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import ... public class WordCount { public static class TokenizerMapper extends Mapper < Object , Text , Text , IntWritable > { private final static IntWritable one = new IntWritable ( 1 ); private Text word = new Text (); public void map ( Object key , Text value , Context context ) throws IOException , InterruptedException { StringTokenizer itr = new StringTokenizer ( value . toString ()); while ( itr . hasMoreTokens ()) { word . set ( itr . nextToken ()); context . write ( word , one ); } } } ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ... public static class IntSumReducer extends Reducer < Text , IntWritable , Text , IntWritable > { private IntWritable result = new IntWritable (); public void reduce ( Text key , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException { int sum = 0 ; for ( IntWritable val : values ) sum += val . get (); result . set ( sum ); context . write ( key , result ); } } public static void main ( String [] args ) throws Exception { ... } } Fonte https://youtu.be/DJPwV2ge9m0?list=PLkz1SCf5iB4dw3jbRo0SYCk2urRESUA3v","title":"A Small Piece of Big Data"},{"location":"tech/#estudo-de-caso-kafka","text":"![](images/kafka0.png Quote Kafka is a distributed streaming platform. LinkedIn OpenSource em 2011 Projeto Apache em ???? Producers x Message Broker x Consumers Produtores: enviam dados/mensagens/records (array de bytes) Consumidores: recebem dados Cluster/Broker: distribu\u00eddo e tolerantes a falhas. Conectores: integra\u00e7\u00e3o simplificada com outras aplica\u00e7\u00f5es Stream processors: spark ou outros frameworks; transformam dados Brokers Cluster de brokers Distribu\u00eddo Tolerante a falhas Desacoplamento espacial Desacoplamento temporal T\u00f3picos, n\u00e3o endere\u00e7os T\u00f3picos Nome de uma stream de dados: ordem de servi\u00e7o, exame de sangue, MSFT Quantidade pode ser imensa. Parti\u00e7\u00e3o Subdivis\u00f5es de t\u00f3picos N\u00famero de parti\u00e7\u00f5es \u00e9 definido por usu\u00e1rio Cada parti\u00e7\u00e3o est\u00e1 associada a um \u00fanico servidor Offset \u00cdndice de uma mensagem em uma parti\u00e7\u00e3o \u00cdndices atribu\u00eddos na ordem de chegada Offsets s\u00e3o locais \u00e0s parti\u00e7\u00f5es Mensagens s\u00e3o unicamente identificadas por (t\u00f3pico, parti\u00e7\u00e3o, \u00edndice) Consumer group Carga pode ser muito grande para um consumidor Compartilham o processamento de um t\u00f3pico Cada mensagem \u00e9 processada por um membro do grupo A mesma mensagem pode ser processada por m\u00faltiplos grupos N\u00famero de consumidores \\(\\leq\\) parti\u00e7\u00f5es no t\u00f3pico M\u00e1ximo de dois consumidores por parti\u00e7\u00e3o (mantem pos. de cada um) Siga o tutorial , at\u00e9 o passo 5. Baixe e descompacte Rode o zookeeper (Terminal 1) Rode o Kafka (Terminal 2) Crie um t\u00f3pico (Terminal 3) - Mais de uma parti\u00e7\u00e3o em um servidor Conecte-se ao Zookeeper e d\u00ea uma olhada. O que est\u00e1 vendo? Liste os t\u00f3picos criados Envie algumas mensagens Inicie um consumidor (Terminal 4) Modern Algorithms and Data Structures: Merkle Trees \u21a9 Bitcoin: A Peer-to-Peer Electronic Cash System \u21a9","title":"Estudo de caso: Kafka"},{"location":"time/","text":"Tempo Neste cap\u00edtulo discutiremos como o tempo \u00e9 importante no desenvolvimento de sistemas distribu\u00eddos. Comecemos por analisar o funcionamento de uma aplica\u00e7\u00e3o distribu\u00edda muito comum, o armazenamento de arquivos na nuvem, sincronizado com o sistema de arquivos local. Alguns exemplos do mundo real s\u00e3o Dropbox, Box, Google Drive and OneDrive; chamemos este servi\u00e7o genericamente de cloud-drive . Se um mesmo arquivo no cloud-drive \u00e9 modificado em duas m\u00e1quinas diferentes, enquanto as mesmas est\u00e3o desconectadas, o qu\u00ea acontece quando elas se reconectam \u00e0 Internet? Mais especificamente, quando as duas m\u00e1quinas se conectam e enviam suas vers\u00f5es do arquivo modificado para o servidor, sendo que ambas foram geradas a partir de um ancestral comum, qual vers\u00e3o deve ser armazenada e qual deve ser descartada? Uma possibilidade simples \u00e9 sempre aceitar cada nova vers\u00e3o como uma modifica\u00e7\u00e3o do arquivo. Assim, efetivamente, quando a primeira vers\u00e3o for entregue, ser\u00e1 aceita e viver\u00e1 momentaneamente at\u00e9 que a outra vers\u00e3o seja recebida e a sobrescreva. No exemplo seguinte, o resultado \u00e9 o mesmo que no exemplo anterior, sem falhas. Contudo, se estendermos um pouco mais a descontividade do n\u00f3 na parte de cima, o resultado final se inverte. No Exemplo, entre as entregas da \"Vers\u00e3o B\" e \"Vers\u00e3o A\" para o servidor no centro do diagrama, vale a \"Vers\u00e3o B\". Tamb\u00e9m pelo gr\u00e1fico, vemos que a \"Vers\u00e3o B\" foi criada depois da \"Vers\u00e3o A\", mas que a vers\u00e3o final vista pelo servidor \u00e9 exatamente a \"A\". Logo, questionamos se esta abordagem \u00e9 correta. Afinal ordem de chegada ao servidor n\u00e3o serve como crit\u00e9rio para escolha, afinal, a ordem de chegada dos arquivos ao servidor n\u00e3o reflete necessariamente a ordem em que os arquivos foram criados. Assim, podemos pensar em outras alternativas de aproveitamento e descarte de arquivos baseadas na cria\u00e7\u00e3o do arquivo. Contudo, o hor\u00e1rio de cria\u00e7\u00e3o de um arquivo \u00e9 relativo a onde foi criado e n\u00e3o ao grupo de processos que comp\u00f5e o sistema, o que pode levar uma modifica\u00e7\u00e3o que tenha acontecido mais tarde, do ponto de vista de um observador externo, a ter um hor\u00e1rio de cria\u00e7\u00e3o oficial anterior. Se for poss\u00edvel identificar a causalidade entre as modifica\u00e7\u00f5es, isto \u00e9, qual vers\u00e3o originou qual outra, ent\u00e3o \u00e9 claro que se deve manter vers\u00f5es de acordo com a ordem causal. Contudo, edi\u00e7\u00f5es concorrentes, como a cria\u00e7\u00e3o das vers\u00f5es A e B no exemplo anterior, n\u00e3o tem rela\u00e7\u00e3o de causalidade entre si. Assim, em qualquer destas linhas de atua\u00e7\u00e3o, voc\u00ea tem em m\u00e3os um conflito para resolver, e automatizar a resolu\u00e7\u00e3o do mesmo \u00e9 muito complicado. \u00c9 por isso que o Dropbox, por exemplo, deixa os dois arquivos para que o usu\u00e1rio analise e decida o que fazer, que servidores git exigem que o usu\u00e1rio pegue a vers\u00e3o salva mais recentemente e compatibilize suas mudan\u00e7as com ela antes de submeter novas mudan\u00e7as, e o Perforce trabalha com locks de arquivos. Se pensarmos em termos n\u00e3o de arquivos sendo enviados para um servidor, mas de opera\u00e7\u00f5es de modifica\u00e7\u00f5es sendo executadas, ent\u00e3o dada esta problem\u00e1tica, podemos simplificar a quest\u00e3o em nossas m\u00e3os. Como ordenar opera\u00e7\u00f5es de clientes? Se duas opera\u00e7\u00f5es originadas em clientes s\u00e3o enviadas ao servidor, qual deve ser executada primeiro? Embora, como j\u00e1 vimos, usar a ordem temporal da cria\u00e7\u00e3o das opera\u00e7\u00f5es tamb\u00e9m seja problem\u00e1tico, j\u00e1 que rel\u00f3gios s\u00e3o dessincronizados em sistemas distribu\u00eddos t\u00edpicos, alguns sistemas tentam resolver automaticamente os conflitos usando exatamente estes rel\u00f3gios. O CassandraDB, por exemplo, usa last write wins ou latest version wins , onde last \u00e9 definido em termos do rel\u00f3gio do cliente. Neste cen\u00e1rio, temos novo problema: Pergunta Como determinar qual foi enviada primeiro, em um sistema ass\u00edncrono? Para usar esta abordagem, precisamos encontrar uma fonte de tempo confi\u00e1vel e distribu\u00edda , constru\u00edda pelo uso de protocolos de sincroniza\u00e7\u00e3o de rel\u00f3gios f\u00edsicos Tempo F\u00edsico Para falarmos sobre sincroniza\u00e7\u00e3o de rel\u00f3gios em um cen\u00e1rio distribu\u00eddo, primeiro devemos entender como funcionam os rel\u00f3gios em n\u00edvel de uma \u00fanica m\u00e1quina, isto \u00e9, seus rel\u00f3gios f\u00edsicos e como s\u00e3o usados pelo sistema operacional. Rel\u00f3gios de Quartzo e At\u00f4micos Quando falamos em rel\u00f3gios, provavelmente falamos sobre rel\u00f3gios a base de quartzo. Para uma introdu\u00e7\u00e3o r\u00e1pida, assista o seguinte v\u00eddeo. Em suma, um rel\u00f3gio de quartzo consiste em um diapaz\u00e3o de quartzo cortado a laser que, devido ao efeito Piezoel\u00e9trico 2 e sua forma particular, vibra a \\(32768 = 2^{15}\\) Hz 3 , e em um contador que conta cada vibra\u00e7\u00e3o, medindo a passagem do tempo. Estes rel\u00f3gios erram na medi\u00e7\u00e3o do tempo em no m\u00e1ximo \u00bds por dia , desde que operem dentro da faixa de 5 a 35C, mas isso tamb\u00e9m muda com a idade do cristal, a corrente el\u00e9trica passando por ele e tamb\u00e9m devido a imperfei\u00e7\u00f5es no cristal 1 . Computadores em geral usam rel\u00f3gios de quartzo, por serem baratos, como base de um rel\u00f3gio mantido em software. Isto \u00e9, do ponto de vista de um computador comum, o tempo \u00e9 medido com base em um rel\u00f3gio quartzo, cujos incrementos s\u00e3o capturados em um contador; o contador gera interrup\u00e7\u00f5es em intervalos programados (e.g., Linux >2.6 usa 250Hz por padr\u00e3o; m\u00e1ximo 1000Hz) e as interrup\u00e7\u00f5es causam ajustes em um rel\u00f3gio em software , um contador indireto \\(C\\) . Precis\u00e3o Dado a frequ\u00eancia padr\u00e3o de 250Hz, medi\u00e7\u00f5es de tempo menores que 4ms s\u00e3o altamente imprecisas. Como medir o tempo gasto em uma fun\u00e7\u00e3o do seu c\u00f3digo? Este rel\u00f3gio em software, \\(C\\) , que usa um rel\u00f3gio de quartzo, impreciso, pode marcar a passagem do tempo com erro para mais ou para menos. Embora o erro exato do rel\u00f3gio seja desconhecido, o mesmo \u00e9 limitado probabilisticamente. A taxa de erro \u00e9 denominada drift , \u00e9 representada por \\(\\rho\\) . Assumindo um rel\u00f3gio perfeito, \\(t\\) , temos que \\(1 - \\rho \\leq \\frac{dC}{dt} \\leq 1 + \\rho\\) . Assim, um \\(\\rho\\) de 0.1 implica em um erro de mais ou menos 10%; a figura a seguir mostra a faixa em que \\(C\\) pode operar e que o erro em rela\u00e7\u00e3o a \\(t\\) vai aumentando com a passagem do tempo. Embora adequado para humanos, o erro dos rel\u00f3gios de quartzo \u00e9 inaceit\u00e1vel em algumas opera\u00e7\u00f5es computacionais. Felizmente, os erros do destes rel\u00f3gios podem ser minimizados ao ponto de termos um erros menores que 1s em milh\u00f5es de anos, nos dispositivos conhecidos como rel\u00f3gios at\u00f4micos . Embora muito bom, o rel\u00f3gio at\u00f4mico tamb\u00e9m n\u00e3o \u00e9 perfeito e, devido a v\u00e1rias raz\u00f5es, pode levar tamb\u00e9m a erros. Mas o qu\u00ea mais se pode fazer no sentido de melhorar a precis\u00e3o dos rel\u00f3gios? A resposta est\u00e1 no UTC. Tempo Universal Coordenado O UTC, de uma mistura dos nomes em Ingl\u00eas e Franc\u00eas do Tempo Universal Coordenado, um padr\u00e3o global para coordena\u00e7\u00e3o da medi\u00e7\u00e3o da passagem do tempo. Segundo o UTC, o sol est\u00e1 a pino \u00e0s 12:00 na latitude 0, ou a no m\u00e1ximo 1s deste instante; ao redor da latitude 0 grau estabelece-se uma faixa em que todos os pontos tem o mesmo hor\u00e1rio, e outras 23 faixas como esta com deslocamentos consecutivos de +-1 hora. Estas faixas, conhecidas coloquialmente como fusos, sofrem ajustes por fatores pol\u00edticos; a China, por exemplo, apesar de seu tamanho, est\u00e1 toda dentro de um mesmo hor\u00e1rio, \"correto\" para Beijing. Mas como o UTC \u00e9 definido? Com base no TAI, Tempo At\u00f4mico Internacional, calculado como a m\u00e9dia dos valores de rel\u00f3gios at\u00f4micos espalhados pelo globo. O TAI mede perfeitamente a passagem do tempo, mas como a rota\u00e7\u00e3o da terra \u00e9 irregular, medir perfeitamente n\u00e3o \u00e9 o adequado. Assim, o UTC leva em considera\u00e7\u00e3o o fato do dia n\u00e3o ter exatamente 24 horas e, de fato, n\u00e3o ter dura\u00e7\u00e3o constante. Por exemplo, ap\u00f3s um grande terremoto o centro de massa da terra pode ser alterado e a rota\u00e7\u00e3o ter sua velocidade aumentada ou diminu\u00edda. UTC Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60 seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61 seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2 milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59 seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary. Sincroniza\u00e7\u00e3o de Rel\u00f3gios Dado o UTC, temos ent\u00e3o uma refer\u00eancia de tempo adequada para uso em sistemas computacionais, colocamos nova pergunta: Se o rel\u00f3gio se dist\u00e2ncia da medida correta da passagem do tempo, \u00e9 poss\u00edvel corrigir este distanciamento, sincronizando-o com uma fonte correta, da qual UTC \u00e9 nossa melhor aproxima\u00e7\u00e3o, para que todos percebam a mesma passagem do tempo? Embora a resposta seja negativa, no sentido de que n\u00e3o \u00e9 poss\u00edvel alcan\u00e7ar sincroniza\u00e7\u00e3o perfeita, nada nos impede de fazer um melhor esfor\u00e7o e, neste sentido, tamb\u00e9m temos que nos perguntar qual a frequ\u00eancia de sincroniza\u00e7\u00e3o? Frequ\u00eancia de Sincroniza\u00e7\u00e3o Como garantir que dois rel\u00f3gios com erro m\u00e1ximo igual a \\(\\rho\\) n\u00e3o diferir\u00e3o em mais que \\(\\delta\\) unidades de tempo? Resposta Sincronize pelo menos a cada \\(\\frac{\\delta}{2\\rho}\\) segundos. E se tivermos muitos rel\u00f3gios a serem sincronizados, o problema \u00e9 mais dif\u00edcil? Frequ\u00eancia de Sincroniza\u00e7\u00e3o Como garantir que dois rel\u00f3gios quaisquer, em um sistema com \\(n\\) rel\u00f3gios, todos com erro m\u00e1ximo igual a \\(\\rho\\) , n\u00e3o diferir\u00e3o em mais que \\(\\delta\\) unidades de tempo? Resposta Se todos sincronizarem com a mesma fonte, a cada \\(\\frac{\\delta}{2\\rho}\\) segundos, seja o n\u00f3 n1 aquele com maior erro em rela\u00e7\u00e3o \u00e0 fonte e n2 aquele com maior erro em rela\u00e7\u00e3o a n1. Como ambos tem um erro m\u00e1ximo de \\(\\delta\\) em rela\u00e7\u00e3o \u00e0 fonte, o erro m\u00e1ximo entre os dois n\u00f3s \u00e9 \\(2\\delta\\) . Como este erro \u00e9 o dobro do desejado, basta dobrar a frequ\u00eancia de sincroniza\u00e7\u00e3o para cortar o erro pela metade. Vejamos um exemplo: \\(\\rho = 0,1\\) \\(\\delta\\) = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Como cada n\u00f3 poderia estar errando em \"dire\u00e7\u00f5es\" diferentes, ap\u00f3s 5s, um n\u00f3 poderia se adiantar em 0,5s enquanto o outro se atrasa pela mesma quantidade de tempo, somando 1s de diferen\u00e7a. Logo, eles tem que se sincronizar a cada 5s, i.e, \\(\\frac{\\delta}{2\\rho} = \\frac{1s}{2 \\times 0,1} = \\frac{1s}{0,2} = 5s\\) Como \u00faltima parada antes de come\u00e7armos a falar sobre a sincroniza\u00e7\u00e3o em si, devemos estabelecer alguns cuidados a serem tomados no processo. Nunca voltar no tempo - isso poderia levar a um dado ter data de edi\u00e7\u00e3o anterior a data de cria\u00e7\u00e3o. Ajustes graduais - acelere ou desacelere o rel\u00f3gio (em software) Diminua/Aumente frequ\u00eancia de interrup\u00e7\u00e3o para atrasar/adiantar rel\u00f3gio Diminua/Aumente incremento com cada interrup\u00e7\u00e3o Ajustes peri\u00f3dicos para fazer curvas convergirem. Corre\u00e7\u00e3o ap\u00f3s dormir ser\u00e1 mais dr\u00e1stica Agora que voc\u00ea j\u00e1 tem uma fonte confi\u00e1vel de tempo, o UTC, e sabe com que frequ\u00eancia sincronizar os rel\u00f3gios, s\u00f3 nos falta fazer a sincroniza\u00e7\u00e3o. Contudo, falta ainda definir o protocolo pelo qual a sincroniza\u00e7\u00e3o \u00e9 feita e exatamente com quem, uma vez que simpleste UTC \u00e9 muito gen\u00e9rico. Comecemos com vetor \"pr\u00f3ximo\" do UTC, os rel\u00f3gios at\u00f4micos em sat\u00e9lites GPS. Global Positioning System Receptores GPS, com seus rel\u00f3gios sincronizados com os dos sat\u00e9lites, que difundem regularmente sua posi\u00e7\u00e3o e o instante em que a difus\u00e3o \u00e9 feita, determinam sua posi\u00e7\u00e3o relativa aos sat\u00e9lites, em uma t\u00e9cnica conhecida como trilatera\u00e7\u00e3o, que consiste em determinar a dist\u00e2ncia do receptor em termos dos eixos \\(x\\) , \\(y\\) e \\(z\\) em rela\u00e7\u00e3o a cada um dos sat\u00e9lites. Em outras palavras, baseado na informa\u00e7\u00e3o de um sat\u00e9lite, o receptor determina sua dist\u00e2ncia ao mesmo e, portanto, determina que est\u00e1 em uma esfera no entorno do sat\u00e9lite. Combinando a informa\u00e7\u00e3o de 2 sat\u00e9lites, a posi\u00e7\u00e3o do receptor \u00e9 limitada a uma circunfer\u00eancia, isto \u00e9, a interse\u00e7\u00e3o de duas esferas. Com um terceiro sat\u00e9lite, a posi\u00e7\u00e3o \u00e9 reduzida a dois pontos, a interse\u00e7\u00e3o de uma esfera e uma circunfer\u00eancia, sendo um no espa\u00e7o e que pode ser facilmente descartado. Contudo, para que funcione, rel\u00f3gios dos sat\u00e9lites e receptores precisam estar sincronizados para que o c\u00e1lculo da dist\u00e2ncia possa ser feito, mas sincronizar os rel\u00f3gios \u00e9 exatamente o problema que estamos tentando resolver. Para contornar esta restri\u00e7\u00e3o, usa-se um quarto sat\u00e9lite, para determinar a dist\u00e2ncia no \"eixo temporal\". Assim, temos uma receita simples para sincroniza\u00e7\u00e3o de rel\u00f3gios com UTC: Coloque um receptor GPS em cada n\u00f3 do seu sistema Tenha erro de 0,1ns a 1ms do UTC Apesar da queda dos pre\u00e7os dos receptores, colocar um GPS em cada dispositivo pode ser custoso demais. Em vez disso, podemos usar um recurso amplamente dispon\u00edvel, redes de computadores, e sincronizar com outra m\u00e1quina, que fez o investimento necess\u00e1rio para manter o erro baixo. Para estes computadores \"de segundo escal\u00e3o\", a receita ent\u00e3o \u00e9: Pergunte que horas s\u00e3o. Use a resposta para ajustar o rel\u00f3gio local. Considere o erro introduzido pela lat\u00eancia vari\u00e1vel da rede. Esta receita b\u00e1sica pode ser ajustada de diversas formas. Algoritmo de Cristian Assumindo que o rel\u00f3gio da m\u00e1quina se sincronizando, \\(M_1\\) , \u00e9 bom o suficiente para medir a passagem de tempo em per\u00edodos curtos, mesmo que tenha uma drift rate consider\u00e1vel em per\u00edodos mais longos, execute o seguinte protocolo para se sincronizar com \\(M_2\\) . \\(M_1\\) pergunta \"que horas s\u00e3o?\" - \\(t_0\\) \\(M_2\\) recebe pergunta - \\(t_1\\) \\(M_2\\) anota o valor do rel\u00f3gio - \\(t_s\\) \\(M_2\\) envia resposta - \\(t_2\\) \\(M_1\\) recebe resposta - \\(t_3\\) Assuma \\(t_1 = t_s = t_2\\) Assuma \\(\\frac{t_3-t_0}{2}\\) como o tempo de transmiss\u00e3o da resposta (m\u00e9dia da ida e da volta) \\(M_1\\) ajusta rel\u00f3gio para \\(t_c = t_s + \\frac{t_3-t_0}{2}\\) Mas e a aproxima\u00e7\u00e3o \\(\\frac{t_3-t_0}{2}\\) , \u00e9 boa? Podemos estimar o erro que ela introduz na sincroniza\u00e7\u00e3o, caso as mensagens tenham tempos de ida e volta assim\u00e9tricos. Apesar das diferen\u00e7as no tempo de ida e volta, existe um tempo m\u00ednimo para o tr\u00e1fego em cada um dos sentidos, \\(T_{min}\\) . A figura a seguir demonstra o erro desta t\u00e9cnica Fonte Observe que h\u00e1 dois casos extremos de erro na estimativa. No primeiro caso, dado um tempo de ida + volta igual a \\(T_1 - T_0\\) , na figura, a mensagem de ida trafega no tempo m\u00ednimo e a volta lentamente. Neste caso, a estimativa \\(\\frac{t_3-t_0}{2}\\) \u00e9 menor que o tempo de volta real. No segundo caso, a mensagem de ida trafega lentamente e a de volta no tempo m\u00ednimo, levando \\(\\frac{t_3-t_0}{2}\\) a ser maior que tempo de transmiss\u00e3o real da mensagem. O erro, contudo, est\u00e1 limitado \u00e0 faixa amarela no desenho, que tem dura\u00e7\u00e3o \\(T_1 - T_0 - 2T_{min}\\) . O erro ent\u00e3o varia de mais ou menos metade deste valor. Algoritmo de Berkeley Enquanto o algoritmo de Cristian permite sincronizar um n\u00f3 com uma fonte, outro algoritmo, de Berkeley, permite sincronizar m\u00faltiplos n\u00f3s uns com os outros. Este algoritmo assume o que n\u00e3o h\u00e1 uma \"fonte da verdade\" do tempo, mas sim a necessidade de que todos os processos convirjam para um mesmo valor do rel\u00f3gio. \u00c9 como nos filmes de espi\u00e3o em que os rel\u00f3gios s\u00e3o sincronizados; pouco importa se a bomba explodir\u00e1 10:57 ou 10:59, desde que todos concordem quando isso vai acontecer. Isso \u00e9 o que chamamos de sincroniza\u00e7\u00e3o interna em vez de externa, como provido pelo algoritmo de Cristian. O algoritmo de Berkeley requer que todo n\u00f3 execute um processo de sincroniza\u00e7\u00e3o, um \"daemon\", e separa seus pap\u00e9is em dois tipos, prim\u00e1rio e secund\u00e1rio . O papel do prim\u00e1rio pode ser rotacionado entre os v\u00e1rios processos, sem perdas para sua execu\u00e7\u00e3o. O algoritmo ent\u00e3o \u00e9 executacomo se segue: Prim\u00e1rio pergunta \"que horas s\u00e3o\" para cada secund\u00e1rio (mensages 1,2,3 e 4) Secund\u00e1rio responde com valor atual do rel\u00f3gio (mensagens 5,6,7 e 8) Prim\u00e1rio ajusta as respostas de acordo com o algoritmo de Cristian, para minimizar erros. Prim\u00e1rio computa m\u00e9dia dos valores recebidos, ignorando outliers (como o da mensagem 8). Prim\u00e1rio envia ajustes para secund\u00e1rios (mensagens 8,9,10 e 11) Secund\u00e1rio executa ajuste sugerido pelo prim\u00e1rio. sequenceDiagram autonumber note over Prim\u00e1rio: 10:00 note over Secund\u00e1rio1: 10:06 note over Secund\u00e1rio2: 10:15 note over Secund\u00e1rio3: 23:18 par Pergunta Prim\u00e1rio->>Prim\u00e1rio: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio1: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio2: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio3: Que horas s\u00e3o? end par Resposta Prim\u00e1rio->>Prim\u00e1rio: 10:00 and Secund\u00e1rio1->>Prim\u00e1rio: 10:06 and Secund\u00e1rio2->>Prim\u00e1rio: 10:15 and rect rgb(255, 0, 0) Secund\u00e1rio3->>Prim\u00e1rio: 23:18 end end par Ajuste Prim\u00e1rio->>Prim\u00e1rio: 10:07 and Prim\u00e1rio->>Secund\u00e1rio1: 10:07 and Prim\u00e1rio->>Secund\u00e1rio2: 10:07 and Prim\u00e1rio->>Secund\u00e1rio3: 10:07 end Embora interessantes, estes algoritmos n\u00e3o s\u00e3o normalmente usados, pelo menos n\u00e3o em sua forma \"pura\", em sistemas computacionais. Em vez deles, usamos o Network Time Protocol (NTP). Network Time Protocol. O NTP foi especificado originalmente na RFC 1305 5 e estendido pelas RFCRFC 5905-5908 6 essencialmente para suportar IPv6 e reduzir o erro de sincroniza\u00e7\u00e3o para at\u00e9 10 \\(\\mu\\) s. Os diversos componentes do NTP s\u00e3o organizados em camadas, ou estrata , de forma que a informa\u00e7\u00e3o do tempo flui da camada 0 ( stratum 0 ) at\u00e9 a camada 15 ( stratum 15). Os componentes n\u00e3o est\u00e3o presos a camadas, que podem ser alteradas a medida que falhas acontecem e s\u00e3o dedicadas, e novos caminhos s\u00e3o encontrados usando-se o algoritmo de \u00e1rvore geradora m\u00ednima Bellman-Ford, al\u00e9m de caminhos redundantes que conferem propriedades de toler\u00e2ncia a falhas \u00e0 topologia. 4 Esta organiza\u00e7\u00e3o hier\u00e1rquica leva a cada camada garantir um n\u00edvel de sincroniza\u00e7\u00e3o diferente e permite escalar o uso do protocolo para n\u00edveis globais , usando a Internet como meio . Stratum 0: rel\u00f3gios at\u00f4micos/receptores GPS Stratum 1: ms to stratum 0 Stratum 2: contata m\u00faltiplos stratum 1 e pares Strata 3...15 Stratum 16: dessincronizado Toda a comunica\u00e7\u00e3o entre n\u00f3s pode ser autenticada , garantindo que a sincroniza\u00e7\u00e3o n\u00e3o seja facilmente manipulada e erros s\u00e3o minimizados pela coleta e uso de estat\u00edsticas de lat\u00eancia de comunica\u00e7\u00e3o, para evitar desvios quando fontes se tornam problem\u00e1ticas. NTP tem m\u00faltiplas formas de execu\u00e7\u00e3o, adequadas para diferentes ambientes. Modo multicast: propaga tempo em rede local RPC: algoritmo de Cristian Sim\u00e9trico: parecido com Berkeley Na pr\u00e1tica, boa parte dos dispositivos usa uma vers\u00e3o simplificada do NTP, o SNTP ( Simple Network Time Protocol ), adequada aos n\u00f3s nas folhas da hierarquia . O SNTP \u00e9 essencialmente o algoritmo de Cristian: \\(\\delta = (t_4-t_1)-(t_2-t_3)\\) \\(t = \\frac{(t_2-t_1)+(t3-t_4)}{2}\\) \\(t_c = t_4+t\\) Por exemplo, \\(t_1 = 1100, t_2 = 800, t_3=850, t_4=1200\\) \\(t = ((800-1100)+(850-1200))/2 = (-300 -350)/ = -325\\) \\(t_c = 1200-325 = 875\\) O Comit\u00ea Gestor da Internet, CGI , mantem uma excelente p\u00e1gina sobre o NTP, com mais detalhes do que apresentado aqui, em NTP.br . PTP - Precision Time Protocol Mesmo com melhoria do protocolo e baratemento de dispositivos GPS, h\u00e1 ainda a necessidade de sincroniza\u00e7\u00e3o sub-microssegundo e barata. O Precision Time Protocol , PTP, especifica\u00e7\u00e3o IEEE 1588 7 tenta cobrir este nicho. Se escrutinizarmos o PTP, veremos que o protocolo em si n\u00e3o difere muito do NTP. Contudo, o PTP usa interfaces de rede especilizadas para fazer o timestamping dos eventos do protocolo, conseguindo remover a lat\u00eancia nos dispositivos processando as mensagens e reduzindo o erro do protocolo at\u00e9 sub \\(\\mu\\) (versus ordem de \\(ms\\) no NTP). Mais detalhes sobre o protocolo est\u00e3o fora do escopo deste documento, mas podem ser facilmente encontrados nos links dados. Usos de rel\u00f3gios sincronizados Assumindo que tenhamos sincronizado os rel\u00f3gios de um sistema computacional, o que podemos fazer agora? Uma s\u00e9rie de problemas interessantes que podem ser resolvidos, como autentica\u00e7\u00e3o , termina\u00e7\u00e3o de transa\u00e7\u00f5es , aloca\u00e7\u00e3o de leases e diversos outros exemplos 8 . Um exemplo interessante \u00e9 a ordena\u00e7\u00e3o de eventos em um banco de dados. Para entender este problema, considere um cen\u00e1rio com um Sistema Banc\u00e1rio replicado, isto \u00e9, com v\u00e1rias c\u00f3pias. No exemplo, nos focamos em duas c\u00f3pias em lados opostos de uma rede de larga escala. Clientes disparam opera\u00e7\u00f5es como saques, dep\u00f3sitos e transfer\u00eancias, por meio de mensagens para as duas c\u00f3pias. Mensagens para a c\u00f3pia pr\u00f3xima do cliente (em verde) s\u00e3o entregues rapidamente, enquanto mensagens para a c\u00f3pia distante (em vermelho), demoram mais para ser entregues. Imagine que o usu\u00e1rio U1 envie o comando C1 \"atualizar saldo da conta para USD 10 9 \" e que o usu\u00e1rio U2 envie o comando C2 \"atualizar saldo da conta para USD 20\". Se os comandos chegam primeiro para a r\u00e9plica mais pr\u00f3xima e s\u00e3o executados na ordem em que chegam, ao final da execu\u00e7\u00e3o a r\u00e9plica R1 ter\u00e1 executado C1 seguido de C2, tendo saldo da conta como USD 20, enquanto R2 ter\u00e1 executado C2 seguido de C1 e ter\u00e1 como saldo na conta USD 10. O problema est\u00e1 na ordem de execu\u00e7\u00e3o das opera\u00e7\u00f5es. Assuma que rel\u00f3gios est\u00e3o perfeitamente sincronizados e que toda mensagem/update carrega consigo o timestamp de quando foi enviada. E se as r\u00e9plicas processarem mensagens na ordem que foram enviadas, como identificado pelos seus timestamps ? 10 Assim, se C1 foi enviado antes de C2, C1 tem um timestamp menor que C2 e ser\u00e1 executada primeiro em ambas as r\u00e9plicas, o que resolve nosso problema, correto? Parcialmente, pois ainda temos o problema de identificar que nenhuma outra mensagem ainda por ser entregue foi enviada antes. Para isto, precisamos estender o modelo e assumir que o tempo de propaga\u00e7\u00e3o m\u00e1ximo de uma mensagem, \\(\\tau\\) , \u00e9 finito. Assim, ao receber um comando com timestamp \\(t\\) , uma r\u00e9plica espera at\u00e9 \\(t + \\tau\\) antes de execut\u00e1-lo, pois qualquer comando com timestamp \\(t' < t\\) deve ter sido entregue at\u00e9 \\(t+\\tau\\) . Implementar este protocolo \u00e9 muito simples: Ordena\u00e7\u00e3o de Mensagens por Timestamp Quando enviar uma mensagem, aumente-a com o valor atual do rel\u00f3gio. Quando receber uma mensagem, coloque-a em uma fila ordenada por timestamp . Quando o rel\u00f3gio marcar um tempo maior que \\(t + \\tau\\) , onde \\(t\\) \u00e9 o timestamp da mensagem na cabe\u00e7a da fila, retire a mensagem da cabe\u00e7a da fila e execute o comando correspondente. Embora correto, este protocolo, ou melhor, o modelo, n\u00e3o leva em considera\u00e7\u00e3o a dessincroniza\u00e7\u00e3o inerente dos rel\u00f3gios em um sistema distribu\u00eddo. Como faz\u00ea-lo, supondo uma diverg\u00eancia m\u00e1xima de \\(\\Delta\\) entre quaisquer dois rel\u00f3gios, algo que pode ser arranjado, como visto antes, sincronizando-se os rel\u00f3gios a cada \\(\\frac{\\Delta}{2*\\rho}\\) . Se \\(\\Delta\\) \u00e9 a diferen\u00e7a m\u00e1xima entre rel\u00f3gios, ent\u00e3o se uma mensagem \u00e9 enviada no instante \\(t\\) , ent\u00e3o at\u00e9 \\(\\Delta +t\\) , outro processo, atrasado em rela\u00e7\u00e3o ao primeiro, poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) . Tal mensagem pode demorar at\u00e9 \\(\\tau\\) para ser entregue \u00e0 r\u00e9plica, ou seja, no instante \\(t + \\tau + \\Delta\\) , do ponto de vista do primeiro cliente. Se a r\u00e9plica estiver sincronizada com cliente, ent\u00e3o se esperar at\u00e9 \\(t + \\tau + \\Delta\\) para executar o comando, o far\u00e1 de forma segura. Se estiver atrasada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o acabar\u00e1 por esperar al\u00e9m do necess\u00e1rio, mas sem violar a corretude do sistema. Finalmente, se a r\u00e9plica estiver adiantada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o seu rel\u00f3gio alcan\u00e7ar\u00e1 \\(t + \\tau + \\Delta\\) antes do rel\u00f3gio do primeiro cliente, mas isso n\u00e3o \u00e9 um problema. Isto porqu\u00ea, o \u00faltimo instante em que o cliente 2 poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) \u00e9 o instante em que o rel\u00f3gio da r\u00e9plica marcar \\(t + \\Delta\\) , e portanto dever\u00e1 tamb\u00e9m ser recebido at\u00e9 que o mesmo rel\u00f3gio marque \\(t + \\tau + \\Delta\\) . O mesmo racioc\u00ednio pode ser usado para definir um protocolo de acesso recursos para os quais leases s\u00e3o distribu\u00eddos, onde um lease \u00e9 uma permiss\u00e3o de acesso durante uma janela de tempo, emitida por um coordenador (possivelmente eleito usando os algoritmos vistos anteriormente), e \\(\\Delta\\) \u00e9 o m\u00e1ximo de dessincronismo entre os rel\u00f3gios. O seguinte protocolo resolve este problema: Aloca\u00e7\u00e3o de Lease Ao receber um lease para a janela de tempo \\(t_1\\) a \\(t_2\\) espera at\u00e9 \\(t_1 + \\Delta\\) usa o recurso at\u00e9 \\(t_2\\) . Se rel\u00f3gio estiver adiantado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1+\\Delta\\) enquanto o anterior acha que \u00e9 \\(t_1\\) ; exclus\u00e3o m\u00fatua garantida. Se rel\u00f3gio estiver atrasado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1 - \\Delta\\) , e continua esperando, enquanto ele acha que j\u00e1 \u00e9 \\(t_1\\) e para de usar; exclus\u00e3o m\u00fatua garantida. Recurso fica ocioso por \\(\\Delta\\) , em m\u00e9dia, a cada lease. Devido ao alto custo de se manter o recurso n\u00e3o utilizado, \\(\\Delta\\) deve ser feito t\u00e3o pequeno quanto poss\u00edvel. Leia Google True Time e Spanner para ver como o Google consegue manter a diferen\u00e7a em sub milisegundos, usando rel\u00f3gios at\u00f4micos dentro de seus datacenters e um API para gera\u00e7\u00e3o de timestamps. Todo Google TrueTime Nas solu\u00e7\u00f5es anteriores, um n\u00f3 precisa esperar por muito tempo antes de usar um recurso. E se ele aprendesse antes que os outros n\u00f3s n\u00e3o far\u00e3o requisi\u00e7\u00f5es? Que n\u00e3o haver\u00e3o sobreposi\u00e7\u00f5es de requisi\u00e7\u00f5es? E se houvesse um rel\u00f3gio que avan\u00e7asse n\u00e3o com o tempo, mas com eventos interessantes do sistema? Esta \u00e9 a ideia dos rel\u00f3gios l\u00f3gicos . Tempo L\u00f3gico A ideia por tr\u00e1s do \"tempo l\u00f3gico\" \u00e9 de o que importa s\u00e3o eventos e n\u00e3o a passagem do tempo, uma vez que tempo \u00e9 relativo aos processos 11 . Assim, surgem os rel\u00f3gios l\u00f3gicos, que ``ticam'' quando um evento importante acontece. Para chegarmos aos rel\u00f3gios l\u00f3gicos, precisamos primeiro entender a rela\u00e7\u00e3o Happened-Before , proposta por Leslie Lamport 12 e que lhe rendeu um Pr\u00eamio Turing em 2014 . Hoje \u00e9 comum usar a rela\u00e7\u00e3o happened-before e o vocabul\u00e1rio associado para falar sobre ordem de eventos em um sistema computacional, em especial um distribu\u00eddo. Happened-Before A rela\u00e7\u00e3o happened-before captura a causalidade entre eventos. Isto \u00e9, se um evento \\(a\\) aconteceu-antes de um evento \\(b\\) , ent\u00e3o \\(a\\) potencialmente causou \\(b\\) . Tamb\u00e9m podemos dizer que \\(a\\) precede \\(b\\) em uma ordem causal. O evento \\(a\\) aconteceu-antes \\(b\\) , notado como \\(a \\rightarrow b\\) , se uma das tr\u00eas condi\u00e7\u00f5es seguintes \u00e9 v\u00e1lida: Happened-Before Se \\(a\\) e \\(b\\) s\u00e3o eventos em um mesmo processo (ou thread ) e \\(a\\) foi executado antes de \\(b\\) . Se \\(a\\) e \\(b\\) s\u00e3o eventos de processos distintos e \\(a\\) \u00e9 o envio de uma mensagem e \\(b\\) a sua recep\u00e7\u00e3o. Se h\u00e1 transitividade, isto \u00e9, se existe um evento \\(c\\) tal que \\(a \\rightarrow c\\) e \\(c \\rightarrow b\\) . TODO Imagem somente com os eventos, sem o valor do rel\u00f3gio. Note que se \\(a \\rightarrow b\\) \u00e9 falso e \\(b \\rightarrow a\\) \u00e9 falso, ent\u00e3o \\(a\\) e \\(b\\) s\u00e3o concorrentes , e que ser concorrente n\u00e3o quer dizer que aconteceram exatamente no mesmo instante, do ponto de vista de um observador externo. Ser concorrente quer dizer que um evento \\(a\\) n\u00e3o podem ter sido a causa do evento \\(b\\) , dado que os efeitos de \\(a\\) n\u00e3o poderiam ser conhecidos pelo processo onde \\(b\\) ocorreu, quando \\(b\\) ocorreu. O cone de luz na figura seguinte mostra esta rela\u00e7\u00e3o entre eventos. Se capturarmos a causalidade de eventos, podemos usar esta informa\u00e7\u00e3o para ordenar o se processamento, de forma a fazer sentido. Considere o seguinte exemplo, em que o primeiro usu\u00e1rio de um servi\u00e7o de emails recebe primeiro a resposta da mensagem A, R:A, para somente depois receber A. Para que a troca de mensagens fa\u00e7a sentido, o usu\u00e1rio posterga a leitura de R:A at\u00e9 depois de ter lido A. Observe que em nenhum momento a informa\u00e7\u00e3o sobre quando as mensagens foram enviadas foi necess\u00e1ria, apenas a ordem das mesmas. Rel\u00f3gios l\u00f3gicos permitem que sistemas capturem a rela\u00e7\u00e3o de causalidade entre eventos e implementem esquemas como o apenas descrito, para coordenar as a\u00e7\u00f5es dos processos em sistemas distribu\u00eddos. Rel\u00f3gios l\u00f3gicos Para que computadores possam usar a causalidade, precisamos capturar a rela\u00e7\u00e3o de acontecer antes em um sistema. Lamport prop\u00f4s uma tal forma, que denominou rel\u00f3gio l\u00f3gico , mas que hoje \u00e9 conhecido universalmente como rel\u00f3gio de Lamport . Estes rel\u00f3gios permitem associar um timestamp a eventos de forma a se garantir a seguinte propriedade: seja \\(e\\) um evento seja \\(C(e)\\) o valor do rel\u00f3gio l\u00f3gico quando associado a \\(e\\) se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) Mas como definir a fun\u00e7\u00e3o \\(C\\) ? Experimentemos a seguinte defini\u00e7\u00e3o: Quase Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. \\(C(e) = ++c_p\\) no momento em que \\(e\\) ocorreu. Usamos como \\(<\\) a rela\u00e7\u00e3o normal de inteiros. Observe que n\u00e3o h\u00e1 fonte da verdade em termos de tempo l\u00f3gico, j\u00e1 que cada processo mant\u00e9m seu pr\u00f3prio rel\u00f3gio que pode ser relacionado com rel\u00f3gios de outros processos. Veja um exemplo desta defini\u00e7\u00e3o em a\u00e7\u00e3o. \u00c9 verdade neste cen\u00e1rio que se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) ? Observe com aten\u00e7\u00e3o os eventos \\(f\\) e \\(k\\) , pois para estes, a regra n\u00e3o \u00e9 respeitada. Rel\u00f3gio de Lamport Para que a regra \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) seja v\u00e1lida, precisamos modificar a tentativa anterior para que, na recep\u00e7\u00e3o de uma mensagem, os contadores sejam atualizados para que sejam maiores tanto que os rel\u00f3gios dos eventos locais quanto dos eventos que antecederam o envio da mensagem sendo recebida. Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. Se o evento \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) Se o evento \\(e\\) \u00e9 o envio de uma mensagem \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) \\(C(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se o evento \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) \\(c_p \\gets max(c_e,ts)+1\\) . \\(C(e) \\gets c_p\\) Com este ajuste, temos os Rel\u00f3gios de Lamport . Neste caso, temos que para quaisquer eventos \\(a,b\\) , se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) . Todo Exemplo em que n\u00e3o \u00e9 bom o suficiente. Se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) . Contudo, a volta n\u00e3o \u00e9 verdade, isto \u00e9, se \\(C(a) < C(b)\\) ent\u00e3o \\(a \\rightarrow b\\) . Esta propriedade \u00e9 interessante na ordena\u00e7\u00e3o de eventos, pois evita que eventos concorrentes sejam ordenados. Entram os rel\u00f3gios vetoriais. Rel\u00f3gio Vetorial Rel\u00f3gios vetoriais s\u00e3o rel\u00f3gios l\u00f3gicos em que cada processo mant\u00e9m n\u00e3o apenas um contador dos seus eventos locais, mas tamb\u00e9m sua vis\u00e3o dos contadores dos outros processos. Estas vis\u00f5es s\u00e3o atualizadas a cada recep\u00e7\u00e3o de mensagem, de acordo com a seguinte especifica\u00e7\u00e3o, onde assume-se que \\(n\\) processos fazem parte do sistema. Rel\u00f3gio Vetorial Considerando o ponto de vista do processo \\(p\\) Seja \\(c_p[i], 1 \\leq i \\leq n\\) inicialmente igual a 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) \\(V(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p[i] \\gets max(c_p[i], ts[i]), \\forall i \\neq p\\) \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) Uma observa\u00e7\u00e3o interessante a ser feita aqui \u00e9 que embora o algoritmo pare\u00e7a indicar que cada processo precisa saber quantos mais processos existem no sistema, isto n\u00e3o \u00e9 verdade, pois pode-se assumir que para todo processo desconhecido \\(q\\) , \\(c_p[q] = 0\\) . Como dito, este rel\u00f3gio l\u00f3gico tem a propriedade \\(a \\rightarrow b \\iff V(a) < V(b)\\) , considerando-se a seguinte defini\u00e7\u00e3o de \\(<\\) para vetores: Compara\u00e7\u00e3o entre vetores \\(v = v' \\iff v[i] = v'[i], 1 \\leq i \\leq n\\) \\(v \\leq v' \\iff v[i] \\leq v'[i], 1 \\leq i \\leq n\\) \\(v < v' \\iff v \\leq v' \\land v \\neq V'\\) Assim, sejam dois eventos \\(e \\neq e'\\) : \\(e \\rightarrow e' \\iff V(e) < V(e')\\) Se \\(V(e) \\not < V(e')\\) e \\(V(e') \\not < V(e)\\) , ent\u00e3o \\(e\\) e \\(e'\\) s\u00e3o concorrentes. Para entender melhor como esta defini\u00e7\u00e3o funciona, considere a seguinte execu\u00e7\u00e3o. O que quer dizer \\(c_p[q] = k\\) , ou tomando o evendo \\(d\\) como exemplo, o que quer dizer \\(c_{P_2}[1]=2\\) ? Quer dizer que \\(P_2\\) est\u00e1 ciente de 2 eventos locais a \\(P_1\\) , assim com est\u00e1 ciente de 0 eventos em \\(P_3\\) e de que \\(d\\) \u00e9 o segundo evento em \\(P_2\\) . Logo, \\(d\\) pode ter sido causado por 2 eventos de \\(P_1\\) , 1 evento de \\(P_2\\) e 0 de \\(P_3\\) . Agora compare os eventos \\(e\\) e \\(d\\) . \\(e\\) e \\(d\\) s\u00e3o concorrentes pois embora as posi\u00e7\u00f5es 1 e 2 de \\(V(d)\\) sejam maiores que em \\(V(e)\\) , a posi\u00e7\u00e3o 3 \u00e9 menor. Isso quer dizer que o nem \\(e\\) est\u00e1 ciente do evento \\(d\\) e nem \\(d\\) est\u00e1 ciente do evento \\(e\\) , ou melhor, que um n\u00e3o pode ter causado o outro. Esta abstra\u00e7\u00e3o simples j\u00e1 \u00e9 muito poderosa e, embora possa ser melhorada 13 , j\u00e1 \u00e9 suficiente para se implementar outras abstra\u00e7\u00f5es interessantes, como ser\u00e1 visto adiante. Antes, \u00e9 necess\u00e1rio mencionar mais um tipo de rel\u00f3gio l\u00f3gico, os h\u00edbridos. Rel\u00f3gios H\u00edbridos A grande vantagem dos rel\u00f3gios l\u00f3gicos sobre os f\u00edsicos \u00e9 de ignorar a passagem do tempo, s\u00f3 se importanto com a ordem de eventos. Esta vantagem tamb\u00e9m \u00e9 uma desvantagem quando eventos precisam ser associados a eventos externos ao sistema, por exemplo, durante uma sess\u00e3o de depura\u00e7\u00e3o. Suponha que ap\u00f3s uma atualiza\u00e7\u00e3o de um sistema, voc\u00ea note um problema nos dados e, em depurando o problema, identifique o evento problem\u00e1tico nos logs do sistema, associado ao seu rel\u00f3gio l\u00f3gico. Como identificar se este evento problem\u00e1tico aconteceu antes ou depois da atualiza\u00e7\u00e3o? Rel\u00f3gios h\u00edbridos tentam resolver este problema combinando rel\u00f3gios f\u00edsicos e l\u00f3gicos em um. No seguinte algoritmo, cada processo mantem um rel\u00f3gio f\u00edsico e um l\u00f3gico e sempre que um evento acontece, usa como novo valor do rel\u00f3gio l\u00f3gico o m\u00e1ximo entre o valor anterior + 1, o valor do timestamp na mensagem sendo recebida + 1, se for o recebimento de uma mensagem, e o valor do rel\u00f3gio f\u00edsico. Isto \u00e9, se poucos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico acompanhar\u00e1 o valor do f\u00edsico. Rel\u00f3gio H\u00edbrido Simples Considerando o ponto de vista do processo \\(p\\) \\(c_p.f\\) \u00e9 o rel\u00f3gio f\u00edsico de \\(p\\) , incrementado automaticamente \\(c_p.l\\) \u00e9 o rel\u00f3gio l\u00f3gico de \\(p\\) , inicialmente 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) \\(H(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p.l \\gets max(c_p.l + 1, ts + 1, c_p.f)\\) \\(V(e) = c_p.l\\) Nesta vers\u00e3o do algoritmo, contudo, se muitos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico pode ser incrementadado muito rapidamente, perdendo a rela\u00e7\u00e3o com o rel\u00f3gio f\u00edsico. Em uma vers\u00e3o melhorada do algoritmo, 14 a dist\u00e2ncia entre os dois rel\u00f3gios \u00e9 limitada, mantendo a propriedade que faz o rel\u00f3gios h\u00edbridos interessantes. 15 Comunica\u00e7\u00e3o em Grupo Rel\u00f3gios l\u00f3gicos podem e s\u00e3o usados diretamente em sistemas, por exemplo, para controlar vers\u00f5es no sistema de identidade da Microsoft, Active Directory . Outra forma de uso \u00e9 como block de constru\u00e7\u00e3o de outras abstra\u00e7\u00f5es, por exemplo, primitivas de comunica\u00e7\u00e3o em grupo, pelas quais um processo envia mensagens para um conjunto de processos. Difus\u00e3o Totalmente Ordenada ( Total Order Multicast ): Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem Difus\u00e3o Causalmente Ordenada: Causalmente Ordenada: uma mensagem s\u00f3 \u00e9 entregue se todas as que causalmente a precedem j\u00e1 foram entregues. Com estas abstra\u00e7\u00f5es, podemos resolver o problema apresentado no in\u00edcio deste cap\u00edtulo, relembrando, cloud-drive , da seguinte forma. Considere um programa qualquer, que se comporte de forma determin\u00edstica (isto \u00e9, dada uma mesma entrada, gera sempre uma mesma sa\u00edda). Como todo programa, este \u00e9 uma m\u00e1quina de estados, com a peculiaridade de ser determin\u00edstica. Logo, se tivermos v\u00e1rias c\u00f3pias deste programa, executando em locais distintos, mas garantirmos que cada c\u00f3pia veja exatamente a mesma entrada de dados , ent\u00e3o garantiremos que todas as c\u00f3pias transitar\u00e3o pelos mesmos estados e chegar\u00e3o ao mesmo estado final. Como difus\u00e3o totalmente ordenada pode ser usado para garantir que todas as c\u00f3pias receber\u00e3o a mesma entrada, pode ser usado para implementar esta t\u00e9cnica, conhecida como Replica\u00e7\u00e3o de M\u00e1quinas de Estados (em ingl\u00eas, State Machine Replication , ou pelo menos o seu princ\u00edpio. Mas como podemos implementar estas primitivas de difus\u00e3o usando rel\u00f3gios l\u00f3gicos? Vejamos um algoritmo, onde consideramos que todas as mensagens s\u00e3o enviadas a todos os processos, inclusive o pr\u00f3prio remetente. Difus\u00e3o Totalmente Ordenado Considerando o ponto de vista do processo \\(p\\) \\(f_p\\) \u00e9 uma fila de mensagens ordenadas pelo seus timestamps , mantida em \\(p\\) Para difundir uma mensagem \\(m\\) colocar \\(m\\) na fila enviar \\(m\\) para todos os demais processos Quando uma mensagem \\(m\\) \u00e9 recebida colocar \\(m\\) na fila se \\(m\\) n\u00e3o \u00e9 um ack enviar \\(m ack\\) de volta ao remetente de \\(m\\) (com timestamp maior que de \\(m\\) ) Seja \\(m\\) a mensagem com timestamp ts na cabe\u00e7a da fila Se para cada processo \\(q\\) , h\u00e1 uma mensagem \\(m'\\) de \\(q\\) com timestamp ts' na fila de \\(p\\) tal que \\(ts < ts'\\) entregar \\(m\\) para a aplica\u00e7\u00e3o O objetivo deste algoritmo \u00e9 de entregar mensagens na ordem de seus timestamps . Para isso, antes de entregar a mensagem \\(m\\) de menor tmestamp ts conhecido atualmente por \\(p\\) , \\(p\\) espera por mensagens com \\(timestamps\\) maiores que ts de todos os processos. Uma vez que isso aconte\u00e7a, \\(p\\) sabe que nenhuma outra mensagem que chegue depois poderia ter \\(timestamp\\) menor que ts. Para que isto funcione, \u00e9 necess\u00e1rio que os canais de comunica\u00e7\u00e3o usados sejam confi\u00e1veis (todas as mensagens enviadas s\u00e3o entregues) e FIFO (a primeira a ser enviada \u00e9 primeira a ser recebida). Exerc\u00edcio - FIFO e Confi\u00e1veis \u00c9 necess\u00e1rio que canais de comunica\u00e7\u00e3o sejam FIFO e confi\u00e1veis para que mensagens com timestamp maiores n\u00e3o sejam perdidas e para que mensagens com timestamps maiores n\u00e3o sejam reordenadas e entregues primeiro. Explique porqu\u00ea isto seria um problema; descreva execu\u00e7\u00f5es problem\u00e1ticas. Vejamos um outro algoritimo, de difus\u00e3o causalmente ordenada. Difus\u00e3o Causalmente Ordenada Considerando o ponto de vista do processo \\(p\\) \\(p\\) incrementa \\(c_p[p]\\) somente no envio de mensagens. \\(p\\) s\u00f3 entrega uma mensagem recebida de \\(q\\) , com timestamp \\(ts\\) quando \\(ts[q] = c_p[q]+1\\) \\(ts[k] \\leq c_p[k], k \\neq q\\) Difus\u00e3o Causalmente Ordenada Considere \\(c_{P_2}[0,2,2]\\) e \\(ts=[1,3,0]\\) , de \\(P_0\\) . O que \\(P_2\\) est\u00e1 esperando? Como age ao receber mensagem com \\(ts\\) ? Um aspecto interessante da implementa\u00e7\u00e3o de primitivas de comunica\u00e7\u00e3o em grupo que usa rel\u00f3gios para ordena\u00e7\u00e3o de mensagens \u00e9 que elas podem ser feitas de forma transparente para a aplica\u00e7\u00e3o que as usa. Isto \u00e9, no exemplo descrito anteriormente em que processos mandam mensagens para r\u00e9plicas usando difus\u00e3o totalmente ordenada, os clientes n\u00e3o precisam estar cientes disto, e podem simplesmente mandar suas requisi\u00e7\u00f5es como faziam antes do servi\u00e7o ser replicado. Mas como ent\u00e3o as mensagens tem seus rel\u00f3gios l\u00f3gicos atualizados e usados para a gera\u00e7\u00e3o de timestamps ? Isto pode ser feito por meio de interceptadores em uma camada de middleware . Quando a aplica\u00e7\u00e3o envia uma mensagem, o rel\u00f3gio l\u00f3gico mantido no middleware \u00e9 atualizado e seu valor usado como timestamp em uma vers\u00e3o estendida da mensagem, efetivamente enviada na rede. Quando a mensagem estendida \u00e9 entregue ao destinat\u00e1rio, a mensagem \u00e9 passada para o interceptador que extrai o timestamp e atualiza seu rel\u00f3gio. A mensagem sem o timestamp \u00e9 entregue para a aplica\u00e7\u00e3o quando apropriado, e aplica\u00e7\u00e3o n\u00e3o percebe a manipula\u00e7\u00e3o. Exclusao M\u00fatua Revisitada Todo Algoritmos de Exclu\u00e3o m\u00fatua baeados em LC Algoritmo de Lamport, Ricart e agrawalla Algoritmo de Maekawa Explain that stuff. \u21a9 Distor\u00e7\u00e3o mec\u00e2nica gera corrente el\u00e9trica e submiss\u00e3o a uma corrente el\u00e9trica gera uma distor\u00e7\u00e3o mec\u00e2nica. \u21a9 32768 \u00e9 a primeira pot\u00eancia de 2 maior que 20000, a maior frequ\u00eancia sonora aud\u00edvel aos seres humanos. \u21a9 Fonte: Benjamin D. Esham, (bdesham) - Based upon Ntp.png by Kim Meyrick \u21a9 RFC 1305 , 1991/1992 \u21a9 RFC 5905-5908,2010 \u21a9 IEEE 1588TM Standard for A Precision Clock Synchronization Protocol for Networked Measurement and Control Systems . \u21a9 Liskov, B.: Distrib Comput (1993) 6: 211. doi:10.1007/BF02242709 \u21a9 Unidade Simples de Dinheiros. \u21a9 Empates s\u00e3o quebrados pelo identificador do processo, isto \u00e9, se duas mensagens s\u00e3o produzidas ao mesmo tempo por U1 e U2, ent\u00e3o o a mensagem de U1 tem preced\u00eancia na execu\u00e7\u00e3o. \u21a9 Reza a lenda que Leslie Lamport desenvolveu o conceito de rel\u00f3gios l\u00f3gicos pensando na teoria da relatividade geral. \u21a9 Time, Clocks and the Ordering of Events in a Distributed System. July 5, 1978 . \u21a9 Matrix Clock \u21a9 O blog de um dos autores descreve ambas as vers\u00f5es de forma resumida. Para a vers\u00e3o completa dos algoritmos, consulte o artigo . \u21a9 Tanto no artigo quanto no blog, a imagem que descreve um exemplo do HLC parece ter um erro e onde se l\u00ea (3,13) deve-se ler (3,10,3). \u21a9","title":"Tempo"},{"location":"time/#tempo","text":"Neste cap\u00edtulo discutiremos como o tempo \u00e9 importante no desenvolvimento de sistemas distribu\u00eddos. Comecemos por analisar o funcionamento de uma aplica\u00e7\u00e3o distribu\u00edda muito comum, o armazenamento de arquivos na nuvem, sincronizado com o sistema de arquivos local. Alguns exemplos do mundo real s\u00e3o Dropbox, Box, Google Drive and OneDrive; chamemos este servi\u00e7o genericamente de cloud-drive . Se um mesmo arquivo no cloud-drive \u00e9 modificado em duas m\u00e1quinas diferentes, enquanto as mesmas est\u00e3o desconectadas, o qu\u00ea acontece quando elas se reconectam \u00e0 Internet? Mais especificamente, quando as duas m\u00e1quinas se conectam e enviam suas vers\u00f5es do arquivo modificado para o servidor, sendo que ambas foram geradas a partir de um ancestral comum, qual vers\u00e3o deve ser armazenada e qual deve ser descartada? Uma possibilidade simples \u00e9 sempre aceitar cada nova vers\u00e3o como uma modifica\u00e7\u00e3o do arquivo. Assim, efetivamente, quando a primeira vers\u00e3o for entregue, ser\u00e1 aceita e viver\u00e1 momentaneamente at\u00e9 que a outra vers\u00e3o seja recebida e a sobrescreva. No exemplo seguinte, o resultado \u00e9 o mesmo que no exemplo anterior, sem falhas. Contudo, se estendermos um pouco mais a descontividade do n\u00f3 na parte de cima, o resultado final se inverte. No Exemplo, entre as entregas da \"Vers\u00e3o B\" e \"Vers\u00e3o A\" para o servidor no centro do diagrama, vale a \"Vers\u00e3o B\". Tamb\u00e9m pelo gr\u00e1fico, vemos que a \"Vers\u00e3o B\" foi criada depois da \"Vers\u00e3o A\", mas que a vers\u00e3o final vista pelo servidor \u00e9 exatamente a \"A\". Logo, questionamos se esta abordagem \u00e9 correta. Afinal ordem de chegada ao servidor n\u00e3o serve como crit\u00e9rio para escolha, afinal, a ordem de chegada dos arquivos ao servidor n\u00e3o reflete necessariamente a ordem em que os arquivos foram criados. Assim, podemos pensar em outras alternativas de aproveitamento e descarte de arquivos baseadas na cria\u00e7\u00e3o do arquivo. Contudo, o hor\u00e1rio de cria\u00e7\u00e3o de um arquivo \u00e9 relativo a onde foi criado e n\u00e3o ao grupo de processos que comp\u00f5e o sistema, o que pode levar uma modifica\u00e7\u00e3o que tenha acontecido mais tarde, do ponto de vista de um observador externo, a ter um hor\u00e1rio de cria\u00e7\u00e3o oficial anterior. Se for poss\u00edvel identificar a causalidade entre as modifica\u00e7\u00f5es, isto \u00e9, qual vers\u00e3o originou qual outra, ent\u00e3o \u00e9 claro que se deve manter vers\u00f5es de acordo com a ordem causal. Contudo, edi\u00e7\u00f5es concorrentes, como a cria\u00e7\u00e3o das vers\u00f5es A e B no exemplo anterior, n\u00e3o tem rela\u00e7\u00e3o de causalidade entre si. Assim, em qualquer destas linhas de atua\u00e7\u00e3o, voc\u00ea tem em m\u00e3os um conflito para resolver, e automatizar a resolu\u00e7\u00e3o do mesmo \u00e9 muito complicado. \u00c9 por isso que o Dropbox, por exemplo, deixa os dois arquivos para que o usu\u00e1rio analise e decida o que fazer, que servidores git exigem que o usu\u00e1rio pegue a vers\u00e3o salva mais recentemente e compatibilize suas mudan\u00e7as com ela antes de submeter novas mudan\u00e7as, e o Perforce trabalha com locks de arquivos. Se pensarmos em termos n\u00e3o de arquivos sendo enviados para um servidor, mas de opera\u00e7\u00f5es de modifica\u00e7\u00f5es sendo executadas, ent\u00e3o dada esta problem\u00e1tica, podemos simplificar a quest\u00e3o em nossas m\u00e3os. Como ordenar opera\u00e7\u00f5es de clientes? Se duas opera\u00e7\u00f5es originadas em clientes s\u00e3o enviadas ao servidor, qual deve ser executada primeiro? Embora, como j\u00e1 vimos, usar a ordem temporal da cria\u00e7\u00e3o das opera\u00e7\u00f5es tamb\u00e9m seja problem\u00e1tico, j\u00e1 que rel\u00f3gios s\u00e3o dessincronizados em sistemas distribu\u00eddos t\u00edpicos, alguns sistemas tentam resolver automaticamente os conflitos usando exatamente estes rel\u00f3gios. O CassandraDB, por exemplo, usa last write wins ou latest version wins , onde last \u00e9 definido em termos do rel\u00f3gio do cliente. Neste cen\u00e1rio, temos novo problema: Pergunta Como determinar qual foi enviada primeiro, em um sistema ass\u00edncrono? Para usar esta abordagem, precisamos encontrar uma fonte de tempo confi\u00e1vel e distribu\u00edda , constru\u00edda pelo uso de protocolos de sincroniza\u00e7\u00e3o de rel\u00f3gios f\u00edsicos","title":"Tempo"},{"location":"time/#tempo-fisico","text":"Para falarmos sobre sincroniza\u00e7\u00e3o de rel\u00f3gios em um cen\u00e1rio distribu\u00eddo, primeiro devemos entender como funcionam os rel\u00f3gios em n\u00edvel de uma \u00fanica m\u00e1quina, isto \u00e9, seus rel\u00f3gios f\u00edsicos e como s\u00e3o usados pelo sistema operacional.","title":"Tempo F\u00edsico"},{"location":"time/#relogios-de-quartzo-e-atomicos","text":"Quando falamos em rel\u00f3gios, provavelmente falamos sobre rel\u00f3gios a base de quartzo. Para uma introdu\u00e7\u00e3o r\u00e1pida, assista o seguinte v\u00eddeo. Em suma, um rel\u00f3gio de quartzo consiste em um diapaz\u00e3o de quartzo cortado a laser que, devido ao efeito Piezoel\u00e9trico 2 e sua forma particular, vibra a \\(32768 = 2^{15}\\) Hz 3 , e em um contador que conta cada vibra\u00e7\u00e3o, medindo a passagem do tempo. Estes rel\u00f3gios erram na medi\u00e7\u00e3o do tempo em no m\u00e1ximo \u00bds por dia , desde que operem dentro da faixa de 5 a 35C, mas isso tamb\u00e9m muda com a idade do cristal, a corrente el\u00e9trica passando por ele e tamb\u00e9m devido a imperfei\u00e7\u00f5es no cristal 1 . Computadores em geral usam rel\u00f3gios de quartzo, por serem baratos, como base de um rel\u00f3gio mantido em software. Isto \u00e9, do ponto de vista de um computador comum, o tempo \u00e9 medido com base em um rel\u00f3gio quartzo, cujos incrementos s\u00e3o capturados em um contador; o contador gera interrup\u00e7\u00f5es em intervalos programados (e.g., Linux >2.6 usa 250Hz por padr\u00e3o; m\u00e1ximo 1000Hz) e as interrup\u00e7\u00f5es causam ajustes em um rel\u00f3gio em software , um contador indireto \\(C\\) . Precis\u00e3o Dado a frequ\u00eancia padr\u00e3o de 250Hz, medi\u00e7\u00f5es de tempo menores que 4ms s\u00e3o altamente imprecisas. Como medir o tempo gasto em uma fun\u00e7\u00e3o do seu c\u00f3digo? Este rel\u00f3gio em software, \\(C\\) , que usa um rel\u00f3gio de quartzo, impreciso, pode marcar a passagem do tempo com erro para mais ou para menos. Embora o erro exato do rel\u00f3gio seja desconhecido, o mesmo \u00e9 limitado probabilisticamente. A taxa de erro \u00e9 denominada drift , \u00e9 representada por \\(\\rho\\) . Assumindo um rel\u00f3gio perfeito, \\(t\\) , temos que \\(1 - \\rho \\leq \\frac{dC}{dt} \\leq 1 + \\rho\\) . Assim, um \\(\\rho\\) de 0.1 implica em um erro de mais ou menos 10%; a figura a seguir mostra a faixa em que \\(C\\) pode operar e que o erro em rela\u00e7\u00e3o a \\(t\\) vai aumentando com a passagem do tempo. Embora adequado para humanos, o erro dos rel\u00f3gios de quartzo \u00e9 inaceit\u00e1vel em algumas opera\u00e7\u00f5es computacionais. Felizmente, os erros do destes rel\u00f3gios podem ser minimizados ao ponto de termos um erros menores que 1s em milh\u00f5es de anos, nos dispositivos conhecidos como rel\u00f3gios at\u00f4micos . Embora muito bom, o rel\u00f3gio at\u00f4mico tamb\u00e9m n\u00e3o \u00e9 perfeito e, devido a v\u00e1rias raz\u00f5es, pode levar tamb\u00e9m a erros. Mas o qu\u00ea mais se pode fazer no sentido de melhorar a precis\u00e3o dos rel\u00f3gios? A resposta est\u00e1 no UTC.","title":"Rel\u00f3gios de Quartzo e At\u00f4micos"},{"location":"time/#tempo-universal-coordenado","text":"O UTC, de uma mistura dos nomes em Ingl\u00eas e Franc\u00eas do Tempo Universal Coordenado, um padr\u00e3o global para coordena\u00e7\u00e3o da medi\u00e7\u00e3o da passagem do tempo. Segundo o UTC, o sol est\u00e1 a pino \u00e0s 12:00 na latitude 0, ou a no m\u00e1ximo 1s deste instante; ao redor da latitude 0 grau estabelece-se uma faixa em que todos os pontos tem o mesmo hor\u00e1rio, e outras 23 faixas como esta com deslocamentos consecutivos de +-1 hora. Estas faixas, conhecidas coloquialmente como fusos, sofrem ajustes por fatores pol\u00edticos; a China, por exemplo, apesar de seu tamanho, est\u00e1 toda dentro de um mesmo hor\u00e1rio, \"correto\" para Beijing. Mas como o UTC \u00e9 definido? Com base no TAI, Tempo At\u00f4mico Internacional, calculado como a m\u00e9dia dos valores de rel\u00f3gios at\u00f4micos espalhados pelo globo. O TAI mede perfeitamente a passagem do tempo, mas como a rota\u00e7\u00e3o da terra \u00e9 irregular, medir perfeitamente n\u00e3o \u00e9 o adequado. Assim, o UTC leva em considera\u00e7\u00e3o o fato do dia n\u00e3o ter exatamente 24 horas e, de fato, n\u00e3o ter dura\u00e7\u00e3o constante. Por exemplo, ap\u00f3s um grande terremoto o centro de massa da terra pode ser alterado e a rota\u00e7\u00e3o ter sua velocidade aumentada ou diminu\u00edda. UTC Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60 seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61 seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2 milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59 seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary.","title":"Tempo Universal Coordenado"},{"location":"time/#sincronizacao-de-relogios","text":"Dado o UTC, temos ent\u00e3o uma refer\u00eancia de tempo adequada para uso em sistemas computacionais, colocamos nova pergunta: Se o rel\u00f3gio se dist\u00e2ncia da medida correta da passagem do tempo, \u00e9 poss\u00edvel corrigir este distanciamento, sincronizando-o com uma fonte correta, da qual UTC \u00e9 nossa melhor aproxima\u00e7\u00e3o, para que todos percebam a mesma passagem do tempo? Embora a resposta seja negativa, no sentido de que n\u00e3o \u00e9 poss\u00edvel alcan\u00e7ar sincroniza\u00e7\u00e3o perfeita, nada nos impede de fazer um melhor esfor\u00e7o e, neste sentido, tamb\u00e9m temos que nos perguntar qual a frequ\u00eancia de sincroniza\u00e7\u00e3o? Frequ\u00eancia de Sincroniza\u00e7\u00e3o Como garantir que dois rel\u00f3gios com erro m\u00e1ximo igual a \\(\\rho\\) n\u00e3o diferir\u00e3o em mais que \\(\\delta\\) unidades de tempo? Resposta Sincronize pelo menos a cada \\(\\frac{\\delta}{2\\rho}\\) segundos. E se tivermos muitos rel\u00f3gios a serem sincronizados, o problema \u00e9 mais dif\u00edcil? Frequ\u00eancia de Sincroniza\u00e7\u00e3o Como garantir que dois rel\u00f3gios quaisquer, em um sistema com \\(n\\) rel\u00f3gios, todos com erro m\u00e1ximo igual a \\(\\rho\\) , n\u00e3o diferir\u00e3o em mais que \\(\\delta\\) unidades de tempo? Resposta Se todos sincronizarem com a mesma fonte, a cada \\(\\frac{\\delta}{2\\rho}\\) segundos, seja o n\u00f3 n1 aquele com maior erro em rela\u00e7\u00e3o \u00e0 fonte e n2 aquele com maior erro em rela\u00e7\u00e3o a n1. Como ambos tem um erro m\u00e1ximo de \\(\\delta\\) em rela\u00e7\u00e3o \u00e0 fonte, o erro m\u00e1ximo entre os dois n\u00f3s \u00e9 \\(2\\delta\\) . Como este erro \u00e9 o dobro do desejado, basta dobrar a frequ\u00eancia de sincroniza\u00e7\u00e3o para cortar o erro pela metade. Vejamos um exemplo: \\(\\rho = 0,1\\) \\(\\delta\\) = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Como cada n\u00f3 poderia estar errando em \"dire\u00e7\u00f5es\" diferentes, ap\u00f3s 5s, um n\u00f3 poderia se adiantar em 0,5s enquanto o outro se atrasa pela mesma quantidade de tempo, somando 1s de diferen\u00e7a. Logo, eles tem que se sincronizar a cada 5s, i.e, \\(\\frac{\\delta}{2\\rho} = \\frac{1s}{2 \\times 0,1} = \\frac{1s}{0,2} = 5s\\) Como \u00faltima parada antes de come\u00e7armos a falar sobre a sincroniza\u00e7\u00e3o em si, devemos estabelecer alguns cuidados a serem tomados no processo. Nunca voltar no tempo - isso poderia levar a um dado ter data de edi\u00e7\u00e3o anterior a data de cria\u00e7\u00e3o. Ajustes graduais - acelere ou desacelere o rel\u00f3gio (em software) Diminua/Aumente frequ\u00eancia de interrup\u00e7\u00e3o para atrasar/adiantar rel\u00f3gio Diminua/Aumente incremento com cada interrup\u00e7\u00e3o Ajustes peri\u00f3dicos para fazer curvas convergirem. Corre\u00e7\u00e3o ap\u00f3s dormir ser\u00e1 mais dr\u00e1stica Agora que voc\u00ea j\u00e1 tem uma fonte confi\u00e1vel de tempo, o UTC, e sabe com que frequ\u00eancia sincronizar os rel\u00f3gios, s\u00f3 nos falta fazer a sincroniza\u00e7\u00e3o. Contudo, falta ainda definir o protocolo pelo qual a sincroniza\u00e7\u00e3o \u00e9 feita e exatamente com quem, uma vez que simpleste UTC \u00e9 muito gen\u00e9rico. Comecemos com vetor \"pr\u00f3ximo\" do UTC, os rel\u00f3gios at\u00f4micos em sat\u00e9lites GPS.","title":"Sincroniza\u00e7\u00e3o de Rel\u00f3gios"},{"location":"time/#global-positioning-system","text":"Receptores GPS, com seus rel\u00f3gios sincronizados com os dos sat\u00e9lites, que difundem regularmente sua posi\u00e7\u00e3o e o instante em que a difus\u00e3o \u00e9 feita, determinam sua posi\u00e7\u00e3o relativa aos sat\u00e9lites, em uma t\u00e9cnica conhecida como trilatera\u00e7\u00e3o, que consiste em determinar a dist\u00e2ncia do receptor em termos dos eixos \\(x\\) , \\(y\\) e \\(z\\) em rela\u00e7\u00e3o a cada um dos sat\u00e9lites. Em outras palavras, baseado na informa\u00e7\u00e3o de um sat\u00e9lite, o receptor determina sua dist\u00e2ncia ao mesmo e, portanto, determina que est\u00e1 em uma esfera no entorno do sat\u00e9lite. Combinando a informa\u00e7\u00e3o de 2 sat\u00e9lites, a posi\u00e7\u00e3o do receptor \u00e9 limitada a uma circunfer\u00eancia, isto \u00e9, a interse\u00e7\u00e3o de duas esferas. Com um terceiro sat\u00e9lite, a posi\u00e7\u00e3o \u00e9 reduzida a dois pontos, a interse\u00e7\u00e3o de uma esfera e uma circunfer\u00eancia, sendo um no espa\u00e7o e que pode ser facilmente descartado. Contudo, para que funcione, rel\u00f3gios dos sat\u00e9lites e receptores precisam estar sincronizados para que o c\u00e1lculo da dist\u00e2ncia possa ser feito, mas sincronizar os rel\u00f3gios \u00e9 exatamente o problema que estamos tentando resolver. Para contornar esta restri\u00e7\u00e3o, usa-se um quarto sat\u00e9lite, para determinar a dist\u00e2ncia no \"eixo temporal\". Assim, temos uma receita simples para sincroniza\u00e7\u00e3o de rel\u00f3gios com UTC: Coloque um receptor GPS em cada n\u00f3 do seu sistema Tenha erro de 0,1ns a 1ms do UTC Apesar da queda dos pre\u00e7os dos receptores, colocar um GPS em cada dispositivo pode ser custoso demais. Em vez disso, podemos usar um recurso amplamente dispon\u00edvel, redes de computadores, e sincronizar com outra m\u00e1quina, que fez o investimento necess\u00e1rio para manter o erro baixo. Para estes computadores \"de segundo escal\u00e3o\", a receita ent\u00e3o \u00e9: Pergunte que horas s\u00e3o. Use a resposta para ajustar o rel\u00f3gio local. Considere o erro introduzido pela lat\u00eancia vari\u00e1vel da rede. Esta receita b\u00e1sica pode ser ajustada de diversas formas.","title":"Global Positioning System"},{"location":"time/#algoritmo-de-cristian","text":"Assumindo que o rel\u00f3gio da m\u00e1quina se sincronizando, \\(M_1\\) , \u00e9 bom o suficiente para medir a passagem de tempo em per\u00edodos curtos, mesmo que tenha uma drift rate consider\u00e1vel em per\u00edodos mais longos, execute o seguinte protocolo para se sincronizar com \\(M_2\\) . \\(M_1\\) pergunta \"que horas s\u00e3o?\" - \\(t_0\\) \\(M_2\\) recebe pergunta - \\(t_1\\) \\(M_2\\) anota o valor do rel\u00f3gio - \\(t_s\\) \\(M_2\\) envia resposta - \\(t_2\\) \\(M_1\\) recebe resposta - \\(t_3\\) Assuma \\(t_1 = t_s = t_2\\) Assuma \\(\\frac{t_3-t_0}{2}\\) como o tempo de transmiss\u00e3o da resposta (m\u00e9dia da ida e da volta) \\(M_1\\) ajusta rel\u00f3gio para \\(t_c = t_s + \\frac{t_3-t_0}{2}\\) Mas e a aproxima\u00e7\u00e3o \\(\\frac{t_3-t_0}{2}\\) , \u00e9 boa? Podemos estimar o erro que ela introduz na sincroniza\u00e7\u00e3o, caso as mensagens tenham tempos de ida e volta assim\u00e9tricos. Apesar das diferen\u00e7as no tempo de ida e volta, existe um tempo m\u00ednimo para o tr\u00e1fego em cada um dos sentidos, \\(T_{min}\\) . A figura a seguir demonstra o erro desta t\u00e9cnica Fonte Observe que h\u00e1 dois casos extremos de erro na estimativa. No primeiro caso, dado um tempo de ida + volta igual a \\(T_1 - T_0\\) , na figura, a mensagem de ida trafega no tempo m\u00ednimo e a volta lentamente. Neste caso, a estimativa \\(\\frac{t_3-t_0}{2}\\) \u00e9 menor que o tempo de volta real. No segundo caso, a mensagem de ida trafega lentamente e a de volta no tempo m\u00ednimo, levando \\(\\frac{t_3-t_0}{2}\\) a ser maior que tempo de transmiss\u00e3o real da mensagem. O erro, contudo, est\u00e1 limitado \u00e0 faixa amarela no desenho, que tem dura\u00e7\u00e3o \\(T_1 - T_0 - 2T_{min}\\) . O erro ent\u00e3o varia de mais ou menos metade deste valor.","title":"Algoritmo de Cristian"},{"location":"time/#algoritmo-de-berkeley","text":"Enquanto o algoritmo de Cristian permite sincronizar um n\u00f3 com uma fonte, outro algoritmo, de Berkeley, permite sincronizar m\u00faltiplos n\u00f3s uns com os outros. Este algoritmo assume o que n\u00e3o h\u00e1 uma \"fonte da verdade\" do tempo, mas sim a necessidade de que todos os processos convirjam para um mesmo valor do rel\u00f3gio. \u00c9 como nos filmes de espi\u00e3o em que os rel\u00f3gios s\u00e3o sincronizados; pouco importa se a bomba explodir\u00e1 10:57 ou 10:59, desde que todos concordem quando isso vai acontecer. Isso \u00e9 o que chamamos de sincroniza\u00e7\u00e3o interna em vez de externa, como provido pelo algoritmo de Cristian. O algoritmo de Berkeley requer que todo n\u00f3 execute um processo de sincroniza\u00e7\u00e3o, um \"daemon\", e separa seus pap\u00e9is em dois tipos, prim\u00e1rio e secund\u00e1rio . O papel do prim\u00e1rio pode ser rotacionado entre os v\u00e1rios processos, sem perdas para sua execu\u00e7\u00e3o. O algoritmo ent\u00e3o \u00e9 executacomo se segue: Prim\u00e1rio pergunta \"que horas s\u00e3o\" para cada secund\u00e1rio (mensages 1,2,3 e 4) Secund\u00e1rio responde com valor atual do rel\u00f3gio (mensagens 5,6,7 e 8) Prim\u00e1rio ajusta as respostas de acordo com o algoritmo de Cristian, para minimizar erros. Prim\u00e1rio computa m\u00e9dia dos valores recebidos, ignorando outliers (como o da mensagem 8). Prim\u00e1rio envia ajustes para secund\u00e1rios (mensagens 8,9,10 e 11) Secund\u00e1rio executa ajuste sugerido pelo prim\u00e1rio. sequenceDiagram autonumber note over Prim\u00e1rio: 10:00 note over Secund\u00e1rio1: 10:06 note over Secund\u00e1rio2: 10:15 note over Secund\u00e1rio3: 23:18 par Pergunta Prim\u00e1rio->>Prim\u00e1rio: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio1: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio2: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio3: Que horas s\u00e3o? end par Resposta Prim\u00e1rio->>Prim\u00e1rio: 10:00 and Secund\u00e1rio1->>Prim\u00e1rio: 10:06 and Secund\u00e1rio2->>Prim\u00e1rio: 10:15 and rect rgb(255, 0, 0) Secund\u00e1rio3->>Prim\u00e1rio: 23:18 end end par Ajuste Prim\u00e1rio->>Prim\u00e1rio: 10:07 and Prim\u00e1rio->>Secund\u00e1rio1: 10:07 and Prim\u00e1rio->>Secund\u00e1rio2: 10:07 and Prim\u00e1rio->>Secund\u00e1rio3: 10:07 end Embora interessantes, estes algoritmos n\u00e3o s\u00e3o normalmente usados, pelo menos n\u00e3o em sua forma \"pura\", em sistemas computacionais. Em vez deles, usamos o Network Time Protocol (NTP).","title":"Algoritmo de Berkeley"},{"location":"time/#network-time-protocol","text":"O NTP foi especificado originalmente na RFC 1305 5 e estendido pelas RFCRFC 5905-5908 6 essencialmente para suportar IPv6 e reduzir o erro de sincroniza\u00e7\u00e3o para at\u00e9 10 \\(\\mu\\) s. Os diversos componentes do NTP s\u00e3o organizados em camadas, ou estrata , de forma que a informa\u00e7\u00e3o do tempo flui da camada 0 ( stratum 0 ) at\u00e9 a camada 15 ( stratum 15). Os componentes n\u00e3o est\u00e3o presos a camadas, que podem ser alteradas a medida que falhas acontecem e s\u00e3o dedicadas, e novos caminhos s\u00e3o encontrados usando-se o algoritmo de \u00e1rvore geradora m\u00ednima Bellman-Ford, al\u00e9m de caminhos redundantes que conferem propriedades de toler\u00e2ncia a falhas \u00e0 topologia. 4 Esta organiza\u00e7\u00e3o hier\u00e1rquica leva a cada camada garantir um n\u00edvel de sincroniza\u00e7\u00e3o diferente e permite escalar o uso do protocolo para n\u00edveis globais , usando a Internet como meio . Stratum 0: rel\u00f3gios at\u00f4micos/receptores GPS Stratum 1: ms to stratum 0 Stratum 2: contata m\u00faltiplos stratum 1 e pares Strata 3...15 Stratum 16: dessincronizado Toda a comunica\u00e7\u00e3o entre n\u00f3s pode ser autenticada , garantindo que a sincroniza\u00e7\u00e3o n\u00e3o seja facilmente manipulada e erros s\u00e3o minimizados pela coleta e uso de estat\u00edsticas de lat\u00eancia de comunica\u00e7\u00e3o, para evitar desvios quando fontes se tornam problem\u00e1ticas. NTP tem m\u00faltiplas formas de execu\u00e7\u00e3o, adequadas para diferentes ambientes. Modo multicast: propaga tempo em rede local RPC: algoritmo de Cristian Sim\u00e9trico: parecido com Berkeley Na pr\u00e1tica, boa parte dos dispositivos usa uma vers\u00e3o simplificada do NTP, o SNTP ( Simple Network Time Protocol ), adequada aos n\u00f3s nas folhas da hierarquia . O SNTP \u00e9 essencialmente o algoritmo de Cristian: \\(\\delta = (t_4-t_1)-(t_2-t_3)\\) \\(t = \\frac{(t_2-t_1)+(t3-t_4)}{2}\\) \\(t_c = t_4+t\\) Por exemplo, \\(t_1 = 1100, t_2 = 800, t_3=850, t_4=1200\\) \\(t = ((800-1100)+(850-1200))/2 = (-300 -350)/ = -325\\) \\(t_c = 1200-325 = 875\\) O Comit\u00ea Gestor da Internet, CGI , mantem uma excelente p\u00e1gina sobre o NTP, com mais detalhes do que apresentado aqui, em NTP.br .","title":"Network Time Protocol."},{"location":"time/#ptp-precision-time-protocol","text":"Mesmo com melhoria do protocolo e baratemento de dispositivos GPS, h\u00e1 ainda a necessidade de sincroniza\u00e7\u00e3o sub-microssegundo e barata. O Precision Time Protocol , PTP, especifica\u00e7\u00e3o IEEE 1588 7 tenta cobrir este nicho. Se escrutinizarmos o PTP, veremos que o protocolo em si n\u00e3o difere muito do NTP. Contudo, o PTP usa interfaces de rede especilizadas para fazer o timestamping dos eventos do protocolo, conseguindo remover a lat\u00eancia nos dispositivos processando as mensagens e reduzindo o erro do protocolo at\u00e9 sub \\(\\mu\\) (versus ordem de \\(ms\\) no NTP). Mais detalhes sobre o protocolo est\u00e3o fora do escopo deste documento, mas podem ser facilmente encontrados nos links dados.","title":"PTP - Precision Time Protocol"},{"location":"time/#usos-de-relogios-sincronizados","text":"Assumindo que tenhamos sincronizado os rel\u00f3gios de um sistema computacional, o que podemos fazer agora? Uma s\u00e9rie de problemas interessantes que podem ser resolvidos, como autentica\u00e7\u00e3o , termina\u00e7\u00e3o de transa\u00e7\u00f5es , aloca\u00e7\u00e3o de leases e diversos outros exemplos 8 . Um exemplo interessante \u00e9 a ordena\u00e7\u00e3o de eventos em um banco de dados. Para entender este problema, considere um cen\u00e1rio com um Sistema Banc\u00e1rio replicado, isto \u00e9, com v\u00e1rias c\u00f3pias. No exemplo, nos focamos em duas c\u00f3pias em lados opostos de uma rede de larga escala. Clientes disparam opera\u00e7\u00f5es como saques, dep\u00f3sitos e transfer\u00eancias, por meio de mensagens para as duas c\u00f3pias. Mensagens para a c\u00f3pia pr\u00f3xima do cliente (em verde) s\u00e3o entregues rapidamente, enquanto mensagens para a c\u00f3pia distante (em vermelho), demoram mais para ser entregues. Imagine que o usu\u00e1rio U1 envie o comando C1 \"atualizar saldo da conta para USD 10 9 \" e que o usu\u00e1rio U2 envie o comando C2 \"atualizar saldo da conta para USD 20\". Se os comandos chegam primeiro para a r\u00e9plica mais pr\u00f3xima e s\u00e3o executados na ordem em que chegam, ao final da execu\u00e7\u00e3o a r\u00e9plica R1 ter\u00e1 executado C1 seguido de C2, tendo saldo da conta como USD 20, enquanto R2 ter\u00e1 executado C2 seguido de C1 e ter\u00e1 como saldo na conta USD 10. O problema est\u00e1 na ordem de execu\u00e7\u00e3o das opera\u00e7\u00f5es. Assuma que rel\u00f3gios est\u00e3o perfeitamente sincronizados e que toda mensagem/update carrega consigo o timestamp de quando foi enviada. E se as r\u00e9plicas processarem mensagens na ordem que foram enviadas, como identificado pelos seus timestamps ? 10 Assim, se C1 foi enviado antes de C2, C1 tem um timestamp menor que C2 e ser\u00e1 executada primeiro em ambas as r\u00e9plicas, o que resolve nosso problema, correto? Parcialmente, pois ainda temos o problema de identificar que nenhuma outra mensagem ainda por ser entregue foi enviada antes. Para isto, precisamos estender o modelo e assumir que o tempo de propaga\u00e7\u00e3o m\u00e1ximo de uma mensagem, \\(\\tau\\) , \u00e9 finito. Assim, ao receber um comando com timestamp \\(t\\) , uma r\u00e9plica espera at\u00e9 \\(t + \\tau\\) antes de execut\u00e1-lo, pois qualquer comando com timestamp \\(t' < t\\) deve ter sido entregue at\u00e9 \\(t+\\tau\\) . Implementar este protocolo \u00e9 muito simples: Ordena\u00e7\u00e3o de Mensagens por Timestamp Quando enviar uma mensagem, aumente-a com o valor atual do rel\u00f3gio. Quando receber uma mensagem, coloque-a em uma fila ordenada por timestamp . Quando o rel\u00f3gio marcar um tempo maior que \\(t + \\tau\\) , onde \\(t\\) \u00e9 o timestamp da mensagem na cabe\u00e7a da fila, retire a mensagem da cabe\u00e7a da fila e execute o comando correspondente. Embora correto, este protocolo, ou melhor, o modelo, n\u00e3o leva em considera\u00e7\u00e3o a dessincroniza\u00e7\u00e3o inerente dos rel\u00f3gios em um sistema distribu\u00eddo. Como faz\u00ea-lo, supondo uma diverg\u00eancia m\u00e1xima de \\(\\Delta\\) entre quaisquer dois rel\u00f3gios, algo que pode ser arranjado, como visto antes, sincronizando-se os rel\u00f3gios a cada \\(\\frac{\\Delta}{2*\\rho}\\) . Se \\(\\Delta\\) \u00e9 a diferen\u00e7a m\u00e1xima entre rel\u00f3gios, ent\u00e3o se uma mensagem \u00e9 enviada no instante \\(t\\) , ent\u00e3o at\u00e9 \\(\\Delta +t\\) , outro processo, atrasado em rela\u00e7\u00e3o ao primeiro, poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) . Tal mensagem pode demorar at\u00e9 \\(\\tau\\) para ser entregue \u00e0 r\u00e9plica, ou seja, no instante \\(t + \\tau + \\Delta\\) , do ponto de vista do primeiro cliente. Se a r\u00e9plica estiver sincronizada com cliente, ent\u00e3o se esperar at\u00e9 \\(t + \\tau + \\Delta\\) para executar o comando, o far\u00e1 de forma segura. Se estiver atrasada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o acabar\u00e1 por esperar al\u00e9m do necess\u00e1rio, mas sem violar a corretude do sistema. Finalmente, se a r\u00e9plica estiver adiantada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o seu rel\u00f3gio alcan\u00e7ar\u00e1 \\(t + \\tau + \\Delta\\) antes do rel\u00f3gio do primeiro cliente, mas isso n\u00e3o \u00e9 um problema. Isto porqu\u00ea, o \u00faltimo instante em que o cliente 2 poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) \u00e9 o instante em que o rel\u00f3gio da r\u00e9plica marcar \\(t + \\Delta\\) , e portanto dever\u00e1 tamb\u00e9m ser recebido at\u00e9 que o mesmo rel\u00f3gio marque \\(t + \\tau + \\Delta\\) . O mesmo racioc\u00ednio pode ser usado para definir um protocolo de acesso recursos para os quais leases s\u00e3o distribu\u00eddos, onde um lease \u00e9 uma permiss\u00e3o de acesso durante uma janela de tempo, emitida por um coordenador (possivelmente eleito usando os algoritmos vistos anteriormente), e \\(\\Delta\\) \u00e9 o m\u00e1ximo de dessincronismo entre os rel\u00f3gios. O seguinte protocolo resolve este problema: Aloca\u00e7\u00e3o de Lease Ao receber um lease para a janela de tempo \\(t_1\\) a \\(t_2\\) espera at\u00e9 \\(t_1 + \\Delta\\) usa o recurso at\u00e9 \\(t_2\\) . Se rel\u00f3gio estiver adiantado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1+\\Delta\\) enquanto o anterior acha que \u00e9 \\(t_1\\) ; exclus\u00e3o m\u00fatua garantida. Se rel\u00f3gio estiver atrasado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1 - \\Delta\\) , e continua esperando, enquanto ele acha que j\u00e1 \u00e9 \\(t_1\\) e para de usar; exclus\u00e3o m\u00fatua garantida. Recurso fica ocioso por \\(\\Delta\\) , em m\u00e9dia, a cada lease. Devido ao alto custo de se manter o recurso n\u00e3o utilizado, \\(\\Delta\\) deve ser feito t\u00e3o pequeno quanto poss\u00edvel. Leia Google True Time e Spanner para ver como o Google consegue manter a diferen\u00e7a em sub milisegundos, usando rel\u00f3gios at\u00f4micos dentro de seus datacenters e um API para gera\u00e7\u00e3o de timestamps. Todo Google TrueTime Nas solu\u00e7\u00f5es anteriores, um n\u00f3 precisa esperar por muito tempo antes de usar um recurso. E se ele aprendesse antes que os outros n\u00f3s n\u00e3o far\u00e3o requisi\u00e7\u00f5es? Que n\u00e3o haver\u00e3o sobreposi\u00e7\u00f5es de requisi\u00e7\u00f5es? E se houvesse um rel\u00f3gio que avan\u00e7asse n\u00e3o com o tempo, mas com eventos interessantes do sistema? Esta \u00e9 a ideia dos rel\u00f3gios l\u00f3gicos .","title":"Usos de rel\u00f3gios sincronizados"},{"location":"time/#tempo-logico","text":"A ideia por tr\u00e1s do \"tempo l\u00f3gico\" \u00e9 de o que importa s\u00e3o eventos e n\u00e3o a passagem do tempo, uma vez que tempo \u00e9 relativo aos processos 11 . Assim, surgem os rel\u00f3gios l\u00f3gicos, que ``ticam'' quando um evento importante acontece. Para chegarmos aos rel\u00f3gios l\u00f3gicos, precisamos primeiro entender a rela\u00e7\u00e3o Happened-Before , proposta por Leslie Lamport 12 e que lhe rendeu um Pr\u00eamio Turing em 2014 . Hoje \u00e9 comum usar a rela\u00e7\u00e3o happened-before e o vocabul\u00e1rio associado para falar sobre ordem de eventos em um sistema computacional, em especial um distribu\u00eddo.","title":"Tempo L\u00f3gico"},{"location":"time/#happened-before","text":"A rela\u00e7\u00e3o happened-before captura a causalidade entre eventos. Isto \u00e9, se um evento \\(a\\) aconteceu-antes de um evento \\(b\\) , ent\u00e3o \\(a\\) potencialmente causou \\(b\\) . Tamb\u00e9m podemos dizer que \\(a\\) precede \\(b\\) em uma ordem causal. O evento \\(a\\) aconteceu-antes \\(b\\) , notado como \\(a \\rightarrow b\\) , se uma das tr\u00eas condi\u00e7\u00f5es seguintes \u00e9 v\u00e1lida: Happened-Before Se \\(a\\) e \\(b\\) s\u00e3o eventos em um mesmo processo (ou thread ) e \\(a\\) foi executado antes de \\(b\\) . Se \\(a\\) e \\(b\\) s\u00e3o eventos de processos distintos e \\(a\\) \u00e9 o envio de uma mensagem e \\(b\\) a sua recep\u00e7\u00e3o. Se h\u00e1 transitividade, isto \u00e9, se existe um evento \\(c\\) tal que \\(a \\rightarrow c\\) e \\(c \\rightarrow b\\) . TODO Imagem somente com os eventos, sem o valor do rel\u00f3gio. Note que se \\(a \\rightarrow b\\) \u00e9 falso e \\(b \\rightarrow a\\) \u00e9 falso, ent\u00e3o \\(a\\) e \\(b\\) s\u00e3o concorrentes , e que ser concorrente n\u00e3o quer dizer que aconteceram exatamente no mesmo instante, do ponto de vista de um observador externo. Ser concorrente quer dizer que um evento \\(a\\) n\u00e3o podem ter sido a causa do evento \\(b\\) , dado que os efeitos de \\(a\\) n\u00e3o poderiam ser conhecidos pelo processo onde \\(b\\) ocorreu, quando \\(b\\) ocorreu. O cone de luz na figura seguinte mostra esta rela\u00e7\u00e3o entre eventos. Se capturarmos a causalidade de eventos, podemos usar esta informa\u00e7\u00e3o para ordenar o se processamento, de forma a fazer sentido. Considere o seguinte exemplo, em que o primeiro usu\u00e1rio de um servi\u00e7o de emails recebe primeiro a resposta da mensagem A, R:A, para somente depois receber A. Para que a troca de mensagens fa\u00e7a sentido, o usu\u00e1rio posterga a leitura de R:A at\u00e9 depois de ter lido A. Observe que em nenhum momento a informa\u00e7\u00e3o sobre quando as mensagens foram enviadas foi necess\u00e1ria, apenas a ordem das mesmas. Rel\u00f3gios l\u00f3gicos permitem que sistemas capturem a rela\u00e7\u00e3o de causalidade entre eventos e implementem esquemas como o apenas descrito, para coordenar as a\u00e7\u00f5es dos processos em sistemas distribu\u00eddos.","title":"Happened-Before"},{"location":"time/#relogios-logicos","text":"Para que computadores possam usar a causalidade, precisamos capturar a rela\u00e7\u00e3o de acontecer antes em um sistema. Lamport prop\u00f4s uma tal forma, que denominou rel\u00f3gio l\u00f3gico , mas que hoje \u00e9 conhecido universalmente como rel\u00f3gio de Lamport . Estes rel\u00f3gios permitem associar um timestamp a eventos de forma a se garantir a seguinte propriedade: seja \\(e\\) um evento seja \\(C(e)\\) o valor do rel\u00f3gio l\u00f3gico quando associado a \\(e\\) se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) Mas como definir a fun\u00e7\u00e3o \\(C\\) ? Experimentemos a seguinte defini\u00e7\u00e3o: Quase Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. \\(C(e) = ++c_p\\) no momento em que \\(e\\) ocorreu. Usamos como \\(<\\) a rela\u00e7\u00e3o normal de inteiros. Observe que n\u00e3o h\u00e1 fonte da verdade em termos de tempo l\u00f3gico, j\u00e1 que cada processo mant\u00e9m seu pr\u00f3prio rel\u00f3gio que pode ser relacionado com rel\u00f3gios de outros processos. Veja um exemplo desta defini\u00e7\u00e3o em a\u00e7\u00e3o. \u00c9 verdade neste cen\u00e1rio que se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) ? Observe com aten\u00e7\u00e3o os eventos \\(f\\) e \\(k\\) , pois para estes, a regra n\u00e3o \u00e9 respeitada.","title":"Rel\u00f3gios l\u00f3gicos"},{"location":"time/#relogio-de-lamport","text":"Para que a regra \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) seja v\u00e1lida, precisamos modificar a tentativa anterior para que, na recep\u00e7\u00e3o de uma mensagem, os contadores sejam atualizados para que sejam maiores tanto que os rel\u00f3gios dos eventos locais quanto dos eventos que antecederam o envio da mensagem sendo recebida. Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. Se o evento \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) Se o evento \\(e\\) \u00e9 o envio de uma mensagem \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) \\(C(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se o evento \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) \\(c_p \\gets max(c_e,ts)+1\\) . \\(C(e) \\gets c_p\\) Com este ajuste, temos os Rel\u00f3gios de Lamport . Neste caso, temos que para quaisquer eventos \\(a,b\\) , se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) . Todo Exemplo em que n\u00e3o \u00e9 bom o suficiente. Se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) . Contudo, a volta n\u00e3o \u00e9 verdade, isto \u00e9, se \\(C(a) < C(b)\\) ent\u00e3o \\(a \\rightarrow b\\) . Esta propriedade \u00e9 interessante na ordena\u00e7\u00e3o de eventos, pois evita que eventos concorrentes sejam ordenados. Entram os rel\u00f3gios vetoriais.","title":"Rel\u00f3gio de Lamport"},{"location":"time/#relogio-vetorial","text":"Rel\u00f3gios vetoriais s\u00e3o rel\u00f3gios l\u00f3gicos em que cada processo mant\u00e9m n\u00e3o apenas um contador dos seus eventos locais, mas tamb\u00e9m sua vis\u00e3o dos contadores dos outros processos. Estas vis\u00f5es s\u00e3o atualizadas a cada recep\u00e7\u00e3o de mensagem, de acordo com a seguinte especifica\u00e7\u00e3o, onde assume-se que \\(n\\) processos fazem parte do sistema. Rel\u00f3gio Vetorial Considerando o ponto de vista do processo \\(p\\) Seja \\(c_p[i], 1 \\leq i \\leq n\\) inicialmente igual a 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) \\(V(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p[i] \\gets max(c_p[i], ts[i]), \\forall i \\neq p\\) \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) Uma observa\u00e7\u00e3o interessante a ser feita aqui \u00e9 que embora o algoritmo pare\u00e7a indicar que cada processo precisa saber quantos mais processos existem no sistema, isto n\u00e3o \u00e9 verdade, pois pode-se assumir que para todo processo desconhecido \\(q\\) , \\(c_p[q] = 0\\) . Como dito, este rel\u00f3gio l\u00f3gico tem a propriedade \\(a \\rightarrow b \\iff V(a) < V(b)\\) , considerando-se a seguinte defini\u00e7\u00e3o de \\(<\\) para vetores: Compara\u00e7\u00e3o entre vetores \\(v = v' \\iff v[i] = v'[i], 1 \\leq i \\leq n\\) \\(v \\leq v' \\iff v[i] \\leq v'[i], 1 \\leq i \\leq n\\) \\(v < v' \\iff v \\leq v' \\land v \\neq V'\\) Assim, sejam dois eventos \\(e \\neq e'\\) : \\(e \\rightarrow e' \\iff V(e) < V(e')\\) Se \\(V(e) \\not < V(e')\\) e \\(V(e') \\not < V(e)\\) , ent\u00e3o \\(e\\) e \\(e'\\) s\u00e3o concorrentes. Para entender melhor como esta defini\u00e7\u00e3o funciona, considere a seguinte execu\u00e7\u00e3o. O que quer dizer \\(c_p[q] = k\\) , ou tomando o evendo \\(d\\) como exemplo, o que quer dizer \\(c_{P_2}[1]=2\\) ? Quer dizer que \\(P_2\\) est\u00e1 ciente de 2 eventos locais a \\(P_1\\) , assim com est\u00e1 ciente de 0 eventos em \\(P_3\\) e de que \\(d\\) \u00e9 o segundo evento em \\(P_2\\) . Logo, \\(d\\) pode ter sido causado por 2 eventos de \\(P_1\\) , 1 evento de \\(P_2\\) e 0 de \\(P_3\\) . Agora compare os eventos \\(e\\) e \\(d\\) . \\(e\\) e \\(d\\) s\u00e3o concorrentes pois embora as posi\u00e7\u00f5es 1 e 2 de \\(V(d)\\) sejam maiores que em \\(V(e)\\) , a posi\u00e7\u00e3o 3 \u00e9 menor. Isso quer dizer que o nem \\(e\\) est\u00e1 ciente do evento \\(d\\) e nem \\(d\\) est\u00e1 ciente do evento \\(e\\) , ou melhor, que um n\u00e3o pode ter causado o outro. Esta abstra\u00e7\u00e3o simples j\u00e1 \u00e9 muito poderosa e, embora possa ser melhorada 13 , j\u00e1 \u00e9 suficiente para se implementar outras abstra\u00e7\u00f5es interessantes, como ser\u00e1 visto adiante. Antes, \u00e9 necess\u00e1rio mencionar mais um tipo de rel\u00f3gio l\u00f3gico, os h\u00edbridos.","title":"Rel\u00f3gio Vetorial"},{"location":"time/#relogios-hibridos","text":"A grande vantagem dos rel\u00f3gios l\u00f3gicos sobre os f\u00edsicos \u00e9 de ignorar a passagem do tempo, s\u00f3 se importanto com a ordem de eventos. Esta vantagem tamb\u00e9m \u00e9 uma desvantagem quando eventos precisam ser associados a eventos externos ao sistema, por exemplo, durante uma sess\u00e3o de depura\u00e7\u00e3o. Suponha que ap\u00f3s uma atualiza\u00e7\u00e3o de um sistema, voc\u00ea note um problema nos dados e, em depurando o problema, identifique o evento problem\u00e1tico nos logs do sistema, associado ao seu rel\u00f3gio l\u00f3gico. Como identificar se este evento problem\u00e1tico aconteceu antes ou depois da atualiza\u00e7\u00e3o? Rel\u00f3gios h\u00edbridos tentam resolver este problema combinando rel\u00f3gios f\u00edsicos e l\u00f3gicos em um. No seguinte algoritmo, cada processo mantem um rel\u00f3gio f\u00edsico e um l\u00f3gico e sempre que um evento acontece, usa como novo valor do rel\u00f3gio l\u00f3gico o m\u00e1ximo entre o valor anterior + 1, o valor do timestamp na mensagem sendo recebida + 1, se for o recebimento de uma mensagem, e o valor do rel\u00f3gio f\u00edsico. Isto \u00e9, se poucos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico acompanhar\u00e1 o valor do f\u00edsico. Rel\u00f3gio H\u00edbrido Simples Considerando o ponto de vista do processo \\(p\\) \\(c_p.f\\) \u00e9 o rel\u00f3gio f\u00edsico de \\(p\\) , incrementado automaticamente \\(c_p.l\\) \u00e9 o rel\u00f3gio l\u00f3gico de \\(p\\) , inicialmente 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) \\(H(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p.l \\gets max(c_p.l + 1, ts + 1, c_p.f)\\) \\(V(e) = c_p.l\\) Nesta vers\u00e3o do algoritmo, contudo, se muitos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico pode ser incrementadado muito rapidamente, perdendo a rela\u00e7\u00e3o com o rel\u00f3gio f\u00edsico. Em uma vers\u00e3o melhorada do algoritmo, 14 a dist\u00e2ncia entre os dois rel\u00f3gios \u00e9 limitada, mantendo a propriedade que faz o rel\u00f3gios h\u00edbridos interessantes. 15","title":"Rel\u00f3gios H\u00edbridos"},{"location":"time/#comunicacao-em-grupo","text":"Rel\u00f3gios l\u00f3gicos podem e s\u00e3o usados diretamente em sistemas, por exemplo, para controlar vers\u00f5es no sistema de identidade da Microsoft, Active Directory . Outra forma de uso \u00e9 como block de constru\u00e7\u00e3o de outras abstra\u00e7\u00f5es, por exemplo, primitivas de comunica\u00e7\u00e3o em grupo, pelas quais um processo envia mensagens para um conjunto de processos. Difus\u00e3o Totalmente Ordenada ( Total Order Multicast ): Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem Difus\u00e3o Causalmente Ordenada: Causalmente Ordenada: uma mensagem s\u00f3 \u00e9 entregue se todas as que causalmente a precedem j\u00e1 foram entregues. Com estas abstra\u00e7\u00f5es, podemos resolver o problema apresentado no in\u00edcio deste cap\u00edtulo, relembrando, cloud-drive , da seguinte forma. Considere um programa qualquer, que se comporte de forma determin\u00edstica (isto \u00e9, dada uma mesma entrada, gera sempre uma mesma sa\u00edda). Como todo programa, este \u00e9 uma m\u00e1quina de estados, com a peculiaridade de ser determin\u00edstica. Logo, se tivermos v\u00e1rias c\u00f3pias deste programa, executando em locais distintos, mas garantirmos que cada c\u00f3pia veja exatamente a mesma entrada de dados , ent\u00e3o garantiremos que todas as c\u00f3pias transitar\u00e3o pelos mesmos estados e chegar\u00e3o ao mesmo estado final. Como difus\u00e3o totalmente ordenada pode ser usado para garantir que todas as c\u00f3pias receber\u00e3o a mesma entrada, pode ser usado para implementar esta t\u00e9cnica, conhecida como Replica\u00e7\u00e3o de M\u00e1quinas de Estados (em ingl\u00eas, State Machine Replication , ou pelo menos o seu princ\u00edpio. Mas como podemos implementar estas primitivas de difus\u00e3o usando rel\u00f3gios l\u00f3gicos? Vejamos um algoritmo, onde consideramos que todas as mensagens s\u00e3o enviadas a todos os processos, inclusive o pr\u00f3prio remetente. Difus\u00e3o Totalmente Ordenado Considerando o ponto de vista do processo \\(p\\) \\(f_p\\) \u00e9 uma fila de mensagens ordenadas pelo seus timestamps , mantida em \\(p\\) Para difundir uma mensagem \\(m\\) colocar \\(m\\) na fila enviar \\(m\\) para todos os demais processos Quando uma mensagem \\(m\\) \u00e9 recebida colocar \\(m\\) na fila se \\(m\\) n\u00e3o \u00e9 um ack enviar \\(m ack\\) de volta ao remetente de \\(m\\) (com timestamp maior que de \\(m\\) ) Seja \\(m\\) a mensagem com timestamp ts na cabe\u00e7a da fila Se para cada processo \\(q\\) , h\u00e1 uma mensagem \\(m'\\) de \\(q\\) com timestamp ts' na fila de \\(p\\) tal que \\(ts < ts'\\) entregar \\(m\\) para a aplica\u00e7\u00e3o O objetivo deste algoritmo \u00e9 de entregar mensagens na ordem de seus timestamps . Para isso, antes de entregar a mensagem \\(m\\) de menor tmestamp ts conhecido atualmente por \\(p\\) , \\(p\\) espera por mensagens com \\(timestamps\\) maiores que ts de todos os processos. Uma vez que isso aconte\u00e7a, \\(p\\) sabe que nenhuma outra mensagem que chegue depois poderia ter \\(timestamp\\) menor que ts. Para que isto funcione, \u00e9 necess\u00e1rio que os canais de comunica\u00e7\u00e3o usados sejam confi\u00e1veis (todas as mensagens enviadas s\u00e3o entregues) e FIFO (a primeira a ser enviada \u00e9 primeira a ser recebida). Exerc\u00edcio - FIFO e Confi\u00e1veis \u00c9 necess\u00e1rio que canais de comunica\u00e7\u00e3o sejam FIFO e confi\u00e1veis para que mensagens com timestamp maiores n\u00e3o sejam perdidas e para que mensagens com timestamps maiores n\u00e3o sejam reordenadas e entregues primeiro. Explique porqu\u00ea isto seria um problema; descreva execu\u00e7\u00f5es problem\u00e1ticas. Vejamos um outro algoritimo, de difus\u00e3o causalmente ordenada. Difus\u00e3o Causalmente Ordenada Considerando o ponto de vista do processo \\(p\\) \\(p\\) incrementa \\(c_p[p]\\) somente no envio de mensagens. \\(p\\) s\u00f3 entrega uma mensagem recebida de \\(q\\) , com timestamp \\(ts\\) quando \\(ts[q] = c_p[q]+1\\) \\(ts[k] \\leq c_p[k], k \\neq q\\) Difus\u00e3o Causalmente Ordenada Considere \\(c_{P_2}[0,2,2]\\) e \\(ts=[1,3,0]\\) , de \\(P_0\\) . O que \\(P_2\\) est\u00e1 esperando? Como age ao receber mensagem com \\(ts\\) ? Um aspecto interessante da implementa\u00e7\u00e3o de primitivas de comunica\u00e7\u00e3o em grupo que usa rel\u00f3gios para ordena\u00e7\u00e3o de mensagens \u00e9 que elas podem ser feitas de forma transparente para a aplica\u00e7\u00e3o que as usa. Isto \u00e9, no exemplo descrito anteriormente em que processos mandam mensagens para r\u00e9plicas usando difus\u00e3o totalmente ordenada, os clientes n\u00e3o precisam estar cientes disto, e podem simplesmente mandar suas requisi\u00e7\u00f5es como faziam antes do servi\u00e7o ser replicado. Mas como ent\u00e3o as mensagens tem seus rel\u00f3gios l\u00f3gicos atualizados e usados para a gera\u00e7\u00e3o de timestamps ? Isto pode ser feito por meio de interceptadores em uma camada de middleware . Quando a aplica\u00e7\u00e3o envia uma mensagem, o rel\u00f3gio l\u00f3gico mantido no middleware \u00e9 atualizado e seu valor usado como timestamp em uma vers\u00e3o estendida da mensagem, efetivamente enviada na rede. Quando a mensagem estendida \u00e9 entregue ao destinat\u00e1rio, a mensagem \u00e9 passada para o interceptador que extrai o timestamp e atualiza seu rel\u00f3gio. A mensagem sem o timestamp \u00e9 entregue para a aplica\u00e7\u00e3o quando apropriado, e aplica\u00e7\u00e3o n\u00e3o percebe a manipula\u00e7\u00e3o.","title":"Comunica\u00e7\u00e3o em Grupo"},{"location":"time/#exclusao-mutua-revisitada","text":"Todo Algoritmos de Exclu\u00e3o m\u00fatua baeados em LC Algoritmo de Lamport, Ricart e agrawalla Algoritmo de Maekawa Explain that stuff. \u21a9 Distor\u00e7\u00e3o mec\u00e2nica gera corrente el\u00e9trica e submiss\u00e3o a uma corrente el\u00e9trica gera uma distor\u00e7\u00e3o mec\u00e2nica. \u21a9 32768 \u00e9 a primeira pot\u00eancia de 2 maior que 20000, a maior frequ\u00eancia sonora aud\u00edvel aos seres humanos. \u21a9 Fonte: Benjamin D. Esham, (bdesham) - Based upon Ntp.png by Kim Meyrick \u21a9 RFC 1305 , 1991/1992 \u21a9 RFC 5905-5908,2010 \u21a9 IEEE 1588TM Standard for A Precision Clock Synchronization Protocol for Networked Measurement and Control Systems . \u21a9 Liskov, B.: Distrib Comput (1993) 6: 211. doi:10.1007/BF02242709 \u21a9 Unidade Simples de Dinheiros. \u21a9 Empates s\u00e3o quebrados pelo identificador do processo, isto \u00e9, se duas mensagens s\u00e3o produzidas ao mesmo tempo por U1 e U2, ent\u00e3o o a mensagem de U1 tem preced\u00eancia na execu\u00e7\u00e3o. \u21a9 Reza a lenda que Leslie Lamport desenvolveu o conceito de rel\u00f3gios l\u00f3gicos pensando na teoria da relatividade geral. \u21a9 Time, Clocks and the Ordering of Events in a Distributed System. July 5, 1978 . \u21a9 Matrix Clock \u21a9 O blog de um dos autores descreve ambas as vers\u00f5es de forma resumida. Para a vers\u00e3o completa dos algoritmos, consulte o artigo . \u21a9 Tanto no artigo quanto no blog, a imagem que descreve um exemplo do HLC parece ter um erro e onde se l\u00ea (3,13) deve-se ler (3,10,3). \u21a9","title":"Exclusao M\u00fatua Revisitada"}]}