{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Notas em Sistemas Distribu\u00eddos","title":"Notas em Sistemas Distribu\u00eddos"},{"location":"#notas-em-sistemas-distribuidos","text":"","title":"Notas em Sistemas Distribu\u00eddos"},{"location":"consistency/","text":"Considere por um momento, uma Content Delivery Network (CDN). CDN Conte\u00fado \u00e9 colocado pr\u00f3ximo aos clientes. Conte\u00fado est\u00e1tico ou majoritariamente determin\u00edstico. Um pequeno atraso na replica\u00e7\u00e3o \u00e9 tolerado. Atualiza\u00e7\u00e3o acontece infrequentemente. As Content Delivery Networks s\u00e3o sistemas que replicam os dados do contratante para, dinamicamente, colocar o conte\u00fado pr\u00f3ximo ao usu\u00e1rio. Se o conte\u00fado \u00e9 majoritariamente est\u00e1tico, entregar esta funcionalidade \u00e9 \"simples\", implicando apenas em um pequeno atraso entre a publica\u00e7\u00e3o de novo conte\u00fado e sua disponibiliza\u00e7\u00e3o para os usu\u00e1rios. Neste caso, um protocolo de difus\u00e3o totalmente ordenada, como o RAFT, pode ser usado na replica\u00e7\u00e3o, isto \u00e9, para garantir que todos os servidores vejam as mesmas mudan\u00e7as, na mesma ordem, e que alcancem o mesmo estado final em algum momento. Contudo, os protocolos de difus\u00e3o totalmente ordenada tem um alto custo para atualizar as r\u00e9plicas e este custo pode ser demais para a aplica\u00e7\u00e3o. Neste caso, podemos tentar relaxar os requisitos da aplica\u00e7\u00e3o, por exemplo permitindo que atualiza\u00e7\u00f5es sejam vistas em ordens diferentes por diferentes \"r\u00e9plicas\", agora com aspas. Por exemplo, se em vez de difus\u00e3o at\u00f4mica us\u00e1ssemos IP-Multicast, ter\u00edamos uma atualiza\u00e7\u00e3o mais barata dos dados, mas alguns valores escritos poderiam nunca ser vistos. O que quero mostrar aqui \u00e9 h\u00e1 custos inerentes na coordena\u00e7\u00e3o das partes do sistema distribu\u00eddo, mas que \u00e9 poss\u00edvel pensar em n\u00edveis diferentes de coordena\u00e7\u00e3o, com diferentes custos e \u00e9 a\u00ed que entram os diversos modelos ou n\u00edveis de consist\u00eancia. Modelos de Consist\u00eancia Embora n\u00e3o seja necess\u00e1rio, para falarmos sobre modelos de consist\u00eancia, falaremos sobre bancos de dados pois \u00e9 algo pr\u00f3ximo da realidade da maioria dos estudantes e torna mais f\u00e1cil o entendimento do t\u00f3pico. Um banco de dados pode ser pensado, em sua forma mais simplista, como um conjunto de vari\u00e1veis nas quais valores s\u00e3o armazenados. Assim, clientes do banco de dados essencialmente executam comandos como \\(X\\) recebe 'Jo\u00e3o' e \\(Y\\) recebe 'joao arroba hmail.com' . Obviamente que \\(X\\) e \\(Y\\) n\u00e3o precisam ser declarados antes da primeira escrita, assim como chaves prim\u00e1rias n\u00e3o s\u00e3o declaradas at\u00e9 que sejam usadas, e que o valor associado a uma vari\u00e1vel pode ter v\u00e1rias partes, como \"{'Endere\u00e7o':'Av 1, n\u00famero 2', 'Profiss\u00e3o':'Computeiro'} e cada parte um tipo. Veja bem, eu disse uma simplifica\u00e7\u00e3o, mas n\u00e3o quer dizer que nao seja uma simplifica\u00e7\u00e3o poderosa. Quando um processo se comunica com um banco de dados, ele o faz com certas expectativas quanto ao funcionamento deste banco. Por exemplo, ao escrever um dados no banco, independentemente de como o banco \u00e9 implementado, o cliente geralmente espera que as escritas aconte\u00e7am na ordem em que as disparou e que, ao ler uma vari\u00e1vel, lhe seja retornado o \"\u00faltimo\" valor escrito na mesma. Esta expectativa \u00e9 independente do banco de dados ser implementado de forma distribu\u00edda ou n\u00e3o. Isto \u00e9, mesmo que os dados armazenados no banco sejam particionados ou replicados entre v\u00e1rios n\u00f3s, o cliente espera que o banco tenha comportamento consistente com o de um banco n\u00e3o distribu\u00eddo e retorne ou aquilo que escreveu ou algo mas recente. N\u00edveis de Consist\u00eancia Consist\u00eancia forte: leituras sempre retornam a vers\u00e3o mais recente do dado sendo lido. Propaga\u00e7\u00e3o instant\u00e2nea ou locks dos dados sendo manipulados enquanto a propaga\u00e7\u00e3o acontece. Consist\u00eancia fraca: leituras retornam algum dado escrito anteriormente. Qualquer coisa vale Consist\u00eancia eventual: se n\u00e3o houver novas escritas, a partir de algum momento as leituras retornam a vers\u00e3o mais recente do dado sendo lido. Propaga\u00e7\u00e3o acontece no segundo plano A expectativa, ou melhor, a forma como o banco de dados age dada uma intera\u00e7\u00e3o com o cliente, ou clientes, \u00e9 o que denominamos um modelo de consist\u00eancia . Em particular, a expectativa descrita acima \u00e9 denominada linearabilidade , tamb\u00e9m conhecida como consist\u00eancia forte . Com o advento do NOSQL, mais e mais desenvolvedores buscam modelos alternativos, por exemplo, consist\u00eancia eventual , em que h\u00e1 a garantia de que atualiza\u00e7\u00f5es estar\u00e3o dispon\u00edveis a partir de algum momento para a leitura, mas n\u00e3o h\u00e1 uma defini\u00e7\u00e3o clara de quando isso ocorrer\u00e1. 1 Enquanto consist\u00eancia eventual traz melhoras de desempenho, trabalhar com este modelo implica em muito mais complexidade no desenvolvimento dos sistemas que usam o banco. Um terceiro modelo geral de consist\u00eancia seria a consist\u00eancia fraca , em que a \u00fanica garantia \u00e9 de que o valor retornado nas leituras foi escrito em algum momento. Na verdade, podemos pensar nos modelos de consist\u00eancia como um espectro com forte e fraca nos extremos e diversos modelos, incluindo eventual , no meio. Diferentes bancos de dados oferecem diferentes modelos, com nomes parecidos ou at\u00e9 iguais e \u00e9 preciso conhecer o que cada sistema est\u00e1 entregando para poder utiliz\u00e1-lo da forma correta. Al\u00e9m disso, os modelos podem ser divididos em Centrados nos Dados e Centrados nos Clientes , sendo que no primeiro o modelo \u00e9 definido em termos das garantias de consist\u00eancia dos dados e, no segundo, em termos das garantias sobre o que os clientes v\u00eaem. 2 Modelos Centrados nos Dados Modelos de consist\u00eancia Propaga\u00e7\u00e3o por ordena\u00e7\u00e3o de opera\u00e7\u00f5es Linearabilidade: ordena\u00e7\u00e3o total que segue a linha do tempo. Sequencial: ordena\u00e7\u00e3o total Causal: ordena\u00e7\u00e3o causal FIFO: ordena\u00e7\u00e3o FIFO Propaga\u00e7\u00e3o quando necess\u00e1rio Consist\u00eancia fraca geral Consist\u00eancia de entrada Nota\u00e7\u00e3o A leitura de x em (a) retorna a A primeira leitura de x em (b) retorna Nil A segunda leitura de x em (b) retorna a Linearabilidade Qualquer leitura de um objeto \\(X\\) retorna o valor gravado em \\(X\\) pela opera\u00e7\u00e3o de escrita mais recente em \\(X\\) . O que quer dizer \"mais recente\" em um sistema distribu\u00eddo ass\u00edncrono? Todas as opera\u00e7\u00f5es de escrita s\u00e3o instantaneamente vis\u00edveis a todos os processos tempo global \u00e9 respeitado. Comportamento observado em um sistema sem conflitos ou centralizado Em qual(is) cen\u00e1rio(s) temos consist\u00eancia estrita? Consist\u00eancia Sequencial O resultado de qualquer execu\u00e7\u00e3o \u00e9 equivalente a alguma execu\u00e7\u00e3o sequencial das opera\u00e7\u00f5es dos processos e as opera\u00e7\u00f5es da cada processo aparecem nesta execu\u00e7\u00e3o sequencial na ordem especificada por seu programa. P2, P3, P4, P1, P4, P3 P1 ou P2, qual veio primeiro? Consist\u00eancia Causal Escritas com potencial rela\u00e7\u00e3o causal s\u00e3o vistas por todos os processos na mesma ordem. Escritas concorrentes (n\u00e3o causalmente relacionadas) podem se vistas em ordens diferentes por processos diferentes. W(x)b depende de R(x)a que depende de W(x)a W(x)c e W(x)b s\u00e3o concorrentes. W(x)b depende de R(x)a que depende de W(x)a. W(x)a deve ser ordenado com W(x)b. P3 n\u00e3o pode ter lido b e depois a. Consist\u00eancia FIFO Escritas de um processo s\u00e3o vistas por todos os outros processos na ordem em que foram feitas. Escritas de diferentes processos podem ser vistas em ordens diferentes. Consist\u00eancia de Entrada Grupos de Opera\u00e7\u00f5es Efeitos de opera\u00e7\u00f5es individuais em um grupo n\u00e3o s\u00e3o vis\u00edveis. Vari\u00e1veis de sincroniza\u00e7\u00e3o Acesso \u00e0s vari\u00e1veis de sincroniza\u00e7\u00e3o da datastore \u00e9 sequencialmente consistente. Acesso \u00e0 vari\u00e1vel de sincroniza\u00e7\u00e3o n\u00e3o \u00e9 permitido at\u00e9 que todas as escritas das anteriores tenham sido executadas em todos os lugares. Acesso aos dados n\u00e3o \u00e9 permitido at\u00e9 que todas as vari\u00e1veis de sincroniza\u00e7\u00e3o tenham sido liberadas. Transa\u00e7\u00f5es tornam o trancamento/destrancamento de vari\u00e1veis transparente. Vari\u00e1veis de sincroniza\u00e7\u00e3o Locks Materializando vari\u00e1veis de sincroniza\u00e7\u00e3o na forma de locks Lock de leitura s\u00f3 retorna quando todas as mudan\u00e7as guardadas por aquele lock tiverem sido executadas no processo. Lock de escrita s\u00f3 retorna quando nenhum outro processo tiver um lock, de leitura ou escrita. Para ler uma vari\u00e1vel, processo deve primeiro contactar o dono atual do lock cercando a vari\u00e1vel, para pegar as mais recentes atualiza\u00e7\u00f5es. Modelos Centrados nos Clientes Ideia b\u00e1sica Evitar sincroniza\u00e7\u00e3o global focando-se no que os clientes v\u00eaem do sistema. Se para os clientes parecer consistente, tudo bem. Consist\u00eancia Eventual Se nenhuma escrita ocorrer em per\u00edodo consider\u00e1vel de tempo, os clientes gradualmente se sincronizar\u00e3o e ficar\u00e3o consistentes. Se clientes sempre acessarem as mesmas r\u00e9plicas, ter\u00e3o impress\u00e3o de consist\u00eancia. Garantias s\u00e3o do ponto de vista de um cliente. Leituras monot\u00f4nicas Escrita monot\u00f4nicas Leia suas escritas Escritas seguem leituras. Modelo de Sistema Cliente pode se mover antes de sua \u00faltima opera\u00e7\u00e3o ter replicado do servidor onde estava para o novo servidor. Leituras Monot\u00f4nicas Garantia Se um processo l\u00ea o valor de um item \\(x\\) , qualquer leitura sucessiva de \\(x\\) retornar\u00e1 o mesmo valor ou um mais recente. Toda vez que se conecta a um servidor de email, seu cliente l\u00ea novas mensagens, caso haja. O cliente nunca esquece uma mensagem, mesmo que ainda n\u00e3o esteja no servidor conectado por \u00faltimo. WS( \\(x_i\\) ) -- opera\u00e7\u00f5es de escrita ( write set ) que levaram a vari\u00e1vel \\(x\\) a ter o valor \\(x_i\\) . WS( \\(x_i;x_j\\) ) -- opera\u00e7\u00f5es de escrita relativas a \\(x_j\\) incluem opera\u00e7\u00f5es de escrita relativas a \\(x_i\\) Escritas Monot\u00f4nicas Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o esta opera\u00e7\u00e3o deve terminar antes que qualquer escrita sucessiva em \\(x\\) possa ser executada pelo mesmo processo. Em um sistema de arquivos na rede, a escrita do conte\u00fado de um arquivo, em certa posi\u00e7\u00e3o, s\u00f3 pode ser feita se escritas anteriores j\u00e1 est\u00e3o registradas no arquivo, independentemente de o cliente contactar novo servidor de arquivos. Leia suas Escritas Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o leituras sucessivas no mesmo item pelo mesmo processo devem refletir tal escrita. Atualizar c\u00f3digo fonte de uma p\u00e1gina e exigir que o navegador carrega a nova vers\u00e3o. Escritas seguem Leituras Garantia: Se um processo l\u00ea um item \\(x\\) , ent\u00e3o escritas sucessivas no mesmo item s\u00f3 podem ser completadas se o mesmo reflete o valor lido anteriormente. S\u00f3 \u00e9 permitido enviar uma resposta a uma mensagem se a mensagem em si \u00e9 vista, independentemente do cliente ter se movimentado. Gerenciamento de R\u00e9plicas Posicionamento Onde colocar r\u00e9plicas para conseguir melhor escalabilidade do sistema? Menor custo de comunica\u00e7\u00e3o? Objetos (c\u00f3digo/dados) Permanente Sob demanda do servidor -- por exemplo em uma CDN Sob demanda do cliente -- por exemplo um cache. Sob demanda do Servidor \\(Q\\) conta acessos ao arquivo \\(F\\) Agrega acessos por poss\u00edvel r\u00e9plica mais pr\u00f3xima ( \\(P\\) ) N\u00famero de acessos acima de limiar \\(R\\) , replica para \\(P\\) N\u00famero de acessos abaixo de \\(D\\) , apaga de \\(P\\) \\(D < R\\) Se n\u00e3o \u00e9 alto o suficiente para replicar nem baixo o suficiente para ignorar (entre \\(D\\) e \\(R\\) ), considera migrar. Propaga\u00e7\u00e3o de Atualiza\u00e7\u00f5es R\u00e9plicas precisam ser atualizadas. Propagar dados -- n\u00e3o reexecuta opera\u00e7\u00f5es. Propagar opera\u00e7\u00f5es -- n\u00e3o copia todos os dados modificados. Propagar notifica\u00e7\u00f5es -- r\u00e9plica precisa solicitar atualiza\u00e7\u00e3o. Usado em caches. Melhor op\u00e7\u00e3o depende do custo das opera\u00e7\u00f5es, dados manipulados, e taxa de leitura/escrita dos dados. Propagar dados raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o caras Propagar opera\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o baratas Propagar notifica\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 pequena pouco uso da rede Proativo/Push ou Reativo/Pull Proativo Mant\u00e9m r\u00e9plicas consistentes Desnecess\u00e1rio se leitura \\(<<\\) escrita. Reativo R\u00e9plicas s\u00f3 se tornam consistentes quando necess\u00e1rio. Lento se leitura \\(>>\\) escrita Qual \u00e9 melhor? H\u00edbrido: Lease R\u00e9plica se registra para receber atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es por um per\u00edodo. Estado sobre r\u00e9plicas \u00e9 mantido enquanto poss\u00edvel, pelo per\u00edodo contratado. Em caso de sobrecarga, deixa de mandar atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es. Em caso de lease antigo n\u00e3o renovado, deixa de mandar atualiza\u00e7\u00f5es/notifica\u00e7\u00f5es. Em caso de renova\u00e7\u00f5es frequentes, aumenta o per\u00edodo do lease. Recupera\u00e7\u00e3o & Checkpoint Assumindo que o modelo de consist\u00eancia implementado \u00e9 satisfat\u00f3rio, temos que garantir que este modelo n\u00e3o ser\u00e1 quebrado na presen\u00e7a de falhas. Isto \u00e9, suponha que uma s\u00e9rie de erros aconteceram no sistema, e que n\u00e3o \u00e9 poss\u00edvel continuar o processamento em algum ou todos os m\u00f3dulos do sistema. Neste cen\u00e1rio, o sistema precisa agir para ou avan\u00e7ar para um novo estado, livre de erros, ou retroceder a um estado anterior, correto. Voltar a um estado correto parece ser a solu\u00e7\u00e3o mais f\u00e1cil, mas pare isto \u00e9 preciso garantir a informa\u00e7\u00e3o sobre estados anteriores seja recuper\u00e1vel. Log Recuper\u00e1vel Replica\u00e7\u00e3o Como garantir que o log poder\u00e1 ser lido para recuperar o processo? Dois discos iguais? Dados diferentes, mas ambos bons? Um bom outro estragado? Ambos estragados? Blocos de paridade Erasure Coding Blocos de paridade C\u00e1lculo da paridade Recupera\u00e7\u00e3o de blocos perdidos Reed Solomon Estado global consistente Um estado global, o conjunto com um estado local de cada processo no sistema e tamb\u00e9m s\u00e3o conhecidos como ou snapshots . Para serem \u00fateis, snapshots precisam formar Estado Globais Consistentes , que s\u00e3o estados globais tal que toda mensagem recebida no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do processo remetente. O mais recente estado global consistente forma uma linha de recupera\u00e7\u00e3o . Linhas de Recupera\u00e7\u00e3o podem ser usados para, n\u00e3o surpreendentemente, recupera\u00e7\u00e3o do sistema, mas tamb\u00e9m para coleta de lixo (remover objetos n\u00e3o referenciados em nenhum outro processo), detec\u00e7\u00e3o de deadlocks e depura\u00e7\u00e3o (pausar o sistema). Se o sistema prov\u00ea comunica\u00e7\u00e3o confi\u00e1vel, ent\u00e3o toda mensagem enviada no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do destinat\u00e1rio, ou o estado global precisa capturar o estado dos canais de comunica\u00e7\u00e3o. Checkpointing independente Cada processo faz o checkpoint local independentemente, incorrendo no risco de um rollback em cascata. Seja \\(C_i^m\\) o \\(m\\) -\u00e9simo checkpoint do processo \\(p_i\\) . Seja \\(I_i^m\\) o intervalo entre \\(C_i^{m-1}\\) e \\(C_i^m\\) . Quando o processo \\(p_i\\) envia a mensagem no intervalo \\(I_i^m\\) , envia \\((i,m)\\) em piggyback Quando o processo \\(p_j\\) recebe a mensagem no intervalo \\(I_j^n\\) , grava a depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) A depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) \u00e9 salva junto com o checkpoint \\(C_j^n\\) Se o processo \\(p_j\\) \u00e9 revertido para o estado \\(C_j^n\\) , ent\u00e3o o \\(p_i\\) n\u00e3o pode reverter para nenhum estado anterior a \\(C_i^m\\) , ou n\u00e3o teria enviado as mensagens recebidas por \\(p_j\\) 4 inclusas em \\(C_j^n\\) . ou Se o processo \\(p_i\\) \u00e9 revertido para o estado \\(C_i^{m-1}\\) , ent\u00e3o o \\(p_j\\) tem que ser revertido pelo menos at\u00e9 \\(C_j^{n-1}\\) , ou incluiria mensagens ainda n\u00e3o enviadas por \\(p_i\\) . Como implementar a recupera\u00e7\u00e3o? # Caso patol\u00f3gico \\(p_i\\) e \\(p_j\\) no estado inicial ( \\(C_i^0, C_j^0\\) ) \\(p_i\\) manda mensagens para \\(p_j\\) ( \\(C_i^1 \\rightarrow C_j^1\\) ) \\(C_j^1\\) \\(p_j\\) manda mensagens para \\(p_i\\) \\(C_j^2 \\rightarrow C_i^1\\) \\(C_i^1\\) \\(p_i\\) manda mensagens para \\(p_j\\) \\(C_i^2 \\rightarrow C_j^2\\) \\(C_j^2\\) \\(p_j\\) manda mensagens para \\(p_i\\) \\(C_j^3 \\rightarrow C_i^2\\) \\(C_i^2\\) ... Se estados locais s\u00e3o capturados na \"hora errada\", a linha de recupera\u00e7\u00e3o pode ser o estado inicial, fazendo um rollback em cascata* Checkpointing coordenado Processos se coordenam por troca de mensagem para executar checkpointing \"simultaneamente\". Bloqueio em duas fases Um coordenador faz multicast da mensagem \"checkpoint-request\" Quando um participante recebe \"checkpoint-request\" faz um checkpoint local para de mandar mensagens da aplica\u00e7\u00e3o responde com \"checkpoint-taken\" Quando \"checkpoint-taken\" recebido de todos os participantes, multicast \"checkpoint-done\" Quando receber \"checkpoint-done\", retoma computa\u00e7\u00e3o normal Por qu\u00ea funciona? Impede forma\u00e7\u00e3o de depend\u00eancias circulares. Todos os processos precisam participar? Somente os que dependem da recupera\u00e7\u00e3o do coordenador. Pontos negativos? Se o coordenador falha, outros processos ficam bloqueados? Timeout! Como eleger outro coordenador? E se dois aparecerem juntos? Pode ser resolvido com um protocolo de elei\u00e7\u00e3o como o do RAFT. N\u00e3o \u00e9 garantido, mas aumenta as chances de sucesso. Chandy-Lamport N\u00e3o interfere na aplica\u00e7\u00e3o Cada processo grava snapshot independentemente Observador (iniciador do snapshot) Salva o pr\u00f3prio estado Envia uma mensagem \"snapshot\" aos outros processos em cada canal de sa\u00edda Grava as mensagens chegando em cada canal at\u00e9 que receba uma mensagem \"snapshot\" naquele canal. Um processo \\(p\\) que receba \"snapshot\" de um processo \\(q\\) grava estado local \\(S_p\\) grava estado do canal \\(C_{q,p} =\\emptyset\\) Envia uma mensagem \"snapshot\" aos outros processos em cada canal de sa\u00edda Grava as mensagens chegando em cada canal at\u00e9 que receba uma mensagem \"snapshot\" naquele canal (excluindo \\(C_{q,p}\\) ) Protocolo termina para o processo \\(p\\) quando tiver recebido marcador \"snapshot\" em cada um de seus canais. O estado global consiste dos snapshots + estado em cada um dos canais. Exige canais FIFO Message Logging Em vez de checkpoints frequentes, crie um log da comunica\u00e7\u00e3o e o re-execute a partir do \u00faltimo checkpoint. Ideia b\u00e1sica: A computa\u00e7\u00e3o \u00e9 determinada pela troca de mensagens (eventos n\u00e3o determin\u00edsticos). Ao se enviar a mesma mensagem a partir de um certo estado, a computa\u00e7\u00e3o desencadeada \u00e9 sempre a mesma. Realista este modelo? H\u00e1 outros eventos n\u00e3o determin\u00edsticos no sistema? \\(Hdr(m)\\) Cabe\u00e7alho da mensagem \\(m\\) contendo fonte, destino, n\u00famero de sequ\u00eancia e n\u00famero de entrega. O cabe\u00e7alho cont\u00e9m a informa\u00e7\u00e3o necess\u00e1ria para reenviar e re-receber a mensagem na ordem certa (dados devem ser reproduzidos para aplica\u00e7\u00e3o). A mensagem \\(m\\) \u00e9 est\u00e1vel se \\(Hdr(m)\\) estiver em mem\u00f3ria est\u00e1vel. \\(Dep(m)\\) : o conjunto de processos a quem \\(m\\) ou mensagens que dependem de \\(m\\) foram entregues. \\(Copy(m)\\) : o conjunto de processos que tem uma c\u00f3pia de \\(Hdr(m)\\) em mem\u00f3ria vol\u00e1til. Se \\(C\\) \u00e9 um conjunto de processos falhos, ent\u00e3o \\(Q\\not\\in C\\) \u00e9 um \u00f3rf\u00e3o se existe uma mensagem \\(m\\) tal que \\(Q \\in Dep(m)\\) e \\(Copy(m)\\subseteq C\\) Se os processos em \\(C\\) forem reiniciados, ent\u00e3o a computa\u00e7\u00e3o seguir\u00e1 um caminho possivelmente distinto do que levou \\(Q\\) a receber \\(m\\) ou um mensagem causalmente dependente de \\(m\\) . Para cada mensagem \\(m\\) n\u00e3o est\u00e1vel, h\u00e1 no m\u00e1ximo um processo dependente em \\(m\\) ( \\(Dep(m) \\leq 1\\) ) Uma mensagem n\u00e3o est\u00e1vel, no protocolo pessimista, deve ser estabilizada antes do envio da pr\u00f3xima mensagem. Toda mensagem \u00e9 precedida por uma escrita em disco. Para cada mensagem \\(m\\) n\u00e3o est\u00e1vel, ent\u00e3o devemos garantir que se \\(Copy(m) \\subseteq C\\) , ent\u00e3o eventually \\(Dep(m) \\subseteq C\\) , onde \\(C\\) \u00e9 o conjunto de processos que falharam. Para garantir que \\(Dep(m) \\subseteq C\\) , fazemos um rollback de cada \u00f3rf\u00e3o \\(Q\\) at\u00e9 que \\(Q \\not\\in Dep(m)\\) Isto \u00e9, for\u00e7amos \\(Q\\) a ser recuperado mesmo que n\u00e3o tenha falhado. Refer\u00eancias https://blog.yugabyte.com/a-primer-on-acid-transactions/ https://jepsen.io/consistency https://fauna.com/blog/demystifying-database-systems-part-4-isolation-levels-vs-consistency-levels https://aphyr.com/posts/313-strong-consistency-models refs/encyclopedia18.pdf Chandy e Lamport Enquanto no Portugu\u00eas Eventual quer dizer possivelmente , no ingl\u00eas quer dizer em algum momento n\u00e3o determinado, mas vindouro. \u21a9 Caso esteja se perguntando se este modelo e estudo tem alguma serventia para voc\u00ea, afinal nos bancos de dados com que trabalhou ou trabalha as opera\u00e7\u00f5es s\u00e3o agrupadas em transa\u00e7\u00f5es e n\u00e3o executadas individualmente e as transa\u00e7\u00f5es garantem ACID, lhe asseguro que sim e que falaremos em transa\u00e7\u00f5es mais adiante. \u21a9","title":"Consist\u00eancia"},{"location":"consistency/#modelos-de-consistencia","text":"Embora n\u00e3o seja necess\u00e1rio, para falarmos sobre modelos de consist\u00eancia, falaremos sobre bancos de dados pois \u00e9 algo pr\u00f3ximo da realidade da maioria dos estudantes e torna mais f\u00e1cil o entendimento do t\u00f3pico. Um banco de dados pode ser pensado, em sua forma mais simplista, como um conjunto de vari\u00e1veis nas quais valores s\u00e3o armazenados. Assim, clientes do banco de dados essencialmente executam comandos como \\(X\\) recebe 'Jo\u00e3o' e \\(Y\\) recebe 'joao arroba hmail.com' . Obviamente que \\(X\\) e \\(Y\\) n\u00e3o precisam ser declarados antes da primeira escrita, assim como chaves prim\u00e1rias n\u00e3o s\u00e3o declaradas at\u00e9 que sejam usadas, e que o valor associado a uma vari\u00e1vel pode ter v\u00e1rias partes, como \"{'Endere\u00e7o':'Av 1, n\u00famero 2', 'Profiss\u00e3o':'Computeiro'} e cada parte um tipo. Veja bem, eu disse uma simplifica\u00e7\u00e3o, mas n\u00e3o quer dizer que nao seja uma simplifica\u00e7\u00e3o poderosa. Quando um processo se comunica com um banco de dados, ele o faz com certas expectativas quanto ao funcionamento deste banco. Por exemplo, ao escrever um dados no banco, independentemente de como o banco \u00e9 implementado, o cliente geralmente espera que as escritas aconte\u00e7am na ordem em que as disparou e que, ao ler uma vari\u00e1vel, lhe seja retornado o \"\u00faltimo\" valor escrito na mesma. Esta expectativa \u00e9 independente do banco de dados ser implementado de forma distribu\u00edda ou n\u00e3o. Isto \u00e9, mesmo que os dados armazenados no banco sejam particionados ou replicados entre v\u00e1rios n\u00f3s, o cliente espera que o banco tenha comportamento consistente com o de um banco n\u00e3o distribu\u00eddo e retorne ou aquilo que escreveu ou algo mas recente. N\u00edveis de Consist\u00eancia Consist\u00eancia forte: leituras sempre retornam a vers\u00e3o mais recente do dado sendo lido. Propaga\u00e7\u00e3o instant\u00e2nea ou locks dos dados sendo manipulados enquanto a propaga\u00e7\u00e3o acontece. Consist\u00eancia fraca: leituras retornam algum dado escrito anteriormente. Qualquer coisa vale Consist\u00eancia eventual: se n\u00e3o houver novas escritas, a partir de algum momento as leituras retornam a vers\u00e3o mais recente do dado sendo lido. Propaga\u00e7\u00e3o acontece no segundo plano A expectativa, ou melhor, a forma como o banco de dados age dada uma intera\u00e7\u00e3o com o cliente, ou clientes, \u00e9 o que denominamos um modelo de consist\u00eancia . Em particular, a expectativa descrita acima \u00e9 denominada linearabilidade , tamb\u00e9m conhecida como consist\u00eancia forte . Com o advento do NOSQL, mais e mais desenvolvedores buscam modelos alternativos, por exemplo, consist\u00eancia eventual , em que h\u00e1 a garantia de que atualiza\u00e7\u00f5es estar\u00e3o dispon\u00edveis a partir de algum momento para a leitura, mas n\u00e3o h\u00e1 uma defini\u00e7\u00e3o clara de quando isso ocorrer\u00e1. 1 Enquanto consist\u00eancia eventual traz melhoras de desempenho, trabalhar com este modelo implica em muito mais complexidade no desenvolvimento dos sistemas que usam o banco. Um terceiro modelo geral de consist\u00eancia seria a consist\u00eancia fraca , em que a \u00fanica garantia \u00e9 de que o valor retornado nas leituras foi escrito em algum momento. Na verdade, podemos pensar nos modelos de consist\u00eancia como um espectro com forte e fraca nos extremos e diversos modelos, incluindo eventual , no meio. Diferentes bancos de dados oferecem diferentes modelos, com nomes parecidos ou at\u00e9 iguais e \u00e9 preciso conhecer o que cada sistema est\u00e1 entregando para poder utiliz\u00e1-lo da forma correta. Al\u00e9m disso, os modelos podem ser divididos em Centrados nos Dados e Centrados nos Clientes , sendo que no primeiro o modelo \u00e9 definido em termos das garantias de consist\u00eancia dos dados e, no segundo, em termos das garantias sobre o que os clientes v\u00eaem. 2","title":"Modelos de Consist\u00eancia"},{"location":"consistency/#modelos-centrados-nos-dados","text":"Modelos de consist\u00eancia Propaga\u00e7\u00e3o por ordena\u00e7\u00e3o de opera\u00e7\u00f5es Linearabilidade: ordena\u00e7\u00e3o total que segue a linha do tempo. Sequencial: ordena\u00e7\u00e3o total Causal: ordena\u00e7\u00e3o causal FIFO: ordena\u00e7\u00e3o FIFO Propaga\u00e7\u00e3o quando necess\u00e1rio Consist\u00eancia fraca geral Consist\u00eancia de entrada","title":"Modelos Centrados nos Dados"},{"location":"consistency/#linearabilidade","text":"Qualquer leitura de um objeto \\(X\\) retorna o valor gravado em \\(X\\) pela opera\u00e7\u00e3o de escrita mais recente em \\(X\\) . O que quer dizer \"mais recente\" em um sistema distribu\u00eddo ass\u00edncrono? Todas as opera\u00e7\u00f5es de escrita s\u00e3o instantaneamente vis\u00edveis a todos os processos tempo global \u00e9 respeitado. Comportamento observado em um sistema sem conflitos ou centralizado Em qual(is) cen\u00e1rio(s) temos consist\u00eancia estrita?","title":"Linearabilidade"},{"location":"consistency/#consistencia-sequencial","text":"O resultado de qualquer execu\u00e7\u00e3o \u00e9 equivalente a alguma execu\u00e7\u00e3o sequencial das opera\u00e7\u00f5es dos processos e as opera\u00e7\u00f5es da cada processo aparecem nesta execu\u00e7\u00e3o sequencial na ordem especificada por seu programa. P2, P3, P4, P1, P4, P3 P1 ou P2, qual veio primeiro?","title":"Consist\u00eancia Sequencial"},{"location":"consistency/#consistencia-causal","text":"Escritas com potencial rela\u00e7\u00e3o causal s\u00e3o vistas por todos os processos na mesma ordem. Escritas concorrentes (n\u00e3o causalmente relacionadas) podem se vistas em ordens diferentes por processos diferentes. W(x)b depende de R(x)a que depende de W(x)a W(x)c e W(x)b s\u00e3o concorrentes. W(x)b depende de R(x)a que depende de W(x)a. W(x)a deve ser ordenado com W(x)b. P3 n\u00e3o pode ter lido b e depois a.","title":"Consist\u00eancia Causal"},{"location":"consistency/#consistencia-fifo","text":"Escritas de um processo s\u00e3o vistas por todos os outros processos na ordem em que foram feitas. Escritas de diferentes processos podem ser vistas em ordens diferentes.","title":"Consist\u00eancia FIFO"},{"location":"consistency/#consistencia-de-entrada","text":"","title":"Consist\u00eancia de Entrada"},{"location":"consistency/#modelos-centrados-nos-clientes","text":"Ideia b\u00e1sica Evitar sincroniza\u00e7\u00e3o global focando-se no que os clientes v\u00eaem do sistema. Se para os clientes parecer consistente, tudo bem. Consist\u00eancia Eventual Se nenhuma escrita ocorrer em per\u00edodo consider\u00e1vel de tempo, os clientes gradualmente se sincronizar\u00e3o e ficar\u00e3o consistentes. Se clientes sempre acessarem as mesmas r\u00e9plicas, ter\u00e3o impress\u00e3o de consist\u00eancia. Garantias s\u00e3o do ponto de vista de um cliente. Leituras monot\u00f4nicas Escrita monot\u00f4nicas Leia suas escritas Escritas seguem leituras.","title":"Modelos Centrados nos Clientes"},{"location":"consistency/#modelo-de-sistema","text":"Cliente pode se mover antes de sua \u00faltima opera\u00e7\u00e3o ter replicado do servidor onde estava para o novo servidor.","title":"Modelo de Sistema"},{"location":"consistency/#leituras-monotonicas","text":"Garantia Se um processo l\u00ea o valor de um item \\(x\\) , qualquer leitura sucessiva de \\(x\\) retornar\u00e1 o mesmo valor ou um mais recente. Toda vez que se conecta a um servidor de email, seu cliente l\u00ea novas mensagens, caso haja. O cliente nunca esquece uma mensagem, mesmo que ainda n\u00e3o esteja no servidor conectado por \u00faltimo. WS( \\(x_i\\) ) -- opera\u00e7\u00f5es de escrita ( write set ) que levaram a vari\u00e1vel \\(x\\) a ter o valor \\(x_i\\) . WS( \\(x_i;x_j\\) ) -- opera\u00e7\u00f5es de escrita relativas a \\(x_j\\) incluem opera\u00e7\u00f5es de escrita relativas a \\(x_i\\)","title":"Leituras Monot\u00f4nicas"},{"location":"consistency/#escritas-monotonicas","text":"Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o esta opera\u00e7\u00e3o deve terminar antes que qualquer escrita sucessiva em \\(x\\) possa ser executada pelo mesmo processo. Em um sistema de arquivos na rede, a escrita do conte\u00fado de um arquivo, em certa posi\u00e7\u00e3o, s\u00f3 pode ser feita se escritas anteriores j\u00e1 est\u00e3o registradas no arquivo, independentemente de o cliente contactar novo servidor de arquivos.","title":"Escritas Monot\u00f4nicas"},{"location":"consistency/#leia-suas-escritas","text":"Garantia: Se um processo escreve em item \\(x\\) , ent\u00e3o leituras sucessivas no mesmo item pelo mesmo processo devem refletir tal escrita. Atualizar c\u00f3digo fonte de uma p\u00e1gina e exigir que o navegador carrega a nova vers\u00e3o.","title":"Leia suas Escritas"},{"location":"consistency/#escritas-seguem-leituras","text":"Garantia: Se um processo l\u00ea um item \\(x\\) , ent\u00e3o escritas sucessivas no mesmo item s\u00f3 podem ser completadas se o mesmo reflete o valor lido anteriormente. S\u00f3 \u00e9 permitido enviar uma resposta a uma mensagem se a mensagem em si \u00e9 vista, independentemente do cliente ter se movimentado.","title":"Escritas seguem Leituras"},{"location":"consistency/#gerenciamento-de-replicas","text":"","title":"Gerenciamento de R\u00e9plicas"},{"location":"consistency/#posicionamento","text":"Onde colocar r\u00e9plicas para conseguir melhor escalabilidade do sistema? Menor custo de comunica\u00e7\u00e3o? Objetos (c\u00f3digo/dados) Permanente Sob demanda do servidor -- por exemplo em uma CDN Sob demanda do cliente -- por exemplo um cache.","title":"Posicionamento"},{"location":"consistency/#propagacao-de-atualizacoes","text":"R\u00e9plicas precisam ser atualizadas. Propagar dados -- n\u00e3o reexecuta opera\u00e7\u00f5es. Propagar opera\u00e7\u00f5es -- n\u00e3o copia todos os dados modificados. Propagar notifica\u00e7\u00f5es -- r\u00e9plica precisa solicitar atualiza\u00e7\u00e3o. Usado em caches. Melhor op\u00e7\u00e3o depende do custo das opera\u00e7\u00f5es, dados manipulados, e taxa de leitura/escrita dos dados. Propagar dados raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o caras Propagar opera\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 grande opera\u00e7\u00f5es s\u00e3o baratas Propagar notifica\u00e7\u00f5es raz\u00e3o leitura/escrita \u00e9 pequena pouco uso da rede","title":"Propaga\u00e7\u00e3o de Atualiza\u00e7\u00f5es"},{"location":"consistency/#recuperacao-checkpoint","text":"Assumindo que o modelo de consist\u00eancia implementado \u00e9 satisfat\u00f3rio, temos que garantir que este modelo n\u00e3o ser\u00e1 quebrado na presen\u00e7a de falhas. Isto \u00e9, suponha que uma s\u00e9rie de erros aconteceram no sistema, e que n\u00e3o \u00e9 poss\u00edvel continuar o processamento em algum ou todos os m\u00f3dulos do sistema. Neste cen\u00e1rio, o sistema precisa agir para ou avan\u00e7ar para um novo estado, livre de erros, ou retroceder a um estado anterior, correto. Voltar a um estado correto parece ser a solu\u00e7\u00e3o mais f\u00e1cil, mas pare isto \u00e9 preciso garantir a informa\u00e7\u00e3o sobre estados anteriores seja recuper\u00e1vel.","title":"Recupera\u00e7\u00e3o &amp; Checkpoint"},{"location":"consistency/#log-recuperavel","text":"","title":"Log Recuper\u00e1vel"},{"location":"consistency/#estado-global-consistente","text":"Um estado global, o conjunto com um estado local de cada processo no sistema e tamb\u00e9m s\u00e3o conhecidos como ou snapshots . Para serem \u00fateis, snapshots precisam formar Estado Globais Consistentes , que s\u00e3o estados globais tal que toda mensagem recebida no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do processo remetente. O mais recente estado global consistente forma uma linha de recupera\u00e7\u00e3o . Linhas de Recupera\u00e7\u00e3o podem ser usados para, n\u00e3o surpreendentemente, recupera\u00e7\u00e3o do sistema, mas tamb\u00e9m para coleta de lixo (remover objetos n\u00e3o referenciados em nenhum outro processo), detec\u00e7\u00e3o de deadlocks e depura\u00e7\u00e3o (pausar o sistema). Se o sistema prov\u00ea comunica\u00e7\u00e3o confi\u00e1vel, ent\u00e3o toda mensagem enviada no estado local de um processo tamb\u00e9m precisa fazer parte do estado local do destinat\u00e1rio, ou o estado global precisa capturar o estado dos canais de comunica\u00e7\u00e3o.","title":"Estado global consistente"},{"location":"consistency/#checkpointing-independente","text":"Cada processo faz o checkpoint local independentemente, incorrendo no risco de um rollback em cascata. Seja \\(C_i^m\\) o \\(m\\) -\u00e9simo checkpoint do processo \\(p_i\\) . Seja \\(I_i^m\\) o intervalo entre \\(C_i^{m-1}\\) e \\(C_i^m\\) . Quando o processo \\(p_i\\) envia a mensagem no intervalo \\(I_i^m\\) , envia \\((i,m)\\) em piggyback Quando o processo \\(p_j\\) recebe a mensagem no intervalo \\(I_j^n\\) , grava a depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) A depend\u00eancia \\(I_i^m \\rightarrow I_j^n\\) \u00e9 salva junto com o checkpoint \\(C_j^n\\) Se o processo \\(p_j\\) \u00e9 revertido para o estado \\(C_j^n\\) , ent\u00e3o o \\(p_i\\) n\u00e3o pode reverter para nenhum estado anterior a \\(C_i^m\\) , ou n\u00e3o teria enviado as mensagens recebidas por \\(p_j\\) 4 inclusas em \\(C_j^n\\) . ou Se o processo \\(p_i\\) \u00e9 revertido para o estado \\(C_i^{m-1}\\) , ent\u00e3o o \\(p_j\\) tem que ser revertido pelo menos at\u00e9 \\(C_j^{n-1}\\) , ou incluiria mensagens ainda n\u00e3o enviadas por \\(p_i\\) . Como implementar a recupera\u00e7\u00e3o?","title":"Checkpointing independente"},{"location":"consistency/#checkpointing-coordenado","text":"Processos se coordenam por troca de mensagem para executar checkpointing \"simultaneamente\".","title":"Checkpointing coordenado"},{"location":"consistency/#referencias","text":"https://blog.yugabyte.com/a-primer-on-acid-transactions/ https://jepsen.io/consistency https://fauna.com/blog/demystifying-database-systems-part-4-isolation-levels-vs-consistency-levels https://aphyr.com/posts/313-strong-consistency-models refs/encyclopedia18.pdf Chandy e Lamport Enquanto no Portugu\u00eas Eventual quer dizer possivelmente , no ingl\u00eas quer dizer em algum momento n\u00e3o determinado, mas vindouro. \u21a9 Caso esteja se perguntando se este modelo e estudo tem alguma serventia para voc\u00ea, afinal nos bancos de dados com que trabalhou ou trabalha as opera\u00e7\u00f5es s\u00e3o agrupadas em transa\u00e7\u00f5es e n\u00e3o executadas individualmente e as transa\u00e7\u00f5es garantem ACID, lhe asseguro que sim e que falaremos em transa\u00e7\u00f5es mais adiante. \u21a9","title":"Refer\u00eancias"},{"location":"disdb/","text":"Voltemo-nos agora aos bancos de dados mais tradicionais, isto \u00e9, bancos de dados relacionais. Destaco que quando falamos em bancos de dados relacionais, geralmente pensamos em bancos de dados transacionais, mas o que s\u00e3o transa\u00e7\u00f5es? Transa\u00e7\u00f5es No banco de dados vistos no cap\u00edtulo anterior, opera\u00e7\u00f5es s\u00e3o enviadas individualmente para as r\u00e9plicas do banco. J\u00e1 no modelo transacional, normalmente pensamos em conjunto de opera\u00e7\u00f5es em vez de opera\u00e7\u00f5es individuais; estes conjuntos de opera\u00e7\u00f5es s\u00e3o as transa\u00e7\u00f5es . Considere um sistema banc\u00e1rio que mant\u00e9m contas com saldos inteiros. Seguindo a nota\u00e7\u00e3o apresentada anteriormente, \\(R(C)10\\) \u00e9 um opera\u00e7\u00e3o de leitura da conta \\(C\\) que retorna o valor 10 e \\(W(C)20\\) \u00e9 a opera\u00e7\u00e3o de atualiza\u00e7\u00e3o do saldo de \\(C\\) para 20. Vamos estender a nota\u00e7\u00e3o para que \\(a = R(C)\\) armazene o valor lido de \\(C\\) em \\(a\\) . Seja \\(T\\) uma transa\u00e7\u00e3o que incrementa o valor de uma conta em \\(1\\) ; ela pode ser especificada como \\(a = R(C); W(C)a+1\\) Imagine duas inst\u00e2ncias desta transa\u00e7\u00e3o executando serialmente. Ao final da execu\u00e7\u00e3o o saldo foi acrescido de 2, como esperado. Se em vez disso as duas inst\u00e2ncias executassem concorrentemente, ter\u00edamos um resultado diverso, mesmo que o esperado fosse o mesmo resultado. Ao final da execu\u00e7\u00e3o, apesar do valor ter sido modificado duas vezes, o saldo teria sido acrescido de 1. Esta diferen\u00e7a entre o esperado e o real est\u00e1 enraizada nas garantias dadas por bancos de dados tradicionais, conhecidas como ACID, acr\u00f4nimo para Atomicidade, Consist\u00eancia, Isolamento e Durabilidade . ACID Atomicidade Consist\u00eancia Isolamento Durabilidade A atomicidade diz respeito ao tratamento das opera\u00e7\u00f5es como um conjunto indivis\u00edvel, isto \u00e9, ou todas as opera\u00e7\u00f5es no conjunto s\u00e3o executadas ou nenhuma \u00e9. A propriedade de consist\u00eancia dita que todas as transi\u00e7\u00f5es do banco de dados devem respeitar restri\u00e7\u00f5es nos seus dados , por exemplo, os tipos de cada entrada no banco e integridade referencial. J\u00e1 a propriedade de isolamento se refere a como e quando os efeitos de uma transa\u00e7\u00e3o passam a ser vis\u00edveis para outras transa\u00e7\u00f5es, possivelmente concorrentes. H\u00e1 diversos n\u00edveis de isolamento, sendo menos restritivos, como consist\u00eancia eventual 1 , ou mais restritivo, como seriabilidade estrita . Finalmente, durabilidade \u00e9 a garantia de que os resultados de uma transa\u00e7\u00e3o s\u00e3o permanentemente gravados no sistema, a despeito de falhas. Caso estas propriedades n\u00e3o sejam garantidas na execu\u00e7\u00e3o de transa\u00e7\u00f5es, problemas podem acontecer, como no exemplo anterior. Por exemplo, seja uma transa\u00e7\u00e3o que move 10% do saldo da segunda conta da primeira para a segunda, isto \u00e9, se \\(a\\) tem saldo inicial 50 e \\(b\\) tem saldo inicial 100, a transa\u00e7\u00e3o transfere 10 de \\(a\\) para \\(b\\) . T1(a,b) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA - (sB*0.1)\\) E seja uma transa\u00e7\u00e3o que calcule o somat\u00f3rio dos saldos em todas as contas especificadas, isto \u00e9, se aplicada \u00e0s contas \\(a\\) e \\(b\\) do exemplo anterior, retorna 150 como resultado. T2([a,b]) \\(sA = R(a)\\) \\(sB = R(b)\\) \\(sT = sA + sB\\) Agora, seja uma execu\u00e7\u00e3o concorrente destas transa\u00e7\u00f5es da seguinte forma (tempo passa para baixo) e que o saldo inicial de \\(a\\) e \\(b\\) s\u00e3o ambos 10. T1(a,b) T2([a,b]) \\(sB = R(b)\\) \\(sA = R(a)\\) \\(W(b)sB*1.1\\) \\(sB = R(b)\\) \\(sA = R(a)\\) \\(W(a)sA - (sB*0.1)\\) \\(sT = sA+sB\\) Qual o valor final calculado? Execu\u00e7\u00e3o Se \\(a\\) inicialmente tem 50 e \\(b\\) 100, ent\u00e3o a seguinte execu\u00e7\u00e3o ocorre: T1(a,b) T2([a,b]) \\(sB = R(b)\\) = 100 \\(sA = R(a) = 50\\) \\(W(b)sB*1.1\\) = 110 \\(sB = R(b) = 110\\) \\(sA = R(a) = 50\\) \\(W(a)sA - (sB*0.1) = 40\\) \\(sT = sA+sB = 160\\) O problema aqui \u00e9 que dados sendo modificados, isto \u00e9, n\u00e3o finais, \"vazaram\" de T1 para T2, um fen\u00f4meno conhecido como dirty read . Isso ocorreu porqu\u00ea o n\u00edvel de isolamento provido foi nenhum. Supondo uma execu\u00e7\u00e3o de duas inst\u00e2ncias de T1, podemos observar outro problema, que pode deixar o BD em estado inv\u00e1lido. T1(a,b) T1(a,b) \\(sB = R(b)\\) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(W(b) sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA-(sB*0.1)\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Execu\u00e7\u00e3o Se \\(a\\) inicialmente tem 50 e \\(b\\) 100, ent\u00e3o a seguinte execu\u00e7\u00e3o ocorre: T1(a,b) T1(a,b) \\(sB = R(b) = 100\\) \\(sB = R(b) = 100\\) \\(W(b)sB*1.1 = 110\\) \\(W(b) sB*1.1\\) = 110 \\(sA = R(a) = 50\\) \\(W(a)sA-(sB*0.1) = 40\\) \\(sA = R(a) = 40\\) \\(W(a)sA-sB*0.1 = 30\\) Observe que \\(sB*0.1\\) foi perdido, o que \u00e9 conhecido como lost update , agora porqu\u00ea faltou isolamento. Qual a solu\u00e7\u00e3o? No primeiro exemplo deste cap\u00edtulo, uma execu\u00e7\u00e3o serial das opera\u00e7\u00f5es n\u00e3o causou problema, enquanto a concorrente sim. Testemos novamente uma execu\u00e7\u00e3o em que as transa\u00e7\u00f5es n\u00e3o se sobrep\u00f5em. T1(a,b) T1(a,b) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA-(sB*0.1)\\) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Esta solu\u00e7\u00e3o funciona, mas, na pr\u00e1tica, queremos o m\u00e1ximo de concorr\u00eancia para garantir o melhor desempenho . O que queremos ent\u00e3o \u00e9 uma execu\u00e7\u00e3o das transa\u00e7\u00f5es semelhante \u00e0 serial, para garantir a corretude dos resultados, mas com o desempenho garantido pela execu\u00e7\u00e3o concorrente. Isto \u00e9, n\u00e3o queremos uma execu\u00e7\u00e3o serial , queremos uma execu\u00e7\u00e3o equivalente a uma execu\u00e7\u00e3o serial . Equival\u00eancia Serial De forma geral, dizemos que duas execu\u00e7\u00f5es de transa\u00e7\u00f5es s\u00e3o equivalentes se s\u00e3o execu\u00e7\u00f5es das mesmas transa\u00e7\u00f5es (mesmas opera\u00e7\u00f5es) quaisquer duas opera\u00e7\u00f5es conflitantes s\u00e3o executadas na mesma ordem nas duas execu\u00e7\u00f5es. Duas opera\u00e7\u00f5es s\u00e3o conflitantes se pertencem a transa\u00e7\u00f5es diferentes, operam no mesmo dado, e pelo menos uma delas \u00e9 escrita. Uma execu\u00e7\u00e3o tem equival\u00eancia serial se \u00e9 equivalente a alguma execu\u00e7\u00e3o serial das transa\u00e7\u00f5es. Ora, se uma execu\u00e7\u00e3o \u00e9 equivalente a uma execu\u00e7\u00e3o serial e a execu\u00e7\u00e3o serial n\u00e3o tem problemas relacionados a isolamento, pois n\u00e3o h\u00e1 transa\u00e7\u00e3o concorrente que acesse dados incompletos, ent\u00e3o a execu\u00e7\u00e3o serial garante resultados corretos. Assim, para obter tanto desempenho advindo da concorr\u00eancia quanto corretude advinda da serializa\u00e7\u00e3o, escalone as opera\u00e7\u00f5es de forma a garantir equival\u00eancia serial. Mas como obter equival\u00eancia serial? N\u00e3o seria vi\u00e1vel executar as opera\u00e7\u00f5es e demonstrar post facto que a execu\u00e7\u00e3o \u00e9 correta. Em vez disso, precisamos garantir por constru\u00e7\u00e3o a equival\u00eancia serial, o que \u00e9 bem mas simples, principalmente se considerarmos a seguinte restri\u00e7\u00e3o a execu\u00e7\u00e3o de duas transa\u00e7\u00f5es tem Equival\u00eancia Serial se todos os pares de opera\u00e7\u00f5es conflitantes entre as transa\u00e7\u00f5es s\u00e3o executados na mesma ordem. Revisitemos o exemplo do lost update . Quais opera\u00e7\u00f5es conflitam nesta execu\u00e7\u00e3o? Conflitos Conflitos: 1x3: \\(\\rightarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\) Opera\u00e7\u00e3o T1(a,b) T1(c,b) 1 \\(sB = R(b)\\) 2 \\(sB = R(b)\\) 3 \\(W(b)sB*1.1\\) 4 \\(W(b)sB*1.1\\) \\(sC = R(c)\\) \\(W(c)sC-sB*0.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Claramente, os pares (1,3), (2,4) e (3,4) s\u00e3o conflitantes. Para se obter equival\u00eancia serial ent\u00e3o \u00e9 necess\u00e1rio garantir que em todos os pares se executem as opera\u00e7\u00f5es na mesma ordem, isto \u00e9, ou da esquerda para a direita ou da direita para a esquerda. Observe que este n\u00e3o \u00e9 o caso neste exemplo. Mas e se modificarmos a execu\u00e7\u00e3o como a seguir? Conflitos Conflitos: 1x3: \\(\\leftarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\) Opera\u00e7\u00e3o T1(a,b) T1(c,b) 2 \\(sB = R(b)\\) 3 \\(W(b)sB*1.1\\) 1 \\(sB = R(b)\\) 4 \\(W(b)sB*1.1\\) \\(sC = R(c)\\) \\(W(c)sC-sB*0.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Neste exemplo modificado teremos as opera\u00e7\u00f5es nos pares de conflitos sendo executadas da direita para a esquerda, o que garante a equival\u00eancia serial da execu\u00e7\u00e3o. Contudo, o modelo de transa\u00e7\u00f5es usado at\u00e9 agora, em que o conjunto de opera\u00e7\u00f5es \u00e9 sempre executado at\u00e9 o fim, n\u00e3o corresponde \u00e0 realidade. Precisamos adicionar a este modelo a possibilidade da transa\u00e7\u00e3o ser abortada , isto \u00e9, ter seus efeitos revertidos. Sob este novo modelo, considere o seguinte exemplo, onde a transa\u00e7\u00e3o da direita \u00e9 abortada. T1(a,b) T1(c,b) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sC = R(c)\\) \\(W(c)sC-sB*0.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) aborte! Apesar das opera\u00e7\u00f5es serem ordenadas da direita para a esquerda, houve um dirty read na execu\u00e7\u00e3o da transa\u00e7\u00e3o da esquerda. Uma forma de pensar em como isso aconteceu, \u00e9 considerar que o aborte! \u00e9 uma opera\u00e7\u00e3o que toca todos os dados usados pela transa\u00e7\u00e3o abortada. Assim, o aborte! conflita com as leituras de \\(b\\) e de \\(a\\) feitas pela transa\u00e7\u00e3o da esquerda e, portanto, houve uma viola\u00e7\u00e3o na ordem de execu\u00e7\u00e3o das opera\u00e7\u00f5es. Para que este dirty read n\u00e3o leve a inconsist\u00eancias, a transa\u00e7\u00e3o da esquerda deve tamb\u00e9m abortar. Esta estrat\u00e9gia pode ser implementada da seguinte forma: se uma transa\u00e7\u00e3o l\u00ea um dado atualizado por uma transa\u00e7\u00e3o n\u00e3o comitada, suspenda a transa\u00e7\u00e3o executando a leitura. se transa\u00e7\u00e3o que atualizou o dado foi abortada, todas as suspensas que leram dela devem ser abortadas. repita passo anterior. Graficamente, podemos ver o exemplo acima assim, tanto no caso de commit quando de abort da segunda transa\u00e7\u00e3o. Apesar de correta, esta abordagem tem um caso patol\u00f3gico que leva a abortos em Cascata : se T1 l\u00ea algo que T2 escreveu, e T2 l\u00ea algo que T3 escreveu, e assim por diante, se a \u00faltima transa\u00e7\u00e3o nesta cadeia de depend\u00eancias for abortada, todas dever\u00e3o ser abortadas. Mas, e se evitarmos dirty reads em vez de tratarmos? Podemos faz\u00ea-lo com a seguinte estrat\u00e9gia: quando um transa\u00e7\u00e3o T1 tenta ler um dado \"sujo\" escrito por T2, suspenda a execu\u00e7\u00e3o da transa\u00e7\u00e3o T1, antes da leitura acontecer. quando transa\u00e7\u00e3o T2 for terminada, continue a execu\u00e7\u00e3o de T1. O que estamos tentando obter aqui \u00e9 uma execu\u00e7\u00e3o estrita , ou seja, uma execu\u00e7\u00e3o em que Leituras e Escritas devem ser atrasadas at\u00e9 que todas as transa\u00e7\u00f5es anteriores que contenham escritas nos mesmos dados sejam \"comitadas\" ou abortadas. Execu\u00e7\u00f5es estritas garante Isolamento, contudo, levam a menor concorr\u00eancia, j\u00e1 que transa\u00e7\u00f5es ficam suspensas. Fica ent\u00e3o a pergunta: como implementar execu\u00e7\u00f5es estritas eficientes ? A resposta est\u00e1 no controle de concorr\u00eancia das transa\u00e7\u00f5es. Controle de Concorr\u00eancia Consideremos tr\u00eas abordagens de controle de concorr\u00eancia usadas por bancos de dados: locking: abordagem pessimista que paga um alto pre\u00e7o de sincroniza\u00e7\u00e3o mesmo quando as transa\u00e7\u00f5es n\u00e3o interferem umas nas outras. multi-vers\u00e3o: abordagem otimista, que tem algo custo quando h\u00e1 muitos conflitos entre as transa\u00e7\u00f5es. timestamp: abordagem mais complexa de se implementar. Locking Nesta abordagem, todos os objetos usados por uma transa\u00e7\u00e3o s\u00e3o trancados, impedindo que sejam acessados por outras transa\u00e7\u00f5es, at\u00e9 que sejam destrancados. Contudo, se os objetos s\u00e3o destrancados t\u00e3o logo n\u00e3o sejam mais usados na transa\u00e7\u00e3o, continuamos a ter dirty reads , como a opera\u00e7\u00e3o em vermelho na figura a seguir. Mesmo que se tentasse abortar a transa\u00e7\u00e3o que executou a dirty read , poderia ser tarde demais, como no exemplo a seguir que demonstra uma escrita prematura . Estes problemas podem ser evitados com o uso de strict two phase locking , em que as transa\u00e7\u00f5es trancam o objeto quando primeiro acessado e s\u00f3 destrancam ao final da transa\u00e7\u00e3o , atomicamente com a termina\u00e7\u00e3o. J\u00e1 para aumentar a concorr\u00eancia, \u00e9 poss\u00edvel usar locks para leitura, compartilhados, e para escrita, exclusivos. Read/Write locks dois n\u00edveis de acesso m\u00faltiplos leitores \u00fanico escritor reads por ser transformados em locks writes n\u00e3o podem se transformados em reads (violaria Strict Two-Phase Locking) Ou, ainda, locks com diferentes granularidades; em um banco de dados relacional, por exemplo, pode ser poss\u00edvel obter um lock em uma coluna de uma linha do banco, de toda a linha, de toda a rela\u00e7\u00e3o, ou mesmo de todo o banco de dados. Mas mesmo com estes ajustes, locks deveriam, via de regra, serem evitados sempre que a probabilidade de conflitos for baixa. Isso porqu\u00ea os locks s\u00e3o uma abordagem pessimista , que incorrem em overhead mesmo quando transa\u00e7\u00f5es n\u00e3o acessam os mesmos dados, lembrando que os locks s\u00f3 podem ser liberados no final das transa\u00e7\u00f5es. Evitar locks pessimista overhead mesmo se n\u00e3o h\u00e1 conflitos ou restritivo ou risco de deadlock lock liberado somente no final, para evitar dirty reads/escrita prematura. Multi-vers\u00e3o Uma alternativa otimista aos locks \u00e9 assumir que n\u00e3o h\u00e1 conflitos nas transa\u00e7\u00f5es enquanto elas executam e, somente ao final da execu\u00e7\u00e3o, testar a validade desta premissa e, caso falhe, abortar a transa\u00e7\u00e3o. O controle de concorr\u00eancia multi-vers\u00e3o (MVCC, do termo em ingl\u00eas) faz isso mantendo uma c\u00f3pia privada dos dados acessados pela transa\u00e7\u00e3o. Ao final da execu\u00e7\u00e3o, na fase de valida\u00e7\u00e3o , se a c\u00f3pia p\u00fablica de onde a privada foi copiada n\u00e3o tiver sido modificada, a transa\u00e7\u00e3o \u00e9 bem sucedida e atualiza\u00e7\u00f5es s\u00e3o feitas nas c\u00f3pias p\u00fablicas. 2 Esta t\u00e9cnica, conhecida como deferred update pois atrasa a atualiza\u00e7\u00e3o da c\u00f3pia p\u00fablica at\u00e9 o final da transa\u00e7\u00e3o, tem como vantagens o baixo overhead , se n\u00e3o houver conflitos. Entretanto, se houver muitos conflitos, o trabalho da transa\u00e7\u00e3o \u00e9 todo desperdi\u00e7ado j\u00e1 que a transa\u00e7\u00e3o ser\u00e1 abortada na valida\u00e7\u00e3o . A valida\u00e7\u00e3o consiste em verificar se os read e write sets de quaisquer transa\u00e7\u00f5es concorrentes s\u00e3o disjuntos, isto \u00e9, se dados transa\u00e7\u00f5es \\(t1\\) e \\(t2\\) : t1 n\u00e3o deve ler dados escritos por t2 t2 n\u00e3o deve ler dados escritos por t1 t1/t2 n\u00e3o deve escrever dados escritos por t2/t1 Na imagem a seguir, a transa\u00e7\u00e3o preta precisa ser validada ou frente \u00e0s transa\u00e7\u00f5es concorrentes vermelhas, j\u00e1 comitadas, ou \u00e0s azuis, ainda por comitar. No caso da valida\u00e7\u00e3o com transa\u00e7\u00f5es j\u00e1 comitadas ( backward validation ) a valida\u00e7\u00e3o pode ser simplificada assim: t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o j\u00e1 comitada. t1 n\u00e3o deve ler dados escritos por t2 Se a valida\u00e7\u00e3o for com as transa\u00e7\u00f5es ainda em execu\u00e7\u00e3o ( forward validation ) a regra passa a ser: t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o ainda em execu\u00e7\u00e3o t2 n\u00e3o deve ler dados escritos por t1 \u00c9 preciso destacar que a forward validation pode levar a um cen\u00e1rio em que nenhuma transa\u00e7\u00e3o \u00e9 jamais comitada, pois uma cascata de aborts pode ocorrer. Timestamping Uma terceira forma de controlar a concorr\u00eancia associando uma ordem l\u00f3gica para a execu\u00e7\u00e3o das transa\u00e7\u00f5es, de acordo com o in\u00edcio das transa\u00e7\u00f5es. Isto \u00e9 feito atribuindo-se um timestamp a cada transa\u00e7\u00e3o e garantindo-se que a execu\u00e7\u00e3o das transa\u00e7\u00f5es seja \u00e9 equivalente \u00e0 execu\u00e7\u00e3o serial de acordo com os timestamps. 3 transa\u00e7\u00e3o recebe um timestamp no in\u00edcio opera\u00e7\u00f5es s\u00e3o validadas na execu\u00e7\u00e3o leia somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver escrito e comitado escreva somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver lido e comitado transa\u00e7\u00f5es \"executam na ordem do timestamp\" Como implementar? Como implementar objetos tem valores tentativos , n\u00e3o comitados objetos tem vers\u00f5es em que foram escritos em que foram comitados e em que foram lidos consist\u00eancia \u00e9 testado na execu\u00e7\u00e3o da opera\u00e7\u00e3o Como implementar -- escrita escritas tem sucesso somente se vers\u00e3o sendo escrita \u00e9 maior que vers\u00f5es lidas se vers\u00e3o sendo escrita \u00e9 menor que vers\u00e3o j\u00e1 escrita, ignore e continue como implementar -- leitura leitura com vers\u00e3o v tem sucesso se maior vers\u00e3o \u00e9 comitada e menor que v ou alguma n\u00e3o comitada leitura com vers\u00e3o v \u00e9 suspensa se maior vers\u00e3o \u00e9 n\u00e3o comitada e menor que v leitura com vers\u00e3o v \u00e9 abortada se maior vers\u00e3o comitada \u00e9 maior que v Bancos de dados distribu\u00eddos Agora que relembramos como transa\u00e7\u00f5es funcionam e temos uma no\u00e7\u00e3o de como podem ser implementadas em um sistema centralizado, vamos tentar entender como faz\u00ea-lo em um sistema distribu\u00eddo. m\u00faltiplos servidores transa\u00e7\u00f5es em cada servidor transa\u00e7\u00f5es distribu\u00eddas como obter equival\u00eancia serial em transa\u00e7\u00f5es distribu\u00eddas Transa\u00e7\u00e3o distribu\u00edda begintransaction(): tid (transaction id) operation(tid,op) endtransaction(tid): ok/nok aborttransaction(tid) Temos v\u00e1rios pap\u00e9is sendo desempenhados aqui: cliente servidor: resource managers servidor: transaction monitor/manager Localmente, cada bd funciona como um sistema centralizado normal, usando abordagens otimistas ou pessimista para garantir consist\u00eancia. O grande problema no bd distribu\u00eddo \u00e9 garantir o acordo na termina\u00e7\u00e3o. Comprometimento distribu\u00eddo O problema... transa\u00e7\u00e3o \\(t\\) acessa recursos nos resource managers (rm) terminar com sucessos \\(t\\) em todos os rm - commit - ou abortar \\(t\\) em todos os rm ainda que enlaces de comunica\u00e7\u00e3o, n\u00f3s e rm falhem, antes ou durante a termina\u00e7\u00e3o da transa\u00e7\u00e3o. participante -- resource manager \"tocados\" pela transa\u00e7\u00e3o coordenador -- transaction manager Cliente decide quando iniciar o commit. Cada participante faz commit ou abort da transa\u00e7\u00e3o local. pode retornar ok ou nok. Coordenador n\u00e3o come\u00e7a a commit at\u00e9 que a \\(t\\) tenha terminado em todos os participantes e cliente tenha solicitado. Participantes falham por parada. 1PC cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes \"comitarem\" Mas... e se um participante retornar nok enquanto outros retornam ok? e se um participante n\u00e3o responder? 2PC cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes se prepararem para terminar coordenador espera que todos se preparem ou digam se n\u00e3o podem coordenador envia ordem de termina\u00e7\u00e3o Comprometimento um participante \\(p\\) est\u00e1 pronto para commit se tiver todos os valores modificados por \\(t\\) em mem\u00f3ria est\u00e1vel e nenhuma raz\u00e3o para abortar a transa\u00e7\u00e3o (outras transa\u00e7\u00f5es conflituosas fizeram commit?) o coordenador n\u00e3o pode come\u00e7ar a termina\u00e7\u00e3o at\u00e9 que todos os participantes estejam prontos. se algum participante aborta, o coordenador deve abortar. Problema de acordo, mas n\u00e3o igual ao consenso. 2PC - o protocolo fase 1 a: coordenador envia vote-request para participantes. b: participante responde com vote-commit ou vote-abort para o coordenador; se vote-abort, aborta localmente. fase 2 a: coordenador coleta votos de todos os processos; se forem todos vote-commit, envia global-commit para os participantes e ok para o cliente b: participantes esperam por global-commit ou global-abort Coordenador Participante Falha no Participante Participante falha no estado \\(S\\) e, ao se recuperar, identifica tal fato ao reprocessar o log de opera\u00e7\u00f5es em mem\u00f3ria dur\u00e1vel. Se est\u00e1 no estado INIT: nem sabia que a termina\u00e7\u00e3o come\u00e7ou. Aborta unilateralmente, pois ou j\u00e1 abortaram ou v\u00e3o abortar. ABORT: havia votado abort ou recebido global-abort -- continua protocolo. COMMIT: estava pronto para terminar a transa\u00e7\u00e3o com sucesso -- continua protocolo. READY: estava esperando por commit ou abort. Precisa saber se coordenador enviou global-commit ou global-abort -- consulta coordenador. 2PC Por que \u00e9 dif\u00edcil? E se \\(R_i\\) falhar depois de ter se preparado? E se \\(R_i\\) falhar mas \\(R_j\\) continuar funcionando? E se todos estiverem desligados quando \\(R_i\\) se recuperar? E se \\(R_i\\) estiver lento e parecer que a transa\u00e7\u00e3o falhou? Falha no Participante READY: esperando por commit ou abort. Precisa saber se coordenador enviou global-commit our global-abort -- consulta coordenador. E se coordenador n\u00e3o estiver presente? Assumindo que participantes se conhecem, contate participante \\(Q\\) Se \\(Q\\) em COMMIT , vai para COMMIT Se \\(Q\\) em ABORT , vai para ABORT Se \\(Q\\) em INIT , ordena que Q aborte e, se confirmado, veja passo anterior Se \\(Q\\) em READY , consulta outro participante. Se todos os participantes em READY? Possivelmente o coordenador j\u00e1 respondeu ao cliente. Precisa esperar pelo coordenador. Falha no Coordenador O problema principal \u00e9: e se ningu\u00e9m ouviu a decis\u00e3o final do coordenador? Neste caso, o protocolo n\u00e3o pode continuar, enquanto o coordenador n\u00e3o retornar, pois se os RM abortarem, podem estar contradizendo algo dito ao cliente, por exemplo, \"Sim, ATM, pode entregar o dinheiro\", ou executando um comando que o cliente v\u00ea como anulado, como \"Reenvie o pedido de mais 27 carros \u00e0 f\u00e1brica.\" Recupera\u00e7\u00e3o do Coordenador Ao se recuperar, o coordenador: sabe se come\u00e7ou a termina\u00e7\u00e3o de alguma transa\u00e7\u00e3o sabe se j\u00e1 enviou alguma resposta final para as transa\u00e7\u00f5es inacabadas sabe se j\u00e1 recebeu a confirma\u00e7\u00e3o de todos os participantes (se transa\u00e7\u00e3o n\u00e3o estiver em aberto) reenvia a \u00faltima mensagem das transa\u00e7\u00f5es em aberto. Otimiza\u00e7\u00f5es Participantes \"somente-leitura\" N\u00e3o se importa com a decis\u00e3o; termina ap\u00f3s fase 1. Responde com vote-commit-ro Abort presumido Se ocorrer timeout, coordenador envia global-abort a todos e esquece transa\u00e7\u00e3o Se questionado, responde com global-abort. Transfer\u00eancia de coordena\u00e7\u00e3o se houver somente um participante... vote-request-transfer participante responde com global-commit/global-abort Coleta de Lixo Mesmo quando somente um participante falha... Ap\u00f3s receber decis\u00e3o, o participante pode concluir e esquecer a transa\u00e7\u00e3o. Mas e se o participante falho precisar se recuperar e todos os outros envolvidos tiverem esquecido a transa\u00e7\u00e3o? Coleta de lixo s\u00f3 pode ser feita quando todos tiverem confirmado a execu\u00e7\u00e3o da transa\u00e7\u00e3o e, por isso, Fase 2b \u00e9 necess\u00e1ria. 3-PC Estende o protocolo para permitir contornar falha do coordenador. O Protocolo Fase 1a -- Coordenador envia vote-request para participantes. Fase 1b -- Participante responde com vote-commit ou vote-abort para o coordenador; se vote-abort, aborta localmente. Fase 2a -- Coordenador coleta votos de todos os processos; se forem todos vote-commit, envia prepare-commit para os participantes; se n\u00e3o, global-abort e para. Fase 2b -- Participantes esperam por prepare-commit ou global-abort; se o primeiro, respondem com ready-commit ; se o segundo, param. Fase 3a -- coordenador espera por ready-commit de todos e ent\u00e3o envia global-commit. Fase 3b -- participantes esperam por global-commit. Coordenador Participante Falha no Participante \\(P\\) consegue saber o que fazer ap\u00f3s se recuperar da falha no estado READY ou PRE-COMMIT Participantes e coordenador n\u00e3o distam mais que um estado. Se algu\u00e9m em READY, o coordenador n\u00e3o mandou global-commit ainda; Aborte. Se todos em PRE-COMMIT, \u00e9 poss\u00edvel comitar, comite. A execu\u00e7\u00e3o dos passos anteriores tem que anular o poder do coordenador. Se todos os participantes em READY? 3PC x 2PC 3PC -- Aumenta disponibilidade 2PC -- Falha do coordenador \u00e9 \"corner case\" 3PC -- Aumenta o custo do \"caminho feliz\" e por isso n\u00e3o \u00e9 usado na pr\u00e1tica Nenhum escala e n\u00e3o us\u00e1-los \u00e9 uma das raz\u00f5es para o surgimento dos sistemas NoSQL Paxos-Commit Usa inst\u00e2ncias de Consenso Distribu\u00eddo para votar. Se o consenso \u00e9 tolerante a falhas e consistente, todos v\u00eaem o mesmo resultado na transa\u00e7\u00e3o. O protocolo Para terminar a transa\u00e7\u00e3o \\(T\\) , o coordenador envia request-commit a todos os participantes. Um participante \\(P\\) prop\u00f5e seu voto na inst\u00e2ncia \\(T_P\\) de consenso. Todo participante \\(P\\) espera pelas decis\u00f5es das inst\u00e2ncias de consenso \\(T_i\\) para todos os participantes \\(i\\) , inclusive si mesmo; se todas as decis\u00f5es forem commit, o participante comita a transa\u00e7\u00e3o. Se cansar de esperar por \\(T_Q\\) , o participante prop\u00f5e abort em \\(T_Q\\) . Falha no Participante Se o participante falha antes de votar, ent\u00e3o algu\u00e9m votar\u00e1 abort por ele. Se o participante \\(P\\) falha, ou \u00e9 suspeito de, ent\u00e3o \u00e9 poss\u00edvel que dois votos diferentes tenham sido propostos em \\(T_P\\) ; isso n\u00e3o \u00e9 um problema pois a decis\u00e3o \u00e9 a mesma para todos observando a inst\u00e2ncia. Ap\u00f3s se recuperar, o participante recupera as decis\u00f5es de todas as inst\u00e2ncias \\(T_i\\) e termina apropriadamente. Log Structured Merge Trees Idealmente, toda manipula\u00e7\u00e3o de dados seria executada a partir da mem\u00f3ria principal, tendo assim a menor lat\u00eancia poss\u00edvel. Contudo, para que se tenha tamb\u00e9m durabilidade das opera\u00e7\u00f5es executadas, para que os dados manipulados sobrevivam a reinicializa\u00e7\u00f5es do servidor, intencionais ou n\u00e3o, \u00e9 preciso armazenar os dados em mem\u00f3ria est\u00e1vel , da qual a mais comum s\u00e3o os discos r\u00edgidos . Bancos de dados relacionais tradicionalmente armazenam seus dados em disco usando estruturas em \u00e1rvore, pois estas tem custo amortizado de leitura e escrita \\(O(log n)\\) . Bancos de dados NoSQL, muito usados em cen\u00e1rios de Big Data , em que quantidades muito grandes de dados s\u00e3o geradas e acessadas com grande velocidade, capitanearam um esfor\u00e7o para otimizar opera\u00e7\u00f5es de escrita enquanto tamb\u00e9m tentando n\u00e3o aumentar significativamente os tempos de leitura. \u00c9 not\u00f3rio que opera\u00e7\u00f5es em disco s\u00e3o muito mais lentas que em mem\u00f3ria principal, mas o que exatamente \u00e9 lento no acesso ao disco? Essencialmente, o posicionamento da cabeca de leitura/escrita na trilha correta do disco, pois esta opera\u00e7\u00e3o \u00e9 mec\u00e2nica. Por esta raz\u00e3o, acessos aleat\u00f3rios s\u00e3o mais custosos que acessos sequenciais, pois neste o custo de posicionamento \u00e9 pago apenas uma vez. Alguns bancos de dados, como o Cassandra, armazenam os dados na forma de uma Log Structured Merge Tree , ou LSMT, que acessa o disco quase que exclusivamente de forma sequencial, minimizando assim o impacto da durabilidade no desempenho do sistema. Considere um banco armazenando uma pequena quantidade de dados, que cabe em mem\u00f3ria principal Usando LSMT, os dados s\u00e3o mantidos em mem\u00f3ria principal em estruturas de dados denominadas memory table , ou simplesmente memtables . Opera\u00e7\u00f5es de escrita s\u00e3o \"logadas\" e um commit log , em disco, antes de serem aplicadas \u00e0s memtables e confirmadas para o cliente. Neste cen\u00e1rio o acesso ao disco na escrita \u00e9 sequencial, o melhor que se pode ter em um disco, e a recupera\u00e7\u00e3o dos dados \u00e9 feita diretamente da mem\u00f3ria, rapidamente. No caso de uma reinicializa\u00e7\u00e3o do processo, a reexecu\u00e7\u00e3o do commit log restaurar\u00e1 o estado da memtable. Observe que a leitura do commit log \u00e9 sequencial, o que acelera a reexecu\u00e7\u00e3o. Ainda assim, se o commit log for extenso, reexecut\u00e1-lo demandar\u00e1 um tempo significativo. Uma forma de acelerar o processo \u00e9 fazer snapshots da memtable de forma sincronizada com a escrita no log. Isto \u00e9, digamos que todas as opera\u00e7\u00f5es de escrita, at\u00e9 a d\u00e9cima, est\u00e3o salvas no commit log e refletidas na memtable. Digamos tamb\u00e9m que todas as opera\u00e7\u00f5es s\u00e3o modifica\u00e7\u00f5es da mesma linha do banco de dados em mem\u00f3ria. Se um snapshot \u00e9 tomado, ele ser\u00e1 correspondente ao commit log, isto \u00e9, conter\u00e1 o efeito de exatamente as mesmas 10 opera\u00e7\u00f5es, mas de forma mais compacta que o log, uma vez que o log conter\u00e1 dez opera\u00e7\u00f5es e o snapshot somente uma linha de dados. Ap\u00f3s o snapshot ser conclu\u00eddo, o log correspondente pode ser apagado, assim como snapshots anteriores. Novas opera\u00e7\u00f5es de escrita devem ser armazenadas em um novo log e, no caso de uma reinicializa\u00e7\u00e3o, primeiro se deve restaurar o snapshot e ent\u00e3o o novo log. Para lidar com corrup\u00e7\u00f5es de arquivo no sistema, pode ser uma boa ideia manter mais do que o \u00faltimo log e snapshot , j\u00e1 que a recupera\u00e7\u00e3o do estado exigiria voltar mais atr\u00e1s na reexecu\u00e7\u00e3o de opera\u00e7\u00f5es. Observe que, al\u00e9m da escrita dos logs, todos os outros acessos ao disco tamb\u00e9m s\u00e3o sequenciais, seja o flush das memtables, ou a leitura dos snapshots para recupera\u00e7\u00e3o e do commit log para reexecu\u00e7\u00e3o e, j\u00e1 que opera\u00e7\u00f5es de leitura s\u00e3o todas respondidas da mem\u00f3ria, o sistema ter\u00e1 um excelente desempenho. Contudo, h\u00e1 outro limitante de desempenho importante, relacionado \u00e0 premissa pouco realista de que os dados cabem todos em mem\u00f3ria. Isto \u00e9, se os dados n\u00e3o cabem em mem\u00f3ria, snapshots ser\u00e3o importantes n\u00e3o somente para permitir coletar lixo dos logs, isto \u00e9, dados obsoletos, mas tamb\u00e9m, para usar a capacidade de armazenamento dos discos. Consideremos ent\u00e3o um cen\u00e1rio em que a memtable cabe apenas n entradas; quando a opera\u00e7\u00e3o para adicionar \\(n+1\\) -\u00e9sima entrada \u00e0 memtable \u00e9 recebida, um flushs dos dados para um novo snapshot \u00e9 feito e a memtable \u00e9 resetada , liberando espa\u00e7o em mem\u00f3ria. Para melhorar o desempenho, estas descargas podem ser feitas proativamente antes da chegada de novas entradas e fora do caminho cr\u00edtico da opera\u00e7\u00e3o de escrita, mas isto \u00e9 apenas uma otimiza\u00e7\u00e3o e portanto n\u00e3o a consideraremos aqui. Neste novo fluxo, os arquivos em disco n\u00e3o correspondem mais a snapshots do banco de dados mas a por\u00e7\u00f5es dos dados, ent\u00e3o nos referiremos a eles como stable storage tables , ou sstables , em oposi\u00e7\u00e3o \u00e0s memtables , pelo menos por enquanto. Compacta\u00e7\u00f5es Apesar deste novo fluxo de escrita aumentar a capacidade de armazenamento do nosso banco de dados, ele traz problemas para o fluxo de leitura. Digamos que a chave \\(k\\) teve um valor atribu\u00eddo e descarregado em uma sstable em diversas ocasi\u00f5es. O primeiro problema aqui \u00e9 que h\u00e1 v\u00e1rios valores antigos associados a \\(k\\) , inutilmente e ocupando espa\u00e7o, isto \u00e9, lixo. O segundo \u00e9 que caso o valor associado a \\(k\\) seja requisitado, o sistema dever\u00e1 retornar a \u00faltima vers\u00e3o, que pode estar em diversos arquivos. Para lidar com ambos os problemas, podemos compactar as sstables juntas, eliminados dados obsoletos e minimizando o n\u00famero de arquivos a serem pesquisados no caso de leitura. Caso a sstables estejam ordenadas, o procedimento de compacta\u00e7\u00e3o pode ser feito como a uni\u00e3o de dois segmentos de dados no merge sort , isto \u00e9, iterando-se paralelamente nos dois arquivos e escolhendo sempre a menor chave da vez e movendo-a para um novo segmento que conter\u00e1 a uni\u00e3o dos dados. A figura a seguir mostra um exemplo que v\u00e1rias sstables de n\u00edvel 0, aquelas geradas por flushs , s\u00e3o unidas gerando sstables de n\u00edvel 1 e assim sucessivamente. Observe como as compacta\u00e7\u00f5es geram uma \u00e1rvore (na verdade, uma floresta), raz\u00e3o do nome merge tree . No caso de uma leitura, somente as tabelas mais \u00e0 direita e de n\u00edvel mais alto precisam ser consultadas e portanto as sstables j\u00e1 usadas como entrada podem ser eliminadas como lixo do sistema. Ainda assim , no caso de uma leitura, diversas sstables potencialmente cont\u00e9m o dado a ser retornado. O problema se agrava em sistemas em que partes do dado possam ser gravadas independentemente, como no CassandraDB, em que cada coluna \u00e9 independente das outras. Diversas propostas poderiam ser feitas para se identificar mais rapidamente se uma sstable cont\u00e9m uma chave . Por exemplo, pode-se associar a cada tabela um bitmap indicando a presen\u00e7a ou n\u00e3o de uma certa chave, mas esta abordagem obviamente falha se o espa\u00e7o de chaves for grande. Outra possibilidade \u00e9 lembrar a faixa de chaves contida na tabela. Esta estrat\u00e9gia pode ser \u00fatil caso haja localidade no espa\u00e7o de chaves no momento da escrita, mas falhar\u00e1 miseravelmente se o espa\u00e7o de chaves for usado uniformemente, resultando em faixas grandes entre a menor e maior chaves de cada tabela. Como acelerar a identifica\u00e7\u00e3o das sstables pertinentes? Entram em cena os filtros de Bloom . Filtros de Bloom De acordo com nossa fonte mais que confi\u00e1vel, a Wikipedia Bloom Filter A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not, thus a Bloom filter has a 100% recall rate. In other words, a query returns either \"possibly in set\" or \"definitely not in set\" . Se associarmos a cada sstable um filtro de Bloom, ent\u00e3o s\u00f3 ser\u00e1 preciso l\u00ea-la se o filtro correspondente disser que a chave possivelmente est\u00e1 contida, como no seguinte exemplo. Mas como exatamente constru\u00edmos um filtro de Bloom? Iniciamos com um vetor de bits inicialmente zerados e um conjunto finito de fun\u00e7\u00f5es de hash cujo resultado seja uniformemente distribu\u00eddo no tamanho do vetor de bits. Para cada elemento colocado no conjunto a ser refletido pelo filtro, aplicamos cada uma das fun\u00e7\u00f5es hash e colocamos o bit 1 na posi\u00e7\u00e3o do vetor igual ao resultado da fun\u00e7\u00e3o . No exemplo a seguir, inserimos os elementos x, y e z e usamos tr\u00eas fun\u00e7\u00f5es hash. Na consulta , cada elemento passa por pelas mesmas fun\u00e7\u00f5es hash para identificar quais bits do vetor ler. Se algum dos \u00edndices apontados n\u00e3o estiver com um 1, como no caso do c, no exemplo, o elemento n\u00e3o pertence ao conjunto. Caso contr\u00e1rio, o filtro responder\u00e1 que \u00e9 poss\u00edvel que perten\u00e7a. Mas qu\u00e3o bom \u00e9 um filtro de Bloom na identifica\u00e7\u00e3o do das sstables? O filtro ser\u00e1 melhor se os bits 1 forem devidos a menos elementos mapeando para tal posi\u00e7\u00e3o, pois se muitos elementos mapearem para a mesma posi\u00e7\u00e3o, falsos positivos podem ocorrer. Assim, de outra forma, quais fatores influenciam na taxa de falsos positivos do filtro? o n\u00famero \\(n\\) de elementos no conjunto, uma vez que quanto mais elementos, mais bits 1 no vetor; o n\u00famero \\(k\\) de hashes, pois quanto mais hashes, mais bits transformados em 1; e, o n\u00famero \\(m\\) de bits no vetor, pois quanto menos bits, mais colis\u00f5es de bits. De forma mais precisa, a probabilidade de setar um certo bit na inser\u00e7\u00e3o de um elemento \u00e9 \\(1/m\\) , e a probabilidade de n\u00e3o setar tal bit \u00e9 \\(1 - 1/m\\) ; a probabilidade de \\(k\\) hashes n\u00e3o setarem um bit \u00e9 \\((1 - 1/m)^k\\) ; a probabilidade de n\u00e3o setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\((1 - 1/m)^{kn}\\) ; a probabilidade de setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\(1 - (1 - 1/m)^{kn}\\) Logo, a probabilidade de falso positivo \\(p = (1 - (1 - 1/m)^{kn})^k \\approx (1 - e^{-kn/m})^k\\) O que nos permite chegar \u00e0 rela\u00e7\u00e3o \\(m/n = - 1.44\\log_2 p\\) , em que podemos calcular \\(m\\) em fun\u00e7\u00e3o do \\(n\\) esperado e do \\(p\\) desejado. E podemos tamb\u00e9m identificar o \\(k\\) \u00f3timo para a situa\u00e7\u00e3o, pela equa\u00e7\u00e3o \\(k = - \\frac{\\ln p}{\\ln 2} = - \\log_2 p\\) Uma forma \"simples\" de visualizar este resultado \u00e9 dada pela figura a seguir, em que o eixo Y d\u00e1 a taxa de falsos positivos do filtro em fun\u00e7\u00e3o do n\u00famero de elementos inseridos, indicado no eixo X, para diversas configura\u00e7\u00f5es, apresentadas como curvas. Por exemplo, com um filtro com \\(m = 2^{24}b = 2MB\\) , ap\u00f3s 1 milh\u00e3o de inser\u00e7\u00f5es, tem-se probabilidade de falsos positivo \\(p = 0,0001\\) . TODO Combinar https://adambcomer.com/blog/simple-database/motivation-design.html https://adambcomer.com/blog/simple-database/memtable.html https://adambcomer.com/blog/simple-database/wal.html https://www.jasondavies.com/bloomfilter/ CAP CAP theorem NoSQL database types Weak Consistency and CAP Implications BASE TODO Incluir explica\u00e7\u00e3o Refer\u00eancias Balancing Strong and Eventual Consistency with Datastore https://blog.yugabyte.com/a-primer-on-acid-transactions/ https://jepsen.io/consistency https://fauna.com/blog/demystifying-database-systems-part-4-isolation-levels-vs-consistency-levels https://www.postgresql.org/docs/9.5/transaction-iso.html Inspirado nas notas de aula de Johan Montelius e Vladimir Vlassov, da disciplina ID2201 Distributed Systems, KTH Royal Institute of Technology. Imagens copiadas descaradamente de seus slides em https://www.kth.se/social/files/57c2cbd7f276541680e39e6d/transactions.pdf https://www.cs.ucy.ac.cy/~dzeina/courses/epl446/lectures/16.pdf https://www.cs.princeton.edu/courses/archive/fall18/cos418/docs/p8-consistency.pdf https://aphyr.com/posts/313-strong-consistency-models Modern Algorithms and Data Structures: Bloom-Filter Consist\u00eancia no sentido visto no cap\u00edtulo anterior, n\u00e3o no sentido ACID. \u21a9 Na pr\u00e1tica, a atualiza\u00e7\u00e3o consiste apenas em mudar um ponteiro para apontar para a c\u00f3pia privada. \u21a9 Baseado no material dispon\u00edvel em Distributed Systems, Basic Course . \u21a9","title":"Bancos de Dados"},{"location":"disdb/#transacoes","text":"No banco de dados vistos no cap\u00edtulo anterior, opera\u00e7\u00f5es s\u00e3o enviadas individualmente para as r\u00e9plicas do banco. J\u00e1 no modelo transacional, normalmente pensamos em conjunto de opera\u00e7\u00f5es em vez de opera\u00e7\u00f5es individuais; estes conjuntos de opera\u00e7\u00f5es s\u00e3o as transa\u00e7\u00f5es . Considere um sistema banc\u00e1rio que mant\u00e9m contas com saldos inteiros. Seguindo a nota\u00e7\u00e3o apresentada anteriormente, \\(R(C)10\\) \u00e9 um opera\u00e7\u00e3o de leitura da conta \\(C\\) que retorna o valor 10 e \\(W(C)20\\) \u00e9 a opera\u00e7\u00e3o de atualiza\u00e7\u00e3o do saldo de \\(C\\) para 20. Vamos estender a nota\u00e7\u00e3o para que \\(a = R(C)\\) armazene o valor lido de \\(C\\) em \\(a\\) . Seja \\(T\\) uma transa\u00e7\u00e3o que incrementa o valor de uma conta em \\(1\\) ; ela pode ser especificada como \\(a = R(C); W(C)a+1\\) Imagine duas inst\u00e2ncias desta transa\u00e7\u00e3o executando serialmente. Ao final da execu\u00e7\u00e3o o saldo foi acrescido de 2, como esperado. Se em vez disso as duas inst\u00e2ncias executassem concorrentemente, ter\u00edamos um resultado diverso, mesmo que o esperado fosse o mesmo resultado. Ao final da execu\u00e7\u00e3o, apesar do valor ter sido modificado duas vezes, o saldo teria sido acrescido de 1. Esta diferen\u00e7a entre o esperado e o real est\u00e1 enraizada nas garantias dadas por bancos de dados tradicionais, conhecidas como ACID, acr\u00f4nimo para Atomicidade, Consist\u00eancia, Isolamento e Durabilidade . ACID Atomicidade Consist\u00eancia Isolamento Durabilidade A atomicidade diz respeito ao tratamento das opera\u00e7\u00f5es como um conjunto indivis\u00edvel, isto \u00e9, ou todas as opera\u00e7\u00f5es no conjunto s\u00e3o executadas ou nenhuma \u00e9. A propriedade de consist\u00eancia dita que todas as transi\u00e7\u00f5es do banco de dados devem respeitar restri\u00e7\u00f5es nos seus dados , por exemplo, os tipos de cada entrada no banco e integridade referencial. J\u00e1 a propriedade de isolamento se refere a como e quando os efeitos de uma transa\u00e7\u00e3o passam a ser vis\u00edveis para outras transa\u00e7\u00f5es, possivelmente concorrentes. H\u00e1 diversos n\u00edveis de isolamento, sendo menos restritivos, como consist\u00eancia eventual 1 , ou mais restritivo, como seriabilidade estrita . Finalmente, durabilidade \u00e9 a garantia de que os resultados de uma transa\u00e7\u00e3o s\u00e3o permanentemente gravados no sistema, a despeito de falhas. Caso estas propriedades n\u00e3o sejam garantidas na execu\u00e7\u00e3o de transa\u00e7\u00f5es, problemas podem acontecer, como no exemplo anterior. Por exemplo, seja uma transa\u00e7\u00e3o que move 10% do saldo da segunda conta da primeira para a segunda, isto \u00e9, se \\(a\\) tem saldo inicial 50 e \\(b\\) tem saldo inicial 100, a transa\u00e7\u00e3o transfere 10 de \\(a\\) para \\(b\\) . T1(a,b) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA - (sB*0.1)\\) E seja uma transa\u00e7\u00e3o que calcule o somat\u00f3rio dos saldos em todas as contas especificadas, isto \u00e9, se aplicada \u00e0s contas \\(a\\) e \\(b\\) do exemplo anterior, retorna 150 como resultado. T2([a,b]) \\(sA = R(a)\\) \\(sB = R(b)\\) \\(sT = sA + sB\\) Agora, seja uma execu\u00e7\u00e3o concorrente destas transa\u00e7\u00f5es da seguinte forma (tempo passa para baixo) e que o saldo inicial de \\(a\\) e \\(b\\) s\u00e3o ambos 10. T1(a,b) T2([a,b]) \\(sB = R(b)\\) \\(sA = R(a)\\) \\(W(b)sB*1.1\\) \\(sB = R(b)\\) \\(sA = R(a)\\) \\(W(a)sA - (sB*0.1)\\) \\(sT = sA+sB\\) Qual o valor final calculado? Execu\u00e7\u00e3o Se \\(a\\) inicialmente tem 50 e \\(b\\) 100, ent\u00e3o a seguinte execu\u00e7\u00e3o ocorre: T1(a,b) T2([a,b]) \\(sB = R(b)\\) = 100 \\(sA = R(a) = 50\\) \\(W(b)sB*1.1\\) = 110 \\(sB = R(b) = 110\\) \\(sA = R(a) = 50\\) \\(W(a)sA - (sB*0.1) = 40\\) \\(sT = sA+sB = 160\\) O problema aqui \u00e9 que dados sendo modificados, isto \u00e9, n\u00e3o finais, \"vazaram\" de T1 para T2, um fen\u00f4meno conhecido como dirty read . Isso ocorreu porqu\u00ea o n\u00edvel de isolamento provido foi nenhum. Supondo uma execu\u00e7\u00e3o de duas inst\u00e2ncias de T1, podemos observar outro problema, que pode deixar o BD em estado inv\u00e1lido. T1(a,b) T1(a,b) \\(sB = R(b)\\) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(W(b) sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA-(sB*0.1)\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Execu\u00e7\u00e3o Se \\(a\\) inicialmente tem 50 e \\(b\\) 100, ent\u00e3o a seguinte execu\u00e7\u00e3o ocorre: T1(a,b) T1(a,b) \\(sB = R(b) = 100\\) \\(sB = R(b) = 100\\) \\(W(b)sB*1.1 = 110\\) \\(W(b) sB*1.1\\) = 110 \\(sA = R(a) = 50\\) \\(W(a)sA-(sB*0.1) = 40\\) \\(sA = R(a) = 40\\) \\(W(a)sA-sB*0.1 = 30\\) Observe que \\(sB*0.1\\) foi perdido, o que \u00e9 conhecido como lost update , agora porqu\u00ea faltou isolamento. Qual a solu\u00e7\u00e3o? No primeiro exemplo deste cap\u00edtulo, uma execu\u00e7\u00e3o serial das opera\u00e7\u00f5es n\u00e3o causou problema, enquanto a concorrente sim. Testemos novamente uma execu\u00e7\u00e3o em que as transa\u00e7\u00f5es n\u00e3o se sobrep\u00f5em. T1(a,b) T1(a,b) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA-(sB*0.1)\\) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Esta solu\u00e7\u00e3o funciona, mas, na pr\u00e1tica, queremos o m\u00e1ximo de concorr\u00eancia para garantir o melhor desempenho . O que queremos ent\u00e3o \u00e9 uma execu\u00e7\u00e3o das transa\u00e7\u00f5es semelhante \u00e0 serial, para garantir a corretude dos resultados, mas com o desempenho garantido pela execu\u00e7\u00e3o concorrente. Isto \u00e9, n\u00e3o queremos uma execu\u00e7\u00e3o serial , queremos uma execu\u00e7\u00e3o equivalente a uma execu\u00e7\u00e3o serial .","title":"Transa\u00e7\u00f5es"},{"location":"disdb/#equivalencia-serial","text":"De forma geral, dizemos que duas execu\u00e7\u00f5es de transa\u00e7\u00f5es s\u00e3o equivalentes se s\u00e3o execu\u00e7\u00f5es das mesmas transa\u00e7\u00f5es (mesmas opera\u00e7\u00f5es) quaisquer duas opera\u00e7\u00f5es conflitantes s\u00e3o executadas na mesma ordem nas duas execu\u00e7\u00f5es. Duas opera\u00e7\u00f5es s\u00e3o conflitantes se pertencem a transa\u00e7\u00f5es diferentes, operam no mesmo dado, e pelo menos uma delas \u00e9 escrita. Uma execu\u00e7\u00e3o tem equival\u00eancia serial se \u00e9 equivalente a alguma execu\u00e7\u00e3o serial das transa\u00e7\u00f5es. Ora, se uma execu\u00e7\u00e3o \u00e9 equivalente a uma execu\u00e7\u00e3o serial e a execu\u00e7\u00e3o serial n\u00e3o tem problemas relacionados a isolamento, pois n\u00e3o h\u00e1 transa\u00e7\u00e3o concorrente que acesse dados incompletos, ent\u00e3o a execu\u00e7\u00e3o serial garante resultados corretos. Assim, para obter tanto desempenho advindo da concorr\u00eancia quanto corretude advinda da serializa\u00e7\u00e3o, escalone as opera\u00e7\u00f5es de forma a garantir equival\u00eancia serial. Mas como obter equival\u00eancia serial? N\u00e3o seria vi\u00e1vel executar as opera\u00e7\u00f5es e demonstrar post facto que a execu\u00e7\u00e3o \u00e9 correta. Em vez disso, precisamos garantir por constru\u00e7\u00e3o a equival\u00eancia serial, o que \u00e9 bem mas simples, principalmente se considerarmos a seguinte restri\u00e7\u00e3o a execu\u00e7\u00e3o de duas transa\u00e7\u00f5es tem Equival\u00eancia Serial se todos os pares de opera\u00e7\u00f5es conflitantes entre as transa\u00e7\u00f5es s\u00e3o executados na mesma ordem. Revisitemos o exemplo do lost update . Quais opera\u00e7\u00f5es conflitam nesta execu\u00e7\u00e3o? Conflitos Conflitos: 1x3: \\(\\rightarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\) Opera\u00e7\u00e3o T1(a,b) T1(c,b) 1 \\(sB = R(b)\\) 2 \\(sB = R(b)\\) 3 \\(W(b)sB*1.1\\) 4 \\(W(b)sB*1.1\\) \\(sC = R(c)\\) \\(W(c)sC-sB*0.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Claramente, os pares (1,3), (2,4) e (3,4) s\u00e3o conflitantes. Para se obter equival\u00eancia serial ent\u00e3o \u00e9 necess\u00e1rio garantir que em todos os pares se executem as opera\u00e7\u00f5es na mesma ordem, isto \u00e9, ou da esquerda para a direita ou da direita para a esquerda. Observe que este n\u00e3o \u00e9 o caso neste exemplo. Mas e se modificarmos a execu\u00e7\u00e3o como a seguir? Conflitos Conflitos: 1x3: \\(\\leftarrow\\) , 2x4: \\(\\leftarrow\\) , 3x4: \\(\\leftarrow\\) Opera\u00e7\u00e3o T1(a,b) T1(c,b) 2 \\(sB = R(b)\\) 3 \\(W(b)sB*1.1\\) 1 \\(sB = R(b)\\) 4 \\(W(b)sB*1.1\\) \\(sC = R(c)\\) \\(W(c)sC-sB*0.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) Neste exemplo modificado teremos as opera\u00e7\u00f5es nos pares de conflitos sendo executadas da direita para a esquerda, o que garante a equival\u00eancia serial da execu\u00e7\u00e3o. Contudo, o modelo de transa\u00e7\u00f5es usado at\u00e9 agora, em que o conjunto de opera\u00e7\u00f5es \u00e9 sempre executado at\u00e9 o fim, n\u00e3o corresponde \u00e0 realidade. Precisamos adicionar a este modelo a possibilidade da transa\u00e7\u00e3o ser abortada , isto \u00e9, ter seus efeitos revertidos. Sob este novo modelo, considere o seguinte exemplo, onde a transa\u00e7\u00e3o da direita \u00e9 abortada. T1(a,b) T1(c,b) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sB = R(b)\\) \\(W(b)sB*1.1\\) \\(sC = R(c)\\) \\(W(c)sC-sB*0.1\\) \\(sA = R(a)\\) \\(W(a)sA-sB*0.1\\) aborte! Apesar das opera\u00e7\u00f5es serem ordenadas da direita para a esquerda, houve um dirty read na execu\u00e7\u00e3o da transa\u00e7\u00e3o da esquerda. Uma forma de pensar em como isso aconteceu, \u00e9 considerar que o aborte! \u00e9 uma opera\u00e7\u00e3o que toca todos os dados usados pela transa\u00e7\u00e3o abortada. Assim, o aborte! conflita com as leituras de \\(b\\) e de \\(a\\) feitas pela transa\u00e7\u00e3o da esquerda e, portanto, houve uma viola\u00e7\u00e3o na ordem de execu\u00e7\u00e3o das opera\u00e7\u00f5es. Para que este dirty read n\u00e3o leve a inconsist\u00eancias, a transa\u00e7\u00e3o da esquerda deve tamb\u00e9m abortar. Esta estrat\u00e9gia pode ser implementada da seguinte forma: se uma transa\u00e7\u00e3o l\u00ea um dado atualizado por uma transa\u00e7\u00e3o n\u00e3o comitada, suspenda a transa\u00e7\u00e3o executando a leitura. se transa\u00e7\u00e3o que atualizou o dado foi abortada, todas as suspensas que leram dela devem ser abortadas. repita passo anterior. Graficamente, podemos ver o exemplo acima assim, tanto no caso de commit quando de abort da segunda transa\u00e7\u00e3o. Apesar de correta, esta abordagem tem um caso patol\u00f3gico que leva a abortos em Cascata : se T1 l\u00ea algo que T2 escreveu, e T2 l\u00ea algo que T3 escreveu, e assim por diante, se a \u00faltima transa\u00e7\u00e3o nesta cadeia de depend\u00eancias for abortada, todas dever\u00e3o ser abortadas. Mas, e se evitarmos dirty reads em vez de tratarmos? Podemos faz\u00ea-lo com a seguinte estrat\u00e9gia: quando um transa\u00e7\u00e3o T1 tenta ler um dado \"sujo\" escrito por T2, suspenda a execu\u00e7\u00e3o da transa\u00e7\u00e3o T1, antes da leitura acontecer. quando transa\u00e7\u00e3o T2 for terminada, continue a execu\u00e7\u00e3o de T1. O que estamos tentando obter aqui \u00e9 uma execu\u00e7\u00e3o estrita , ou seja, uma execu\u00e7\u00e3o em que Leituras e Escritas devem ser atrasadas at\u00e9 que todas as transa\u00e7\u00f5es anteriores que contenham escritas nos mesmos dados sejam \"comitadas\" ou abortadas. Execu\u00e7\u00f5es estritas garante Isolamento, contudo, levam a menor concorr\u00eancia, j\u00e1 que transa\u00e7\u00f5es ficam suspensas. Fica ent\u00e3o a pergunta: como implementar execu\u00e7\u00f5es estritas eficientes ? A resposta est\u00e1 no controle de concorr\u00eancia das transa\u00e7\u00f5es.","title":"Equival\u00eancia Serial"},{"location":"disdb/#controle-de-concorrencia","text":"Consideremos tr\u00eas abordagens de controle de concorr\u00eancia usadas por bancos de dados: locking: abordagem pessimista que paga um alto pre\u00e7o de sincroniza\u00e7\u00e3o mesmo quando as transa\u00e7\u00f5es n\u00e3o interferem umas nas outras. multi-vers\u00e3o: abordagem otimista, que tem algo custo quando h\u00e1 muitos conflitos entre as transa\u00e7\u00f5es. timestamp: abordagem mais complexa de se implementar.","title":"Controle de Concorr\u00eancia"},{"location":"disdb/#locking","text":"Nesta abordagem, todos os objetos usados por uma transa\u00e7\u00e3o s\u00e3o trancados, impedindo que sejam acessados por outras transa\u00e7\u00f5es, at\u00e9 que sejam destrancados. Contudo, se os objetos s\u00e3o destrancados t\u00e3o logo n\u00e3o sejam mais usados na transa\u00e7\u00e3o, continuamos a ter dirty reads , como a opera\u00e7\u00e3o em vermelho na figura a seguir. Mesmo que se tentasse abortar a transa\u00e7\u00e3o que executou a dirty read , poderia ser tarde demais, como no exemplo a seguir que demonstra uma escrita prematura . Estes problemas podem ser evitados com o uso de strict two phase locking , em que as transa\u00e7\u00f5es trancam o objeto quando primeiro acessado e s\u00f3 destrancam ao final da transa\u00e7\u00e3o , atomicamente com a termina\u00e7\u00e3o. J\u00e1 para aumentar a concorr\u00eancia, \u00e9 poss\u00edvel usar locks para leitura, compartilhados, e para escrita, exclusivos. Read/Write locks dois n\u00edveis de acesso m\u00faltiplos leitores \u00fanico escritor reads por ser transformados em locks writes n\u00e3o podem se transformados em reads (violaria Strict Two-Phase Locking) Ou, ainda, locks com diferentes granularidades; em um banco de dados relacional, por exemplo, pode ser poss\u00edvel obter um lock em uma coluna de uma linha do banco, de toda a linha, de toda a rela\u00e7\u00e3o, ou mesmo de todo o banco de dados. Mas mesmo com estes ajustes, locks deveriam, via de regra, serem evitados sempre que a probabilidade de conflitos for baixa. Isso porqu\u00ea os locks s\u00e3o uma abordagem pessimista , que incorrem em overhead mesmo quando transa\u00e7\u00f5es n\u00e3o acessam os mesmos dados, lembrando que os locks s\u00f3 podem ser liberados no final das transa\u00e7\u00f5es. Evitar locks pessimista overhead mesmo se n\u00e3o h\u00e1 conflitos ou restritivo ou risco de deadlock lock liberado somente no final, para evitar dirty reads/escrita prematura.","title":"Locking"},{"location":"disdb/#multi-versao","text":"Uma alternativa otimista aos locks \u00e9 assumir que n\u00e3o h\u00e1 conflitos nas transa\u00e7\u00f5es enquanto elas executam e, somente ao final da execu\u00e7\u00e3o, testar a validade desta premissa e, caso falhe, abortar a transa\u00e7\u00e3o. O controle de concorr\u00eancia multi-vers\u00e3o (MVCC, do termo em ingl\u00eas) faz isso mantendo uma c\u00f3pia privada dos dados acessados pela transa\u00e7\u00e3o. Ao final da execu\u00e7\u00e3o, na fase de valida\u00e7\u00e3o , se a c\u00f3pia p\u00fablica de onde a privada foi copiada n\u00e3o tiver sido modificada, a transa\u00e7\u00e3o \u00e9 bem sucedida e atualiza\u00e7\u00f5es s\u00e3o feitas nas c\u00f3pias p\u00fablicas. 2 Esta t\u00e9cnica, conhecida como deferred update pois atrasa a atualiza\u00e7\u00e3o da c\u00f3pia p\u00fablica at\u00e9 o final da transa\u00e7\u00e3o, tem como vantagens o baixo overhead , se n\u00e3o houver conflitos. Entretanto, se houver muitos conflitos, o trabalho da transa\u00e7\u00e3o \u00e9 todo desperdi\u00e7ado j\u00e1 que a transa\u00e7\u00e3o ser\u00e1 abortada na valida\u00e7\u00e3o . A valida\u00e7\u00e3o consiste em verificar se os read e write sets de quaisquer transa\u00e7\u00f5es concorrentes s\u00e3o disjuntos, isto \u00e9, se dados transa\u00e7\u00f5es \\(t1\\) e \\(t2\\) : t1 n\u00e3o deve ler dados escritos por t2 t2 n\u00e3o deve ler dados escritos por t1 t1/t2 n\u00e3o deve escrever dados escritos por t2/t1 Na imagem a seguir, a transa\u00e7\u00e3o preta precisa ser validada ou frente \u00e0s transa\u00e7\u00f5es concorrentes vermelhas, j\u00e1 comitadas, ou \u00e0s azuis, ainda por comitar. No caso da valida\u00e7\u00e3o com transa\u00e7\u00f5es j\u00e1 comitadas ( backward validation ) a valida\u00e7\u00e3o pode ser simplificada assim: t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o j\u00e1 comitada. t1 n\u00e3o deve ler dados escritos por t2 Se a valida\u00e7\u00e3o for com as transa\u00e7\u00f5es ainda em execu\u00e7\u00e3o ( forward validation ) a regra passa a ser: t1: transa\u00e7\u00e3o sendo validada t2: transa\u00e7\u00e3o ainda em execu\u00e7\u00e3o t2 n\u00e3o deve ler dados escritos por t1 \u00c9 preciso destacar que a forward validation pode levar a um cen\u00e1rio em que nenhuma transa\u00e7\u00e3o \u00e9 jamais comitada, pois uma cascata de aborts pode ocorrer.","title":"Multi-vers\u00e3o"},{"location":"disdb/#timestamping","text":"Uma terceira forma de controlar a concorr\u00eancia associando uma ordem l\u00f3gica para a execu\u00e7\u00e3o das transa\u00e7\u00f5es, de acordo com o in\u00edcio das transa\u00e7\u00f5es. Isto \u00e9 feito atribuindo-se um timestamp a cada transa\u00e7\u00e3o e garantindo-se que a execu\u00e7\u00e3o das transa\u00e7\u00f5es seja \u00e9 equivalente \u00e0 execu\u00e7\u00e3o serial de acordo com os timestamps. 3 transa\u00e7\u00e3o recebe um timestamp no in\u00edcio opera\u00e7\u00f5es s\u00e3o validadas na execu\u00e7\u00e3o leia somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver escrito e comitado escreva somente se nenhuma transa\u00e7\u00e3o com maior timestamp tiver lido e comitado transa\u00e7\u00f5es \"executam na ordem do timestamp\" Como implementar?","title":"Timestamping"},{"location":"disdb/#como-implementar","text":"objetos tem valores tentativos , n\u00e3o comitados objetos tem vers\u00f5es em que foram escritos em que foram comitados e em que foram lidos consist\u00eancia \u00e9 testado na execu\u00e7\u00e3o da opera\u00e7\u00e3o","title":"Como implementar"},{"location":"disdb/#como-implementar-escrita","text":"escritas tem sucesso somente se vers\u00e3o sendo escrita \u00e9 maior que vers\u00f5es lidas se vers\u00e3o sendo escrita \u00e9 menor que vers\u00e3o j\u00e1 escrita, ignore e continue","title":"Como implementar -- escrita"},{"location":"disdb/#como-implementar-leitura","text":"leitura com vers\u00e3o v tem sucesso se maior vers\u00e3o \u00e9 comitada e menor que v ou alguma n\u00e3o comitada leitura com vers\u00e3o v \u00e9 suspensa se maior vers\u00e3o \u00e9 n\u00e3o comitada e menor que v leitura com vers\u00e3o v \u00e9 abortada se maior vers\u00e3o comitada \u00e9 maior que v","title":"como implementar -- leitura"},{"location":"disdb/#bancos-de-dados-distribuidos","text":"Agora que relembramos como transa\u00e7\u00f5es funcionam e temos uma no\u00e7\u00e3o de como podem ser implementadas em um sistema centralizado, vamos tentar entender como faz\u00ea-lo em um sistema distribu\u00eddo. m\u00faltiplos servidores transa\u00e7\u00f5es em cada servidor transa\u00e7\u00f5es distribu\u00eddas como obter equival\u00eancia serial em transa\u00e7\u00f5es distribu\u00eddas","title":"Bancos de dados distribu\u00eddos"},{"location":"disdb/#transacao-distribuida","text":"begintransaction(): tid (transaction id) operation(tid,op) endtransaction(tid): ok/nok aborttransaction(tid) Temos v\u00e1rios pap\u00e9is sendo desempenhados aqui: cliente servidor: resource managers servidor: transaction monitor/manager Localmente, cada bd funciona como um sistema centralizado normal, usando abordagens otimistas ou pessimista para garantir consist\u00eancia. O grande problema no bd distribu\u00eddo \u00e9 garantir o acordo na termina\u00e7\u00e3o.","title":"Transa\u00e7\u00e3o distribu\u00edda"},{"location":"disdb/#comprometimento-distribuido","text":"O problema... transa\u00e7\u00e3o \\(t\\) acessa recursos nos resource managers (rm) terminar com sucessos \\(t\\) em todos os rm - commit - ou abortar \\(t\\) em todos os rm ainda que enlaces de comunica\u00e7\u00e3o, n\u00f3s e rm falhem, antes ou durante a termina\u00e7\u00e3o da transa\u00e7\u00e3o. participante -- resource manager \"tocados\" pela transa\u00e7\u00e3o coordenador -- transaction manager Cliente decide quando iniciar o commit. Cada participante faz commit ou abort da transa\u00e7\u00e3o local. pode retornar ok ou nok. Coordenador n\u00e3o come\u00e7a a commit at\u00e9 que a \\(t\\) tenha terminado em todos os participantes e cliente tenha solicitado. Participantes falham por parada.","title":"Comprometimento distribu\u00eddo"},{"location":"disdb/#1pc","text":"cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes \"comitarem\" Mas... e se um participante retornar nok enquanto outros retornam ok? e se um participante n\u00e3o responder?","title":"1PC"},{"location":"disdb/#2pc","text":"cliente envia endtransaction(tid) para o coordenador coordenador envia mensagem para participantes se prepararem para terminar coordenador espera que todos se preparem ou digam se n\u00e3o podem coordenador envia ordem de termina\u00e7\u00e3o","title":"2PC"},{"location":"disdb/#3-pc","text":"Estende o protocolo para permitir contornar falha do coordenador.","title":"3-PC"},{"location":"disdb/#paxos-commit","text":"Usa inst\u00e2ncias de Consenso Distribu\u00eddo para votar. Se o consenso \u00e9 tolerante a falhas e consistente, todos v\u00eaem o mesmo resultado na transa\u00e7\u00e3o.","title":"Paxos-Commit"},{"location":"disdb/#log-structured-merge-trees","text":"Idealmente, toda manipula\u00e7\u00e3o de dados seria executada a partir da mem\u00f3ria principal, tendo assim a menor lat\u00eancia poss\u00edvel. Contudo, para que se tenha tamb\u00e9m durabilidade das opera\u00e7\u00f5es executadas, para que os dados manipulados sobrevivam a reinicializa\u00e7\u00f5es do servidor, intencionais ou n\u00e3o, \u00e9 preciso armazenar os dados em mem\u00f3ria est\u00e1vel , da qual a mais comum s\u00e3o os discos r\u00edgidos . Bancos de dados relacionais tradicionalmente armazenam seus dados em disco usando estruturas em \u00e1rvore, pois estas tem custo amortizado de leitura e escrita \\(O(log n)\\) . Bancos de dados NoSQL, muito usados em cen\u00e1rios de Big Data , em que quantidades muito grandes de dados s\u00e3o geradas e acessadas com grande velocidade, capitanearam um esfor\u00e7o para otimizar opera\u00e7\u00f5es de escrita enquanto tamb\u00e9m tentando n\u00e3o aumentar significativamente os tempos de leitura. \u00c9 not\u00f3rio que opera\u00e7\u00f5es em disco s\u00e3o muito mais lentas que em mem\u00f3ria principal, mas o que exatamente \u00e9 lento no acesso ao disco? Essencialmente, o posicionamento da cabeca de leitura/escrita na trilha correta do disco, pois esta opera\u00e7\u00e3o \u00e9 mec\u00e2nica. Por esta raz\u00e3o, acessos aleat\u00f3rios s\u00e3o mais custosos que acessos sequenciais, pois neste o custo de posicionamento \u00e9 pago apenas uma vez. Alguns bancos de dados, como o Cassandra, armazenam os dados na forma de uma Log Structured Merge Tree , ou LSMT, que acessa o disco quase que exclusivamente de forma sequencial, minimizando assim o impacto da durabilidade no desempenho do sistema. Considere um banco armazenando uma pequena quantidade de dados, que cabe em mem\u00f3ria principal Usando LSMT, os dados s\u00e3o mantidos em mem\u00f3ria principal em estruturas de dados denominadas memory table , ou simplesmente memtables . Opera\u00e7\u00f5es de escrita s\u00e3o \"logadas\" e um commit log , em disco, antes de serem aplicadas \u00e0s memtables e confirmadas para o cliente. Neste cen\u00e1rio o acesso ao disco na escrita \u00e9 sequencial, o melhor que se pode ter em um disco, e a recupera\u00e7\u00e3o dos dados \u00e9 feita diretamente da mem\u00f3ria, rapidamente. No caso de uma reinicializa\u00e7\u00e3o do processo, a reexecu\u00e7\u00e3o do commit log restaurar\u00e1 o estado da memtable. Observe que a leitura do commit log \u00e9 sequencial, o que acelera a reexecu\u00e7\u00e3o. Ainda assim, se o commit log for extenso, reexecut\u00e1-lo demandar\u00e1 um tempo significativo. Uma forma de acelerar o processo \u00e9 fazer snapshots da memtable de forma sincronizada com a escrita no log. Isto \u00e9, digamos que todas as opera\u00e7\u00f5es de escrita, at\u00e9 a d\u00e9cima, est\u00e3o salvas no commit log e refletidas na memtable. Digamos tamb\u00e9m que todas as opera\u00e7\u00f5es s\u00e3o modifica\u00e7\u00f5es da mesma linha do banco de dados em mem\u00f3ria. Se um snapshot \u00e9 tomado, ele ser\u00e1 correspondente ao commit log, isto \u00e9, conter\u00e1 o efeito de exatamente as mesmas 10 opera\u00e7\u00f5es, mas de forma mais compacta que o log, uma vez que o log conter\u00e1 dez opera\u00e7\u00f5es e o snapshot somente uma linha de dados. Ap\u00f3s o snapshot ser conclu\u00eddo, o log correspondente pode ser apagado, assim como snapshots anteriores. Novas opera\u00e7\u00f5es de escrita devem ser armazenadas em um novo log e, no caso de uma reinicializa\u00e7\u00e3o, primeiro se deve restaurar o snapshot e ent\u00e3o o novo log. Para lidar com corrup\u00e7\u00f5es de arquivo no sistema, pode ser uma boa ideia manter mais do que o \u00faltimo log e snapshot , j\u00e1 que a recupera\u00e7\u00e3o do estado exigiria voltar mais atr\u00e1s na reexecu\u00e7\u00e3o de opera\u00e7\u00f5es. Observe que, al\u00e9m da escrita dos logs, todos os outros acessos ao disco tamb\u00e9m s\u00e3o sequenciais, seja o flush das memtables, ou a leitura dos snapshots para recupera\u00e7\u00e3o e do commit log para reexecu\u00e7\u00e3o e, j\u00e1 que opera\u00e7\u00f5es de leitura s\u00e3o todas respondidas da mem\u00f3ria, o sistema ter\u00e1 um excelente desempenho. Contudo, h\u00e1 outro limitante de desempenho importante, relacionado \u00e0 premissa pouco realista de que os dados cabem todos em mem\u00f3ria. Isto \u00e9, se os dados n\u00e3o cabem em mem\u00f3ria, snapshots ser\u00e3o importantes n\u00e3o somente para permitir coletar lixo dos logs, isto \u00e9, dados obsoletos, mas tamb\u00e9m, para usar a capacidade de armazenamento dos discos. Consideremos ent\u00e3o um cen\u00e1rio em que a memtable cabe apenas n entradas; quando a opera\u00e7\u00e3o para adicionar \\(n+1\\) -\u00e9sima entrada \u00e0 memtable \u00e9 recebida, um flushs dos dados para um novo snapshot \u00e9 feito e a memtable \u00e9 resetada , liberando espa\u00e7o em mem\u00f3ria. Para melhorar o desempenho, estas descargas podem ser feitas proativamente antes da chegada de novas entradas e fora do caminho cr\u00edtico da opera\u00e7\u00e3o de escrita, mas isto \u00e9 apenas uma otimiza\u00e7\u00e3o e portanto n\u00e3o a consideraremos aqui. Neste novo fluxo, os arquivos em disco n\u00e3o correspondem mais a snapshots do banco de dados mas a por\u00e7\u00f5es dos dados, ent\u00e3o nos referiremos a eles como stable storage tables , ou sstables , em oposi\u00e7\u00e3o \u00e0s memtables , pelo menos por enquanto.","title":"Log Structured Merge Trees"},{"location":"disdb/#compactacoes","text":"Apesar deste novo fluxo de escrita aumentar a capacidade de armazenamento do nosso banco de dados, ele traz problemas para o fluxo de leitura. Digamos que a chave \\(k\\) teve um valor atribu\u00eddo e descarregado em uma sstable em diversas ocasi\u00f5es. O primeiro problema aqui \u00e9 que h\u00e1 v\u00e1rios valores antigos associados a \\(k\\) , inutilmente e ocupando espa\u00e7o, isto \u00e9, lixo. O segundo \u00e9 que caso o valor associado a \\(k\\) seja requisitado, o sistema dever\u00e1 retornar a \u00faltima vers\u00e3o, que pode estar em diversos arquivos. Para lidar com ambos os problemas, podemos compactar as sstables juntas, eliminados dados obsoletos e minimizando o n\u00famero de arquivos a serem pesquisados no caso de leitura. Caso a sstables estejam ordenadas, o procedimento de compacta\u00e7\u00e3o pode ser feito como a uni\u00e3o de dois segmentos de dados no merge sort , isto \u00e9, iterando-se paralelamente nos dois arquivos e escolhendo sempre a menor chave da vez e movendo-a para um novo segmento que conter\u00e1 a uni\u00e3o dos dados. A figura a seguir mostra um exemplo que v\u00e1rias sstables de n\u00edvel 0, aquelas geradas por flushs , s\u00e3o unidas gerando sstables de n\u00edvel 1 e assim sucessivamente. Observe como as compacta\u00e7\u00f5es geram uma \u00e1rvore (na verdade, uma floresta), raz\u00e3o do nome merge tree . No caso de uma leitura, somente as tabelas mais \u00e0 direita e de n\u00edvel mais alto precisam ser consultadas e portanto as sstables j\u00e1 usadas como entrada podem ser eliminadas como lixo do sistema. Ainda assim , no caso de uma leitura, diversas sstables potencialmente cont\u00e9m o dado a ser retornado. O problema se agrava em sistemas em que partes do dado possam ser gravadas independentemente, como no CassandraDB, em que cada coluna \u00e9 independente das outras. Diversas propostas poderiam ser feitas para se identificar mais rapidamente se uma sstable cont\u00e9m uma chave . Por exemplo, pode-se associar a cada tabela um bitmap indicando a presen\u00e7a ou n\u00e3o de uma certa chave, mas esta abordagem obviamente falha se o espa\u00e7o de chaves for grande. Outra possibilidade \u00e9 lembrar a faixa de chaves contida na tabela. Esta estrat\u00e9gia pode ser \u00fatil caso haja localidade no espa\u00e7o de chaves no momento da escrita, mas falhar\u00e1 miseravelmente se o espa\u00e7o de chaves for usado uniformemente, resultando em faixas grandes entre a menor e maior chaves de cada tabela. Como acelerar a identifica\u00e7\u00e3o das sstables pertinentes? Entram em cena os filtros de Bloom .","title":"Compacta\u00e7\u00f5es"},{"location":"disdb/#filtros-de-bloom","text":"De acordo com nossa fonte mais que confi\u00e1vel, a Wikipedia Bloom Filter A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not, thus a Bloom filter has a 100% recall rate. In other words, a query returns either \"possibly in set\" or \"definitely not in set\" . Se associarmos a cada sstable um filtro de Bloom, ent\u00e3o s\u00f3 ser\u00e1 preciso l\u00ea-la se o filtro correspondente disser que a chave possivelmente est\u00e1 contida, como no seguinte exemplo. Mas como exatamente constru\u00edmos um filtro de Bloom? Iniciamos com um vetor de bits inicialmente zerados e um conjunto finito de fun\u00e7\u00f5es de hash cujo resultado seja uniformemente distribu\u00eddo no tamanho do vetor de bits. Para cada elemento colocado no conjunto a ser refletido pelo filtro, aplicamos cada uma das fun\u00e7\u00f5es hash e colocamos o bit 1 na posi\u00e7\u00e3o do vetor igual ao resultado da fun\u00e7\u00e3o . No exemplo a seguir, inserimos os elementos x, y e z e usamos tr\u00eas fun\u00e7\u00f5es hash. Na consulta , cada elemento passa por pelas mesmas fun\u00e7\u00f5es hash para identificar quais bits do vetor ler. Se algum dos \u00edndices apontados n\u00e3o estiver com um 1, como no caso do c, no exemplo, o elemento n\u00e3o pertence ao conjunto. Caso contr\u00e1rio, o filtro responder\u00e1 que \u00e9 poss\u00edvel que perten\u00e7a. Mas qu\u00e3o bom \u00e9 um filtro de Bloom na identifica\u00e7\u00e3o do das sstables? O filtro ser\u00e1 melhor se os bits 1 forem devidos a menos elementos mapeando para tal posi\u00e7\u00e3o, pois se muitos elementos mapearem para a mesma posi\u00e7\u00e3o, falsos positivos podem ocorrer. Assim, de outra forma, quais fatores influenciam na taxa de falsos positivos do filtro? o n\u00famero \\(n\\) de elementos no conjunto, uma vez que quanto mais elementos, mais bits 1 no vetor; o n\u00famero \\(k\\) de hashes, pois quanto mais hashes, mais bits transformados em 1; e, o n\u00famero \\(m\\) de bits no vetor, pois quanto menos bits, mais colis\u00f5es de bits. De forma mais precisa, a probabilidade de setar um certo bit na inser\u00e7\u00e3o de um elemento \u00e9 \\(1/m\\) , e a probabilidade de n\u00e3o setar tal bit \u00e9 \\(1 - 1/m\\) ; a probabilidade de \\(k\\) hashes n\u00e3o setarem um bit \u00e9 \\((1 - 1/m)^k\\) ; a probabilidade de n\u00e3o setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\((1 - 1/m)^{kn}\\) ; a probabilidade de setar um bit ap\u00f3s \\(n\\) inser\u00e7\u00f5es \u00e9 \\(1 - (1 - 1/m)^{kn}\\) Logo, a probabilidade de falso positivo \\(p = (1 - (1 - 1/m)^{kn})^k \\approx (1 - e^{-kn/m})^k\\) O que nos permite chegar \u00e0 rela\u00e7\u00e3o \\(m/n = - 1.44\\log_2 p\\) , em que podemos calcular \\(m\\) em fun\u00e7\u00e3o do \\(n\\) esperado e do \\(p\\) desejado. E podemos tamb\u00e9m identificar o \\(k\\) \u00f3timo para a situa\u00e7\u00e3o, pela equa\u00e7\u00e3o \\(k = - \\frac{\\ln p}{\\ln 2} = - \\log_2 p\\) Uma forma \"simples\" de visualizar este resultado \u00e9 dada pela figura a seguir, em que o eixo Y d\u00e1 a taxa de falsos positivos do filtro em fun\u00e7\u00e3o do n\u00famero de elementos inseridos, indicado no eixo X, para diversas configura\u00e7\u00f5es, apresentadas como curvas. Por exemplo, com um filtro com \\(m = 2^{24}b = 2MB\\) , ap\u00f3s 1 milh\u00e3o de inser\u00e7\u00f5es, tem-se probabilidade de falsos positivo \\(p = 0,0001\\) . TODO Combinar https://adambcomer.com/blog/simple-database/motivation-design.html https://adambcomer.com/blog/simple-database/memtable.html https://adambcomer.com/blog/simple-database/wal.html https://www.jasondavies.com/bloomfilter/","title":"Filtros de Bloom"},{"location":"disdb/#cap","text":"CAP theorem NoSQL database types Weak Consistency and CAP Implications","title":"CAP"},{"location":"disdb/#base","text":"TODO Incluir explica\u00e7\u00e3o","title":"BASE"},{"location":"disdb/#referencias","text":"Balancing Strong and Eventual Consistency with Datastore https://blog.yugabyte.com/a-primer-on-acid-transactions/ https://jepsen.io/consistency https://fauna.com/blog/demystifying-database-systems-part-4-isolation-levels-vs-consistency-levels https://www.postgresql.org/docs/9.5/transaction-iso.html Inspirado nas notas de aula de Johan Montelius e Vladimir Vlassov, da disciplina ID2201 Distributed Systems, KTH Royal Institute of Technology. Imagens copiadas descaradamente de seus slides em https://www.kth.se/social/files/57c2cbd7f276541680e39e6d/transactions.pdf https://www.cs.ucy.ac.cy/~dzeina/courses/epl446/lectures/16.pdf https://www.cs.princeton.edu/courses/archive/fall18/cos418/docs/p8-consistency.pdf https://aphyr.com/posts/313-strong-consistency-models Modern Algorithms and Data Structures: Bloom-Filter Consist\u00eancia no sentido visto no cap\u00edtulo anterior, n\u00e3o no sentido ACID. \u21a9 Na pr\u00e1tica, a atualiza\u00e7\u00e3o consiste apenas em mudar um ponteiro para apontar para a c\u00f3pia privada. \u21a9 Baseado no material dispon\u00edvel em Distributed Systems, Basic Course . \u21a9","title":"Refer\u00eancias"},{"location":"disfs/","text":"Sistemas de Arquivos Distribu\u00eddos Leitura Sistemas Distribu\u00eddos: princ\u00edpios e paradigmas, 2a edi\u00e7\u00e3o. Cap\u00edtulo 11: Sistemas de Arquivos Distribu\u00eddos. Distributed Systems: Concepts and Designs. Cap\u00edtulo 12: Distributed File Systems. Google File System Google file system Google, 2003 File System Dados recuperados da Internet usados em consultas Milh\u00f5es de arquivos de m\u00faltiplos GB Chunks de 64MB (``blocos do disco'') Opera\u00e7\u00f5es comuns s\u00e3o appends ou reads Servidores/discos/mem\u00f3rias est\u00e3o sempre falhando Centenas de clientes concorrentes no mesmo arquivo Clusters de n\u00f3s ``comuns'' Master node: metadata Chunk servers: data Permite usar um cluster como um \u00fanico HD el\u00e1stico na rede. Fonte Apps recebem \\emph{leases} de acesso direto aos dados Atomic commitment garante consist\u00eancia entre r\u00e9plicas Fonte Consist\u00eancia Application sends the file name and data to the GFS client. GFS Client send the file name and chunk index to master Master sends the identity of the primary and other secondary replicas to the client. Client caches this information. Client contacts master again only when primary is unreachable or it sends a reply saying it does not holds the lease anymore. Considering the network topology the client sends the data to all the replicas.This improves performance. GFS separates data flow from the control flow. Replicas store the data in their LRU buffers till it is used. After all replicas receiving of the data, client sends write request to the primary. Primary decides the mutation order. It applies this order to its local copy. Primary sends the write request to all the secondary replicas. They perform write according to serial order decided by the primary. After completing the operation all secondary acknowledge primary. Primary replies the client about completion of the operation. In case of the errors that is when some of the secondary fail to write client request is supposed to be fail.This leaves modified chunk inconsistent. Client handles this by retrying the failed mutation. Fonte","title":"Sistemas de Arquivos"},{"location":"disfs/#sistemas-de-arquivos-distribuidos","text":"","title":"Sistemas de Arquivos Distribu\u00eddos"},{"location":"disfs/#leitura","text":"Sistemas Distribu\u00eddos: princ\u00edpios e paradigmas, 2a edi\u00e7\u00e3o. Cap\u00edtulo 11: Sistemas de Arquivos Distribu\u00eddos. Distributed Systems: Concepts and Designs. Cap\u00edtulo 12: Distributed File Systems.","title":"Leitura"},{"location":"disfs/#google-file-system","text":"Google file system Google, 2003 File System Dados recuperados da Internet usados em consultas Milh\u00f5es de arquivos de m\u00faltiplos GB Chunks de 64MB (``blocos do disco'') Opera\u00e7\u00f5es comuns s\u00e3o appends ou reads Servidores/discos/mem\u00f3rias est\u00e3o sempre falhando Centenas de clientes concorrentes no mesmo arquivo Clusters de n\u00f3s ``comuns'' Master node: metadata Chunk servers: data Permite usar um cluster como um \u00fanico HD el\u00e1stico na rede. Fonte Apps recebem \\emph{leases} de acesso direto aos dados Atomic commitment garante consist\u00eancia entre r\u00e9plicas Fonte Consist\u00eancia Application sends the file name and data to the GFS client. GFS Client send the file name and chunk index to master Master sends the identity of the primary and other secondary replicas to the client. Client caches this information. Client contacts master again only when primary is unreachable or it sends a reply saying it does not holds the lease anymore. Considering the network topology the client sends the data to all the replicas.This improves performance. GFS separates data flow from the control flow. Replicas store the data in their LRU buffers till it is used. After all replicas receiving of the data, client sends write request to the primary. Primary decides the mutation order. It applies this order to its local copy. Primary sends the write request to all the secondary replicas. They perform write according to serial order decided by the primary. After completing the operation all secondary acknowledge primary. Primary replies the client about completion of the operation. In case of the errors that is when some of the secondary fail to write client request is supposed to be fail.This leaves modified chunk inconsistent. Client handles this by retrying the failed mutation. Fonte","title":"Google File System"},{"location":"intro/","text":"Introdu\u00e7\u00e3o Escrever bons sistemas distribu\u00eddos \u00e9 uma tarefa que esbarra em diversos obst\u00e1culos, sendo a defini\u00e7\u00e3o do que \u00e9 um sistema distribu\u00eddo e do que \u00e9 ser \"bom\" neste contexto sendo nossos primeiros obst\u00e1culos. O qu\u00ea s\u00e3o Sistemas Distribu\u00eddos? Sistemas simples Para atacarmos a primeira quest\u00e3o e entendermos o que \u00e9 um Sistema Distribu\u00eddo, talvez seja mais f\u00e1cil come\u00e7ar pelo que n\u00e3o \u00e9 um sistema n\u00e3o-distribu\u00eddo. Estes s\u00e3o os sistemas que cont\u00e9m em um \u00fanico processo toda a l\u00f3gica de neg\u00f3cio, armazenamento e interface com usu\u00e1rio, mesmo que sejam divididos em v\u00e1rios m\u00f3dulos e usem diferentes bibliotecas e frameworks . Sejam estes sistemas constru\u00eddo com blocos que se encaixam perfeitamente, disponibilizados basicamente pela biblioteca da linguagem que est\u00e1 utilizando; Sistemas n\u00e3o t\u00e3o simples ou desenvolvido por times com diversas pessoas e usando bibliotecas de muitos fornecedores diferentes, aumentando consideravelmente a complexidade do desenvolvimento; o resultado, contudo, continua sendo um artefato s\u00f3, executado como um \u00fanico processo, e por isso os denominaremos sistemas monol\u00edtico . 1 Programar sistemas distribu\u00eddos \u00e9 dar outro salto em complexidade, pois frequentemente temos que usar pe\u00e7as que n\u00e3o foram pensadas para trabalhar juntas, for\u00e7ando-nos a usar um pouco de super-cola e arame. Cable hell! Bem, na verdade, em vez de cola usamos middleware , como logo discutiremos, e, em vez de arame, usamos cabos de rede, o que \u00e9, de fato, a principal caracter\u00edstica de um sistema distribu\u00eddo em rela\u00e7\u00e3o a um n\u00e3o-distribu\u00eddo: separa\u00e7\u00e3o e dispers\u00e3o de suas partes em v\u00e1rios componentes independentes (processos, sensores, atuadores, etc), mas que se coordenam para execu\u00e7\u00e3o de alguma tarefa. Vejamos alguns exemplos de tarefas executadas por sistemas distribu\u00eddos, que voc\u00ea usa hoje. Entregue este email para fulano@knowhere.uni . Envie o item I para o endere\u00e7o E, ap\u00f3s cobran\u00e7a de D dinheiros da conta C. Em um ambiente de simula\u00e7\u00e3o de batalhas em 3D, simule o disparo de um proj\u00e9til na dire\u00e7\u00e3o em que o o avatar est\u00e1 olhando, com velocidade V, enquanto movimenta o avatar A para a esquerda com velocidade W. Autorize a transfer\u00eancia de D dinheiros da conta C para a conta C'. Movimente o bra\u00e7o mec\u00e2nico que est\u00e1 segurando um bisturi, 3cm \u00e0 direita, ent\u00e3o abaixe-o 3mm, e movimente-o 4cm para a esquerda Inclua o coment\u00e1rio ``LOL!!!'' na lista de coment\u00e1rios do item XYZ, com marca de tempo T Leia o valor do sensor de temperatura T e, caso seu valor supere V, emita alarme luminoso vermelho intermitente e alarme sonoro Fica claro por estes exemplos que h\u00e1 comunica\u00e7\u00e3o entre diversos componentes, por exemplo o console de videogame e um servi\u00e7o que mantem uma \"sala\" aberta para um jogo. Assim, uma poss\u00edvel defini\u00e7\u00e3o de Sistema Distribu\u00eddo, que me agrada, \u00e9 a seguinte: Sistema Distribu\u00eddo Cole\u00e7\u00e3o de sistemas computacionais (software ou hardware), independentes mas com alguma forma de comunica\u00e7\u00e3o , que colaboram na execu\u00e7\u00e3o de alguma tarefa . Componentes hospedeiro n\u00f3 No jarg\u00e3o da \u00e1rea, os componentes independentes s\u00e3o denominados n\u00f3s . Frequentemente, cada n\u00f3 do sistema ser\u00e1, na pr\u00e1tica, um processo em um computador hospedeiro, um host , para que possa fazer uso de todos os recursos do hospedeiro e, por isso, frequentemente nos referimos ao pr\u00f3prio host como o n\u00f3. Contudo, nada impede que possivelmente m\u00faltiplos n\u00f3s possam ser executados em um mesmo host ou mesmo que m\u00faltiplos hosts virtuais, sejam m\u00e1quinas virtuais ou containers, executem na mesma m\u00e1quina f\u00edsica; isso n\u00e3o muda o fato de que os componentes s\u00e3o independentes e poderiam ser distanciados. 2 Comunica\u00e7\u00e3o mem\u00f3ria compartilhada mensagens Quanto \u00e0 comunica\u00e7\u00e3o, os n\u00f3s podem compartilhar um espa\u00e7o de endere\u00e7amento comum, seja porqu\u00ea est\u00e3o co-locados no mesmo hospedeiro ou seja porqu\u00ea tem acesso a alguma forma de mem\u00f3ria compartilhada distribu\u00edda, que veremos mais adiante. Eles tamb\u00e9m podem se comunicar por mensagens trocadas via uma rede de comunica\u00e7\u00e3o, como a Internet. Quanto \u00e0 tarefa em comum, veja o seguinte exemplo, em que v\u00e1rios clientes trocam emails por meio de uma m\u00e1quina com a qual se comunicam para entregar mensagens a serem enviadas e receber mensagens a eles destinadas; enquanto aguardam a entrega, mensagens s\u00e3o armazenadas em um Sistema Gerenciador de Banco de Dados (SGBD) em uma outra m\u00e1quina, da qual os usu\u00e1rios n\u00e3o tem ci\u00eancia. Depend\u00eancia ao colaborarem, criam depend\u00eancia quando um funciona, outros podem funcionar quando um para, outros param Neste exemplo, cada celular, o processo que implementa o servi\u00e7o de email e o servidor de banco de dados, s\u00e3o n\u00f3s do sistema. Observe que o n\u00f3 do servi\u00e7o de email \u00e9 respons\u00e1vel por receber os emails e encaminh\u00e1-los para o banco em um sentido, bem como ler emails do banco e entregar para os destinat\u00e1rios, no outro. Observe tamb\u00e9m que se o banco de dados para de funcionar, o servi\u00e7o de email passa a ser in\u00fatil, uma vez que n\u00e3o pode armazenar novas mensagens e nem recuperar mensagens j\u00e1 armazenadas. Neste contexto, uma descri\u00e7\u00e3o c\u00ednica mas definitivamente realista \u00e9 a de Leslie Lamport , que certa vez disse: A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable. Lamport est\u00e1 correto quanto aos problemas em sistemas distribu\u00eddos, e problemas podem se manifestar em diversas formas. Por exemplo, mesmo que um computador n\u00e3o pare, se ele ficar lento ou se o canal de comunica\u00e7\u00e3o n\u00e3o for confi\u00e1vel, uma aplica\u00e7\u00e3o cr\u00edtica poderia ser inviabilizada, como no exemplo de telecirurgia acima. Algumas aplica\u00e7\u00f5es, contudo, aparentemente conseguem superar estes obst\u00e1culos. Pensemos em algumas aplica\u00e7\u00f5es distribu\u00eddas com as quais interagimos todos os dias e que, por seu sucesso, devem ser bons sistemas distribu\u00eddos. Alguns exemplos \u00f3bvios s\u00e3o Amazon.com , Facebook , e GMail . Estes sistemas rodam em grandes data centers com milhares de m\u00e1quinas , estando constantemente sujeitos a fontes queimadas, discos corruptos, mem\u00f3rias defeituosas, etc 3 . Apesar disto, dificilmente estes servi\u00e7os s\u00e3o reportados como fora do ar, s\u00e3o altamente respons\u00edveis e, goste ou n\u00e3o do que fazem, s\u00e3o bem sucedidos porqu\u00ea cumprem bem suas tarefas. Assim, digamos que um sistema computacional \u00e9 bom se est\u00e1 sempre funcional, com bom desempenho e \u00e9 de baixo custo. Observe que estar sempre funcional implica em continuar provendo o servi\u00e7o mesmo que partes do sistema estejam com problemas, que ter bom desempenho implica que respostas \"r\u00e1pidas\" s\u00e3o dadas para o usu\u00e1rio, e que baixo custo implica em n\u00e3o gastar mais que o necess\u00e1rio para realizar a tarefa para a qual foi constru\u00eddo. Um \"bom\" sistema Dispon\u00edvel: Sempre funcional Poder computacional: Capacidade de processamento Capacidade de armazenamento Baixa lat\u00eancia Baixo custo Tamanho apropriado \u00e0 tarefa Enquanto subjetiva, nossa defini\u00e7\u00e3o de bom nos permite estabelecer um pano de fundo para delinear as dificuldades de se implementar sistemas distribu\u00eddos. Como veremos adiante, os requisitos para um bom sistema distribu\u00eddo s\u00e3o conflitantes e dif\u00edceis, \u00e0s vezes imposs\u00edveis de serem alcan\u00e7ados. Mas se esta \u00e9 a realidade da programa\u00e7\u00e3o distribu\u00edda, por qu\u00ea faz\u00ea-lo? A resposta tem a ver com a colabora\u00e7\u00e3o , na defini\u00e7\u00e3o. Por qu\u00ea desenvolvemos sistemas distribu\u00eddos? A primeira raz\u00e3o \u00e9 o fato \u00e9 que computadores individuais tem capacidade reduzida de processamento e armazenamento, mas nossa necessidade de poder computacional cresce exponencialmente. Assim, precisamos crescer nosso poder computacional, mas aumentar a capacidade de um dispositivo ( scale up ou vertical scaling ), mesmo de forma linear, tem custo exponencial. O que nos resta ent\u00e3o \u00e9 agregar o poder computacional de diversos computadores \"baratos\" ( scale out ou horizontal scaling ) para satisfazer nossas necessidades. 4 Mesmo se pensarmos que a escala com que estes sistemas trabalham deve ser muito diferente daquela dos sistemas que n\u00f3s desenvolvemos, e portanto as t\u00e9cnicas usadas em sua constru\u00e7\u00e3o devem ser muito distintas do que fazemos, a verdade n\u00e3o poderia ser mais longe disto. Com a quantidade de informa\u00e7\u00e3o armazenada a cada acesso a um s\u00edtio, a cada produto vendido, ou a cada consulta feita, praticamente qualquer sistema de informa\u00e7\u00e3o de sucesso necessitar\u00e1 aplicar as t\u00e9cnicas de computa\u00e7\u00e3o distribu\u00edda e superar as mesmas barreiras para conseguir atender ao n\u00famero crescente de clientes (computacionais ou humanos) e aumentar sua \u00e1rea de cobertura, mesmo que n\u00e3o chegue a escala dos exemplos acima, e melhorar ou manter a qualidade do servi\u00e7o que presta. PQ? escalabilidade toler\u00e2ncia a falhas Este \u00faltimo ponto, sobre qualidade do servi\u00e7o, tem a ver com a capacidade de um sistema se manter no ar a despeito de problemas, isto \u00e9, de ser tolerante a falhas. Toler\u00e2ncia a falhas implica em redund\u00e2ncia, em c\u00f3pias, o que fatidicamente implica em distribui\u00e7\u00e3o e em Sistemas Distribu\u00eddos. Assim, podemos concluir que as principais raz\u00f5es para se desenvolver sistemas distribu\u00eddos s\u00e3o alcan\u00e7ar escalabilidade e toler\u00e2ncia a falhas , ambas resultantes da agrega\u00e7\u00e3o (correta) do poder computacional de m\u00faltiplos componentes. Uma vez que tenhamos entendido o porqu\u00ea de desenvolver sistemas distribu\u00eddos, vejamos que tipos de sistemas resultam desta abordagem. Tipos de Sistemas Distribu\u00eddos H\u00e1 quem diga que j\u00e1 somos todos desenvolvedores de sistemas distribu\u00eddos . Ainda assim, \u00e9 importante entender que h\u00e1 v\u00e1rios tipos de sistemas distribu\u00eddos, com diversas finalidades e diversas arquiteturas, pois classifica\u00e7\u00f5es nos ajudam a pensar sobre sistemas e a encontrar e reusar solu\u00e7\u00f5es previamente testadas e depuradas. Sistemas de Computa\u00e7\u00e3o A possibilidade de agregar poder de processamento de muitos computadores via uma rede de comunica\u00e7\u00e3o com alt\u00edssima largura de banda nos permite atacar problemas computacionalmente muito intensos. Clusters como o da imagem a seguir, do High Performance Computing Center de Stuttgart, s\u00e3o compartilhados por pesquisadores resolvendo problemas de \u00e1reas como bio-inform\u00e1tica, engenharia, economia e intelig\u00eancia artificial. Na engenharia, por exemplo, HPC pode ser usada para testar a efici\u00eancia de projetos sem construir prot\u00f3tipos. Turbina Carro !? Os n\u00f3s de um cluster s\u00e3o normalmente divididos em tr\u00eas categorias: administra\u00e7\u00e3o, computa\u00e7\u00e3o e armazenamento. N\u00f3s de administra\u00e7\u00e3o implementam um monitoramento distribu\u00eddo dos demais n\u00f3s, servem de ponto de entrada para usu\u00e1rios e prov\u00eaem interface para submiss\u00e3o de tarefas, como o Torque, que executa sobre o MOAB. Outro exemplo, o Oscar \u00e9 um conjunto de softwares para gerenciamento de clusters. Uma das ferramentas inclusas no Oscar \u00e9 o OpenPBS, pelo qual tarefas s\u00e3o atribu\u00eddas aos diversos n\u00f3s do sistema que estejam alocados para tal tarefa. O OpenPBS portanto \u00e9 tamb\u00e9m um sistema distribu\u00eddo. Finalmente, as tarefas submetidas em si s\u00e3o tamb\u00e9m aplica\u00e7\u00f5es distribu\u00eddas em que cada processo executando em uma m\u00e1quina distinta \u00e9 respons\u00e1vel por resolver uma parte do problema. Acoplamento Forte Fraco Este tipo de sistemas distribu\u00eddos s\u00e3o o que chamamos de fortemente acoplados pois h\u00e1 grande depend\u00eancia dos componentes uns nos outros, tanto na administra\u00e7\u00e3o quanto na aplica\u00e7\u00e3o, e se um dos componentes para de funcionar, normalmente os outros tamb\u00e9m param. Um outro tipo de sistema, com a mesma finalidade de atacar problemas que exigem muita computa\u00e7\u00e3o mas com componentes fracamente acoplados , s\u00e3o as grades computacionais . Muito usadas at\u00e9 meados da d\u00e9cada passada, neste arranjo, membros de uma associa\u00e7\u00e3o disponibilizam capacidade computacional a um pool . De l\u00e1, os recursos podem ser acessados, seguindo algum crit\u00e9rio de gerenciamento, por quaisquer dos membros da associa\u00e7\u00e3o. Este modelo surgiu de iniciativas como o SETI@home , em que pessoas doavam tempo ocioso do seu computador para analisar sinais de r\u00e1dio recebidos do espa\u00e7o. Ap\u00f3s o sucesso inicial, a computa\u00e7\u00e3o foi movida de computadores de volunt\u00e1rios para os de institui\u00e7\u00f5es com interesses em comum. Computa\u00e7\u00e3o utilit\u00e1ria Fornecimento sob demanda Pagamento proporcional As grades computacionais podem ser vistas como precursoras da computa\u00e7\u00e3o utilit\u00e1ria , isto \u00e9, o fornecimento de recursos computacionais por provedores em troca de um pagamento proporcional \u00e0 quantidade de recursos utilizados, como no fornecimento de \u00e1gua ou eletricidade. A materializa\u00e7\u00e3o recente da computa\u00e7\u00e3o utilit\u00e1ria s\u00e3o as nuvens computacionais. Este tipo de sistema, embora possa ser pensando como infraestrutura para outros sistemas distribu\u00eddos, s\u00e3o, na verdade, complexas pe\u00e7as de engenharia, com diversos subsistemas respons\u00e1veis por sincroniza\u00e7\u00e3o de rel\u00f3gios, monitora\u00e7\u00e3o de falhas, coleta de logs, roteamento eficiente tolerante a falhas, movimenta\u00e7\u00e3o de recursos virtualizados para consolida\u00e7\u00e3o de recursos f\u00edsicos, armazenamento redundante de dados, etc. O seguinte v\u00eddeo mostra, em 360 graus, um dos datacenters do Google, para que voc\u00ea tenha ideia da escala em que estes sistemas s\u00e3o constru\u00eddos. J\u00e1 este outro s\u00edtio apresenta uma viagem fotogr\u00e1fica por alguns datacenters . Sistemas de Informa\u00e7\u00e3o Provavelmente mais comuns entre os profissionais da computa\u00e7\u00e3o, os sistemas de informa\u00e7\u00e3o distribu\u00eddos s\u00e3o encontrados em diversas formas. De fato, o termo \"sistema de informa\u00e7\u00e3o\" \u00e9 t\u00e3o abrangente, que dificilmente um sistema distribu\u00eddo n\u00e3o estaria nesta classe. Seja como for, o seguinte exemplo \u00e9 de uma arquitetura em tr\u00eas camadas, onde a primeira implementa a interface com o usu\u00e1rio, a segunda cont\u00e9m a l\u00f3gica do neg\u00f3cio, e a terceira mantem os dados da aplica\u00e7\u00e3o. Pe\u00e7a fundamental desta abordagem, os bancos de dados na terceira camada s\u00e3o frequentemente distribu\u00eddos. Isto \u00e9, um banco em que v\u00e1rios n\u00f3s mantem os dados e portanto precisam se coordenar para manter os dados consistentes. A figura a seguir mostra um cen\u00e1rio com tr\u00eas bancos; imagine que em um deles est\u00e1 uma rela\u00e7\u00e3o com os dados dos clientes, em outro, os dados do estoque e, no terceiro, as ordens de compra. Quando um cliente faz um pedido, o cliente deve ser validado no primeiro n\u00f3, o item \u00e9 removido do estoque no segundo, e uma cobran\u00e7a \u00e9 disparada para o cliente no terceiro. Se qualquer destas tr\u00eas rela\u00e7\u00f5es n\u00e3o for corretamente consultada e alterada, os efeitos podem ser catastr\u00f3ficos para o neg\u00f3cio ou para o cliente. graph LR B{Aplica\u00e7\u00e3o} B -->|Requisi\u00e7\u00e3o| C[(SGBD 1)] B -->|Requisi\u00e7\u00e3o| D[(SGBD 2)] B -->|Requisi\u00e7\u00e3o| E[(SGBD 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B Como implementar as famosas propriedades ACID neste banco de dados? Embora veremos isso um pouco mais para frente neste material, por enquanto, apenas assuma que n\u00e3o \u00e9 exatamente f\u00e1cil ou barato. Esta dificuldade foi a raz\u00e3o do surgimento dos bancos de dados NOSQL (n\u00e9e NoSQL), dos quais uma pequena amostra \u00e9 dada pela seguinte figura. Tamb\u00e9m discutiremos como estes bancos de dados funcionam, quando falarmos sobre sistemas P2P. Integra\u00e7\u00e3o de Aplica\u00e7\u00f5es Frequentemente \u00e9 necess\u00e1rio integrar sistemas de informa\u00e7\u00e3o legados com sistemas mais modernos, ou simplesmente exp\u00f4-los usando uma interface mais moderna. Nestes casos, \u00e9 poss\u00edvel integrar diversos sistemas usando um middleware que os encapsule. Veremos mais adiante o que \u00e9 um middleware ; por enquanto, pense nele apenas como um camada de software que se interp\u00f5e entre os clientes e um servi\u00e7o oferecido. No exemplo, o middleware pode, por exemplo, se expor via interface REST para os clientes, mas consultar o sistema legado em um padr\u00e3o antigo. Outro exemplo, na imagem seguinte, \u00e9 um sistema que agrega subsistemas de diversos departamentos de uma empresa via troca de mensagens. Observe que nenhum departamento precisa conversar diretamente com os outros, ou mesmo conhec\u00ea-los; eles apenas publicam a mensagem para quem tiver interesse e aguardam um resposta tamb\u00e9m na forma de uma mensagem. Observe que nenhum componente tem que saber da exist\u00eancia do outro ou se torna indispon\u00edvel caso os outros falhem, o que aumenta a escalabilidade do sistema e sua capacidade de tolerar falhas. Sistemas Pervasivos/Ub\u00edquos Sistemas ub\u00edquos tamb\u00e9m s\u00e3o geralmente distribu\u00eddos. Segundo Weiser, 1993 Ubiquitous computing is the method of enhancing computer use by making many computers available throughout the physical environment, but making them effectively invisible to the user. Assim, sistemas ub\u00edquos aumentam e otimizam a intera\u00e7\u00e3o do usu\u00e1rio com o ambiente, para que estes foquem-se na tarefa em vez de na ferramenta. Outra forma de se colocar, \u00e9 que sistemas pervasivos devem ajudar as pessoas a realizar suas tarefas, de forma impl\u00edcita, sem ter que pensar em como a tarefa ser\u00e1 executada. Para que seja realizada, a computa\u00e7\u00e3o pervasiva requer que dispositivos detectem o contexto em que est\u00e3o inseridos, combinem-se de forma ad-hoc e compartilhem informa\u00e7\u00f5es. Exemplos fict\u00edcios e reais Smart Life Esta \u00e9 uma vis\u00e3o futur\u00edstica da Microsoft para a integra\u00e7\u00e3o de tecnologias. Amazon Go Este mercado automatiza o pagamento dos itens escolhidos pelo consumidor, utilizando t\u00e9cnicas de processamento digital de imagens, aprendizado de m\u00e1quina e sensores. Reality Check Para quem viu o filme Minority Report e sonhou com as UI do futuro, aqui vai um reality check . Para quem n\u00e3o viu ainda, corrija esta falha em sua forma\u00e7\u00e3o t\u00e9cnica o mais rapidamente poss\u00edvel. Redes de Sensores e Internet das Coisas Eu vou me arriscar colocando Redes de Sensores e Internet das Coisas como uma subsess\u00e3o de Sistemas Pervasivos. Isto porqu\u00ea, a meu ver, as redes de sensores s\u00e3o parte da infraestrutura para se obter sistemas pervasivos; s\u00e3o os sensores que percebem mudan\u00e7as contexto e \"le\u00eam\" o estado do contexto atual e alimentam outros sistemas que reagem a tal estado. A Internet das Coisas (IoT, do ingl\u00eas Internet of Things ) vai tamb\u00e9m na mesma linha, levando \u00e0 integra\u00e7\u00e3o entre sensores, atuadores, e outros dispositivos que nos servem, em um ambiente de computa\u00e7\u00e3o pervasiva. \"Mas se \u00e9 assim, qual o risco?\", voc\u00ea pergunta. Bem, a Internet das Coisas pode ser vista como algo al\u00e9m dos sistemas pervasivos, pois se estes \u00faltimos s\u00e3o focados nos humanos em um certo contexto, a IoT 6 n\u00e3o necessariamente foca-se nos humanos, mas na realiza\u00e7\u00e3o de alguma tarefa. Por exemplo, um sistema de irriga\u00e7\u00e3o que percebe o n\u00edvel de umidade do ar, analisa previs\u00f5es de chuva e decide em quanto irrigar uma planta\u00e7\u00e3o de laranjas provavelmente n\u00e3o se importar\u00e1 com a presen\u00e7a ou n\u00e3o de um humano na planta\u00e7\u00e3o. Alguns exemplos de IoT e redes de sensores Smart grid e lavadora que escolhe hor\u00e1rio Termostatos que percebem movimento Fechaduras que se abrem quando o dono se aproxima Movimenta\u00e7\u00e3o de tropas e de fauna \u00cdndices de polui\u00e7\u00e3o Abalos s\u00edsmicos e predi\u00e7\u00e3o de avalanches link Uma nota sobre privacidade nos sistemas pervasivos \u00c0 medida em que aumentamos o ambiente ao nosso redor ou a n\u00f3s mesmos com dispositivos computacionais, por um lado facilitamos nossa vida pois somos assistidos por tais dispositivos, mas por outro, nos tornamos cada vez mais dependentes nos mesmos, com s\u00e9rios riscos \u00e0 nossa privacidade. Isto ocorre por que para que realizem suas tarefas, os sistemas pervasivos precisam de cada vez mais informa\u00e7\u00f5es sobre n\u00f3s, e h\u00e1 sempre o risco de que estas informa\u00e7\u00f5es sejam usadas de forma que n\u00e3o nos apetece. Exemplos de hacking em IOT Hackers Can Access Pacemakers, but Don\u2019t Panic Just Yet Ethical hacker shows us how easily smart devices can be hacked and give access to your personal info Your Roomba May Be Mapping Your Home, Collecting Data That Could Be Shared . Refer\u00eancias Neste ponto, devo estressar que muitos se referem a sistemas n\u00e3o-distribu\u00eddos como centralizados mas prefiro reservar este termo para sistemas distribu\u00eddos que usam um processo centralizador. O termo monol\u00edtico tamb\u00e9m \u00e9 muito usado em contraposi\u00e7\u00e3o \u00e0 arquitetura de micro-servi\u00e7os, mas sinto que este uso est\u00e1 de acordo com o uso que fazemos aqui. \u21a9 Escolhemos aqui ignorar o argumento muito plaus\u00edvel de que um algoritmo distribu\u00eddo poderia ser executado entre, por exemplo, diversos chips em uma mesma placa. \u21a9 What Can We Learn from Four Years of Data Center Hardware Failures? \u21a9 Mesmo que o custo n\u00e3o fosse um problema, seria imposs\u00edvel implementar scale up funcionalmente al\u00e9m de um certo limite, pois o computador teria que ser t\u00e3o grande que suas partes teriam que ser tratadas independentemente, revertendo a um cen\u00e1rio scale out custoso demais. \u21a9 The Log: What every software engineer should know about real-time data's unifying abstraction \u21a9 Vision and challenges for realising the Internet of things \u21a9","title":"Introdu\u00e7\u00e3o"},{"location":"intro/#introducao","text":"Escrever bons sistemas distribu\u00eddos \u00e9 uma tarefa que esbarra em diversos obst\u00e1culos, sendo a defini\u00e7\u00e3o do que \u00e9 um sistema distribu\u00eddo e do que \u00e9 ser \"bom\" neste contexto sendo nossos primeiros obst\u00e1culos.","title":"Introdu\u00e7\u00e3o"},{"location":"intro/#o-que-sao-sistemas-distribuidos","text":"Sistemas simples Para atacarmos a primeira quest\u00e3o e entendermos o que \u00e9 um Sistema Distribu\u00eddo, talvez seja mais f\u00e1cil come\u00e7ar pelo que n\u00e3o \u00e9 um sistema n\u00e3o-distribu\u00eddo. Estes s\u00e3o os sistemas que cont\u00e9m em um \u00fanico processo toda a l\u00f3gica de neg\u00f3cio, armazenamento e interface com usu\u00e1rio, mesmo que sejam divididos em v\u00e1rios m\u00f3dulos e usem diferentes bibliotecas e frameworks . Sejam estes sistemas constru\u00eddo com blocos que se encaixam perfeitamente, disponibilizados basicamente pela biblioteca da linguagem que est\u00e1 utilizando; Sistemas n\u00e3o t\u00e3o simples ou desenvolvido por times com diversas pessoas e usando bibliotecas de muitos fornecedores diferentes, aumentando consideravelmente a complexidade do desenvolvimento; o resultado, contudo, continua sendo um artefato s\u00f3, executado como um \u00fanico processo, e por isso os denominaremos sistemas monol\u00edtico . 1 Programar sistemas distribu\u00eddos \u00e9 dar outro salto em complexidade, pois frequentemente temos que usar pe\u00e7as que n\u00e3o foram pensadas para trabalhar juntas, for\u00e7ando-nos a usar um pouco de super-cola e arame. Cable hell! Bem, na verdade, em vez de cola usamos middleware , como logo discutiremos, e, em vez de arame, usamos cabos de rede, o que \u00e9, de fato, a principal caracter\u00edstica de um sistema distribu\u00eddo em rela\u00e7\u00e3o a um n\u00e3o-distribu\u00eddo: separa\u00e7\u00e3o e dispers\u00e3o de suas partes em v\u00e1rios componentes independentes (processos, sensores, atuadores, etc), mas que se coordenam para execu\u00e7\u00e3o de alguma tarefa. Vejamos alguns exemplos de tarefas executadas por sistemas distribu\u00eddos, que voc\u00ea usa hoje. Entregue este email para fulano@knowhere.uni . Envie o item I para o endere\u00e7o E, ap\u00f3s cobran\u00e7a de D dinheiros da conta C. Em um ambiente de simula\u00e7\u00e3o de batalhas em 3D, simule o disparo de um proj\u00e9til na dire\u00e7\u00e3o em que o o avatar est\u00e1 olhando, com velocidade V, enquanto movimenta o avatar A para a esquerda com velocidade W. Autorize a transfer\u00eancia de D dinheiros da conta C para a conta C'. Movimente o bra\u00e7o mec\u00e2nico que est\u00e1 segurando um bisturi, 3cm \u00e0 direita, ent\u00e3o abaixe-o 3mm, e movimente-o 4cm para a esquerda Inclua o coment\u00e1rio ``LOL!!!'' na lista de coment\u00e1rios do item XYZ, com marca de tempo T Leia o valor do sensor de temperatura T e, caso seu valor supere V, emita alarme luminoso vermelho intermitente e alarme sonoro Fica claro por estes exemplos que h\u00e1 comunica\u00e7\u00e3o entre diversos componentes, por exemplo o console de videogame e um servi\u00e7o que mantem uma \"sala\" aberta para um jogo. Assim, uma poss\u00edvel defini\u00e7\u00e3o de Sistema Distribu\u00eddo, que me agrada, \u00e9 a seguinte: Sistema Distribu\u00eddo Cole\u00e7\u00e3o de sistemas computacionais (software ou hardware), independentes mas com alguma forma de comunica\u00e7\u00e3o , que colaboram na execu\u00e7\u00e3o de alguma tarefa . Componentes hospedeiro n\u00f3 No jarg\u00e3o da \u00e1rea, os componentes independentes s\u00e3o denominados n\u00f3s . Frequentemente, cada n\u00f3 do sistema ser\u00e1, na pr\u00e1tica, um processo em um computador hospedeiro, um host , para que possa fazer uso de todos os recursos do hospedeiro e, por isso, frequentemente nos referimos ao pr\u00f3prio host como o n\u00f3. Contudo, nada impede que possivelmente m\u00faltiplos n\u00f3s possam ser executados em um mesmo host ou mesmo que m\u00faltiplos hosts virtuais, sejam m\u00e1quinas virtuais ou containers, executem na mesma m\u00e1quina f\u00edsica; isso n\u00e3o muda o fato de que os componentes s\u00e3o independentes e poderiam ser distanciados. 2 Comunica\u00e7\u00e3o mem\u00f3ria compartilhada mensagens Quanto \u00e0 comunica\u00e7\u00e3o, os n\u00f3s podem compartilhar um espa\u00e7o de endere\u00e7amento comum, seja porqu\u00ea est\u00e3o co-locados no mesmo hospedeiro ou seja porqu\u00ea tem acesso a alguma forma de mem\u00f3ria compartilhada distribu\u00edda, que veremos mais adiante. Eles tamb\u00e9m podem se comunicar por mensagens trocadas via uma rede de comunica\u00e7\u00e3o, como a Internet. Quanto \u00e0 tarefa em comum, veja o seguinte exemplo, em que v\u00e1rios clientes trocam emails por meio de uma m\u00e1quina com a qual se comunicam para entregar mensagens a serem enviadas e receber mensagens a eles destinadas; enquanto aguardam a entrega, mensagens s\u00e3o armazenadas em um Sistema Gerenciador de Banco de Dados (SGBD) em uma outra m\u00e1quina, da qual os usu\u00e1rios n\u00e3o tem ci\u00eancia. Depend\u00eancia ao colaborarem, criam depend\u00eancia quando um funciona, outros podem funcionar quando um para, outros param Neste exemplo, cada celular, o processo que implementa o servi\u00e7o de email e o servidor de banco de dados, s\u00e3o n\u00f3s do sistema. Observe que o n\u00f3 do servi\u00e7o de email \u00e9 respons\u00e1vel por receber os emails e encaminh\u00e1-los para o banco em um sentido, bem como ler emails do banco e entregar para os destinat\u00e1rios, no outro. Observe tamb\u00e9m que se o banco de dados para de funcionar, o servi\u00e7o de email passa a ser in\u00fatil, uma vez que n\u00e3o pode armazenar novas mensagens e nem recuperar mensagens j\u00e1 armazenadas. Neste contexto, uma descri\u00e7\u00e3o c\u00ednica mas definitivamente realista \u00e9 a de Leslie Lamport , que certa vez disse: A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable. Lamport est\u00e1 correto quanto aos problemas em sistemas distribu\u00eddos, e problemas podem se manifestar em diversas formas. Por exemplo, mesmo que um computador n\u00e3o pare, se ele ficar lento ou se o canal de comunica\u00e7\u00e3o n\u00e3o for confi\u00e1vel, uma aplica\u00e7\u00e3o cr\u00edtica poderia ser inviabilizada, como no exemplo de telecirurgia acima. Algumas aplica\u00e7\u00f5es, contudo, aparentemente conseguem superar estes obst\u00e1culos. Pensemos em algumas aplica\u00e7\u00f5es distribu\u00eddas com as quais interagimos todos os dias e que, por seu sucesso, devem ser bons sistemas distribu\u00eddos. Alguns exemplos \u00f3bvios s\u00e3o Amazon.com , Facebook , e GMail . Estes sistemas rodam em grandes data centers com milhares de m\u00e1quinas , estando constantemente sujeitos a fontes queimadas, discos corruptos, mem\u00f3rias defeituosas, etc 3 . Apesar disto, dificilmente estes servi\u00e7os s\u00e3o reportados como fora do ar, s\u00e3o altamente respons\u00edveis e, goste ou n\u00e3o do que fazem, s\u00e3o bem sucedidos porqu\u00ea cumprem bem suas tarefas. Assim, digamos que um sistema computacional \u00e9 bom se est\u00e1 sempre funcional, com bom desempenho e \u00e9 de baixo custo. Observe que estar sempre funcional implica em continuar provendo o servi\u00e7o mesmo que partes do sistema estejam com problemas, que ter bom desempenho implica que respostas \"r\u00e1pidas\" s\u00e3o dadas para o usu\u00e1rio, e que baixo custo implica em n\u00e3o gastar mais que o necess\u00e1rio para realizar a tarefa para a qual foi constru\u00eddo. Um \"bom\" sistema Dispon\u00edvel: Sempre funcional Poder computacional: Capacidade de processamento Capacidade de armazenamento Baixa lat\u00eancia Baixo custo Tamanho apropriado \u00e0 tarefa Enquanto subjetiva, nossa defini\u00e7\u00e3o de bom nos permite estabelecer um pano de fundo para delinear as dificuldades de se implementar sistemas distribu\u00eddos. Como veremos adiante, os requisitos para um bom sistema distribu\u00eddo s\u00e3o conflitantes e dif\u00edceis, \u00e0s vezes imposs\u00edveis de serem alcan\u00e7ados. Mas se esta \u00e9 a realidade da programa\u00e7\u00e3o distribu\u00edda, por qu\u00ea faz\u00ea-lo? A resposta tem a ver com a colabora\u00e7\u00e3o , na defini\u00e7\u00e3o.","title":"O qu\u00ea s\u00e3o Sistemas Distribu\u00eddos?"},{"location":"intro/#por-que-desenvolvemos-sistemas-distribuidos","text":"A primeira raz\u00e3o \u00e9 o fato \u00e9 que computadores individuais tem capacidade reduzida de processamento e armazenamento, mas nossa necessidade de poder computacional cresce exponencialmente. Assim, precisamos crescer nosso poder computacional, mas aumentar a capacidade de um dispositivo ( scale up ou vertical scaling ), mesmo de forma linear, tem custo exponencial. O que nos resta ent\u00e3o \u00e9 agregar o poder computacional de diversos computadores \"baratos\" ( scale out ou horizontal scaling ) para satisfazer nossas necessidades. 4 Mesmo se pensarmos que a escala com que estes sistemas trabalham deve ser muito diferente daquela dos sistemas que n\u00f3s desenvolvemos, e portanto as t\u00e9cnicas usadas em sua constru\u00e7\u00e3o devem ser muito distintas do que fazemos, a verdade n\u00e3o poderia ser mais longe disto. Com a quantidade de informa\u00e7\u00e3o armazenada a cada acesso a um s\u00edtio, a cada produto vendido, ou a cada consulta feita, praticamente qualquer sistema de informa\u00e7\u00e3o de sucesso necessitar\u00e1 aplicar as t\u00e9cnicas de computa\u00e7\u00e3o distribu\u00edda e superar as mesmas barreiras para conseguir atender ao n\u00famero crescente de clientes (computacionais ou humanos) e aumentar sua \u00e1rea de cobertura, mesmo que n\u00e3o chegue a escala dos exemplos acima, e melhorar ou manter a qualidade do servi\u00e7o que presta. PQ? escalabilidade toler\u00e2ncia a falhas Este \u00faltimo ponto, sobre qualidade do servi\u00e7o, tem a ver com a capacidade de um sistema se manter no ar a despeito de problemas, isto \u00e9, de ser tolerante a falhas. Toler\u00e2ncia a falhas implica em redund\u00e2ncia, em c\u00f3pias, o que fatidicamente implica em distribui\u00e7\u00e3o e em Sistemas Distribu\u00eddos. Assim, podemos concluir que as principais raz\u00f5es para se desenvolver sistemas distribu\u00eddos s\u00e3o alcan\u00e7ar escalabilidade e toler\u00e2ncia a falhas , ambas resultantes da agrega\u00e7\u00e3o (correta) do poder computacional de m\u00faltiplos componentes. Uma vez que tenhamos entendido o porqu\u00ea de desenvolver sistemas distribu\u00eddos, vejamos que tipos de sistemas resultam desta abordagem.","title":"Por qu\u00ea desenvolvemos sistemas distribu\u00eddos?"},{"location":"intro/#tipos-de-sistemas-distribuidos","text":"H\u00e1 quem diga que j\u00e1 somos todos desenvolvedores de sistemas distribu\u00eddos . Ainda assim, \u00e9 importante entender que h\u00e1 v\u00e1rios tipos de sistemas distribu\u00eddos, com diversas finalidades e diversas arquiteturas, pois classifica\u00e7\u00f5es nos ajudam a pensar sobre sistemas e a encontrar e reusar solu\u00e7\u00f5es previamente testadas e depuradas.","title":"Tipos de Sistemas Distribu\u00eddos"},{"location":"intro/#sistemas-de-computacao","text":"A possibilidade de agregar poder de processamento de muitos computadores via uma rede de comunica\u00e7\u00e3o com alt\u00edssima largura de banda nos permite atacar problemas computacionalmente muito intensos. Clusters como o da imagem a seguir, do High Performance Computing Center de Stuttgart, s\u00e3o compartilhados por pesquisadores resolvendo problemas de \u00e1reas como bio-inform\u00e1tica, engenharia, economia e intelig\u00eancia artificial. Na engenharia, por exemplo, HPC pode ser usada para testar a efici\u00eancia de projetos sem construir prot\u00f3tipos. Turbina Carro !? Os n\u00f3s de um cluster s\u00e3o normalmente divididos em tr\u00eas categorias: administra\u00e7\u00e3o, computa\u00e7\u00e3o e armazenamento. N\u00f3s de administra\u00e7\u00e3o implementam um monitoramento distribu\u00eddo dos demais n\u00f3s, servem de ponto de entrada para usu\u00e1rios e prov\u00eaem interface para submiss\u00e3o de tarefas, como o Torque, que executa sobre o MOAB. Outro exemplo, o Oscar \u00e9 um conjunto de softwares para gerenciamento de clusters. Uma das ferramentas inclusas no Oscar \u00e9 o OpenPBS, pelo qual tarefas s\u00e3o atribu\u00eddas aos diversos n\u00f3s do sistema que estejam alocados para tal tarefa. O OpenPBS portanto \u00e9 tamb\u00e9m um sistema distribu\u00eddo. Finalmente, as tarefas submetidas em si s\u00e3o tamb\u00e9m aplica\u00e7\u00f5es distribu\u00eddas em que cada processo executando em uma m\u00e1quina distinta \u00e9 respons\u00e1vel por resolver uma parte do problema. Acoplamento Forte Fraco Este tipo de sistemas distribu\u00eddos s\u00e3o o que chamamos de fortemente acoplados pois h\u00e1 grande depend\u00eancia dos componentes uns nos outros, tanto na administra\u00e7\u00e3o quanto na aplica\u00e7\u00e3o, e se um dos componentes para de funcionar, normalmente os outros tamb\u00e9m param. Um outro tipo de sistema, com a mesma finalidade de atacar problemas que exigem muita computa\u00e7\u00e3o mas com componentes fracamente acoplados , s\u00e3o as grades computacionais . Muito usadas at\u00e9 meados da d\u00e9cada passada, neste arranjo, membros de uma associa\u00e7\u00e3o disponibilizam capacidade computacional a um pool . De l\u00e1, os recursos podem ser acessados, seguindo algum crit\u00e9rio de gerenciamento, por quaisquer dos membros da associa\u00e7\u00e3o. Este modelo surgiu de iniciativas como o SETI@home , em que pessoas doavam tempo ocioso do seu computador para analisar sinais de r\u00e1dio recebidos do espa\u00e7o. Ap\u00f3s o sucesso inicial, a computa\u00e7\u00e3o foi movida de computadores de volunt\u00e1rios para os de institui\u00e7\u00f5es com interesses em comum. Computa\u00e7\u00e3o utilit\u00e1ria Fornecimento sob demanda Pagamento proporcional As grades computacionais podem ser vistas como precursoras da computa\u00e7\u00e3o utilit\u00e1ria , isto \u00e9, o fornecimento de recursos computacionais por provedores em troca de um pagamento proporcional \u00e0 quantidade de recursos utilizados, como no fornecimento de \u00e1gua ou eletricidade. A materializa\u00e7\u00e3o recente da computa\u00e7\u00e3o utilit\u00e1ria s\u00e3o as nuvens computacionais. Este tipo de sistema, embora possa ser pensando como infraestrutura para outros sistemas distribu\u00eddos, s\u00e3o, na verdade, complexas pe\u00e7as de engenharia, com diversos subsistemas respons\u00e1veis por sincroniza\u00e7\u00e3o de rel\u00f3gios, monitora\u00e7\u00e3o de falhas, coleta de logs, roteamento eficiente tolerante a falhas, movimenta\u00e7\u00e3o de recursos virtualizados para consolida\u00e7\u00e3o de recursos f\u00edsicos, armazenamento redundante de dados, etc. O seguinte v\u00eddeo mostra, em 360 graus, um dos datacenters do Google, para que voc\u00ea tenha ideia da escala em que estes sistemas s\u00e3o constru\u00eddos. J\u00e1 este outro s\u00edtio apresenta uma viagem fotogr\u00e1fica por alguns datacenters .","title":"Sistemas de Computa\u00e7\u00e3o"},{"location":"intro/#sistemas-de-informacao","text":"Provavelmente mais comuns entre os profissionais da computa\u00e7\u00e3o, os sistemas de informa\u00e7\u00e3o distribu\u00eddos s\u00e3o encontrados em diversas formas. De fato, o termo \"sistema de informa\u00e7\u00e3o\" \u00e9 t\u00e3o abrangente, que dificilmente um sistema distribu\u00eddo n\u00e3o estaria nesta classe. Seja como for, o seguinte exemplo \u00e9 de uma arquitetura em tr\u00eas camadas, onde a primeira implementa a interface com o usu\u00e1rio, a segunda cont\u00e9m a l\u00f3gica do neg\u00f3cio, e a terceira mantem os dados da aplica\u00e7\u00e3o. Pe\u00e7a fundamental desta abordagem, os bancos de dados na terceira camada s\u00e3o frequentemente distribu\u00eddos. Isto \u00e9, um banco em que v\u00e1rios n\u00f3s mantem os dados e portanto precisam se coordenar para manter os dados consistentes. A figura a seguir mostra um cen\u00e1rio com tr\u00eas bancos; imagine que em um deles est\u00e1 uma rela\u00e7\u00e3o com os dados dos clientes, em outro, os dados do estoque e, no terceiro, as ordens de compra. Quando um cliente faz um pedido, o cliente deve ser validado no primeiro n\u00f3, o item \u00e9 removido do estoque no segundo, e uma cobran\u00e7a \u00e9 disparada para o cliente no terceiro. Se qualquer destas tr\u00eas rela\u00e7\u00f5es n\u00e3o for corretamente consultada e alterada, os efeitos podem ser catastr\u00f3ficos para o neg\u00f3cio ou para o cliente. graph LR B{Aplica\u00e7\u00e3o} B -->|Requisi\u00e7\u00e3o| C[(SGBD 1)] B -->|Requisi\u00e7\u00e3o| D[(SGBD 2)] B -->|Requisi\u00e7\u00e3o| E[(SGBD 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B Como implementar as famosas propriedades ACID neste banco de dados? Embora veremos isso um pouco mais para frente neste material, por enquanto, apenas assuma que n\u00e3o \u00e9 exatamente f\u00e1cil ou barato. Esta dificuldade foi a raz\u00e3o do surgimento dos bancos de dados NOSQL (n\u00e9e NoSQL), dos quais uma pequena amostra \u00e9 dada pela seguinte figura. Tamb\u00e9m discutiremos como estes bancos de dados funcionam, quando falarmos sobre sistemas P2P.","title":"Sistemas de Informa\u00e7\u00e3o"},{"location":"intro/#integracao-de-aplicacoes","text":"Frequentemente \u00e9 necess\u00e1rio integrar sistemas de informa\u00e7\u00e3o legados com sistemas mais modernos, ou simplesmente exp\u00f4-los usando uma interface mais moderna. Nestes casos, \u00e9 poss\u00edvel integrar diversos sistemas usando um middleware que os encapsule. Veremos mais adiante o que \u00e9 um middleware ; por enquanto, pense nele apenas como um camada de software que se interp\u00f5e entre os clientes e um servi\u00e7o oferecido. No exemplo, o middleware pode, por exemplo, se expor via interface REST para os clientes, mas consultar o sistema legado em um padr\u00e3o antigo. Outro exemplo, na imagem seguinte, \u00e9 um sistema que agrega subsistemas de diversos departamentos de uma empresa via troca de mensagens. Observe que nenhum departamento precisa conversar diretamente com os outros, ou mesmo conhec\u00ea-los; eles apenas publicam a mensagem para quem tiver interesse e aguardam um resposta tamb\u00e9m na forma de uma mensagem. Observe que nenhum componente tem que saber da exist\u00eancia do outro ou se torna indispon\u00edvel caso os outros falhem, o que aumenta a escalabilidade do sistema e sua capacidade de tolerar falhas.","title":"Integra\u00e7\u00e3o de Aplica\u00e7\u00f5es"},{"location":"intro/#sistemas-pervasivosubiquos","text":"Sistemas ub\u00edquos tamb\u00e9m s\u00e3o geralmente distribu\u00eddos. Segundo Weiser, 1993 Ubiquitous computing is the method of enhancing computer use by making many computers available throughout the physical environment, but making them effectively invisible to the user. Assim, sistemas ub\u00edquos aumentam e otimizam a intera\u00e7\u00e3o do usu\u00e1rio com o ambiente, para que estes foquem-se na tarefa em vez de na ferramenta. Outra forma de se colocar, \u00e9 que sistemas pervasivos devem ajudar as pessoas a realizar suas tarefas, de forma impl\u00edcita, sem ter que pensar em como a tarefa ser\u00e1 executada. Para que seja realizada, a computa\u00e7\u00e3o pervasiva requer que dispositivos detectem o contexto em que est\u00e3o inseridos, combinem-se de forma ad-hoc e compartilhem informa\u00e7\u00f5es. Exemplos fict\u00edcios e reais Smart Life Esta \u00e9 uma vis\u00e3o futur\u00edstica da Microsoft para a integra\u00e7\u00e3o de tecnologias. Amazon Go Este mercado automatiza o pagamento dos itens escolhidos pelo consumidor, utilizando t\u00e9cnicas de processamento digital de imagens, aprendizado de m\u00e1quina e sensores. Reality Check Para quem viu o filme Minority Report e sonhou com as UI do futuro, aqui vai um reality check . Para quem n\u00e3o viu ainda, corrija esta falha em sua forma\u00e7\u00e3o t\u00e9cnica o mais rapidamente poss\u00edvel.","title":"Sistemas Pervasivos/Ub\u00edquos"},{"location":"intro/#referencias","text":"Neste ponto, devo estressar que muitos se referem a sistemas n\u00e3o-distribu\u00eddos como centralizados mas prefiro reservar este termo para sistemas distribu\u00eddos que usam um processo centralizador. O termo monol\u00edtico tamb\u00e9m \u00e9 muito usado em contraposi\u00e7\u00e3o \u00e0 arquitetura de micro-servi\u00e7os, mas sinto que este uso est\u00e1 de acordo com o uso que fazemos aqui. \u21a9 Escolhemos aqui ignorar o argumento muito plaus\u00edvel de que um algoritmo distribu\u00eddo poderia ser executado entre, por exemplo, diversos chips em uma mesma placa. \u21a9 What Can We Learn from Four Years of Data Center Hardware Failures? \u21a9 Mesmo que o custo n\u00e3o fosse um problema, seria imposs\u00edvel implementar scale up funcionalmente al\u00e9m de um certo limite, pois o computador teria que ser t\u00e3o grande que suas partes teriam que ser tratadas independentemente, revertendo a um cen\u00e1rio scale out custoso demais. \u21a9 The Log: What every software engineer should know about real-time data's unifying abstraction \u21a9 Vision and challenges for realising the Internet of things \u21a9","title":"Refer\u00eancias"},{"location":"preface/","text":"Pref\u00e1cio Por qu\u00ea ler estas notas? Computa\u00e7\u00e3o distribu\u00edda \u00c1rea extremamente ativa Diferencial As \u00e1reas ligadas ao desenvolvimentos de sistemas computacionais, como Ci\u00eancia e Engenharia de Computa\u00e7\u00e3o e Sistemas de Informa\u00e7\u00e3o, est\u00e3o extremamente em voga e tem atra\u00eddo mais e mais profissionais, mais ou menos qualificados, tornando este mercado cada vez mais competitivo . Dentro destas grandes \u00e1reas, o desenvolvimento de sistemas distribu\u00eddos \u00e9 um dos t\u00f3picos mais \"quentes\" e ter conhecimentos espec\u00edficos desta sub\u00e1rea pode ser uma excelente vantagem e forma de se destacar de seus colegas e competidores. Fundamental a outras \u00e1reas Aprendizado de m\u00e1quina Ci\u00eancia de dados Computa\u00e7\u00e3o gr\u00e1fica Se estiver se perguntando do que estou falando, sobre como posso dizer que \u00e9 quente uma \u00e1rea sobre a qual talvez voc\u00ea nunca tenha ouvido falar, ao contr\u00e1rio de \u00e1reas como aprendizado de m\u00e1quina e ci\u00eancia de dados , ent\u00e3o deixe-me explicar o que quero dizer. Sem o desenvolvimento da teoria da computa\u00e7\u00e3o distribu\u00edda , na forma do estudo de algoritmos e t\u00e9cnicas de implementa\u00e7\u00e3o, e sua coloca\u00e7\u00e3o em pr\u00e1tica, na forma do desenvolvimento de sistemas distribu\u00eddos, nenhum desenvolvimento s\u00e9rio destas outras \u00e1reas, sedentas por desempenho, escalaria para problemas reais. Veja, por exemplo, a seguinte descri\u00e7\u00e3o dos skills necess\u00e1rios para se atuar como cientista de dados ou como engenheiro de software no Facebook . \u00c9 fato que aplica\u00e7\u00f5es distribu\u00eddos j\u00e1 s\u00e3o parte inexpurg\u00e1vel da infraestrutura computacional que usamos para resolver os mais diversos problemas. Este curso A teoria por baixo dos frameworks que j\u00e1 usam Assim, respondendo \u00e0 pergunta acima, entendo que ler estas notas lhe permitir\u00e1 mergulhar rapidamente no cora\u00e7\u00e3o da computa\u00e7\u00e3o distribu\u00edda, para entender os fundamentos de como as grandes infra-estruturas computacionais que usamos hoje funcionam, muito al\u00e9m das anota\u00e7\u00f5es do Springboot e dos clientes de bancos de dados. Isso, de uma forma muito direta e mais simples de digerir quer as fontes onde me baseei para escrev\u00ea-las, al\u00e9m de usar diversos materiais dispon\u00edveis mais recentes que a bibliografia b\u00e1sica. Estrutura Por qu\u00ea? Vis\u00e3o geral Teoria Pr\u00e1tica Cen\u00e1rio atual Neste curso apesentaremos uma vis\u00e3o geral do que s\u00e3o sistemas distribu\u00eddos, porqu\u00eas t\u00e9cnicos para os desenvolvermos e como faz\u00ea-lo, com uma forte componente pr\u00e1tica, por meio do desenvolvimento de um projeto com (um dos) p\u00e9s na realidade. Faremos isso come\u00e7ando por uma revis\u00e3o de conceitos de redes de computadores e sistemas operacionais enquanto falamos sobre a arquitetura mais fundamental de computa\u00e7\u00e3o distribu\u00edda, Cliente/Servidor, e de como \u00e9 usada para implementar um proto banco de dados distribu\u00eddo, uma Tabela de Espalhamento Distribu\u00edda em mem\u00f3ria. \u00c0 medida em que apresentamos problemas com o modelo assumido inicialmente e com nossa implementa\u00e7\u00e3o inicial, buscaremos por solu\u00e7\u00f5es enquanto introduzimos novas abstra\u00e7\u00f5es, mais poderosas e mais complexas. Ao final desta jornada, teremos fundamentado a constru\u00e7\u00e3o de uma Tabela de Espalhamento Distribu\u00eddo com particionamento de dados entre n\u00f3s, usando protocolos par-a-par e replica\u00e7\u00e3o de m\u00e1quinas de estados. Em paralelo, teremos estudado diversos frameworks de computa\u00e7\u00e3o distribu\u00edda atuais, como modelo ou bloco de constru\u00e7\u00e3o para a resolu\u00e7\u00e3o de nossos problemas. Em resumo, durante este curso voc\u00ea ir\u00e1: programar processos que se comuniquem via redes de computadores; conhecer arquiteturas cl\u00e1ssicas de sistemas distribu\u00eddos (e.g, cliente/servidor, p2p e h\u00edbrida), seus usos e limita\u00e7\u00f5es; escrever programas multithreaded simples e a entender como o uso de multithreading afeta os componentes de um sistema distribu\u00eddo; entender a problem\u00e1tica da coordena\u00e7\u00e3o e do controle de concorr\u00eancia em sistemas distribu\u00eddos; entender o uso de sistemas de nomea\u00e7\u00e3o em sistemas distribu\u00eddos bem como diversas formas de se implementar tais sistemas de nomea\u00e7\u00e3o; entender os conceitos b\u00e1sicos de replica\u00e7\u00e3o e toler\u00e2ncia a falhas; entender as implica\u00e7\u00f5es da dessincroniza\u00e7\u00e3o de rel\u00f3gios na coordena\u00e7\u00e3o, replica\u00e7\u00e3o e toler\u00e2ncia a falhas; projetar sistemas com componentes geograficamente distantes, fracamente acoplados; entender onde os diversos middleware podem ser usados para acoplar tais componentes; conhecer v\u00e1rias t\u00e9cnicas que controle de concorr\u00eancia controlar o acesso a um recurso compartilhado; TODO Estruturar melhor esta se\u00e7\u00e3o uma vez que a estrutura do documento tenha estabilizado mais. Um aviso aos incautos: \u00e9 imposs\u00edvel falar sobre sistemas distribu\u00eddos sem algumas indas e vindas. Quando iniciarmos nosso estudo, falaremos sobre sockets como forma de comunica\u00e7\u00e3o entre processos para que possamos rapidamente come\u00e7ar a experimentar e praticar a constru\u00e7\u00e3o de sistemas distribu\u00eddos. Ao falarmos de sockets , seremos naturalmente obrigados a discutir a arquitetura cliente/servidor , antes mesmo de falarmos de arquiteturas. Quando falarmos em arquiteturas, falaremos sobre sistemas P2P e de como, nestes sistemas, processos s\u00e3o organizados de forma plana em vez de hier\u00e1rquica. Ao falarmos sobre P2P, seremos fo\u00e7ados a mencionar seus representantes mais relevantes atualmente, os bancos de dados NOSQL, isto antes mesmo de falarmos sobre sistemas de bancos de dados distribu\u00eddos. Mais tarde, quando voltar a falar sobre bancos de dados distribu\u00eddos, nos focaremos n\u00e3o na arquitetura dos bancos de dados, mas como bancos de dados s\u00e3o vistos pelos outros componentes do sistema distribu\u00eddo. Isto \u00e9, nos focaremos nos contratos que levam os bancos de dados a se comportem da maneira que esperamos que se comportem, ou n\u00e3o. Finalmente, quando discutirmos como o banco implementa os contratos, seremos conduzidos a falar sobre locks distribu\u00eddos e problemas de acordo, abstra\u00e7\u00f5es que ter\u00e3o sido discutidas discutidas anteriormente. O ponto aqui \u00e9 todos os t\u00f3picos acabam sendo fortemente relacionados uns com os outros e mesclar o que estudamos de forma consistente \u00e9 um processo iterativo. Conven\u00e7\u00f5es Neste documento, usamos diversos recursos visuais com diferentes prop\u00f3sitos. it\u00e1lico indica termos em outras l\u00ednguas, como framework ou middleware . Alguns termos, contudo, s\u00e3o t\u00e3o corriqueiramente usados que me escapam quando escrevendo e acabam n\u00e3o grafados corretamente. negrito indica a introdu\u00e7\u00e3o de termos e conceitos importantes, como escalabilidade e falha . Apontadores indicam um s\u00edtio relacionado ao termo, por exemplo, como criar um reposit\u00f3rio no Github , e cuja leitura \u00e9 sugerida ao final da aula. Notas de rodap\u00e9, indicam uma observa\u00e7\u00e3o importante sobre o que est\u00e1 sendo apresentado, cuja leitura \u00e9 sugerida ao final do par\u00e1grafo. 1 Estas notas incluem referenciais te\u00f3ricos importantes, com detalhes da publica\u00e7\u00e3o e apontadores para onde a publica\u00e7\u00e3o pode ser lida, por exemplo, para o livro Distributed Systems: Principles and Paradigms 2 no qual estas notas s\u00e3o fortemente baseadas; este uso dever\u00e1 ser migrado para uma forma mais can\u00f4nica de refer\u00eancias. Imagens n\u00e3o autorais s\u00e3o tamb\u00e9m apontadores para onde s\u00e3o encontradas e tem como texto alternativo as informa\u00e7\u00f5es da autoria. Caixas alinhadas \u00e0 esquerda s\u00e3o usadas para v\u00e1rias finalidades. Por exemplo, para apresentar exerc\u00edcios, destacar especifica\u00e7\u00f5es, apontar tarefas a serem executas por mim... Os diversos usos s\u00e3o indicados nos \u00edcones e cores das caixas. Exerc\u00edcio Isso \u00e9 um exerc\u00edcio! Resumo Elementos visuais Caixas alinhadas \u00e0 direita podem ser vistas como um sum\u00e1rio executivo do que est\u00e1 sendo apresentado no texto pr\u00f3ximo. TODO Diferenciar os usos de negrito, Ativar plugin bibtex Diferenciar caixas Agradecimentos Agrade\u00e7o ao Prof. Paulo R. S. L. Coelho pelas diversas contribui\u00e7\u00f5es feitas a este texto. Agrade\u00e7o tamb\u00e9m aos diversos alunos est\u00e3o sempre, gentilmente, apresentando oportunidades de melhorias. Caso queira sugerir corre\u00e7\u00f5es, fa\u00e7a um pull request a apontando a corre\u00e7\u00e3o no branch main, a partir do qual eu atualizarei o HTML. TODO Adicionar guia de sugest\u00f5es. Referencial Estas notas, em sua forma atual, s\u00e3o fortemente baseadas no livro Distributed Systems: Principles and Paradigms 2 , mas tamb\u00e9m em alguns materiais mais recentes dispon\u00edveis livremente na Internet. Exemplo de nota de rodap\u00e9. \u21a9 Distributed Systems: Principles and Paradigms \u21a9 \u21a9","title":"Pref\u00e1cio"},{"location":"preface/#prefacio","text":"","title":"Pref\u00e1cio"},{"location":"preface/#por-que-ler-estas-notas","text":"Computa\u00e7\u00e3o distribu\u00edda \u00c1rea extremamente ativa Diferencial As \u00e1reas ligadas ao desenvolvimentos de sistemas computacionais, como Ci\u00eancia e Engenharia de Computa\u00e7\u00e3o e Sistemas de Informa\u00e7\u00e3o, est\u00e3o extremamente em voga e tem atra\u00eddo mais e mais profissionais, mais ou menos qualificados, tornando este mercado cada vez mais competitivo . Dentro destas grandes \u00e1reas, o desenvolvimento de sistemas distribu\u00eddos \u00e9 um dos t\u00f3picos mais \"quentes\" e ter conhecimentos espec\u00edficos desta sub\u00e1rea pode ser uma excelente vantagem e forma de se destacar de seus colegas e competidores. Fundamental a outras \u00e1reas Aprendizado de m\u00e1quina Ci\u00eancia de dados Computa\u00e7\u00e3o gr\u00e1fica Se estiver se perguntando do que estou falando, sobre como posso dizer que \u00e9 quente uma \u00e1rea sobre a qual talvez voc\u00ea nunca tenha ouvido falar, ao contr\u00e1rio de \u00e1reas como aprendizado de m\u00e1quina e ci\u00eancia de dados , ent\u00e3o deixe-me explicar o que quero dizer. Sem o desenvolvimento da teoria da computa\u00e7\u00e3o distribu\u00edda , na forma do estudo de algoritmos e t\u00e9cnicas de implementa\u00e7\u00e3o, e sua coloca\u00e7\u00e3o em pr\u00e1tica, na forma do desenvolvimento de sistemas distribu\u00eddos, nenhum desenvolvimento s\u00e9rio destas outras \u00e1reas, sedentas por desempenho, escalaria para problemas reais. Veja, por exemplo, a seguinte descri\u00e7\u00e3o dos skills necess\u00e1rios para se atuar como cientista de dados ou como engenheiro de software no Facebook . \u00c9 fato que aplica\u00e7\u00f5es distribu\u00eddos j\u00e1 s\u00e3o parte inexpurg\u00e1vel da infraestrutura computacional que usamos para resolver os mais diversos problemas. Este curso A teoria por baixo dos frameworks que j\u00e1 usam Assim, respondendo \u00e0 pergunta acima, entendo que ler estas notas lhe permitir\u00e1 mergulhar rapidamente no cora\u00e7\u00e3o da computa\u00e7\u00e3o distribu\u00edda, para entender os fundamentos de como as grandes infra-estruturas computacionais que usamos hoje funcionam, muito al\u00e9m das anota\u00e7\u00f5es do Springboot e dos clientes de bancos de dados. Isso, de uma forma muito direta e mais simples de digerir quer as fontes onde me baseei para escrev\u00ea-las, al\u00e9m de usar diversos materiais dispon\u00edveis mais recentes que a bibliografia b\u00e1sica.","title":"Por qu\u00ea ler estas notas?"},{"location":"preface/#estrutura","text":"Por qu\u00ea? Vis\u00e3o geral Teoria Pr\u00e1tica Cen\u00e1rio atual Neste curso apesentaremos uma vis\u00e3o geral do que s\u00e3o sistemas distribu\u00eddos, porqu\u00eas t\u00e9cnicos para os desenvolvermos e como faz\u00ea-lo, com uma forte componente pr\u00e1tica, por meio do desenvolvimento de um projeto com (um dos) p\u00e9s na realidade. Faremos isso come\u00e7ando por uma revis\u00e3o de conceitos de redes de computadores e sistemas operacionais enquanto falamos sobre a arquitetura mais fundamental de computa\u00e7\u00e3o distribu\u00edda, Cliente/Servidor, e de como \u00e9 usada para implementar um proto banco de dados distribu\u00eddo, uma Tabela de Espalhamento Distribu\u00edda em mem\u00f3ria. \u00c0 medida em que apresentamos problemas com o modelo assumido inicialmente e com nossa implementa\u00e7\u00e3o inicial, buscaremos por solu\u00e7\u00f5es enquanto introduzimos novas abstra\u00e7\u00f5es, mais poderosas e mais complexas. Ao final desta jornada, teremos fundamentado a constru\u00e7\u00e3o de uma Tabela de Espalhamento Distribu\u00eddo com particionamento de dados entre n\u00f3s, usando protocolos par-a-par e replica\u00e7\u00e3o de m\u00e1quinas de estados. Em paralelo, teremos estudado diversos frameworks de computa\u00e7\u00e3o distribu\u00edda atuais, como modelo ou bloco de constru\u00e7\u00e3o para a resolu\u00e7\u00e3o de nossos problemas. Em resumo, durante este curso voc\u00ea ir\u00e1: programar processos que se comuniquem via redes de computadores; conhecer arquiteturas cl\u00e1ssicas de sistemas distribu\u00eddos (e.g, cliente/servidor, p2p e h\u00edbrida), seus usos e limita\u00e7\u00f5es; escrever programas multithreaded simples e a entender como o uso de multithreading afeta os componentes de um sistema distribu\u00eddo; entender a problem\u00e1tica da coordena\u00e7\u00e3o e do controle de concorr\u00eancia em sistemas distribu\u00eddos; entender o uso de sistemas de nomea\u00e7\u00e3o em sistemas distribu\u00eddos bem como diversas formas de se implementar tais sistemas de nomea\u00e7\u00e3o; entender os conceitos b\u00e1sicos de replica\u00e7\u00e3o e toler\u00e2ncia a falhas; entender as implica\u00e7\u00f5es da dessincroniza\u00e7\u00e3o de rel\u00f3gios na coordena\u00e7\u00e3o, replica\u00e7\u00e3o e toler\u00e2ncia a falhas; projetar sistemas com componentes geograficamente distantes, fracamente acoplados; entender onde os diversos middleware podem ser usados para acoplar tais componentes; conhecer v\u00e1rias t\u00e9cnicas que controle de concorr\u00eancia controlar o acesso a um recurso compartilhado; TODO Estruturar melhor esta se\u00e7\u00e3o uma vez que a estrutura do documento tenha estabilizado mais. Um aviso aos incautos: \u00e9 imposs\u00edvel falar sobre sistemas distribu\u00eddos sem algumas indas e vindas. Quando iniciarmos nosso estudo, falaremos sobre sockets como forma de comunica\u00e7\u00e3o entre processos para que possamos rapidamente come\u00e7ar a experimentar e praticar a constru\u00e7\u00e3o de sistemas distribu\u00eddos. Ao falarmos de sockets , seremos naturalmente obrigados a discutir a arquitetura cliente/servidor , antes mesmo de falarmos de arquiteturas. Quando falarmos em arquiteturas, falaremos sobre sistemas P2P e de como, nestes sistemas, processos s\u00e3o organizados de forma plana em vez de hier\u00e1rquica. Ao falarmos sobre P2P, seremos fo\u00e7ados a mencionar seus representantes mais relevantes atualmente, os bancos de dados NOSQL, isto antes mesmo de falarmos sobre sistemas de bancos de dados distribu\u00eddos. Mais tarde, quando voltar a falar sobre bancos de dados distribu\u00eddos, nos focaremos n\u00e3o na arquitetura dos bancos de dados, mas como bancos de dados s\u00e3o vistos pelos outros componentes do sistema distribu\u00eddo. Isto \u00e9, nos focaremos nos contratos que levam os bancos de dados a se comportem da maneira que esperamos que se comportem, ou n\u00e3o. Finalmente, quando discutirmos como o banco implementa os contratos, seremos conduzidos a falar sobre locks distribu\u00eddos e problemas de acordo, abstra\u00e7\u00f5es que ter\u00e3o sido discutidas discutidas anteriormente. O ponto aqui \u00e9 todos os t\u00f3picos acabam sendo fortemente relacionados uns com os outros e mesclar o que estudamos de forma consistente \u00e9 um processo iterativo.","title":"Estrutura"},{"location":"preface/#convencoes","text":"Neste documento, usamos diversos recursos visuais com diferentes prop\u00f3sitos. it\u00e1lico indica termos em outras l\u00ednguas, como framework ou middleware . Alguns termos, contudo, s\u00e3o t\u00e3o corriqueiramente usados que me escapam quando escrevendo e acabam n\u00e3o grafados corretamente. negrito indica a introdu\u00e7\u00e3o de termos e conceitos importantes, como escalabilidade e falha . Apontadores indicam um s\u00edtio relacionado ao termo, por exemplo, como criar um reposit\u00f3rio no Github , e cuja leitura \u00e9 sugerida ao final da aula. Notas de rodap\u00e9, indicam uma observa\u00e7\u00e3o importante sobre o que est\u00e1 sendo apresentado, cuja leitura \u00e9 sugerida ao final do par\u00e1grafo. 1 Estas notas incluem referenciais te\u00f3ricos importantes, com detalhes da publica\u00e7\u00e3o e apontadores para onde a publica\u00e7\u00e3o pode ser lida, por exemplo, para o livro Distributed Systems: Principles and Paradigms 2 no qual estas notas s\u00e3o fortemente baseadas; este uso dever\u00e1 ser migrado para uma forma mais can\u00f4nica de refer\u00eancias. Imagens n\u00e3o autorais s\u00e3o tamb\u00e9m apontadores para onde s\u00e3o encontradas e tem como texto alternativo as informa\u00e7\u00f5es da autoria. Caixas alinhadas \u00e0 esquerda s\u00e3o usadas para v\u00e1rias finalidades. Por exemplo, para apresentar exerc\u00edcios, destacar especifica\u00e7\u00f5es, apontar tarefas a serem executas por mim... Os diversos usos s\u00e3o indicados nos \u00edcones e cores das caixas. Exerc\u00edcio Isso \u00e9 um exerc\u00edcio! Resumo Elementos visuais Caixas alinhadas \u00e0 direita podem ser vistas como um sum\u00e1rio executivo do que est\u00e1 sendo apresentado no texto pr\u00f3ximo. TODO Diferenciar os usos de negrito, Ativar plugin bibtex Diferenciar caixas","title":"Conven\u00e7\u00f5es"},{"location":"preface/#agradecimentos","text":"Agrade\u00e7o ao Prof. Paulo R. S. L. Coelho pelas diversas contribui\u00e7\u00f5es feitas a este texto. Agrade\u00e7o tamb\u00e9m aos diversos alunos est\u00e3o sempre, gentilmente, apresentando oportunidades de melhorias. Caso queira sugerir corre\u00e7\u00f5es, fa\u00e7a um pull request a apontando a corre\u00e7\u00e3o no branch main, a partir do qual eu atualizarei o HTML. TODO Adicionar guia de sugest\u00f5es.","title":"Agradecimentos"},{"location":"preface/#referencial","text":"Estas notas, em sua forma atual, s\u00e3o fortemente baseadas no livro Distributed Systems: Principles and Paradigms 2 , mas tamb\u00e9m em alguns materiais mais recentes dispon\u00edveis livremente na Internet. Exemplo de nota de rodap\u00e9. \u21a9 Distributed Systems: Principles and Paradigms \u21a9 \u21a9","title":"Referencial"},{"location":"projeto/","text":"A \u00e1rea de computa\u00e7\u00e3o distribu\u00edda \u00e9 rica em aplica\u00e7\u00f5es e desenvolv\u00ea-los \u00e9 topar de frente com v\u00e1rios problemas e decidir como resolv\u00ea-los ou contorn\u00e1-los e, por isto, nada melhor que um projeto para experimentar em primeira m\u00e3o as ang\u00fastias e prazeres da \u00e1rea. Assim, proponho visitarmos o material destas notas \u00e0 luz de uma aplica\u00e7\u00e3o gen\u00e9rica mas real, desenvolvida por voc\u00eas enquanto vemos a teoria. O projeto consiste em uma aplica\u00e7\u00e3o com dois tipos de usu\u00e1rios, os clientes e os administradores , que voc\u00ea pode pensar em termos de compradores e lojistas, pacientes e m\u00e9dicos, ou consumidores e produtores de conte\u00fado, dependendo da aplica\u00e7\u00e3o que voc\u00ea resolver implementar. As funcionalidades s\u00e3o expostas para estes usu\u00e1rios via dois tipos de aplica\u00e7\u00f5es distintas, o portal do cliente e o portal administrativo , mas ambos manipulam a mesma base de dados . M\u00faltiplas inst\u00e2ncias de cada portal podem existir e cada inst\u00e2ncia mant\u00e9m um cache da base de dados em mem\u00f3ria, com as entradas mais recentemente acessadas. A totalidade da base \u00e9 particionada usando consistent hashing . Cada parti\u00e7\u00e3o \u00e9 replicada em outros n\u00f3s usando um protocolo de difus\u00e3o at\u00f4mica . A arquitetura do sistema ser\u00e1 h\u00edbrida , contendo um pouco de Cliente/Servidor e Peer-2-Peer, al\u00e9m de ser multicamadas. Apesar de introduzir complexidade extra, tamb\u00e9m usaremos m\u00faltiplos mecanismos para a comunica\u00e7\u00e3o entre as partes, para que possam experimentar com diversas abordagens. O sistemas tem duas aplica\u00e7\u00f5es , CLI ou GUI, para os dois tipos de usu\u00e1rios do sistema, clientes, e administradores. Estas aplica\u00e7\u00f5es se comunicar\u00e3o com os portais para manipular os dados dos clientes e associados a cada cliente. A aplica\u00e7\u00e3o do administrador manipula clientes, isto \u00e9, permite o CRUD de clientes. A aplica\u00e7\u00e3o do cliente permite manipular os dados associados aos clientes. O cadastro do cliente inclui a provis\u00e3o de um identificador \u00fanico do cliente CID ( client id ). Os dados dos clientes s\u00e3o mantidos em uma tabela CID -> Dados do Cliente, em mem\u00f3ria (use uma tabela hash). O CID tem tipo BigInteger ou equivalente 1 ; voc\u00ea deve decidir o que comp\u00f5e os dados do cliente, mass eles devem ser armazenados como uma string JSON. A comunica\u00e7\u00e3o entre administradores e portal Administrativo se d\u00e1 por uso direto de sockets e TCP, ou middleware pub/sub Mosquitto, ou gRPC. Somente clientes devidamente cadastrados no sistema podem ter suas opera\u00e7\u00f5es executadas. A comunica\u00e7\u00e3o entre cliente e portal Cliente se d\u00e1 por de sockets e TCP, ou middleware pub/sub Mosquitto, ou gRPC. O CID do cliente executando opera\u00e7\u00f5es no porta cliente deve ser informado em cada opera\u00e7\u00e3o para \"autenticar\" o cliente e autorizar a execu\u00e7\u00e3o da opera\u00e7\u00e3o. O cliente tem um \"saco\" de dados com diversas entradas armazenados no sistema, que podem ser manipuladas individualmente ou em conjunto; cada entrada corresponde a uma entrada no banco de dados, mantido em mem\u00f3ria (use uma tabela hash ). Aqui chamarei cada entrada no saco de \"tarefa\", mas dependendo da aplica\u00e7\u00e3o que voc\u00ea escolher, tarefas podem ser, por exemplo, eventos em um calend\u00e1rio ou entradas em uma lista compras. Cada tarefa tem um t\u00edtulo, que serve de identificador da tarefa, e um corpo; ambos s\u00e3o do tipo String , JSON ou n\u00e3o. Os dados s\u00e3o mantidos em uma tabela hash e m\u00faltiplas entradas podem ser necess\u00e1rias para armazenar e manter uma tarefa, isto \u00e9, algumas entradas podem ser de metadados, por exemplo, \u00edndice Por exemplo, para representar duas tarefas, t1 e t2 , com corpos c1 e c2 , associadas ao cliente cliente1 , podemos ter as seguintes entradas. cliente1 -> [t1,t2] cliente1:t1 -> c1 cliente1:t2 -> c2 Com este formato, podemos identificar os t\u00edtulos das tarefas associadas ao cliente1 e, a partir desta lista, identificar o conte\u00fado associado a cada tarefa. Este formato tamb\u00e9m permite que m\u00faltiplos clientes tenham tarefas com o mesmo t\u00edtulo. O formato exato em que os dados ser\u00e3o armazenados pode variar e, por isso, nos casos de uso apresentados a seguir, as API usadas devem ser consideradas inten\u00e7\u00f5es e n\u00e3o necessariamente o que ser\u00e1 implementado no seu trabalho. Casos de Uso Todo Diagramas de intera\u00e7\u00e3o. Manipula\u00e7\u00e3o Clientes Inser\u00e7\u00e3o de Cliente Administrador Gera um CID para cada cliente, baseado em seu nome ou outro atributo \u00fanico. inserirCliente(CID, \"dados do cliente\") Informa o CID para o cliente Portal Administrador Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Se cliente existia, falha a opera\u00e7\u00e3o. Se cliente n\u00e3o existia, insere dados no banco e atualiza a cache. Cliente Recebe CID diretamente do administrador Modifica\u00e7\u00e3o de Cliente Administrador Determina CID de cliente a ser modificado. modificarCliente(CID, \"novos dados do cliente\") Portal Administrador Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Se cliente existe, atualiza o cliente e atualiza a cache. Se cliente n\u00e3o existe, retorna erro. Recupera\u00e7\u00e3o de Clientes Administrador Determina CID de cliente a ser recuperado recuperarCliente(CID) Portal Administrador Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Se cliente n\u00e3o existe na cache, pesquisa banco de dados e atualiza a cache caso encontre. Se cliente (n\u00e3o) existe na cache, retorna (erro) informa\u00e7\u00e3o. Remo\u00e7\u00e3o de Cliente Administrador Determina CID de cliente a ser removido apagarCliente(CID) Portal Administrador Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Apaga dados do banco. Apaga dados da cache, se existe. Manipula\u00e7\u00e3o de Tarefas dos Clientes Nesta descri\u00e7\u00e3o, a intera\u00e7\u00e3o com a cache foi omitida, mas dever\u00e1 ser implementada. Inser\u00e7\u00e3o de tarefa Cliente Usa o CID informado pelo administrador inserirTarefa(CID, \"titulo da tarefa\", \"descri\u00e7\u00e3o da tarefa\") Portal Cliente Autentica o cliente Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Modifica\u00e7\u00e3o de tarefa Cliente Usa o CID informado pelo administrador modificarTarefa(CID, \"titulo da tarefa\", \"nova descri\u00e7\u00e3o da tarefa\") Portal Cliente Autentica o cliente Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Enumera\u00e7\u00e3o de tarefas Cliente Usa o CID informado pelo administrador listarTarefas(CID) Portal Cliente Autentica o cliente Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Remo\u00e7\u00e3o de todas as tarefas Cliente Usa o CID informado pelo administrador apagarTarefas(CID) Portal Cliente Autentica o cliente Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Remo\u00e7\u00e3o de tarefa Cliente Usa o CID informado pelo administrador apagarTarefa(CID, \"titulo da tarefa\") Portal Cliente Autentica o cliente Executa a opera\u00e7\u00e3o e retorna c\u00f3digo de erro/sucesso. Intera\u00e7\u00e3o entre portais Etapa 1 - Usu\u00e1rios/Portais Implementar os casos de uso usando como cache tabelas hash locais aos portais Cliente e Administrador. Se certificar de que cada opera\u00e7\u00e3o use uma API distinta na comunica\u00e7\u00e3o via gRPC ou uma mensagem distinta no uso de pub/sub. Se certificar de que todas as API possam retornar erros/exce\u00e7\u00f5es e que estas s\u00e3o tratadas; explicar sua decis\u00e3o de tratamento dos erros. Implementar testes automatizados de sucesso e falha de cada uma das opera\u00e7\u00f5es na API. Documentar o esquema de dados usados nas tabelas. Usar dois tipos de comunica\u00e7\u00e3o distintos entre clientes e portais. O sistema deve permitir a execu\u00e7\u00e3o de m\u00faltiplos cliente, administradores, portais cliente e portais administrador. Implementar a propaga\u00e7\u00e3o de informa\u00e7\u00e3o entre as diversas caches do sistema. Sugiro usar pubsub, j\u00e1 que a comunica\u00e7\u00e3o \u00e9 de 1 para muitos. Uma poss\u00edvel inst\u00e2ncia desta etapa do projeto seria a seguinte Etapa 2 - Banco de dados. Nesta etapa voc\u00ea modificar\u00e1 o sistema para que modifica\u00e7\u00f5es dos dados sejam refletidas no banco de dados particionado implementado usando consistent hashing . Etapa 3 - Replica\u00e7\u00e3o Nesta etapa voc\u00ea modificar\u00e1 o sistema para que todas as modifica\u00e7\u00f5es nas parti\u00e7\u00f5es do banco de dados sejam replicadas em outras parti\u00e7\u00f5es. Inteiro de 64 bits n\u00e3o \u00e9 BigInteger. \u21a9","title":"Projeto"},{"location":"projeto/#casos-de-uso","text":"Todo Diagramas de intera\u00e7\u00e3o.","title":"Casos de Uso"},{"location":"projeto/#interacao-entre-portais","text":"","title":"Intera\u00e7\u00e3o entre portais"},{"location":"projeto/#etapa-1-usuariosportais","text":"Implementar os casos de uso usando como cache tabelas hash locais aos portais Cliente e Administrador. Se certificar de que cada opera\u00e7\u00e3o use uma API distinta na comunica\u00e7\u00e3o via gRPC ou uma mensagem distinta no uso de pub/sub. Se certificar de que todas as API possam retornar erros/exce\u00e7\u00f5es e que estas s\u00e3o tratadas; explicar sua decis\u00e3o de tratamento dos erros. Implementar testes automatizados de sucesso e falha de cada uma das opera\u00e7\u00f5es na API. Documentar o esquema de dados usados nas tabelas. Usar dois tipos de comunica\u00e7\u00e3o distintos entre clientes e portais. O sistema deve permitir a execu\u00e7\u00e3o de m\u00faltiplos cliente, administradores, portais cliente e portais administrador. Implementar a propaga\u00e7\u00e3o de informa\u00e7\u00e3o entre as diversas caches do sistema. Sugiro usar pubsub, j\u00e1 que a comunica\u00e7\u00e3o \u00e9 de 1 para muitos. Uma poss\u00edvel inst\u00e2ncia desta etapa do projeto seria a seguinte","title":"Etapa 1 - Usu\u00e1rios/Portais"},{"location":"projeto/#etapa-2-banco-de-dados","text":"Nesta etapa voc\u00ea modificar\u00e1 o sistema para que modifica\u00e7\u00f5es dos dados sejam refletidas no banco de dados particionado implementado usando consistent hashing .","title":"Etapa 2 - Banco de dados."},{"location":"projeto/#etapa-3-replicacao","text":"Nesta etapa voc\u00ea modificar\u00e1 o sistema para que todas as modifica\u00e7\u00f5es nas parti\u00e7\u00f5es do banco de dados sejam replicadas em outras parti\u00e7\u00f5es. Inteiro de 64 bits n\u00e3o \u00e9 BigInteger. \u21a9","title":"Etapa 3 - Replica\u00e7\u00e3o"},{"location":"snippets/","text":"Comunica\u00e7\u00e3o Orientada a Fluxos TODO Material graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B transacionais. Isto \u00e9, eles prov\u00eaem as garantias na execu\u00e7\u00e3o de transa\u00e7\u00f5es conhecidas como propriedades ACID. ACID Atomicidade: transa\u00e7\u00f5es s\u00e3o tratadas de forma indivis\u00edvel, isto \u00e9, ou tudo ou nada. Consist\u00eancia: transa\u00e7\u00f5es levam banco de um estado consistente a outro. E.g., x == 2*y Isolamento: transa\u00e7\u00f5es n\u00e3o v\u00eaem dados n\u00e3o comitados umas das outras. Durabilidade: os efeitos de uma transa\u00e7\u00e3o comitada devem persistir no sistema a despeito de falhas. Para relembrar no que implica ACID, considere a seguinte sequ\u00eancia de opera\u00e7\u00f5es, onde X e Y s\u00e3o valores guardados pelo banco de dados, a, b e c s\u00e3o vari\u00e1veis definidas no programa, e SELECT e SET s\u00e3o comandos para ler e modificar o banco de dados. 1 2 3 4 5 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: SET Y=b Suponha duas inst\u00e2ncias desta sequ\u00eancia, \\(T_1\\) e \\(T_2\\) , concorrentes, em que as opera\u00e7\u00f5es escalonadas da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 T1 T2 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: a = SELECT X 6: c = a * 2 7: b = c + 10 8: SET X=c 9: SET Y=b 10:SET Y=b Ao final da execu\u00e7\u00e3o, X ter\u00e1 o valor atribu\u00eddo por \\(T_2\\) , mas \\(Y\\) ter\u00e1 o valor de \\(T_1\\) . Este escalonamento violou a consist\u00eancia do banco de dados por qu\u00ea as opera\u00e7\u00f5es n\u00e3o foram executadas isoladamente . , como mostra a hierarquia a seguir, adaptada de jepsen.io . graph BT S --> SS[Strict Serializable] RU[Read Uncommitted] --> RC[Read Committed] RC --> CS[Cursor Stability] RC --> MAV[Monotonic Atomic View] MAV --> RR[Repeatable Read] MAV --> SI[Snapshot Isolation] CS --> RR SI --> S[Serializable] RR --> S L[Linearizable] --> SS Seq[Sequential] --> L C[Causal] --> Seq WFR[Writes Follow Reads] --> C FIFO --> C MR[Monotonic Reads] --> FIFO MW[Monotonic Writes] --> FIFO RW[Read Your Writes] --> FIFO e \u00e9 a\u00ed que entram os modelos de consist\u00eancia.","title":"Snippets"},{"location":"snippets/#comunicacao-orientada-a-fluxos","text":"TODO Material graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B transacionais. Isto \u00e9, eles prov\u00eaem as garantias na execu\u00e7\u00e3o de transa\u00e7\u00f5es conhecidas como propriedades ACID. ACID Atomicidade: transa\u00e7\u00f5es s\u00e3o tratadas de forma indivis\u00edvel, isto \u00e9, ou tudo ou nada. Consist\u00eancia: transa\u00e7\u00f5es levam banco de um estado consistente a outro. E.g., x == 2*y Isolamento: transa\u00e7\u00f5es n\u00e3o v\u00eaem dados n\u00e3o comitados umas das outras. Durabilidade: os efeitos de uma transa\u00e7\u00e3o comitada devem persistir no sistema a despeito de falhas. Para relembrar no que implica ACID, considere a seguinte sequ\u00eancia de opera\u00e7\u00f5es, onde X e Y s\u00e3o valores guardados pelo banco de dados, a, b e c s\u00e3o vari\u00e1veis definidas no programa, e SELECT e SET s\u00e3o comandos para ler e modificar o banco de dados. 1 2 3 4 5 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: SET Y=b Suponha duas inst\u00e2ncias desta sequ\u00eancia, \\(T_1\\) e \\(T_2\\) , concorrentes, em que as opera\u00e7\u00f5es escalonadas da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 T1 T2 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: a = SELECT X 6: c = a * 2 7: b = c + 10 8: SET X=c 9: SET Y=b 10:SET Y=b Ao final da execu\u00e7\u00e3o, X ter\u00e1 o valor atribu\u00eddo por \\(T_2\\) , mas \\(Y\\) ter\u00e1 o valor de \\(T_1\\) . Este escalonamento violou a consist\u00eancia do banco de dados por qu\u00ea as opera\u00e7\u00f5es n\u00e3o foram executadas isoladamente . , como mostra a hierarquia a seguir, adaptada de jepsen.io . graph BT S --> SS[Strict Serializable] RU[Read Uncommitted] --> RC[Read Committed] RC --> CS[Cursor Stability] RC --> MAV[Monotonic Atomic View] MAV --> RR[Repeatable Read] MAV --> SI[Snapshot Isolation] CS --> RR SI --> S[Serializable] RR --> S L[Linearizable] --> SS Seq[Sequential] --> L C[Causal] --> Seq WFR[Writes Follow Reads] --> C FIFO --> C MR[Monotonic Reads] --> FIFO MW[Monotonic Writes] --> FIFO RW[Read Your Writes] --> FIFO e \u00e9 a\u00ed que entram os modelos de consist\u00eancia.","title":"Comunica\u00e7\u00e3o Orientada a Fluxos"},{"location":"tech/","text":"O objetivo deste cap\u00edtulo \u00e9 visitar algumas t\u00e9cnicas e tecnologias recentes e interessantes na \u00e1rea de sistemas distribu\u00eddos. N\u00e3o espere ent\u00e3o que as v\u00e1rias se\u00e7\u00f5es sejam conexas umas com as outras. Blockchain Em uma cadeia de suprimentos ( supply chain ) temos, em v\u00e1rios n\u00edveis, Clientes , Vendedores e Fornecedores , que estabelecem contratos de bens e servi\u00e7os . As intera\u00e7\u00f5es multipartido de trocas de bens podem ser registradas em livros raz\u00e3o mantidos independentemente pelos participantes, registrando cada troca de bens envolvendo o participante respons\u00e1vel. Considere o bem \"bananas\". Assim, o produtor registra quantas carretas de bananas vendeu e o atravessador quantas comprou, ainda na ro\u00e7a. O atravessador registra quantas carretas vendeu para o exportador e o exportador quantas comprou, no porto. O exportador registra quantas toneladas exportou e o importador quantas recebeu. O importador registra quantos cachos entregou para cada cadeia de supermercado, e assim por diante at\u00e9 que chegue ao consumidor. A um consumidor, o cliente final na cadeia, seria interessante saber quem produziu o cacho de bananas que est\u00e1 comprando, se a produ\u00e7\u00e3o \u00e9 livre de trabalho escravo, se o transporte foi feito dentro de par\u00e2metros corretos de temperatura, se n\u00e3o violou tratados de rotas mar\u00edtimas para proteger baleias, e assim por diante. Essencialmente, seria interessante rastrear como o bem \"bananas\" foi transferido de m\u00e3o em m\u00e3o at\u00e9 chegar \u00e0 feira livre, para decidir se deve ou n\u00e3o compr\u00e1-lo, pelo pre\u00e7o pedido. Al\u00e9m de bananas, h\u00e1 diversos outros bens dos quais precisamos rastrear a proveni\u00eancia, tanto bens tang\u00edveis (e.g., casa ) quanto intang\u00edveis (e.g., patente ), nominais (e.g., promiss\u00f3ria ) e ao portador (e.g., dinheiro \"vivo\" ), etc. Esta abordagem dificilmente permitiria aos participantes ou auditores reconstruir todo o trajeto , que dir\u00e1 um consumidor na ponta, al\u00e9m ser suscet\u00edvel a modifica\u00e7\u00f5es , intencionais ou n\u00e3o. Blockchains s\u00e3o uma alternativa para a constru\u00e7\u00e3o de um \"livro raz\u00e3o\" que \u00e9 compartilhado , incorrupt\u00edvel , decentralizado e \"facilmente\" audit\u00e1vel. A primeira blockchain foi introduzida por Satoshi Nakamoto 1 no artigo Bitcoin: A Peer-to-Peer Electronic Cash System , destinada a \"rastrear\" a troca da moeda digital bitcoin . Desde ent\u00e3o, diversas outras blockchains , como evidenciado nesta lista , foram desenvolvidas com diferentes usos e funcionalidades. De forma geral, podemos caracterizar blockchains como tendo as seguintes propriedades: Decentraliza\u00e7\u00e3o: os dados s\u00e3o mantidos por centenas ou milhares de n\u00f3s, usando protocolo P2P, e o sistemas n\u00e3o \u00e9 facilmente subjug\u00e1vel. Consenso: todos os participantes v\u00eaem, eventualmente, a mesma sequ\u00eancia de transa\u00e7\u00f5es. Proveni\u00eancia: todo o hist\u00f3rico de um bem \u00e9 mantido na blockchain e pode ser lido. Imutabilidade: entradas na blockchain n\u00e3o podem ser alteradas. Finalidade: entradas na blockchain n\u00e3o podem ser refutadas (o que impede o gasto duplo). John Oliver, apresentador do Last Week Tonight , descreveu bitcoin em mar\u00e7o de 2018 como sendo Everything you don't understand about money, combined with everything you don't understand about technology. A complexidade aumenta com as funcionalidades das demais blockchains, pois nestas, diferentes tipos de bens podem ser registrados, usu\u00e1rios podem ser identific\u00e1veis, os registros podem ser audit\u00e1veis sobe certas circunst\u00e2ncias, e o consumo de energia exorbitante pode ser drasticamente reduzido. Mas come\u00e7emos do come\u00e7o e falemos sobre Bitcoin. Bitcoin Bitcoin \u00e9 uma moeda digital, usada para comprar pizzas , drogas e teslas . Tamb\u00e9m \u00e9 tido por muitos como investimento, mas neste aspecto, veja o gr\u00e1fico e tire suas pr\u00f3prias conclus\u00f5es. Cryptocurrency Prices by Coinlib Mas como funciona a blockchain do bitcoin? Vejamos um exemplo, nos mesmos moldes da cadeia da bitcoin. Em primeiro lugar, para a constru\u00e7\u00e3o da cadeia, precisamos de fun\u00e7\u00f5es hash. Como sabem, pequenas modifica\u00e7\u00f5es na entrada da fun\u00e7\u00e3o hash levam a grandes altera\u00e7\u00f5es na sa\u00edda. Por exemplo, \\(sha256(lasaro) = 0490cc073d98dad147ec3d7348bfd54759ce7ef0134d02f28641c8cede61e5f4\\) \\(sha256(l\u00e1saro) = dc2a5d1a6fb23c8449d0be17d412309a97b208efbec67254524bdac0a9dcf1ae\\) . https://andersbrownworth.com/blockchain/hash Tendo fun\u00e7\u00f5es hash, podemos construir blocos da cadeia. A princ\u00edpio, cada cada bloco na cadeia tem um identificador \u00fanico um conjunto de transa\u00e7\u00f5es, no estilo passe 10 moedas do Jaquim para o Jos\u00e9 um n\u00famero aleat\u00f3rio conhecido como nonce , um tempero para o bloco. Para cada bloco, precisamos calcular tamb\u00e9m seu hash. Dada a propriedade vista acima, sabemos que pequenas modifica\u00e7\u00f5es nos dados de um bloco levam a grandes modifica\u00e7\u00f5es no hash do bloco em si. Logo, pequenas modifica\u00e7\u00f5es em qualquer dos campos descritos, leva a mudan\u00e7as no hash do bloco. https://andersbrownworth.com/blockchain/block Como pr\u00f3ximo passo, precisamos encadear os blocos e, para isto, usamos identificadores sequenciais e adicionamos a cada bloco o hash do bloco anterior. Isto \u00e9, cada bloco referencia o anterior, guardando um resumo do mesmo. https://andersbrownworth.com/blockchain/blockchain Dado que modifica\u00e7\u00f5es no bloco mudam seu hash, altera\u00e7\u00f5es em um bloco da cadeia leva o bloco seguinte a ter um hash anterior inv\u00e1lido, quebrando a cadeia. \u00c9 esta caracter\u00edstica que leva \u00e0 imutabilidade de partes antigas da cadeia. Mas como os blocos s\u00e3o constru\u00eddos? Este \u00e9 um processo conhecido como minera\u00e7\u00e3o. https://andersbrownworth.com/blockchain/blockchain \u00c9 com a minera\u00e7\u00e3o que novos blocos s\u00e3o constru\u00eddos mas n\u00e3o adianta minerar se os blocos n\u00e3o forem aceitos pela comunidade. https://andersbrownworth.com/blockchain/distributed Assim, embora partes antigas da cadeia sejam est\u00e1veis, partes recentes podem ser modificadas, uma vez que processos podem mudar de opini\u00e3o sobre quais os \u00faltimos blocos na cadeia. Contratos inteligentes Os termos do neg\u00f3cio s\u00e3o mantidos na blockchain: \"Se na data X a entidade E n\u00e3o tiver transferido D dinheiros para a entidade F, ent\u00e3o transfira o asset A de E para F.\" Se quiser saber mais, consulte esta pequena lista artigos sobre blockchain . Todo NFT Smart-contracts grupos pequenos e aleat\u00f3rios como certificadores. proof-of-stake Como sincronizar duas m\u00e1quinas? Abordagem 1 Copie os arquivos da fonte para o destino Abordagem 2 Produza um hash do arquivo Troque o hash com a outra m\u00e1quina Se hashes iguais, pronto. Se hashes diferentes, copie o arquivo para a outra m\u00e1quina. Abordagem 3 - Merkle Tree 2 Divida o arquivo em blocos de mesmo tamanho Fa\u00e7a um hash de cada bloco Se mais de um hash gerado, Concatene hashes duas a duas; cada concatena\u00e7\u00e3o resulta em um novo bloco. Repita o processo; os hashes resultantes correspondem a uma \u00e1rvore Troque hashes da raiz. Se hashes iguais, pronto. Se hashes diferentes troque hashes das raizes das sub\u00e1rvores e execute recursivamente. Se um byte \u00e9 adicionado no meio do arquivo? A conclus\u00e3o \u00e9 que blocos com tamanho pr\u00e9-definido s\u00e3o problem\u00e1ticos e que precisamos de blocos definidos pelo conte\u00fado. Por exemplo, em um texto, uma possibilidade \u00e9 definir um bloco como um per\u00edodo ou um par\u00e1grafo; se uma palavra \u00e9 inserida no texto, , somente o bloco em que foi inserida \u00e9 modificado e somente o hash do mesmo ter\u00e1 novo valor. Mas esta abordagem n\u00e3o \u00e9 gen\u00e9rica, pois qual o correspondente em uma imagem ou um \u00e1udio ou em um arquivo tgz ? Rabin Fingerprinting Rabin Fingerprint Rolling Hash A Small Piece of Big Data Big-Data Big data is a term for data sets that are so large or complex that traditional data processing application software is inadequate to deal with them. Ciclo convencional: Coleta Armazenamento An\u00e1lise Consulta Compartilhamento Visualiza\u00e7\u00e3o Atualiza\u00e7\u00e3o ... \u00c1reas Grandes massas de dados: Propaganda Astronomia Ci\u00eancia e-governos meteorologia genomics Dados Internet das coisas sensoriamento remoto suas fotos logs de software RFID redes de sensores ... Qu\u00e3o grande \u00e9 ``big'' o suficiente? Depende dos dados, ferramentas, e capacidade de manipul\u00e1-los. Uma vez dado um passo, o alvo passa a ser o pr\u00f3ximo passo. Isso quer dizer que vai de alguns TB at\u00e9 Petabytes, dependendo do problema. Gartner, 2012 Big data is high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization. Volume: incapacidade de armazenar todos os dados; apenas observe e guarde conclus\u00f5es Velocidade: dados passando em ``tempo real'' Variedade: imagens, v\u00eddeos, \u00e1udio, temperatura,... Machine learning para automa\u00e7\u00e3o de extra\u00e7\u00e3o de informa\u00e7\u00e3o, por exemplo, detec\u00e7\u00e3o de padr\u00f5es, sem se preocupar com o porqu\u00ea dos mesmos. Como lidar? Bancos de dados colunares Stream DBs MapReduce ... Map Reduce Google, 2004 Processamento distribu\u00eddo Processa arquivos no Google FS Chubby Google, 2006 Hadoop HDFS: Hadoop Distributed File System Map Reduce Yahoo! Open source em 2011, 1.0.0 2012, 2.0.0, 2017, 3.0.0 nov 2018, 2.9.2 Ecosistema Hive: data warehouse Spark: Kafka Yarn Pig: linguagem para especifica\u00e7\u00e3o de data flow. HBase: banco de dados estruturado Sqoop Flume Oozie Avro: serializa\u00e7\u00e3o Mahout: machine learning HDFS Distribu\u00eddo Escal\u00e1vel Cost effective Tolerante a falhas Alta vaz\u00e3o Arquitetura Rack e rack failure Top of rack switch Core switch Name Node: nomes das pastas e arquivos Data Node: conte\u00fado dos arquivos Cliente Arquitetura Crie arquivo: cliente -> name node Escreva um block (e.g., 128MB): cliente Aloque block: cliente -> name node Salve os dados: cliente -> data node Heartbeat block report: data node -> name node Dados s\u00e3o replicados (RF configurado por arquivo): Data node -> data node Name node Dados em memory e edit log. Name node \u00e9 um SPOF? Quorum Journal Manager replica edit log. Standby Name Node Zookeeper usado para decidir quem \u00e9 o l\u00edder Secondary Name Node replica checkpoint da imagem em mem\u00f3ria. MapReduce Programa\u00e7\u00e3o funcional Map: (map length (() (a) (a b c)) = (0 1 3)) Fold/Reduce: (reduce + (1 2 3)) = 6 MapReduce N\u00e3o h\u00e1 depend\u00eancia entre os dados Dados divididos em \\emph{shards} Execu\u00e7\u00e3o paralela e distribu\u00edda Trabalhador recebe um shard Mestre agrega valores Milhares de processos Petabytes de dados MapReduce Shards s\u00e3o arquivos do GFS/HDFS/EC2 Fun\u00e7\u00e3o mapeada a cada shard Resultado \u00e9 lista de chaves e valores Agrega\u00e7\u00e3o acontece por chaves Resultado s\u00e3o arquivos no GFS/HDFS/EC2 MapReduce Exemplo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import ... public class WordCount { public static class TokenizerMapper extends Mapper < Object , Text , Text , IntWritable > { private final static IntWritable one = new IntWritable ( 1 ); private Text word = new Text (); public void map ( Object key , Text value , Context context ) throws IOException , InterruptedException { StringTokenizer itr = new StringTokenizer ( value . toString ()); while ( itr . hasMoreTokens ()) { word . set ( itr . nextToken ()); context . write ( word , one ); } } } ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ... public static class IntSumReducer extends Reducer < Text , IntWritable , Text , IntWritable > { private IntWritable result = new IntWritable (); public void reduce ( Text key , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException { int sum = 0 ; for ( IntWritable val : values ) sum += val . get (); result . set ( sum ); context . write ( key , result ); } } public static void main ( String [] args ) throws Exception { ... } } Fonte https://youtu.be/DJPwV2ge9m0?list=PLkz1SCf5iB4dw3jbRo0SYCk2urRESUA3v Serverless Quando voce est\u00e1 desenvolvendo uma aplica\u00e7\u00e3o distribu\u00edda, voc\u00ea provavelmente pensa em clientes e servidores. Quando se foca nos servidores, voc\u00ea pensa em um processo, escutando em uma porta, em leituras em sockets, parsing de requisi\u00e7\u00f5es, invoca\u00e7\u00f5es de m\u00e9todos, c\u00e1lculo de resultados e envio de uma resposta. Mesmo que voc\u00ea use frameworks que simplifiquem parte deste fluxo, como o gRPC, voc\u00ea ainda deve pensar na cria\u00e7\u00e3o do servidor, no transporte utilizado, e outros detalhes que n\u00e3o tem a ver com a opera\u00e7\u00e3o a ser executada. A ideia da computa\u00e7\u00e3o \"sem servidor\" ( serverless ) e remover todos estes detalhes do seu caminho e deixar que voc\u00ea se preocupe exclusivamente com as opera\u00e7\u00f5es a serem executadas, as fun\u00e7\u00f5es que tratam suas requisi\u00e7\u00f5es. Um dos exemplos desta arquitetura popularizados pela AWS \u00e9 o seguinte: envie uma imagem para armazenamento na nuvem quando a mensagem \u00e9 recebida, v\u00e1rias fun\u00e7\u00f5es s\u00e3o disparadas para analis\u00e1-la tagging autom\u00e1tico: Tem \u00e1gua? Gato? Rosto? Uberl\u00e2ndia? sugest\u00e3o de edi\u00e7\u00f5es: Horizonte inclinado? Super ou sub-exposta? sentimento duplicatas etc Na arquitetura normal, voc\u00ea deveria escrever um programa que possivelmente siga o seguinte fluxo: Enquanto houver dados a serem lidos Leia imagem do socket Salve imagem Para toda imagem \\(i\\) salva auto_tag( \\(i\\) ) auto_edit( \\(i\\) ) analise_sentimento( \\(i\\) ) teste_duplicata( \\(i\\) ) ... J\u00e1 na arquitetura serverless , voc\u00ea s\u00f3 precisa escrever as fun\u00e7\u00f5es em si e associ\u00e1-las a eventos nova imagem e toda vez que uma nova imagem for submetida para o sistema, possivelmente sem ter que escrever c\u00f3digo do lado do servidor tamb\u00e9m, as fun\u00e7\u00f5es ser\u00e3o executadas na imagem. O primeiro servi\u00e7o deste tipo criado foi o AWS Lambda, que permite que suas fun\u00e7\u00f5es sejam criadas em diferentes linguagens e enviadas para a nuvem para aguardarem suas entradas. Obviamente, o servidor ainda existe , mas ele \u00e9 gerado e executado pelo provedor. Quando uma nova fun\u00e7\u00e3o \u00e9 registrada, o servidor \u00e9 capaz de multiplexar novos dados para esta fun\u00e7\u00e3o. O servidor tamb\u00e9m \u00e9 respons\u00e1vel por limitar o tempo de execu\u00e7\u00e3o da fun\u00e7\u00e3o e por calcular por quanto tempo a fun\u00e7\u00e3o executou para executar o faturamento da mesma. Amazon pode at\u00e9 ter dado o pontap\u00e9 inicial da computa\u00e7\u00e3o serverless , mas a ideia se espalhou e hoje h\u00e1 diversos sistemas equivalentes, tanto no mundo dos provedores de computa\u00e7\u00e3o em nuvem quanto na comunidade software livre, por exemplo: KNative OpenFaaS OpenWhisk A grande vantagem do uso destas solu\u00e7\u00f5es livres est\u00e1 no uso de containers para executar seu c\u00f3digo, e como containers s\u00e3o suportados em praticamente todos os provedores hoje, \u00e9 poss\u00edvel migrar suas fun\u00e7\u00f5es entre provedores ou mesmo combinar diversos provedores em uma \u00fanica aplica\u00e7\u00e3o. Para overview r\u00e1pido de um destes projetos, OpenFaaS, assista ao seguinte video Pseud\u00f4nimo. Possivelmente mais de uma pessoa. \u21a9 Modern Algorithms and Data Structures: Merkle Trees \u21a9","title":"Tecnologias"},{"location":"tech/#blockchain","text":"Em uma cadeia de suprimentos ( supply chain ) temos, em v\u00e1rios n\u00edveis, Clientes , Vendedores e Fornecedores , que estabelecem contratos de bens e servi\u00e7os . As intera\u00e7\u00f5es multipartido de trocas de bens podem ser registradas em livros raz\u00e3o mantidos independentemente pelos participantes, registrando cada troca de bens envolvendo o participante respons\u00e1vel. Considere o bem \"bananas\". Assim, o produtor registra quantas carretas de bananas vendeu e o atravessador quantas comprou, ainda na ro\u00e7a. O atravessador registra quantas carretas vendeu para o exportador e o exportador quantas comprou, no porto. O exportador registra quantas toneladas exportou e o importador quantas recebeu. O importador registra quantos cachos entregou para cada cadeia de supermercado, e assim por diante at\u00e9 que chegue ao consumidor. A um consumidor, o cliente final na cadeia, seria interessante saber quem produziu o cacho de bananas que est\u00e1 comprando, se a produ\u00e7\u00e3o \u00e9 livre de trabalho escravo, se o transporte foi feito dentro de par\u00e2metros corretos de temperatura, se n\u00e3o violou tratados de rotas mar\u00edtimas para proteger baleias, e assim por diante. Essencialmente, seria interessante rastrear como o bem \"bananas\" foi transferido de m\u00e3o em m\u00e3o at\u00e9 chegar \u00e0 feira livre, para decidir se deve ou n\u00e3o compr\u00e1-lo, pelo pre\u00e7o pedido. Al\u00e9m de bananas, h\u00e1 diversos outros bens dos quais precisamos rastrear a proveni\u00eancia, tanto bens tang\u00edveis (e.g., casa ) quanto intang\u00edveis (e.g., patente ), nominais (e.g., promiss\u00f3ria ) e ao portador (e.g., dinheiro \"vivo\" ), etc. Esta abordagem dificilmente permitiria aos participantes ou auditores reconstruir todo o trajeto , que dir\u00e1 um consumidor na ponta, al\u00e9m ser suscet\u00edvel a modifica\u00e7\u00f5es , intencionais ou n\u00e3o. Blockchains s\u00e3o uma alternativa para a constru\u00e7\u00e3o de um \"livro raz\u00e3o\" que \u00e9 compartilhado , incorrupt\u00edvel , decentralizado e \"facilmente\" audit\u00e1vel. A primeira blockchain foi introduzida por Satoshi Nakamoto 1 no artigo Bitcoin: A Peer-to-Peer Electronic Cash System , destinada a \"rastrear\" a troca da moeda digital bitcoin . Desde ent\u00e3o, diversas outras blockchains , como evidenciado nesta lista , foram desenvolvidas com diferentes usos e funcionalidades. De forma geral, podemos caracterizar blockchains como tendo as seguintes propriedades: Decentraliza\u00e7\u00e3o: os dados s\u00e3o mantidos por centenas ou milhares de n\u00f3s, usando protocolo P2P, e o sistemas n\u00e3o \u00e9 facilmente subjug\u00e1vel. Consenso: todos os participantes v\u00eaem, eventualmente, a mesma sequ\u00eancia de transa\u00e7\u00f5es. Proveni\u00eancia: todo o hist\u00f3rico de um bem \u00e9 mantido na blockchain e pode ser lido. Imutabilidade: entradas na blockchain n\u00e3o podem ser alteradas. Finalidade: entradas na blockchain n\u00e3o podem ser refutadas (o que impede o gasto duplo). John Oliver, apresentador do Last Week Tonight , descreveu bitcoin em mar\u00e7o de 2018 como sendo Everything you don't understand about money, combined with everything you don't understand about technology. A complexidade aumenta com as funcionalidades das demais blockchains, pois nestas, diferentes tipos de bens podem ser registrados, usu\u00e1rios podem ser identific\u00e1veis, os registros podem ser audit\u00e1veis sobe certas circunst\u00e2ncias, e o consumo de energia exorbitante pode ser drasticamente reduzido. Mas come\u00e7emos do come\u00e7o e falemos sobre Bitcoin.","title":"Blockchain"},{"location":"tech/#bitcoin","text":"Bitcoin \u00e9 uma moeda digital, usada para comprar pizzas , drogas e teslas . Tamb\u00e9m \u00e9 tido por muitos como investimento, mas neste aspecto, veja o gr\u00e1fico e tire suas pr\u00f3prias conclus\u00f5es. Cryptocurrency Prices by Coinlib Mas como funciona a blockchain do bitcoin? Vejamos um exemplo, nos mesmos moldes da cadeia da bitcoin. Em primeiro lugar, para a constru\u00e7\u00e3o da cadeia, precisamos de fun\u00e7\u00f5es hash. Como sabem, pequenas modifica\u00e7\u00f5es na entrada da fun\u00e7\u00e3o hash levam a grandes altera\u00e7\u00f5es na sa\u00edda. Por exemplo, \\(sha256(lasaro) = 0490cc073d98dad147ec3d7348bfd54759ce7ef0134d02f28641c8cede61e5f4\\) \\(sha256(l\u00e1saro) = dc2a5d1a6fb23c8449d0be17d412309a97b208efbec67254524bdac0a9dcf1ae\\) . https://andersbrownworth.com/blockchain/hash Tendo fun\u00e7\u00f5es hash, podemos construir blocos da cadeia. A princ\u00edpio, cada cada bloco na cadeia tem um identificador \u00fanico um conjunto de transa\u00e7\u00f5es, no estilo passe 10 moedas do Jaquim para o Jos\u00e9 um n\u00famero aleat\u00f3rio conhecido como nonce , um tempero para o bloco. Para cada bloco, precisamos calcular tamb\u00e9m seu hash. Dada a propriedade vista acima, sabemos que pequenas modifica\u00e7\u00f5es nos dados de um bloco levam a grandes modifica\u00e7\u00f5es no hash do bloco em si. Logo, pequenas modifica\u00e7\u00f5es em qualquer dos campos descritos, leva a mudan\u00e7as no hash do bloco. https://andersbrownworth.com/blockchain/block Como pr\u00f3ximo passo, precisamos encadear os blocos e, para isto, usamos identificadores sequenciais e adicionamos a cada bloco o hash do bloco anterior. Isto \u00e9, cada bloco referencia o anterior, guardando um resumo do mesmo. https://andersbrownworth.com/blockchain/blockchain Dado que modifica\u00e7\u00f5es no bloco mudam seu hash, altera\u00e7\u00f5es em um bloco da cadeia leva o bloco seguinte a ter um hash anterior inv\u00e1lido, quebrando a cadeia. \u00c9 esta caracter\u00edstica que leva \u00e0 imutabilidade de partes antigas da cadeia. Mas como os blocos s\u00e3o constru\u00eddos? Este \u00e9 um processo conhecido como minera\u00e7\u00e3o. https://andersbrownworth.com/blockchain/blockchain \u00c9 com a minera\u00e7\u00e3o que novos blocos s\u00e3o constru\u00eddos mas n\u00e3o adianta minerar se os blocos n\u00e3o forem aceitos pela comunidade. https://andersbrownworth.com/blockchain/distributed Assim, embora partes antigas da cadeia sejam est\u00e1veis, partes recentes podem ser modificadas, uma vez que processos podem mudar de opini\u00e3o sobre quais os \u00faltimos blocos na cadeia.","title":"Bitcoin"},{"location":"tech/#contratos-inteligentes","text":"Os termos do neg\u00f3cio s\u00e3o mantidos na blockchain: \"Se na data X a entidade E n\u00e3o tiver transferido D dinheiros para a entidade F, ent\u00e3o transfira o asset A de E para F.\" Se quiser saber mais, consulte esta pequena lista artigos sobre blockchain . Todo NFT Smart-contracts grupos pequenos e aleat\u00f3rios como certificadores. proof-of-stake","title":"Contratos inteligentes"},{"location":"tech/#como-sincronizar-duas-maquinas","text":"Abordagem 1 Copie os arquivos da fonte para o destino Abordagem 2 Produza um hash do arquivo Troque o hash com a outra m\u00e1quina Se hashes iguais, pronto. Se hashes diferentes, copie o arquivo para a outra m\u00e1quina. Abordagem 3 - Merkle Tree 2 Divida o arquivo em blocos de mesmo tamanho Fa\u00e7a um hash de cada bloco Se mais de um hash gerado, Concatene hashes duas a duas; cada concatena\u00e7\u00e3o resulta em um novo bloco. Repita o processo; os hashes resultantes correspondem a uma \u00e1rvore Troque hashes da raiz. Se hashes iguais, pronto. Se hashes diferentes troque hashes das raizes das sub\u00e1rvores e execute recursivamente. Se um byte \u00e9 adicionado no meio do arquivo? A conclus\u00e3o \u00e9 que blocos com tamanho pr\u00e9-definido s\u00e3o problem\u00e1ticos e que precisamos de blocos definidos pelo conte\u00fado. Por exemplo, em um texto, uma possibilidade \u00e9 definir um bloco como um per\u00edodo ou um par\u00e1grafo; se uma palavra \u00e9 inserida no texto, , somente o bloco em que foi inserida \u00e9 modificado e somente o hash do mesmo ter\u00e1 novo valor. Mas esta abordagem n\u00e3o \u00e9 gen\u00e9rica, pois qual o correspondente em uma imagem ou um \u00e1udio ou em um arquivo tgz ?","title":"Como sincronizar duas m\u00e1quinas?"},{"location":"tech/#rabin-fingerprinting","text":"Rabin Fingerprint Rolling Hash","title":"Rabin Fingerprinting"},{"location":"tech/#a-small-piece-of-big-data","text":"Big-Data Big data is a term for data sets that are so large or complex that traditional data processing application software is inadequate to deal with them. Ciclo convencional: Coleta Armazenamento An\u00e1lise Consulta Compartilhamento Visualiza\u00e7\u00e3o Atualiza\u00e7\u00e3o ... \u00c1reas Grandes massas de dados: Propaganda Astronomia Ci\u00eancia e-governos meteorologia genomics Dados Internet das coisas sensoriamento remoto suas fotos logs de software RFID redes de sensores ... Qu\u00e3o grande \u00e9 ``big'' o suficiente? Depende dos dados, ferramentas, e capacidade de manipul\u00e1-los. Uma vez dado um passo, o alvo passa a ser o pr\u00f3ximo passo. Isso quer dizer que vai de alguns TB at\u00e9 Petabytes, dependendo do problema. Gartner, 2012 Big data is high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization. Volume: incapacidade de armazenar todos os dados; apenas observe e guarde conclus\u00f5es Velocidade: dados passando em ``tempo real'' Variedade: imagens, v\u00eddeos, \u00e1udio, temperatura,... Machine learning para automa\u00e7\u00e3o de extra\u00e7\u00e3o de informa\u00e7\u00e3o, por exemplo, detec\u00e7\u00e3o de padr\u00f5es, sem se preocupar com o porqu\u00ea dos mesmos. Como lidar? Bancos de dados colunares Stream DBs MapReduce ... Map Reduce Google, 2004 Processamento distribu\u00eddo Processa arquivos no Google FS Chubby Google, 2006 Hadoop HDFS: Hadoop Distributed File System Map Reduce Yahoo! Open source em 2011, 1.0.0 2012, 2.0.0, 2017, 3.0.0 nov 2018, 2.9.2 Ecosistema Hive: data warehouse Spark: Kafka Yarn Pig: linguagem para especifica\u00e7\u00e3o de data flow. HBase: banco de dados estruturado Sqoop Flume Oozie Avro: serializa\u00e7\u00e3o Mahout: machine learning HDFS Distribu\u00eddo Escal\u00e1vel Cost effective Tolerante a falhas Alta vaz\u00e3o Arquitetura Rack e rack failure Top of rack switch Core switch Name Node: nomes das pastas e arquivos Data Node: conte\u00fado dos arquivos Cliente Arquitetura Crie arquivo: cliente -> name node Escreva um block (e.g., 128MB): cliente Aloque block: cliente -> name node Salve os dados: cliente -> data node Heartbeat block report: data node -> name node Dados s\u00e3o replicados (RF configurado por arquivo): Data node -> data node Name node Dados em memory e edit log. Name node \u00e9 um SPOF? Quorum Journal Manager replica edit log. Standby Name Node Zookeeper usado para decidir quem \u00e9 o l\u00edder Secondary Name Node replica checkpoint da imagem em mem\u00f3ria. MapReduce Programa\u00e7\u00e3o funcional Map: (map length (() (a) (a b c)) = (0 1 3)) Fold/Reduce: (reduce + (1 2 3)) = 6 MapReduce N\u00e3o h\u00e1 depend\u00eancia entre os dados Dados divididos em \\emph{shards} Execu\u00e7\u00e3o paralela e distribu\u00edda Trabalhador recebe um shard Mestre agrega valores Milhares de processos Petabytes de dados MapReduce Shards s\u00e3o arquivos do GFS/HDFS/EC2 Fun\u00e7\u00e3o mapeada a cada shard Resultado \u00e9 lista de chaves e valores Agrega\u00e7\u00e3o acontece por chaves Resultado s\u00e3o arquivos no GFS/HDFS/EC2 MapReduce Exemplo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import ... public class WordCount { public static class TokenizerMapper extends Mapper < Object , Text , Text , IntWritable > { private final static IntWritable one = new IntWritable ( 1 ); private Text word = new Text (); public void map ( Object key , Text value , Context context ) throws IOException , InterruptedException { StringTokenizer itr = new StringTokenizer ( value . toString ()); while ( itr . hasMoreTokens ()) { word . set ( itr . nextToken ()); context . write ( word , one ); } } } ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ... public static class IntSumReducer extends Reducer < Text , IntWritable , Text , IntWritable > { private IntWritable result = new IntWritable (); public void reduce ( Text key , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException { int sum = 0 ; for ( IntWritable val : values ) sum += val . get (); result . set ( sum ); context . write ( key , result ); } } public static void main ( String [] args ) throws Exception { ... } } Fonte https://youtu.be/DJPwV2ge9m0?list=PLkz1SCf5iB4dw3jbRo0SYCk2urRESUA3v","title":"A Small Piece of Big Data"},{"location":"tech/#serverless","text":"Quando voce est\u00e1 desenvolvendo uma aplica\u00e7\u00e3o distribu\u00edda, voc\u00ea provavelmente pensa em clientes e servidores. Quando se foca nos servidores, voc\u00ea pensa em um processo, escutando em uma porta, em leituras em sockets, parsing de requisi\u00e7\u00f5es, invoca\u00e7\u00f5es de m\u00e9todos, c\u00e1lculo de resultados e envio de uma resposta. Mesmo que voc\u00ea use frameworks que simplifiquem parte deste fluxo, como o gRPC, voc\u00ea ainda deve pensar na cria\u00e7\u00e3o do servidor, no transporte utilizado, e outros detalhes que n\u00e3o tem a ver com a opera\u00e7\u00e3o a ser executada. A ideia da computa\u00e7\u00e3o \"sem servidor\" ( serverless ) e remover todos estes detalhes do seu caminho e deixar que voc\u00ea se preocupe exclusivamente com as opera\u00e7\u00f5es a serem executadas, as fun\u00e7\u00f5es que tratam suas requisi\u00e7\u00f5es. Um dos exemplos desta arquitetura popularizados pela AWS \u00e9 o seguinte: envie uma imagem para armazenamento na nuvem quando a mensagem \u00e9 recebida, v\u00e1rias fun\u00e7\u00f5es s\u00e3o disparadas para analis\u00e1-la tagging autom\u00e1tico: Tem \u00e1gua? Gato? Rosto? Uberl\u00e2ndia? sugest\u00e3o de edi\u00e7\u00f5es: Horizonte inclinado? Super ou sub-exposta? sentimento duplicatas etc Na arquitetura normal, voc\u00ea deveria escrever um programa que possivelmente siga o seguinte fluxo: Enquanto houver dados a serem lidos Leia imagem do socket Salve imagem Para toda imagem \\(i\\) salva auto_tag( \\(i\\) ) auto_edit( \\(i\\) ) analise_sentimento( \\(i\\) ) teste_duplicata( \\(i\\) ) ... J\u00e1 na arquitetura serverless , voc\u00ea s\u00f3 precisa escrever as fun\u00e7\u00f5es em si e associ\u00e1-las a eventos nova imagem e toda vez que uma nova imagem for submetida para o sistema, possivelmente sem ter que escrever c\u00f3digo do lado do servidor tamb\u00e9m, as fun\u00e7\u00f5es ser\u00e3o executadas na imagem. O primeiro servi\u00e7o deste tipo criado foi o AWS Lambda, que permite que suas fun\u00e7\u00f5es sejam criadas em diferentes linguagens e enviadas para a nuvem para aguardarem suas entradas. Obviamente, o servidor ainda existe , mas ele \u00e9 gerado e executado pelo provedor. Quando uma nova fun\u00e7\u00e3o \u00e9 registrada, o servidor \u00e9 capaz de multiplexar novos dados para esta fun\u00e7\u00e3o. O servidor tamb\u00e9m \u00e9 respons\u00e1vel por limitar o tempo de execu\u00e7\u00e3o da fun\u00e7\u00e3o e por calcular por quanto tempo a fun\u00e7\u00e3o executou para executar o faturamento da mesma. Amazon pode at\u00e9 ter dado o pontap\u00e9 inicial da computa\u00e7\u00e3o serverless , mas a ideia se espalhou e hoje h\u00e1 diversos sistemas equivalentes, tanto no mundo dos provedores de computa\u00e7\u00e3o em nuvem quanto na comunidade software livre, por exemplo: KNative OpenFaaS OpenWhisk A grande vantagem do uso destas solu\u00e7\u00f5es livres est\u00e1 no uso de containers para executar seu c\u00f3digo, e como containers s\u00e3o suportados em praticamente todos os provedores hoje, \u00e9 poss\u00edvel migrar suas fun\u00e7\u00f5es entre provedores ou mesmo combinar diversos provedores em uma \u00fanica aplica\u00e7\u00e3o. Para overview r\u00e1pido de um destes projetos, OpenFaaS, assista ao seguinte video Pseud\u00f4nimo. Possivelmente mais de uma pessoa. \u21a9 Modern Algorithms and Data Structures: Merkle Trees \u21a9","title":"Serverless"},{"location":"arch/arch/","text":"Introdu\u00e7\u00e3o De acordo com David Garlan and Mary Shaw, January 1994, CMU-CS-94-166, em An Introduction to Software Architecture ... an architectural style determines the vocabulary of components and connectors that can be used in instances of that style, together with a set of constraints on how they can be combined. These can include topological constraints on architectural descriptions (e.g., no cycles). Other constraints\u2014say, having to do with execution semantics\u2014might also be part of the style definition. Em outras palavras, um estilo ou padr\u00e3o arquitetural \u00e9 o conjunto de princ\u00edpios que prov\u00ea uma infraestrutura abstrata para uma fam\u00edlia de sistemas, e promove o reuso de projeto ao prover solu\u00e7\u00f5es para problemas recorrentes e frequentes ao definir quais o componentes presentes no sistema e como estes interagem uns com os outros, por meio de conectores , para implementar a solu\u00e7\u00e3o para um problema. Componentes e Conectores Para se alcan\u00e7ar efici\u00eancia no desenvolvimento de sistemas, \u00e9 imperativo que se pare de reinventar a roda a cada itera\u00e7\u00e3o e, em vez disso, se reuse artefatos existentes, providos pela linguagem sendo usada, por frameworks de terceiros e por itera\u00e7\u00f5es anteriores da equipe. De fato, o desenvolvimento de novos sistemas deveria ser pautado pela cria\u00e7\u00e3o de componentes simples e coesos, que possam ser operados independentemente e que por meio de interfaces bem especificadas completas, possam ser ent\u00e3o conectados para resolver um problema maior. Uma vez selecionados, os componentes s\u00e3o conectados por meio de conectores, que podem assumir m\u00faltiplas formas para esconder as complexas itera\u00e7\u00f5es entres os componentes, por exemplo, por meio de fluxos de mensagens ou invoca\u00e7\u00f5es remotas de procedimentos. graph LR A[Componente 1] --> C{Conector} --> B(Componente 2) TODO Desenhar o conector usando s\u00edmbolo padr\u00e3o. Componentes bem projetados, deveriam ser facilmente substitu\u00eddos por outros que respeitem a conex\u00e3o. Isto aumenta a manutenabilidade do sistemas e pode simplificar passos como a replica\u00e7\u00e3o de componentes. graph LR A[Componente 1] --> C{Conector 1} --> B(Componente 2) D{Conector 2} E{Conector 3} Alguns conectores s\u00e3o complexos o suficiente para serem considerados eles pr\u00f3prios componentes, mas no contexto desta discuss\u00e3o, a bem da abstra\u00e7\u00e3o, os consideraremos apenas como conectores. Por exemplo, um broker MQTT usado para a comunica\u00e7\u00e3o entre dois processos \u00e9 considerado um conector, e n\u00e3o um componente. Dependendo de como s\u00e3o conectados, haver\u00e1 maior ou menor depend\u00eancia entre os componentes. Quando houver forte depend\u00eancia, diremos que os componentes est\u00e3o fortemente acoplados ( tightly coupled ). Caso contr\u00e1rio, diremos que est\u00e3o fracamente acoplados ( loosely coupled ). A raz\u00e3o \u00f3bvia para preferir sistemas fracamente conectados \u00e9 sua capacidade de tolerar disrup\u00e7\u00f5es; se um componente depende pouco de outro, ent\u00e3o n\u00e3o se incomodar\u00e1 com sua aus\u00eancia por causa de algum problema. Considere por exemplo o sistema na figura a seguir. Cada aplica\u00e7\u00e3o cliente (App X) conversa com cada SGBD, sistema de arquivos e outros servi\u00e7os, i.e., com o backend , usando uma API diferente no cen\u00e1rio do lado esquerdo; ou seja, cada aplica\u00e7\u00e3o precisa conhecer cda uma das API e uma troca em um dos servi\u00e7os do backend exige ajustes em todas as aplica\u00e7\u00f5es. J\u00e1 no lado direito, um conector foi colocado entre as aplica\u00e7\u00f5es e o backend , oferecendo uma interface \u00fanica para todos os clientes. A responsabilidade de conhecer as API espec\u00edficas dos componentes do backend passa a ser ent\u00e3o do conector, e quais quer mudan\u00e7as nos servi\u00e7os implicam mudan\u00e7as apenas no conector, n\u00e3o no clientes. Certos conectores permitem um acoplamento t\u00e3o fraco entre componentes, que estes n\u00e3o precisam se conhecer ou sequer estar ativos no mesmo momento, como os sistemas pubsub discutidos anteriormente. Tamb\u00e9m a quest\u00e3o da simplifica\u00e7\u00e3o de API, uma vez que o middleware pode impor um padr\u00e3o a ser seguido por todos os componentes e minimizar a necessidade os componentes conhecerem as interfaces uns dos outros. Cliente/Servidor A forma como os componentes se comunicam, isto \u00e9, como os conectores s\u00e3o usados \u00e9 importante no estudo arquitetural. Mas tamb\u00e9m s\u00e3o importantes os pap\u00e9is assumidos pelos componentes na realiza\u00e7\u00e3o de tarefas. Neste sentido, provavelmente a arquitetura de computa\u00e7\u00e3o distribu\u00edda mais comum \u00e9 a Cliente/Servidor . Na arquitetura Cliente/Servidor, como implicado pelo nome, h\u00e1 um processo que serve a pedidos realizados por outros processos. Isto \u00e9 feito quando o cliente o contacta o servidor e requer ( request ) a realiza\u00e7\u00e3o do servi\u00e7o. O servidor , por sua vez, pode desempenhar tarefas como fazer c\u00e1lculos, armazenar dados, ou repassar uma mensagem e, ao final da realiza\u00e7\u00e3o da tarefa, responder ( response ) ao cliente. Esta arquitetura forma a base da computa\u00e7\u00e3o distribu\u00edda, sobre a qual todos os outros modelos s\u00e3o implementados, sendo uma das raz\u00f5es hist\u00f3rica: os primeiros sistemas a permitirem a opera\u00e7\u00e3o por m\u00faltiplos usu\u00e1rios, ainda na d\u00e9cada de 60, eram compostos de um host robusto ao qual se conectavam diversos terminais, essencialmente com teclado e monitor, isto \u00e9, um servidor e v\u00e1rios clientes. Com a redu\u00e7\u00e3o dos computadores, surgiram as primeiras redes de computadores e a necessidade de uma abstra\u00e7\u00e3o para o estabelecimento de comunica\u00e7\u00e3o entre processos em hosts distintos, e assim surgiram os sockets . Com os sockets , vem uma grande flexibilidade, pois um processo n\u00e3o precisa saber como o outro manuseia os dados que lhe cabem, desde que siga um protocolo pr\u00e9-estabelecido na comunica\u00e7\u00e3o. Isto \u00e9, processos podem ser implementado em diferentes linguagens, sistemas operacionais e arquiteturas, desde observadas os cuidados necess\u00e1rios para se obter transpar\u00eancia de acesso . Esta flexibilidade \u00e9 a outra raz\u00e3o do sucesso do modelo cliente/servidor, permitindo que clientes se conectem a servidores para usar seus recursos, que podem ser acessados concorrentemente por diversos clientes. Exemplos desta arquitetura s\u00e3o abundantes, incluindo um navegador que se comunica com um servidor Apache para recuperar uma p\u00e1gina Web ou em um aplicativo m\u00f3vel que solicita ao servidor de aplica\u00e7\u00f5es que dispare uma transfer\u00eancia de fundos. Embora seja poss\u00edvel usar sockets de forma ass\u00edncrona, a API mais comum \u00e9 s\u00edncrona, isto \u00e9, quando um processo espera receber uma mensagem de outro, ele fica bloqueado esperando algum dado estar dispon\u00edvel para leitura no referido socket. De forma gen\u00e9rica, estas intera\u00e7\u00f5es acontecem como na figura a seguir. sequenceDiagram activate Servidor activate Cliente note left of Servidor: Cria socket e espera por conex\u00f5es deactivate Servidor Cliente->>+Servidor: Connect? deactivate Cliente note left of Servidor: Aceita conex\u00e3o note right of Cliente: Inativo (esperando requisi\u00e7\u00e3o) Servidor->>-Cliente: Connect! activate Cliente note right of Cliente: Ativo (gerando requisi\u00e7\u00e3o) note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) Cliente->>+Servidor: Request deactivate Cliente note right of Cliente: Inativo (esperando resposta) note left of Servidor: Ativo (processando requisi\u00e7\u00e3o) Servidor-->>-Cliente: Response activate Cliente note right of Cliente: Ativo (processando resposta note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) deactivate Cliente activate Cliente note right of Cliente: Ativo (gerando requisi\u00e7\u00e3o) Cliente->>+Servidor: Request deactivate Cliente note right of Cliente: Inativo (esperando resposta) note left of Servidor: Ativo (processando requisi\u00e7\u00e3o) Servidor-->>-Cliente: Response activate Cliente note right of Cliente: Ativo (processando resposta note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) deactivate Cliente Observe que o cliente fica inativo enquanto espera a resposta e que o servidor fica inativo enquanto espera outras requisi\u00e7\u00f5es. Para minimizar os per\u00edodos de inatividade, o cliente pode usar o socket assincronamente, o que n\u00e3o \u00e9 exatamente simples, ou usar m\u00faltiplos threads, para que continue operando mesmo enquanto um thread estiver bloqueado esperando a resposta do servidor. Do lado do servidor, o minimiza\u00e7\u00e3o da ociosidade \u00e9 feita pelo uso de m\u00faltiplos clientes, concorrentes, e tamb\u00e9m pelo uso de m\u00faltiplos threads. Neste caso, contudo, \u00e9 necess\u00e1rio tomar muito cuidado para garantir que a concorr\u00eancia n\u00e3o causar\u00e1 efeitos indesejados nos dados e execu\u00e7\u00e3o das tarefas. Veja por exemplo o caso de um banco de dados, que precisa garantir que a requisi\u00e7\u00e3o por um cliente n\u00e3o afete a resposta sendo enviada para outro. Embora tenhamos colocado aqui apenas um servidor atendendo aos clientes, em muitas aplica\u00e7\u00f5es modernas, m\u00faltiplos servidores atender\u00e3o ao conjunto de clientes. Pense por exemplo no servi\u00e7o de email do Google, o Gmail; com os milh\u00f5es de usu\u00e1rios que tem, certamente h\u00e1 mais de um servidor implementando o servi\u00e7o e certamente estes diversos servidores ficam atr\u00e1s do que chamamos de um balanceador de carga , que roteia as requisi\u00e7\u00f5es seguindo diferentes pol\u00edticas, por exemplo, round robin . Mesmo que comum, em certas situa\u00e7\u00f5es, esta divis\u00e3o entre clientes e servidores pode se tornar confusa. Primeiro, por qu\u00ea uma vez estabelecida a conex\u00e3o, n\u00e3o h\u00e1 uma diferencia\u00e7\u00e3o entre quem iniciou e quem aceitou a mesma; s\u00e3o apenas duas pontas do mesmo socket. Segundo, pode ser que o servi\u00e7o relevante sendo prestado, seja prestado por quem estabelece a conex\u00e3o. De fato ambos podem estar prestando servi\u00e7os um para o outro, no que \u00e9 conhecido como P2P. Terceiro, um mesmo processo pode atuar tanto como cliente quanto como servidor, no que \u00e9 conhecido como arquitetura multicamadas. Quero dizer, usando-se sockets como base, podemos construir outros modelos de comunica\u00e7\u00e3o entre processos, efetivamente colocando camadas na nossa cebola. 1 A seguir, exploraremos algumas destas arquiteturas. Sistemas multi-camadas Se organizarmos clientes e servidores em camadas em vez de hub-n-spoke como na imagem anterior, podemos dizer que temos uma arquitetura com duas camadas. Se os na camada de servidores agirem como clientes para outra camada, uma arquitetura com 3 camadas e assim por diante. Observe que as camadas l\u00f3gicas do sistema n\u00e3o necessariamente tem que casar com as camadas \"f\u00edsicas\". \u00c9 poss\u00edvel at\u00e9 que camadas l\u00f3gicas sejam particionadas entre os hosts do sistema, como nestas poss\u00edveis configura\u00e7\u00f5es de duas camadas. Por outro lado, cada camada l\u00f3gica pode ser subdividida em mais componentes, resultando em m\u00faltiplos tiers , como neste exemplo de um sistema de busca na Web. Par-a-Par (Peer-to-Peer, P2P) Diferentemente de sistemas cliente/servidor, em que um n\u00f3 serve o outro, em sistemas par-a-par, os n\u00f3s s\u00e3o parceiros e tem igual responsabilidade (e da\u00ed o nome) na execu\u00e7\u00e3o das tarefas. Como todo sistema distribu\u00eddo, a arquitetura P2P visa agregar poder computacional de m\u00faltiplos n\u00f3s . Mas al\u00e9m disso, pela n\u00e3o diferencia\u00e7\u00e3o dos componentes, espera-se tolerar falhas de componentes sem paralisar o servi\u00e7o , uma vez que n\u00e3o h\u00e1 um componente centralizador, detentor \u00fanico de uma certa funcionalidade e que possa ser um ponto \u00fanico de falha (SPOF, do ingl\u00eas single point of failure ). Os sistemas P2P tendem portanto a ter alta disponibilidade. Os sistemas P2P tem tamb\u00e9m alta escalabilidade como caracter\u00edstica comum, podendo chegar a n\u00edveis globais, como por exemplo os sistemas de compartilhamento de arquivos, m\u00fasicas e filmes, raz\u00e3o da fama e inf\u00e2mia da arquitetura. Para que isso seja poss\u00edvel, estes sistemas precisam se tornar auto-gerenci\u00e1veis , pois sistemas globais devem tolerar entrada e sa\u00edda frequente de n\u00f3s (por falhas ou a\u00e7\u00e3o de seus usu\u00e1rios), diferentes dom\u00ednios administrativos , e heterogeneidade na comunica\u00e7\u00e3o. Devido a import\u00e2ncia desta arquitetura, a estudaremos separadamente. H\u00edbridos Embora haja uma distin\u00e7\u00e3o clara entre cliente/servidor e P2P, boa parte dos sistemas que distribu\u00eddos podem ser na verdade considerados h\u00edbridos destas duas arquiteturas. Considere um sistema de email, por exemplo. Embora clientes usem as funcionalidades dos servidores de email para enviar e receber mensagens, os servidores conversam uns com os outros para implementar a tarefa de encaminhar as mensagens. Outros exemplos abundam. Bancos de dados, e.g., DynamoDB, CassandraDB , Redis,... Jogos multiplayer (pense no particionamento dos mapas ) Compartilhamento de arquivos: Bittorrent Foquemo-nos no exemplo do Bittorrent. O que h\u00e1 de mais interessante neste exemplo o fato de haverem diversas implementa\u00e7\u00f5es dos clientes, e.g., \\(\\mu\\) Torrent, Azureus, Transmission, Vuze, qTorrent, implementados em diversas linguagens e para diversas plataformas, todos interoper\u00e1veis. Isso \u00e9 um atestado do que uma especifica\u00e7\u00e3o bem feita e aberta pode alcan\u00e7ar. Observe na figura adiante os diversos passos necess\u00e1rios \u00e0 recupera\u00e7\u00e3o do arquivo de interesse neste sistema. Diversos passos seguem a arquitetura cliente/servidor enquanto \"somente\" o passo de compartilhamento de arquivos \u00e9 P2P. Voltando ao exemplo do sistema de informa\u00e7\u00e3o, observe que o cliente acessa um servi\u00e7o, implementado por pares de n\u00f3s. Podemos dizer que tamb\u00e9m este \u00e9 h\u00edbrido. graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B Um \u00faltimo exemplo \u00e9 o sistema que suporta a criptomoeda Bitcoin, em que milhares de n\u00f3s armazenam coletivamente o hist\u00f3rico de transa\u00e7\u00f5es de trocas de dono das moedas. Mas em vez de expandir aqui este assunto, diferiremos esta discuss\u00e3o para a se\u00e7\u00e3o BlockChain . Outras arquiteturas \u00c9 poss\u00edvel pensar em muitas outras organiza\u00e7\u00f5es dos componentes de sistemas distribu\u00eddos e, de fato, diversas outras arquiteturas podem e foram propostas e merecem destaque. SOA TODO SOA - Foco no uso de outras formas de comunica\u00e7\u00e3o para chegar em outras arquiteturas. MOM TODO MOM - Foco na arquitetura pois o uso ser\u00e1 visto no pr\u00f3ximo cap\u00edtulo.s Publish/Subscribe Message Queues Publish/subscribe \u00e9 uma das manifesta\u00e7\u00f5es os message oriented middleware , ou MOM. Uma outra manifesta\u00e7\u00e3o s\u00e3o as filas de mensagens , que permitem que componentes enviem mensagens para caixas postais uns dos outros. Dependendo da implementa\u00e7\u00e3o e do MOM usado, componentes n\u00e3o precisam sequer se identificar ou mesmo estar ativos ao mesmo tempo para que a troca de mensagens aconte\u00e7a, novamente levando a sistemas mais ou menos acoplados. No cap\u00edtulo seguinte, usaremos um estudo de caso para no aprofundarmos em arquiteturas orientadas a mensagens, pois neste caso, a arquitetura se confunde com os conectores do nosso sistema distribu\u00eddo. Microsservi\u00e7os A moda da vez \u00e9 a chamada arquitetura de microsservi\u00e7os , na qual a divis\u00e3o de tarefas entre componentes visa levar aos componentes mais simples para tal tarefa. Assim, os mesmos podem ser replicados, escalonados, desenvolvidos e mantidos independentemente. Cada tarefa conta ent\u00e3o com diversos componentes, organizados em camadas resolvendo um problema em espec\u00edfico, mas todos contribuindo para a realiza\u00e7\u00e3o de uma tarefa maior comum. TODO Event Sourcing Stream Processing/Event sourcing Stream Processing/Event Sourcing Kafka Overview Refer\u00eancias https://www.cs.cmu.edu/~dga/15-744/S07/lectures/16-dht.pdf Distributed System Architectures and Architectural Styles . Para aprender um pouco sobre como funcionam as redes de um datacenter , definidas por software, assista ao seguinte v\u00eddeo, que fala sobre a infra-estrutura do Facebook. Se voc\u00ea n\u00e3o pegou a refer\u00eancia, avance uma casa 2 at\u00e9 modelos . \u21a9 Se voc\u00ea n\u00e3o pegou esta refer\u00eancia, n\u00e3o teve inf\u00e2ncia. \u21a9","title":"Introdu\u00e7\u00e3o"},{"location":"arch/arch/#introducao","text":"De acordo com David Garlan and Mary Shaw, January 1994, CMU-CS-94-166, em An Introduction to Software Architecture ... an architectural style determines the vocabulary of components and connectors that can be used in instances of that style, together with a set of constraints on how they can be combined. These can include topological constraints on architectural descriptions (e.g., no cycles). Other constraints\u2014say, having to do with execution semantics\u2014might also be part of the style definition. Em outras palavras, um estilo ou padr\u00e3o arquitetural \u00e9 o conjunto de princ\u00edpios que prov\u00ea uma infraestrutura abstrata para uma fam\u00edlia de sistemas, e promove o reuso de projeto ao prover solu\u00e7\u00f5es para problemas recorrentes e frequentes ao definir quais o componentes presentes no sistema e como estes interagem uns com os outros, por meio de conectores , para implementar a solu\u00e7\u00e3o para um problema.","title":"Introdu\u00e7\u00e3o"},{"location":"arch/arch/#componentes-e-conectores","text":"Para se alcan\u00e7ar efici\u00eancia no desenvolvimento de sistemas, \u00e9 imperativo que se pare de reinventar a roda a cada itera\u00e7\u00e3o e, em vez disso, se reuse artefatos existentes, providos pela linguagem sendo usada, por frameworks de terceiros e por itera\u00e7\u00f5es anteriores da equipe. De fato, o desenvolvimento de novos sistemas deveria ser pautado pela cria\u00e7\u00e3o de componentes simples e coesos, que possam ser operados independentemente e que por meio de interfaces bem especificadas completas, possam ser ent\u00e3o conectados para resolver um problema maior. Uma vez selecionados, os componentes s\u00e3o conectados por meio de conectores, que podem assumir m\u00faltiplas formas para esconder as complexas itera\u00e7\u00f5es entres os componentes, por exemplo, por meio de fluxos de mensagens ou invoca\u00e7\u00f5es remotas de procedimentos. graph LR A[Componente 1] --> C{Conector} --> B(Componente 2) TODO Desenhar o conector usando s\u00edmbolo padr\u00e3o. Componentes bem projetados, deveriam ser facilmente substitu\u00eddos por outros que respeitem a conex\u00e3o. Isto aumenta a manutenabilidade do sistemas e pode simplificar passos como a replica\u00e7\u00e3o de componentes. graph LR A[Componente 1] --> C{Conector 1} --> B(Componente 2) D{Conector 2} E{Conector 3} Alguns conectores s\u00e3o complexos o suficiente para serem considerados eles pr\u00f3prios componentes, mas no contexto desta discuss\u00e3o, a bem da abstra\u00e7\u00e3o, os consideraremos apenas como conectores. Por exemplo, um broker MQTT usado para a comunica\u00e7\u00e3o entre dois processos \u00e9 considerado um conector, e n\u00e3o um componente. Dependendo de como s\u00e3o conectados, haver\u00e1 maior ou menor depend\u00eancia entre os componentes. Quando houver forte depend\u00eancia, diremos que os componentes est\u00e3o fortemente acoplados ( tightly coupled ). Caso contr\u00e1rio, diremos que est\u00e3o fracamente acoplados ( loosely coupled ). A raz\u00e3o \u00f3bvia para preferir sistemas fracamente conectados \u00e9 sua capacidade de tolerar disrup\u00e7\u00f5es; se um componente depende pouco de outro, ent\u00e3o n\u00e3o se incomodar\u00e1 com sua aus\u00eancia por causa de algum problema. Considere por exemplo o sistema na figura a seguir. Cada aplica\u00e7\u00e3o cliente (App X) conversa com cada SGBD, sistema de arquivos e outros servi\u00e7os, i.e., com o backend , usando uma API diferente no cen\u00e1rio do lado esquerdo; ou seja, cada aplica\u00e7\u00e3o precisa conhecer cda uma das API e uma troca em um dos servi\u00e7os do backend exige ajustes em todas as aplica\u00e7\u00f5es. J\u00e1 no lado direito, um conector foi colocado entre as aplica\u00e7\u00f5es e o backend , oferecendo uma interface \u00fanica para todos os clientes. A responsabilidade de conhecer as API espec\u00edficas dos componentes do backend passa a ser ent\u00e3o do conector, e quais quer mudan\u00e7as nos servi\u00e7os implicam mudan\u00e7as apenas no conector, n\u00e3o no clientes. Certos conectores permitem um acoplamento t\u00e3o fraco entre componentes, que estes n\u00e3o precisam se conhecer ou sequer estar ativos no mesmo momento, como os sistemas pubsub discutidos anteriormente. Tamb\u00e9m a quest\u00e3o da simplifica\u00e7\u00e3o de API, uma vez que o middleware pode impor um padr\u00e3o a ser seguido por todos os componentes e minimizar a necessidade os componentes conhecerem as interfaces uns dos outros.","title":"Componentes e Conectores"},{"location":"arch/arch/#clienteservidor","text":"A forma como os componentes se comunicam, isto \u00e9, como os conectores s\u00e3o usados \u00e9 importante no estudo arquitetural. Mas tamb\u00e9m s\u00e3o importantes os pap\u00e9is assumidos pelos componentes na realiza\u00e7\u00e3o de tarefas. Neste sentido, provavelmente a arquitetura de computa\u00e7\u00e3o distribu\u00edda mais comum \u00e9 a Cliente/Servidor . Na arquitetura Cliente/Servidor, como implicado pelo nome, h\u00e1 um processo que serve a pedidos realizados por outros processos. Isto \u00e9 feito quando o cliente o contacta o servidor e requer ( request ) a realiza\u00e7\u00e3o do servi\u00e7o. O servidor , por sua vez, pode desempenhar tarefas como fazer c\u00e1lculos, armazenar dados, ou repassar uma mensagem e, ao final da realiza\u00e7\u00e3o da tarefa, responder ( response ) ao cliente. Esta arquitetura forma a base da computa\u00e7\u00e3o distribu\u00edda, sobre a qual todos os outros modelos s\u00e3o implementados, sendo uma das raz\u00f5es hist\u00f3rica: os primeiros sistemas a permitirem a opera\u00e7\u00e3o por m\u00faltiplos usu\u00e1rios, ainda na d\u00e9cada de 60, eram compostos de um host robusto ao qual se conectavam diversos terminais, essencialmente com teclado e monitor, isto \u00e9, um servidor e v\u00e1rios clientes. Com a redu\u00e7\u00e3o dos computadores, surgiram as primeiras redes de computadores e a necessidade de uma abstra\u00e7\u00e3o para o estabelecimento de comunica\u00e7\u00e3o entre processos em hosts distintos, e assim surgiram os sockets . Com os sockets , vem uma grande flexibilidade, pois um processo n\u00e3o precisa saber como o outro manuseia os dados que lhe cabem, desde que siga um protocolo pr\u00e9-estabelecido na comunica\u00e7\u00e3o. Isto \u00e9, processos podem ser implementado em diferentes linguagens, sistemas operacionais e arquiteturas, desde observadas os cuidados necess\u00e1rios para se obter transpar\u00eancia de acesso . Esta flexibilidade \u00e9 a outra raz\u00e3o do sucesso do modelo cliente/servidor, permitindo que clientes se conectem a servidores para usar seus recursos, que podem ser acessados concorrentemente por diversos clientes. Exemplos desta arquitetura s\u00e3o abundantes, incluindo um navegador que se comunica com um servidor Apache para recuperar uma p\u00e1gina Web ou em um aplicativo m\u00f3vel que solicita ao servidor de aplica\u00e7\u00f5es que dispare uma transfer\u00eancia de fundos. Embora seja poss\u00edvel usar sockets de forma ass\u00edncrona, a API mais comum \u00e9 s\u00edncrona, isto \u00e9, quando um processo espera receber uma mensagem de outro, ele fica bloqueado esperando algum dado estar dispon\u00edvel para leitura no referido socket. De forma gen\u00e9rica, estas intera\u00e7\u00f5es acontecem como na figura a seguir. sequenceDiagram activate Servidor activate Cliente note left of Servidor: Cria socket e espera por conex\u00f5es deactivate Servidor Cliente->>+Servidor: Connect? deactivate Cliente note left of Servidor: Aceita conex\u00e3o note right of Cliente: Inativo (esperando requisi\u00e7\u00e3o) Servidor->>-Cliente: Connect! activate Cliente note right of Cliente: Ativo (gerando requisi\u00e7\u00e3o) note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) Cliente->>+Servidor: Request deactivate Cliente note right of Cliente: Inativo (esperando resposta) note left of Servidor: Ativo (processando requisi\u00e7\u00e3o) Servidor-->>-Cliente: Response activate Cliente note right of Cliente: Ativo (processando resposta note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) deactivate Cliente activate Cliente note right of Cliente: Ativo (gerando requisi\u00e7\u00e3o) Cliente->>+Servidor: Request deactivate Cliente note right of Cliente: Inativo (esperando resposta) note left of Servidor: Ativo (processando requisi\u00e7\u00e3o) Servidor-->>-Cliente: Response activate Cliente note right of Cliente: Ativo (processando resposta note left of Servidor: Inativo (esperando requisi\u00e7\u00e3o) deactivate Cliente Observe que o cliente fica inativo enquanto espera a resposta e que o servidor fica inativo enquanto espera outras requisi\u00e7\u00f5es. Para minimizar os per\u00edodos de inatividade, o cliente pode usar o socket assincronamente, o que n\u00e3o \u00e9 exatamente simples, ou usar m\u00faltiplos threads, para que continue operando mesmo enquanto um thread estiver bloqueado esperando a resposta do servidor. Do lado do servidor, o minimiza\u00e7\u00e3o da ociosidade \u00e9 feita pelo uso de m\u00faltiplos clientes, concorrentes, e tamb\u00e9m pelo uso de m\u00faltiplos threads. Neste caso, contudo, \u00e9 necess\u00e1rio tomar muito cuidado para garantir que a concorr\u00eancia n\u00e3o causar\u00e1 efeitos indesejados nos dados e execu\u00e7\u00e3o das tarefas. Veja por exemplo o caso de um banco de dados, que precisa garantir que a requisi\u00e7\u00e3o por um cliente n\u00e3o afete a resposta sendo enviada para outro. Embora tenhamos colocado aqui apenas um servidor atendendo aos clientes, em muitas aplica\u00e7\u00f5es modernas, m\u00faltiplos servidores atender\u00e3o ao conjunto de clientes. Pense por exemplo no servi\u00e7o de email do Google, o Gmail; com os milh\u00f5es de usu\u00e1rios que tem, certamente h\u00e1 mais de um servidor implementando o servi\u00e7o e certamente estes diversos servidores ficam atr\u00e1s do que chamamos de um balanceador de carga , que roteia as requisi\u00e7\u00f5es seguindo diferentes pol\u00edticas, por exemplo, round robin . Mesmo que comum, em certas situa\u00e7\u00f5es, esta divis\u00e3o entre clientes e servidores pode se tornar confusa. Primeiro, por qu\u00ea uma vez estabelecida a conex\u00e3o, n\u00e3o h\u00e1 uma diferencia\u00e7\u00e3o entre quem iniciou e quem aceitou a mesma; s\u00e3o apenas duas pontas do mesmo socket. Segundo, pode ser que o servi\u00e7o relevante sendo prestado, seja prestado por quem estabelece a conex\u00e3o. De fato ambos podem estar prestando servi\u00e7os um para o outro, no que \u00e9 conhecido como P2P. Terceiro, um mesmo processo pode atuar tanto como cliente quanto como servidor, no que \u00e9 conhecido como arquitetura multicamadas. Quero dizer, usando-se sockets como base, podemos construir outros modelos de comunica\u00e7\u00e3o entre processos, efetivamente colocando camadas na nossa cebola. 1 A seguir, exploraremos algumas destas arquiteturas.","title":"Cliente/Servidor"},{"location":"arch/arch/#sistemas-multi-camadas","text":"Se organizarmos clientes e servidores em camadas em vez de hub-n-spoke como na imagem anterior, podemos dizer que temos uma arquitetura com duas camadas. Se os na camada de servidores agirem como clientes para outra camada, uma arquitetura com 3 camadas e assim por diante. Observe que as camadas l\u00f3gicas do sistema n\u00e3o necessariamente tem que casar com as camadas \"f\u00edsicas\". \u00c9 poss\u00edvel at\u00e9 que camadas l\u00f3gicas sejam particionadas entre os hosts do sistema, como nestas poss\u00edveis configura\u00e7\u00f5es de duas camadas. Por outro lado, cada camada l\u00f3gica pode ser subdividida em mais componentes, resultando em m\u00faltiplos tiers , como neste exemplo de um sistema de busca na Web.","title":"Sistemas multi-camadas"},{"location":"arch/arch/#par-a-par-peer-to-peer-p2p","text":"Diferentemente de sistemas cliente/servidor, em que um n\u00f3 serve o outro, em sistemas par-a-par, os n\u00f3s s\u00e3o parceiros e tem igual responsabilidade (e da\u00ed o nome) na execu\u00e7\u00e3o das tarefas. Como todo sistema distribu\u00eddo, a arquitetura P2P visa agregar poder computacional de m\u00faltiplos n\u00f3s . Mas al\u00e9m disso, pela n\u00e3o diferencia\u00e7\u00e3o dos componentes, espera-se tolerar falhas de componentes sem paralisar o servi\u00e7o , uma vez que n\u00e3o h\u00e1 um componente centralizador, detentor \u00fanico de uma certa funcionalidade e que possa ser um ponto \u00fanico de falha (SPOF, do ingl\u00eas single point of failure ). Os sistemas P2P tendem portanto a ter alta disponibilidade. Os sistemas P2P tem tamb\u00e9m alta escalabilidade como caracter\u00edstica comum, podendo chegar a n\u00edveis globais, como por exemplo os sistemas de compartilhamento de arquivos, m\u00fasicas e filmes, raz\u00e3o da fama e inf\u00e2mia da arquitetura. Para que isso seja poss\u00edvel, estes sistemas precisam se tornar auto-gerenci\u00e1veis , pois sistemas globais devem tolerar entrada e sa\u00edda frequente de n\u00f3s (por falhas ou a\u00e7\u00e3o de seus usu\u00e1rios), diferentes dom\u00ednios administrativos , e heterogeneidade na comunica\u00e7\u00e3o. Devido a import\u00e2ncia desta arquitetura, a estudaremos separadamente.","title":"Par-a-Par (Peer-to-Peer, P2P)"},{"location":"arch/arch/#hibridos","text":"Embora haja uma distin\u00e7\u00e3o clara entre cliente/servidor e P2P, boa parte dos sistemas que distribu\u00eddos podem ser na verdade considerados h\u00edbridos destas duas arquiteturas. Considere um sistema de email, por exemplo. Embora clientes usem as funcionalidades dos servidores de email para enviar e receber mensagens, os servidores conversam uns com os outros para implementar a tarefa de encaminhar as mensagens. Outros exemplos abundam. Bancos de dados, e.g., DynamoDB, CassandraDB , Redis,... Jogos multiplayer (pense no particionamento dos mapas ) Compartilhamento de arquivos: Bittorrent Foquemo-nos no exemplo do Bittorrent. O que h\u00e1 de mais interessante neste exemplo o fato de haverem diversas implementa\u00e7\u00f5es dos clientes, e.g., \\(\\mu\\) Torrent, Azureus, Transmission, Vuze, qTorrent, implementados em diversas linguagens e para diversas plataformas, todos interoper\u00e1veis. Isso \u00e9 um atestado do que uma especifica\u00e7\u00e3o bem feita e aberta pode alcan\u00e7ar. Observe na figura adiante os diversos passos necess\u00e1rios \u00e0 recupera\u00e7\u00e3o do arquivo de interesse neste sistema. Diversos passos seguem a arquitetura cliente/servidor enquanto \"somente\" o passo de compartilhamento de arquivos \u00e9 P2P. Voltando ao exemplo do sistema de informa\u00e7\u00e3o, observe que o cliente acessa um servi\u00e7o, implementado por pares de n\u00f3s. Podemos dizer que tamb\u00e9m este \u00e9 h\u00edbrido. graph LR A[Cliente] -->|Requisi\u00e7\u00e3o| B{Monitor de Transa\u00e7\u00f5es} B -->|Resposta| A B -->|Requisi\u00e7\u00e3o| C[(Servidor 1)] B -->|Requisi\u00e7\u00e3o| D[(Servidor 2)] B -->|Requisi\u00e7\u00e3o| E[(Servidor 3)] C -->|Resposta| B D -->|Resposta| B E -->|Resposta| B Um \u00faltimo exemplo \u00e9 o sistema que suporta a criptomoeda Bitcoin, em que milhares de n\u00f3s armazenam coletivamente o hist\u00f3rico de transa\u00e7\u00f5es de trocas de dono das moedas. Mas em vez de expandir aqui este assunto, diferiremos esta discuss\u00e3o para a se\u00e7\u00e3o BlockChain .","title":"H\u00edbridos"},{"location":"arch/arch/#outras-arquiteturas","text":"\u00c9 poss\u00edvel pensar em muitas outras organiza\u00e7\u00f5es dos componentes de sistemas distribu\u00eddos e, de fato, diversas outras arquiteturas podem e foram propostas e merecem destaque.","title":"Outras arquiteturas"},{"location":"arch/arch/#soa","text":"TODO SOA - Foco no uso de outras formas de comunica\u00e7\u00e3o para chegar em outras arquiteturas.","title":"SOA"},{"location":"arch/arch/#mom","text":"TODO MOM - Foco na arquitetura pois o uso ser\u00e1 visto no pr\u00f3ximo cap\u00edtulo.s Publish/Subscribe Message Queues Publish/subscribe \u00e9 uma das manifesta\u00e7\u00f5es os message oriented middleware , ou MOM. Uma outra manifesta\u00e7\u00e3o s\u00e3o as filas de mensagens , que permitem que componentes enviem mensagens para caixas postais uns dos outros. Dependendo da implementa\u00e7\u00e3o e do MOM usado, componentes n\u00e3o precisam sequer se identificar ou mesmo estar ativos ao mesmo tempo para que a troca de mensagens aconte\u00e7a, novamente levando a sistemas mais ou menos acoplados. No cap\u00edtulo seguinte, usaremos um estudo de caso para no aprofundarmos em arquiteturas orientadas a mensagens, pois neste caso, a arquitetura se confunde com os conectores do nosso sistema distribu\u00eddo.","title":"MOM"},{"location":"arch/arch/#microsservicos","text":"A moda da vez \u00e9 a chamada arquitetura de microsservi\u00e7os , na qual a divis\u00e3o de tarefas entre componentes visa levar aos componentes mais simples para tal tarefa. Assim, os mesmos podem ser replicados, escalonados, desenvolvidos e mantidos independentemente. Cada tarefa conta ent\u00e3o com diversos componentes, organizados em camadas resolvendo um problema em espec\u00edfico, mas todos contribuindo para a realiza\u00e7\u00e3o de uma tarefa maior comum.","title":"Microsservi\u00e7os"},{"location":"arch/arch/#_1","text":"TODO Event Sourcing Stream Processing/Event sourcing Stream Processing/Event Sourcing Kafka Overview","title":""},{"location":"arch/arch/#referencias","text":"https://www.cs.cmu.edu/~dga/15-744/S07/lectures/16-dht.pdf Distributed System Architectures and Architectural Styles . Para aprender um pouco sobre como funcionam as redes de um datacenter , definidas por software, assista ao seguinte v\u00eddeo, que fala sobre a infra-estrutura do Facebook. Se voc\u00ea n\u00e3o pegou a refer\u00eancia, avance uma casa 2 at\u00e9 modelos . \u21a9 Se voc\u00ea n\u00e3o pegou esta refer\u00eancia, n\u00e3o teve inf\u00e2ncia. \u21a9","title":"Refer\u00eancias"},{"location":"arch/microservices/","text":"No dia 3 de Junho de 2020, o termo microservice resultava em 6.6 milh\u00f5es de resultados no Google . Isso porqu\u00ea a organiza\u00e7\u00e3o de aplica\u00e7\u00f5es distribu\u00eddas na forma de \"pequenos\" processos, especializados e independentes e que colaboram para implementar um servi\u00e7o maior, se tornou um padr\u00e3o importante no desenvolvimento de novas aplica\u00e7\u00f5es. Exatamente por isso, precisamos come\u00e7ar com um aviso: diversas tecnologias surgiram com grande estrondo, sendo alguns exemplos recentes Docker, Golang, Angular, e JQuery, e embora seja certo que algumas destas encontrar\u00e3o seus nichos, como fizeram antes delas Cobol, C, e SQL, outras desaparecer\u00e3o da face da ind\u00fastria; afinal, quem sabe o que \u00e9 Delphi e quem ainda usa JQuery? Os micro-servi\u00e7os n\u00e3o s\u00e3o uma panac\u00e9ia ! Este fen\u00f4meno \u00e9 capturado pelas v\u00e1rias fases do hype-cycle da Gartner. 1 A Arquitetura Orientada a microsservi\u00e7os, tendo atingido o pico das expectativas infladas 2 em 2017, est\u00e1 deslizando na Trough of Desillusionment 2 em 2019. Isto \u00e9, este modelo de desenvolvimento n\u00e3o \u00e9 mais propagandeado como uma bala de prata para todas as aplica\u00e7\u00f5es distribu\u00eddas. Ainda assim, \u00e9 um importante modelo. Mas afinal, o que \u00e9 a arquitetura de microsservi\u00e7os? Em vez de explicar diretamente o que s\u00e3o, pode ser mais f\u00e1cil pensar primeiro termos do que n\u00e3o s\u00e3o, em termos de sistemas monol\u00edticos. Uma extrapola\u00e7\u00e3o que pode ser feita aqui, refor\u00e7ando a observa\u00e7\u00e3o que problemas (e solu\u00e7\u00f5es) de sistemas distribu\u00eddos s\u00e3o refletidos em n\u00edvel de processamento paralelo e concorrente, \u00e9 que a uma arquitetura SEDA lembra em muito a arquitetura de micro-servi\u00e7os . Observe que \u00e0 direita no exemplo de microsservi\u00e7os, se v\u00ea um conector (ou componente) denominado event bus . A ideia \u00e9 que componentes publiquem mensagens no barramento, os publishers , e que componentes interessados em mensagens de algum t\u00f3pico, os subscribers se subscrevam. O barramento ent\u00e3o serve de canal de comunica\u00e7\u00e3o, entregando as mensagens publicadas a quem tiver interesse, implementando assim uma arquitetura publish/subscribe . Monolitos Muitas aplica\u00e7\u00f5es seguem o modelo de 3 camadas em que em um dos extremos tem-se a interface com os usu\u00e1rios, materializada normalmente por um navegador, no outro tem-se um SGBD onde s\u00e3o armazenados os dados da aplica\u00e7\u00e3o, e, no meio, a l\u00f3gica do neg\u00f3cio. A camada central, implementada por um \u00fanico processo, que alimenta a interface com o usu\u00e1rio, manipula o modelo de dados, e onde reside a l\u00f3gica do neg\u00f3cio, \u00e9 um monolito . Monolitos seguem um modelo simples e largamente utilizado de desenvolvimento em que v\u00e1rios contribuidores implementam partes distintas da l\u00f3gica, que s\u00e3o compiladas em conjunto e colocadas em produ\u00e7\u00e3o de forma at\u00f4mica: Desenvolva Teste Implante volte ao passo 1 Simples n\u00e3o quer dizer necessariamente eficiente; no caso de atualiza\u00e7\u00f5es de uma parte do sistema, todo o monolito precisa ser trocado , incorrendo em, com raras exce\u00e7\u00f5es, indisponibilidade total do sistema, incluindo as partes n\u00e3o modificadas. Esta dificuldade tende a limitar as janelas de atualiza\u00e7\u00e3o do sistema, o que aumenta no n\u00famero de mudan\u00e7as que ocorrem a cada atualiza\u00e7\u00e3o, o que aumenta o risco de regress\u00f5es e portanto requer mais testes, o que aumenta o intervalo entre janelas de atualiza\u00e7\u00e3o. Al\u00e9m disso, nos caso de bugs, \u00e9 mais dif\u00edcil encontrar o problema, uma vez que fica imposs\u00edvel aos desenvolvedores conhecer todo o sistema . Isso apenas exacerba o problema, o que limita mais ainda as atualiza\u00e7\u00f5es, gerando um ciclo vicioso que mantem desenvolvedores acordados nas madrugadas de sexta para s\u00e1bado quando \u00e9 dia de deploy . Sistemas monol\u00edticos tamb\u00e9m podem ser problem\u00e1ticos quanto \u00e0 escalabilidade, pois quando a capacidade do sistema \u00e9 atingida, ou todo o sistema \u00e9 movido para um host de maior capacidade ou todo o sistema deve ser replicado. Na primeira abordagem, o custo geralmente \u00e9 um empecilho, pois pre\u00e7os de hardware crescem exponencialmente com scale up . Al\u00e9m disso, um servidor, por mais parrudo que seja, \u00e9 um Ponto \u00danico de Falha (ou SPOF, do ingl\u00eas single point of failure ). Quanto \u00e0 segunda abordagem, ela traz complexidades na coordena\u00e7\u00e3o das r\u00e9plicas e inefici\u00eancias ao replicar inclusive as partes subutilizadas. Ambas as abordagens tamb\u00e9m esbarram na escalabilidade do banco de dados que lhes serve de backend . Para contornar ou pelo menos minimizar estes problemas, pode-se fragmentar o servi\u00e7o e o banco de dados, o que facilita tanto a escalabilidade vertical quanto horizontal de cada m\u00f3dulo, que \u00e9 menor e mais simples de coordenar, e divide a carga nos bancos de dados; mas isso \u00e9 a troca do servi\u00e7o monol\u00edtico por microsservi\u00e7os. Microsservi\u00e7os De acordo com Lewis & Fowler The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. Em outras palavras, com os microsservi\u00e7os, quebra-se o monolito em diferentes processos, \" small autonomous services that work together, modelled around a business domain \", cada um gerenciando os dados relevantes para aquela parte do sistema e, possivelmente, sua pr\u00f3pria intera\u00e7\u00e3o com o usu\u00e1rio. Com o uso de microsservi\u00e7os, se d\u00e1 mais um passo em dire\u00e7\u00e3o \u00e0 m\u00e1xima escalabilidade do sistema. Este modelo tem implica\u00e7\u00f5es diretas no desenvolvimento: cada processo \u00e9 desenvolvido por um time diferente, que mantem controle sobre desenvolvimento, teste, e manuten\u00e7\u00e3o em produ\u00e7\u00e3o, o que \u00e9 fact\u00edvel j\u00e1 que cada servi\u00e7o \u00e9 simples e focado em um problema pequeno e ningu\u00e9m tem que entender em detalhes o funcionamento de todo o sistema. Al\u00e9m disso, quando um servi\u00e7o precisa ser atualizado, se bem projetado, todos os demais podem continuar operantes e \u00e9 poss\u00edvel at\u00e9 que m\u00faltiplas vers\u00f5es do mesmo servi\u00e7o sejam executadas concorrentemente, possibilitando atualiza\u00e7\u00f5es sem janelas de manuten\u00e7\u00e3o. Quanto \u00e0 escalabilidade, esta \u00e9 feita independentemente tamb\u00e9m; no exemplo na imagem seguinte, \u00e9 prov\u00e1vel que o servi\u00e7o de acesso ao cat\u00e1logo seja mais utilizado que os demais e portanto merecedor de mais recursos e mais c\u00f3pias. Como se percebe facilmente, o uso de microsservi\u00e7os pode ser relacionado \u00e0s t\u00e9cnicas de processamento paralelo: trate dados diferentes em blocos diferentes (paralelismo de dados ou replica\u00e7\u00e3o) e trate fun\u00e7\u00f5es diferentes em blocos diferentes (paralelismo de tarefas ou sharding ). Como na computa\u00e7\u00e3o paralela, na \"componentiza\u00e7\u00e3o\" \u00e9 importante considerar os requisitos das diferentes tarefas em termos de CPU, E/S, e mem\u00f3ria, para que possam escalar independentemente e n\u00e3o gerar gargalos desnecess\u00e1rios. Do Monolito aos Microsservi\u00e7os Com tantas vantagens, surge a d\u00favida se todos os sistemas deveriam ser desenvolvidos usando-se a arquitetura de microsservi\u00e7os. A resposta \u00e9 n\u00e3o , pois como colocado no in\u00edcio desta se\u00e7\u00e3o, n\u00e3o existem balas de prata e se um sistema monol\u00edtico est\u00e1 funcionando para voc\u00ea e n\u00e3o h\u00e1 perspectiva de problemas acometerem (a demanda no sistema n\u00e3o est\u00e1 aumentando, a l\u00f3gica do sistema \u00e9 muito simples, indisponibilidade n\u00e3o te traz preju\u00edzo, voc\u00ea n\u00e3o pode arcar com a refatora\u00e7\u00e3o), ent\u00e3o mantenha seu sistema como est\u00e1. Caso haja a necessidade de evolu\u00e7\u00e3o e o modelo de microsservi\u00e7os pare\u00e7a adequado, existem recomenda\u00e7\u00f5es de como a migra\u00e7\u00e3o pode ser feita. Primeiro, \u00e9 preciso aceitar que o desenvolvimento de microsservi\u00e7os afeta a organiza\u00e7\u00e3o do time de desenvolvimento e que a organiza\u00e7\u00e3o provavelmente refletir\u00e1 a arquitetura. O desenvolvimento, manuten\u00e7\u00e3o e opera\u00e7\u00e3o de microsservi\u00e7os acontece em times pequenos, de 1 a 8 pessoas (\"pizza team\"), dependendo da complexidade do servi\u00e7o; se houver a necessidade de mais pessoas no time, o escopo do microsservi\u00e7o provavelmente est\u00e1 grande demais; cada componente resolve um problema, bem. Segundo, a mudan\u00e7a n\u00e3o dever\u00e1 acontecer atomicamente. Uma boa estrat\u00e9gia \u00e9 identificar uma parte do sistema que funcionaria bem como microsservi\u00e7o, desenvolv\u00ea-la e modificar o monolito para usar o microsservi\u00e7o. O aprendizado ent\u00e3o \u00e9 usado para encontrar novo candidato e o procedimento \u00e9 iterado at\u00e9 que o monolito seja apenas uma casca e possa tamb\u00e9m ser removido. Mais f\u00e1cil dito que feito, h\u00e1 muita documenta\u00e7\u00e3o orientando o processo. Para saber mais Como esta arquitetura n\u00e3o faz parte ainda do nosso curr\u00edculo, n\u00e3o nos aprofundaremos nela aqui. Felizmente h\u00e1 muito material na Web sobre este modelo, sendo a lista a seguir uma \u00ednfima fra\u00e7\u00e3o. Para uma explica\u00e7\u00e3o geral do que s\u00e3o, assista a Martin Fowler no v\u00eddeo seguinte, assista ou consulte os v\u00e1rios artigos no seu s\u00edtio . Para entender os princ\u00edpios por tr\u00e1s do uso da arquitetura, Para um exemplo importante do uso de microsservi\u00e7os, considere a Netflix, que usa microsservi\u00e7os em larga escala em seus servi\u00e7os. Qu\u00e3o larga? \"...over five hundred services... we don't know how many...\" Apesar de tal uso, ou justamente por causa dele, seus servi\u00e7os mant\u00e9m uma \"...availability of 9.995...\", ou seja, ficam indispon\u00edveis por menos de 16 segundos por ano . Com respeito a estar preparado para falhas, afinal \"... it is not if failures will happen... ... it is when it happens...\", a empresa usa uma abordagem de inje\u00e7\u00e3o de falhas em servi\u00e7os em produ\u00e7\u00e3o. Os diferentes tiposde falhas s\u00e3o injetados por um \" ex\u00e9rcito de macacos do caos \" Para uma vis\u00e3o pr\u00e1tica da implementa\u00e7\u00e3o de microsservi\u00e7os usando AWS, veja \"The hype cycle is a branded graphical presentation developed and used by the American research, advisory and information technology firm Gartner, for representing the maturity, adoption and social application of specific technologies.\" \u21a9 Peak of Inflated - Expectations Early publicity produces a number of success stories\u2014often accompanied by scores of failures. Some companies take action; most don't. Technology Trigger -- A potential technology breakthrough kicks things off. Early proof-of-concept stories and media interest trigger significant publicity. Often no usable products exist and commercial viability is unproven. Slope of Enlightenment -- More instances of how the technology can benefit the enterprise start to crystallize and become more widely understood. Second- and third-generation products appear from technology providers. More enterprises fund pilots; conservative companies remain cautious. Plateau of Productivity -- Mainstream adoption starts to take off. Criteria for assessing provider viability are more clearly defined. The technology's broad market applicability and relevance are clearly paying off. Trough of Disillusionment - Interest wanes as experiments and implementations fail to deliver. Producers of the technology shake out or fail. Investment continues only if the surviving providers improve their products to the satisfaction of early adopters. \u21a9 \u21a9","title":"Microsservi\u00e7os"},{"location":"arch/microservices/#monolitos","text":"Muitas aplica\u00e7\u00f5es seguem o modelo de 3 camadas em que em um dos extremos tem-se a interface com os usu\u00e1rios, materializada normalmente por um navegador, no outro tem-se um SGBD onde s\u00e3o armazenados os dados da aplica\u00e7\u00e3o, e, no meio, a l\u00f3gica do neg\u00f3cio. A camada central, implementada por um \u00fanico processo, que alimenta a interface com o usu\u00e1rio, manipula o modelo de dados, e onde reside a l\u00f3gica do neg\u00f3cio, \u00e9 um monolito . Monolitos seguem um modelo simples e largamente utilizado de desenvolvimento em que v\u00e1rios contribuidores implementam partes distintas da l\u00f3gica, que s\u00e3o compiladas em conjunto e colocadas em produ\u00e7\u00e3o de forma at\u00f4mica: Desenvolva Teste Implante volte ao passo 1 Simples n\u00e3o quer dizer necessariamente eficiente; no caso de atualiza\u00e7\u00f5es de uma parte do sistema, todo o monolito precisa ser trocado , incorrendo em, com raras exce\u00e7\u00f5es, indisponibilidade total do sistema, incluindo as partes n\u00e3o modificadas. Esta dificuldade tende a limitar as janelas de atualiza\u00e7\u00e3o do sistema, o que aumenta no n\u00famero de mudan\u00e7as que ocorrem a cada atualiza\u00e7\u00e3o, o que aumenta o risco de regress\u00f5es e portanto requer mais testes, o que aumenta o intervalo entre janelas de atualiza\u00e7\u00e3o. Al\u00e9m disso, nos caso de bugs, \u00e9 mais dif\u00edcil encontrar o problema, uma vez que fica imposs\u00edvel aos desenvolvedores conhecer todo o sistema . Isso apenas exacerba o problema, o que limita mais ainda as atualiza\u00e7\u00f5es, gerando um ciclo vicioso que mantem desenvolvedores acordados nas madrugadas de sexta para s\u00e1bado quando \u00e9 dia de deploy . Sistemas monol\u00edticos tamb\u00e9m podem ser problem\u00e1ticos quanto \u00e0 escalabilidade, pois quando a capacidade do sistema \u00e9 atingida, ou todo o sistema \u00e9 movido para um host de maior capacidade ou todo o sistema deve ser replicado. Na primeira abordagem, o custo geralmente \u00e9 um empecilho, pois pre\u00e7os de hardware crescem exponencialmente com scale up . Al\u00e9m disso, um servidor, por mais parrudo que seja, \u00e9 um Ponto \u00danico de Falha (ou SPOF, do ingl\u00eas single point of failure ). Quanto \u00e0 segunda abordagem, ela traz complexidades na coordena\u00e7\u00e3o das r\u00e9plicas e inefici\u00eancias ao replicar inclusive as partes subutilizadas. Ambas as abordagens tamb\u00e9m esbarram na escalabilidade do banco de dados que lhes serve de backend . Para contornar ou pelo menos minimizar estes problemas, pode-se fragmentar o servi\u00e7o e o banco de dados, o que facilita tanto a escalabilidade vertical quanto horizontal de cada m\u00f3dulo, que \u00e9 menor e mais simples de coordenar, e divide a carga nos bancos de dados; mas isso \u00e9 a troca do servi\u00e7o monol\u00edtico por microsservi\u00e7os.","title":"Monolitos"},{"location":"arch/microservices/#microsservicos","text":"De acordo com Lewis & Fowler The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. Em outras palavras, com os microsservi\u00e7os, quebra-se o monolito em diferentes processos, \" small autonomous services that work together, modelled around a business domain \", cada um gerenciando os dados relevantes para aquela parte do sistema e, possivelmente, sua pr\u00f3pria intera\u00e7\u00e3o com o usu\u00e1rio. Com o uso de microsservi\u00e7os, se d\u00e1 mais um passo em dire\u00e7\u00e3o \u00e0 m\u00e1xima escalabilidade do sistema. Este modelo tem implica\u00e7\u00f5es diretas no desenvolvimento: cada processo \u00e9 desenvolvido por um time diferente, que mantem controle sobre desenvolvimento, teste, e manuten\u00e7\u00e3o em produ\u00e7\u00e3o, o que \u00e9 fact\u00edvel j\u00e1 que cada servi\u00e7o \u00e9 simples e focado em um problema pequeno e ningu\u00e9m tem que entender em detalhes o funcionamento de todo o sistema. Al\u00e9m disso, quando um servi\u00e7o precisa ser atualizado, se bem projetado, todos os demais podem continuar operantes e \u00e9 poss\u00edvel at\u00e9 que m\u00faltiplas vers\u00f5es do mesmo servi\u00e7o sejam executadas concorrentemente, possibilitando atualiza\u00e7\u00f5es sem janelas de manuten\u00e7\u00e3o. Quanto \u00e0 escalabilidade, esta \u00e9 feita independentemente tamb\u00e9m; no exemplo na imagem seguinte, \u00e9 prov\u00e1vel que o servi\u00e7o de acesso ao cat\u00e1logo seja mais utilizado que os demais e portanto merecedor de mais recursos e mais c\u00f3pias. Como se percebe facilmente, o uso de microsservi\u00e7os pode ser relacionado \u00e0s t\u00e9cnicas de processamento paralelo: trate dados diferentes em blocos diferentes (paralelismo de dados ou replica\u00e7\u00e3o) e trate fun\u00e7\u00f5es diferentes em blocos diferentes (paralelismo de tarefas ou sharding ). Como na computa\u00e7\u00e3o paralela, na \"componentiza\u00e7\u00e3o\" \u00e9 importante considerar os requisitos das diferentes tarefas em termos de CPU, E/S, e mem\u00f3ria, para que possam escalar independentemente e n\u00e3o gerar gargalos desnecess\u00e1rios.","title":"Microsservi\u00e7os"},{"location":"arch/microservices/#do-monolito-aos-microsservicos","text":"Com tantas vantagens, surge a d\u00favida se todos os sistemas deveriam ser desenvolvidos usando-se a arquitetura de microsservi\u00e7os. A resposta \u00e9 n\u00e3o , pois como colocado no in\u00edcio desta se\u00e7\u00e3o, n\u00e3o existem balas de prata e se um sistema monol\u00edtico est\u00e1 funcionando para voc\u00ea e n\u00e3o h\u00e1 perspectiva de problemas acometerem (a demanda no sistema n\u00e3o est\u00e1 aumentando, a l\u00f3gica do sistema \u00e9 muito simples, indisponibilidade n\u00e3o te traz preju\u00edzo, voc\u00ea n\u00e3o pode arcar com a refatora\u00e7\u00e3o), ent\u00e3o mantenha seu sistema como est\u00e1. Caso haja a necessidade de evolu\u00e7\u00e3o e o modelo de microsservi\u00e7os pare\u00e7a adequado, existem recomenda\u00e7\u00f5es de como a migra\u00e7\u00e3o pode ser feita. Primeiro, \u00e9 preciso aceitar que o desenvolvimento de microsservi\u00e7os afeta a organiza\u00e7\u00e3o do time de desenvolvimento e que a organiza\u00e7\u00e3o provavelmente refletir\u00e1 a arquitetura. O desenvolvimento, manuten\u00e7\u00e3o e opera\u00e7\u00e3o de microsservi\u00e7os acontece em times pequenos, de 1 a 8 pessoas (\"pizza team\"), dependendo da complexidade do servi\u00e7o; se houver a necessidade de mais pessoas no time, o escopo do microsservi\u00e7o provavelmente est\u00e1 grande demais; cada componente resolve um problema, bem. Segundo, a mudan\u00e7a n\u00e3o dever\u00e1 acontecer atomicamente. Uma boa estrat\u00e9gia \u00e9 identificar uma parte do sistema que funcionaria bem como microsservi\u00e7o, desenvolv\u00ea-la e modificar o monolito para usar o microsservi\u00e7o. O aprendizado ent\u00e3o \u00e9 usado para encontrar novo candidato e o procedimento \u00e9 iterado at\u00e9 que o monolito seja apenas uma casca e possa tamb\u00e9m ser removido. Mais f\u00e1cil dito que feito, h\u00e1 muita documenta\u00e7\u00e3o orientando o processo. Para saber mais Como esta arquitetura n\u00e3o faz parte ainda do nosso curr\u00edculo, n\u00e3o nos aprofundaremos nela aqui. Felizmente h\u00e1 muito material na Web sobre este modelo, sendo a lista a seguir uma \u00ednfima fra\u00e7\u00e3o. Para uma explica\u00e7\u00e3o geral do que s\u00e3o, assista a Martin Fowler no v\u00eddeo seguinte, assista ou consulte os v\u00e1rios artigos no seu s\u00edtio . Para entender os princ\u00edpios por tr\u00e1s do uso da arquitetura, Para um exemplo importante do uso de microsservi\u00e7os, considere a Netflix, que usa microsservi\u00e7os em larga escala em seus servi\u00e7os. Qu\u00e3o larga? \"...over five hundred services... we don't know how many...\" Apesar de tal uso, ou justamente por causa dele, seus servi\u00e7os mant\u00e9m uma \"...availability of 9.995...\", ou seja, ficam indispon\u00edveis por menos de 16 segundos por ano . Com respeito a estar preparado para falhas, afinal \"... it is not if failures will happen... ... it is when it happens...\", a empresa usa uma abordagem de inje\u00e7\u00e3o de falhas em servi\u00e7os em produ\u00e7\u00e3o. Os diferentes tiposde falhas s\u00e3o injetados por um \" ex\u00e9rcito de macacos do caos \" Para uma vis\u00e3o pr\u00e1tica da implementa\u00e7\u00e3o de microsservi\u00e7os usando AWS, veja \"The hype cycle is a branded graphical presentation developed and used by the American research, advisory and information technology firm Gartner, for representing the maturity, adoption and social application of specific technologies.\" \u21a9 Peak of Inflated - Expectations Early publicity produces a number of success stories\u2014often accompanied by scores of failures. Some companies take action; most don't. Technology Trigger -- A potential technology breakthrough kicks things off. Early proof-of-concept stories and media interest trigger significant publicity. Often no usable products exist and commercial viability is unproven. Slope of Enlightenment -- More instances of how the technology can benefit the enterprise start to crystallize and become more widely understood. Second- and third-generation products appear from technology providers. More enterprises fund pilots; conservative companies remain cautious. Plateau of Productivity -- Mainstream adoption starts to take off. Criteria for assessing provider viability are more clearly defined. The technology's broad market applicability and relevance are clearly paying off. Trough of Disillusionment - Interest wanes as experiments and implementations fail to deliver. Producers of the technology shake out or fail. Investment continues only if the surviving providers improve their products to the satisfaction of early adopters. \u21a9 \u21a9","title":"Do Monolito aos Microsservi\u00e7os"},{"location":"arch/p2p/","text":"Sistemas Peer-2-Peer Nesta se\u00e7\u00e3o, nos aprofundaremos no estudo de sistemas P2P, come\u00e7ando pelo fato de que seus componentes se organizam em redes l\u00f3gica, sobrepostas \u00e0 rede f\u00edsica. Rede Sobreposta ( Overlay ) Nesta rede l\u00f3gica, os processos estabelecem canais de comunica\u00e7\u00e3o tipicamente na forma de conex\u00f5es TCP/IP. Por serem ignorantes \u00e0 topologia f\u00edsica da rede e usarem a pilha de comunica\u00e7\u00e3o IP, as redes sobrepostas s\u00e3o mais simples e ao mesmo tempo mais poderosas. Nestas redes s\u00e3o executados diversos algoritmos, como de descoberta de n\u00f3s, roteamento de pacotes e de otimiza\u00e7\u00e3o de rotas pelo descarte e cria\u00e7\u00e3o de conex\u00f5es. Uma vez que as conex\u00f5es na rede sobreposta n\u00e3o correspondem a conex\u00f5es f\u00edsicas , como se pode ver na seguinte figura, vizinhos em um rede sobreposta n\u00e3o necessariamente correspondem a vizinhos na rede f\u00edsica e vice-versa. Isto tamb\u00e9m implica que a otimiza\u00e7\u00e3o da rota l\u00f3gica n\u00e3o necessariamente leva \u00e0 otimiza\u00e7\u00e3o da rota f\u00edsica . Dependendo em como esta rede \u00e9 organizada (ou n\u00e3o), a mesma \u00e9 classificada como estruturada ou n\u00e3o-estruturada . Rede N\u00e3o-Estruturada Se a rede sobreposta \u00e9 constru\u00edda de forma aleat\u00f3ria, por exemplo deixando os n\u00f3s se conectarem apenas aos vizinhos na rede no ponto em que se conectaram inicialmente, ent\u00e3o esta \u00e9 denominada uma rede n\u00e3o-estruturada . A figura a seguir \u00e9 um exemplo que se percebe que n\u00f3s tem graus diferentes de conectividade e que n\u00e3o est\u00e3o particularmente organizados em nenhuma topologia. Suponha que esta rede seja usada para armazenar e consultar dados. Inser\u00e7\u00f5es de dados podem ser feitas muito rapidamente, armazenando-os no primeiro n\u00f3 dispon\u00edvel encontrado. Os objetos amarelo e vermelho foram inseridos desta forma, e copiados em n\u00f3s pr\u00f3ximos para tolerar a falha de alguns hosts sem perder os dados. Buscas, contudo, ter\u00e3o que vasculhar a rede usando algoritmos como busca em largura , busca em profundidade ou caminhada aleat\u00f3ria (resposta probabil\u00edstica). Rede Estruturada Se as conex\u00f5es s\u00e3o constru\u00eddas e mantidas de forma a gerar uma topologia bem definida , chamamos esta rede de estruturada . Nesta rede, a inser\u00e7\u00e3o de n\u00f3s requer a propaga\u00e7\u00e3o desta informa\u00e7\u00e3o para outros n\u00f3s e a atualiza\u00e7\u00e3o das conex\u00f5es para manter a estrutura. A estrutura geralmente serve ao prop\u00f3sito de associar os n\u00f3s aos dados de uma forma planejada. Por exemplo, n\u00f3s pr\u00f3ximos na rede podem ser respons\u00e1veis por dados logicamente pr\u00f3ximos. Claramente, a inser\u00e7\u00e3o e acesso a dados nesta rede \u00e9 mais custosa, pois independentemente de onde a requisi\u00e7\u00e3o \u00e9 feita, isto \u00e9, a partir de qual n\u00f3, ela dever\u00e1 ser atendida por um n\u00f3 espec\u00edfico. Veja o exemplo do Chord, uma rede P2P em que os n\u00f3s formam um anel l\u00f3gico, cujos detalhes veremos adiante. Cada n\u00f3 \u00e9 respons\u00e1vel pela faixa de valores indexados por chaves entre o identificador do n\u00f3 e o do n\u00f3 anterior. Logo, qualquer inser\u00e7\u00e3o ou consulta de dados, deve ser feita especificamente para um determinado n\u00f3, e deve ser roteada para o mesmo. A estrutura da rede permite que tal roteamento seja feito eficientemente, no n\u00edvel da rede sobreposta. Como outro exemplo considere uma rede em que os n\u00f3s armazenam informa\u00e7\u00f5es sobre os dados de uma certa \u00e1rea geogr\u00e1fica e que n\u00f3s vizinhos na rede sejam aqueles respons\u00e1veis por \u00e1reas que se tocam. Neste exemplo, para se acessar os dados de um certo ponto no mapa, basta rotear a requisi\u00e7\u00e3o para o vizinho mais pr\u00f3ximo do ponto; necessariamente a requisi\u00e7\u00e3o chegar\u00e1 ao n\u00f3 correto. De n\u00e3o estruturada a estruturada A seguinte tabela resume as diferen\u00e7as entre os dois tipos de redes sobrepostas. Estruturada N\u00e3o-Estruturada Estrutura bem definida Estrutura aleat\u00f3ria Adi\u00e7\u00e3o de dados \u00e9 lenta Adi\u00e7\u00e3o de dados \u00e9 r\u00e1pida Adi\u00e7\u00e3o de n\u00f3s \u00e9 lenta Adi\u00e7\u00e3o de n\u00f3s \u00e9 r\u00e1pida Busca por dados \u00e9 r\u00e1pida Busca por dados lenta Mas, e se pud\u00e9ssemos juntar o melhor dos dois mundos em um \u00fanico sistema? Isso \u00e9 poss\u00edvel em certos cen\u00e1rios. Por exemplo, seja uma grade \\(N \\times N\\) em que n\u00f3s em uma borda da matriz conseguem se conectar aos n\u00f3s da borda oposta. Dist\u00e2ncias entre n\u00f3s s\u00e3o medidas como a soma das dist\u00e2ncias em \\(x\\) mais a dist\u00e2ncia em \\(y\\) . \\(a = (x,y), b = (x', y')\\) \\(d_x(a,b) = min(|x - x'|, N - |x - x'|)\\) \\(d_y(a,b) = min(|y - y'|, N - |y - y'|)\\) \\(d(a,b) = d_x(a,b) + d_y(a,b)\\) Suponha que cada divida a organiza\u00e7\u00e3o da topologia em dois m\u00f3dulos, um de descoberta de novos n\u00f3s e outro de sele\u00e7\u00e3o. O m\u00f3dulo de descoberta leva inicialmente ao estabelecimento de conex\u00f5es aleat\u00f3rias e \u00e0 forma\u00e7\u00e3o de uma rede sobreposta n\u00e3o estruturada como, por exemplo, a seguinte. Ap\u00f3s as conex\u00f5es inicias, cada um dos n\u00f3s executa o seguinte protocolo iteradamente. O m\u00f3dulo de descoberta, repetidamente, pergunta aos seus vizinhos quem s\u00e3o os seus vizinhos e se conecta aos mesmos. O m\u00f3dulo de sele\u00e7\u00e3o computa a dist\u00e2ncia entre o n\u00f3 e todos os seus vizinhos e descarta as conex\u00f5es com maior dist\u00e2ncia. Ao final de m\u00faltiplas intera\u00e7\u00f5es, cada n\u00f3 ter\u00e1 como seus vizinhos, os n\u00f3s mais pr\u00f3ximos. Se a rede for completa (um n\u00f3 em cada posi\u00e7\u00e3o da grade), como no exemplo, e o m\u00f3dulo de sele\u00e7\u00e3o sempre mantiver quatro conex\u00f5es, ao final do processo os vizinhos ser\u00e3o os n\u00f3s \u00e0 direita, esquerda, acima e abaixo. Se a rede n\u00e3o for completa ou se menos conex\u00f5es forem mantidas, uma aproxima\u00e7\u00e3o ser\u00e1 obtida. A seguinte figura apresenta uma outra rede resultada da aplica\u00e7\u00e3o do mesmo princ\u00edpio, mas em uma \"grade\" com tr\u00eas dimens\u00f5es. Se em vez da dist\u00e2ncia cartesiana fosse usada a dist\u00e2ncia de Hamming entre os identificadores dos n\u00f3s, ao final das itera\u00e7\u00f5es, a topologia alcan\u00e7ada seria um hyper-cubo, como os da seguinte figura, 1 no qual diversos esquemas de roteamento eficientes podem ser usados . 2 Sistemas P2P Arquitetura decentralizada; N\u00e3o h\u00e1 distin\u00e7\u00e3o de pap\u00e9is entre n\u00f3s ou conjuntos de n\u00f3s desempenham os mesmos pap\u00e9is, em parceria; Escalabilidade geogr\u00e1fica global, isto \u00e9, com n\u00f3s espalhados por todo o globo; Pode haver entrada e sa\u00edda de n\u00f3s do sistema com alta frequ\u00eancia; N\u00f3s se organizam em redes sobrepostas (em ingl\u00eas, overlay ), redes l\u00f3gicas sobre as redes f\u00edsicas; Auto-administra\u00e7\u00e3o. Resiliente a falhas Tabelas de Espalhamento Distribu\u00eddas (DHT) A versatilidade dos sistemas P2P os levaram a ser amplamente estudados e aplicados, sendo que entre as aplica\u00e7\u00f5es mais bem sucedidas est\u00e3o as Tabelas de Espalhamento Distribu\u00eddas (DHT, do ingl\u00eas, Distributed Hash Tables ). As tabelas de espalhamento (tamb\u00e9m conhecidas como mapas, dicion\u00e1rios, arrays associativos) tem caracter\u00edsticas que a tornam adequadas ao armazenamento de dados a v\u00e1rios cen\u00e1rios. Em ess\u00eancia, estas tabelas s\u00e3o fun\u00e7\u00f5es que mapeiam uma chave para um valor, uma fun\u00e7\u00e3o \\(f\\) tal que \\(f(K): V \\cup \\{null\\}\\) \\(K\\) : Universo de chaves \\(V\\) : Universo de valores isto \u00e9, \\(f(k) = v, k\\in K, v \\in V\\) ou \\(v =\\) null. Na pr\u00e1tica, s\u00e3o estruturas de dados adapt\u00e1veis, com um API muito simples, e com opera\u00e7\u00f5es de tempo (mais ou menos) constante para fazer CRUD de pares chave/valor. Tanto \\(K\\) quanto \\(V\\) s\u00e3o blobs de dados, isto \u00e9, sem nenhuma forma distinta, e por isso podem ser usadas para resolver uma gama de problemas. API sejam \\(k \\in K\\) e \\(v,w \\in V\\) \\(put(k,v)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) else \\(f(k) \\rightarrow v\\) ; return \\(null\\) \\(update(k,v)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) ; \\(f(k) \\rightarrow v\\) else return \\(null\\) \\(get(k)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) else return \\(null\\) \\(del(k)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) else return \\(null\\) execu\u00e7\u00e3o \\(O(1)\\) Se as tabelas de espalhamento s\u00e3o estruturas de dados \u00fateis, uma vers\u00e3o distribu\u00edda seria ainda mais \u00fatil, principalmente porqu\u00ea ela poderia ser tolerante a falhas e ter escalabilidade linear . \u00c9 justamente desta idea que surgem as DHT, literalmente tabelas de espalhamento distribu\u00eddas, estruturas de dados que mant\u00e9m a mesma API e funcionalidades de tabelas de espalhamento, mas que agrega capacidades de diversos hosts . Dentre os desafios na implementa\u00e7\u00e3o de uma DHT est\u00e3o O que usar como chave? Uma DHT deve ser vers\u00e1til para ser utilizada para v\u00e1rios fins, ent\u00e3o a chave precisa ser independente da aplica\u00e7\u00e3o. Como dividir a carga entre hosts? \u00c9 preciso balancear a carga para que um lado da rede n\u00e3o se torne mais importante que o outro e para n\u00e3o levar a uma hierarquiza\u00e7\u00e3o entre os n\u00f3s. Como rotear requisi\u00e7\u00f5es para o host correto? Uma vez que os dados devem ser particionados entre hosts para garantir escalabilidade, como encontrar o n\u00f3 onde determinado dado est\u00e1 or deveria estar? Identifica\u00e7\u00e3o A identifica\u00e7\u00e3o de objetos precisa ser facilmente determin\u00e1vel pela aplica\u00e7\u00e3o para permitir a recupera\u00e7\u00e3o precisa dos dados. Por exemplo, podemos usar o identificador \u00fanico CPF como chave para dados de pessoas e dividir seus poss\u00edveis valores em faixas, atribu\u00eddas a diferentes n\u00f3s do sistema. 000.000.000-00 - 111.111.111-00: n\u00f3 1 111.111.111-01 - 222.222.222-00: n\u00f3 2 222.222.222-01 - 333.333.333-00: n\u00f3 3 ... Contudo, esta chave \u00e9 ruim pois n\u00e3o propicia uma distribui\u00e7\u00e3o uniforme da carga de trabalho entre os hosts; como CPF s\u00e3o gerados sequencialmente, os hosts iniciais seriam respons\u00e1veis por mais dados que os demais. Mas mesmo que a gera\u00e7\u00e3o de CPF fosse aleat\u00f3ria, ainda ter\u00edamos outro problema com seu uso como chave: o CPF s\u00f3 se aplica a pessoas e portanto n\u00e3o \u00e9 us\u00e1vel em outras aplica\u00e7\u00f5es. Para resolver estes tr\u00eas problemas, recorremos a uma abordagem usada na literatura da \u00e1rea, dividindo a identifica\u00e7\u00e3o em duas camadas: Seja \\(i\\) o identificador do objeto, dado pela aplica\u00e7\u00e3o (e.g., CPF, nome, telefone) Seja \\(h\\) uma fun\u00e7\u00e3o hash criptogr\u00e1fica O objeto identificado por \\(i\\) na aplica\u00e7\u00e3o ser\u00e1 identificado por \\(k = h(i)\\) dentro da DHT. Divis\u00e3o da carga Se usarmos, por exemplo, MD5, \u00e9 fato que \\(k\\) tem distribui\u00e7\u00e3o uniforme no espa\u00e7o de 0 a \\(2^{160}-1\\) poss\u00edveis valores. Para dividirmos os dados entre os hosts tamb\u00e9m uniformemente, distribua os valores entre os hosts em fun\u00e7\u00e3o de \\(k\\) . Alguns exemplos de divis\u00e3o s\u00e3o: defina buckets para cada host e atribua o dado com chave \\(k\\) para bucket \\(k \\% b\\) , onde \\(b\\) \u00e9 o n\u00famero de buckets divida a faixa de valores em \\(b\\) segmentos e atribua a cada host uma faixa dados \\(2^n\\) hosts, atribua ao host \\(0 < x < 2^n-1\\) os dados cujas chaves terminem com o valor \\(x\\) . S\u00e3o v\u00e1rias as formas de se dividir os dados e estas est\u00e3o intimamente ligadas \u00e0 rede sobreposta que se pretende montar e a como o roteamento ser\u00e1 feito. Roteamento Para estudar o desafio do roteamento, nas se\u00e7\u00f5es seguintes estudaremos o Chord, um sistema P2P que surgiu no meio acad\u00eamico mas cujo design influenciou fortemente a ind\u00fastria no desenvolvimento dos bancos dados distribu\u00eddos NOSQL, como Cassandra, Dynamo, e Redis. No caso da grade 4x4, a o hipercubo \u00e9 topologicamente igual \u00e0 rede obtida pela dist\u00e2ncia cartesiana como mostrado no exemplo acima. \u21a9 Neste problema do ICPC, um esquema de nomea\u00e7\u00e3o dos n\u00f3s de um hypercube \u00e9 apresentado; usando este esquema, derive um algoritmo de roteamento em que a dist\u00e2ncia percorrida por qualquer mensagem seja sempre igual ao n\u00famero de dimens\u00f5es do cubo. \u21a9","title":"P2P"},{"location":"arch/p2p/#sistemas-peer-2-peer","text":"Nesta se\u00e7\u00e3o, nos aprofundaremos no estudo de sistemas P2P, come\u00e7ando pelo fato de que seus componentes se organizam em redes l\u00f3gica, sobrepostas \u00e0 rede f\u00edsica.","title":"Sistemas Peer-2-Peer"},{"location":"arch/p2p/#rede-sobreposta-overlay","text":"Nesta rede l\u00f3gica, os processos estabelecem canais de comunica\u00e7\u00e3o tipicamente na forma de conex\u00f5es TCP/IP. Por serem ignorantes \u00e0 topologia f\u00edsica da rede e usarem a pilha de comunica\u00e7\u00e3o IP, as redes sobrepostas s\u00e3o mais simples e ao mesmo tempo mais poderosas. Nestas redes s\u00e3o executados diversos algoritmos, como de descoberta de n\u00f3s, roteamento de pacotes e de otimiza\u00e7\u00e3o de rotas pelo descarte e cria\u00e7\u00e3o de conex\u00f5es. Uma vez que as conex\u00f5es na rede sobreposta n\u00e3o correspondem a conex\u00f5es f\u00edsicas , como se pode ver na seguinte figura, vizinhos em um rede sobreposta n\u00e3o necessariamente correspondem a vizinhos na rede f\u00edsica e vice-versa. Isto tamb\u00e9m implica que a otimiza\u00e7\u00e3o da rota l\u00f3gica n\u00e3o necessariamente leva \u00e0 otimiza\u00e7\u00e3o da rota f\u00edsica . Dependendo em como esta rede \u00e9 organizada (ou n\u00e3o), a mesma \u00e9 classificada como estruturada ou n\u00e3o-estruturada .","title":"Rede Sobreposta (Overlay)"},{"location":"arch/p2p/#tabelas-de-espalhamento-distribuidas-dht","text":"A versatilidade dos sistemas P2P os levaram a ser amplamente estudados e aplicados, sendo que entre as aplica\u00e7\u00f5es mais bem sucedidas est\u00e3o as Tabelas de Espalhamento Distribu\u00eddas (DHT, do ingl\u00eas, Distributed Hash Tables ). As tabelas de espalhamento (tamb\u00e9m conhecidas como mapas, dicion\u00e1rios, arrays associativos) tem caracter\u00edsticas que a tornam adequadas ao armazenamento de dados a v\u00e1rios cen\u00e1rios. Em ess\u00eancia, estas tabelas s\u00e3o fun\u00e7\u00f5es que mapeiam uma chave para um valor, uma fun\u00e7\u00e3o \\(f\\) tal que \\(f(K): V \\cup \\{null\\}\\) \\(K\\) : Universo de chaves \\(V\\) : Universo de valores isto \u00e9, \\(f(k) = v, k\\in K, v \\in V\\) ou \\(v =\\) null. Na pr\u00e1tica, s\u00e3o estruturas de dados adapt\u00e1veis, com um API muito simples, e com opera\u00e7\u00f5es de tempo (mais ou menos) constante para fazer CRUD de pares chave/valor. Tanto \\(K\\) quanto \\(V\\) s\u00e3o blobs de dados, isto \u00e9, sem nenhuma forma distinta, e por isso podem ser usadas para resolver uma gama de problemas. API sejam \\(k \\in K\\) e \\(v,w \\in V\\) \\(put(k,v)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) else \\(f(k) \\rightarrow v\\) ; return \\(null\\) \\(update(k,v)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) ; \\(f(k) \\rightarrow v\\) else return \\(null\\) \\(get(k)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) else return \\(null\\) \\(del(k)\\) : if \\(f(k) = w \\neq null\\) then return \\(w\\) else return \\(null\\) execu\u00e7\u00e3o \\(O(1)\\) Se as tabelas de espalhamento s\u00e3o estruturas de dados \u00fateis, uma vers\u00e3o distribu\u00edda seria ainda mais \u00fatil, principalmente porqu\u00ea ela poderia ser tolerante a falhas e ter escalabilidade linear . \u00c9 justamente desta idea que surgem as DHT, literalmente tabelas de espalhamento distribu\u00eddas, estruturas de dados que mant\u00e9m a mesma API e funcionalidades de tabelas de espalhamento, mas que agrega capacidades de diversos hosts . Dentre os desafios na implementa\u00e7\u00e3o de uma DHT est\u00e3o O que usar como chave? Uma DHT deve ser vers\u00e1til para ser utilizada para v\u00e1rios fins, ent\u00e3o a chave precisa ser independente da aplica\u00e7\u00e3o. Como dividir a carga entre hosts? \u00c9 preciso balancear a carga para que um lado da rede n\u00e3o se torne mais importante que o outro e para n\u00e3o levar a uma hierarquiza\u00e7\u00e3o entre os n\u00f3s. Como rotear requisi\u00e7\u00f5es para o host correto? Uma vez que os dados devem ser particionados entre hosts para garantir escalabilidade, como encontrar o n\u00f3 onde determinado dado est\u00e1 or deveria estar?","title":"Tabelas de Espalhamento Distribu\u00eddas (DHT)"},{"location":"cases/","text":"Neste cap\u00edtulo, visitamos diversos estudos de caso das tecnologias vistas em outras se\u00e7\u00f5es.","title":"Introdu\u00e7\u00e3o"},{"location":"cases/bftsmart/","text":"BFT-Smart Todo BFT-Smart","title":"BFT-Smart"},{"location":"cases/bftsmart/#bft-smart","text":"Todo BFT-Smart","title":"BFT-Smart"},{"location":"cases/cassandra/","text":"Sistema P2P: Cassandra Outra alternativa \u00e9 fazer com que cada n\u00f3 do sistema conhe\u00e7a todos os outros. Assim, cada requisi\u00e7\u00e3o pode ser diretamente encaminhada ao n\u00f3 respons\u00e1vel por trat\u00e1-la. O custo do roteamento, neste caso, \u00e9 \\(O(1)\\) , muito mais r\u00e1pido que na abordagem anterior. O custo de armazenamento da tabela de rotas \u00e9, contudo, \\(O(n)\\) , o que pode ser proibitivo em uma rede com milhares de n\u00f3s, apesar de ser uma solu\u00e7\u00e3o vi\u00e1vel em redes menores. Este \u00e9 o caso do CassandraDB, uma banco de dados distribu\u00eddo baseado no Chord, que estudaremos melhor mais adiante, considerado uma DHT de salto \u00fanico ( single-hop DHT). O CassandraDB foi, sem sombra de d\u00favida, influenciado pelo projeto do DynamoDB, o que \u00e9 facilmente explic\u00e1vel j\u00e1 que um dos criadores do Dynamo foi o arquiteto do Cassandra. Mas em vez de uma c\u00f3pia, o Cassandra largamente expande a funcionalidade do Dynamo ao se inspirar no banco de dados BigTable , do Google. Com isso, o Cassandra se aproxima do modelo relacional, facilitando o desenvolvimento de certas aplica\u00e7\u00f5es, sem perder as caracter\u00edsticas desej\u00e1veis das DHT. A principal caracter\u00edstica neste sentido \u00e9 o modelo h\u00edbrido chave-valor/relacional, em que os valores associados a uma chave s\u00e3o divididos em colunas. A combina\u00e7\u00e3o chave-colunas s\u00e3o denominadas column-families e seu conjunto keyspace . Estas duas estruturas s\u00e3o equivalente \u00e0s tabelas/rela\u00e7\u00f5es e aos bancos de dados, dos bancos de dados relacionais. Uma diferen\u00e7a fundamental entre column-families e rela\u00e7\u00f5es \u00e9 que as \u00faltimas precisam de um esquema pr\u00e9-definido, enquanto que as primeiras n\u00e3o tem um esquema. Isto quer dizer que novas colunas podem ser adicionadas dinamicamente e que nem todas precisam estar presentes para cada chave. De fato, m\u00faltiplos registros com a mesma chave, ou linhas, podem ter conjuntos de colunas diferentes. Para que o correto conjunto de colunas associado a uma chave possa ser apurado, ap\u00f3s m\u00faltiplas escritas com a mesma chave tenham ocorrido, a cada tupla (chave,coluna,valor) \u00e9 associado tamb\u00e9m um timestamp . . Assim, dados uma mesma chave e coluna, o valor v\u00e1lido \u00e9 o com o maior timestamp. Devido a possibilidade de valores serem escritos para diferentes colunas independentemente, valores v\u00e1lidos e inv\u00e1lidos podem ter o mesmo timestamp . Por exemplo, considere os seguintes dados escritos no banco: Chave Coluna \\(\\rightarrow\\) Valor Timestamp 3 Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 30 02:02:2020,13:45:00 3 Idade \\(\\rightarrow\\) 33 02:02:2020,13:50:00 3 Telefone \\(\\rightarrow\\) 333444554433 02:02:2020,13:55:00 Uma busca pelos dados associados \u00e0 chave 3 retornar\u00e1 o seguinte resultado: Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 33, Telefone \\(\\rightarrow\\) 333444554433. Para facilitar mais ainda o desenvolvimento, o Cassandra conta com uma linguagem de consulta similar ao SQL (Structured Query Language), a CQL (Cassandra Query Language). Assim, a consulta a estes dados seria mais ou menos como SELECT * FROM dados WHERE key == 3 . 1 H\u00e1 muitos recursos online para se aprender mais se aprender mais sobre como usar o Cassandra, por exemplo, aqui . H\u00e1 tamb\u00e9m diversos projetos de c\u00f3digo livre que o usam e podem ser estudados, por exemplo, o clone de Twiter Twissandra . Mas embora o uso de sistemas gerenciadores de bancos de dados em sistemas distribu\u00eddos seja interessante, aqui nos focaremos em alguns dos aspectos de como estes SGBD s\u00e3o constru\u00eddos. Detalhes de Implementa\u00e7\u00e3o A se\u00e7\u00e3o de tecnologias descreve v\u00e1rias estruturas de dados recorrentemente usadas em implementa\u00e7\u00e3o de bancos de dados como o Cassandra. Este exemplo \u00e9 meramente ilustrativo e n\u00e3o segue estritamente a sintaxe do CQL. \u21a9","title":"Cassandra"},{"location":"cases/cassandra/#sistema-p2p-cassandra","text":"Outra alternativa \u00e9 fazer com que cada n\u00f3 do sistema conhe\u00e7a todos os outros. Assim, cada requisi\u00e7\u00e3o pode ser diretamente encaminhada ao n\u00f3 respons\u00e1vel por trat\u00e1-la. O custo do roteamento, neste caso, \u00e9 \\(O(1)\\) , muito mais r\u00e1pido que na abordagem anterior. O custo de armazenamento da tabela de rotas \u00e9, contudo, \\(O(n)\\) , o que pode ser proibitivo em uma rede com milhares de n\u00f3s, apesar de ser uma solu\u00e7\u00e3o vi\u00e1vel em redes menores. Este \u00e9 o caso do CassandraDB, uma banco de dados distribu\u00eddo baseado no Chord, que estudaremos melhor mais adiante, considerado uma DHT de salto \u00fanico ( single-hop DHT). O CassandraDB foi, sem sombra de d\u00favida, influenciado pelo projeto do DynamoDB, o que \u00e9 facilmente explic\u00e1vel j\u00e1 que um dos criadores do Dynamo foi o arquiteto do Cassandra. Mas em vez de uma c\u00f3pia, o Cassandra largamente expande a funcionalidade do Dynamo ao se inspirar no banco de dados BigTable , do Google. Com isso, o Cassandra se aproxima do modelo relacional, facilitando o desenvolvimento de certas aplica\u00e7\u00f5es, sem perder as caracter\u00edsticas desej\u00e1veis das DHT. A principal caracter\u00edstica neste sentido \u00e9 o modelo h\u00edbrido chave-valor/relacional, em que os valores associados a uma chave s\u00e3o divididos em colunas. A combina\u00e7\u00e3o chave-colunas s\u00e3o denominadas column-families e seu conjunto keyspace . Estas duas estruturas s\u00e3o equivalente \u00e0s tabelas/rela\u00e7\u00f5es e aos bancos de dados, dos bancos de dados relacionais. Uma diferen\u00e7a fundamental entre column-families e rela\u00e7\u00f5es \u00e9 que as \u00faltimas precisam de um esquema pr\u00e9-definido, enquanto que as primeiras n\u00e3o tem um esquema. Isto quer dizer que novas colunas podem ser adicionadas dinamicamente e que nem todas precisam estar presentes para cada chave. De fato, m\u00faltiplos registros com a mesma chave, ou linhas, podem ter conjuntos de colunas diferentes. Para que o correto conjunto de colunas associado a uma chave possa ser apurado, ap\u00f3s m\u00faltiplas escritas com a mesma chave tenham ocorrido, a cada tupla (chave,coluna,valor) \u00e9 associado tamb\u00e9m um timestamp . . Assim, dados uma mesma chave e coluna, o valor v\u00e1lido \u00e9 o com o maior timestamp. Devido a possibilidade de valores serem escritos para diferentes colunas independentemente, valores v\u00e1lidos e inv\u00e1lidos podem ter o mesmo timestamp . Por exemplo, considere os seguintes dados escritos no banco: Chave Coluna \\(\\rightarrow\\) Valor Timestamp 3 Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 30 02:02:2020,13:45:00 3 Idade \\(\\rightarrow\\) 33 02:02:2020,13:50:00 3 Telefone \\(\\rightarrow\\) 333444554433 02:02:2020,13:55:00 Uma busca pelos dados associados \u00e0 chave 3 retornar\u00e1 o seguinte resultado: Nome \\(\\rightarrow\\) Jos\u00e9, Idade \\(\\rightarrow\\) 33, Telefone \\(\\rightarrow\\) 333444554433. Para facilitar mais ainda o desenvolvimento, o Cassandra conta com uma linguagem de consulta similar ao SQL (Structured Query Language), a CQL (Cassandra Query Language). Assim, a consulta a estes dados seria mais ou menos como SELECT * FROM dados WHERE key == 3 . 1 H\u00e1 muitos recursos online para se aprender mais se aprender mais sobre como usar o Cassandra, por exemplo, aqui . H\u00e1 tamb\u00e9m diversos projetos de c\u00f3digo livre que o usam e podem ser estudados, por exemplo, o clone de Twiter Twissandra . Mas embora o uso de sistemas gerenciadores de bancos de dados em sistemas distribu\u00eddos seja interessante, aqui nos focaremos em alguns dos aspectos de como estes SGBD s\u00e3o constru\u00eddos. Detalhes de Implementa\u00e7\u00e3o A se\u00e7\u00e3o de tecnologias descreve v\u00e1rias estruturas de dados recorrentemente usadas em implementa\u00e7\u00e3o de bancos de dados como o Cassandra. Este exemplo \u00e9 meramente ilustrativo e n\u00e3o segue estritamente a sintaxe do CQL. \u21a9","title":"Sistema P2P: Cassandra"},{"location":"cases/chord/","text":"P2P: Chord Chord \u00e9 uma sistema P2P de m\u00faltiplas aplica\u00e7\u00f5es desenvolvido pelos membros do CSAIL , do MIT, e publicado em 2001. Desde ent\u00e3o, inspirou diversos outros sistemas, tornando-se sin\u00f4nimo com P2P. Neste sistema, n\u00f3s organizam-se em um anel l\u00f3gico e cada um torna-se respons\u00e1vel por um dos segmentos do anel adjacente a onde se encontra no mesmo. Requisi\u00e7\u00f5es para correspondentes a um segmento s\u00e3o roteados para o n\u00f3 respons\u00e1vel usando uma tabela de rotas conhecida como finger table . Se tra\u00e7armos os caminhos apontados por esta tabela sobre o anel, desenharemos cordas sobre o mesmo, o que explica o nome do sistema. Identifica\u00e7\u00e3o No Chord o problema da identifica\u00e7\u00e3o dos dados \u00e9 resolvido usando-se chaves de \\(m\\) bits , geradas por meio de uma fun\u00e7\u00e3o hash criptogr\u00e1fica a partir de chaves que fa\u00e7a sentido para a aplica\u00e7\u00e3o, por exemplo nome, telefone, ou CPF. Como a fun\u00e7\u00e3o hash \u00e9 criptogr\u00e1fica, uma pequena varia\u00e7\u00e3o na entrada implica em grande varia\u00e7\u00e3o na sa\u00edda e, para quem observa apenas a sa\u00edda da fun\u00e7\u00e3o, uma sequ\u00eancia de chaves \u00e9 indistingu\u00edvel de uma sequ\u00eancia aleat\u00f3ria. Divis\u00e3o de carga A cada n\u00f3 \u00e9 atribu\u00eddo um identificador \u00fanico de \\(m\\) bits , gerado aleatoriamente. Como \\(m\\) normalmente \u00e9 grande, com mais de uma centena de bits, a probabilidade de dois n\u00f3s terem o mesmo identificar \u00e9 desprez\u00edvel. Al\u00e9m disso, os n\u00f3s se organizam em uma rede sobreposta estruturada na forma de um anel l\u00f3gico , em que os n\u00f3s aparecem ordenadamente de acordo com seus identificadores. A figura a seguir mostra um anel em cujo os n\u00f3s tem identificadores de 8 bits (0 a 255), com cinco n\u00f3s. 1 Assumamos inicialmente que os n\u00f3s s\u00f3 est\u00e3o cientes dos seus vizinhos imediatos no anel. Cada chave \u00e9 associada a um n\u00f3, respons\u00e1vel por atender requisi\u00e7\u00f5es de cria\u00e7\u00e3o, consulta, modifica\u00e7\u00e3o e remo\u00e7\u00e3o dos dados relacionados \u00e0quela chave. A pseudo aleatoriedade na gera\u00e7\u00e3o da chave e a aleatoriedade na gera\u00e7\u00e3o dos identificadores de n\u00f3s faz com que a distribui\u00e7\u00e3o de carga entre os n\u00f3s seja uniforme. O dado com chave \\(k\\) \u00e9 responsabilidade do n\u00f3 com menor identificador \\(i \\geq k\\) , aka, sucessor de \\(k\\) ( \\(i = suc(k)\\) ), no anel. Na figura a seguir, \u00e9 apresentado junto a cada n\u00f3 as chaves pelas quais o n\u00f3 \u00e9 respons\u00e1vel. Roteamento Suponha que um cliente solicite ao Chord do exemplo anterior que armazene o valor \\(v\\) associado \u00e0 chave \\(k\\) . A solicita\u00e7\u00e3o \u00e9 feita pelo contato a um dos n\u00f3s no sistema, que pode ou n\u00e3o ser o respons\u00e1vel por \\(k\\) . Caso seja o respons\u00e1vel, a solicita\u00e7\u00e3o \u00e9 executada localmente e uma resposta devolvida ao cliente. Caso contr\u00e1rio, a requisi\u00e7\u00e3o deve repassada ou roteada para o n\u00f3 correto. Na rede estruturada definida at\u00e9 agora, uma op\u00e7\u00e3o \u00f3bvia \u00e9 repassar a requisi\u00e7\u00e3o para um dos vizinhos e assim sucessivamente at\u00e9 que alcance o n\u00f3 correto. Esta solu\u00e7\u00e3o, correta, tem custo da ordem do n\u00famero de n\u00f3s no sistema, \\(O(n)\\) . Em uma inst\u00e2ncia com milhares de n\u00f3s, \\(O(n)\\) \u00e9 um custo muito alto, ainda mais se considerarmos que cada salto na rede sobreposta potencialmente cruza toda a Internet, uma vez que, refor\u00e7ando, a proximidade na rede sobreposta n\u00e3o implica em proximidade na rede f\u00edsica abaixo. Observe que o custo em termos de espa\u00e7o para se implementar esta solu\u00e7\u00e3o \u00e9 \\(O(1)\\) para cada n\u00f3 do sistema. Em outras palavras, cada n\u00f3 mantem uma tabela de rotas com uma ou duas entradas, apontando para seus vizinhos. Com uma rede com milhares de n\u00f3s, uma solu\u00e7\u00e3o \\(O(n)\\) saltos, onde cada pode levar ao outro lado do planeta , opera\u00e7\u00f5es teriam uma lat\u00eancia muito alta. Para amenizar o custo, Chord prop\u00f5e a cria\u00e7\u00e3o de uma tabela de rotas, tamb\u00e9m conhecida como finger-table , que aponta para n\u00f3s no anel com dist\u00e2ncias que se dobram a cada entrada. A finger-table \u00e9 constru\u00edda da seguinte forma, onde \\(m\\) \u00e9 a quantidade de bits usados para identificar n\u00f3s no sistema: seja \\(F_p\\) a finger-table do processo \\(p\\) ; seja \\(F_p[i]\\) a \\(i\\) -\u00e9sima da tabela; e, \\(F_p[i] = suc(p+2^{i-1})\\) . Observe que nesta tabela, a \\(i\\) -\u00e9sima entrada aponta para o processo que no que sucede \\(p\\) pelo menos \\(2^{i-1}\\) , e que esta dist\u00e2ncia de sucess\u00e3o aumenta exponencialmente. Observe tamb\u00e9m que a maior dist\u00e2ncia \u00e9 proporcional a metade do tamanho do anel. Isto quer dizer que o \u00faltimo finger da tabela proporciona um salto de \\(1/2\\) anel, o pen\u00faltimo \\(1/4\\) do anel, o ante-pen\u00faltimo \\(1/8\\) , e assim sucessivamente. Outra forma de se ver esta tabela \u00e9 como proporcionando um salto de pelo menos metade da dist\u00e2ncia restante para o n\u00f3 respons\u00e1vel pela chave, resultando em um roteamento com custo \\(O(log n)\\) . Mas como este potencial \u00e9 explorado? Usando-se o seguinte algoritmo de busca pela entrada correta na tabela de roteamento, do ponto de vista do processo \\(p\\) : seja \\(k\\) a chave para qual estamos procurando o sucessor; itere pela tabela at\u00e9 achar a primeira entrada cujo valor, i.e., o identificador de um n\u00f3, \u00e9 maior que \\(k\\) ; se a entrada \u00e9 a primeira da tabela, ent\u00e3o encaminhe a requisi\u00e7\u00e3o para o n\u00f3 apontado, pois ele \u00e9 o sucessor de \\(k\\) , at\u00e9 onde \\(p\\) consegue determinar; sen\u00e3o, encaminhe a requisi\u00e7\u00e3o para a entrada anterior, pois o n\u00f3 referenciado est\u00e1 mais pr\u00f3ximo do sucessor para determin\u00e1-lo com seguran\u00e7a. Considere no exemplo a seguir a busca pelo sucessor de 26, iniciada pelo n\u00f3 1. Duas observa\u00e7\u00f5es s\u00e3o importantes aqui. A primeira, \u00e9 que as compara\u00e7\u00f5es para se encontrar a entrada correta, deve respeitar o anel, por exemplo, em um anel com 32 posi\u00e7\u00f5es, por exemplo, \\(31 < 0\\) . No seguinte exemplo, considere por exemplo a busca que o n\u00f3 21 faz pelo sucessor de 31; qual deve ser a entrada selecionada? A segunda observa\u00e7\u00e3o \u00e9 que n\u00e3o se pode encaminhar a requisi\u00e7\u00e3o diretamente para o n\u00f3 apontado na entrada encontrada, pois a vis\u00e3o de \\(p\\) pode ser incompleta para partes distantes do anel. Tente identificar exemplos no anel a seguir onde este comportamento seria errado. A organiza\u00e7\u00e3o dos n\u00f3s em um anel virtual e a distribui\u00e7\u00e3o da responsabilidade dos dados pelo particionamento do espa\u00e7o das chaves de forma correspondente \u00e0s faixas no anel l\u00f3gico \u00e9 a t\u00e9cnica conhecida como espalhamento consistente , do ingl\u00eas, consistent hashing . Churn Apesar do espalhamento consistente ser uma t\u00e9cnica muito \u00fatil, ela n\u00e3o resolve todos os problemas. Ali\u00e1s, v\u00e1rios outros problemas precisam ser resolvidos, sendo o primeiro deles lidar com a entrada e sa\u00edda de n\u00f3s, principalmente por falhas de n\u00f3s e comunica\u00e7\u00e3o. Quando um novo n\u00f3 entra do sistema, ele precisa seguir os seguintes passos: Escolher um novo Identificador \\(I\\) Identificar o sucessor \\(S\\) de \\(I\\) Identificar o antecessor \\(A\\) de \\(I\\) Informar \\(A\\) e \\(S\\) de sua entrada, para que ajustem suas tabelas de rota. \\(A\\) e \\(S\\) propagam a informa\u00e7\u00e3o da entrada de \\(I\\) para seus vizinhos, permitindo que ajustem suas tabelas de rota. Al\u00e9m disto, a reorganiza\u00e7\u00e3o dos n\u00f3s exige movimenta\u00e7\u00e3o de dados, pois parte dos dados armazenados em \\(S\\) , com chaves menores que \\(I\\) , precisam ser copiadas para \\(I\\) , o novo respons\u00e1vel. As principais quest\u00f5es a serem respondidas durante a movimenta\u00e7\u00e3o dos dados s\u00e3o como manter os dados dispon\u00edveis para inser\u00e7\u00e3o e consulta durante todo o processo, e como minimizar o impacto da reorganiza\u00e7\u00e3o nos n\u00f3s vizinhos ao novo n\u00f3 Quanto \u00e0 primeira quest\u00e3o, pode-se rotear as requisi\u00e7\u00f5es para os dois n\u00f3s respons\u00e1veis, o atual e o novo, e combinar as respostas, mantendo os dados mais recentes. Quanto \u00e0 segunda, uma op\u00e7\u00e3o \u00e9 fazer com que cada novo n\u00f3 assuma diversas posi\u00e7\u00f5es no anel, com identificadores distintos, passando a \"incomodar\" m\u00faltiplos processos, mas de forma mais suave. Embora se possa \"facilmente\" resolver os problemas da entrada de n\u00f3s, os da sa\u00edda s\u00e3o mais complexos, principalmente porqu\u00ea a sa\u00edda acontece geralmente bruscamente, por exemplo por falhas no sistema. Quanto \u00e0 reorganiza\u00e7\u00e3o das tabelas de rota, cada n\u00f3 precisa monitorar os n\u00f3s que figuram em sua tabela e, caso pare\u00e7am indispon\u00edveis, ajustar par apontar para outro n\u00f3. Contudo, caso a suspeita seja indevida, isto pode levar a dados serem consultados e armazenados nos n\u00f3s errados. Tamb\u00e9m com rela\u00e7\u00e3o aos dados, h\u00e1 o problema de n\u00e3o perd\u00ea-los quando o n\u00f3 respons\u00e1vel se torna indispon\u00edvel. O tratamento destes problemas est\u00e1 relacionado e \u00e9 feito pelo replica\u00e7\u00e3o dos dados em m\u00faltiplos n\u00f3s. Isto \u00e9 feito no Chord, por exemplo, da seguinte forma: para cada dado, com chave \\(k\\) , h\u00e1 \\(r\\) c\u00f3pias; a primeira c\u00f3pia \u00e9 mantida no sucessor de \\(k\\) ; a segunda c\u00f3pia, no sucessor do sucessor de \\(k\\) , e assim por diante; cada escrita \u00e9 feita na primeira c\u00f3pia, respondida, e replicada para as demais c\u00f3pias; cada leitura \u00e9 feita na c\u00f3pia com menor identificador. No caso de falha de uma c\u00f3pia, h\u00e1 \\(r-1\\) c\u00f3pias ainda dispon\u00edveis para responder \u00e0 requisi\u00e7\u00e3o, mantendo o sistema dispon\u00edvel a despeito de ( \\(r-1\\) ) falhas, no que se chama de degrada\u00e7\u00e3o graciosa . H\u00e1 contudo, um problema introduzido por esta abordagem. Assuma a seguinte sequ\u00eancia de passos, em um sistema com \\(r=2\\) . escrita na c\u00f3pia 1; resposta ao cliente; replica\u00e7\u00e3o para c\u00f3pia 2; escrita na c\u00f3pia 1; resposta ao cliente; falha da c\u00f3pia 1; leitura na c\u00f3pia 2. O cliente, ao ler o dado, l\u00ea uma vers\u00e3o antiga do mesmo, inconsistente com a vis\u00e3o que tinha do sistema. De fato, este tipo de sistema \u00e9 chamado de eventualmente consistente pois somente na aus\u00eancia de falhas e de escritas as diversas r\u00e9plicas ser\u00e3o consistentes umas com as outras. Continuemos a sequ\u00eancia: escrita na c\u00f3pia 2; c\u00f3pia 1 volta a funcionar; leitura na c\u00f3pia 1. Neste caso, a c\u00f3pia \"secund\u00e1ria\" 2 tem um dado mais atual, que precisa ser repassado para a c\u00f3pia 1; este movimento de converg\u00eancia de dados \u00e9 conhecido como anti-entropia. Finalmente, continuemos a sequ\u00eancia: escrita na c\u00f3pia 1, por outro cliente. Assim, ambas as c\u00f3pias, 1 e 2, tem dados derivados da primeira escrita, mas feitos \"concorrentemente\", um conflito . Qual dos dois \u00e9 o correto neste contexto? \u00c9 imposs\u00edvel apresentar uma estrat\u00e9gia gen\u00e9rica para resolver esta situa\u00e7\u00e3o, mas alguns sistemas usar\u00e3o uma estrat\u00e9gia do tipo \"a \u00faltima escrita vence\", onde a \u00faltima escrita pode ser determinada em por rel\u00f3gios l\u00f3gicos, vetoriais, tempo, e uma pitada de \"arranjo t\u00e9cnico\" para quebrar empates. O Dynamo, que veremos a seguir, \u00e9 um destes sistemas. Espalhamento Consistente Carga uniforme entre n\u00f3s. Todos os n\u00f3s sabem como rotear requisi\u00e7\u00f5es N\u00famero de saltos m\u00e9dio \u00e9 conhecido. O sistema se adapta a entrada e sa\u00edda de n\u00f3s, por falhas ou n\u00e3o. Observe que as dist\u00e2ncias entre os n\u00f3s no anel foram desenhadas de forma proporcional \u00e0 diferen\u00e7a num\u00e9rica entre os identificadores. \u21a9","title":"Chord"},{"location":"cases/chord/#p2p-chord","text":"Chord \u00e9 uma sistema P2P de m\u00faltiplas aplica\u00e7\u00f5es desenvolvido pelos membros do CSAIL , do MIT, e publicado em 2001. Desde ent\u00e3o, inspirou diversos outros sistemas, tornando-se sin\u00f4nimo com P2P. Neste sistema, n\u00f3s organizam-se em um anel l\u00f3gico e cada um torna-se respons\u00e1vel por um dos segmentos do anel adjacente a onde se encontra no mesmo. Requisi\u00e7\u00f5es para correspondentes a um segmento s\u00e3o roteados para o n\u00f3 respons\u00e1vel usando uma tabela de rotas conhecida como finger table . Se tra\u00e7armos os caminhos apontados por esta tabela sobre o anel, desenharemos cordas sobre o mesmo, o que explica o nome do sistema.","title":"P2P: Chord"},{"location":"cases/chord/#identificacao","text":"No Chord o problema da identifica\u00e7\u00e3o dos dados \u00e9 resolvido usando-se chaves de \\(m\\) bits , geradas por meio de uma fun\u00e7\u00e3o hash criptogr\u00e1fica a partir de chaves que fa\u00e7a sentido para a aplica\u00e7\u00e3o, por exemplo nome, telefone, ou CPF. Como a fun\u00e7\u00e3o hash \u00e9 criptogr\u00e1fica, uma pequena varia\u00e7\u00e3o na entrada implica em grande varia\u00e7\u00e3o na sa\u00edda e, para quem observa apenas a sa\u00edda da fun\u00e7\u00e3o, uma sequ\u00eancia de chaves \u00e9 indistingu\u00edvel de uma sequ\u00eancia aleat\u00f3ria.","title":"Identifica\u00e7\u00e3o"},{"location":"cases/chord/#divisao-de-carga","text":"A cada n\u00f3 \u00e9 atribu\u00eddo um identificador \u00fanico de \\(m\\) bits , gerado aleatoriamente. Como \\(m\\) normalmente \u00e9 grande, com mais de uma centena de bits, a probabilidade de dois n\u00f3s terem o mesmo identificar \u00e9 desprez\u00edvel. Al\u00e9m disso, os n\u00f3s se organizam em uma rede sobreposta estruturada na forma de um anel l\u00f3gico , em que os n\u00f3s aparecem ordenadamente de acordo com seus identificadores. A figura a seguir mostra um anel em cujo os n\u00f3s tem identificadores de 8 bits (0 a 255), com cinco n\u00f3s. 1 Assumamos inicialmente que os n\u00f3s s\u00f3 est\u00e3o cientes dos seus vizinhos imediatos no anel. Cada chave \u00e9 associada a um n\u00f3, respons\u00e1vel por atender requisi\u00e7\u00f5es de cria\u00e7\u00e3o, consulta, modifica\u00e7\u00e3o e remo\u00e7\u00e3o dos dados relacionados \u00e0quela chave. A pseudo aleatoriedade na gera\u00e7\u00e3o da chave e a aleatoriedade na gera\u00e7\u00e3o dos identificadores de n\u00f3s faz com que a distribui\u00e7\u00e3o de carga entre os n\u00f3s seja uniforme. O dado com chave \\(k\\) \u00e9 responsabilidade do n\u00f3 com menor identificador \\(i \\geq k\\) , aka, sucessor de \\(k\\) ( \\(i = suc(k)\\) ), no anel. Na figura a seguir, \u00e9 apresentado junto a cada n\u00f3 as chaves pelas quais o n\u00f3 \u00e9 respons\u00e1vel.","title":"Divis\u00e3o de carga"},{"location":"cases/chord/#roteamento","text":"Suponha que um cliente solicite ao Chord do exemplo anterior que armazene o valor \\(v\\) associado \u00e0 chave \\(k\\) . A solicita\u00e7\u00e3o \u00e9 feita pelo contato a um dos n\u00f3s no sistema, que pode ou n\u00e3o ser o respons\u00e1vel por \\(k\\) . Caso seja o respons\u00e1vel, a solicita\u00e7\u00e3o \u00e9 executada localmente e uma resposta devolvida ao cliente. Caso contr\u00e1rio, a requisi\u00e7\u00e3o deve repassada ou roteada para o n\u00f3 correto. Na rede estruturada definida at\u00e9 agora, uma op\u00e7\u00e3o \u00f3bvia \u00e9 repassar a requisi\u00e7\u00e3o para um dos vizinhos e assim sucessivamente at\u00e9 que alcance o n\u00f3 correto. Esta solu\u00e7\u00e3o, correta, tem custo da ordem do n\u00famero de n\u00f3s no sistema, \\(O(n)\\) . Em uma inst\u00e2ncia com milhares de n\u00f3s, \\(O(n)\\) \u00e9 um custo muito alto, ainda mais se considerarmos que cada salto na rede sobreposta potencialmente cruza toda a Internet, uma vez que, refor\u00e7ando, a proximidade na rede sobreposta n\u00e3o implica em proximidade na rede f\u00edsica abaixo. Observe que o custo em termos de espa\u00e7o para se implementar esta solu\u00e7\u00e3o \u00e9 \\(O(1)\\) para cada n\u00f3 do sistema. Em outras palavras, cada n\u00f3 mantem uma tabela de rotas com uma ou duas entradas, apontando para seus vizinhos. Com uma rede com milhares de n\u00f3s, uma solu\u00e7\u00e3o \\(O(n)\\) saltos, onde cada pode levar ao outro lado do planeta , opera\u00e7\u00f5es teriam uma lat\u00eancia muito alta. Para amenizar o custo, Chord prop\u00f5e a cria\u00e7\u00e3o de uma tabela de rotas, tamb\u00e9m conhecida como finger-table , que aponta para n\u00f3s no anel com dist\u00e2ncias que se dobram a cada entrada. A finger-table \u00e9 constru\u00edda da seguinte forma, onde \\(m\\) \u00e9 a quantidade de bits usados para identificar n\u00f3s no sistema: seja \\(F_p\\) a finger-table do processo \\(p\\) ; seja \\(F_p[i]\\) a \\(i\\) -\u00e9sima da tabela; e, \\(F_p[i] = suc(p+2^{i-1})\\) . Observe que nesta tabela, a \\(i\\) -\u00e9sima entrada aponta para o processo que no que sucede \\(p\\) pelo menos \\(2^{i-1}\\) , e que esta dist\u00e2ncia de sucess\u00e3o aumenta exponencialmente. Observe tamb\u00e9m que a maior dist\u00e2ncia \u00e9 proporcional a metade do tamanho do anel. Isto quer dizer que o \u00faltimo finger da tabela proporciona um salto de \\(1/2\\) anel, o pen\u00faltimo \\(1/4\\) do anel, o ante-pen\u00faltimo \\(1/8\\) , e assim sucessivamente. Outra forma de se ver esta tabela \u00e9 como proporcionando um salto de pelo menos metade da dist\u00e2ncia restante para o n\u00f3 respons\u00e1vel pela chave, resultando em um roteamento com custo \\(O(log n)\\) . Mas como este potencial \u00e9 explorado? Usando-se o seguinte algoritmo de busca pela entrada correta na tabela de roteamento, do ponto de vista do processo \\(p\\) : seja \\(k\\) a chave para qual estamos procurando o sucessor; itere pela tabela at\u00e9 achar a primeira entrada cujo valor, i.e., o identificador de um n\u00f3, \u00e9 maior que \\(k\\) ; se a entrada \u00e9 a primeira da tabela, ent\u00e3o encaminhe a requisi\u00e7\u00e3o para o n\u00f3 apontado, pois ele \u00e9 o sucessor de \\(k\\) , at\u00e9 onde \\(p\\) consegue determinar; sen\u00e3o, encaminhe a requisi\u00e7\u00e3o para a entrada anterior, pois o n\u00f3 referenciado est\u00e1 mais pr\u00f3ximo do sucessor para determin\u00e1-lo com seguran\u00e7a. Considere no exemplo a seguir a busca pelo sucessor de 26, iniciada pelo n\u00f3 1. Duas observa\u00e7\u00f5es s\u00e3o importantes aqui. A primeira, \u00e9 que as compara\u00e7\u00f5es para se encontrar a entrada correta, deve respeitar o anel, por exemplo, em um anel com 32 posi\u00e7\u00f5es, por exemplo, \\(31 < 0\\) . No seguinte exemplo, considere por exemplo a busca que o n\u00f3 21 faz pelo sucessor de 31; qual deve ser a entrada selecionada? A segunda observa\u00e7\u00e3o \u00e9 que n\u00e3o se pode encaminhar a requisi\u00e7\u00e3o diretamente para o n\u00f3 apontado na entrada encontrada, pois a vis\u00e3o de \\(p\\) pode ser incompleta para partes distantes do anel. Tente identificar exemplos no anel a seguir onde este comportamento seria errado. A organiza\u00e7\u00e3o dos n\u00f3s em um anel virtual e a distribui\u00e7\u00e3o da responsabilidade dos dados pelo particionamento do espa\u00e7o das chaves de forma correspondente \u00e0s faixas no anel l\u00f3gico \u00e9 a t\u00e9cnica conhecida como espalhamento consistente , do ingl\u00eas, consistent hashing .","title":"Roteamento"},{"location":"cases/chord/#churn","text":"Apesar do espalhamento consistente ser uma t\u00e9cnica muito \u00fatil, ela n\u00e3o resolve todos os problemas. Ali\u00e1s, v\u00e1rios outros problemas precisam ser resolvidos, sendo o primeiro deles lidar com a entrada e sa\u00edda de n\u00f3s, principalmente por falhas de n\u00f3s e comunica\u00e7\u00e3o. Quando um novo n\u00f3 entra do sistema, ele precisa seguir os seguintes passos: Escolher um novo Identificador \\(I\\) Identificar o sucessor \\(S\\) de \\(I\\) Identificar o antecessor \\(A\\) de \\(I\\) Informar \\(A\\) e \\(S\\) de sua entrada, para que ajustem suas tabelas de rota. \\(A\\) e \\(S\\) propagam a informa\u00e7\u00e3o da entrada de \\(I\\) para seus vizinhos, permitindo que ajustem suas tabelas de rota. Al\u00e9m disto, a reorganiza\u00e7\u00e3o dos n\u00f3s exige movimenta\u00e7\u00e3o de dados, pois parte dos dados armazenados em \\(S\\) , com chaves menores que \\(I\\) , precisam ser copiadas para \\(I\\) , o novo respons\u00e1vel. As principais quest\u00f5es a serem respondidas durante a movimenta\u00e7\u00e3o dos dados s\u00e3o como manter os dados dispon\u00edveis para inser\u00e7\u00e3o e consulta durante todo o processo, e como minimizar o impacto da reorganiza\u00e7\u00e3o nos n\u00f3s vizinhos ao novo n\u00f3 Quanto \u00e0 primeira quest\u00e3o, pode-se rotear as requisi\u00e7\u00f5es para os dois n\u00f3s respons\u00e1veis, o atual e o novo, e combinar as respostas, mantendo os dados mais recentes. Quanto \u00e0 segunda, uma op\u00e7\u00e3o \u00e9 fazer com que cada novo n\u00f3 assuma diversas posi\u00e7\u00f5es no anel, com identificadores distintos, passando a \"incomodar\" m\u00faltiplos processos, mas de forma mais suave. Embora se possa \"facilmente\" resolver os problemas da entrada de n\u00f3s, os da sa\u00edda s\u00e3o mais complexos, principalmente porqu\u00ea a sa\u00edda acontece geralmente bruscamente, por exemplo por falhas no sistema. Quanto \u00e0 reorganiza\u00e7\u00e3o das tabelas de rota, cada n\u00f3 precisa monitorar os n\u00f3s que figuram em sua tabela e, caso pare\u00e7am indispon\u00edveis, ajustar par apontar para outro n\u00f3. Contudo, caso a suspeita seja indevida, isto pode levar a dados serem consultados e armazenados nos n\u00f3s errados. Tamb\u00e9m com rela\u00e7\u00e3o aos dados, h\u00e1 o problema de n\u00e3o perd\u00ea-los quando o n\u00f3 respons\u00e1vel se torna indispon\u00edvel. O tratamento destes problemas est\u00e1 relacionado e \u00e9 feito pelo replica\u00e7\u00e3o dos dados em m\u00faltiplos n\u00f3s. Isto \u00e9 feito no Chord, por exemplo, da seguinte forma: para cada dado, com chave \\(k\\) , h\u00e1 \\(r\\) c\u00f3pias; a primeira c\u00f3pia \u00e9 mantida no sucessor de \\(k\\) ; a segunda c\u00f3pia, no sucessor do sucessor de \\(k\\) , e assim por diante; cada escrita \u00e9 feita na primeira c\u00f3pia, respondida, e replicada para as demais c\u00f3pias; cada leitura \u00e9 feita na c\u00f3pia com menor identificador. No caso de falha de uma c\u00f3pia, h\u00e1 \\(r-1\\) c\u00f3pias ainda dispon\u00edveis para responder \u00e0 requisi\u00e7\u00e3o, mantendo o sistema dispon\u00edvel a despeito de ( \\(r-1\\) ) falhas, no que se chama de degrada\u00e7\u00e3o graciosa . H\u00e1 contudo, um problema introduzido por esta abordagem. Assuma a seguinte sequ\u00eancia de passos, em um sistema com \\(r=2\\) . escrita na c\u00f3pia 1; resposta ao cliente; replica\u00e7\u00e3o para c\u00f3pia 2; escrita na c\u00f3pia 1; resposta ao cliente; falha da c\u00f3pia 1; leitura na c\u00f3pia 2. O cliente, ao ler o dado, l\u00ea uma vers\u00e3o antiga do mesmo, inconsistente com a vis\u00e3o que tinha do sistema. De fato, este tipo de sistema \u00e9 chamado de eventualmente consistente pois somente na aus\u00eancia de falhas e de escritas as diversas r\u00e9plicas ser\u00e3o consistentes umas com as outras. Continuemos a sequ\u00eancia: escrita na c\u00f3pia 2; c\u00f3pia 1 volta a funcionar; leitura na c\u00f3pia 1. Neste caso, a c\u00f3pia \"secund\u00e1ria\" 2 tem um dado mais atual, que precisa ser repassado para a c\u00f3pia 1; este movimento de converg\u00eancia de dados \u00e9 conhecido como anti-entropia. Finalmente, continuemos a sequ\u00eancia: escrita na c\u00f3pia 1, por outro cliente. Assim, ambas as c\u00f3pias, 1 e 2, tem dados derivados da primeira escrita, mas feitos \"concorrentemente\", um conflito . Qual dos dois \u00e9 o correto neste contexto? \u00c9 imposs\u00edvel apresentar uma estrat\u00e9gia gen\u00e9rica para resolver esta situa\u00e7\u00e3o, mas alguns sistemas usar\u00e3o uma estrat\u00e9gia do tipo \"a \u00faltima escrita vence\", onde a \u00faltima escrita pode ser determinada em por rel\u00f3gios l\u00f3gicos, vetoriais, tempo, e uma pitada de \"arranjo t\u00e9cnico\" para quebrar empates. O Dynamo, que veremos a seguir, \u00e9 um destes sistemas. Espalhamento Consistente Carga uniforme entre n\u00f3s. Todos os n\u00f3s sabem como rotear requisi\u00e7\u00f5es N\u00famero de saltos m\u00e9dio \u00e9 conhecido. O sistema se adapta a entrada e sa\u00edda de n\u00f3s, por falhas ou n\u00e3o. Observe que as dist\u00e2ncias entre os n\u00f3s no anel foram desenhadas de forma proporcional \u00e0 diferen\u00e7a num\u00e9rica entre os identificadores. \u21a9","title":"Churn"},{"location":"cases/copycat/","text":"Coordena\u00e7\u00e3o: Copycat Copycat \u00e9 um arcabou\u00e7o de replica\u00e7\u00e3o de m\u00e1quinas de estados implementada pela Atomix . Na base do Copycat est\u00e1 uma implementa\u00e7\u00e3o do Raft. Sobre o Raft, uma API simples mas moderna permite a cria\u00e7\u00e3o de m\u00e1quinas de estados usando lambdas , futures , e o estilo fluent de encadeamento de invoca\u00e7\u00f5es. Lambda Classe com um \u00fanico m\u00e9todo. 1 2 3 4 5 6 7 8 class Tarefa implements Runnable { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } } new Thread ( new Tarefa ()). start (); Classe an\u00f4nima - uso \u00fanico 1 2 3 4 5 6 new Thread ( new Runnable () { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } }). start (); Lambda 1 2 3 4 new Thread (() -> { while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); }). start (); Fluent Encadeamento 1 2 3 4 5 Collection < Pessoa > c = ...; c . stream () . filter ( p -> p . idade > 33 ) . map ( Pessoa :: sobrenomeNome ) //.map(p -> p.sobrenomeNome()) . forEach ( s -> System . out . println ( s )); Future Promessa de computa\u00e7\u00e3o e resultado. 1 2 ExecutorService executor = Executors . newSingleThreadExecutor (); Future < Integer > futFib = executor . submit (() -> { return Fibonacci ( 217 )}; Quando ser\u00e1 executado? Em algum momento. Como pegar o resultado? 1 2 3 4 while ( ! futFib . isDone ()) System . out . println ( \"tah calculando...\" ); int fib217 = futFib . get (); Em qual thread? Em algum thread. Depende do Executor Service usado. H\u00e1 v\u00e1rias vers\u00f5es do Copycat dispon\u00edveis, com vantagens e desvantagens. Vers\u00f5es Vers\u00e3o 1.1.4 Baseado em http://atomix.io/copycat/docs/getting-started/ e https://www.baeldung.com/atomix C\u00f3digo funcional em https://github.com/pluxos/atomix_labs Documenta\u00e7\u00e3o oficial removida Vers\u00e3o >= 2 Melhor desempenho Documenta\u00e7\u00e3o ruim ou inexistente https://github.com/atomix/atomix Vers\u00e3o 3 em Go evolu\u00e7\u00e3o r\u00e1pida o c\u00f3digo \u00e9 a documenta\u00e7\u00e3o Aqui usaremos a vers\u00e3o 1.1.4, que apesar de antiga, \u00e9 a melhor documentada atualmente, pelo tutorial referenciado acima. Clone e compile o projeto Instale depend\u00eancias: git maven JDK >= 1.8 git clone https://github.com/pluxos/atomix_labs cd atomix_labs cd replication mvn compile mvn test Voc\u00ea deve ver uma sa\u00edda semelhante \u00e0 seguinte, o que quer dizer que seu c\u00f3digo est\u00e1 compilando perfeitamente. 1 2 3 4 5 6 7 8 9 Tests run: 1 , Failures: 0 , Errors: 0 , Skipped: 0 [ INFO ] --------------------------------------- [ INFO ] BUILD SUCCESS [ INFO ] --------------------------------------- [ INFO ] Total time: 6 .898 s [ INFO ] Finished at: 2017 -10-25T08:38:08-02:00 [ INFO ] Final Memory: 15M/159M [ INFO ] --------------------------------------- Antes de come\u00e7ar a escrever suas pr\u00f3rpia m\u00e1quinas de estado, familiarize-se com a estrutura do projeto em https://github.com/pluxos/atomix_labs/tree/master/replication/src/main/java/atomix_lab/state_machine Observe que h\u00e1 tr\u00eas pastas: type - tipos dos dados mantidos pela replica (Edge e Vertex) Os tipos s\u00e3o serializable para que o Java saiba como transform\u00e1-los em bytes. command - estruturas que cont\u00eam informa\u00e7\u00f5es para modificar os tipos Os comandos ser\u00e3o enviadas do cliente para o cluster e s\u00e3o naturalmente serializable. client - cria comandos e os envia para serem executados no cluster Respostas podem ser esperadas s\u00edncrona ou assincronamente. server - recebe os comandos na ordem definida pelo Raft e os executa O projeto foi constru\u00eddo seguindo as instru\u00e7\u00f5es no tutorial mencionado antes, saltando-se a parte dos snapshots, isto \u00e9: crie um projeto maven eclipse tem template para isso adicione depend\u00eancias no pom.xml como so criei um projeto, coloquei as depend\u00eancias tanto do cliente quando do servidor defina Command que modifiquem o estado das r\u00e9plicas defina Queries que consultem o estado das r\u00e9plicas implemente a r\u00e9plica para lidar com os comandos implemente o cliente para emitir comandos Para executar um servidor, voc\u00ea precisa passar diversos par\u00e2metros identificador do processo (inteiro) IP do processo com identificador 0 porta do processo com identificar 0 IP do processo com identificador 1 porta do processo com identificar 1 ... Sabendo seu identificador, o servidor sabe em qual porta escutar e em quais IP/porta se conectar para se comunicar com os outros servidores. Para testar o projeto, execute tr\u00eas servidores, em tr\u00eas terminais distintos. Usando o maven, da linha de comando, basta executar os seguintes comandos[^\\]: 1 2 3 4 5 6 7 8 9 10 11 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"0 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"1 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"2 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" O cliente n\u00e3o precisa de um identificador, apenas dos pares IP/porta dos servidores. Por exemplo, use o comando: 1 2 3 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.client.GraphClient\" \\\\ -Dexec.args = \"127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" Exerc\u00edcio Uma vez executado o projeto, modifique-o para incluir uma nova opera\u00e7\u00e3o ( Command ) e nova consulta ( Query ), de sua escolha. Estudo de caso: Ratis Ratis \u00e9 um arcabou\u00e7o de coordena\u00e7\u00e3o recentemente emancipado como um projeto no Apache . Embora mal documentado, o projeto tem alguns exemplos que demonstram como usar abstra\u00e7\u00f5es j\u00e1 implementadas. A seguir veremos um passo-a-passo, baseado nestes exemplos, de como usar o Ratis para implementar uma m\u00e1quina de estados replicada. Crie um novo projeto Maven com o nome ChaveValor (eu estou usando IntelliJ, mas as instru\u00e7\u00f5es devem ser semelhantes para Eclipse). Abra o arquivo pom.xml do seu projeto e adicione o seguinte trecho, com as depend\u00eancias do projeto, incluindo o pr\u00f3prio Ratis. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 <dependencies> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-server --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-server </artifactId> <version> 2.0.0 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-netty --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-netty </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-grpc </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> com.beust </groupId> <artifactId> jcommander </artifactId> <version> 1.78 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> 1.7.25 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-slf4j-impl --> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-slf4j-impl </artifactId> <version> 2.14.1 </version> <scope> compile </scope> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-api </artifactId> <version> 2.14.1 </version> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-core </artifactId> <version> 2.14.1 </version> <scope> provided </scope> </dependency> </dependencies> Adicione tamb\u00e9m o plugin Maven e o plugin para gerar um .jar com todas as depend\u00eancias. Observe que estou usando Java 14, mas voc\u00ea pode mudar para a sua vers\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> ${maven.compiler.version} </version> <configuration> <source> 14 </source> <target> 14 </target> </configuration> </plugin> <plugin> <artifactId> maven-assembly-plugin </artifactId> <executions> <execution> <phase> package </phase> <goals> <goal> single </goal> </goals> </execution> </executions> <configuration> <descriptorRefs> <descriptorRef> jar-with-dependencies </descriptorRef> </descriptorRefs> </configuration> </plugin> </plugins> </build> Crie uma nova classe denominada Cliente no arquivo Cliente.java . Nesta classe, iremos criar um objeto RaftClient que ser\u00e1 usado para enviar opera\u00e7\u00f5es para os servidores. Esta classe \u00e9 importada juntamente com outras v\u00e1rias depend\u00eancias, adicionadas no pom.xml , que devemos instanciar antes do RaftClient . Neste exemplo eu coloco praticamente todos os par\u00e2metros de configura\u00e7\u00e3o do Ratis hardcoded para simplificar o c\u00f3digo. Obviamente que voce deveria ser estes par\u00e2metros como argumentos para o programa ou de um arquivo de configura\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.apache.ratis.client.RaftClient ; import org.apache.ratis.conf.Parameters ; import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcFactory ; import org.apache.ratis.protocol.* ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.nio.charset.Charset ; import java.util.HashMap ; import java.util.Map ; public class Cliente { O campo raftGroupId identifica um cluster Ratis; isso quer dizer que um mesmo processo pode participar de v\u00e1rios clusters , mas aqui nos focaremos em apenas um. O valor do campo deve ter exatamente caracteres, o que soma 32 bytes em java, e ser\u00e1 interpretado como um UUID . id2addr \u00e9 um mapa do identificador de cada processo no cluster para seu endere\u00e7o IP + Porta. Aqui usei v\u00e1rias portas distintas porqu\u00ea todos os processos est\u00e3o rodando na mesma m\u00e1quina, mas se estivesse executando em m\u00e1quinas distintas, com IP distintos, poderia usar a mesma porta em todos. addresses \u00e9 uma lista de RaftPeer constru\u00edda a parti de id2addr . O campo raftGroup \u00e9 uma refer\u00eancia a todos os servidores, associados ao identificador do grupo, raftGroupId . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void main ( String args [] ) throws IOException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), addresses ); Uma vez criado o grupo, criamos o cliente usando a f\u00e1brica retornada por RaftClient.newBuilder() . A f\u00e1brica deve ser configurada com os dados do grupo e o tipo de transporte, neste caso gRPC. Tamb\u00e9m \u00e9 necess\u00e1rio o identificador do processo que est\u00e1 se conectando ao grupo; neste caso, usamos um identificador aleat\u00f3rio qualquer, diferente do que faremos com os servidores. 1 2 3 4 5 6 7 8 RaftProperties raftProperties = new RaftProperties (); RaftClient client = RaftClient . newBuilder () . setProperties ( raftProperties ) . setRaftGroup ( raftGroup ) . setClientRpc ( new GrpcFactory ( new Parameters ()) . newRaftClientRpc ( ClientId . randomId (), raftProperties )) . build (); Uma vez criado o cliente, podemos fazer invoca\u00e7\u00f5es de opera\u00e7\u00f5es nos servidores. Cada opera\u00e7\u00e3o ser\u00e1 invocada em todos os servidores, na mesma ordem. Este prot\u00f3tipo suporta duas opera\u00e7\u00f5es, add e get , incluindo algumas varia\u00e7\u00f5es, que ignoraremos por enquanto. A opera\u00e7\u00e3o add \u00e9 codificada como uma String , add:k:v , onde k e v s\u00e3o do tipo String . add:k:v adiciona uma entrada em um mapa implementado pelo nosso servidor com chave k e valor v . J\u00e1 a opera\u00e7\u00e3o get:k recupera o valor v associado \u00e0 chave k , se presente no mapa. O m\u00e9todo RaftClient.io().send \u00e9 usado para enviar modifica\u00e7\u00f5es para as r\u00e9plicas e deve, necessariamente, passar pelo protocolo Raft. J\u00e1 o m\u00e9todo RaftClient.io().sendReadOnly \u00e9 usado para enviar consultas a qualquer das r\u00e9plicas. Ambos os m\u00e9todos codificam o comando sendo enviado ( add:k:v ou get:k ) no formato interno do Ratis para as r\u00e9plicas e retorna um objeto RaftClientReply , que pode ser usado para pegar a resposta da opera\u00e7\u00e3o. O c\u00f3digo \u00e9 auto explicativo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 RaftClientReply getValue ; CompletableFuture < RaftClientReply > compGetValue ; String response ; switch ( args [ 0 ] ){ case \"add\" : getValue = client . io (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"get\" : getValue = client . io (). sendReadOnly ( Message . valueOf ( \"get:\" + args [ 1 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"add_async\" : compGetValue = client . async (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); getValue = compGetValue . get (); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; case \"get_stale\" : getValue = client . io (). sendStaleRead ( Message . valueOf ( \"get:\" + args [ 1 ] ), 0 , RaftPeerId . valueOf ( args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; default : System . out . println ( \"comando inv\u00e1lido\" ); } client . close (); } } Um vez criado o cliente, crie a classe Servidor , no arquivo Servidor.java ; a parte inicial do c\u00f3digo \u00e9 semelhante \u00e0 do cliente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcConfigKeys ; import org.apache.ratis.protocol.RaftGroup ; import org.apache.ratis.protocol.RaftGroupId ; import org.apache.ratis.protocol.RaftPeer ; import org.apache.ratis.protocol.RaftPeerId ; import org.apache.ratis.server.RaftServer ; import org.apache.ratis.server.RaftServerConfigKeys ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import org.apache.ratis.util.LifeCycle ; import java.io.File ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.util.Collections ; import java.util.HashMap ; import java.util.Map ; import java.util.concurrent.TimeUnit ; public class Servidor { //Parametros: myId public static void main ( String args [] ) throws IOException , InterruptedException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. //Setup for node all nodes. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); A primeira diferen\u00e7a vem na necessidade de identificar o servidor dentro do conjunto de servidores, o que \u00e9 feito com um RaftPeerId . Como cada servidor deve usar um identificador \u00fanico, do conjunto pr\u00e9-determinado em id2addr , o identificador \u00e9 passado como argumento para o programa, obrigatoriamente. 1 2 3 4 5 6 7 8 //Setup for this node. RaftPeerId myId = RaftPeerId . valueOf ( args [ 0 ] ); if ( addresses . stream (). noneMatch ( p -> p . getId (). equals ( myId ))) { System . out . println ( \"Identificador \" + args [ 0 ] + \" \u00e9 inv\u00e1lido.\" ); System . exit ( 1 ); } Encare a se\u00e7\u00e3o seguinte como uma receita, mas observe que o m\u00e9todo RaftServerConfigKeys.setStorageDir recebe o nome de uma pasta como argumento, que ser\u00e1 usada para armazenar o estado da m\u00e1quina de estados. Se voc\u00ea executar o servidor m\u00faltiplas vezes, a cada nova execu\u00e7\u00e3o o estado anterior do sistema ser\u00e1 recuperado desta pasta. Para limpar o estado, apague as pastas de cada servidor. 1 2 3 4 RaftProperties properties = new RaftProperties (); properties . setInt ( GrpcConfigKeys . OutputStream . RETRY_TIMES_KEY , Integer . MAX_VALUE ); GrpcConfigKeys . Server . setPort ( properties , 1000 ); RaftServerConfigKeys . setStorageDir ( properties , Collections . singletonList ( new File ( \"/tmp/\" + myId ))); A m\u00e1quina de estados em si \u00e9 especificada no pr\u00f3ximo excerto, em setStateMachine , que veremos a seguir. 1 2 3 4 5 6 7 8 9 //Join the group of processes. final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), id2addr ); RaftServer raftServer = RaftServer . newBuilder () . setServerId ( myId ) . setStateMachine ( new MaquinaDeEstados ()) . setProperties ( properties ) . setGroup ( raftGroup ) . build (); raftServer . start (); Uma vez iniciado o servidor, basta esperar que ele termine antes de sair do programa. 1 2 3 4 5 while ( raftServer . getLifeCycleState () != LifeCycle . State . CLOSED ) { TimeUnit . SECONDS . sleep ( 1 ); } } } Vamos agora para a defini\u00e7\u00e3o da classe MaquinaDeEstados , no arquivo MaquinaDeEstados.java . Esta classe deve implementar a interface org.apache.ratis.statemachine.StateMachine e seus v\u00e1rios m\u00e9todos ou, mais simples, estende org.apache.ratis.statemachine.impl.BaseStateMachine , a abordagem que usaremos aqui. 1 2 public class MaquinaDeEstados extends BaseStateMachine { Por enquanto, ignoraremos o armazenamento do estado em disco, mantendo-o simplesmente em mem\u00f3ria no campo key2values , e simplesmente implementaremos o processamento de comandos, come\u00e7ando pela implementa\u00e7\u00e3o do m\u00e9todo query . Este m\u00e9todo \u00e9 repons\u00e1vel por implementar opera\u00e7\u00f5es que n\u00e3o alteram o estado da m\u00e1quina de estados, enviadas com o m\u00e9todo RaftClient::sendReadOnly . A \u00fanica query no nosso sistema \u00e9 o get . No c\u00f3digo, o conte\u00fado da requisi\u00e7\u00e3o enviada pelo cliente deve ser recuperado em quebrado em opera\u00e7\u00e3o ( get ) e chave , usando : como delimitador. Recuperado o valor associado \u00e0 chave, o mesmo \u00e9 colocado em um CompletableFuture e retornado. 1 2 3 4 5 6 7 8 9 10 private final Map < String , String > key2values = new ConcurrentHashMap <> (); @Override public CompletableFuture < Message > query ( Message request ) { final String [] opKey = request . getContent (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKey [ 0 ]+ \":\" + key2values . get ( opKey [ 1 ] ); LOG . debug ( \"{}: {} = {}\" , opKey [ 0 ] , opKey [ 1 ] , result ); return CompletableFuture . completedFuture ( Message . valueOf ( result )); } O m\u00e9todo applyTransaction implementa opera\u00e7\u00f5es que alteram o estado, como add , enviadas com o m\u00e9todo RaftClient::send . Da mesma forma que em get , a opera\u00e7\u00e3o deve ser recuperada em quebrada em opera\u00e7\u00e3o ( add ), chave e valor, usando : como delimitador. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableFuture < Message > applyTransaction ( TransactionContext trx ) { final RaftProtos . LogEntryProto entry = trx . getLogEntry (); final String [] opKeyValue = entry . getStateMachineLogEntry (). getLogData (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKeyValue [ 0 ]+ \":\" + key2values . put ( opKeyValue [ 1 ] , opKeyValue [ 2 ] ); final CompletableFuture < Message > f = CompletableFuture . completedFuture ( Message . valueOf ( result )); final RaftProtos . RaftPeerRole role = trx . getServerRole (); LOG . info ( \"{}:{} {} {}={}\" , role , getId (), opKeyValue [ 0 ] , opKeyValue [ 1 ] , opKeyValue [ 2 ] ); return f ; } Pronto, voc\u00ea j\u00e1 tem uma m\u00e1quina de estados replicada, bastando agora apenas compil\u00e1-la e execut\u00e1-la. Para compilar, de raiz do projeto execute o comando mvn package . A primeira vez que faz isso pode demorar um pouco pois v\u00e1rias depend\u00eancias s\u00e3o baixadas da Internet. Ao final da execu\u00e7\u00e3o do comando voc\u00ea deveria ver algo semelhante ao seguinte 1 2 3 4 5 6 7 ... INFO ] ------------------------------------------------------------------------ [ INFO ] BUILD SUCCESS [ INFO ] ------------------------------------------------------------------------ [ INFO ] Total time: 4 .793 s [ INFO ] Finished at: 2020 -12-06T23:06:32-03:00 [ INFO ] ------------------------------------------------------------------------ Ent\u00e3o, em tr\u00eas terminais diferentes, execute os seguintes comandos: 1 2 3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p2 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p3 Para executar o cliente, em um outro terminal, fa\u00e7a, por exemplo, 1 2 3 4 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k1 testek1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get k1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k2 testek2 Todo o c\u00f3digo est\u00e1 dispon\u00edvel no Github Exerc\u00edcio Adicionar opera\u00e7\u00f5es del clear Opera\u00e7\u00f5es ass\u00edncronas TODO Opera\u00e7\u00f5es ass\u00edncronas usando async() em vez de io() . CompletableFuture Leituras \"velhas\" TODO stale reads usando sendStaleRead em vez de sendRead . \u00edndice inicial n\u00f3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get_stale k1 p1 Estudo de caso: Zookeeper O Zookeeper foi criado para coordenar as a\u00e7\u00f5es dos componentes de sistemas distribu\u00eddos, porqu\u00ea sistemas distribu\u00eddos s\u00e3o como zool\u00f3gicos, com animais de diversas esp\u00e9cies, sendo obrigados a conviver de forma anti-natural. Vis\u00e3o Geral O qu\u00ea? ZooKeeper is a centralized service for maintaining configuration information, naming , providing distributed synchronization , and providing group services . All of these kinds of services are used in some form or another by distributed applications . Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them, which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed. O arcabou\u00e7o foi criado pelo Yahoo! para servir como pe\u00e7a na constru\u00e7\u00e3o de sistemas distribu\u00eddos dentro da empresa. Por qu\u00ea? Coordination services are notoriously hard to get right. They are especially prone to errors such as race conditions and deadlock. The motivation behind ZooKeeper is to relieve distributed applications the responsibility of implementing coordination services from scratch. Mais tarde o sistema tornou-se Open Source e parte de diversos projetos, tanto abertos quanto propriet\u00e1rios. A raz\u00e3o de seu sucesso, arrisco dizer, \u00e9 a simplicidade de sua API, semelhante a um sistema de arquivos. Como? [ZooKeeper] exposes a simple set of primitives that distributed applications can build upon to implement higher level services for synchronization, configuration maintenance, and groups and naming. It is designed to be easy to program to, and uses a data model styled after the familiar directory tree structure of file systems . It runs in Java and has bindings for both Java and C . ZooKeeper allows distributed processes to coordinate with each other through a shared hierarchal namespace which is organized similarly to a standard file system . ... Unlike a typical file system, which is designed for storage, ZooKeeper data is kept in-memory , which means ZooKeeper can achieve high throughput and low latency numbers. O sistema de arquivos do Zookeeper tem n\u00f3s denominados znodes , em refer\u00eancia aos i-nodes do mundo Unix. O znode raiz \u00e9 denominado / e um filho da raiz nomeado teste \u00e9 referido como /teste . Cada znode pode ser visto como arquivo e diret\u00f3rio ao mesmo tempo. Znodes s\u00e3o manipulados, essencialmente, por 4 opera\u00e7\u00f5es, implementando CRUD, e uma quinta opera\u00e7\u00e3o que lista os znodes filhos de um dado znode. C: create R: get U: set D: delete ls *: get children Znodes s\u00e3o lidos e escritos sempre integralmente. Isto \u00e9, n\u00e3o se pode escrever apenas parte do conte\u00fado do \"arquivo\". Por isso, recomenda-se que os arquivos sejam sempre pequenos, onde pequeno \u00e9 relativo. O sistema de arquivos do Zookeeper \u00e9 replicado em v\u00e1rios n\u00f3s, usando a t\u00e9cnica de replica\u00e7\u00e3o de m\u00e1quinas de estados estudada. A difus\u00e3o ordenada de comandos \u00e9 implementadas O protocolo utilizado \u00e9 pelo protocolo de difus\u00e3o at\u00f4mica pr\u00f3prio do Zookeeper, ZAB ( Zookeeper Atomic Broadcast ). Comandos de modifica\u00e7\u00e3o do sistema de arquivos, como create e delete , podem ser enviados para qualquer das r\u00e9plicas, mas ser\u00e3o internamente encaminhados para um processos l\u00edder e de l\u00e1 replicados. J\u00e1 comandos de leitura s\u00e3o executados direto na r\u00e9plica que os recebe, sendo respondidos mais rapidamente mas que, devido \u00e0 assincronia do sistema, podem ser respondidos com dados antigos. Por este motivo, clientes sempre conversam com o mesmo servidor, a n\u00e3o ser que sejam for\u00e7ados a estabelecer nova conex\u00e3o, e s\u00f3 emitem novos comandos depois que o anterior tiver sido respondido. Este comportamento resulta em garantias de consist\u00eancia espec\u00edficas, denominadas consist\u00eancia sequencial ordenada . Por causa do custo em termos de mensagens trocadas entre os processos para mensagens de atualiza\u00e7\u00e3o e pelo baixo custo das mensagens de leitura, o zookeeper \u00e9 recomendado para cargas de trabalho com poucas escritas. Desempenho ZooKeeper is fast [...] and it performs best where reads are more common than writes, at ratios of around 10:1. O gr\u00e1fico seguinte mostra como o desempenho do sistema varia com o n\u00famero de processos. No eixo Y, a quantidade de requisi\u00e7\u00f5es processadas por segundo, ou seja, a vaz\u00e3o. No eixo X, a percentagem das requisi\u00e7\u00f5es do teste que s\u00e3o leituras e, portanto, repondidas na r\u00e9plica em que s\u00e3o recebidas. As diferentes curvas mostram diferentes configura\u00e7\u00f5es do sistema, indo de 3 a 12 r\u00e9plicas. Em geral, todas as configura\u00e7\u00f5es apresentam melhor desempenho quando h\u00e1 uma percentagem maior de leituras. Mas observe como as curvas se invertem, se focando primeiro na curva para 3 servidores: quando todas as opera\u00e7\u00f5es s\u00e3o de escrita, e portanto precisam passar pelo protocolo de difus\u00e3o at\u00f4mica, esta curva apresenta os melhores resultados. Isto ocorre porqu\u00ea o overhead de executar o protocolo \u00e9 mais baixo entre 3 servidores que entre 13. Em compensa\u00e7\u00e3o, quando temos mais leituras, que n\u00e3o precisam de sincroniza\u00e7\u00e3o, ent\u00e3o ter mais servidores \u00e9 mais vantajoso pois sobre menos carga de trabalho para cada servidor. Laborat\u00f3rio Instale o Zookeeper em sua m\u00e1quina seguindo estas instru\u00e7\u00f5es. Baixe: wget www-eu.apache.org/dist/zookeeper/zookeeper-3.6.2 Descomprima: tar xvzf zookeeper*.tgz Entre na pasta criada. Configure: copie o arquivo conf/zoo_sample.cfg para conf/zoo.cfg Execute ./bin/zkServer.sh start-foreground em um terminal ./bin/zkCli.sh -server 127.0.0.1:2181 em outro terminal Do shell do programa cliente (executado por \u00faltimo), digite help e enter para ver uma lista de todos os comandos dispon\u00edveis. Vejamos alguns exemplos b\u00e1sicos. ls / - lista os n\u00f3s filhos da raiz. create /teste lala - cria o n\u00f3 /teste com conte\u00fado lala get /teste - pega o conte\u00fado do arquivo set /teste lele - atualiza o conte\u00fado do arquivo delete /teste - apaga o arquivo Outros comandos interessantes s\u00e3o: stat /teste - mostra medatados do arquivo, por exemplo vers\u00e3o, e timestamps set -v V /teste lili - faz um update condiciona, isto \u00e9, atualiza o conte\u00fado do arquivo se a vers\u00e3o do mesmo, como mostrada pelo comando stat , for igual a V N\u00f3s Ef\u00eameros e Watches O Zookeeper tem muitas funcionalidades interessantes, mas chamarei a aten\u00e7\u00e3o a duas que s\u00e3o particularmente \u00fateis: N\u00f3s ef\u00eameros , criados com a flag -e , p.e., create -ef /teste/noefemero efemero , s\u00e3o automaticamente destru\u00eddos quando o cliente que os criou se desconecta do servidor. E watches avisam ao cliente quando uma opera\u00e7\u00e3o em um certo znode ou em seus filhos acontece. Para ser avisado quando os dados de um n\u00f3 forem alterados, use a op\u00e7\u00e3o -w do get, por exemplo, get -w /teste . Para monitorar altera\u00e7\u00f5es no conjunto de filhos de um n\u00f3, use -w no ls , por exemplo, ls -w /teste . N\u00f3s Ef\u00eameros e Watches Crie um zNode /teste Debaixo de /teste, crie tr\u00eas outros, sequenciais Crie um zNode /teste2 Crie um zNode ef\u00eamero Conecte-se com outro cliente Coloque um watch em /teste2 Desconecte o primeiro cliente Observe o evento gerado no segundo cliente Reconecte o primeiro cliente Cluster tolerante a falhas Observe que voc\u00ea est\u00e1 executando o Zookeeper em apenas um n\u00f3, ou seja, n\u00e3o h\u00e1 toler\u00e2ncia a falhas alguma aqui. Para tolerar falhas, voc\u00ea precisa de um cluster multi-n\u00f3s, mesmo que seja em uma \u00fanica m\u00e1quina. Neste caso, crie tr\u00eas arquivos de configura\u00e7\u00e3o, zoo1.cfg , zoo2.cfg e zoo3.cfg . O arquivo zooX.cfg , onde 1 <= X <= 3 , fica assim: dataDir=/tmp/lasaro/zooX #Substitua o X pelo valor correto server.1=zoo1:2888:3888 server.2=zoo2:2889:3889 server.3=zoo3:2890:3890 clientPort=218X #Substitua o X pelo valor correto Crie diret\u00f3rios e arquivos de identifica\u00e7\u00e3o. mkdir /tmp/lasaro/zooX echo X > /tmp/lasaro/zooX/myid Execute servidores. ./bin/zkServer.sh start conf/zooX.cfg Ainda que tenha tr\u00eas servidores executando em uma mesma m\u00e1quina, seu cluster parar\u00e1 de funcionar se a m\u00e1quina parar de funcionar. O ideal \u00e9 que cada servidor execute em uma m\u00e1quina distinta. Receitas \u00c9 poss\u00edvel resolver diversos problemas encontrados em sistemas distribu\u00eddos usando-se o ZooKeeper, por exemplo, o problema de descoberta de processos. Rendezvous Ponto de encontro de processos. Defina um zNode raiz a ser usado: /rendezvous/app1/ Cada filho de /rendezvous/app1 corresponde a um processo: IP Porta N\u00famero de processadores ... Processo p ao ser iniciado: procura /rendezvous/app1/p se achar, continua se n\u00e3o achar, cria /rendezvous/app1/p lista os filhos de /rendezvous/app1 Como lidar com sa\u00edda de processos? Fa\u00e7a todos os zNodes s\u00e3o ef\u00eameros. Quando um n\u00f3 \u00e9 desconectado, o zNode correspondente ser\u00e1 destru\u00eddo. Como detectar mudan\u00e7as no grupo de processos? Monitore os filhos de /rendezvous/app1 Sempre que receber notifica\u00e7\u00f5es, refa\u00e7a o c\u00e1lculo do membership . Elei\u00e7\u00e3o de L\u00edderes Rendezvous. Fa\u00e7a os zNodes sequenciais. Ordene os zNodes e escolha o primeiro. Monitore o zNode. Se ele sumir, eleja outro l\u00edder. Exclus\u00e3o M\u00fatua Construa uma fila usando n\u00f3s ef\u00eameros e sequenciais. O processo na cabe\u00e7a da fila tem direito de acesso. Em caso de falhas, o processo \u00e9 removido da cabe\u00e7a da fila. V\u00e1rias outras receitas podem ser facilmente encontradas no s\u00edtio do projeto : Lock distribu\u00eddo Filas, e.g. de prioridades Barreira Servi\u00e7o de nomes Termina\u00e7\u00e3o em duas fases Contador at\u00f4mico Al\u00e9m destas, outro projeto, o Curator se dedica apenas a colecionar implementa\u00e7\u00f5es corretas de receitas para o Zookeeper. Estudo de caso: Etcd Todo etcd Estudo de caso: Kafka Todo Kafka Estudo de caso BFT-Smart Todo BFT-Smart O \\\\ no final da linha \u00e9 s\u00f3 para mostrar que o comando continua na pr\u00f3xima e facilitar a visualiza\u00e7\u00e3o. Na hora de executar, use apenas uma linha, sem o \\\\ . \u21a9","title":"Copycat"},{"location":"cases/copycat/#coordenacao-copycat","text":"Copycat \u00e9 um arcabou\u00e7o de replica\u00e7\u00e3o de m\u00e1quinas de estados implementada pela Atomix . Na base do Copycat est\u00e1 uma implementa\u00e7\u00e3o do Raft. Sobre o Raft, uma API simples mas moderna permite a cria\u00e7\u00e3o de m\u00e1quinas de estados usando lambdas , futures , e o estilo fluent de encadeamento de invoca\u00e7\u00f5es. Lambda Classe com um \u00fanico m\u00e9todo. 1 2 3 4 5 6 7 8 class Tarefa implements Runnable { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } } new Thread ( new Tarefa ()). start (); Classe an\u00f4nima - uso \u00fanico 1 2 3 4 5 6 new Thread ( new Runnable () { public void run (){ while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); } }). start (); Lambda 1 2 3 4 new Thread (() -> { while ( true ) System . out . println ( \"Bem vindo a um loop infinito\" ); }). start (); Fluent Encadeamento 1 2 3 4 5 Collection < Pessoa > c = ...; c . stream () . filter ( p -> p . idade > 33 ) . map ( Pessoa :: sobrenomeNome ) //.map(p -> p.sobrenomeNome()) . forEach ( s -> System . out . println ( s )); Future Promessa de computa\u00e7\u00e3o e resultado. 1 2 ExecutorService executor = Executors . newSingleThreadExecutor (); Future < Integer > futFib = executor . submit (() -> { return Fibonacci ( 217 )}; Quando ser\u00e1 executado? Em algum momento. Como pegar o resultado? 1 2 3 4 while ( ! futFib . isDone ()) System . out . println ( \"tah calculando...\" ); int fib217 = futFib . get (); Em qual thread? Em algum thread. Depende do Executor Service usado. H\u00e1 v\u00e1rias vers\u00f5es do Copycat dispon\u00edveis, com vantagens e desvantagens. Vers\u00f5es Vers\u00e3o 1.1.4 Baseado em http://atomix.io/copycat/docs/getting-started/ e https://www.baeldung.com/atomix C\u00f3digo funcional em https://github.com/pluxos/atomix_labs Documenta\u00e7\u00e3o oficial removida Vers\u00e3o >= 2 Melhor desempenho Documenta\u00e7\u00e3o ruim ou inexistente https://github.com/atomix/atomix Vers\u00e3o 3 em Go evolu\u00e7\u00e3o r\u00e1pida o c\u00f3digo \u00e9 a documenta\u00e7\u00e3o Aqui usaremos a vers\u00e3o 1.1.4, que apesar de antiga, \u00e9 a melhor documentada atualmente, pelo tutorial referenciado acima. Clone e compile o projeto Instale depend\u00eancias: git maven JDK >= 1.8 git clone https://github.com/pluxos/atomix_labs cd atomix_labs cd replication mvn compile mvn test Voc\u00ea deve ver uma sa\u00edda semelhante \u00e0 seguinte, o que quer dizer que seu c\u00f3digo est\u00e1 compilando perfeitamente. 1 2 3 4 5 6 7 8 9 Tests run: 1 , Failures: 0 , Errors: 0 , Skipped: 0 [ INFO ] --------------------------------------- [ INFO ] BUILD SUCCESS [ INFO ] --------------------------------------- [ INFO ] Total time: 6 .898 s [ INFO ] Finished at: 2017 -10-25T08:38:08-02:00 [ INFO ] Final Memory: 15M/159M [ INFO ] --------------------------------------- Antes de come\u00e7ar a escrever suas pr\u00f3rpia m\u00e1quinas de estado, familiarize-se com a estrutura do projeto em https://github.com/pluxos/atomix_labs/tree/master/replication/src/main/java/atomix_lab/state_machine Observe que h\u00e1 tr\u00eas pastas: type - tipos dos dados mantidos pela replica (Edge e Vertex) Os tipos s\u00e3o serializable para que o Java saiba como transform\u00e1-los em bytes. command - estruturas que cont\u00eam informa\u00e7\u00f5es para modificar os tipos Os comandos ser\u00e3o enviadas do cliente para o cluster e s\u00e3o naturalmente serializable. client - cria comandos e os envia para serem executados no cluster Respostas podem ser esperadas s\u00edncrona ou assincronamente. server - recebe os comandos na ordem definida pelo Raft e os executa O projeto foi constru\u00eddo seguindo as instru\u00e7\u00f5es no tutorial mencionado antes, saltando-se a parte dos snapshots, isto \u00e9: crie um projeto maven eclipse tem template para isso adicione depend\u00eancias no pom.xml como so criei um projeto, coloquei as depend\u00eancias tanto do cliente quando do servidor defina Command que modifiquem o estado das r\u00e9plicas defina Queries que consultem o estado das r\u00e9plicas implemente a r\u00e9plica para lidar com os comandos implemente o cliente para emitir comandos Para executar um servidor, voc\u00ea precisa passar diversos par\u00e2metros identificador do processo (inteiro) IP do processo com identificador 0 porta do processo com identificar 0 IP do processo com identificador 1 porta do processo com identificar 1 ... Sabendo seu identificador, o servidor sabe em qual porta escutar e em quais IP/porta se conectar para se comunicar com os outros servidores. Para testar o projeto, execute tr\u00eas servidores, em tr\u00eas terminais distintos. Usando o maven, da linha de comando, basta executar os seguintes comandos[^\\]: 1 2 3 4 5 6 7 8 9 10 11 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"0 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"1 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.server.GraphStateMachine\" \\\\ -Dexec.args = \"2 127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" O cliente n\u00e3o precisa de um identificador, apenas dos pares IP/porta dos servidores. Por exemplo, use o comando: 1 2 3 mvn exec:java \\\\ -Dexec.mainClass = \"atomix_lab.state_machine.client.GraphClient\" \\\\ -Dexec.args = \"127.0.0.1 5000 127.0.0.1 5001 127.0.0.1 5002\" Exerc\u00edcio Uma vez executado o projeto, modifique-o para incluir uma nova opera\u00e7\u00e3o ( Command ) e nova consulta ( Query ), de sua escolha.","title":"Coordena\u00e7\u00e3o: Copycat"},{"location":"cases/copycat/#estudo-de-caso-ratis","text":"Ratis \u00e9 um arcabou\u00e7o de coordena\u00e7\u00e3o recentemente emancipado como um projeto no Apache . Embora mal documentado, o projeto tem alguns exemplos que demonstram como usar abstra\u00e7\u00f5es j\u00e1 implementadas. A seguir veremos um passo-a-passo, baseado nestes exemplos, de como usar o Ratis para implementar uma m\u00e1quina de estados replicada. Crie um novo projeto Maven com o nome ChaveValor (eu estou usando IntelliJ, mas as instru\u00e7\u00f5es devem ser semelhantes para Eclipse). Abra o arquivo pom.xml do seu projeto e adicione o seguinte trecho, com as depend\u00eancias do projeto, incluindo o pr\u00f3prio Ratis. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 <dependencies> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-server --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-server </artifactId> <version> 2.0.0 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-netty --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-netty </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-grpc </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> com.beust </groupId> <artifactId> jcommander </artifactId> <version> 1.78 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> 1.7.25 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-slf4j-impl --> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-slf4j-impl </artifactId> <version> 2.14.1 </version> <scope> compile </scope> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-api </artifactId> <version> 2.14.1 </version> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-core </artifactId> <version> 2.14.1 </version> <scope> provided </scope> </dependency> </dependencies> Adicione tamb\u00e9m o plugin Maven e o plugin para gerar um .jar com todas as depend\u00eancias. Observe que estou usando Java 14, mas voc\u00ea pode mudar para a sua vers\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> ${maven.compiler.version} </version> <configuration> <source> 14 </source> <target> 14 </target> </configuration> </plugin> <plugin> <artifactId> maven-assembly-plugin </artifactId> <executions> <execution> <phase> package </phase> <goals> <goal> single </goal> </goals> </execution> </executions> <configuration> <descriptorRefs> <descriptorRef> jar-with-dependencies </descriptorRef> </descriptorRefs> </configuration> </plugin> </plugins> </build> Crie uma nova classe denominada Cliente no arquivo Cliente.java . Nesta classe, iremos criar um objeto RaftClient que ser\u00e1 usado para enviar opera\u00e7\u00f5es para os servidores. Esta classe \u00e9 importada juntamente com outras v\u00e1rias depend\u00eancias, adicionadas no pom.xml , que devemos instanciar antes do RaftClient . Neste exemplo eu coloco praticamente todos os par\u00e2metros de configura\u00e7\u00e3o do Ratis hardcoded para simplificar o c\u00f3digo. Obviamente que voce deveria ser estes par\u00e2metros como argumentos para o programa ou de um arquivo de configura\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.apache.ratis.client.RaftClient ; import org.apache.ratis.conf.Parameters ; import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcFactory ; import org.apache.ratis.protocol.* ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.nio.charset.Charset ; import java.util.HashMap ; import java.util.Map ; public class Cliente { O campo raftGroupId identifica um cluster Ratis; isso quer dizer que um mesmo processo pode participar de v\u00e1rios clusters , mas aqui nos focaremos em apenas um. O valor do campo deve ter exatamente caracteres, o que soma 32 bytes em java, e ser\u00e1 interpretado como um UUID . id2addr \u00e9 um mapa do identificador de cada processo no cluster para seu endere\u00e7o IP + Porta. Aqui usei v\u00e1rias portas distintas porqu\u00ea todos os processos est\u00e3o rodando na mesma m\u00e1quina, mas se estivesse executando em m\u00e1quinas distintas, com IP distintos, poderia usar a mesma porta em todos. addresses \u00e9 uma lista de RaftPeer constru\u00edda a parti de id2addr . O campo raftGroup \u00e9 uma refer\u00eancia a todos os servidores, associados ao identificador do grupo, raftGroupId . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void main ( String args [] ) throws IOException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), addresses ); Uma vez criado o grupo, criamos o cliente usando a f\u00e1brica retornada por RaftClient.newBuilder() . A f\u00e1brica deve ser configurada com os dados do grupo e o tipo de transporte, neste caso gRPC. Tamb\u00e9m \u00e9 necess\u00e1rio o identificador do processo que est\u00e1 se conectando ao grupo; neste caso, usamos um identificador aleat\u00f3rio qualquer, diferente do que faremos com os servidores. 1 2 3 4 5 6 7 8 RaftProperties raftProperties = new RaftProperties (); RaftClient client = RaftClient . newBuilder () . setProperties ( raftProperties ) . setRaftGroup ( raftGroup ) . setClientRpc ( new GrpcFactory ( new Parameters ()) . newRaftClientRpc ( ClientId . randomId (), raftProperties )) . build (); Uma vez criado o cliente, podemos fazer invoca\u00e7\u00f5es de opera\u00e7\u00f5es nos servidores. Cada opera\u00e7\u00e3o ser\u00e1 invocada em todos os servidores, na mesma ordem. Este prot\u00f3tipo suporta duas opera\u00e7\u00f5es, add e get , incluindo algumas varia\u00e7\u00f5es, que ignoraremos por enquanto. A opera\u00e7\u00e3o add \u00e9 codificada como uma String , add:k:v , onde k e v s\u00e3o do tipo String . add:k:v adiciona uma entrada em um mapa implementado pelo nosso servidor com chave k e valor v . J\u00e1 a opera\u00e7\u00e3o get:k recupera o valor v associado \u00e0 chave k , se presente no mapa. O m\u00e9todo RaftClient.io().send \u00e9 usado para enviar modifica\u00e7\u00f5es para as r\u00e9plicas e deve, necessariamente, passar pelo protocolo Raft. J\u00e1 o m\u00e9todo RaftClient.io().sendReadOnly \u00e9 usado para enviar consultas a qualquer das r\u00e9plicas. Ambos os m\u00e9todos codificam o comando sendo enviado ( add:k:v ou get:k ) no formato interno do Ratis para as r\u00e9plicas e retorna um objeto RaftClientReply , que pode ser usado para pegar a resposta da opera\u00e7\u00e3o. O c\u00f3digo \u00e9 auto explicativo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 RaftClientReply getValue ; CompletableFuture < RaftClientReply > compGetValue ; String response ; switch ( args [ 0 ] ){ case \"add\" : getValue = client . io (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"get\" : getValue = client . io (). sendReadOnly ( Message . valueOf ( \"get:\" + args [ 1 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"add_async\" : compGetValue = client . async (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); getValue = compGetValue . get (); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; case \"get_stale\" : getValue = client . io (). sendStaleRead ( Message . valueOf ( \"get:\" + args [ 1 ] ), 0 , RaftPeerId . valueOf ( args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; default : System . out . println ( \"comando inv\u00e1lido\" ); } client . close (); } } Um vez criado o cliente, crie a classe Servidor , no arquivo Servidor.java ; a parte inicial do c\u00f3digo \u00e9 semelhante \u00e0 do cliente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcConfigKeys ; import org.apache.ratis.protocol.RaftGroup ; import org.apache.ratis.protocol.RaftGroupId ; import org.apache.ratis.protocol.RaftPeer ; import org.apache.ratis.protocol.RaftPeerId ; import org.apache.ratis.server.RaftServer ; import org.apache.ratis.server.RaftServerConfigKeys ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import org.apache.ratis.util.LifeCycle ; import java.io.File ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.util.Collections ; import java.util.HashMap ; import java.util.Map ; import java.util.concurrent.TimeUnit ; public class Servidor { //Parametros: myId public static void main ( String args [] ) throws IOException , InterruptedException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. //Setup for node all nodes. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); A primeira diferen\u00e7a vem na necessidade de identificar o servidor dentro do conjunto de servidores, o que \u00e9 feito com um RaftPeerId . Como cada servidor deve usar um identificador \u00fanico, do conjunto pr\u00e9-determinado em id2addr , o identificador \u00e9 passado como argumento para o programa, obrigatoriamente. 1 2 3 4 5 6 7 8 //Setup for this node. RaftPeerId myId = RaftPeerId . valueOf ( args [ 0 ] ); if ( addresses . stream (). noneMatch ( p -> p . getId (). equals ( myId ))) { System . out . println ( \"Identificador \" + args [ 0 ] + \" \u00e9 inv\u00e1lido.\" ); System . exit ( 1 ); } Encare a se\u00e7\u00e3o seguinte como uma receita, mas observe que o m\u00e9todo RaftServerConfigKeys.setStorageDir recebe o nome de uma pasta como argumento, que ser\u00e1 usada para armazenar o estado da m\u00e1quina de estados. Se voc\u00ea executar o servidor m\u00faltiplas vezes, a cada nova execu\u00e7\u00e3o o estado anterior do sistema ser\u00e1 recuperado desta pasta. Para limpar o estado, apague as pastas de cada servidor. 1 2 3 4 RaftProperties properties = new RaftProperties (); properties . setInt ( GrpcConfigKeys . OutputStream . RETRY_TIMES_KEY , Integer . MAX_VALUE ); GrpcConfigKeys . Server . setPort ( properties , 1000 ); RaftServerConfigKeys . setStorageDir ( properties , Collections . singletonList ( new File ( \"/tmp/\" + myId ))); A m\u00e1quina de estados em si \u00e9 especificada no pr\u00f3ximo excerto, em setStateMachine , que veremos a seguir. 1 2 3 4 5 6 7 8 9 //Join the group of processes. final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), id2addr ); RaftServer raftServer = RaftServer . newBuilder () . setServerId ( myId ) . setStateMachine ( new MaquinaDeEstados ()) . setProperties ( properties ) . setGroup ( raftGroup ) . build (); raftServer . start (); Uma vez iniciado o servidor, basta esperar que ele termine antes de sair do programa. 1 2 3 4 5 while ( raftServer . getLifeCycleState () != LifeCycle . State . CLOSED ) { TimeUnit . SECONDS . sleep ( 1 ); } } } Vamos agora para a defini\u00e7\u00e3o da classe MaquinaDeEstados , no arquivo MaquinaDeEstados.java . Esta classe deve implementar a interface org.apache.ratis.statemachine.StateMachine e seus v\u00e1rios m\u00e9todos ou, mais simples, estende org.apache.ratis.statemachine.impl.BaseStateMachine , a abordagem que usaremos aqui. 1 2 public class MaquinaDeEstados extends BaseStateMachine { Por enquanto, ignoraremos o armazenamento do estado em disco, mantendo-o simplesmente em mem\u00f3ria no campo key2values , e simplesmente implementaremos o processamento de comandos, come\u00e7ando pela implementa\u00e7\u00e3o do m\u00e9todo query . Este m\u00e9todo \u00e9 repons\u00e1vel por implementar opera\u00e7\u00f5es que n\u00e3o alteram o estado da m\u00e1quina de estados, enviadas com o m\u00e9todo RaftClient::sendReadOnly . A \u00fanica query no nosso sistema \u00e9 o get . No c\u00f3digo, o conte\u00fado da requisi\u00e7\u00e3o enviada pelo cliente deve ser recuperado em quebrado em opera\u00e7\u00e3o ( get ) e chave , usando : como delimitador. Recuperado o valor associado \u00e0 chave, o mesmo \u00e9 colocado em um CompletableFuture e retornado. 1 2 3 4 5 6 7 8 9 10 private final Map < String , String > key2values = new ConcurrentHashMap <> (); @Override public CompletableFuture < Message > query ( Message request ) { final String [] opKey = request . getContent (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKey [ 0 ]+ \":\" + key2values . get ( opKey [ 1 ] ); LOG . debug ( \"{}: {} = {}\" , opKey [ 0 ] , opKey [ 1 ] , result ); return CompletableFuture . completedFuture ( Message . valueOf ( result )); } O m\u00e9todo applyTransaction implementa opera\u00e7\u00f5es que alteram o estado, como add , enviadas com o m\u00e9todo RaftClient::send . Da mesma forma que em get , a opera\u00e7\u00e3o deve ser recuperada em quebrada em opera\u00e7\u00e3o ( add ), chave e valor, usando : como delimitador. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableFuture < Message > applyTransaction ( TransactionContext trx ) { final RaftProtos . LogEntryProto entry = trx . getLogEntry (); final String [] opKeyValue = entry . getStateMachineLogEntry (). getLogData (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKeyValue [ 0 ]+ \":\" + key2values . put ( opKeyValue [ 1 ] , opKeyValue [ 2 ] ); final CompletableFuture < Message > f = CompletableFuture . completedFuture ( Message . valueOf ( result )); final RaftProtos . RaftPeerRole role = trx . getServerRole (); LOG . info ( \"{}:{} {} {}={}\" , role , getId (), opKeyValue [ 0 ] , opKeyValue [ 1 ] , opKeyValue [ 2 ] ); return f ; } Pronto, voc\u00ea j\u00e1 tem uma m\u00e1quina de estados replicada, bastando agora apenas compil\u00e1-la e execut\u00e1-la. Para compilar, de raiz do projeto execute o comando mvn package . A primeira vez que faz isso pode demorar um pouco pois v\u00e1rias depend\u00eancias s\u00e3o baixadas da Internet. Ao final da execu\u00e7\u00e3o do comando voc\u00ea deveria ver algo semelhante ao seguinte 1 2 3 4 5 6 7 ... INFO ] ------------------------------------------------------------------------ [ INFO ] BUILD SUCCESS [ INFO ] ------------------------------------------------------------------------ [ INFO ] Total time: 4 .793 s [ INFO ] Finished at: 2020 -12-06T23:06:32-03:00 [ INFO ] ------------------------------------------------------------------------ Ent\u00e3o, em tr\u00eas terminais diferentes, execute os seguintes comandos: 1 2 3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p2 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p3 Para executar o cliente, em um outro terminal, fa\u00e7a, por exemplo, 1 2 3 4 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k1 testek1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get k1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k2 testek2 Todo o c\u00f3digo est\u00e1 dispon\u00edvel no Github Exerc\u00edcio Adicionar opera\u00e7\u00f5es del clear","title":"Estudo de caso: Ratis"},{"location":"cases/copycat/#estudo-de-caso-zookeeper","text":"O Zookeeper foi criado para coordenar as a\u00e7\u00f5es dos componentes de sistemas distribu\u00eddos, porqu\u00ea sistemas distribu\u00eddos s\u00e3o como zool\u00f3gicos, com animais de diversas esp\u00e9cies, sendo obrigados a conviver de forma anti-natural.","title":"Estudo de caso: Zookeeper"},{"location":"cases/copycat/#estudo-de-caso-etcd","text":"Todo etcd","title":"Estudo de caso: Etcd"},{"location":"cases/copycat/#estudo-de-caso-kafka","text":"Todo Kafka","title":"Estudo de caso: Kafka"},{"location":"cases/copycat/#estudo-de-caso-bft-smart","text":"Todo BFT-Smart O \\\\ no final da linha \u00e9 s\u00f3 para mostrar que o comando continua na pr\u00f3xima e facilitar a visualiza\u00e7\u00e3o. Na hora de executar, use apenas uma linha, sem o \\\\ . \u21a9","title":"Estudo de caso BFT-Smart"},{"location":"cases/dynamo/","text":"Sistema P2P: DynamoDB DynamoDB \u00e9 o marco fundamental dos bancos de dados NoSQL. No v\u00eddeo a seguir um de seus evangelizadores, descreve rapidamente o banco, os cen\u00e1rios em que deveria ser usado e diversos padr\u00f5es de projeto para modelagem de dados. Enquanto o assiste, alguns pontos devem ser ressaltados sobre o Dynamo de forma espec\u00edfica e os NoSQL de forma geral: surgiram da necessidade de escalabilidade dos bancos de dados, isto \u00e9, da necessidade de lidar com milh\u00f5es e milh\u00f5es de entradas de dados, gerados e processados com baixa lat\u00eancia e alta vaz\u00e3o, a despeito de falhas; maior escalabilidade implica em maior exposi\u00e7\u00e3o a particionamentos da rede em que o sistema roda, que associado \u00e0 necessidade de manuten\u00e7\u00e3o de alta disponibilidade, implica em perda de garantias de consist\u00eancia (veremos o Teorema CAP adiante); Partition keys s\u00e3o as chaves usadas para roteamento dos dados, ou seja, as chaves discutidas anteriormente neste cap\u00edtulo sobre sistema P2P; Sort keys s\u00e3o chaves usadas dentro de cada n\u00f3 para ordenar os dados na hora de gerar as SSTables ( String Sorted Tables ), e se usadas em agregados de valores, s\u00e3o equivalentes ao GROUP BY do SQL; Lambda functions s\u00e3o fun\u00e7\u00f5es para processamento de dados executadas em entradas definidas por um pipeline de processamento sem a defini\u00e7\u00e3o expl\u00edcita de sockets e portas, em um modelo conhecido como Serverless . Este modelo \u00e9 adequado a algumas aplica\u00e7\u00f5es, como o carrinho de compras da Amazon.com, aplica\u00e7\u00e3o para a qual o Dynamodb foi inicialmente desenvolvido. Nesta aplica\u00e7\u00e3o, cada usu\u00e1rio tem um identificador \u00fanico , recuperado no momento em que se loga ao sistema da Amazon. Este identificador \u00fanico \u00e9 a chave de particionamento e os dados s\u00e3o o conte\u00fado do carrinho de compras. Para lidar com falhas, o conte\u00fado do carrinho \u00e9 replicado nos n\u00f3s sucessivos ao respons\u00e1vel pela dupla chave valor. O carrinho \u00e9 modificado atomicamente , isto \u00e9, sobrescrito por inteiro. A replica\u00e7\u00e3o, associada \u00e0s modifica\u00e7\u00f5es at\u00f4micas, potencializa conflitos, que s\u00e3o identificados comparando-se os vetores de vers\u00e3o (rel\u00f3gios vetoriais) associados a cada valor escrito. No caso de conflitos, as m\u00faltiplas c\u00f3pias concorrentes s\u00e3o apresentadas ao usu\u00e1rio na forma de um carrinho de compras com a uni\u00e3o dos itens nos respectivos carrinhos, de forma que o usu\u00e1rio possa corrig\u00ed-lo. Na pior das hip\u00f3teses, uma compra com erros ser\u00e1 feita, e necessitar\u00e1 de uma atividade compensat\u00f3ria para o usu\u00e1rio, como um brinde. Na pr\u00e1tica, muitos sistemas mant\u00e9m os pap\u00e9is de clientes, que requisitam a execu\u00e7\u00e3o de servi\u00e7os, e servidores, que executam as requisi\u00e7\u00f5es, mas distribuem as tarefas dos servidores entre pares para aquela fun\u00e7\u00e3o, sendo efetivamente sistemas h\u00edbridos. Este \u00e9 o caso dos bancos de dados NOSQL, como o Dynamo, que acabamos de estudar, e tamb\u00e9m do Cassandra, que veremos a seguir.","title":"Dynamo"},{"location":"cases/dynamo/#sistema-p2p-dynamodb","text":"DynamoDB \u00e9 o marco fundamental dos bancos de dados NoSQL. No v\u00eddeo a seguir um de seus evangelizadores, descreve rapidamente o banco, os cen\u00e1rios em que deveria ser usado e diversos padr\u00f5es de projeto para modelagem de dados. Enquanto o assiste, alguns pontos devem ser ressaltados sobre o Dynamo de forma espec\u00edfica e os NoSQL de forma geral: surgiram da necessidade de escalabilidade dos bancos de dados, isto \u00e9, da necessidade de lidar com milh\u00f5es e milh\u00f5es de entradas de dados, gerados e processados com baixa lat\u00eancia e alta vaz\u00e3o, a despeito de falhas; maior escalabilidade implica em maior exposi\u00e7\u00e3o a particionamentos da rede em que o sistema roda, que associado \u00e0 necessidade de manuten\u00e7\u00e3o de alta disponibilidade, implica em perda de garantias de consist\u00eancia (veremos o Teorema CAP adiante); Partition keys s\u00e3o as chaves usadas para roteamento dos dados, ou seja, as chaves discutidas anteriormente neste cap\u00edtulo sobre sistema P2P; Sort keys s\u00e3o chaves usadas dentro de cada n\u00f3 para ordenar os dados na hora de gerar as SSTables ( String Sorted Tables ), e se usadas em agregados de valores, s\u00e3o equivalentes ao GROUP BY do SQL; Lambda functions s\u00e3o fun\u00e7\u00f5es para processamento de dados executadas em entradas definidas por um pipeline de processamento sem a defini\u00e7\u00e3o expl\u00edcita de sockets e portas, em um modelo conhecido como Serverless . Este modelo \u00e9 adequado a algumas aplica\u00e7\u00f5es, como o carrinho de compras da Amazon.com, aplica\u00e7\u00e3o para a qual o Dynamodb foi inicialmente desenvolvido. Nesta aplica\u00e7\u00e3o, cada usu\u00e1rio tem um identificador \u00fanico , recuperado no momento em que se loga ao sistema da Amazon. Este identificador \u00fanico \u00e9 a chave de particionamento e os dados s\u00e3o o conte\u00fado do carrinho de compras. Para lidar com falhas, o conte\u00fado do carrinho \u00e9 replicado nos n\u00f3s sucessivos ao respons\u00e1vel pela dupla chave valor. O carrinho \u00e9 modificado atomicamente , isto \u00e9, sobrescrito por inteiro. A replica\u00e7\u00e3o, associada \u00e0s modifica\u00e7\u00f5es at\u00f4micas, potencializa conflitos, que s\u00e3o identificados comparando-se os vetores de vers\u00e3o (rel\u00f3gios vetoriais) associados a cada valor escrito. No caso de conflitos, as m\u00faltiplas c\u00f3pias concorrentes s\u00e3o apresentadas ao usu\u00e1rio na forma de um carrinho de compras com a uni\u00e3o dos itens nos respectivos carrinhos, de forma que o usu\u00e1rio possa corrig\u00ed-lo. Na pior das hip\u00f3teses, uma compra com erros ser\u00e1 feita, e necessitar\u00e1 de uma atividade compensat\u00f3ria para o usu\u00e1rio, como um brinde. Na pr\u00e1tica, muitos sistemas mant\u00e9m os pap\u00e9is de clientes, que requisitam a execu\u00e7\u00e3o de servi\u00e7os, e servidores, que executam as requisi\u00e7\u00f5es, mas distribuem as tarefas dos servidores entre pares para aquela fun\u00e7\u00e3o, sendo efetivamente sistemas h\u00edbridos. Este \u00e9 o caso dos bancos de dados NOSQL, como o Dynamo, que acabamos de estudar, e tamb\u00e9m do Cassandra, que veremos a seguir.","title":"Sistema P2P: DynamoDB"},{"location":"cases/etcd/","text":"Todo etcd","title":"Etcd"},{"location":"cases/grpc/","text":"RPC: gRPC gRPC \u00e9 um framework para invoca\u00e7\u00e3o remota de procedimentos multi-linguagem e sistema operacional, usando internamente pelo Google h\u00e1 v\u00e1rios anos para implementar sua arquitetura de micro-servi\u00e7os. Inicialmente desenvolvido pelo Google, o gRPC \u00e9 hoje de c\u00f3digo livre encubado pela Cloud Native Computing Foundation. O s\u00edtio gRPC.io documenta muito bem o gRPC, inclusive os princ\u00edpios que nortearam seu projeto. O seu uso segue, em linhas gerais, o modelo discutido nas se\u00e7\u00f5es anteriores, isto \u00e9, inicia-se pela defini\u00e7\u00e3o de estruturas de dados e servi\u00e7os, \"compila-se\" a defini\u00e7\u00e3o para gerar stubs na linguagem desejada, e compila-se os stubs juntamente com os c\u00f3digos cliente e servidor para gerar os bin\u00e1rios correspondentes. Vejamos a seguir um tutorial passo a passo, em Java, baseado no quickstart guide . Instala\u00e7\u00e3o Os procedimentos de instala\u00e7\u00e3o dependem da linguagem em que pretende usar o gRPC, tanto para cliente quanto para servidor. No caso do Java , n\u00e3o h\u00e1 instala\u00e7\u00e3o propriamente dita . Exemplo Java Observe que o reposit\u00f3rio base apontado no tutorial serve de exemplo para diversas linguagens e diversos servi\u00e7os, ent\u00e3o sua estrutura \u00e9 meio complicada. N\u00f3s nos focaremos aqui no exemplo mais simples, uma esp\u00e9cie de \"hello word\" do RPC. Pegando o c\u00f3digo Para usar os exemplos, voc\u00ea precisa clonar o reposit\u00f3rio com o tutorial, usando o comando a seguir. 1 git clone -b v1.33.0 https://github.com/grpc/grpc-java Uma vez clonado, entre na pasta de exemplo do Java e certifique-se que est\u00e1 na vers\u00e3o 1.33, usada neste tutorial. 1 2 cd grpc-java/examples git checkout v1.36.0 Compilando e executando O projeto usa gradle para gerenciar as depend\u00eancias. Para, use o wrapper do gradle como se segue. 1 2 cd grpc-java/examples ./gradlew installDist -PskipAndroid = true Caso esteja na UFU, coloque tamb\u00e9m informa\u00e7\u00e3o sobre o proxy no comando. 1 ./gradlew -Dhttp.proxyHost = proxy.ufu.br -Dhttp.proxyPort = 3128 -Dhttps.proxyHost = proxy.ufu.br -Dhttps.proxyPort = 3128 installDist Como quando usamos sockets diretamente, para usar o servi\u00e7o definido neste exemplo, primeiros temos que executar o servidor. 1 ./build/install/examples/bin/hello-world-server Agora, em um terminal distinto e a partir da mesma localiza\u00e7\u00e3o, execute o cliente, quantas vezes quiser. 1 ./build/install/examples/bin/hello-world-client O servi\u00e7o O exemplo n\u00e3o \u00e9 muito excitante, pois tudo o que o servi\u00e7o faz \u00e9 enviar uma sauda\u00e7\u00e3o aos clientes. O servi\u00e7o \u00e9 definido no seguinte arquivo .proto , localizado em ./src/main/proto/helloworld.proto . 1 2 3 4 5 6 7 8 9 10 11 12 13 message HelloRequest { string name = 1 ; } message HelloReply { string message = 1 ; } // The greeting service definition. service Greeter { rpc SayHello ( HelloRequest ) returns ( HelloReply ) {} } No arquivo, inicialmente s\u00e3o definidas duas mensagens, usadas como requisi\u00e7\u00e3o (cliente para servidor) e outra como resposta (servidor para cliente) do servi\u00e7o definido em seguida. A mensagem HelloRequest tem apenas um campo denominado name , do tipo string . Esta mensagem conter\u00e1 o nome do cliente, usado na resposta gerada pelo servidor. A mensagem HelloReply tamb\u00e9m tem um campo do tipo string , denominado message , que conter\u00e1 a resposta do servidor. O servi\u00e7o dispon\u00edvel \u00e9 definido pela palavra chave service e de nome Greeter ; \u00e9 importante entender que este nome ser\u00e1 usado em todo o c\u00f3digo gerado pelo compilador gRPC e que se for mudado, todas as refer\u00eancias ao c\u00f3digo gerado devem ser atualizadas. O servi\u00e7o possui apenas uma opera\u00e7\u00e3o, SayHello , que recebe como entrada uma mensagem HelloRequest e gera como resposta uma mensagem HelloReply . Caso a opera\u00e7\u00e3o precisasse de mais do que o conte\u00fado de name para executar, a mensagem HelloRequest deveria ser estendida, pois n\u00e3o h\u00e1 passar mais de uma mensagem para a opera\u00e7\u00e3o. Por outro lado, embora seja poss\u00edvel passar zero mensagens, esta n\u00e3o \u00e9 uma pr\u00e1tica recomendada. Isto porqu\u00ea caso o servi\u00e7o precisasse ser modificado no futuro, embora seja poss\u00edvel estender uma mensagem, n\u00e3o \u00e9 poss\u00edvel modificar a assinatura do servi\u00e7o. Assim, caso n\u00e3o haja a necessidade de se passar qualquer informa\u00e7\u00e3o para a opera\u00e7\u00e3o, recomenda-se que seja usada uma mensagem de entrada vazia, que poderia ser estendida no futuro. O mesmo se aplica ao resultado da opera\u00e7\u00e3o. Observe tamb\u00e9m que embora o servi\u00e7o de exemplo tenha apenas uma opera\u00e7\u00e3o, poderia ter m\u00faltiplas. Por exemplo, para definir uma vers\u00e3o em portugu\u00eas da opera\u00e7\u00e3o SayHello , podemos fazer da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 message HelloRequest { string name = 1 ; } message HelloReply { string message = 1 ; } message OlaRequest { // <<<<<==== string name = 1 ; } message OlaReply { // <<<<<==== string message = 1 ; } service Greeter { rpc SayHello ( HelloRequest ) returns ( HelloReply ) {} rpc DigaOla ( OlaRequest ) returns ( OlaReply ) {} // <<<<<==== } ... Observe que a nova opera\u00e7\u00e3o recebe como entrada mensagens OlaRequest e OlaReply , que tem defini\u00e7\u00f5es exatamente iguais a HellorRequest e HelloReply . Logo, em vez de definir novas mensagens, poder\u00edamos ter usado as j\u00e1 definidas. Novamente, esta n\u00e3o \u00e9 uma boa pr\u00e1tica, pois caso fosse necess\u00e1rio evoluir uma das opera\u00e7\u00f5es para atender a novos requisitos e estender suas mensagens, n\u00e3o ser\u00e1 necess\u00e1rio tocar o restante do servi\u00e7o. Apenas refor\u00e7ando, \u00e9 boa pr\u00e1tica definir requests e responses para cada m\u00e9todo, a n\u00e3o ser que n\u00e3o haja d\u00favida de que ser\u00e3o para sempre iguais. Implementando um servi\u00e7o Agora modifique o arquivo .proto como acima, para incluir a opera\u00e7\u00e3o DigaOla , recompile e reexecute o servi\u00e7o. N\u00e3o d\u00e1 certo, n\u00e3o \u00e9 mesmo? Isto porqu\u00ea voc\u00ea adicionou a defini\u00e7\u00e3o de uma nova opera\u00e7\u00e3o, mas n\u00e3o incluiu o c\u00f3digo para implement\u00e1-la. Fa\u00e7amos ent\u00e3o a modifica\u00e7\u00e3o do c\u00f3digo, come\u00e7ando por ./src/main/java/io/grpc/examples/helloworld/HelloWorldServer.java . Este arquivo define a classe que implementa o servi\u00e7o Greeter , GreeterImpl , com um m\u00e9todo para cada uma das opera\u00e7\u00f5es definidas. Para confirmar, procure por sayHello para encontrar a implementa\u00e7\u00e3o de SayHello ; observe que a diferen\u00e7a do casing vem das boas pr\u00e1ticas de Java, de definir m\u00e9todos e vari\u00e1veis em Camel casing . Para que sua vers\u00e3o estendida do servi\u00e7o Greeter funcione, defina um m\u00e9todo correspondendo \u00e0 DigaOla , sem consultar o c\u00f3digo exemplo abaixo, mas usando o c\u00f3digo de sayHello como base; n\u00e3o se importe por enquanto com os m\u00e9todos sendo invocados. Note que os ... indicam que parte do c\u00f3digo, que n\u00e3o sofreu modifica\u00e7\u00f5es, foi omitido. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... private class GreeterImpl extends GreeterGrpc . GreeterImplBase { ... @Override public void sayHello ( HelloRequest req , StreamObserver < HelloReply > responseObserver ) { ... } @Override public void digaOla ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( \"Ola \" + req . getName ()). build (); responseObserver . onNext ( reply ); responseObserver . onCompleted (); } } Se voc\u00ea recompilar e reexecutar o c\u00f3digo, n\u00e3o perceber\u00e1 qualquer mudan\u00e7a na sa\u00edda do programa. Isto porqu\u00ea embora tenha definido um novo servi\u00e7o, voc\u00ea n\u00e3o o utilizou. Para tanto, agora modifique o cliente, em src/main/java/io/grpc/examples/helloworld/HelloWorldClient.java , novamente se baseando no c\u00f3digo existente e n\u00e3o se preocupando com \"detalhes\". 1 2 3 4 5 6 7 8 9 10 11 12 13 public void greet ( String name ) { logger . info ( \"Will try to greet \" + name + \" ...\" ); ... OlaRequest request2 = OlaRequest . newBuilder (). setName ( name ). build (); OlaReply response2 ; try { response2 = blockingStub . digaOla ( request2 ); } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } logger . info ( \"Greeting: \" + response2 . getMessage ()); } Agora sim, voc\u00ea pode reexecutar cliente e servidor. 1 2 3 ./gradlew installDist ./build/install/examples/bin/hello-world-server & ./build/install/examples/bin/hello-world-client Percebeu como foi f\u00e1cil adicionar uma opera\u00e7\u00e3o ao servi\u00e7o? Agora nos foquemos nos detalhes, come\u00e7ando sobre como um servidor gRPC \u00e9 criado. Observe que um objeto Server \u00e9 criado por uma f\u00e1brica que recebe como par\u00e2metros a porta em que o servi\u00e7o dever\u00e1 escutar e o objeto que efetivamente implementa as opera\u00e7\u00f5es definidas no arquivo .proto . O start() tamb\u00e9m \u00e9 invocado na sequ\u00eancia e, estudando o c\u00f3digo, voc\u00ea entender\u00e1 como o fim da execu\u00e7\u00e3o \u00e9 tratada. 1 2 3 4 5 6 7 8 9 import io.grpc.Server ; ... private Server server ; ... server = ServerBuilder . forPort ( port ) . addService ( new GreeterImpl ()) . build () . start (); ... Do lado do cliente, \u00e9 criado um ManagedChannel e com este um GreeterBlockingStub , um stub em cujas chamadas s\u00e3o bloqueantes. Finalmente, no stub s\u00e3o invocados os servi\u00e7os definidos na IDL. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import io.grpc.Channel ; import io.grpc.ManagedChannel ; import io.grpc.ManagedChannelBuilder ; ... ManagedChannel channel = ManagedChannelBuilder . forTarget ( target ) . usePlaintext () . build (); ... private final GreeterGrpc . GreeterBlockingStub blockingStub = GreeterGrpc . newBlockingStub ( channel ); ... HelloRequest request = HelloRequest . newBuilder () . setName ( name ) . build (); HelloReply response ; try { response = blockingStub . sayHello ( request ); } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } logger . info ( \"Greeting: \" + response . getMessage ()); Diga Ol\u00e1s! Para fixar o conte\u00fado \u00e9 preciso colocar a m\u00e3o na massa. Estenda a defini\u00e7\u00e3o do servi\u00e7o com uma opera\u00e7\u00e3o DigaOlas em que uma lista de nomes \u00e9 enviada ao servidor e tal que o servidor responda com **uma longa string**cumprimentando todos os nomes, um ap\u00f3s o outro. S\u00f3 abra depois de pensar em como resolver o problema Voc\u00ea pode usar repeated no campo message do tipo HelloRequest . Stream Para terminar este estudo de caso, modifique a fun\u00e7\u00e3o definida no exerc\u00edcio anterior para gerar m\u00faltiplas respostas, uma para cada nome passado, em vez de uma \u00fanica, longa, resposta. S\u00f3 abra depois de pensar em como resolver o problema Voc\u00ea dever\u00e1 usar streams . 1 rpc DigaOlas ( OlaRequest ) returns ( stream OlaReply ) {} Do lado do servidor 1 2 3 4 5 6 7 8 9 10 11 List < String > listOfHi = Arrays . asList ( \"e aih\" , \"ola\" , \"ciao\" , \"bao\" , \"howdy\" , \"s'up\" ); @Override public void digaOlas ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { for ( String hi : listOfHi ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( hi + \", \" req . getName ()). build (); responseObserver . onNext ( reply ); } responseObserver . onCompleted (); } Do lado do cliente 1 2 3 4 5 6 7 8 9 10 11 OlaRequest request = OlaRequest . newBuilder (). setName ( name ). build (); try { Iterator < OlaReply > it = blockingStub . digaOlas ( request ); while ( it . hasNext ()){ OlaReply response = it . next (); logger . info ( \"Greeting: \" + response . getMessage ()); } } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } Desafio de Interoperabilidade Siga o tutorial abaixo e execute use o gRPC em Python. Uma vez executados cliente e servidor, tente fazer com que interaja com a implementa\u00e7\u00e3o em java. 1 2 3 4 5 6 7 8 9 10 apt-get install python3 apt-get install python3-pip python3 -m pip install --upgrade pip python3 -m pip install grpcio python3 -m pip install grpcio-tools git clone -b v1..x https://github.com/grpc/grpc cd grpc/examples/python/helloworld python3 greeter \\_ server.py python3 greeter \\_ client.py Para recompilar os stubs , fa\u00e7a 1 python3 -m grpc_tools.protoc -I../../protos --python_out = . --grpc_python_out = . ../../protos/helloworld.proto Modifique o servidor 1 2 def DigaOla ( self , request , context ): return helloworld_pb2 . OlaReply ( message = 'Ola, %s !' + request . name ) Modifique o cliente 1 2 response = stub . DigaOla ( helloworld_pb2 . OlaRequest ( name = 'zelelele' )) print ( \"Greeter client received: \" + response . message ) Outros modos de trabalho gRPC \u00e9 um framework bem flex\u00edvel e para entender como \u00e9 poss\u00edvel us\u00e1-lo para estabelecer canais de comunica\u00e7\u00e3o para fluxos, al\u00e9m da documenta\u00e7\u00e3o j\u00e1 apontada, sugiro o artigo gRPC: A Deep Dive into the Communication Pattern , que a detalha.","title":"gRPC"},{"location":"cases/grpc/#rpc-grpc","text":"gRPC \u00e9 um framework para invoca\u00e7\u00e3o remota de procedimentos multi-linguagem e sistema operacional, usando internamente pelo Google h\u00e1 v\u00e1rios anos para implementar sua arquitetura de micro-servi\u00e7os. Inicialmente desenvolvido pelo Google, o gRPC \u00e9 hoje de c\u00f3digo livre encubado pela Cloud Native Computing Foundation. O s\u00edtio gRPC.io documenta muito bem o gRPC, inclusive os princ\u00edpios que nortearam seu projeto. O seu uso segue, em linhas gerais, o modelo discutido nas se\u00e7\u00f5es anteriores, isto \u00e9, inicia-se pela defini\u00e7\u00e3o de estruturas de dados e servi\u00e7os, \"compila-se\" a defini\u00e7\u00e3o para gerar stubs na linguagem desejada, e compila-se os stubs juntamente com os c\u00f3digos cliente e servidor para gerar os bin\u00e1rios correspondentes. Vejamos a seguir um tutorial passo a passo, em Java, baseado no quickstart guide .","title":"RPC: gRPC"},{"location":"cases/grpc/#instalacao","text":"Os procedimentos de instala\u00e7\u00e3o dependem da linguagem em que pretende usar o gRPC, tanto para cliente quanto para servidor. No caso do Java , n\u00e3o h\u00e1 instala\u00e7\u00e3o propriamente dita .","title":"Instala\u00e7\u00e3o"},{"location":"cases/grpc/#exemplo-java","text":"Observe que o reposit\u00f3rio base apontado no tutorial serve de exemplo para diversas linguagens e diversos servi\u00e7os, ent\u00e3o sua estrutura \u00e9 meio complicada. N\u00f3s nos focaremos aqui no exemplo mais simples, uma esp\u00e9cie de \"hello word\" do RPC.","title":"Exemplo Java"},{"location":"cases/grpc/#pegando-o-codigo","text":"Para usar os exemplos, voc\u00ea precisa clonar o reposit\u00f3rio com o tutorial, usando o comando a seguir. 1 git clone -b v1.33.0 https://github.com/grpc/grpc-java Uma vez clonado, entre na pasta de exemplo do Java e certifique-se que est\u00e1 na vers\u00e3o 1.33, usada neste tutorial. 1 2 cd grpc-java/examples git checkout v1.36.0","title":"Pegando o c\u00f3digo"},{"location":"cases/grpc/#compilando-e-executando","text":"O projeto usa gradle para gerenciar as depend\u00eancias. Para, use o wrapper do gradle como se segue. 1 2 cd grpc-java/examples ./gradlew installDist -PskipAndroid = true Caso esteja na UFU, coloque tamb\u00e9m informa\u00e7\u00e3o sobre o proxy no comando. 1 ./gradlew -Dhttp.proxyHost = proxy.ufu.br -Dhttp.proxyPort = 3128 -Dhttps.proxyHost = proxy.ufu.br -Dhttps.proxyPort = 3128 installDist Como quando usamos sockets diretamente, para usar o servi\u00e7o definido neste exemplo, primeiros temos que executar o servidor. 1 ./build/install/examples/bin/hello-world-server Agora, em um terminal distinto e a partir da mesma localiza\u00e7\u00e3o, execute o cliente, quantas vezes quiser. 1 ./build/install/examples/bin/hello-world-client","title":"Compilando e executando"},{"location":"cases/grpc/#o-servico","text":"O exemplo n\u00e3o \u00e9 muito excitante, pois tudo o que o servi\u00e7o faz \u00e9 enviar uma sauda\u00e7\u00e3o aos clientes. O servi\u00e7o \u00e9 definido no seguinte arquivo .proto , localizado em ./src/main/proto/helloworld.proto . 1 2 3 4 5 6 7 8 9 10 11 12 13 message HelloRequest { string name = 1 ; } message HelloReply { string message = 1 ; } // The greeting service definition. service Greeter { rpc SayHello ( HelloRequest ) returns ( HelloReply ) {} } No arquivo, inicialmente s\u00e3o definidas duas mensagens, usadas como requisi\u00e7\u00e3o (cliente para servidor) e outra como resposta (servidor para cliente) do servi\u00e7o definido em seguida. A mensagem HelloRequest tem apenas um campo denominado name , do tipo string . Esta mensagem conter\u00e1 o nome do cliente, usado na resposta gerada pelo servidor. A mensagem HelloReply tamb\u00e9m tem um campo do tipo string , denominado message , que conter\u00e1 a resposta do servidor. O servi\u00e7o dispon\u00edvel \u00e9 definido pela palavra chave service e de nome Greeter ; \u00e9 importante entender que este nome ser\u00e1 usado em todo o c\u00f3digo gerado pelo compilador gRPC e que se for mudado, todas as refer\u00eancias ao c\u00f3digo gerado devem ser atualizadas. O servi\u00e7o possui apenas uma opera\u00e7\u00e3o, SayHello , que recebe como entrada uma mensagem HelloRequest e gera como resposta uma mensagem HelloReply . Caso a opera\u00e7\u00e3o precisasse de mais do que o conte\u00fado de name para executar, a mensagem HelloRequest deveria ser estendida, pois n\u00e3o h\u00e1 passar mais de uma mensagem para a opera\u00e7\u00e3o. Por outro lado, embora seja poss\u00edvel passar zero mensagens, esta n\u00e3o \u00e9 uma pr\u00e1tica recomendada. Isto porqu\u00ea caso o servi\u00e7o precisasse ser modificado no futuro, embora seja poss\u00edvel estender uma mensagem, n\u00e3o \u00e9 poss\u00edvel modificar a assinatura do servi\u00e7o. Assim, caso n\u00e3o haja a necessidade de se passar qualquer informa\u00e7\u00e3o para a opera\u00e7\u00e3o, recomenda-se que seja usada uma mensagem de entrada vazia, que poderia ser estendida no futuro. O mesmo se aplica ao resultado da opera\u00e7\u00e3o. Observe tamb\u00e9m que embora o servi\u00e7o de exemplo tenha apenas uma opera\u00e7\u00e3o, poderia ter m\u00faltiplas. Por exemplo, para definir uma vers\u00e3o em portugu\u00eas da opera\u00e7\u00e3o SayHello , podemos fazer da seguinte forma. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 message HelloRequest { string name = 1 ; } message HelloReply { string message = 1 ; } message OlaRequest { // <<<<<==== string name = 1 ; } message OlaReply { // <<<<<==== string message = 1 ; } service Greeter { rpc SayHello ( HelloRequest ) returns ( HelloReply ) {} rpc DigaOla ( OlaRequest ) returns ( OlaReply ) {} // <<<<<==== } ... Observe que a nova opera\u00e7\u00e3o recebe como entrada mensagens OlaRequest e OlaReply , que tem defini\u00e7\u00f5es exatamente iguais a HellorRequest e HelloReply . Logo, em vez de definir novas mensagens, poder\u00edamos ter usado as j\u00e1 definidas. Novamente, esta n\u00e3o \u00e9 uma boa pr\u00e1tica, pois caso fosse necess\u00e1rio evoluir uma das opera\u00e7\u00f5es para atender a novos requisitos e estender suas mensagens, n\u00e3o ser\u00e1 necess\u00e1rio tocar o restante do servi\u00e7o. Apenas refor\u00e7ando, \u00e9 boa pr\u00e1tica definir requests e responses para cada m\u00e9todo, a n\u00e3o ser que n\u00e3o haja d\u00favida de que ser\u00e3o para sempre iguais.","title":"O servi\u00e7o"},{"location":"cases/grpc/#implementando-um-servico","text":"Agora modifique o arquivo .proto como acima, para incluir a opera\u00e7\u00e3o DigaOla , recompile e reexecute o servi\u00e7o. N\u00e3o d\u00e1 certo, n\u00e3o \u00e9 mesmo? Isto porqu\u00ea voc\u00ea adicionou a defini\u00e7\u00e3o de uma nova opera\u00e7\u00e3o, mas n\u00e3o incluiu o c\u00f3digo para implement\u00e1-la. Fa\u00e7amos ent\u00e3o a modifica\u00e7\u00e3o do c\u00f3digo, come\u00e7ando por ./src/main/java/io/grpc/examples/helloworld/HelloWorldServer.java . Este arquivo define a classe que implementa o servi\u00e7o Greeter , GreeterImpl , com um m\u00e9todo para cada uma das opera\u00e7\u00f5es definidas. Para confirmar, procure por sayHello para encontrar a implementa\u00e7\u00e3o de SayHello ; observe que a diferen\u00e7a do casing vem das boas pr\u00e1ticas de Java, de definir m\u00e9todos e vari\u00e1veis em Camel casing . Para que sua vers\u00e3o estendida do servi\u00e7o Greeter funcione, defina um m\u00e9todo correspondendo \u00e0 DigaOla , sem consultar o c\u00f3digo exemplo abaixo, mas usando o c\u00f3digo de sayHello como base; n\u00e3o se importe por enquanto com os m\u00e9todos sendo invocados. Note que os ... indicam que parte do c\u00f3digo, que n\u00e3o sofreu modifica\u00e7\u00f5es, foi omitido. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... private class GreeterImpl extends GreeterGrpc . GreeterImplBase { ... @Override public void sayHello ( HelloRequest req , StreamObserver < HelloReply > responseObserver ) { ... } @Override public void digaOla ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( \"Ola \" + req . getName ()). build (); responseObserver . onNext ( reply ); responseObserver . onCompleted (); } } Se voc\u00ea recompilar e reexecutar o c\u00f3digo, n\u00e3o perceber\u00e1 qualquer mudan\u00e7a na sa\u00edda do programa. Isto porqu\u00ea embora tenha definido um novo servi\u00e7o, voc\u00ea n\u00e3o o utilizou. Para tanto, agora modifique o cliente, em src/main/java/io/grpc/examples/helloworld/HelloWorldClient.java , novamente se baseando no c\u00f3digo existente e n\u00e3o se preocupando com \"detalhes\". 1 2 3 4 5 6 7 8 9 10 11 12 13 public void greet ( String name ) { logger . info ( \"Will try to greet \" + name + \" ...\" ); ... OlaRequest request2 = OlaRequest . newBuilder (). setName ( name ). build (); OlaReply response2 ; try { response2 = blockingStub . digaOla ( request2 ); } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } logger . info ( \"Greeting: \" + response2 . getMessage ()); } Agora sim, voc\u00ea pode reexecutar cliente e servidor. 1 2 3 ./gradlew installDist ./build/install/examples/bin/hello-world-server & ./build/install/examples/bin/hello-world-client Percebeu como foi f\u00e1cil adicionar uma opera\u00e7\u00e3o ao servi\u00e7o? Agora nos foquemos nos detalhes, come\u00e7ando sobre como um servidor gRPC \u00e9 criado. Observe que um objeto Server \u00e9 criado por uma f\u00e1brica que recebe como par\u00e2metros a porta em que o servi\u00e7o dever\u00e1 escutar e o objeto que efetivamente implementa as opera\u00e7\u00f5es definidas no arquivo .proto . O start() tamb\u00e9m \u00e9 invocado na sequ\u00eancia e, estudando o c\u00f3digo, voc\u00ea entender\u00e1 como o fim da execu\u00e7\u00e3o \u00e9 tratada. 1 2 3 4 5 6 7 8 9 import io.grpc.Server ; ... private Server server ; ... server = ServerBuilder . forPort ( port ) . addService ( new GreeterImpl ()) . build () . start (); ... Do lado do cliente, \u00e9 criado um ManagedChannel e com este um GreeterBlockingStub , um stub em cujas chamadas s\u00e3o bloqueantes. Finalmente, no stub s\u00e3o invocados os servi\u00e7os definidos na IDL. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import io.grpc.Channel ; import io.grpc.ManagedChannel ; import io.grpc.ManagedChannelBuilder ; ... ManagedChannel channel = ManagedChannelBuilder . forTarget ( target ) . usePlaintext () . build (); ... private final GreeterGrpc . GreeterBlockingStub blockingStub = GreeterGrpc . newBlockingStub ( channel ); ... HelloRequest request = HelloRequest . newBuilder () . setName ( name ) . build (); HelloReply response ; try { response = blockingStub . sayHello ( request ); } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } logger . info ( \"Greeting: \" + response . getMessage ()); Diga Ol\u00e1s! Para fixar o conte\u00fado \u00e9 preciso colocar a m\u00e3o na massa. Estenda a defini\u00e7\u00e3o do servi\u00e7o com uma opera\u00e7\u00e3o DigaOlas em que uma lista de nomes \u00e9 enviada ao servidor e tal que o servidor responda com **uma longa string**cumprimentando todos os nomes, um ap\u00f3s o outro. S\u00f3 abra depois de pensar em como resolver o problema Voc\u00ea pode usar repeated no campo message do tipo HelloRequest . Stream Para terminar este estudo de caso, modifique a fun\u00e7\u00e3o definida no exerc\u00edcio anterior para gerar m\u00faltiplas respostas, uma para cada nome passado, em vez de uma \u00fanica, longa, resposta. S\u00f3 abra depois de pensar em como resolver o problema Voc\u00ea dever\u00e1 usar streams . 1 rpc DigaOlas ( OlaRequest ) returns ( stream OlaReply ) {} Do lado do servidor 1 2 3 4 5 6 7 8 9 10 11 List < String > listOfHi = Arrays . asList ( \"e aih\" , \"ola\" , \"ciao\" , \"bao\" , \"howdy\" , \"s'up\" ); @Override public void digaOlas ( OlaRequest req , StreamObserver < OlaReply > responseObserver ) { for ( String hi : listOfHi ) { OlaReply reply = OlaReply . newBuilder (). setMessage ( hi + \", \" req . getName ()). build (); responseObserver . onNext ( reply ); } responseObserver . onCompleted (); } Do lado do cliente 1 2 3 4 5 6 7 8 9 10 11 OlaRequest request = OlaRequest . newBuilder (). setName ( name ). build (); try { Iterator < OlaReply > it = blockingStub . digaOlas ( request ); while ( it . hasNext ()){ OlaReply response = it . next (); logger . info ( \"Greeting: \" + response . getMessage ()); } } catch ( StatusRuntimeException e ) { logger . log ( Level . WARNING , \"RPC failed: {0}\" , e . getStatus ()); return ; } Desafio de Interoperabilidade Siga o tutorial abaixo e execute use o gRPC em Python. Uma vez executados cliente e servidor, tente fazer com que interaja com a implementa\u00e7\u00e3o em java. 1 2 3 4 5 6 7 8 9 10 apt-get install python3 apt-get install python3-pip python3 -m pip install --upgrade pip python3 -m pip install grpcio python3 -m pip install grpcio-tools git clone -b v1..x https://github.com/grpc/grpc cd grpc/examples/python/helloworld python3 greeter \\_ server.py python3 greeter \\_ client.py Para recompilar os stubs , fa\u00e7a 1 python3 -m grpc_tools.protoc -I../../protos --python_out = . --grpc_python_out = . ../../protos/helloworld.proto Modifique o servidor 1 2 def DigaOla ( self , request , context ): return helloworld_pb2 . OlaReply ( message = 'Ola, %s !' + request . name ) Modifique o cliente 1 2 response = stub . DigaOla ( helloworld_pb2 . OlaRequest ( name = 'zelelele' )) print ( \"Greeter client received: \" + response . message )","title":"Implementando um servi\u00e7o"},{"location":"cases/grpc/#outros-modos-de-trabalho","text":"gRPC \u00e9 um framework bem flex\u00edvel e para entender como \u00e9 poss\u00edvel us\u00e1-lo para estabelecer canais de comunica\u00e7\u00e3o para fluxos, al\u00e9m da documenta\u00e7\u00e3o j\u00e1 apontada, sugiro o artigo gRPC: A Deep Dive into the Communication Pattern , que a detalha.","title":"Outros modos de trabalho"},{"location":"cases/kafka/","text":"Fila de Mensagens/PubSub: Kafka Quote Kafka is a distributed streaming platform. LinkedIn OpenSource em 2011 Projeto Apache em ???? Producers x Message Broker x Consumers Produtores: enviam dados/mensagens/records (array de bytes) Consumidores: recebem dados Cluster/Broker: distribu\u00eddo e tolerantes a falhas. Conectores: integra\u00e7\u00e3o simplificada com outras aplica\u00e7\u00f5es Stream processors: spark ou outros frameworks; transformam dados Brokers Cluster de brokers Distribu\u00eddo Tolerante a falhas Desacoplamento espacial Desacoplamento temporal T\u00f3picos, n\u00e3o endere\u00e7os T\u00f3picos Nome de uma stream de dados: ordem de servi\u00e7o, exame de sangue, MSFT Quantidade pode ser imensa. Parti\u00e7\u00e3o Subdivis\u00f5es de t\u00f3picos N\u00famero de parti\u00e7\u00f5es \u00e9 definido por usu\u00e1rio Cada parti\u00e7\u00e3o est\u00e1 associada a um \u00fanico servidor Offset \u00cdndice de uma mensagem em uma parti\u00e7\u00e3o \u00cdndices atribu\u00eddos na ordem de chegada Offsets s\u00e3o locais \u00e0s parti\u00e7\u00f5es Mensagens s\u00e3o unicamente identificadas por (t\u00f3pico, parti\u00e7\u00e3o, \u00edndice) Consumer group Carga pode ser muito grande para um consumidor Compartilham o processamento de um t\u00f3pico Cada mensagem \u00e9 processada por um membro do grupo A mesma mensagem pode ser processada por m\u00faltiplos grupos N\u00famero de consumidores \\(\\leq\\) parti\u00e7\u00f5es no t\u00f3pico M\u00e1ximo de dois consumidores por parti\u00e7\u00e3o (mantem pos. de cada um) Siga o tutorial , at\u00e9 o passo 5. Baixe e descompacte Rode o zookeeper (Terminal 1) Rode o Kafka (Terminal 2) Crie um t\u00f3pico (Terminal 3) - Mais de uma parti\u00e7\u00e3o em um servidor Conecte-se ao Zookeeper e d\u00ea uma olhada. O que est\u00e1 vendo? Liste os t\u00f3picos criados Envie algumas mensagens Inicie um consumidor (Terminal 4) TODO https://kafka.apache.org/","title":"Kafka"},{"location":"cases/kafka/#fila-de-mensagenspubsub-kafka","text":"Quote Kafka is a distributed streaming platform. LinkedIn OpenSource em 2011 Projeto Apache em ???? Producers x Message Broker x Consumers Produtores: enviam dados/mensagens/records (array de bytes) Consumidores: recebem dados Cluster/Broker: distribu\u00eddo e tolerantes a falhas. Conectores: integra\u00e7\u00e3o simplificada com outras aplica\u00e7\u00f5es Stream processors: spark ou outros frameworks; transformam dados Brokers Cluster de brokers Distribu\u00eddo Tolerante a falhas Desacoplamento espacial Desacoplamento temporal T\u00f3picos, n\u00e3o endere\u00e7os T\u00f3picos Nome de uma stream de dados: ordem de servi\u00e7o, exame de sangue, MSFT Quantidade pode ser imensa. Parti\u00e7\u00e3o Subdivis\u00f5es de t\u00f3picos N\u00famero de parti\u00e7\u00f5es \u00e9 definido por usu\u00e1rio Cada parti\u00e7\u00e3o est\u00e1 associada a um \u00fanico servidor Offset \u00cdndice de uma mensagem em uma parti\u00e7\u00e3o \u00cdndices atribu\u00eddos na ordem de chegada Offsets s\u00e3o locais \u00e0s parti\u00e7\u00f5es Mensagens s\u00e3o unicamente identificadas por (t\u00f3pico, parti\u00e7\u00e3o, \u00edndice) Consumer group Carga pode ser muito grande para um consumidor Compartilham o processamento de um t\u00f3pico Cada mensagem \u00e9 processada por um membro do grupo A mesma mensagem pode ser processada por m\u00faltiplos grupos N\u00famero de consumidores \\(\\leq\\) parti\u00e7\u00f5es no t\u00f3pico M\u00e1ximo de dois consumidores por parti\u00e7\u00e3o (mantem pos. de cada um) Siga o tutorial , at\u00e9 o passo 5. Baixe e descompacte Rode o zookeeper (Terminal 1) Rode o Kafka (Terminal 2) Crie um t\u00f3pico (Terminal 3) - Mais de uma parti\u00e7\u00e3o em um servidor Conecte-se ao Zookeeper e d\u00ea uma olhada. O que est\u00e1 vendo? Liste os t\u00f3picos criados Envie algumas mensagens Inicie um consumidor (Terminal 4) TODO https://kafka.apache.org/","title":"Fila de Mensagens/PubSub: Kafka"},{"location":"cases/mosquito/","text":"Pub/Sub: MQTT e MosQuiTTo MQTT \u00e9 um protocolo de transporte para publish/subscribe do tipo cliente-servidor, definido pela OASIS, uma organiza\u00e7\u00e3o aberta respons\u00e1vel por padr\u00f5es como SAML e DocBook. A especifica\u00e7\u00e3o atual \u00e9 a de n\u00famero 5, lan\u00e7ada em mar\u00e7o de 2019. O protocolo \u00e9 leve, aberto e f\u00e1cil de implementar, ideal para comunica\u00e7\u00e3o Machine to Machine (M2M) e uso no contexto de Internet das Coisas ( Internet of Things - I0T ). MQTT is a very light weight and binary protocol, and due to its minimal packet overhead, MQTT excels when transferring data over the wire in comparison to protocols like HTTP. Another important aspect of the protocol is that MQTT is extremely easy to implement on the client side. Ease of use was a key concern in the development of MQTT and makes it a perfect fit for constrained devices with limited resources today. O Eclipse Mosquitto \u00e9 um broker de c\u00f3digo livre que implementa o protocolo MQTT v5.0, v3.1.1 e v3.1. Por ser m\u00ednimo, o Mosquitto \u00e9 ideal para uso em dispositivos pequenos e com pouca capacidade energ\u00e9tica, como computadores low power single board , mas flex\u00edvel o suficiente para ser usado em aplica\u00e7\u00f5es de larga escala. Instala\u00e7\u00e3o Ubuntu: apt-get install mosquitto MacOS: brew install mosquitto Windows: baixe mosquitto-2.0.9a-install-windows-x64.exe Inicializando o servi\u00e7o O arquivo mosquito.conf cont\u00e9m as configura\u00e7\u00f5es para o broker . As configura\u00e7\u00f5es funcionam bem para o nosso caso. O broker aceita requisi\u00e7\u00f5es na porta 1883 e publishers e subscribers tamb\u00e9m utilizam essa porta por padr\u00e3o. Basta iniciar o broker com a op\u00e7\u00e3o -v para ter mais detalhes sobre o que ocorre internamente. Ubuntu: mosquitto -v MacOS: /usr/local/sbin/mosquitto -c /usr/local/etc/mosquitto/mosquitto.conf Publicando Para publicar uma mensagem, o publisher deve indicar um host, porta, t\u00f3pico e mensagem. Caso o host e porta sejam omitidos, assume-se localhost:1883 . No MacOS, adicione /usr/local/opt/mosquitto/bin/mosquitto_sub ao path . 1 2 3 # publicando valor de 40 para t\u00f3picos 'sensor/temperature/1' e 'sensor/temperature/2' mosquitto_pub -t sensor/temperature/1 -m 40 mosquitto_pub -t sensor/temperature/2 -m 32 Caso o subscriber n\u00e3o esteja em execu\u00e7\u00e3o, adicione a op\u00e7\u00e3o -r para que o broker retenha a mensagem. Consumindo O consumidor funciona de maneira semelhante, informando o t\u00f3pico de interesse: 1 2 # consumindo mensagens de t\u00f3pico /sensor/temperature/* mosquitto_sub -t sensor/temperature/+ Programando Existem tamb\u00e9m APIs em diversas linguagem para desenvolvimento de aplica\u00e7\u00f5es que utilizem o Mosquitto. A biblioteca pode ser baixada aqui . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import org.eclipse.paho.client.mqttv3.MqttClient ; import org.eclipse.paho.client.mqttv3.MqttConnectOptions ; import org.eclipse.paho.client.mqttv3.MqttException ; import org.eclipse.paho.client.mqttv3.MqttMessage ; import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence ; public class MqttPublishSample { public static void main ( String [] args ) { String topic = \"MQTT Examples\" ; String content = \"Message from MqttPublishSample\" ; int qos = 2 ; String broker = \"tcp://mqtt.eclipse.org:1883\" ; String clientId = \"JavaSample\" ; MemoryPersistence persistence = new MemoryPersistence (); try { MqttClient sampleClient = new MqttClient ( broker , clientId , persistence ); MqttConnectOptions connOpts = new MqttConnectOptions (); connOpts . setCleanSession ( true ); System . out . println ( \"Connecting to broker: \" + broker ); sampleClient . connect ( connOpts ); System . out . println ( \"Connected\" ); System . out . println ( \"Publishing message: \" + content ); MqttMessage message = new MqttMessage ( content . getBytes ()); message . setQos ( qos ); sampleClient . publish ( topic , message ); System . out . println ( \"Message published\" ); sampleClient . disconnect (); System . out . println ( \"Disconnected\" ); System . exit ( 0 ); } catch ( MqttException me ) { System . out . println ( \"reason \" + me . getReasonCode ()); System . out . println ( \"msg \" + me . getMessage ()); System . out . println ( \"loc \" + me . getLocalizedMessage ()); System . out . println ( \"cause \" + me . getCause ()); System . out . println ( \"excep \" + me ); me . printStackTrace (); } } } Hive /usr/local/opt/mosquitto/bin/mosquitto_sub -h broker.hivemq.com -p 1883 -t esportes/+/flamengo /usr/local/opt/mosquitto/bin/mosquitto_pub -t esportes/nadacao/flamengo -m \"perdeu mais uma vez\" -r -h broker.hivemq.com Exerc\u00edcios - RPC e Publish/Subscribe Usando thrift e a linguagem Java, estenda o servi\u00e7o ChaveValor para retornar o valor antigo de uma determinada chave na opera\u00e7\u00e3o setKV() caso a chave j\u00e1 exista. Usando o broker mosquitto instalado localmente, fa\u00e7a em Java um publisher que simula um sensor de temperatura e publica valores aleat\u00f3rios entre 15 e 45 a cada segundo. Fa\u00e7a o subscriber que ir\u00e1 consumir esses dados de temperatura. Refer\u00eancias MQTT Essentials MQTT Client in Java Thrift Tutorial","title":"Mosquito"},{"location":"cases/mosquito/#pubsub-mqtt-e-mosquitto","text":"MQTT \u00e9 um protocolo de transporte para publish/subscribe do tipo cliente-servidor, definido pela OASIS, uma organiza\u00e7\u00e3o aberta respons\u00e1vel por padr\u00f5es como SAML e DocBook. A especifica\u00e7\u00e3o atual \u00e9 a de n\u00famero 5, lan\u00e7ada em mar\u00e7o de 2019. O protocolo \u00e9 leve, aberto e f\u00e1cil de implementar, ideal para comunica\u00e7\u00e3o Machine to Machine (M2M) e uso no contexto de Internet das Coisas ( Internet of Things - I0T ). MQTT is a very light weight and binary protocol, and due to its minimal packet overhead, MQTT excels when transferring data over the wire in comparison to protocols like HTTP. Another important aspect of the protocol is that MQTT is extremely easy to implement on the client side. Ease of use was a key concern in the development of MQTT and makes it a perfect fit for constrained devices with limited resources today. O Eclipse Mosquitto \u00e9 um broker de c\u00f3digo livre que implementa o protocolo MQTT v5.0, v3.1.1 e v3.1. Por ser m\u00ednimo, o Mosquitto \u00e9 ideal para uso em dispositivos pequenos e com pouca capacidade energ\u00e9tica, como computadores low power single board , mas flex\u00edvel o suficiente para ser usado em aplica\u00e7\u00f5es de larga escala.","title":"Pub/Sub: MQTT e MosQuiTTo"},{"location":"cases/mosquito/#referencias","text":"MQTT Essentials MQTT Client in Java Thrift Tutorial","title":"Refer\u00eancias"},{"location":"cases/ratis/","text":"Coordena\u00e7\u00e3o: Ratis Ratis \u00e9 um arcabou\u00e7o de coordena\u00e7\u00e3o recentemente emancipado como um projeto no Apache . Embora mal documentado, o projeto tem alguns exemplos que demonstram como usar abstra\u00e7\u00f5es j\u00e1 implementadas. A seguir veremos um passo-a-passo, baseado nestes exemplos, de como usar o Ratis para implementar uma m\u00e1quina de estados replicada. Crie um novo projeto Maven com o nome ChaveValor (eu estou usando IntelliJ, mas as instru\u00e7\u00f5es devem ser semelhantes para Eclipse). Abra o arquivo pom.xml do seu projeto e adicione o seguinte trecho, com as depend\u00eancias do projeto, incluindo o pr\u00f3prio Ratis. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 <dependencies> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-server --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-server </artifactId> <version> 2.0.0 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-netty --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-netty </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-grpc </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> com.beust </groupId> <artifactId> jcommander </artifactId> <version> 1.78 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> 1.7.25 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-slf4j-impl --> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-slf4j-impl </artifactId> <version> 2.14.1 </version> <scope> compile </scope> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-api </artifactId> <version> 2.14.1 </version> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-core </artifactId> <version> 2.14.1 </version> <scope> provided </scope> </dependency> </dependencies> Adicione tamb\u00e9m o plugin Maven e o plugin para gerar um .jar com todas as depend\u00eancias. Observe que estou usando Java 14, mas voc\u00ea pode mudar para a sua vers\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> ${maven.compiler.version} </version> <configuration> <source> 14 </source> <target> 14 </target> </configuration> </plugin> <plugin> <artifactId> maven-assembly-plugin </artifactId> <executions> <execution> <phase> package </phase> <goals> <goal> single </goal> </goals> </execution> </executions> <configuration> <descriptorRefs> <descriptorRef> jar-with-dependencies </descriptorRef> </descriptorRefs> </configuration> </plugin> </plugins> </build> Crie uma nova classe denominada Cliente no arquivo Cliente.java . Nesta classe, iremos criar um objeto RaftClient que ser\u00e1 usado para enviar opera\u00e7\u00f5es para os servidores. Esta classe \u00e9 importada juntamente com outras v\u00e1rias depend\u00eancias, adicionadas no pom.xml , que devemos instanciar antes do RaftClient . Neste exemplo eu coloco praticamente todos os par\u00e2metros de configura\u00e7\u00e3o do Ratis hardcoded para simplificar o c\u00f3digo. Obviamente que voce deveria ser estes par\u00e2metros como argumentos para o programa ou de um arquivo de configura\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.apache.ratis.client.RaftClient ; import org.apache.ratis.conf.Parameters ; import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcFactory ; import org.apache.ratis.protocol.* ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.nio.charset.Charset ; import java.util.HashMap ; import java.util.Map ; public class Cliente { O campo raftGroupId identifica um cluster Ratis; isso quer dizer que um mesmo processo pode participar de v\u00e1rios clusters , mas aqui nos focaremos em apenas um. O valor do campo deve ter exatamente caracteres, o que soma 32 bytes em java, e ser\u00e1 interpretado como um UUID . id2addr \u00e9 um mapa do identificador de cada processo no cluster para seu endere\u00e7o IP + Porta. Aqui usei v\u00e1rias portas distintas porqu\u00ea todos os processos est\u00e3o rodando na mesma m\u00e1quina, mas se estivesse executando em m\u00e1quinas distintas, com IP distintos, poderia usar a mesma porta em todos. addresses \u00e9 uma lista de RaftPeer constru\u00edda a parti de id2addr . O campo raftGroup \u00e9 uma refer\u00eancia a todos os servidores, associados ao identificador do grupo, raftGroupId . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void main ( String args [] ) throws IOException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), addresses ); Uma vez criado o grupo, criamos o cliente usando a f\u00e1brica retornada por RaftClient.newBuilder() . A f\u00e1brica deve ser configurada com os dados do grupo e o tipo de transporte, neste caso gRPC. Tamb\u00e9m \u00e9 necess\u00e1rio o identificador do processo que est\u00e1 se conectando ao grupo; neste caso, usamos um identificador aleat\u00f3rio qualquer, diferente do que faremos com os servidores. 1 2 3 4 5 6 7 8 RaftProperties raftProperties = new RaftProperties (); RaftClient client = RaftClient . newBuilder () . setProperties ( raftProperties ) . setRaftGroup ( raftGroup ) . setClientRpc ( new GrpcFactory ( new Parameters ()) . newRaftClientRpc ( ClientId . randomId (), raftProperties )) . build (); Uma vez criado o cliente, podemos fazer invoca\u00e7\u00f5es de opera\u00e7\u00f5es nos servidores. Cada opera\u00e7\u00e3o ser\u00e1 invocada em todos os servidores, na mesma ordem. Este prot\u00f3tipo suporta duas opera\u00e7\u00f5es, add e get , incluindo algumas varia\u00e7\u00f5es, que ignoraremos por enquanto. A opera\u00e7\u00e3o add \u00e9 codificada como uma String , add:k:v , onde k e v s\u00e3o do tipo String . add:k:v adiciona uma entrada em um mapa implementado pelo nosso servidor com chave k e valor v . J\u00e1 a opera\u00e7\u00e3o get:k recupera o valor v associado \u00e0 chave k , se presente no mapa. O m\u00e9todo RaftClient.io().send \u00e9 usado para enviar modifica\u00e7\u00f5es para as r\u00e9plicas e deve, necessariamente, passar pelo protocolo Raft. J\u00e1 o m\u00e9todo RaftClient.io().sendReadOnly \u00e9 usado para enviar consultas a qualquer das r\u00e9plicas. Ambos os m\u00e9todos codificam o comando sendo enviado ( add:k:v ou get:k ) no formato interno do Ratis para as r\u00e9plicas e retorna um objeto RaftClientReply , que pode ser usado para pegar a resposta da opera\u00e7\u00e3o. O c\u00f3digo \u00e9 auto explicativo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 RaftClientReply getValue ; CompletableFuture < RaftClientReply > compGetValue ; String response ; switch ( args [ 0 ] ){ case \"add\" : getValue = client . io (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"get\" : getValue = client . io (). sendReadOnly ( Message . valueOf ( \"get:\" + args [ 1 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"add_async\" : compGetValue = client . async (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); getValue = compGetValue . get (); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; case \"get_stale\" : getValue = client . io (). sendStaleRead ( Message . valueOf ( \"get:\" + args [ 1 ] ), 0 , RaftPeerId . valueOf ( args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; default : System . out . println ( \"comando inv\u00e1lido\" ); } client . close (); } } Um vez criado o cliente, crie a classe Servidor , no arquivo Servidor.java ; a parte inicial do c\u00f3digo \u00e9 semelhante \u00e0 do cliente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcConfigKeys ; import org.apache.ratis.protocol.RaftGroup ; import org.apache.ratis.protocol.RaftGroupId ; import org.apache.ratis.protocol.RaftPeer ; import org.apache.ratis.protocol.RaftPeerId ; import org.apache.ratis.server.RaftServer ; import org.apache.ratis.server.RaftServerConfigKeys ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import org.apache.ratis.util.LifeCycle ; import java.io.File ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.util.Collections ; import java.util.HashMap ; import java.util.Map ; import java.util.concurrent.TimeUnit ; public class Servidor { //Parametros: myId public static void main ( String args [] ) throws IOException , InterruptedException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. //Setup for node all nodes. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); A primeira diferen\u00e7a vem na necessidade de identificar o servidor dentro do conjunto de servidores, o que \u00e9 feito com um RaftPeerId . Como cada servidor deve usar um identificador \u00fanico, do conjunto pr\u00e9-determinado em id2addr , o identificador \u00e9 passado como argumento para o programa, obrigatoriamente. 1 2 3 4 5 6 7 8 //Setup for this node. RaftPeerId myId = RaftPeerId . valueOf ( args [ 0 ] ); if ( addresses . stream (). noneMatch ( p -> p . getId (). equals ( myId ))) { System . out . println ( \"Identificador \" + args [ 0 ] + \" \u00e9 inv\u00e1lido.\" ); System . exit ( 1 ); } Encare a se\u00e7\u00e3o seguinte como uma receita, mas observe que o m\u00e9todo RaftServerConfigKeys.setStorageDir recebe o nome de uma pasta como argumento, que ser\u00e1 usada para armazenar o estado da m\u00e1quina de estados. Se voc\u00ea executar o servidor m\u00faltiplas vezes, a cada nova execu\u00e7\u00e3o o estado anterior do sistema ser\u00e1 recuperado desta pasta. Para limpar o estado, apague as pastas de cada servidor. 1 2 3 4 RaftProperties properties = new RaftProperties (); properties . setInt ( GrpcConfigKeys . OutputStream . RETRY_TIMES_KEY , Integer . MAX_VALUE ); GrpcConfigKeys . Server . setPort ( properties , 1000 ); RaftServerConfigKeys . setStorageDir ( properties , Collections . singletonList ( new File ( \"/tmp/\" + myId ))); A m\u00e1quina de estados em si \u00e9 especificada no pr\u00f3ximo excerto, em setStateMachine , que veremos a seguir. 1 2 3 4 5 6 7 8 9 //Join the group of processes. final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), id2addr ); RaftServer raftServer = RaftServer . newBuilder () . setServerId ( myId ) . setStateMachine ( new MaquinaDeEstados ()) . setProperties ( properties ) . setGroup ( raftGroup ) . build (); raftServer . start (); Uma vez iniciado o servidor, basta esperar que ele termine antes de sair do programa. 1 2 3 4 5 while ( raftServer . getLifeCycleState () != LifeCycle . State . CLOSED ) { TimeUnit . SECONDS . sleep ( 1 ); } } } Vamos agora para a defini\u00e7\u00e3o da classe MaquinaDeEstados , no arquivo MaquinaDeEstados.java . Esta classe deve implementar a interface org.apache.ratis.statemachine.StateMachine e seus v\u00e1rios m\u00e9todos ou, mais simples, estende org.apache.ratis.statemachine.impl.BaseStateMachine , a abordagem que usaremos aqui. 1 2 public class MaquinaDeEstados extends BaseStateMachine { Por enquanto, ignoraremos o armazenamento do estado em disco, mantendo-o simplesmente em mem\u00f3ria no campo key2values , e simplesmente implementaremos o processamento de comandos, come\u00e7ando pela implementa\u00e7\u00e3o do m\u00e9todo query . Este m\u00e9todo \u00e9 repons\u00e1vel por implementar opera\u00e7\u00f5es que n\u00e3o alteram o estado da m\u00e1quina de estados, enviadas com o m\u00e9todo RaftClient::sendReadOnly . A \u00fanica query no nosso sistema \u00e9 o get . No c\u00f3digo, o conte\u00fado da requisi\u00e7\u00e3o enviada pelo cliente deve ser recuperado em quebrado em opera\u00e7\u00e3o ( get ) e chave , usando : como delimitador. Recuperado o valor associado \u00e0 chave, o mesmo \u00e9 colocado em um CompletableFuture e retornado. 1 2 3 4 5 6 7 8 9 10 private final Map < String , String > key2values = new ConcurrentHashMap <> (); @Override public CompletableFuture < Message > query ( Message request ) { final String [] opKey = request . getContent (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKey [ 0 ]+ \":\" + key2values . get ( opKey [ 1 ] ); LOG . debug ( \"{}: {} = {}\" , opKey [ 0 ] , opKey [ 1 ] , result ); return CompletableFuture . completedFuture ( Message . valueOf ( result )); } O m\u00e9todo applyTransaction implementa opera\u00e7\u00f5es que alteram o estado, como add , enviadas com o m\u00e9todo RaftClient::send . Da mesma forma que em get , a opera\u00e7\u00e3o deve ser recuperada em quebrada em opera\u00e7\u00e3o ( add ), chave e valor, usando : como delimitador. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableFuture < Message > applyTransaction ( TransactionContext trx ) { final RaftProtos . LogEntryProto entry = trx . getLogEntry (); final String [] opKeyValue = entry . getStateMachineLogEntry (). getLogData (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKeyValue [ 0 ]+ \":\" + key2values . put ( opKeyValue [ 1 ] , opKeyValue [ 2 ] ); final CompletableFuture < Message > f = CompletableFuture . completedFuture ( Message . valueOf ( result )); final RaftProtos . RaftPeerRole role = trx . getServerRole (); LOG . info ( \"{}:{} {} {}={}\" , role , getId (), opKeyValue [ 0 ] , opKeyValue [ 1 ] , opKeyValue [ 2 ] ); return f ; } Pronto, voc\u00ea j\u00e1 tem uma m\u00e1quina de estados replicada, bastando agora apenas compil\u00e1-la e execut\u00e1-la. Para compilar, de raiz do projeto execute o comando mvn package . A primeira vez que faz isso pode demorar um pouco pois v\u00e1rias depend\u00eancias s\u00e3o baixadas da Internet. Ao final da execu\u00e7\u00e3o do comando voc\u00ea deveria ver algo semelhante ao seguinte 1 2 3 4 5 6 7 ... INFO ] ------------------------------------------------------------------------ [ INFO ] BUILD SUCCESS [ INFO ] ------------------------------------------------------------------------ [ INFO ] Total time: 4 .793 s [ INFO ] Finished at: 2020 -12-06T23:06:32-03:00 [ INFO ] ------------------------------------------------------------------------ Ent\u00e3o, em tr\u00eas terminais diferentes, execute os seguintes comandos: 1 2 3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p2 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p3 Para executar o cliente, em um outro terminal, fa\u00e7a, por exemplo, 1 2 3 4 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k1 testek1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get k1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k2 testek2 Todo o c\u00f3digo est\u00e1 dispon\u00edvel no Github Exerc\u00edcio Adicionar opera\u00e7\u00f5es del clear Opera\u00e7\u00f5es ass\u00edncronas TODO Opera\u00e7\u00f5es ass\u00edncronas usando async() em vez de io() . CompletableFuture Leituras \"velhas\" TODO stale reads usando sendStaleRead em vez de sendRead . \u00edndice inicial n\u00f3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get_stale k1 p1","title":"Ratis"},{"location":"cases/ratis/#coordenacao-ratis","text":"Ratis \u00e9 um arcabou\u00e7o de coordena\u00e7\u00e3o recentemente emancipado como um projeto no Apache . Embora mal documentado, o projeto tem alguns exemplos que demonstram como usar abstra\u00e7\u00f5es j\u00e1 implementadas. A seguir veremos um passo-a-passo, baseado nestes exemplos, de como usar o Ratis para implementar uma m\u00e1quina de estados replicada. Crie um novo projeto Maven com o nome ChaveValor (eu estou usando IntelliJ, mas as instru\u00e7\u00f5es devem ser semelhantes para Eclipse). Abra o arquivo pom.xml do seu projeto e adicione o seguinte trecho, com as depend\u00eancias do projeto, incluindo o pr\u00f3prio Ratis. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 <dependencies> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-server --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-server </artifactId> <version> 2.0.0 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.ratis/ratis-netty --> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-netty </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> org.apache.ratis </groupId> <artifactId> ratis-grpc </artifactId> <version> 2.0.0 </version> </dependency> <dependency> <groupId> com.beust </groupId> <artifactId> jcommander </artifactId> <version> 1.78 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> 1.7.25 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-slf4j-impl --> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-slf4j-impl </artifactId> <version> 2.14.1 </version> <scope> compile </scope> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-api </artifactId> <version> 2.14.1 </version> </dependency> <dependency> <groupId> org.apache.logging.log4j </groupId> <artifactId> log4j-core </artifactId> <version> 2.14.1 </version> <scope> provided </scope> </dependency> </dependencies> Adicione tamb\u00e9m o plugin Maven e o plugin para gerar um .jar com todas as depend\u00eancias. Observe que estou usando Java 14, mas voc\u00ea pode mudar para a sua vers\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> ${maven.compiler.version} </version> <configuration> <source> 14 </source> <target> 14 </target> </configuration> </plugin> <plugin> <artifactId> maven-assembly-plugin </artifactId> <executions> <execution> <phase> package </phase> <goals> <goal> single </goal> </goals> </execution> </executions> <configuration> <descriptorRefs> <descriptorRef> jar-with-dependencies </descriptorRef> </descriptorRefs> </configuration> </plugin> </plugins> </build> Crie uma nova classe denominada Cliente no arquivo Cliente.java . Nesta classe, iremos criar um objeto RaftClient que ser\u00e1 usado para enviar opera\u00e7\u00f5es para os servidores. Esta classe \u00e9 importada juntamente com outras v\u00e1rias depend\u00eancias, adicionadas no pom.xml , que devemos instanciar antes do RaftClient . Neste exemplo eu coloco praticamente todos os par\u00e2metros de configura\u00e7\u00e3o do Ratis hardcoded para simplificar o c\u00f3digo. Obviamente que voce deveria ser estes par\u00e2metros como argumentos para o programa ou de um arquivo de configura\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.apache.ratis.client.RaftClient ; import org.apache.ratis.conf.Parameters ; import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcFactory ; import org.apache.ratis.protocol.* ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.nio.charset.Charset ; import java.util.HashMap ; import java.util.Map ; public class Cliente { O campo raftGroupId identifica um cluster Ratis; isso quer dizer que um mesmo processo pode participar de v\u00e1rios clusters , mas aqui nos focaremos em apenas um. O valor do campo deve ter exatamente caracteres, o que soma 32 bytes em java, e ser\u00e1 interpretado como um UUID . id2addr \u00e9 um mapa do identificador de cada processo no cluster para seu endere\u00e7o IP + Porta. Aqui usei v\u00e1rias portas distintas porqu\u00ea todos os processos est\u00e3o rodando na mesma m\u00e1quina, mas se estivesse executando em m\u00e1quinas distintas, com IP distintos, poderia usar a mesma porta em todos. addresses \u00e9 uma lista de RaftPeer constru\u00edda a parti de id2addr . O campo raftGroup \u00e9 uma refer\u00eancia a todos os servidores, associados ao identificador do grupo, raftGroupId . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void main ( String args [] ) throws IOException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), addresses ); Uma vez criado o grupo, criamos o cliente usando a f\u00e1brica retornada por RaftClient.newBuilder() . A f\u00e1brica deve ser configurada com os dados do grupo e o tipo de transporte, neste caso gRPC. Tamb\u00e9m \u00e9 necess\u00e1rio o identificador do processo que est\u00e1 se conectando ao grupo; neste caso, usamos um identificador aleat\u00f3rio qualquer, diferente do que faremos com os servidores. 1 2 3 4 5 6 7 8 RaftProperties raftProperties = new RaftProperties (); RaftClient client = RaftClient . newBuilder () . setProperties ( raftProperties ) . setRaftGroup ( raftGroup ) . setClientRpc ( new GrpcFactory ( new Parameters ()) . newRaftClientRpc ( ClientId . randomId (), raftProperties )) . build (); Uma vez criado o cliente, podemos fazer invoca\u00e7\u00f5es de opera\u00e7\u00f5es nos servidores. Cada opera\u00e7\u00e3o ser\u00e1 invocada em todos os servidores, na mesma ordem. Este prot\u00f3tipo suporta duas opera\u00e7\u00f5es, add e get , incluindo algumas varia\u00e7\u00f5es, que ignoraremos por enquanto. A opera\u00e7\u00e3o add \u00e9 codificada como uma String , add:k:v , onde k e v s\u00e3o do tipo String . add:k:v adiciona uma entrada em um mapa implementado pelo nosso servidor com chave k e valor v . J\u00e1 a opera\u00e7\u00e3o get:k recupera o valor v associado \u00e0 chave k , se presente no mapa. O m\u00e9todo RaftClient.io().send \u00e9 usado para enviar modifica\u00e7\u00f5es para as r\u00e9plicas e deve, necessariamente, passar pelo protocolo Raft. J\u00e1 o m\u00e9todo RaftClient.io().sendReadOnly \u00e9 usado para enviar consultas a qualquer das r\u00e9plicas. Ambos os m\u00e9todos codificam o comando sendo enviado ( add:k:v ou get:k ) no formato interno do Ratis para as r\u00e9plicas e retorna um objeto RaftClientReply , que pode ser usado para pegar a resposta da opera\u00e7\u00e3o. O c\u00f3digo \u00e9 auto explicativo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 RaftClientReply getValue ; CompletableFuture < RaftClientReply > compGetValue ; String response ; switch ( args [ 0 ] ){ case \"add\" : getValue = client . io (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"get\" : getValue = client . io (). sendReadOnly ( Message . valueOf ( \"get:\" + args [ 1 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta:\" + response ); break ; case \"add_async\" : compGetValue = client . async (). send ( Message . valueOf ( \"add:\" + args [ 1 ] + \":\" + args [ 2 ] )); getValue = compGetValue . get (); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; case \"get_stale\" : getValue = client . io (). sendStaleRead ( Message . valueOf ( \"get:\" + args [ 1 ] ), 0 , RaftPeerId . valueOf ( args [ 2 ] )); response = getValue . getMessage (). getContent (). toString ( Charset . defaultCharset ()); System . out . println ( \"Resposta: \" + response ); break ; default : System . out . println ( \"comando inv\u00e1lido\" ); } client . close (); } } Um vez criado o cliente, crie a classe Servidor , no arquivo Servidor.java ; a parte inicial do c\u00f3digo \u00e9 semelhante \u00e0 do cliente. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import org.apache.ratis.conf.RaftProperties ; import org.apache.ratis.grpc.GrpcConfigKeys ; import org.apache.ratis.protocol.RaftGroup ; import org.apache.ratis.protocol.RaftGroupId ; import org.apache.ratis.protocol.RaftPeer ; import org.apache.ratis.protocol.RaftPeerId ; import org.apache.ratis.server.RaftServer ; import org.apache.ratis.server.RaftServerConfigKeys ; import org.apache.ratis.thirdparty.com.google.protobuf.ByteString ; import org.apache.ratis.util.LifeCycle ; import java.io.File ; import java.io.IOException ; import java.net.InetSocketAddress ; import java.util.Collections ; import java.util.HashMap ; import java.util.Map ; import java.util.concurrent.TimeUnit ; public class Servidor { //Parametros: myId public static void main ( String args [] ) throws IOException , InterruptedException { String raftGroupId = \"raft_group____um\" ; // 16 caracteres. //Setup for node all nodes. Map < String , InetSocketAddress > id2addr = new HashMap <> (); id2addr . put ( \"p1\" , new InetSocketAddress ( \"127.0.0.1\" , 3000 )); id2addr . put ( \"p2\" , new InetSocketAddress ( \"127.0.0.1\" , 3500 )); id2addr . put ( \"p3\" , new InetSocketAddress ( \"127.0.0.1\" , 4000 )); List < RaftPeer > addresses = id2addr . entrySet () . stream () . map ( e -> RaftPeer . newBuilder (). setId ( e . getKey ()). setAddress ( e . getValue ()). build ()) . collect ( Collectors . toList ()); A primeira diferen\u00e7a vem na necessidade de identificar o servidor dentro do conjunto de servidores, o que \u00e9 feito com um RaftPeerId . Como cada servidor deve usar um identificador \u00fanico, do conjunto pr\u00e9-determinado em id2addr , o identificador \u00e9 passado como argumento para o programa, obrigatoriamente. 1 2 3 4 5 6 7 8 //Setup for this node. RaftPeerId myId = RaftPeerId . valueOf ( args [ 0 ] ); if ( addresses . stream (). noneMatch ( p -> p . getId (). equals ( myId ))) { System . out . println ( \"Identificador \" + args [ 0 ] + \" \u00e9 inv\u00e1lido.\" ); System . exit ( 1 ); } Encare a se\u00e7\u00e3o seguinte como uma receita, mas observe que o m\u00e9todo RaftServerConfigKeys.setStorageDir recebe o nome de uma pasta como argumento, que ser\u00e1 usada para armazenar o estado da m\u00e1quina de estados. Se voc\u00ea executar o servidor m\u00faltiplas vezes, a cada nova execu\u00e7\u00e3o o estado anterior do sistema ser\u00e1 recuperado desta pasta. Para limpar o estado, apague as pastas de cada servidor. 1 2 3 4 RaftProperties properties = new RaftProperties (); properties . setInt ( GrpcConfigKeys . OutputStream . RETRY_TIMES_KEY , Integer . MAX_VALUE ); GrpcConfigKeys . Server . setPort ( properties , 1000 ); RaftServerConfigKeys . setStorageDir ( properties , Collections . singletonList ( new File ( \"/tmp/\" + myId ))); A m\u00e1quina de estados em si \u00e9 especificada no pr\u00f3ximo excerto, em setStateMachine , que veremos a seguir. 1 2 3 4 5 6 7 8 9 //Join the group of processes. final RaftGroup raftGroup = RaftGroup . valueOf ( RaftGroupId . valueOf ( ByteString . copyFromUtf8 ( raftGroupId )), id2addr ); RaftServer raftServer = RaftServer . newBuilder () . setServerId ( myId ) . setStateMachine ( new MaquinaDeEstados ()) . setProperties ( properties ) . setGroup ( raftGroup ) . build (); raftServer . start (); Uma vez iniciado o servidor, basta esperar que ele termine antes de sair do programa. 1 2 3 4 5 while ( raftServer . getLifeCycleState () != LifeCycle . State . CLOSED ) { TimeUnit . SECONDS . sleep ( 1 ); } } } Vamos agora para a defini\u00e7\u00e3o da classe MaquinaDeEstados , no arquivo MaquinaDeEstados.java . Esta classe deve implementar a interface org.apache.ratis.statemachine.StateMachine e seus v\u00e1rios m\u00e9todos ou, mais simples, estende org.apache.ratis.statemachine.impl.BaseStateMachine , a abordagem que usaremos aqui. 1 2 public class MaquinaDeEstados extends BaseStateMachine { Por enquanto, ignoraremos o armazenamento do estado em disco, mantendo-o simplesmente em mem\u00f3ria no campo key2values , e simplesmente implementaremos o processamento de comandos, come\u00e7ando pela implementa\u00e7\u00e3o do m\u00e9todo query . Este m\u00e9todo \u00e9 repons\u00e1vel por implementar opera\u00e7\u00f5es que n\u00e3o alteram o estado da m\u00e1quina de estados, enviadas com o m\u00e9todo RaftClient::sendReadOnly . A \u00fanica query no nosso sistema \u00e9 o get . No c\u00f3digo, o conte\u00fado da requisi\u00e7\u00e3o enviada pelo cliente deve ser recuperado em quebrado em opera\u00e7\u00e3o ( get ) e chave , usando : como delimitador. Recuperado o valor associado \u00e0 chave, o mesmo \u00e9 colocado em um CompletableFuture e retornado. 1 2 3 4 5 6 7 8 9 10 private final Map < String , String > key2values = new ConcurrentHashMap <> (); @Override public CompletableFuture < Message > query ( Message request ) { final String [] opKey = request . getContent (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKey [ 0 ]+ \":\" + key2values . get ( opKey [ 1 ] ); LOG . debug ( \"{}: {} = {}\" , opKey [ 0 ] , opKey [ 1 ] , result ); return CompletableFuture . completedFuture ( Message . valueOf ( result )); } O m\u00e9todo applyTransaction implementa opera\u00e7\u00f5es que alteram o estado, como add , enviadas com o m\u00e9todo RaftClient::send . Da mesma forma que em get , a opera\u00e7\u00e3o deve ser recuperada em quebrada em opera\u00e7\u00e3o ( add ), chave e valor, usando : como delimitador. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableFuture < Message > applyTransaction ( TransactionContext trx ) { final RaftProtos . LogEntryProto entry = trx . getLogEntry (); final String [] opKeyValue = entry . getStateMachineLogEntry (). getLogData (). toString ( Charset . defaultCharset ()). split ( \":\" ); final String result = opKeyValue [ 0 ]+ \":\" + key2values . put ( opKeyValue [ 1 ] , opKeyValue [ 2 ] ); final CompletableFuture < Message > f = CompletableFuture . completedFuture ( Message . valueOf ( result )); final RaftProtos . RaftPeerRole role = trx . getServerRole (); LOG . info ( \"{}:{} {} {}={}\" , role , getId (), opKeyValue [ 0 ] , opKeyValue [ 1 ] , opKeyValue [ 2 ] ); return f ; } Pronto, voc\u00ea j\u00e1 tem uma m\u00e1quina de estados replicada, bastando agora apenas compil\u00e1-la e execut\u00e1-la. Para compilar, de raiz do projeto execute o comando mvn package . A primeira vez que faz isso pode demorar um pouco pois v\u00e1rias depend\u00eancias s\u00e3o baixadas da Internet. Ao final da execu\u00e7\u00e3o do comando voc\u00ea deveria ver algo semelhante ao seguinte 1 2 3 4 5 6 7 ... INFO ] ------------------------------------------------------------------------ [ INFO ] BUILD SUCCESS [ INFO ] ------------------------------------------------------------------------ [ INFO ] Total time: 4 .793 s [ INFO ] Finished at: 2020 -12-06T23:06:32-03:00 [ INFO ] ------------------------------------------------------------------------ Ent\u00e3o, em tr\u00eas terminais diferentes, execute os seguintes comandos: 1 2 3 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p2 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Servidor p3 Para executar o cliente, em um outro terminal, fa\u00e7a, por exemplo, 1 2 3 4 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k1 testek1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente get k1 java -cp target/ChaveValor-1.0-SNAPSHOT-jar-with-dependencies.jar Cliente add k2 testek2 Todo o c\u00f3digo est\u00e1 dispon\u00edvel no Github Exerc\u00edcio Adicionar opera\u00e7\u00f5es del clear","title":"Coordena\u00e7\u00e3o: Ratis"},{"location":"cases/refs/","text":"Refer\u00eancias What is gRPC: introduction Thrift: the missing guide MQTT Essentials MQTT Client in Java Thrift Tutorial","title":"Refer\u00eancias"},{"location":"cases/refs/#referencias","text":"What is gRPC: introduction Thrift: the missing guide MQTT Essentials MQTT Client in Java Thrift Tutorial","title":"Refer\u00eancias"},{"location":"cases/rmi/","text":"RPC: Remote Method Invocation TODO Como usar RMI.","title":"RMI"},{"location":"cases/rmi/#rpc-remote-method-invocation","text":"TODO Como usar RMI.","title":"RPC: Remote Method Invocation"},{"location":"cases/swim/","text":"","title":"Swim"},{"location":"cases/thrift/","text":"RPC: Thrift Thrift Instala\u00e7\u00e3o Baixe e compile o thrift ou instale-o usando apt-get, por exemplo. apt-get install thrift-compiler execute \"thrift\" na linha de comando. Para thrift com Java, tamb\u00e9m precisar\u00e3o dos seguintes arquivos slf4j libthrift0.13.0.jar coloque-os na pasta jars IDL Thrift Servi\u00e7os 1 2 3 4 5 service ChaveValor { void set ( 1 : i32 key , 2 : string value ), string get ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), void delete ( 1 : i32 key ) } N\u00e3o se pode retornar NULL!!! Exce\u00e7\u00f5es 1 2 3 4 exception KeyNotFound { 1 : i64 hora r , 2 : string chaveProcurada = \"thrifty\" } Exemplo: chavevalor.thrift 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } Compila\u00e7\u00e3o thrift --gen java chavevalor.thrift thrift --gen py chavevalor.thrift ChaveValorHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } package chavevalor ; import org.apache.thrift.TException ; import java.util.HashMap ; import chavevalor.* ; public class ChaveValorHandler implements ChaveValor . Iface { private HashMap < Integer , String > kv = new HashMap <> (); @Override public String getKV ( int key ) throws TException { if ( kv . containsKey ( key )) return kv . get ( key ); else throw new KeyNotFound (); } @Override public boolean setKV ( int key , String valor ) throws TException { kv . put ( key , valor ); return true ; } @Override public void delKV ( int key ) throws TException { kv . remove ( key ); } } Arquitetura Runtime library -- componentes podem ser selecionados em tempo de execu\u00e7\u00e3o e implementa\u00e7\u00f5es podem ser trocadas Protocol -- respons\u00e1vel pela serializa\u00e7\u00e3oo dos dados TBinaryProtocol TJSONProtocol TDebugProtocol ... Transport -- I/O no ``fio'' TSocket TFramedTransport (non-blocking server) TFileTransport TMemoryTransport Processor -- Conecta protocolos de entrada e sa\u00edda com o \\emph{handler} Handler -- Implementa\u00e7\u00e3o das opera\u00e7\u00f5es oferecidas Server -- Escuta portas e repassa dados (protocolo) para o processors TSimpleServer TThreadPool TNonBlockingChannel Classpath 1 2 3 javac -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java -d . *.java java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorServer java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorClient","title":"Thrift"},{"location":"cases/thrift/#rpc-thrift","text":"Thrift","title":"RPC: Thrift"},{"location":"cases/thrift/#instalacao","text":"Baixe e compile o thrift ou instale-o usando apt-get, por exemplo. apt-get install thrift-compiler execute \"thrift\" na linha de comando. Para thrift com Java, tamb\u00e9m precisar\u00e3o dos seguintes arquivos slf4j libthrift0.13.0.jar coloque-os na pasta jars","title":"Instala\u00e7\u00e3o"},{"location":"cases/thrift/#idl-thrift","text":"Servi\u00e7os 1 2 3 4 5 service ChaveValor { void set ( 1 : i32 key , 2 : string value ), string get ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), void delete ( 1 : i32 key ) } N\u00e3o se pode retornar NULL!!! Exce\u00e7\u00f5es 1 2 3 4 exception KeyNotFound { 1 : i64 hora r , 2 : string chaveProcurada = \"thrifty\" } Exemplo: chavevalor.thrift 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } Compila\u00e7\u00e3o thrift --gen java chavevalor.thrift thrift --gen py chavevalor.thrift ChaveValorHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV ( 1 : i32 key ) throws ( 1 : KeyNotFound knf ), bool setKV ( 1 : i32 key , 2 : string value ), void delKV ( 1 : i32 key ) } package chavevalor ; import org.apache.thrift.TException ; import java.util.HashMap ; import chavevalor.* ; public class ChaveValorHandler implements ChaveValor . Iface { private HashMap < Integer , String > kv = new HashMap <> (); @Override public String getKV ( int key ) throws TException { if ( kv . containsKey ( key )) return kv . get ( key ); else throw new KeyNotFound (); } @Override public boolean setKV ( int key , String valor ) throws TException { kv . put ( key , valor ); return true ; } @Override public void delKV ( int key ) throws TException { kv . remove ( key ); } }","title":"IDL Thrift"},{"location":"cases/thrift/#arquitetura","text":"Runtime library -- componentes podem ser selecionados em tempo de execu\u00e7\u00e3o e implementa\u00e7\u00f5es podem ser trocadas Protocol -- respons\u00e1vel pela serializa\u00e7\u00e3oo dos dados TBinaryProtocol TJSONProtocol TDebugProtocol ... Transport -- I/O no ``fio'' TSocket TFramedTransport (non-blocking server) TFileTransport TMemoryTransport Processor -- Conecta protocolos de entrada e sa\u00edda com o \\emph{handler} Handler -- Implementa\u00e7\u00e3o das opera\u00e7\u00f5es oferecidas Server -- Escuta portas e repassa dados (protocolo) para o processors TSimpleServer TThreadPool TNonBlockingChannel","title":"Arquitetura"},{"location":"cases/thrift/#classpath","text":"1 2 3 javac -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java -d . *.java java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorServer java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorClient","title":"Classpath"},{"location":"cases/zookeeper/","text":"Coordena\u00e7\u00e3o: Zookeeper O Zookeeper foi criado para coordenar as a\u00e7\u00f5es dos componentes de sistemas distribu\u00eddos, porqu\u00ea sistemas distribu\u00eddos s\u00e3o como zool\u00f3gicos, com animais de diversas esp\u00e9cies, sendo obrigados a conviver de forma anti-natural. Vis\u00e3o Geral O qu\u00ea? ZooKeeper is a centralized service for maintaining configuration information, naming , providing distributed synchronization , and providing group services . All of these kinds of services are used in some form or another by distributed applications . Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them, which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed. O arcabou\u00e7o foi criado pelo Yahoo! para servir como pe\u00e7a na constru\u00e7\u00e3o de sistemas distribu\u00eddos dentro da empresa. Por qu\u00ea? Coordination services are notoriously hard to get right. They are especially prone to errors such as race conditions and deadlock. The motivation behind ZooKeeper is to relieve distributed applications the responsibility of implementing coordination services from scratch. Mais tarde o sistema tornou-se Open Source e parte de diversos projetos, tanto abertos quanto propriet\u00e1rios. A raz\u00e3o de seu sucesso, arrisco dizer, \u00e9 a simplicidade de sua API, semelhante a um sistema de arquivos. Como? [ZooKeeper] exposes a simple set of primitives that distributed applications can build upon to implement higher level services for synchronization, configuration maintenance, and groups and naming. It is designed to be easy to program to, and uses a data model styled after the familiar directory tree structure of file systems . It runs in Java and has bindings for both Java and C . ZooKeeper allows distributed processes to coordinate with each other through a shared hierarchal namespace which is organized similarly to a standard file system . ... Unlike a typical file system, which is designed for storage, ZooKeeper data is kept in-memory , which means ZooKeeper can achieve high throughput and low latency numbers. O sistema de arquivos do Zookeeper tem n\u00f3s denominados znodes , em refer\u00eancia aos i-nodes do mundo Unix. O znode raiz \u00e9 denominado / e um filho da raiz nomeado teste \u00e9 referido como /teste . Cada znode pode ser visto como arquivo e diret\u00f3rio ao mesmo tempo. Znodes s\u00e3o manipulados, essencialmente, por 4 opera\u00e7\u00f5es, implementando CRUD, e uma quinta opera\u00e7\u00e3o que lista os znodes filhos de um dado znode. C: create R: get U: set D: delete ls *: get children Znodes s\u00e3o lidos e escritos sempre integralmente. Isto \u00e9, n\u00e3o se pode escrever apenas parte do conte\u00fado do \"arquivo\". Por isso, recomenda-se que os arquivos sejam sempre pequenos, onde pequeno \u00e9 relativo. O sistema de arquivos do Zookeeper \u00e9 replicado em v\u00e1rios n\u00f3s, usando a t\u00e9cnica de replica\u00e7\u00e3o de m\u00e1quinas de estados estudada. A difus\u00e3o ordenada de comandos \u00e9 implementadas O protocolo utilizado \u00e9 pelo protocolo de difus\u00e3o at\u00f4mica pr\u00f3prio do Zookeeper, ZAB ( Zookeeper Atomic Broadcast ). Comandos de modifica\u00e7\u00e3o do sistema de arquivos, como create e delete , podem ser enviados para qualquer das r\u00e9plicas, mas ser\u00e3o internamente encaminhados para um processos l\u00edder e de l\u00e1 replicados. J\u00e1 comandos de leitura s\u00e3o executados direto na r\u00e9plica que os recebe, sendo respondidos mais rapidamente mas que, devido \u00e0 assincronia do sistema, podem ser respondidos com dados antigos. Por este motivo, clientes sempre conversam com o mesmo servidor, a n\u00e3o ser que sejam for\u00e7ados a estabelecer nova conex\u00e3o, e s\u00f3 emitem novos comandos depois que o anterior tiver sido respondido. Este comportamento resulta em garantias de consist\u00eancia espec\u00edficas, denominadas consist\u00eancia sequencial ordenada . Por causa do custo em termos de mensagens trocadas entre os processos para mensagens de atualiza\u00e7\u00e3o e pelo baixo custo das mensagens de leitura, o zookeeper \u00e9 recomendado para cargas de trabalho com poucas escritas. Desempenho ZooKeeper is fast [...] and it performs best where reads are more common than writes, at ratios of around 10:1. O gr\u00e1fico seguinte mostra como o desempenho do sistema varia com o n\u00famero de processos. No eixo Y, a quantidade de requisi\u00e7\u00f5es processadas por segundo, ou seja, a vaz\u00e3o. No eixo X, a percentagem das requisi\u00e7\u00f5es do teste que s\u00e3o leituras e, portanto, repondidas na r\u00e9plica em que s\u00e3o recebidas. As diferentes curvas mostram diferentes configura\u00e7\u00f5es do sistema, indo de 3 a 12 r\u00e9plicas. Em geral, todas as configura\u00e7\u00f5es apresentam melhor desempenho quando h\u00e1 uma percentagem maior de leituras. Mas observe como as curvas se invertem, se focando primeiro na curva para 3 servidores: quando todas as opera\u00e7\u00f5es s\u00e3o de escrita, e portanto precisam passar pelo protocolo de difus\u00e3o at\u00f4mica, esta curva apresenta os melhores resultados. Isto ocorre porqu\u00ea o overhead de executar o protocolo \u00e9 mais baixo entre 3 servidores que entre 13. Em compensa\u00e7\u00e3o, quando temos mais leituras, que n\u00e3o precisam de sincroniza\u00e7\u00e3o, ent\u00e3o ter mais servidores \u00e9 mais vantajoso pois sobre menos carga de trabalho para cada servidor. Laborat\u00f3rio Instale o Zookeeper em sua m\u00e1quina seguindo estas instru\u00e7\u00f5es. Baixe: wget www-eu.apache.org/dist/zookeeper/zookeeper-3.6.2 Descomprima: tar xvzf zookeeper*.tgz Entre na pasta criada. Configure: copie o arquivo conf/zoo_sample.cfg para conf/zoo.cfg Execute ./bin/zkServer.sh start-foreground em um terminal ./bin/zkCli.sh -server 127.0.0.1:2181 em outro terminal Do shell do programa cliente (executado por \u00faltimo), digite help e enter para ver uma lista de todos os comandos dispon\u00edveis. Vejamos alguns exemplos b\u00e1sicos. ls / - lista os n\u00f3s filhos da raiz. create /teste lala - cria o n\u00f3 /teste com conte\u00fado lala get /teste - pega o conte\u00fado do arquivo set /teste lele - atualiza o conte\u00fado do arquivo delete /teste - apaga o arquivo Outros comandos interessantes s\u00e3o: stat /teste - mostra medatados do arquivo, por exemplo vers\u00e3o, e timestamps set -v V /teste lili - faz um update condiciona, isto \u00e9, atualiza o conte\u00fado do arquivo se a vers\u00e3o do mesmo, como mostrada pelo comando stat , for igual a V N\u00f3s Ef\u00eameros e Watches O Zookeeper tem muitas funcionalidades interessantes, mas chamarei a aten\u00e7\u00e3o a duas que s\u00e3o particularmente \u00fateis: N\u00f3s ef\u00eameros , criados com a flag -e , p.e., create -ef /teste/noefemero efemero , s\u00e3o automaticamente destru\u00eddos quando o cliente que os criou se desconecta do servidor. E watches avisam ao cliente quando uma opera\u00e7\u00e3o em um certo znode ou em seus filhos acontece. Para ser avisado quando os dados de um n\u00f3 forem alterados, use a op\u00e7\u00e3o -w do get, por exemplo, get -w /teste . Para monitorar altera\u00e7\u00f5es no conjunto de filhos de um n\u00f3, use -w no ls , por exemplo, ls -w /teste . N\u00f3s Ef\u00eameros e Watches Crie um zNode /teste Debaixo de /teste, crie tr\u00eas outros, sequenciais Crie um zNode /teste2 Crie um zNode ef\u00eamero Conecte-se com outro cliente Coloque um watch em /teste2 Desconecte o primeiro cliente Observe o evento gerado no segundo cliente Reconecte o primeiro cliente Cluster tolerante a falhas Observe que voc\u00ea est\u00e1 executando o Zookeeper em apenas um n\u00f3, ou seja, n\u00e3o h\u00e1 toler\u00e2ncia a falhas alguma aqui. Para tolerar falhas, voc\u00ea precisa de um cluster multi-n\u00f3s, mesmo que seja em uma \u00fanica m\u00e1quina. Neste caso, crie tr\u00eas arquivos de configura\u00e7\u00e3o, zoo1.cfg , zoo2.cfg e zoo3.cfg . O arquivo zooX.cfg , onde 1 <= X <= 3 , fica assim: dataDir=/tmp/lasaro/zooX #Substitua o X pelo valor correto server.1=zoo1:2888:3888 server.2=zoo2:2889:3889 server.3=zoo3:2890:3890 clientPort=218X #Substitua o X pelo valor correto Crie diret\u00f3rios e arquivos de identifica\u00e7\u00e3o. mkdir /tmp/lasaro/zooX echo X > /tmp/lasaro/zooX/myid Execute servidores. ./bin/zkServer.sh start conf/zooX.cfg Ainda que tenha tr\u00eas servidores executando em uma mesma m\u00e1quina, seu cluster parar\u00e1 de funcionar se a m\u00e1quina parar de funcionar. O ideal \u00e9 que cada servidor execute em uma m\u00e1quina distinta. Receitas \u00c9 poss\u00edvel resolver diversos problemas encontrados em sistemas distribu\u00eddos usando-se o ZooKeeper, por exemplo, o problema de descoberta de processos. Rendezvous Ponto de encontro de processos. Defina um zNode raiz a ser usado: /rendezvous/app1/ Cada filho de /rendezvous/app1 corresponde a um processo: IP Porta N\u00famero de processadores ... Processo p ao ser iniciado: procura /rendezvous/app1/p se achar, continua se n\u00e3o achar, cria /rendezvous/app1/p lista os filhos de /rendezvous/app1 Como lidar com sa\u00edda de processos? Fa\u00e7a todos os zNodes s\u00e3o ef\u00eameros. Quando um n\u00f3 \u00e9 desconectado, o zNode correspondente ser\u00e1 destru\u00eddo. Como detectar mudan\u00e7as no grupo de processos? Monitore os filhos de /rendezvous/app1 Sempre que receber notifica\u00e7\u00f5es, refa\u00e7a o c\u00e1lculo do membership . Elei\u00e7\u00e3o de L\u00edderes Rendezvous. Fa\u00e7a os zNodes sequenciais. Ordene os zNodes e escolha o primeiro. Monitore o zNode. Se ele sumir, eleja outro l\u00edder. Exclus\u00e3o M\u00fatua Construa uma fila usando n\u00f3s ef\u00eameros e sequenciais. O processo na cabe\u00e7a da fila tem direito de acesso. Em caso de falhas, o processo \u00e9 removido da cabe\u00e7a da fila. V\u00e1rias outras receitas podem ser facilmente encontradas no s\u00edtio do projeto : Lock distribu\u00eddo Filas, e.g. de prioridades Barreira Servi\u00e7o de nomes Termina\u00e7\u00e3o em duas fases Contador at\u00f4mico Al\u00e9m destas, outro projeto, o Curator se dedica apenas a colecionar implementa\u00e7\u00f5es corretas de receitas para o Zookeeper.","title":"Zookeeper"},{"location":"cases/zookeeper/#coordenacao-zookeeper","text":"O Zookeeper foi criado para coordenar as a\u00e7\u00f5es dos componentes de sistemas distribu\u00eddos, porqu\u00ea sistemas distribu\u00eddos s\u00e3o como zool\u00f3gicos, com animais de diversas esp\u00e9cies, sendo obrigados a conviver de forma anti-natural.","title":"Coordena\u00e7\u00e3o: Zookeeper"},{"location":"comm/","text":"Comunica\u00e7\u00e3o Canal Protocolo A pedra fundamental da constru\u00e7\u00e3o de sistemas distribu\u00eddos \u00e9 a capacidade de comunica\u00e7\u00e3o entre seus componentes e, para que os componentes de um sistema distribu\u00eddo se comuniquem, \u00e9 necess\u00e1rio que seus hosts possuam tenham algum canal de comunica\u00e7\u00e3o que os conecte e que se estabele\u00e7a um protocolo de comunica\u00e7\u00e3o , que define as regras para que a comunica\u00e7\u00e3o aconte\u00e7a. Por exemplo, quando voc\u00ea fala com uma pessoa, cara-a-cara, o canal de comunica\u00e7\u00e3o \u00e9 o ar e o protocolo utilizado \u00e9 a linguagem conhecida pelas duas partes. Se o canal n\u00e3o est\u00e1 presente ou se o protocolo n\u00e3o \u00e9 bem definido, a comunica\u00e7\u00e3o n\u00e3o acontece. As camadas de abstra\u00e7\u00e3o mais b\u00e1sicas do desenvolvimento de SD est\u00e3o nas redes de computadores , que servem de substrato a todo e qualquer sistema distribu\u00eddo, afinal. Por isso, neste cap\u00edtulo revisaremos rapidamente como as redes funcionam, relembraremos como sockets s\u00e3o usados e, na sequ\u00eancia, subiremos algumas camadas de abstra\u00e7\u00e3o.","title":"Introdu\u00e7\u00e3o"},{"location":"comm/datarep/","text":"Representa\u00e7\u00e3o de dados O desenvolvimento de sistemas distribu\u00eddos usando diretamente Sockets como forma de comunica\u00e7\u00e3o entre componentes n\u00e3o \u00e9 para os fracos de cora\u00e7\u00e3o. Sua grande vantagem est\u00e1 no acesso baixo n\u00edvel \u00e0 rede , e todo o ganho de desempenho que isso pode trazer. Suas desvantagens, entretanto, s\u00e3o v\u00e1rias: interface de \"arquivo\" para se ler e escrever bytes; controle de fluxo de \"objetos\" \u00e9 por conta da aplica\u00e7\u00e3o, isto \u00e9, a aplica\u00e7\u00e3o precisa sinalizar quantos bytes ser\u00e3o escritos de um lado, para que o outro saiba quanto ler para obter um \"objeto\" correto; logo, a serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o de objetos \u00e9 tamb\u00e9m por conta da aplica\u00e7\u00e3o; tratamento de desconex\u00f5es e eventuais reconex\u00f5es tamb\u00e9m \u00e9 gerenciado pela aplica\u00e7\u00e3o e nem a t\u00e3o famosa confiabilidade do TCP ajuda. Enquanto se poderia argumentar que algumas destas desvantagens podem ser descartadas em fun\u00e7\u00e3o da discuss\u00e3o de incluir ou n\u00e3o API na comunica\u00e7\u00e3o fim-a-fim , \u00e9 certo que algumas funcionalidades s\u00e3o ub\u00edquas em aplica\u00e7\u00f5es distribu\u00eddas. Foquemo-nos agora na necessidade de representar dados complexos em formato intelig\u00edvel pelos v\u00e1rios componentes da aplica\u00e7\u00e3o distribu\u00edda. Exceto por aplica\u00e7\u00f5es muito simples, processos em um sistema distribu\u00eddo trocam dados complexos, por exemplo estruturas ou classes com diversos campos, incluindo valores num\u00e9ricos de diversos tipos, strings e vetores de bytes, com diversos n\u00edveis de aninhamento e somando v\u00e1rios KB. Neste cen\u00e1rio, v\u00e1rios fatores precisam ser levados em considera\u00e7\u00e3o na hora de colocar esta estrutura no fio , como: varia\u00e7\u00f5es de defini\u00e7\u00f5es de tipos, por exemplo, inteiro : 8: 16, 32, ou 64 bits? varia\u00e7\u00f5es na representa\u00e7\u00e3o de dados complexos: classe x estrutura conjunto de caracteres diferentes: ASCII x UTF little endian, como x64 e IA-32, ou big endian como SPARC (< V9), Motorola e PowerPC? ou ainda, flex\u00edvel como ARM, MIPS ou IA-64? fim de linha com crlf (DOS) x lf (Unix)? fragmenta\u00e7\u00e3o de dados na rede Representa\u00e7\u00e3o Textual Uma abordagem comumente usada \u00e9 a representa\u00e7\u00e3o em formato textual \"amig\u00e1vel a humanos\". Veja o exemplo de como o protocolo HTTP requisita e recebe uma p\u00e1gina HTML. 1 2 3 4 5 6 7 telnet www.google.com 80 Trying 187.72.192.217... Connected to www.google.com. Escape character is '^]'. GET / HTTP/1.1 host: www.google.com < === Linha vazia! As linhas 5 e 6 s\u00e3o entradas pelo cliente para requisitar a p\u00e1gina raiz do s\u00edtio www.google.com . A linha 7, vazia, indica ao servidor que a requisi\u00e7\u00e3o est\u00e1 terminada. Em resposta a esta requisi\u00e7\u00e3o, o servidor envia o seguinte, em que as primeiras linhas trazem metadados da p\u00e1gina requisitada e, ap\u00f3s a linha em branco, vem a resposta em HTML \u00e0 requisi\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 HTTP/1.1 302 Found Location: http://www.google.com.br/?gws_rd=cr & ei=HTDqWJ3BDYe-wATs_a3ACA Cache-Control: private Content-Type: text/html; charset=UTF-8 P3P: CP=\"This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info.\" Date: Sun, 09 Apr 2017 12:59:09 GMT Server: gws Content-Length: 262 X-XSS-Protection: 1; mode=block X-Frame-Options: SAMEORIGIN Set-Cookie: NID=100=NB_AruuFWL0hXk2-h7VDduHO_UkjAr6RaqgG7VbccTsfLzFfhxEKx21Xpa2EH7IgshgczE9vU4W1TyKsa07wQeuZosl5DbyZluR1ViDRf0C-5lRpd9cCpCD5JXXjy-UE; expires=Mon, 09-Oct-2017 12:59:09 GMT; path=/; domain=.google.com; HttpOnly < HTML >< HEAD >< meta http-equiv = \"content-type\" content = \"text/html;charset=utf-8\" > < TITLE > 302 Moved </ TITLE ></ HEAD >< BODY > < H1 > 302 Moved </ H1 > The document has moved < A HREF = \"http://www.google.com.br/?gws_rd=cr&amp;ei=HTDqWJ3BDYe-wATs_a3ACA\" > here </ A > . </ BODY ></ HTML > Representa\u00e7\u00f5es textuais s\u00e3o usadas em diversos protocolos como SMTP, POP, e telnet. Algumas destas representa\u00e7\u00f5es seguem padr\u00f5es formalizados, o que facilita a gera\u00e7\u00e3o e interpreta\u00e7\u00e3o dos dados. Dois padr\u00f5es bem conhecidas s\u00e3o XML e JSON. XML \u00e9 o acr\u00f4nimo para Extensible Markup Language , ou seja, uma linguagem marca\u00e7\u00e3o que pode ser estendida para representar diferentes tipos de informa\u00e7\u00e3o. A HTML, por exemplo, \u00e9 uma inst\u00e2ncia de XML destinada \u00e0 representa\u00e7\u00e3o de hipertexto (A bem da verdade, XML foi uma generaliza\u00e7\u00e3o de HTML). Por exemplo, para representarmos os dados relativos \u00e0 uma pessoa, podemos ter uma inst\u00e2ncia XML assim: 1 2 3 4 5 6 7 8 9 <person> <name> John Doe </name> <id> 112234556 </id> <email> jdoe@example.com </email> <telephones> <telephone type= \"mobile\" > 123 321 123 </telephone> <telephone type= \"home\" > 321 123 321 </telephone> </telephones> </person> Uma das grandes vantagens do uso de XML \u00e9 a possibilidade de se formalizar o que pode ou n\u00e3o estar em um arquivo para um certo dom\u00ednio utilizando um XML Domain Object Model . H\u00e1, por exemplo, modelos para representa\u00e7\u00e3o de documentos de texto, governos eletr\u00f4nicos, representa\u00e7\u00e3o de conhecimento, etc . Sua maior desvantagem \u00e9 que \u00e9 muito verborr\u00e1gico e por vezes complicado de se usar, abrindo alas para o seu mais famoso concorrente, JSON. JSON \u00e9 o acr\u00f4nimo de Javascript Object Notation , isto \u00e9, o formato para representa\u00e7\u00e3o de objetos da linguagem Javascript. Devido \u00e0 sua simplicidade e versatilidade, entretanto, foi adotado como forma de representa\u00e7\u00e3o de dados em sistemas desenvolvidos nas mais diferentes linguagens. O mesmo exemplo visto anteriormente, em XML, \u00e9 representado em JSON assim: 1 2 3 4 5 6 7 8 9 { \"name\" : \"John Doe\" , \"id\" : 112234556 , \"email\" : \"jdoe@example.com\" , \"telephones\" : [ { \"type\" : \"mobile\" , \"number\" : \"123 321 123\" }, { \"type\" : \"home\" , \"number\" : \"321 123 321\" }, ] } Em Python, por exemplo, JSON s\u00e3o gerados e interpretados nativamente, sem a necessidade de frameworks externos, facilitando seu uso. Mas de fato, a op\u00e7\u00e3o final por XML ou JSON \u00e9 quest\u00e3o de prefer\u00eancia, uma vez que os dois formatos s\u00e3o, de fato, equivalentes na quest\u00e3o da representa\u00e7\u00e3o de informa\u00e7\u00e3o. Outros formatos, bin\u00e1rios, oferecem vantagens no uso de espa\u00e7o para armazenar e transmitir dados, e por isso s\u00e3o frequentemente usados como forma de serializa\u00e7\u00e3o de dados em sistemas distribu\u00eddos, isto \u00e9, na transforma\u00e7\u00e3o de TAD para sequ\u00eancias de bytes que seguir\u00e3o \"no fio\". ASN.1 (Abstract Syntax Notation), pela ISO XDR (eXternal Data Representation) Java serialization Google Protocol Buffers Thrift ASN.1 e XDR s\u00e3o de interesse hist\u00f3rico, mas n\u00e3o os discutiremos aqui. Quanto \u00e0 serializa\u00e7\u00e3o feita nativamente pelo Java, por meio de ObjectOutputStreams , como neste exemplo , embora seja tentadora para quem usa Java, \u00e9 necess\u00e1rio saber que ela \u00e9 restrita \u00e0 JVM e que usa muito espa\u00e7o, embora minimize riscos de uma desserializa\u00e7\u00e3o para uma classe diferente. Nos foquemos nas outras alternativas listadas, protobuf e Thrift, que podem levar a representa\u00e7\u00f5es bin\u00e1rias e textuais. Protocol Buffers Nas palavras dos criadores , Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Por meio de protobuf, \u00e9 poss\u00edvel estruturar dados e gerar o c\u00f3digo correspondente em diversas linguagens, for forma compartilh\u00e1vel entre as mesmas. Veja o exemplo a seguir, que especifica os dados referentes a uma pessoa. Observe a presen\u00e7a de campos de preenchimento opcional ( optional ), de enumera\u00e7\u00f5es ( enum ), e de cole\u00e7\u00f5es ( repeated ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 message Person { required string name = 1 ; required int32 id = 2 ; optional string email = 3 ; enum PhoneType { MOBILE = 0 ; HOME = 1 ; WORK = 2 ; } message PhoneNumber { required string number = 1 ; optional PhoneType type = 2 [ default = HOME ]; } repeated PhoneNumber phone = 4 ; } Al\u00e9m dos tipos usados no exemplo, diversos outros tipos primitivos est\u00e3o dispon\u00edveis: bool : boolean (true/false) double : 64-bit; ponto-flutuante float : 32-bit; ponto-flutuante i32 : 32-bit; inteiro sinalizado i64 : 64-bit; inteiro sinalizado siXX : signed uiXX : unsigned sfixedXX : codifica\u00e7\u00e3o de tamanho fixo bytes : 8-bit; inteiro sinalizado string : string UTF-8 ou ASCII 7-bit Al\u00e9m destes, tamb\u00e9m pode ser usado um tipo indefinido e adapt\u00e1vel, Any , bem como cole\u00e7\u00f5es. A especifica\u00e7\u00e3o protobuf pode ser traduzida para m\u00faltiplas linguagens Por exemplo, se a tradu\u00e7\u00e3o for feita para C++, o tipo message resulta em uma classe de mesmo nome, com funcionalidades para serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o do objeto, como no exemplo a seguir. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //Instancia person e salva conte\u00fado em arquivo Person person ; person . set_name ( \"John Doe\" ); person . set_id ( 1234 ); person . set_email ( \"jdoe@example.com\" ); fstream output ( \"myfile\" , ios :: out | ios :: binary ); person . SerializeToOstream ( & output ); //Instancia Person e o inicializa com dados do arquivo fstream input ( \"myfile\" , ios :: in | ios :: binary ); Person person ; person . ParseFromIstream ( & input ); cout << \"Name: \" << person . name () << endl ; cout << \"E-mail: \" << person . email () << endl ; De acordo com benchmarks do pr\u00f3prio projeto , a opera\u00e7\u00e3o em XML seria mais ordens de grandeza mais lenta e ocuparia mais espa\u00e7o. When this message is encoded to the protocol buffer binary format, it would probably be 28 bytes long and take around 100-200 nanoseconds to parse. The XML version is at least 69 bytes if you remove whitespace, and would take around 5,000-10,000 nanoseconds to parse. Thrift Originalmente desenvolvido pela Facebook, Apache Thrift \u00e9 um arcabou\u00e7o desenvolvimento de servi\u00e7os multi-linguagens. Isto, mesmo que por enquanto nos foquemos no aspecto da representa\u00e7\u00e3o de dados desta tecnologia, veremos depois que pode ser usado para executar a troca de dados entre processos. 1 Comparado ao protobuf, ele possui praticamente as mesmas funcionalidades, i.e., a defini\u00e7\u00e3o de estruturas de dados complexos e gera\u00e7\u00e3o de c\u00f3digo para serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o de inst\u00e2ncias destas estruturas. O mesmo exemplo acima, que define uma estrutura para representar pessoas e seus contatos, ficaria assim em thrift. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 enum PhoneType { MOBILE = 0 ; HOME = 1 ; WORK = 2 ; } struct PhoneNumber { 1 : required string number ; 2 : optional PhoneType type = 2 PhoneType.HOME ; } struct Person { 1 : required string name ; 2 : required i32 id ; 3 : optional string email ; 4 : list < PhoneNumber > phone ; } exception PessoaNaoEncontrada { 1 : i64 hora ; 2 : string chaveProcurada ; } Usar a classe correspondente em Java, depois da gera\u00e7\u00e3o de c\u00f3digo pelo compilador thriftc , \u00e9 bem simples. 1 Person p = new Person ( \"John Doe\" , 112234556 , \"jdoe@example.com\" , Collections . emptyList ()) Observe que al\u00e9m do uso de cole\u00e7\u00f5es e enumera\u00e7\u00f5es, demonstradas no exemplo, os mesmos tipos b\u00e1sicos tamb\u00e9m est\u00e3o dispon\u00edveis. bool: boolean (true/false) byte: 8-bit; inteiro sinalizado i16: 16-bit; inteiro sinalizado i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado double: 64-bit; ponto-flutuante string: string UTF-8 binary: sequ\u00eancia de bytes cole\u00e7\u00f5es: List, Map, Set Uma vez que tenhamos facilidades para representar dados complexos e transform\u00e1-los em sequ\u00eancias de bytes, e de volta, pensemos em como podemos definir, de forma simplificada, servi\u00e7os que manipulam estes dados. Estas funcionalidades s\u00e3o normalmente implementadas por frameworks de comunica\u00e7\u00e3o de mais alto n\u00edvel que, jarg\u00e3o da \u00e1rea de sistemas distribu\u00eddos, s\u00e3o denominados middleware . O Facebook, insatisfeito com os progressos da vers\u00e3o Apache, acabou fazendo um novo fork do projeto, fbthrift , tamb\u00e9m de c\u00f3digo livre, mas que tem evolu\u00eddo de forma desconexa do projeto Apache. Contudo, no escopo do nosso estudo, as duas vers\u00f5es s\u00e3o essencialmente iguais. \u21a9","title":"Representa\u00e7\u00e3o"},{"location":"comm/datarep/#representacao-de-dados","text":"O desenvolvimento de sistemas distribu\u00eddos usando diretamente Sockets como forma de comunica\u00e7\u00e3o entre componentes n\u00e3o \u00e9 para os fracos de cora\u00e7\u00e3o. Sua grande vantagem est\u00e1 no acesso baixo n\u00edvel \u00e0 rede , e todo o ganho de desempenho que isso pode trazer. Suas desvantagens, entretanto, s\u00e3o v\u00e1rias: interface de \"arquivo\" para se ler e escrever bytes; controle de fluxo de \"objetos\" \u00e9 por conta da aplica\u00e7\u00e3o, isto \u00e9, a aplica\u00e7\u00e3o precisa sinalizar quantos bytes ser\u00e3o escritos de um lado, para que o outro saiba quanto ler para obter um \"objeto\" correto; logo, a serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o de objetos \u00e9 tamb\u00e9m por conta da aplica\u00e7\u00e3o; tratamento de desconex\u00f5es e eventuais reconex\u00f5es tamb\u00e9m \u00e9 gerenciado pela aplica\u00e7\u00e3o e nem a t\u00e3o famosa confiabilidade do TCP ajuda. Enquanto se poderia argumentar que algumas destas desvantagens podem ser descartadas em fun\u00e7\u00e3o da discuss\u00e3o de incluir ou n\u00e3o API na comunica\u00e7\u00e3o fim-a-fim , \u00e9 certo que algumas funcionalidades s\u00e3o ub\u00edquas em aplica\u00e7\u00f5es distribu\u00eddas. Foquemo-nos agora na necessidade de representar dados complexos em formato intelig\u00edvel pelos v\u00e1rios componentes da aplica\u00e7\u00e3o distribu\u00edda. Exceto por aplica\u00e7\u00f5es muito simples, processos em um sistema distribu\u00eddo trocam dados complexos, por exemplo estruturas ou classes com diversos campos, incluindo valores num\u00e9ricos de diversos tipos, strings e vetores de bytes, com diversos n\u00edveis de aninhamento e somando v\u00e1rios KB. Neste cen\u00e1rio, v\u00e1rios fatores precisam ser levados em considera\u00e7\u00e3o na hora de colocar esta estrutura no fio , como: varia\u00e7\u00f5es de defini\u00e7\u00f5es de tipos, por exemplo, inteiro : 8: 16, 32, ou 64 bits? varia\u00e7\u00f5es na representa\u00e7\u00e3o de dados complexos: classe x estrutura conjunto de caracteres diferentes: ASCII x UTF little endian, como x64 e IA-32, ou big endian como SPARC (< V9), Motorola e PowerPC? ou ainda, flex\u00edvel como ARM, MIPS ou IA-64? fim de linha com crlf (DOS) x lf (Unix)? fragmenta\u00e7\u00e3o de dados na rede","title":"Representa\u00e7\u00e3o de dados"},{"location":"comm/epidemics/","text":"Protocolos Epid\u00eamicos H\u00e1 v\u00e1rias formas de se propagar informa\u00e7\u00e3o entre n\u00f3 de um sistema distribu\u00eddo. Uma forma particularmente interessante \u00e9 espelhada no modo como boatos ou doen\u00e7as se propagam entre um conjunto de indiv\u00edduos; este tipo de protocolo \u00e9 conhecido como gossiping (fofoca) ou epid\u00eamico . Gossiping Epidemia ou fofoca Multicast Tolerante a falhas Sem entidade central Algumas caracter\u00edsticas fundamentais dos protocolos epid\u00eamicos os distinguem de outros protocolos e frameworks de comunica\u00e7\u00e3o. Primeiro, estes protocolos resolvem um problema de multicast de mensagens, isto \u00e9, de comunica\u00e7\u00e3o um para muitos, em oposi\u00e7\u00e3o ao unicast das conex\u00f5es TCP ou \u00e0s invoca\u00e7\u00f5es remotas do RPC. Segundo, n\u00e3o h\u00e1 a figura de uma entidade coordenadora, como os brokers nas filas de mensagens e sistemas pubsub. Finalmente, a entrega de mensagens \u00e9 garantida probabil\u00edsticamente, o que quer dizer que quando uma mensagem \u00e9 enviada, h\u00e1 uma probabilidade dela ser entregue pelos demais processos, mas n\u00e3o h\u00e1 garantias de que o mesmo acontecer\u00e1. A despeito do que isso possa dar entender, estes protocolos podem ser configurados para uma taxa de entrega t\u00e3o alta quanto se queira e funcionam muito bem em redes n\u00e3o confi\u00e1veis, isto \u00e9, onde h\u00e1 perda de mensagens individuais. Na pr\u00e1tica, estes protocolos s\u00e3o usados na descoberta de n\u00f3 em um sistema distribu\u00eddo, para propagar informa\u00e7\u00f5es sobre seus estados individuais e para computar informa\u00e7\u00f5es globais. Algoritmo Imagine uma pessoa contaminada por um v\u00edrus; a medida que o tempo passa, esta pessoa tem contato com outras pessoas que, com certa probabilidade, se tornam tamb\u00e9m infectadas. Cada novo infectado passa a propagar o v\u00edrus nos seus contatos e, assim, depois de alguns ciclos, toda a popula\u00e7\u00e3o \u00e9 infectada. N\u00f3s podemos ent\u00e3o modelar estes protocolos com o seguinte algoritmo b\u00e1sico, que executa em rodadas. Algoritmo b\u00e1sico A cada rodada para cada n\u00f3 \\(p\\) infectado com o v\u00edrus \\(v\\) escolha \\(F\\) outros processos, \\(\\{p_1,p_2,p_3,...,p_f\\}, p_i \\neq p\\) , aleatoriamente para cada \\(p_i\\) , contamine \\(p_i\\) com \\(v\\) Agora vamos dissecar este algoritmo. Rodadas Em primeiro lugar, por qu\u00ea a execu\u00e7\u00e3o em rodadas em vez de propagar imediatamente qualquer nova informa\u00e7\u00e3o que receber? H\u00e1 muitos v\u00edrus por a\u00ed, ou melhor dizendo, muitas informa\u00e7\u00f5es a serem propagadas, e portanto faz sentido ter intervalos entre as propaga\u00e7\u00f5es para permitir que um conjunto de novos dados seja consolidado para aproveitar cada intera\u00e7\u00e3o para passar um pacote j\u00e1 consolidado de dados adiante. Dito isso, cada ciclo pode ser feito arbitrariamente curto, acelerando a dispers\u00e3o das informa\u00e7\u00f5es. Al\u00e9m disso, na pr\u00e1tica cada n\u00f3 executa as suas rodadas independentemente dos outros, mas sincronizar os ciclos facilita a an\u00e1lise dos algoritmos. Fanout Em segundo lugar, por qu\u00ea limitar as intera\u00e7\u00f5es em cada ciclo a \\(F\\) ? O objetivo deste tipo de algoritmo \u00e9 escalar para centenas, milhares ou at\u00e9 milh\u00f5es de processos. Logo, \u00e9 preciso limitar a quantidade de intera\u00e7\u00f5es a cada ciclo por raz\u00f5es pr\u00e1ticas. Dito isso, podemos ajustar o \\(F\\) , conhecido como o fanout do algoritmo, para cima para acelerar a difus\u00e3o tanto quanto quisermos. Considere o caso em que \\(F=2\\) ; no in\u00edcio do algoritmo, temos 1 processo infectado. Durante o primeiro ciclo, o processo infectado propaga a informa\u00e7\u00e3o para outros dois, elevando o n\u00famero de infectados a 3. No pr\u00f3ximo ciclo, cada um destes infectados infecta outros dois, m\u00f3dulo intera\u00e7\u00f5es entre n\u00f3s j\u00e1 infectados e que desperdi\u00e7am oportunidades de propaga\u00e7\u00e3o. Se imaginarmos estes ciclos como uma \u00e1rvore em que cada ciclo corresponde a um ciclo, em que os n\u00f3s contaminados no final do ciclo s\u00e3o os n\u00f3s da \u00e1rvore, e que as intera\u00e7\u00f5es s\u00e3o arestas, temos o seguinte. Ciclos \\(n\\) n\u00f3s \\(F\\) fanout \\(log_F(n)\\) ciclos Depois de \\(c\\) ciclos, teremos \\(c^F\\) n\u00f3s contaminados ou, de forma inversa, se para contaminar \\(n\\) n\u00f3s, s\u00e3o necess\u00e1rios \\(log_F(n)\\) ciclos. Gossip Simulator: https://flopezluis.github.io/gossip-simulator/ Escolha a quantidade de nodes e um fanout . Clique em um dos n\u00f3s para infect\u00e1-lo e clique play para animar. Push x Pull Push x Pull Push \\(\\rightarrow\\) Pull \\(\\leftarrow\\) Push/Pull \\(\\leftrightarrow\\) Alguns aspectos do algoritmo b\u00e1sico podem ser alterados, como a decis\u00e3o sobre quais n\u00f3s contatam quais n\u00f3s e como a informa\u00e7\u00e3o flui na comunica\u00e7\u00e3o. No algoritmo b\u00e1sico, somente n\u00f3s infectados contatam outros n\u00f3s para ent\u00e3o fazer um push do v\u00edrus. Para acelerar a propaga\u00e7\u00e3o, processos saud\u00e1veis podem tentar se infectar contactando outros n\u00f3s e fazendo um pull dos v\u00edrus presentes no outro. Ou, como \u00e9 frequentemente verdade, a melhor abordagem pode ser um misto das duas anteriores, isto \u00e9, uma em que todos os n\u00f3s s\u00e3o ativos em causar contatos e a propaga\u00e7\u00e3o da informa\u00e7\u00e3o acontece nos dois sentidos, isto \u00e9, push/pull , o que faz mais sentido em um ambiente com m\u00faltiplos v\u00edrus circulando. M\u00faltiplos v\u00edrus Em um sistema real, a cada momento diversas informa\u00e7\u00f5es distintas devem estar sendo propagadas, o que \u00e9 equivalente a ter m\u00faltiplos v\u00edrus circulando na mesma popula\u00e7\u00e3o. Por exemplo, cada processo pode gerar periodicamente um resumo da carga de trabalho com a qual est\u00e1 lidando (taxa de escrita em disco, taxa de utiliza\u00e7\u00e3o de CPU, etc) e propagar este resumo para todo o sistema, para ser usado como entrada em uma pol\u00edtica de balanceamento de carga. Assim, um modelo comum de representa\u00e7\u00e3o dos dados em cada n\u00f3 \u00e9 um mapa, um banco de dados chave/valor , onde a chave \u00e9 um identificador \u00fanico da informa\u00e7\u00e3o e o valor \u00e9 dado em si, por exemplo (\"ABCD1234_CPU%\",\"90%\"). A cada contato, um n\u00f3 faz um pull das entradas cujas chaves desconhece e um push das que a contraparte n\u00e3o conhece. Fofoca antiga Uma raz\u00e3o para protocolos epid\u00eamicos serem tamb\u00e9m chamados de gossiping \u00e9 o fato de que informa\u00e7\u00f5es envelhecem e devem parar de ser propagadas quando deixam de ser relevantes. Algumas estrat\u00e9gias se complementam para implementar este comportamento. Frescor da informa\u00e7\u00e3o : se cada n\u00f3 registra o instante em que primeiro recebeu uma informa\u00e7\u00e3o, pode ent\u00e3o determinar um limiar de tempo dentro do qual repassar\u00e1 a informa\u00e7\u00e3o em seus contatos. Depois deste tempo a informa\u00e7\u00e3o n\u00e3o mais se propaga pois n\u00e3o \u00e9 mais uma \"fofoca quente\" ou porqu\u00ea o n\u00f3 deixou de ser \"contagioso\" para aquele v\u00edrus. Coleta de lixo : para restringir a quantidade de espa\u00e7o usado pelo n\u00f3, informa\u00e7\u00f5es muito antigas devem ser esquecidas em algum momento. Este processo pode ser gradual, por exemplo excluindo os dados ap\u00f3s algum tempo, mas mantendo as chaves, efetivamente tornando o n\u00f3 n\u00e3o infectado mas imune ao v\u00edrus. Mesmo que as chaves sejam armazenadas de forma eficiente, por exemplo via uso de filtros de bloom , elas devem ser completamente esquecidas em algum momento, a partir do qual uma reinfec\u00e7\u00e3o \u00e9 poss\u00edvel j\u00e1 que uma nova exposi\u00e7\u00e3o seria indistingu\u00edvel da exposi\u00e7\u00e3o inicial. Vers\u00f5es Em certas aplica\u00e7\u00f5es, como a propaga\u00e7\u00e3o da carga de trabalho de um processo, faz sentido que as informa\u00e7\u00f5es sejam atualizadas. Por exemplo, mesmo que a informa\u00e7\u00e3o sobre a carga de trabalho do processo \u00e0s 10:00hs ainda esteja sendo propagada, se a carga \u00e0s 10:01hs se torna conhecida, pode n\u00e3o ser mais necess\u00e1rio propagar a anterior. Este mecanismo pode se implementado facilmente estendendo-se o par (identificador,valor) para uma tripla (identificador, timestamp /vers\u00e3o,valor), onde timestamp /vers\u00e3o pode ser o valor do rel\u00f3gio quando a informa\u00e7\u00e3o foi gerada ou simplesmente um contador incrementado a cada gera\u00e7\u00e3o. Pontos negativos Obviamente nem tudo s\u00e3o flores no uso destes protocolos e algumas desvantagens devem ser destacadas. Velocidade: dado a escolha aleat\u00f3ria das infec\u00e7\u00f5es, \u00e0 medida que o n\u00famero de infectados aumenta, mais e mais contatos n\u00e3o levam a mais infec\u00e7\u00f5es, desacelerando a propaga\u00e7\u00e3o para outros n\u00f3s. Por outro lado, com tantos infectados, em algum momento os n\u00e3o infectados acabaram tendo \"azar\". Convergence Simulator: https://www.serf.io/docs/internals/simulator.html Este simulador do Serf permite ver o qu\u00e3o r\u00e1pido a informa\u00e7\u00e3o atinge qual percentagem dos n\u00f3s do sistema; no exemplo, ap\u00f3s 0,5s, 50% dos 30 n\u00f3s estavam infectados. No s\u00edtio \u00e9 poss\u00edvel ajustar o n\u00famero de n\u00f3s, dura\u00e7\u00e3o da rodada, perda de pacotes e n\u00f3s defeituosos. Depura\u00e7\u00e3o: devido \u00e0 imprevisibilidade da comunica\u00e7\u00e3o, \u00e9 dif\u00edcil reproduzir execu\u00e7\u00f5es do protocolo e depurar no caso de comportamentos estranhos. Descoberta inicial: encontros entre n\u00f3s s\u00f3 s\u00e3o poss\u00edveis se estes j\u00e1 se conhecerem, o que implica que de alguma forma os n\u00f3s precisam ser inicializados para se contactarem ao sistema. Isto \u00e9 normalmente feito usando-se uma lista de n\u00f3s semente , com grande probabilidade de estar presentes no sistema, o que enfraquece a premissa de falta de entidades coordenadoras. Exemplos Protocolos epid\u00eamicos s\u00e3o amplamente usados na ind\u00fastria, com diferentes aplica\u00e7\u00f5es na ind\u00fastria, desde replica\u00e7\u00e3o de bancos de dados sem requisitos de consist\u00eancia forte, quando na descoberta de processos e detec\u00e7\u00e3o de defeitos em clusters , quanto em outras aplica\u00e7\u00f5es de dissemina\u00e7\u00e3o de informa\u00e7\u00e3o. CassandraDB: O Cassandra \u00e9 um banco de dados peer-2-peer em que n\u00f3s entram e saem do sistema e por isso podem n\u00e3o estar presentes para armazenar dados de sua responsabilidade. Quando um n\u00f3 do sistema volta a ficar online, gossiping \u00e9 usado para identificar e propagar os dados para as r\u00e9plicas devidas. Serf : Este sistema de gerenciamento de clusters usa gossiping para descobrir n\u00f3s, detectar se est\u00e3o funcionais ou n\u00e3o, ou mesmo propagar perguntas e respostas aos n\u00f3s do sistema, por exemplo \"quanto espa\u00e7o em disco voc\u00ea tem livre?\"","title":"Epid\u00eamicos"},{"location":"comm/epidemics/#protocolos-epidemicos","text":"H\u00e1 v\u00e1rias formas de se propagar informa\u00e7\u00e3o entre n\u00f3 de um sistema distribu\u00eddo. Uma forma particularmente interessante \u00e9 espelhada no modo como boatos ou doen\u00e7as se propagam entre um conjunto de indiv\u00edduos; este tipo de protocolo \u00e9 conhecido como gossiping (fofoca) ou epid\u00eamico . Gossiping Epidemia ou fofoca Multicast Tolerante a falhas Sem entidade central Algumas caracter\u00edsticas fundamentais dos protocolos epid\u00eamicos os distinguem de outros protocolos e frameworks de comunica\u00e7\u00e3o. Primeiro, estes protocolos resolvem um problema de multicast de mensagens, isto \u00e9, de comunica\u00e7\u00e3o um para muitos, em oposi\u00e7\u00e3o ao unicast das conex\u00f5es TCP ou \u00e0s invoca\u00e7\u00f5es remotas do RPC. Segundo, n\u00e3o h\u00e1 a figura de uma entidade coordenadora, como os brokers nas filas de mensagens e sistemas pubsub. Finalmente, a entrega de mensagens \u00e9 garantida probabil\u00edsticamente, o que quer dizer que quando uma mensagem \u00e9 enviada, h\u00e1 uma probabilidade dela ser entregue pelos demais processos, mas n\u00e3o h\u00e1 garantias de que o mesmo acontecer\u00e1. A despeito do que isso possa dar entender, estes protocolos podem ser configurados para uma taxa de entrega t\u00e3o alta quanto se queira e funcionam muito bem em redes n\u00e3o confi\u00e1veis, isto \u00e9, onde h\u00e1 perda de mensagens individuais. Na pr\u00e1tica, estes protocolos s\u00e3o usados na descoberta de n\u00f3 em um sistema distribu\u00eddo, para propagar informa\u00e7\u00f5es sobre seus estados individuais e para computar informa\u00e7\u00f5es globais.","title":"Protocolos Epid\u00eamicos"},{"location":"comm/epidemics/#algoritmo","text":"Imagine uma pessoa contaminada por um v\u00edrus; a medida que o tempo passa, esta pessoa tem contato com outras pessoas que, com certa probabilidade, se tornam tamb\u00e9m infectadas. Cada novo infectado passa a propagar o v\u00edrus nos seus contatos e, assim, depois de alguns ciclos, toda a popula\u00e7\u00e3o \u00e9 infectada. N\u00f3s podemos ent\u00e3o modelar estes protocolos com o seguinte algoritmo b\u00e1sico, que executa em rodadas. Algoritmo b\u00e1sico A cada rodada para cada n\u00f3 \\(p\\) infectado com o v\u00edrus \\(v\\) escolha \\(F\\) outros processos, \\(\\{p_1,p_2,p_3,...,p_f\\}, p_i \\neq p\\) , aleatoriamente para cada \\(p_i\\) , contamine \\(p_i\\) com \\(v\\) Agora vamos dissecar este algoritmo.","title":"Algoritmo"},{"location":"comm/epidemics/#exemplos","text":"Protocolos epid\u00eamicos s\u00e3o amplamente usados na ind\u00fastria, com diferentes aplica\u00e7\u00f5es na ind\u00fastria, desde replica\u00e7\u00e3o de bancos de dados sem requisitos de consist\u00eancia forte, quando na descoberta de processos e detec\u00e7\u00e3o de defeitos em clusters , quanto em outras aplica\u00e7\u00f5es de dissemina\u00e7\u00e3o de informa\u00e7\u00e3o. CassandraDB: O Cassandra \u00e9 um banco de dados peer-2-peer em que n\u00f3s entram e saem do sistema e por isso podem n\u00e3o estar presentes para armazenar dados de sua responsabilidade. Quando um n\u00f3 do sistema volta a ficar online, gossiping \u00e9 usado para identificar e propagar os dados para as r\u00e9plicas devidas. Serf : Este sistema de gerenciamento de clusters usa gossiping para descobrir n\u00f3s, detectar se est\u00e3o funcionais ou n\u00e3o, ou mesmo propagar perguntas e respostas aos n\u00f3s do sistema, por exemplo \"quanto espa\u00e7o em disco voc\u00ea tem livre?\"","title":"Exemplos"},{"location":"comm/internet/","text":"A Internet Se voc\u00ea se lembrar da pilha de protocolos de comunica\u00e7\u00e3o de refer\u00eancia OSI, lembrar\u00e1 que h\u00e1 uma organiza\u00e7\u00e3o em camadas em que cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel e serve de funda\u00e7\u00e3o para a funcionalidade da camada de cima, isto \u00e9, cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel de abstra\u00e7\u00e3o que serve de base para o n\u00edvel imediatamente superior: O protocolo de cada camada inclui cabe\u00e7alhos ( header ) e carga ( payload ) e o conjunto de cabe\u00e7alho + carga de uma camada \u00e9 considerado carga da camada inferior. Assim, embora tenha-se a impress\u00e3o de que cada camada conversa com a equivalente do outro lado da comunica\u00e7\u00e3o, na pr\u00e1tica, a comunica\u00e7\u00e3o desce e sobe a pilha. S\u00e3o sete as camadas: F\u00edsica: Bits Enlace: Frames/quadros; controle de fluxo; acesso ao meio. Rede: Datagramas/pacotes; roteamento Transporte: Controle de fluxo; fim a fim; confiabilidade; tcp e udp Sess\u00e3o: Streams/fluxos; conex\u00f5es l\u00f3gicas; restart; checkpoint; http, ssl Apresenta\u00e7\u00e3o: Objetos; json, xml; criptografia Aplica\u00e7\u00e3o: Aplica\u00e7\u00f5es; http, pop, ftp O internetworking protocol , ou IP, \u00e9 um protocolo da camada 3, mas apesar disso, nos referimos \u00e0 pilha que usa este protocolo como a pilha IP. Esta pilha \u00e9, na pr\u00e1tica, diferente da pilha de refer\u00eancia OSI por ser mais simples, como se v\u00ea na figura a seguir O IP trabalha conectando diversas redes via os roteadores , n\u00f3s que fazem parte de mais de uma rede. Nestes n\u00f3s, os os pacotes de dados sobem somente at\u00e9 a camada 3 e l\u00e1 s\u00e3o encaminhados, por melhor esfor\u00e7o para o pr\u00f3ximo segmento rumo ao destinat\u00e1rio. Assim, para a aplica\u00e7\u00e3o usando o IP, as redes se comportam como uma \u00fanica e coerente rede, exceto por alguns detalhes. Esta habilidade \u00e9 o que d\u00e1 o nome ao protocolo e, de fato, a toda a Internet. 1 Como usu\u00e1rios da pilha IP, temos que entender que o fato da pilha IP ser mais simples que a OSI implica que as funcionalidades das camadas 5 e 6 devem ser implementadas na camada de aplica\u00e7\u00e3o, por voc\u00ea desenvolvedor. Contudo, n\u00e3o tema! Estas funcionalidades podem se normalmente implementadas por meio de frameworks ou do middleware em uso. Alguns exemplos de tais funcionalidades s\u00e3o (De)Serializa\u00e7\u00e3o - convers\u00e3o de estruturas complexas, e.g., objetos e estruturas, em sequ\u00eancia de bytes. Nomeamento - identifica\u00e7\u00e3o de hosts Criptografia - oculta\u00e7\u00e3o dos dados trafegados Replica\u00e7\u00e3o - comunica\u00e7\u00e3o com m\u00faltiplos interlocutores Invoca\u00e7\u00e3o remota de procedimentos - abstra\u00e7\u00e3o de protocolos de comunica\u00e7\u00e3o A grande vantagem desta abordagem \u00e9 que se pode implementar exatamente e somente as funcionalidades desejadas. Este caracter\u00edstica \u00e9 conhecida como o argumento fim-a-fim no projeto de sistemas ; uma an\u00e1lise recente deste argumento foi feita aqui . Quanto \u00e0s camadas mais baixas, embora tenhamos que entender como a camada 3 funciona, dificilmente interagiremos com algo abaixo da camada 4, a camada de transporte , o que fazemos usando sockets . By User:Ludovic.ferre - Internet Connectivity Distribution&Core.svg, CC BY-SA 3.0, ( https://commons.wikimedia.org/w/index.php?curid=10030716 ) \u21a9","title":"Internet"},{"location":"comm/internet/#a-internet","text":"Se voc\u00ea se lembrar da pilha de protocolos de comunica\u00e7\u00e3o de refer\u00eancia OSI, lembrar\u00e1 que h\u00e1 uma organiza\u00e7\u00e3o em camadas em que cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel e serve de funda\u00e7\u00e3o para a funcionalidade da camada de cima, isto \u00e9, cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel de abstra\u00e7\u00e3o que serve de base para o n\u00edvel imediatamente superior: O protocolo de cada camada inclui cabe\u00e7alhos ( header ) e carga ( payload ) e o conjunto de cabe\u00e7alho + carga de uma camada \u00e9 considerado carga da camada inferior. Assim, embora tenha-se a impress\u00e3o de que cada camada conversa com a equivalente do outro lado da comunica\u00e7\u00e3o, na pr\u00e1tica, a comunica\u00e7\u00e3o desce e sobe a pilha. S\u00e3o sete as camadas: F\u00edsica: Bits Enlace: Frames/quadros; controle de fluxo; acesso ao meio. Rede: Datagramas/pacotes; roteamento Transporte: Controle de fluxo; fim a fim; confiabilidade; tcp e udp Sess\u00e3o: Streams/fluxos; conex\u00f5es l\u00f3gicas; restart; checkpoint; http, ssl Apresenta\u00e7\u00e3o: Objetos; json, xml; criptografia Aplica\u00e7\u00e3o: Aplica\u00e7\u00f5es; http, pop, ftp O internetworking protocol , ou IP, \u00e9 um protocolo da camada 3, mas apesar disso, nos referimos \u00e0 pilha que usa este protocolo como a pilha IP. Esta pilha \u00e9, na pr\u00e1tica, diferente da pilha de refer\u00eancia OSI por ser mais simples, como se v\u00ea na figura a seguir O IP trabalha conectando diversas redes via os roteadores , n\u00f3s que fazem parte de mais de uma rede. Nestes n\u00f3s, os os pacotes de dados sobem somente at\u00e9 a camada 3 e l\u00e1 s\u00e3o encaminhados, por melhor esfor\u00e7o para o pr\u00f3ximo segmento rumo ao destinat\u00e1rio. Assim, para a aplica\u00e7\u00e3o usando o IP, as redes se comportam como uma \u00fanica e coerente rede, exceto por alguns detalhes. Esta habilidade \u00e9 o que d\u00e1 o nome ao protocolo e, de fato, a toda a Internet. 1 Como usu\u00e1rios da pilha IP, temos que entender que o fato da pilha IP ser mais simples que a OSI implica que as funcionalidades das camadas 5 e 6 devem ser implementadas na camada de aplica\u00e7\u00e3o, por voc\u00ea desenvolvedor. Contudo, n\u00e3o tema! Estas funcionalidades podem se normalmente implementadas por meio de frameworks ou do middleware em uso. Alguns exemplos de tais funcionalidades s\u00e3o (De)Serializa\u00e7\u00e3o - convers\u00e3o de estruturas complexas, e.g., objetos e estruturas, em sequ\u00eancia de bytes. Nomeamento - identifica\u00e7\u00e3o de hosts Criptografia - oculta\u00e7\u00e3o dos dados trafegados Replica\u00e7\u00e3o - comunica\u00e7\u00e3o com m\u00faltiplos interlocutores Invoca\u00e7\u00e3o remota de procedimentos - abstra\u00e7\u00e3o de protocolos de comunica\u00e7\u00e3o A grande vantagem desta abordagem \u00e9 que se pode implementar exatamente e somente as funcionalidades desejadas. Este caracter\u00edstica \u00e9 conhecida como o argumento fim-a-fim no projeto de sistemas ; uma an\u00e1lise recente deste argumento foi feita aqui . Quanto \u00e0s camadas mais baixas, embora tenhamos que entender como a camada 3 funciona, dificilmente interagiremos com algo abaixo da camada 4, a camada de transporte , o que fazemos usando sockets . By User:Ludovic.ferre - Internet Connectivity Distribution&Core.svg, CC BY-SA 3.0, ( https://commons.wikimedia.org/w/index.php?curid=10030716 ) \u21a9","title":"A Internet"},{"location":"comm/middleware/","text":"Middleware e Transpar\u00eancia Middleware software hardware/OS aplica\u00e7\u00e3o diversas funcionalidades De acordo com Tanenbaum & Van Steen , middleware \u00e9 ... the software layer that lies between the operating system and applications on each side of a distributed computing system in a network. Isto \u00e9, o middleware \u00e9 a camada ware que fica no middle , entre, o software e o hardware . Software, no caso, \u00e9 a aplica\u00e7\u00e3o distribu\u00edda sendo desenvolvida e hardware \u00e9 a abstra\u00e7\u00e3o do host em que se executam os componentes, provida pelo sistema operacional. Uso aqui o termo abstra\u00e7\u00e3o porqu\u00ea o sistema operacional pode encapsular hardware real, mas tamb\u00e9m pode encapsular outra abstra\u00e7\u00e3o de hardware , por exemplo, uma m\u00e1quina virtual ou cont\u00eainer. A figura seguinte mostra um exemplo com tr\u00eas aplica\u00e7\u00f5es executando sobre um middleware , que por sua vez \u00e9 executado sobre diferentes sistemas operacionais, em hosts conectados por uma rede de comunica\u00e7\u00e3o. 1 Com este cen\u00e1rio em mente, \u00e9 importante entender o que diz Sacha Krakowiak quando afirma que as principais fun\u00e7\u00f5es do middleware s\u00e3o: esconder a distribui\u00e7\u00e3o e o fato de que um aplica\u00e7\u00e3o \u00e9 geralmente composta por m\u00faltiplas partes, executando em localiza\u00e7\u00f5es geograficamente distintas, esconder a heterogeneidade dos v\u00e1rios componentes de hardware, sistemas operacionais e protocolos de comunica\u00e7\u00e3o prover interfaces uniformes, de alto n\u00edvel e padronizadas para os desenvolvedores de aplica\u00e7\u00e3o e integradores, de forma que aplica\u00e7\u00f5es possam ser facilmente compostas, reusadas, portadas e feitas interoper\u00e1veis. Assim, os middleware facilitam a conex\u00e3o entre componentes e permitem o uso de protocolos mais abstratos que as opera\u00e7\u00f5es de write(byte[]) e read(): byte[] dos protocolos de baixo n\u00edvel, escondendo a complexidade da coordena\u00e7\u00e3o de sistemas independentes. Desenvolver sistemas distribu\u00eddos sem usar um middleware \u00e9 como desenvolver um aplicativo sem usar quaisquer bibliotecas: poss\u00edvel, mas complicado, e estar\u00e1 certamente reinventando a roda. Isto \u00e9, voc\u00ea praticamente tem que refazer o middleware antes de desenvolver o sistema em si. Idealmente, com o middleware , o desenvolvedor conseguiria facilmente implementar uma aplica\u00e7\u00e3o em que a distribui\u00e7\u00e3o fosse totalmente transparente, levando o sistema, uma cole\u00e7\u00e3o de sistemas computacionais (software ou hardware) independentes, a se apresentar para o usu\u00e1rio como um sistema \u00fanico , monol\u00edtico. Pense no browser e na WWW, por exemplo: o quanto voc\u00ea sabe sobre as p\u00e1ginas estarem particionadas em milh\u00f5es de servidores? Isso \u00e9 o que chamamos de transpar\u00eancia . Transpar\u00eancia Total Acesso + Localiza\u00e7\u00e3o + Reloca\u00e7\u00e3o + Migra\u00e7\u00e3o + Replica\u00e7\u00e3o + Falha Se n\u00e3o h\u00e1 qualquer ind\u00edcio de que a aplica\u00e7\u00e3o \u00e9 distribu\u00edda, ent\u00e3o temos transpar\u00eancia total . Podemos quebrar esta transpar\u00eancia total em v\u00e1rias transpar\u00eancias mais simples: Acesso , Localiza\u00e7\u00e3o , Reloca\u00e7\u00e3o , Migra\u00e7\u00e3o , Replica\u00e7\u00e3o , e Falha . Vejamos cada uma destas separadamente. Transpar\u00eancia de Acesso Transpar\u00eancia de Acesso como se apresenta representa\u00e7\u00e3o de dados arquitetura OS linguagem padr\u00f5es abertos e bem conhecidos. A transpar\u00eancia de acesso diz respeito \u00e0 representa\u00e7\u00e3o de dados e mecanismos de invoca\u00e7\u00e3o (arquitetura, formatos, linguagens...). Cada computador tem uma arquitetura e uma forma de representar seus dados. Por exemplo, considere os padr\u00f5es para representa\u00e7\u00e3o de n\u00fameros em ponto flutuante IEEE e IBM. Ambos dividem os bits em sinal, expoente e mantissa, mas com tamanhos diferentes. IEEE 2 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Half 16 1 5 10 Single 32 1 8 23 Double 64 1 11 52 Quadruple 128 1 15 112 IBM 3 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Single 32 1 7 24 Double 64 1 7 56 Quadruple 128 1 7 112 (8b ignorados) E se dois componentes de um SD executam em m\u00e1quinas com arquiteturas diferentes, como trocam n\u00fameros em ponto flutuante? \u00c9 preciso que usem um padr\u00e3o conhecido por ambos os hosts , seja o padr\u00e3o a arquitetura \"nativa\" do host ou um padr\u00e3o intermedi\u00e1rio, definido pelo middleware . A mesma quest\u00e3o \u00e9 v\u00e1lida para representa\u00e7\u00f5es de strings e classes, e diferen\u00e7as de sistemas operacionais e linguagens. No caso espec\u00edfico das strings, pense em um programa escrito em linguagem C e que este programa deva comunicar-se com um outro, escrito em Java, e trocar strings com o mesmo. Enquanto em C uma string \u00e9 uma sequ\u00eancia de bytes imprim\u00edveis terminadas por um \\0 , em Java uma string \u00e9 uma classe que encapsula uma sequ\u00eancia de chars, sendo que cada char \u00e9 um c\u00f3digo 16 bits representativo de um c\u00f3digo Unicode 4 . Como transferir strings entre duas plataformas? N\u00e3o faz\u00ea-lo? Simplificar a string Java? Estender a string C? Para se tentar obter transpar\u00eancia de acesso, \u00e9 importante que se use padr\u00f5es implementados em m\u00faltiplas arquiteturas, abertos e bem conhecidos, com interfaces bem definidas . Transpar\u00eancia de Localiza\u00e7\u00e3o Transpar\u00eancia de localiza\u00e7\u00e3o onde est\u00e1 o objeto lat\u00eancia cache paralelismo programa\u00e7\u00e3o ass\u00edncrona arquiteturas reativas A transpar\u00eancia de localiza\u00e7\u00e3o diz respeito a onde est\u00e1 o objeto acessado pela aplica\u00e7\u00e3o, seja um BD, p\u00e1gina Web ou servi\u00e7o de echo: pouco importa ao usu\u00e1rio, se est\u00e1 dentro da mesma m\u00e1quina de onde executa o acesso, se na sala ao lado ou em um servidor do outro lado do globo, desde que o servi\u00e7o seja provido de forma r\u00e1pida e confi\u00e1vel. A esta transpar\u00eancia \u00e9 essencial uma boa distribui\u00e7\u00e3o do servi\u00e7o, sobre uma rede com baixa lat\u00eancia, ou o uso de t\u00e9cnicas que permitam esconder a lat\u00eancia. Escondendo a Lat\u00eancia Para se esconder a lat\u00eancia, v\u00e1rias t\u00e1ticas s\u00e3o utiliz\u00e1veis: Caching de dados Em vez de sempre buscar os dados no servidor, mantenha c\u00f3pias locais dos dados que mudam menos (e.g., o CSS do stack overflow ). Use paralelismo Em vez de validar formul\u00e1rio ap\u00f3s preenchimento de cada campo, valide em paralelo enquanto usu\u00e1rio preenche o campo seguinte. Use callbacks para indicar campos com problemas a serem corrigidos. Saiba que nem todo problema \u00e9 paraleliz\u00e1vel, por exemplo, autentica\u00e7\u00e3o Use programa\u00e7\u00e3o ass\u00edncrona AsyncIO C# await/async Futures e Promises Outra forma de diminuir lat\u00eancia \u00e9 trazer para pr\u00f3ximo do usu\u00e1rio parte da computa\u00e7\u00e3o. Isto \u00e9 comumente feito com a interface com usu\u00e1rio, mas pode ser usado tamb\u00e9m para outras partes do sistema. Como exemplo do primeiro, pense em consoles de video-game que fazem o processamento gr\u00e1fico pesado de jogos online na casa do usu\u00e1rio 5 . Como exemplo do segundo, pense em aplicativos que mant\u00e9m os dados em celulares at\u00e9 que uma boa conex\u00e3o, por exemplo WiFi, esteja dispon\u00edvel para sincronizar com o servidor. De forma geral, pense em esconder lat\u00eancia pelos seguintes passos: Distribua tarefas Delegue computa\u00e7\u00e3o aos clientes (e.g., JavaScript e Applets Java) Particione dados entre servidores (e.g., Domain Name Service e World Wide Web) para dividir a carga e aumentar a vaz\u00e3o Aproxime dados dos clientes Mantenha c\u00f3pias de dados em m\u00faltiplos lugares. Atualize dados de acordo com necessidade (e.g., cache do navegador, com c\u00f3digo do google.com sendo atualizado a cada 4 dias) Transpar\u00eancia de Reloca\u00e7\u00e3o Transpar\u00eancia de reloca\u00e7\u00e3o como se movimenta visto por clientes As vezes componentes do sistema distribu\u00eddo precisam ser movimentados de uma localiza\u00e7\u00e3o \u00e0 outra, por exemplo porqu\u00ea um novo host foi contratado. Se implementadas corretamente, as t\u00e9cnicas que entregam transpar\u00eancia de localiza\u00e7\u00e3o n\u00e3o deixam que o cliente perceba a movimenta\u00e7\u00e3o, no que chamamos transpar\u00eancia de Reloca\u00e7\u00e3o. Rede de baixa lat\u00eancia Distribui\u00e7\u00e3o inteligente E.g: Servi\u00e7os de nome M\u00faltiplas c\u00f3pias C\u00f3pias tempor\u00e1rias Transpar\u00eancia de Migra\u00e7\u00e3o Transpar\u00eancia de migra\u00e7\u00e3o como se movimenta visto por si mesmo Do ponto de vista do pr\u00f3prio servi\u00e7o, n\u00e3o perceber que se est\u00e1 sendo movimentado \u00e9 chamado transpar\u00eancia de Migra\u00e7\u00e3o. Um servi\u00e7o com esta propriedade, n\u00e3o precisa ser parado e reconfigurado quando a mudan\u00e7a acontece. Uma das formas de se implementar esta propriedade \u00e9 atrav\u00e9s da migra\u00e7\u00e3o provida por m\u00e1quinas virtuais, usado, por exemplo, para consolidar o uso de servidores em nuvens computacionais. Veja o exemplo do VMotion da VMware. Na verdade, a movimenta\u00e7\u00e3o neste cen\u00e1rio, \u00e9 uma c\u00f3pia da m\u00e1quina virtual. Uma vez que a c\u00f3pia esteja pr\u00f3xima do fim, a imagem original \u00e9 congelada, a c\u00f3pia conclu\u00edda, e h\u00e1 um chaveamento na rede para se direcionar toda comunica\u00e7\u00e3o para nova c\u00f3pia. O m\u00e1quina original \u00e9 ent\u00e3o descartada. Transpar\u00eancia de Replica\u00e7\u00e3o Transpar\u00eancia de replica\u00e7\u00e3o redund\u00e2ncia visto por clientes A capacidade de ter c\u00f3pias de um servi\u00e7o e de direcionar trabalho de uma para outra \u00e9 tamb\u00e9m \u00fatil para se obter transpar\u00eancia no caso de falhas. Isto porqu\u00ea para se manter um servi\u00e7o funcional a despeito de falhas, \u00e9 preciso ter m\u00faltiplas c\u00f3pias, prontas para funcionar a qualquer momento. Dependendo das garantias desejadas na manuten\u00e7\u00e3o da consist\u00eancia entre as c\u00f3pias, o custo pode variar muito, de forma que para se ter um custo menor, tem-se garantias mais fracas, por exemplo, que as r\u00e9plicas tem um atraso entre elas de no m\u00e1ximo \\(X\\) minutos. Este \u00e9 um dilema parecido com o TCP x UDP, em que mais garantias implicam em maior custo de comunica\u00e7\u00e3o. Algumas aplica\u00e7\u00f5es toleram inconsist\u00eancias e podem viver com menores custos. Um exemplo famoso \u00e9 o dos \"carrinhos de compra\" da Amazon.com , que podem fechar pedidos com conte\u00fado diferente do desejado pelo cliente. Outras aplica\u00e7\u00f5es s\u00e3o normalmente constru\u00eddas com requisitos de consist\u00eancia forte entre as r\u00e9plicas, como sistemas financeiros. Para estas aplica\u00e7\u00f5es, uma t\u00e9cnica importante para se conseguir replica\u00e7\u00e3o \u00e9 o uso de frameworks de comunica\u00e7\u00e3o em grupo , que entregam para m\u00faltiplas inst\u00e2ncias de um mesmo servi\u00e7o, as mesmas mensagens, permitindo que elas se mantenham como c\u00f3pias. Esta t\u00e9cnica funciona se os servi\u00e7os forem m\u00e1quinas de estado determin\u00edsticas, que consideram como eventos as mensagens entregues pelo protocolo de comunica\u00e7\u00e3o em grupo e \u00e9 denominada replica\u00e7\u00e3o de m\u00e1quinas de estado . Replica\u00e7\u00e3o de M\u00e1quina de Estados determin\u00edstica mesmo estado inicial mesmos eventos mesmo estado final atraso entre r\u00e9plicas stateDiagram ei: Estado Inicial e1: Estado 1 e2: Estado 2 e3: Estado 3 en: Estado N ei --> e1 e1 --> e2 e2 --> e1 e2 --> e3 e3 --> e2 e1 --> en e3 --> en Todo Figura com state machine replication Novamente \u00e9 preciso chamar \u00e0 aten\u00e7\u00e3o a quest\u00e3o dos custos desta t\u00e9cnica. Replica\u00e7\u00e3o de M\u00e1quinas de Estados \u00e9 muito custosa e por isso faz-se um esfor\u00e7o para n\u00e3o utiliz\u00e1-la ou para utiliz\u00e1-la em \"cantinhos\" do sistema onde inconsist\u00eancias s\u00e3o absolutamente caras demais para sere permitidas. Isto porqu\u00ea manter m\u00faltiplas c\u00f3pias \\(\\Rightarrow\\) sincroniza\u00e7\u00e3o \\(\\Rightarrow\\) custos. Se houver mudan\u00e7as frequentes nos dados, tal custo precisa ser pago tamb\u00e9m frequentemente. Mitiga\u00e7\u00f5es incluem uso de r\u00e9plicas tempor\u00e1rias, protocolos de invalida\u00e7\u00e3o de cache, contrata\u00e7\u00e3o de redes com mais largura de banda e menor lat\u00eancia, sendo que estes \u00faltimos esbarram em limita\u00e7\u00f5es financeiras e f\u00edsicas. Transpar\u00eancia de Concorr\u00eancia Transpar\u00eancia de concorr\u00eancia obliviedade a outros servi\u00e7os visto por clientes Outra transpar\u00eancia almej\u00e1vel \u00e9 de concorr\u00eancia, isto \u00e9, imperceptibilidade quanto ao fato de que o servi\u00e7o est\u00e1 executando concorrentemente a outros servi\u00e7os e sendo acessado por outros clientes. Isto \u00e9 importante tanto em termos de seguran\u00e7a, no sentido de que um cliente n\u00e3o deveria acessar os dados do outro, caso isso seja um requisito do sistema, quanto tem termos de desempenho. Nuvens computacionais s\u00e3o um exemplo de onde este tipo de transpar\u00eancia \u00e9 essencial. Considere um servi\u00e7o de banco de dados em uma nuvem qualquer. Para prover a mesma interface com a qual usu\u00e1rios est\u00e3o acostumados a anos, \u00e9 poss\u00edvel que este servi\u00e7o seja simplesmente um wrapper ao redor do SGBD que se comprava e instalava in-house anteriormente. Para se tornar vi\u00e1vel, contudo, uma mesma inst\u00e2ncia deve servir m\u00faltiplos clientes, os tenants , sem que a carga de trabalho introduzida por um, interfira no desempenho do outro. No meio, chamamos esta propriedade de multi-tenancy , mas \u00e9 apenas um exemplo de transpar\u00eancia de concorr\u00eancia. Esta transpar\u00eancia est\u00e1 fundamentalmente ligada \u00e0 escalabilidade, isto \u00e9, \u00e0 adequa\u00e7\u00e3o dos pool de recursos \u00e0s demandas dos clientes: se mais clientes est\u00e3o presentes, ent\u00e3o aumente a quantidade de servidores ( scale up ) e separe as cargas ( sharding ); se menos clientes est\u00e3o presentes, ent\u00e3o desligue algumas m\u00e1quinas ( scale down ) e consolide recursos. Desafios para se obter transpar\u00eancia Apesar de desej\u00e1veis, as transpar\u00eancia discutidas s\u00e3o dif\u00edceis de se conseguir, principalmente se em conjunto. Isto porqu\u00ea, do ponto de vista de usu\u00e1rios espalhados pelo globo, atr\u00e1s de redes heterog\u00eaneas e com possibilidade de erros, acontecer\u00e3o atrasos e perdas na comunica\u00e7\u00e3o, denunciando a distribui\u00e7\u00e3o. Do ponto de vista do desenvolvedor , \u00e9 preciso tomar decis\u00f5es baseado em premissas ligadas \u00e0 realidade da rede. Por exemplo, se uma requisi\u00e7\u00e3o n\u00e3o foi respondida, quanto tempo um cliente deve esperar antes de reenvi\u00e1-la, possivelmente para outro servidor, sem incorrer em risco significativo da requisi\u00e7\u00e3o ser processada duas vezes? A resposta para esta pergunta \u00e9 muito mais complicada do que pode parecer. De forma geral , qualquer aumento de transpar\u00eancia tem um custo, seja em termos monet\u00e1rios (e.g., contrata\u00e7\u00e3o de enlace dedicado ou de host em outra posi\u00e7\u00e3o geogr\u00e1fica), ou em termos de desempenho (e.g., coordenar a entrega de mensagens em sistemas de comunica\u00e7\u00e3o em grupo). Provavelmente os maiores obst\u00e1culos para se alcan\u00e7ar os diversos tipos de transpar\u00eancia s\u00e3o impostos pela parte da infraestrutura que torna o sistema distribu\u00eddo poss\u00edvel, a rede. Para entender o porqu\u00ea, vejamos algumas premissas normalmente assumidas sobre a rede que n\u00e3o s\u00e3o, definitivamente, verdade: A lat\u00eancia \u00e9 zero. A largura de banda \u00e9 infinita. A rede \u00e9 confi\u00e1vel. A rede \u00e9 segura. A rede \u00e9 homog\u00eanea. A rede \u00e9 est\u00e1tica. A rede tem acesso gr\u00e1tis. A rede \u00e9 administrada por voc\u00ea ou algu\u00e9m acess\u00edvel. Distributed Systems: Principles and Paradigms. Cap\u00edtulo 1, Figura 1. \u21a9 IEEE Floating Point \u21a9 IBM Floating Point \u21a9 Simplifica\u00e7\u00f5es s\u00e3o poss\u00edveis, mas introduzem outras complexidades. \u21a9 O Google stadia \u00e9 uma plataforma de jogos que vai na contram\u00e3o desta ideia, levando todo o processamento pesado para a nuvem. \u21a9","title":"Middlewares"},{"location":"comm/middleware/#middleware-e-transparencia","text":"Middleware software hardware/OS aplica\u00e7\u00e3o diversas funcionalidades De acordo com Tanenbaum & Van Steen , middleware \u00e9 ... the software layer that lies between the operating system and applications on each side of a distributed computing system in a network. Isto \u00e9, o middleware \u00e9 a camada ware que fica no middle , entre, o software e o hardware . Software, no caso, \u00e9 a aplica\u00e7\u00e3o distribu\u00edda sendo desenvolvida e hardware \u00e9 a abstra\u00e7\u00e3o do host em que se executam os componentes, provida pelo sistema operacional. Uso aqui o termo abstra\u00e7\u00e3o porqu\u00ea o sistema operacional pode encapsular hardware real, mas tamb\u00e9m pode encapsular outra abstra\u00e7\u00e3o de hardware , por exemplo, uma m\u00e1quina virtual ou cont\u00eainer. A figura seguinte mostra um exemplo com tr\u00eas aplica\u00e7\u00f5es executando sobre um middleware , que por sua vez \u00e9 executado sobre diferentes sistemas operacionais, em hosts conectados por uma rede de comunica\u00e7\u00e3o. 1 Com este cen\u00e1rio em mente, \u00e9 importante entender o que diz Sacha Krakowiak quando afirma que as principais fun\u00e7\u00f5es do middleware s\u00e3o: esconder a distribui\u00e7\u00e3o e o fato de que um aplica\u00e7\u00e3o \u00e9 geralmente composta por m\u00faltiplas partes, executando em localiza\u00e7\u00f5es geograficamente distintas, esconder a heterogeneidade dos v\u00e1rios componentes de hardware, sistemas operacionais e protocolos de comunica\u00e7\u00e3o prover interfaces uniformes, de alto n\u00edvel e padronizadas para os desenvolvedores de aplica\u00e7\u00e3o e integradores, de forma que aplica\u00e7\u00f5es possam ser facilmente compostas, reusadas, portadas e feitas interoper\u00e1veis. Assim, os middleware facilitam a conex\u00e3o entre componentes e permitem o uso de protocolos mais abstratos que as opera\u00e7\u00f5es de write(byte[]) e read(): byte[] dos protocolos de baixo n\u00edvel, escondendo a complexidade da coordena\u00e7\u00e3o de sistemas independentes. Desenvolver sistemas distribu\u00eddos sem usar um middleware \u00e9 como desenvolver um aplicativo sem usar quaisquer bibliotecas: poss\u00edvel, mas complicado, e estar\u00e1 certamente reinventando a roda. Isto \u00e9, voc\u00ea praticamente tem que refazer o middleware antes de desenvolver o sistema em si. Idealmente, com o middleware , o desenvolvedor conseguiria facilmente implementar uma aplica\u00e7\u00e3o em que a distribui\u00e7\u00e3o fosse totalmente transparente, levando o sistema, uma cole\u00e7\u00e3o de sistemas computacionais (software ou hardware) independentes, a se apresentar para o usu\u00e1rio como um sistema \u00fanico , monol\u00edtico. Pense no browser e na WWW, por exemplo: o quanto voc\u00ea sabe sobre as p\u00e1ginas estarem particionadas em milh\u00f5es de servidores? Isso \u00e9 o que chamamos de transpar\u00eancia . Transpar\u00eancia Total Acesso + Localiza\u00e7\u00e3o + Reloca\u00e7\u00e3o + Migra\u00e7\u00e3o + Replica\u00e7\u00e3o + Falha Se n\u00e3o h\u00e1 qualquer ind\u00edcio de que a aplica\u00e7\u00e3o \u00e9 distribu\u00edda, ent\u00e3o temos transpar\u00eancia total . Podemos quebrar esta transpar\u00eancia total em v\u00e1rias transpar\u00eancias mais simples: Acesso , Localiza\u00e7\u00e3o , Reloca\u00e7\u00e3o , Migra\u00e7\u00e3o , Replica\u00e7\u00e3o , e Falha . Vejamos cada uma destas separadamente.","title":"Middleware e Transpar\u00eancia"},{"location":"comm/mom/","text":"Message Oriented Middleware Nesta se\u00e7\u00e3o, discutiremos Message Oriente Middleware (MOM), middlewares focados nas mensagens trocadas entre processos em um n\u00edvel mais alto do que quando revisamos sockets , que tamb\u00e9m s\u00e3o uma tecnologia para a troca de mensagens entre processos em um n\u00edvel de abstra\u00e7\u00e3o mais baixo e mais dif\u00edcil de usar corretamente. MOM apresentam-se em muitas formas, deste a Message Passing Interface (MPI), usada em aplica\u00e7\u00f5es HPC ( high performance computing ), quanto os sistemas de Message Queues (MQ) e Publisher/Subscriber (PubSub), usados em sistemas de informa\u00e7\u00e3o, Internet of Things (IOT) e Big Data . Message Passing Interface Message Passing Interface \u00e9 uma tecnologia muito usada para coordenar a distribui\u00e7\u00e3o e agrega\u00e7\u00e3o de dados em aplica\u00e7\u00f5es em HPC ( high performance computing ). Com este foco em HPC, \u00e9 natural implementa\u00e7\u00f5es se concentram em torno das linguagens percebidas como de melhor desempenho e mais usadas pelas comunidades que fazer uso de HPC, como C, C++ e Fortran. Por exemplo, OpenMPI , que se destaca como implementa\u00e7\u00e3o de MPI por ser de c\u00f3digo livre e bem mantida pela sua comunidade, \u00e9 focada nestas tr\u00eas linguagens, contudo, h\u00e1 tamb\u00e9m uma vers\u00e3o para Java. Sistemas usando MPI normalmente implementam o paradigma Single Program Multiple Data , em que o mesmo bin\u00e1rio \u00e9 executado em v\u00e1rios computadores diferentes, simultaneamente. Os processos ent\u00e3o recebem parte do volume total de dados a serem processados, e os processam da mesma forma ( paralelismo de dados : mesma tarefa, mas dados diferentes) ou recebem todos os dados mas executam processamentos diferentes ( paralelismo de tarefas : mesmos dados mas tarefas diferentes). Quatro das opera\u00e7\u00f5es providas pelas implementa\u00e7\u00f5es de MPI, mostradas na figura a seguir, prov\u00eaem as ferramentas para espalhar dados ( broadcast ), fragmentos dos dados ( scatter ), coletar e compor fragmentos ( gather ), ou reduzir resultados parciais ( reduce ). Por exemplo, suponha que voc\u00ea esteja desenvolvendo uma aplica\u00e7\u00e3o que far\u00e1 buscas de caminhos em grafos, com v\u00e1rias propriedades distintas. Digamos que precise calcular uma rota entre v\u00e1rios v\u00e9rtices do grafo usando caminhadas aleat\u00f3rias. Usando a fun\u00e7\u00e3o broadcast , voc\u00ea pode enviar uma c\u00f3pia do grafo para cada processo dispon\u00edvel para que independentemente calcule alguma rota. Ao final do c\u00e1lculo, um processo pode coletar os resultados de cada processo e escolher a melhor entre as rotas encontradas usando a fun\u00e7\u00e3o reduction . Se preferir que cada busca se restrinja a um subgrafo, onde os v\u00e1rios subgrafos s\u00e3o complementares, ent\u00e3o a fun\u00e7\u00e3o scatter seria usada. 1 Finalmente, a fun\u00e7\u00e3o gather poderia ser usada para coletar subgrafos com rotas encontradas e montar um grafo com todas as alternativas. Filas de mensagem Filas de mensagem prov\u00eam uma forma de encaminhar dados para n\u00f3s espec\u00edficos sem a necessidade de conex\u00e3o direta com os mesmos, atrav\u00e9s de caixas de entrada , funcionando como um servi\u00e7o de correio, parecido o servi\u00e7o de email ou mesmo as redes sociais para trocas de mensagens. Estes middleware permitem enfrentar uma das dificuldades de se implementar sistemas distribu\u00eddos hoje, advinda do n\u00famero cada vez maior de componentes, o fato de que componentes em saem do sistema frequentemente, por diversas raz\u00f5es, e que \u00e9 dif\u00edcil garantir que componentes que precisam interagir estar\u00e3o online ao mesmo tempo. Por exemplo, imagine se redes sociais tivessem o mesmo problema, isto \u00e9, se suas mensagens s\u00f3 pudessem ser entregues se tanto voc\u00ea quanto o destinat\u00e1rio estivessem online ao mesmo tempo. O modelo de caixa de entrada, contudo, permite que haja um desacoplamento temporal das contrapartes na conversa ao armazenar mensagens at\u00e9 que o destinat\u00e1rio esteja apto a receb\u00ea-las. Obviamente o desacoplamento temporal vale somente para remetentes e destinat\u00e1rios; os processos implementando o canal de comunica\u00e7\u00e3o onde as caixas de entrada residem, os brokers , devem se manter online para permitir a comunica\u00e7\u00e3o. As filas de mensagem, existentes h\u00e1 muito tempo, ganharam mais notoriedade recentemente, com a expans\u00e3o de seu uso em sistemas com arquiteturas microsservi\u00e7os, que estudaremos mais tarde. Exemplos RabbitMQ ZeroMQ IBM Websphere Estudos de caso Contudo, mesmo com as filas, outro problema permanece: com mais e mais componentes, \u00e9 dif\u00edcil fazer com que todos se conhe\u00e7am e que cada um saiba exatamente qual informa\u00e7\u00e3o deve disponibilizar para cada outro. Este problema seria semelhante a exigir que toda vez que fosse expressar sua opini\u00e3o na internet sobre variabilidade da taxa de gera\u00e7\u00e3o de memes nos fins de semana, tivesse que contactar individualmente cada um dos usu\u00e1rios da mesma rede para perguntar se est\u00e1 interessado. Felizmente, tamb\u00e9m assim como nas redes sociais, outro MOM permite que mensagens sejam ofertadas no sistema distribu\u00eddo e que somente aqueles processos que tenham se declarado interessados no t\u00f3pico as receber\u00e3o. Publish/Subscribe Os mecanismos de comunica\u00e7\u00e3o estudados at\u00e9 agora exigem que os processos se identifiquem e se enderecem para que haja troca de informa\u00e7\u00e3o. Quando falamos de comunica\u00e7\u00e3o publish/subscribe (ou pub/sub ), esta este requisito n\u00e3o est\u00e1 mais presente. Isto porqu\u00ea neste modelo o processo que envia uma mensagem, publisher , n\u00e3o envia mensagens para um destinat\u00e1rio. Em vez disso, publica mensagens com um t\u00f3picos , aos quais os subscribers se subscrevem. Assim, a comunica\u00e7\u00e3o n\u00e3o acontece diretamente mas via brokers publishers e subscribers n\u00e3o precisam executar ao mesmo tempo ou sequer saber da exist\u00eancia um do outro. Desta forma, um dos aspectos mais importantes proporcionados pelo padr\u00e3o pub/sub \u00e9 o desacoplamento em v\u00e1rias dimens\u00f5es das partes envolvidas. Espa\u00e7o: publishers e subscribers n\u00e3o precisam se conhecer (por exemplo, n\u00e3o h\u00e1 necessidade de informar endere\u00e7o IP e porta de cada um). Tempo: publishers e subscribers n\u00e3o precisam nem estar em execu\u00e7\u00e3o ao mesmo tempo. Sincroniza\u00e7\u00e3o: opera\u00e7\u00f5es em cada componente n\u00e3o precisam ser interrompida durante a publica\u00e7\u00e3o ou recebimento. Al\u00e9m disso, os brokers que servem de ponto de conex\u00e3o entre publishers e subscribers e que d\u00e3o persist\u00eancia \u00e0s mensagens (caso necess\u00e1rio) e distribuem as mensagens a quem devido, tamb\u00e9m permitem especifica\u00e7\u00e3o de filtros de mensagens associados \u00e0s subscri\u00e7\u00f5es, em diversos n\u00edveis. Baseada em assunto: subscribers se registram para receber mensagens de um ou mais t\u00f3picos de interesse. Em geral esses t\u00f3picos s\u00e3o strings com um formato hier\u00e1rquico, por exemplo /devices/sensor/+/temperature . Baseada em conte\u00fado: baseada em linguagem de filtragem de conte\u00fado espec\u00edfica. Downside: mensagem n\u00e3o pode ser criptografada. Baseada em tipo: leva em considera\u00e7\u00e3o o tipo ou classe de uma mensagem ou evento, como o tipo Exception e subtipos, por exemplo. Observe que uma mesma mensagem pode ser entregue a m\u00faltiplos subscribers se pertencer a um t\u00f3pico de interesse em comum e que um mesmo subscriber pode se interessar por diversos t\u00f3picos. Embora simples, frameworks pub/sub permitem a implementa\u00e7\u00e3o de arquiteturas complexas, como o exemplo da figura a seguir e como estudaremos mais adiante. O particionamento b\u00e1sico provido pela MPI \u00e9 simplesmente uma divis\u00e3o do buffer com os dados entre os v\u00e1rios processos, ent\u00e3o para fragmentar um grafo, voc\u00ea teria um pouco de trabalho. \u21a9","title":"MOM"},{"location":"comm/mom/#message-oriented-middleware","text":"Nesta se\u00e7\u00e3o, discutiremos Message Oriente Middleware (MOM), middlewares focados nas mensagens trocadas entre processos em um n\u00edvel mais alto do que quando revisamos sockets , que tamb\u00e9m s\u00e3o uma tecnologia para a troca de mensagens entre processos em um n\u00edvel de abstra\u00e7\u00e3o mais baixo e mais dif\u00edcil de usar corretamente. MOM apresentam-se em muitas formas, deste a Message Passing Interface (MPI), usada em aplica\u00e7\u00f5es HPC ( high performance computing ), quanto os sistemas de Message Queues (MQ) e Publisher/Subscriber (PubSub), usados em sistemas de informa\u00e7\u00e3o, Internet of Things (IOT) e Big Data .","title":"Message Oriented Middleware"},{"location":"comm/mom/#message-passing-interface","text":"Message Passing Interface \u00e9 uma tecnologia muito usada para coordenar a distribui\u00e7\u00e3o e agrega\u00e7\u00e3o de dados em aplica\u00e7\u00f5es em HPC ( high performance computing ). Com este foco em HPC, \u00e9 natural implementa\u00e7\u00f5es se concentram em torno das linguagens percebidas como de melhor desempenho e mais usadas pelas comunidades que fazer uso de HPC, como C, C++ e Fortran. Por exemplo, OpenMPI , que se destaca como implementa\u00e7\u00e3o de MPI por ser de c\u00f3digo livre e bem mantida pela sua comunidade, \u00e9 focada nestas tr\u00eas linguagens, contudo, h\u00e1 tamb\u00e9m uma vers\u00e3o para Java. Sistemas usando MPI normalmente implementam o paradigma Single Program Multiple Data , em que o mesmo bin\u00e1rio \u00e9 executado em v\u00e1rios computadores diferentes, simultaneamente. Os processos ent\u00e3o recebem parte do volume total de dados a serem processados, e os processam da mesma forma ( paralelismo de dados : mesma tarefa, mas dados diferentes) ou recebem todos os dados mas executam processamentos diferentes ( paralelismo de tarefas : mesmos dados mas tarefas diferentes). Quatro das opera\u00e7\u00f5es providas pelas implementa\u00e7\u00f5es de MPI, mostradas na figura a seguir, prov\u00eaem as ferramentas para espalhar dados ( broadcast ), fragmentos dos dados ( scatter ), coletar e compor fragmentos ( gather ), ou reduzir resultados parciais ( reduce ). Por exemplo, suponha que voc\u00ea esteja desenvolvendo uma aplica\u00e7\u00e3o que far\u00e1 buscas de caminhos em grafos, com v\u00e1rias propriedades distintas. Digamos que precise calcular uma rota entre v\u00e1rios v\u00e9rtices do grafo usando caminhadas aleat\u00f3rias. Usando a fun\u00e7\u00e3o broadcast , voc\u00ea pode enviar uma c\u00f3pia do grafo para cada processo dispon\u00edvel para que independentemente calcule alguma rota. Ao final do c\u00e1lculo, um processo pode coletar os resultados de cada processo e escolher a melhor entre as rotas encontradas usando a fun\u00e7\u00e3o reduction . Se preferir que cada busca se restrinja a um subgrafo, onde os v\u00e1rios subgrafos s\u00e3o complementares, ent\u00e3o a fun\u00e7\u00e3o scatter seria usada. 1 Finalmente, a fun\u00e7\u00e3o gather poderia ser usada para coletar subgrafos com rotas encontradas e montar um grafo com todas as alternativas.","title":"Message Passing Interface"},{"location":"comm/mom/#filas-de-mensagem","text":"Filas de mensagem prov\u00eam uma forma de encaminhar dados para n\u00f3s espec\u00edficos sem a necessidade de conex\u00e3o direta com os mesmos, atrav\u00e9s de caixas de entrada , funcionando como um servi\u00e7o de correio, parecido o servi\u00e7o de email ou mesmo as redes sociais para trocas de mensagens. Estes middleware permitem enfrentar uma das dificuldades de se implementar sistemas distribu\u00eddos hoje, advinda do n\u00famero cada vez maior de componentes, o fato de que componentes em saem do sistema frequentemente, por diversas raz\u00f5es, e que \u00e9 dif\u00edcil garantir que componentes que precisam interagir estar\u00e3o online ao mesmo tempo. Por exemplo, imagine se redes sociais tivessem o mesmo problema, isto \u00e9, se suas mensagens s\u00f3 pudessem ser entregues se tanto voc\u00ea quanto o destinat\u00e1rio estivessem online ao mesmo tempo. O modelo de caixa de entrada, contudo, permite que haja um desacoplamento temporal das contrapartes na conversa ao armazenar mensagens at\u00e9 que o destinat\u00e1rio esteja apto a receb\u00ea-las. Obviamente o desacoplamento temporal vale somente para remetentes e destinat\u00e1rios; os processos implementando o canal de comunica\u00e7\u00e3o onde as caixas de entrada residem, os brokers , devem se manter online para permitir a comunica\u00e7\u00e3o. As filas de mensagem, existentes h\u00e1 muito tempo, ganharam mais notoriedade recentemente, com a expans\u00e3o de seu uso em sistemas com arquiteturas microsservi\u00e7os, que estudaremos mais tarde. Exemplos RabbitMQ ZeroMQ IBM Websphere Estudos de caso Contudo, mesmo com as filas, outro problema permanece: com mais e mais componentes, \u00e9 dif\u00edcil fazer com que todos se conhe\u00e7am e que cada um saiba exatamente qual informa\u00e7\u00e3o deve disponibilizar para cada outro. Este problema seria semelhante a exigir que toda vez que fosse expressar sua opini\u00e3o na internet sobre variabilidade da taxa de gera\u00e7\u00e3o de memes nos fins de semana, tivesse que contactar individualmente cada um dos usu\u00e1rios da mesma rede para perguntar se est\u00e1 interessado. Felizmente, tamb\u00e9m assim como nas redes sociais, outro MOM permite que mensagens sejam ofertadas no sistema distribu\u00eddo e que somente aqueles processos que tenham se declarado interessados no t\u00f3pico as receber\u00e3o.","title":"Filas de mensagem"},{"location":"comm/mom/#publishsubscribe","text":"Os mecanismos de comunica\u00e7\u00e3o estudados at\u00e9 agora exigem que os processos se identifiquem e se enderecem para que haja troca de informa\u00e7\u00e3o. Quando falamos de comunica\u00e7\u00e3o publish/subscribe (ou pub/sub ), esta este requisito n\u00e3o est\u00e1 mais presente. Isto porqu\u00ea neste modelo o processo que envia uma mensagem, publisher , n\u00e3o envia mensagens para um destinat\u00e1rio. Em vez disso, publica mensagens com um t\u00f3picos , aos quais os subscribers se subscrevem. Assim, a comunica\u00e7\u00e3o n\u00e3o acontece diretamente mas via brokers publishers e subscribers n\u00e3o precisam executar ao mesmo tempo ou sequer saber da exist\u00eancia um do outro. Desta forma, um dos aspectos mais importantes proporcionados pelo padr\u00e3o pub/sub \u00e9 o desacoplamento em v\u00e1rias dimens\u00f5es das partes envolvidas. Espa\u00e7o: publishers e subscribers n\u00e3o precisam se conhecer (por exemplo, n\u00e3o h\u00e1 necessidade de informar endere\u00e7o IP e porta de cada um). Tempo: publishers e subscribers n\u00e3o precisam nem estar em execu\u00e7\u00e3o ao mesmo tempo. Sincroniza\u00e7\u00e3o: opera\u00e7\u00f5es em cada componente n\u00e3o precisam ser interrompida durante a publica\u00e7\u00e3o ou recebimento. Al\u00e9m disso, os brokers que servem de ponto de conex\u00e3o entre publishers e subscribers e que d\u00e3o persist\u00eancia \u00e0s mensagens (caso necess\u00e1rio) e distribuem as mensagens a quem devido, tamb\u00e9m permitem especifica\u00e7\u00e3o de filtros de mensagens associados \u00e0s subscri\u00e7\u00f5es, em diversos n\u00edveis. Baseada em assunto: subscribers se registram para receber mensagens de um ou mais t\u00f3picos de interesse. Em geral esses t\u00f3picos s\u00e3o strings com um formato hier\u00e1rquico, por exemplo /devices/sensor/+/temperature . Baseada em conte\u00fado: baseada em linguagem de filtragem de conte\u00fado espec\u00edfica. Downside: mensagem n\u00e3o pode ser criptografada. Baseada em tipo: leva em considera\u00e7\u00e3o o tipo ou classe de uma mensagem ou evento, como o tipo Exception e subtipos, por exemplo. Observe que uma mesma mensagem pode ser entregue a m\u00faltiplos subscribers se pertencer a um t\u00f3pico de interesse em comum e que um mesmo subscriber pode se interessar por diversos t\u00f3picos. Embora simples, frameworks pub/sub permitem a implementa\u00e7\u00e3o de arquiteturas complexas, como o exemplo da figura a seguir e como estudaremos mais adiante. O particionamento b\u00e1sico provido pela MPI \u00e9 simplesmente uma divis\u00e3o do buffer com os dados entre os v\u00e1rios processos, ent\u00e3o para fragmentar um grafo, voc\u00ea teria um pouco de trabalho. \u21a9","title":"Publish/Subscribe"},{"location":"comm/redes/","text":"Redes de Computadores Redes de computadores podem ter diversas topologias e caracter\u00edsticas, por exemplo: Ponto-a-ponto Barramento Compartilhado Token Ring Colis\u00f5es Sem Com Sem Roteamento Trivial Complexo Simples # Conex\u00f5es Exponencial Linear Linear Nas redes atuais, pode se dizer que o meio mais utilizado \u00e9 provido pela arquitetura Ethernet , que trata da comunica\u00e7\u00e3o entre n\u00f3s usando um barramento compartilhado , mesmo que este esteja por vezes escondido. Sobre este meio, s\u00e3o usados protocolos para, por exemplo, Controle de acesso ao meio Transmiss\u00e3o de mensagens Evitar e tratar colis\u00f5es As redes Ethernet, contudo, cobrem pequenas \u00e1reas e, para se ter conversas mais \"abrangentes\", \u00e9 necess\u00e1rio que se conecte diversas destas redes. A conversa ent\u00e3o \u00e9 feita por meio de intermedi\u00e1rios, gateways que conectam duas ou mais redes, permitindo que mensagens de um interlocutor sejam roteadas para o outro. Gateway Drawing. Um exemplo interessante das quest\u00f5es ligadas \u00e0 manuten\u00e7\u00e3o da conversa entre dois pontos \u00e9 a decis\u00e3o sobre o uso de comuta\u00e7\u00e3o de pacotes ( packet switching ) ou de circuitos ( circuit switching ). Comuta\u00e7\u00e3o de pacotes Comuta\u00e7\u00e3o de circuito Cada pacote viaja independentemente Todo pacote viaja por caminho predefinido Lat\u00eancia vari\u00e1vel Lat\u00eancia \"constante\" Banda n\u00e3o reservada Banda reservada Banda n\u00e3o desperdi\u00e7ada Banda desperdi\u00e7ada Outro fator importante \u00e9 a unidade m\u00e1xima de transmiss\u00e3o ( maximum transmission unit , MTU), o tamanho m\u00e1ximo de um pacote em determinada rede. \u00c9 necess\u00e1rio entender que qualquer quantidade de dados maior que o MTU precisar\u00e1 ser dividida em m\u00faltiplos pacotes. Tamb\u00e9m \u00e9 importante perceber que redes s\u00e3o heterog\u00eaneas, e que o v\u00e1rios segmentos no caminho entre origem e destino podem ter MTU diferentes, levando \u00e0 fragmenta\u00e7\u00e3o de pacotes em tr\u00e2nsito e, possivelmente, entrega desordenada dos mesmos. Fragmenta\u00e7\u00e3o Drawing. Finalmente, h\u00e1 uma quest\u00e3o importante relativa \u00e0 confiabilidade na transmiss\u00e3o dos elementos da conversa, isto \u00e9, se a rede deve garantir ou n\u00e3o que algo \"dito\" por um interlocutor deve garantidamente ser \"ouvido\" pelo outro, ou se a mensagem pode ser perdida no meio. Felizmente boa parte da complexidade da resolu\u00e7\u00e3o destas quest\u00f5es \u00e9 abstra\u00edda do desenvolvedor dos sistemas distribu\u00eddos , isto \u00e9, voc\u00ea, cabendo-lhe apenas a decis\u00e3o de qual protocolo utilizar. Nas redes atuais, a conversa entre componentes ser\u00e1 feita, em algum n\u00edvel, por meio dos protocolos da arquitetura Internet .","title":"Redes"},{"location":"comm/redes/#redes-de-computadores","text":"Redes de computadores podem ter diversas topologias e caracter\u00edsticas, por exemplo: Ponto-a-ponto Barramento Compartilhado Token Ring Colis\u00f5es Sem Com Sem Roteamento Trivial Complexo Simples # Conex\u00f5es Exponencial Linear Linear Nas redes atuais, pode se dizer que o meio mais utilizado \u00e9 provido pela arquitetura Ethernet , que trata da comunica\u00e7\u00e3o entre n\u00f3s usando um barramento compartilhado , mesmo que este esteja por vezes escondido. Sobre este meio, s\u00e3o usados protocolos para, por exemplo, Controle de acesso ao meio Transmiss\u00e3o de mensagens Evitar e tratar colis\u00f5es As redes Ethernet, contudo, cobrem pequenas \u00e1reas e, para se ter conversas mais \"abrangentes\", \u00e9 necess\u00e1rio que se conecte diversas destas redes. A conversa ent\u00e3o \u00e9 feita por meio de intermedi\u00e1rios, gateways que conectam duas ou mais redes, permitindo que mensagens de um interlocutor sejam roteadas para o outro. Gateway Drawing. Um exemplo interessante das quest\u00f5es ligadas \u00e0 manuten\u00e7\u00e3o da conversa entre dois pontos \u00e9 a decis\u00e3o sobre o uso de comuta\u00e7\u00e3o de pacotes ( packet switching ) ou de circuitos ( circuit switching ). Comuta\u00e7\u00e3o de pacotes Comuta\u00e7\u00e3o de circuito Cada pacote viaja independentemente Todo pacote viaja por caminho predefinido Lat\u00eancia vari\u00e1vel Lat\u00eancia \"constante\" Banda n\u00e3o reservada Banda reservada Banda n\u00e3o desperdi\u00e7ada Banda desperdi\u00e7ada Outro fator importante \u00e9 a unidade m\u00e1xima de transmiss\u00e3o ( maximum transmission unit , MTU), o tamanho m\u00e1ximo de um pacote em determinada rede. \u00c9 necess\u00e1rio entender que qualquer quantidade de dados maior que o MTU precisar\u00e1 ser dividida em m\u00faltiplos pacotes. Tamb\u00e9m \u00e9 importante perceber que redes s\u00e3o heterog\u00eaneas, e que o v\u00e1rios segmentos no caminho entre origem e destino podem ter MTU diferentes, levando \u00e0 fragmenta\u00e7\u00e3o de pacotes em tr\u00e2nsito e, possivelmente, entrega desordenada dos mesmos. Fragmenta\u00e7\u00e3o Drawing. Finalmente, h\u00e1 uma quest\u00e3o importante relativa \u00e0 confiabilidade na transmiss\u00e3o dos elementos da conversa, isto \u00e9, se a rede deve garantir ou n\u00e3o que algo \"dito\" por um interlocutor deve garantidamente ser \"ouvido\" pelo outro, ou se a mensagem pode ser perdida no meio. Felizmente boa parte da complexidade da resolu\u00e7\u00e3o destas quest\u00f5es \u00e9 abstra\u00edda do desenvolvedor dos sistemas distribu\u00eddos , isto \u00e9, voc\u00ea, cabendo-lhe apenas a decis\u00e3o de qual protocolo utilizar. Nas redes atuais, a conversa entre componentes ser\u00e1 feita, em algum n\u00edvel, por meio dos protocolos da arquitetura Internet .","title":"Redes de Computadores"},{"location":"comm/refs/","text":"The call Stack Message Oriented Middleware Enterprise Message Bus To Message Bus or Not: distributed system design","title":"Refer\u00eancias"},{"location":"comm/rpc/","text":"Invoca\u00e7\u00e3o Remota de Procedimentos - RPC Em 1984, Birrel e Nelson 1 introduziram o mecanismo de Invoca\u00e7\u00e3o Remota de Procedimentos ( Remote Procedure Calls ), que permite que processos fa\u00e7am, pasmem, invoca\u00e7\u00f5es de procedimentos remotos! \u00d3bvio, a inova\u00e7\u00e3o n\u00e3o est\u00e1 na capacidade de uma m\u00e1quina conversar com outra, mas em como esta conversa acontece, do ponto de vista do programador. Por exemplo, RPC permite que se procure a substring apontada por c dentro da string apontada por a , a partir da posi\u00e7\u00e3o 3, usando x = substring(a,3,c); mas com o invocador da fun\u00e7\u00e3o em um processo e a implementa\u00e7\u00e3o da fun\u00e7\u00e3o propriamente dita, em outro, possivelmente em outra m\u00e1quina. Stubs Se o que queremos \u00e9 colocar o c\u00f3digo da fun\u00e7\u00e3o substring em um outro processo e execut\u00e1-lo como se estiv\u00e9ssemos no mesmo processo que faz a invoca\u00e7\u00e3o, precisamos pensar em v\u00e1rias quest\u00f5es, sendo a principal o fato de que, embora seja simulada a invoca\u00e7\u00e3o local, \"por debaixo do cap\u00f4\" h\u00e1 o uso sockets para a comunica\u00e7\u00e3o com o processo remoto. Esta simula\u00e7\u00e3o usar\u00e1 c\u00f3digo extra, que finge implementar substring para o invocador mas delega ao c\u00f3digo remoto o trabalho real da busca. Este c\u00f3digo extra \u00e9 conhecido como stub , ou para ser mais preciso, stub cliente , que faz parte do processo invocando a opera\u00e7\u00e3o, e stub servidor , que faz parte do processo executando a opera\u00e7\u00e3o invocada 2 . Assim, o cliente invoca a fun\u00e7\u00e3o no stub cliente, achando que \u00e9 a fun\u00e7\u00e3o que quer executar. O stub cliente faz o marshaling 3 dos par\u00e2metros e usa o SO para transferir os dados via rede para o stub servidor. Quando recebe a resposta do servidor, o stub cliente retorna a mesma resposta, como se tivesse sido calculada localmente. J\u00e1 o stub servidor fica esperando o contato do cliente. Quando acontece, faz o unmarshalling dos dados, invoca a fun\u00e7\u00e3o localmente na aplica\u00e7\u00e3o servidor e pega o resultado, que retorna ao cliente. Stub cliente Stub servidor 1. invoca substring no stub 1. retorna o resultado para o stub 2. conecta-se ao servidor, envia par\u00e2metros e especifica a fun\u00e7\u00e3o 2. envia resulta serializado para cliente 3. transmite os dados serializados transmite resposta serializada 4. desserializa par\u00e2metros 4. desserializa os par\u00e2metro 5. invoca a fun\u00e7\u00e3o substring localmente 5. retorna o resultado para o invocador Transpar\u00eancia \u00c9 para o programador a grande vantagem do uso de RPC, pois se pode escrever c\u00f3digo distribu\u00eddo \"igual\" ao n\u00e3o-distribu\u00eddo, certo? Isto \u00e9, interface baseada em procedimentos e sem a necessidade de detalhar portas, sockets, e representa\u00e7\u00e3o de dados . Ou seja, tudo \u00e9 transparente! Como j\u00e1 discutimos, v\u00e1rios fatores trabalham contra a transpar\u00eancia em sistemas distribu\u00eddos . Em espec\u00edfico quanto \u00e0 transpar\u00eancia dada pelo RPC, tamb\u00e9m temos limita\u00e7\u00f5es. Antes de nos aprofundarmos, lembremos como uma invoca\u00e7\u00e3o de fun\u00e7\u00f5es acontece normalmente dentro de um \u00fanico processo. 4 O c\u00f3digo x = substring(a,3,c); , que procura *c em *a , \u00e9 traduzido nos seguintes passos em linguagem de m\u00e1quina: coloque o valor de c na pilha coloque 3 na pilha coloque o valor de a na pilha coloque o endere\u00e7o de retorno na pilha (junto com outros dados de controle) salte para substring ajustando o instruction pointer ... procure substring ... coloque o resultado no acumulador limpe a pilha salte de volta recuperando o endere\u00e7o de retorno da pilha e ajustando o IP coloque resultado em x O problema \u00e9 que h\u00e1 uma distin\u00e7\u00e3o clara em pelo menos dois processos e se pensarmos no c\u00f3digo descrito acima, temos que entender que processos independentes n\u00e3o compartilham um espa\u00e7o de endere\u00e7amento, e processos independentes n\u00e3o compartilham uma pilha. Assim, como fica a passagem de par\u00e2metro por refer\u00eancia , uma vez que o stub servidor n\u00e3o pode usar endere\u00e7os do espa\u00e7o de endere\u00e7amento do cliente? Algumas abordagens para simular a passagem por refer\u00eancia s\u00e3o poss\u00edveis. Por exemplo, o valor apontado pelo ponteiro \u00e9 passado para o servidor , que armazena o valor e alguma posi\u00e7\u00e3o de mem\u00f3ria e passa o endere\u00e7o de tal posi\u00e7\u00e3o para a fun\u00e7\u00e3o invocada. Contudo, a modifica\u00e7\u00e3o do valor pela fun\u00e7\u00e3o n\u00e3o reflete imediatamente no invocador; tais valores tem que ser copiados novamente e usados para sobrescrever o valor original no cliente. Al\u00e9m disso, esta abordagem s\u00f3 \u00e9 poss\u00edvel se o valor apontado for delimitado, o que nem sempre \u00e9 f\u00e1cil de determinar. Por exemplo, se o ponteiro for para o primeiro elemento de uma lista, o que deve ser copiado para o servidor? S\u00f3 o primeiro elemento? Toda a lista? Como ensinar para o framework RPC o que \u00e9 \"toda\" a lista? Java \"resolve\" o problema da passagem de par\u00e2metro por refer\u00eancia passando todo o grafo do objeto passado como par\u00e2metro para o servidor. Isto \u00e9, al\u00e9m de serializar o objeto apontado no par\u00e2metro, se o mesmo aponta para outros objetos, estes tamb\u00e9m ser\u00e3o serializados e transferidos; o servidor ir\u00e1 ent\u00e3o reconstruir todo o grafo e passar para o m\u00e9todo sendo invocado. \u00c9 muito f\u00e1cil ver que esta abordagem pode se tornar invi\u00e1vel rapidamente. Quando for o caso, Java permite marcar objetos como remotos e, em vez de serializar este objeto e enviar para o servidor, envia informa\u00e7\u00e3o suficiente para que o servidor possa invocar m\u00e9todos em tal objeto no cliente, tornando nebulosa a defini\u00e7\u00e3o de quem \u00e9 quem. Outros fatores tamb\u00e9m trabalham contra a transpar\u00eancia para o desenvolvedor. Descoberta de Servi\u00e7os Por exemplo, mesmo que o socket seja ocultado, ele ainda existe e precisa de informa\u00e7\u00f5es sobre onde se conectar (endere\u00e7o e porta), que de alguma forma deve ser passada para o framework de RPC. Esta informa\u00e7\u00e3o pode ser configurada a priori por um administrador de sistemas, mas requer atualiza\u00e7\u00f5es sempre que a localiza\u00e7\u00e3o do servi\u00e7o for alterada ou novos servidores adicionados. Mais interessante seria um mecanismo que permitisse uma indire\u00e7\u00e3o para o servi\u00e7o; o pr\u00f3prio DNS pode ser uma op\u00e7\u00e3o inicial, mas um servi\u00e7o dedicado pode ser mais apropriado, pois permite descobrir servi\u00e7os e n\u00e3o apenas servidores. Birrel e Nelson propuseram um servi\u00e7o de P\u00e1ginas Amarelas , no qual clientes podem questionar quem oferece um certo servi\u00e7o e serem redirecionados automaticamente. Esta abordagem tem seus pr\u00f3prios problemas, como por exemplo determinar quem administra o servi\u00e7o para incluir novos servidores. E como determinar qual servi\u00e7o acessar, caso hajam m\u00faltiplas op\u00e7\u00f5es de servidores . Apesar dos problemas, p\u00e1ginas amarelas foram usadas em abordagens muito mais recentes para descobertas de servi\u00e7os, por exemplo Web Services Discovery , que permite a descoberta de Web Services em escala global, e Java Remote Object Registry que permite a descoberta de objetos remotos Java. Tratamento de Exce\u00e7\u00f5es Uma vez que a invoca\u00e7\u00e3o \u00e9 remota, h\u00e1 sempre o risco de problemas de comunica\u00e7\u00e3o entre cliente e servidor. Logo, \u00e9 necess\u00e1ria a introdu\u00e7\u00e3o de c\u00f3digo para tratamento de erros deste tipo, o que absolutamente n\u00e3o era necess\u00e1rio no caso do c\u00f3digo centralizado. Assim, o que era um simples x = substring(a,3,c); passa para algo assim (em uma linguagem fict\u00edcia): 1 2 3 4 5 6 7 8 9 10 11 12 13 int x = -2 ; try { x = substring ( a , 3 , c ); } catch ( CommunicationFailureException cfe ) { log_error ( \"Como pode substring falhar? Desespero!!!\" ); } if ( x == -2 ) system_exit ( -2 ) else if ( x == -1 ) //n\u00e3o achou else //achou na posi\u00e7\u00e3o x O que nos leva novamente ao ponto sobre n\u00e3o haver transpar\u00eancia total em sistemas distribu\u00eddos... e esta falta de transpar\u00eancia pode ser muito mais complicada do que simplesmente adicionar try e catch ao seu c\u00f3digo. Mais que isso, imagine que a opera\u00e7\u00e3o sendo executada altere algum estado no servidor. Se esta fosse uma operac\u00e3o local, cada invoca\u00e7\u00e3o da opera\u00e7\u00e3o corresponderia a exatamente uma execu\u00e7\u00e3o da opera\u00e7\u00e3o, na aus\u00eancia de falhas. No caso de falhas, se o processo quebra como um todo, no seu rein\u00edcio, pode-se identificar se a opera\u00e7\u00e3o foi ou n\u00e3o executada e aplicar a\u00e7\u00f5es corretivas. Mas e no caso remoto? Reexecu\u00e7\u00f5es No caso da opera\u00e7\u00e3o distribu\u00edda, se o servidor quebra, isso levar\u00e1 a um erro ser percebido do lado do cliente como uma falha na conex\u00e3o . Se o cliente havia invocado uma opera\u00e7\u00e3o mas percebeu o erro antes de receber uma confirma\u00e7\u00e3o de sua execu\u00e7\u00e3o, isto pode indicar que: (i) ou a requisi\u00e7\u00e3o nunca foi recebida pelo servidor e, portanto, n\u00e3o foi executada, (ii) ou a execu\u00e7\u00e3o foi recebida e executada, mas a resposta n\u00e3o foi enviada. O cliente tem que tratar o erro, mas como? Se a opera\u00e7\u00e3o precisa ser executada a qualquer custo , o cliente pode retent\u00e1-la quando conseguir novo contato com o servidor (ou mesmo com outro). Neste caso, se o que de fato aconteceu foi a situa\u00e7\u00e3o (i), ent\u00e3o retentar garantir\u00e1 que a opera\u00e7\u00e3o seja executada pelo servidor, mesmo que v\u00e1rias tentativas sejam necess\u00e1rias. Contudo, se o que o ocorreu foi a situa\u00e7\u00e3o (ii), ent\u00e3o reenviar a opera\u00e7\u00e3o levar\u00e1 a mesma a ser executada m\u00faltiplas vezes, o que pode ou n\u00e3o ser ok. Esta abordagem \u00e9 o que garantir\u00e1 que a execu\u00e7\u00e3o acontece pelo menos 1 vez . Imagine que a opera\u00e7\u00e3o se tratasse de uma transfer\u00eancia de saldo, ou a encomenda de de um caminh\u00e3o carregado de algum produto caro. Neste caso, reexecutar n\u00e3o parece ser uma op\u00e7\u00e3o. Neste caso, talvez a melhor op\u00e7\u00e3o seja n\u00e3o retentar a opera\u00e7\u00e3o, o que levar\u00e1 a zero execu\u00e7\u00f5es na situa\u00e7\u00e3o (ii) e uma execu\u00e7\u00e3o na situa\u00e7\u00e3o, ou seja, a no m\u00e1ximo uma execu\u00e7\u00e3o. Uma situa\u00e7\u00e3o em que esta abordagem \u00e9 claramente prefer\u00edvel \u00e9 a entrega de quadros em um stream de v\u00eddeo ou \u00e1udio, devido \u00e0 import\u00e2ncia da opera\u00e7\u00e3o ser atrelada ao momento de sua execu\u00e7\u00e3o. Quantidade de execu\u00e7\u00f5es No m\u00e1ximo uma - n\u00e3o retentar Exatamente uma - impedir que falhas aconte\u00e7am Pelo menos uma - retentar at\u00e9 ter confirma\u00e7\u00e3o Nenhuma destas abordagens \u00e9 igual ao que \u00e9 garantido na vers\u00e3o centralizada e que \u00e9 provavelmente o que todo desenvolvedor desejaria para suas invoca\u00e7\u00f5es de m\u00e9todos, que fossem executados exatamente uma vez. Garantir esta sem\u00e2ntica na comunica\u00e7\u00e3o \u00e9 muito dif\u00edcil, pois \u00e9 imposs\u00edvel ter certeza de que uma mensagem n\u00e3o foi processada pelo servidor ainda. De fato, \u00e9 imposs\u00edvel ter certeza se o servidor falhou; pode ter sido apenas uma falha na comunica\u00e7\u00e3o. Como \u00e9 imposs\u00edvel evitar falhas, se uma opera\u00e7\u00e3o deve executada, ela deve ser retentada. Mas ela n\u00e3o pode ser repetida, ent\u00e3o a alternativa \u00e9 tornar as opera\u00e7\u00f5es idempotentes , o que quer dizer que o efeito desejado \u00e9 alcan\u00e7ado pela primeira execu\u00e7\u00e3o e que execu\u00e7\u00f5es seguintes n\u00e3o alteram o estado. Opera\u00e7\u00f5es idempotentes M\u00faltiplas execu\u00e7\u00f5es tem o mesmo efeito uma execu\u00e7\u00e3o. Exemplo: x = 10 Anti-exemplo: x = x+1 . Infelizmente n\u00e3o \u00e9 trivial programar para idempot\u00eancia, principalmente se o servidor for acessado concorrentemente por m\u00faltiplos clientes, tornando seu estado uam regi\u00e3o cr\u00edtica. Concorr\u00eancia no servidor \u00c9 importante notar que um servidor n\u00e3o est\u00e1 obrigado a atender requisi\u00e7\u00f5es de somente um cliente. Logo, se m\u00faltiplos clientes acessam o mesmo servidor, o estado do servidor ser\u00e1 \"compartilhado\" pelos v\u00e1rios clientes e passos s\u00e3o necess\u00e1rios para que o comportamento no acesso deste estado seja coerente com a especifica\u00e7\u00e3o. Pense por exemplo em um servidor que conta o n\u00famero de acessos feitos por clientes. O incremento do contador deve ser considerado uma regi\u00e3o cr\u00edtica, caso m\u00faltiplos threads tratem as requisi\u00e7\u00f5es dos clientes, o que j\u00e1 vimos ser uma boa idia. Claro que dificilmente seu servidor seria algo t\u00e3o simples assim. Em vez disso, ele provavelmente executar\u00e1 l\u00f3gicas complicadas, como por exemplo, armazenar o estado de contas banc\u00e1rias e, neste caso, as fun\u00e7\u00f5es expostas por RPC incluir\u00edam a opera\u00e7\u00e3o transferir saldo de A para B , o que nos leva a mais um problema interessante, o do risco de reexecu\u00e7\u00f5es. Al\u00e9m disso, o servidor provavelmente suportar\u00e1 diversas opera\u00e7\u00f5es e por isso dever\u00e1 identificar qual a opera\u00e7\u00e3o sendo requisitada. Isto \u00e9 feito por um dispatcher , que demultiplexa as opera\u00e7\u00f5es requisitadas; o dispatcher pode, em algumas arquiteturas, ser independente do skeleton em si. Interface Definition Language H\u00e1 diversas op\u00e7\u00f5es de frameworks para RPC, com diferentes caracter\u00edsticas, focos, e garantias. Alguns s\u00e3o parte da linguagem e outros s\u00e3o implementados como bibliotecas. Alguns suportam m\u00faltiplas linguagens e alguns apenas uma. Suporte a RPC na linguagem Sem RPC: C, C++, Java < 5.0 (1.5), Python Com RPC: Java, Go, Erlang, Scala, Haskell Ambientes heterog\u00eaneos: Thrift, gRPC, Akka, SOAP Frameworks mais modernos permitem escolher a forma de serializa\u00e7\u00e3o dos dados, se leg\u00edvel para humanos ou bin\u00e1rio, se o transporte \u00e9 via HTTP ou protocolo mais baixo n\u00edvel, se os dados trafegam abertamente ou se faz uso de comunica\u00e7\u00e3o criptografada (SSL). Outros permitem escolher sem\u00e2ntica de execu\u00e7\u00e3o entre no m\u00e1ximo uma e pelo menos uma , e h\u00e1 at\u00e9 quem prometa exatamente uma . Mas todos os frameworks tem algumas caracter\u00edsticas em comum e uma delas \u00e9 o uso de uma Linguagem de Defini\u00e7\u00e3o de Interface (IDL). Uma IDL \u00e9 a linguagem pela qual desenvolvedor define quais as opera\u00e7\u00f5es (fun\u00e7\u00f5es, procedimentos, m\u00e9todos) ser\u00e3o acess\u00edveis via RPC e quais os seus operandos. H\u00e1 v\u00e1rias IDL definidas, para os diversos frameworks dispon\u00edveis. A imagem a seguir mostra um exemplo gen\u00e9rico da cria\u00e7\u00e3o cliente e servidor usando um framework RPC gen\u00e9rico, inclusive o processamento da defini\u00e7\u00e3o feita em IDL do servi\u00e7o e a jun\u00e7\u00e3o deste c\u00f3digo gerado ao c\u00f3digo escrito pelo desenvolvedor. O fluxo de processamento \u00e9 o seguinte: Arquivo em IDL \u00e9 compilado por um compilador IDL e gera diversos arquivos: stub cliente - c\u00f3digo que implementa a interface, com c\u00f3digo para repassar invoca\u00e7\u00f5es para o servidor. stub servidor ( skeleton ) - c\u00f3digo que atende a conex\u00f5es do stub cliente e repassa para a implementa\u00e7\u00e3o pr\u00f3pria da fun\u00e7\u00e3o. convers\u00e3o de dados - c\u00f3digo que serializa e deserializa dados para serem trafegados de e para o servidor cabe\u00e7alhos - defini\u00e7\u00f5es da interface na linguagem de desenvolvimento da aplica\u00e7\u00e3o; se linguagem C, por exemplo, estes ser\u00e3o arquivos .h , se em Java, ent\u00e3o estes ser\u00e3o arquivos .java , com defini\u00e7\u00e3o de interface . O c\u00f3digo cliente \u00e9 compilado e gera o cliente, que deve inicializar a infraestrutura RPC Tipo de transporte SSL? Localizar servidor Lidar com falhas O c\u00f3digo servidor \u00e9 compilado e gera o servidor, que deve exportar e localizar servi\u00e7os (servi\u00e7o de nomea\u00e7\u00e3o) Gerenciamento de portas Conex\u00f5es Varia\u00e7\u00f5es de processamento Invoca\u00e7\u00f5es de procedimentos e m\u00e9todos s\u00e3o geralmente s\u00edncronas, o que quer dizer que o chamador do procedimento normalmente espera a conclus\u00e3o do procedimento para continuar a executar. Essa abordagem \u00e9 necess\u00e1ria quando o chamador precisa do resultado do procedimento para continuar, mas deixa de fazer sentido quando ou o procedimento n\u00e3o tem um resultado ... ... ou quando o resultado s\u00f3 ser\u00e1 necess\u00e1rio mais tarde, podendo ser recebido via um callback . Independentemente de qual abordagem for utilizada, ambos os processos, chamador e chamado, precisam estar ativos ao mesmo tempo para que a comunica\u00e7\u00e3o aconte\u00e7a, isto \u00e9, os processos est\u00e3o acoplados no tempo . Nas se\u00e7\u00f5es seguintes veremos como este requisito pode ser relaxado, permitindo que os processos sejam desacoplados no tempo. Implementing RPC \u21a9 O stub do servidor tamb\u00e9m \u00e9 conhecido como skeleton . \u21a9 Marshalling: representar par\u00e2metros de forma pr\u00f3pria para transmiss\u00e3o \"no fio\". \u21a9 Omitirei alguns detalhes aqui, em nome da generalidade, mas voc\u00eas podem recuper\u00e1-los em seus livros de Arquitetura de Computadores. \u21a9","title":"RPC"},{"location":"comm/rpc/#invocacao-remota-de-procedimentos-rpc","text":"Em 1984, Birrel e Nelson 1 introduziram o mecanismo de Invoca\u00e7\u00e3o Remota de Procedimentos ( Remote Procedure Calls ), que permite que processos fa\u00e7am, pasmem, invoca\u00e7\u00f5es de procedimentos remotos! \u00d3bvio, a inova\u00e7\u00e3o n\u00e3o est\u00e1 na capacidade de uma m\u00e1quina conversar com outra, mas em como esta conversa acontece, do ponto de vista do programador. Por exemplo, RPC permite que se procure a substring apontada por c dentro da string apontada por a , a partir da posi\u00e7\u00e3o 3, usando x = substring(a,3,c); mas com o invocador da fun\u00e7\u00e3o em um processo e a implementa\u00e7\u00e3o da fun\u00e7\u00e3o propriamente dita, em outro, possivelmente em outra m\u00e1quina.","title":"Invoca\u00e7\u00e3o Remota de Procedimentos - RPC"},{"location":"comm/rpc/#stubs","text":"Se o que queremos \u00e9 colocar o c\u00f3digo da fun\u00e7\u00e3o substring em um outro processo e execut\u00e1-lo como se estiv\u00e9ssemos no mesmo processo que faz a invoca\u00e7\u00e3o, precisamos pensar em v\u00e1rias quest\u00f5es, sendo a principal o fato de que, embora seja simulada a invoca\u00e7\u00e3o local, \"por debaixo do cap\u00f4\" h\u00e1 o uso sockets para a comunica\u00e7\u00e3o com o processo remoto. Esta simula\u00e7\u00e3o usar\u00e1 c\u00f3digo extra, que finge implementar substring para o invocador mas delega ao c\u00f3digo remoto o trabalho real da busca. Este c\u00f3digo extra \u00e9 conhecido como stub , ou para ser mais preciso, stub cliente , que faz parte do processo invocando a opera\u00e7\u00e3o, e stub servidor , que faz parte do processo executando a opera\u00e7\u00e3o invocada 2 . Assim, o cliente invoca a fun\u00e7\u00e3o no stub cliente, achando que \u00e9 a fun\u00e7\u00e3o que quer executar. O stub cliente faz o marshaling 3 dos par\u00e2metros e usa o SO para transferir os dados via rede para o stub servidor. Quando recebe a resposta do servidor, o stub cliente retorna a mesma resposta, como se tivesse sido calculada localmente. J\u00e1 o stub servidor fica esperando o contato do cliente. Quando acontece, faz o unmarshalling dos dados, invoca a fun\u00e7\u00e3o localmente na aplica\u00e7\u00e3o servidor e pega o resultado, que retorna ao cliente. Stub cliente Stub servidor 1. invoca substring no stub 1. retorna o resultado para o stub 2. conecta-se ao servidor, envia par\u00e2metros e especifica a fun\u00e7\u00e3o 2. envia resulta serializado para cliente 3. transmite os dados serializados transmite resposta serializada 4. desserializa par\u00e2metros 4. desserializa os par\u00e2metro 5. invoca a fun\u00e7\u00e3o substring localmente 5. retorna o resultado para o invocador","title":"Stubs"},{"location":"comm/rpc/#transparencia","text":"\u00c9 para o programador a grande vantagem do uso de RPC, pois se pode escrever c\u00f3digo distribu\u00eddo \"igual\" ao n\u00e3o-distribu\u00eddo, certo? Isto \u00e9, interface baseada em procedimentos e sem a necessidade de detalhar portas, sockets, e representa\u00e7\u00e3o de dados . Ou seja, tudo \u00e9 transparente! Como j\u00e1 discutimos, v\u00e1rios fatores trabalham contra a transpar\u00eancia em sistemas distribu\u00eddos . Em espec\u00edfico quanto \u00e0 transpar\u00eancia dada pelo RPC, tamb\u00e9m temos limita\u00e7\u00f5es. Antes de nos aprofundarmos, lembremos como uma invoca\u00e7\u00e3o de fun\u00e7\u00f5es acontece normalmente dentro de um \u00fanico processo. 4 O c\u00f3digo x = substring(a,3,c); , que procura *c em *a , \u00e9 traduzido nos seguintes passos em linguagem de m\u00e1quina: coloque o valor de c na pilha coloque 3 na pilha coloque o valor de a na pilha coloque o endere\u00e7o de retorno na pilha (junto com outros dados de controle) salte para substring ajustando o instruction pointer ... procure substring ... coloque o resultado no acumulador limpe a pilha salte de volta recuperando o endere\u00e7o de retorno da pilha e ajustando o IP coloque resultado em x O problema \u00e9 que h\u00e1 uma distin\u00e7\u00e3o clara em pelo menos dois processos e se pensarmos no c\u00f3digo descrito acima, temos que entender que processos independentes n\u00e3o compartilham um espa\u00e7o de endere\u00e7amento, e processos independentes n\u00e3o compartilham uma pilha. Assim, como fica a passagem de par\u00e2metro por refer\u00eancia , uma vez que o stub servidor n\u00e3o pode usar endere\u00e7os do espa\u00e7o de endere\u00e7amento do cliente? Algumas abordagens para simular a passagem por refer\u00eancia s\u00e3o poss\u00edveis. Por exemplo, o valor apontado pelo ponteiro \u00e9 passado para o servidor , que armazena o valor e alguma posi\u00e7\u00e3o de mem\u00f3ria e passa o endere\u00e7o de tal posi\u00e7\u00e3o para a fun\u00e7\u00e3o invocada. Contudo, a modifica\u00e7\u00e3o do valor pela fun\u00e7\u00e3o n\u00e3o reflete imediatamente no invocador; tais valores tem que ser copiados novamente e usados para sobrescrever o valor original no cliente. Al\u00e9m disso, esta abordagem s\u00f3 \u00e9 poss\u00edvel se o valor apontado for delimitado, o que nem sempre \u00e9 f\u00e1cil de determinar. Por exemplo, se o ponteiro for para o primeiro elemento de uma lista, o que deve ser copiado para o servidor? S\u00f3 o primeiro elemento? Toda a lista? Como ensinar para o framework RPC o que \u00e9 \"toda\" a lista? Java \"resolve\" o problema da passagem de par\u00e2metro por refer\u00eancia passando todo o grafo do objeto passado como par\u00e2metro para o servidor. Isto \u00e9, al\u00e9m de serializar o objeto apontado no par\u00e2metro, se o mesmo aponta para outros objetos, estes tamb\u00e9m ser\u00e3o serializados e transferidos; o servidor ir\u00e1 ent\u00e3o reconstruir todo o grafo e passar para o m\u00e9todo sendo invocado. \u00c9 muito f\u00e1cil ver que esta abordagem pode se tornar invi\u00e1vel rapidamente. Quando for o caso, Java permite marcar objetos como remotos e, em vez de serializar este objeto e enviar para o servidor, envia informa\u00e7\u00e3o suficiente para que o servidor possa invocar m\u00e9todos em tal objeto no cliente, tornando nebulosa a defini\u00e7\u00e3o de quem \u00e9 quem. Outros fatores tamb\u00e9m trabalham contra a transpar\u00eancia para o desenvolvedor.","title":"Transpar\u00eancia"},{"location":"comm/rpc/#interface-definition-language","text":"H\u00e1 diversas op\u00e7\u00f5es de frameworks para RPC, com diferentes caracter\u00edsticas, focos, e garantias. Alguns s\u00e3o parte da linguagem e outros s\u00e3o implementados como bibliotecas. Alguns suportam m\u00faltiplas linguagens e alguns apenas uma. Suporte a RPC na linguagem Sem RPC: C, C++, Java < 5.0 (1.5), Python Com RPC: Java, Go, Erlang, Scala, Haskell Ambientes heterog\u00eaneos: Thrift, gRPC, Akka, SOAP Frameworks mais modernos permitem escolher a forma de serializa\u00e7\u00e3o dos dados, se leg\u00edvel para humanos ou bin\u00e1rio, se o transporte \u00e9 via HTTP ou protocolo mais baixo n\u00edvel, se os dados trafegam abertamente ou se faz uso de comunica\u00e7\u00e3o criptografada (SSL). Outros permitem escolher sem\u00e2ntica de execu\u00e7\u00e3o entre no m\u00e1ximo uma e pelo menos uma , e h\u00e1 at\u00e9 quem prometa exatamente uma . Mas todos os frameworks tem algumas caracter\u00edsticas em comum e uma delas \u00e9 o uso de uma Linguagem de Defini\u00e7\u00e3o de Interface (IDL). Uma IDL \u00e9 a linguagem pela qual desenvolvedor define quais as opera\u00e7\u00f5es (fun\u00e7\u00f5es, procedimentos, m\u00e9todos) ser\u00e3o acess\u00edveis via RPC e quais os seus operandos. H\u00e1 v\u00e1rias IDL definidas, para os diversos frameworks dispon\u00edveis. A imagem a seguir mostra um exemplo gen\u00e9rico da cria\u00e7\u00e3o cliente e servidor usando um framework RPC gen\u00e9rico, inclusive o processamento da defini\u00e7\u00e3o feita em IDL do servi\u00e7o e a jun\u00e7\u00e3o deste c\u00f3digo gerado ao c\u00f3digo escrito pelo desenvolvedor. O fluxo de processamento \u00e9 o seguinte: Arquivo em IDL \u00e9 compilado por um compilador IDL e gera diversos arquivos: stub cliente - c\u00f3digo que implementa a interface, com c\u00f3digo para repassar invoca\u00e7\u00f5es para o servidor. stub servidor ( skeleton ) - c\u00f3digo que atende a conex\u00f5es do stub cliente e repassa para a implementa\u00e7\u00e3o pr\u00f3pria da fun\u00e7\u00e3o. convers\u00e3o de dados - c\u00f3digo que serializa e deserializa dados para serem trafegados de e para o servidor cabe\u00e7alhos - defini\u00e7\u00f5es da interface na linguagem de desenvolvimento da aplica\u00e7\u00e3o; se linguagem C, por exemplo, estes ser\u00e3o arquivos .h , se em Java, ent\u00e3o estes ser\u00e3o arquivos .java , com defini\u00e7\u00e3o de interface . O c\u00f3digo cliente \u00e9 compilado e gera o cliente, que deve inicializar a infraestrutura RPC Tipo de transporte SSL? Localizar servidor Lidar com falhas O c\u00f3digo servidor \u00e9 compilado e gera o servidor, que deve exportar e localizar servi\u00e7os (servi\u00e7o de nomea\u00e7\u00e3o) Gerenciamento de portas Conex\u00f5es","title":"Interface Definition Language"},{"location":"comm/rpc/#variacoes-de-processamento","text":"Invoca\u00e7\u00f5es de procedimentos e m\u00e9todos s\u00e3o geralmente s\u00edncronas, o que quer dizer que o chamador do procedimento normalmente espera a conclus\u00e3o do procedimento para continuar a executar. Essa abordagem \u00e9 necess\u00e1ria quando o chamador precisa do resultado do procedimento para continuar, mas deixa de fazer sentido quando ou o procedimento n\u00e3o tem um resultado ... ... ou quando o resultado s\u00f3 ser\u00e1 necess\u00e1rio mais tarde, podendo ser recebido via um callback . Independentemente de qual abordagem for utilizada, ambos os processos, chamador e chamado, precisam estar ativos ao mesmo tempo para que a comunica\u00e7\u00e3o aconte\u00e7a, isto \u00e9, os processos est\u00e3o acoplados no tempo . Nas se\u00e7\u00f5es seguintes veremos como este requisito pode ser relaxado, permitindo que os processos sejam desacoplados no tempo. Implementing RPC \u21a9 O stub do servidor tamb\u00e9m \u00e9 conhecido como skeleton . \u21a9 Marshalling: representar par\u00e2metros de forma pr\u00f3pria para transmiss\u00e3o \"no fio\". \u21a9 Omitirei alguns detalhes aqui, em nome da generalidade, mas voc\u00eas podem recuper\u00e1-los em seus livros de Arquitetura de Computadores. \u21a9","title":"Varia\u00e7\u00f5es de processamento"},{"location":"comm/sockets/","text":"Para se definir um socket a partir de um host \u00e9 necess\u00e1rio identificar o outro fim da comunica\u00e7\u00e3o, isto \u00e9, o outro host , ou melhor, uma de suas interfaces de rede. Os sockets s\u00e3o ent\u00e3o a abstra\u00e7\u00e3o dos canais de comunica\u00e7\u00e3o, mas como dito antes, \u00e9 necess\u00e1rio definir tamb\u00e9m os protocolos usados por estes sockets. O primeiro protocolo \u00e9 o de endere\u00e7amento, que define qual pilha de protocolos usar, na camada 3. No caso da pilha IP, usa-se o protocolo AF_INET ou PF_INET. Escolhido o protocolo, cada interface tem um endere\u00e7o MAC, na camada 2, que a identifica entre as interfaces na mesma rede local, e cada interface tem um endere\u00e7o IPv4/IPv6 de 32/128 bits, que o indentifica entre todos os hosts na Internet. 1 Mas dentro de um host , podem haver diversas aplica\u00e7\u00f5es sendo executadas. Como identificar exatamente com qual se quer conversar? Isto \u00e9 feito pela defini\u00e7\u00e3o uma porta: Porta: inteiro de 16 bits Associadas a servi\u00e7os pela Internet Assigned Numbers Authority , IANA. Portas \"Bem conhecidas\": 0-1023 Portas Propriet\u00e1rias: 49151 Portas Din\u00e2micas: 65535 Tamb\u00e9m \u00e9 necess\u00e1rio definir o protocolo de transporte dos dados, na camada 4. Novamente, no caso da pilha IP, pode-se usar TCP ( SOCK_STREAM ) ou UDP ( SOCK_DGRAM ). A API usada para estabelecer a conversa via socket tem v\u00e1rias chamadas, que devem ser executadas na ordem certa no processo iniciando a conversa e naquele que aceita participar da mesma. Comecemos estudando o TCP. TCP O fluxograma da cria\u00e7\u00e3o de um socket TCP \u00e9 apresentado na seguinte figura: stateDiagram-v2 Servidor --> Entrada/Sa\u00edda Cliente --> Entrada/Sa\u00edda Entrada/Sa\u00edda --> Encerramento state Servidor { ss: Cria socket sb: Associa porta sl: Escuta conex\u00f5es sa: Aceita conex\u00f5es ss --> sb sb --> sl sl --> sa } state Entrada/Sa\u00edda { leitura --> escrita escrita --> leitura } state Cliente { cs: Cria socket cc: Inicia conex\u00e3o cs --> cc } state Encerramento { sc: Fecha conex\u00e3o } Estabelecido o socket, o mesmo pode ser usado como um arquivo , isto \u00e9, lendo-se e escrevendo-se bytes. O que exatamente deve ser escrito e como o que \u00e9 lido deve ser interpretado \u00e9 o protocolo da camada 7, sua responsabilidade . Vejamos um exemplo do uso de sockets, em Python, descrito no arquivo server.py . 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #server.py #!/usr/bin/python # This is server.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . bind (( host , port )) # Bind to the port s . listen ( 5 ) # Now wait for client connections. while True : c , addr = s . accept () # Establish connection with client. print ( 'Got connection from' , addr ) c . send ( 'Thank you for connecting' . encode ()) c . close () # Close the connection Para execut\u00e1-lo, execute o seguinte comando em um terminal. 1 python server.py Em outro terminal, execute um dos dois comandos a seguir. 3 1 telnet localhost 12345 1 netcat localhost 12345 No segundo terminal a mensagem Thank you for connecting ser\u00e1 impressa, enquanto no primeiro veremos algo como ('Got connection from', ('127.0.0.1', 57801)) O que est\u00e1 acontecendo aqui \u00e9 um processo criou um socket e ficou aguardando uma conex\u00e3o, usando o c\u00f3digo em Python. Tanto o telnet quando o netcat s\u00e3o programas gen\u00e9ricos para se conversar com outro processo usando TCP/IP. Aqui, estes programas simplesmente se conectaram e imprimiram o que quer que o primeiro processo lhes tenha enviado, assumindo que correspondia a uma string, o que neste caso \u00e9 correto. Simples, n\u00e3o \u00e9 mesmo? Duas observa\u00e7\u00f5es importantes a serem feitas aqui. A primeira \u00e9 que, em geral, denominamos o processo que fica aguardando a conex\u00e3o de servidor e o processo que se conecta de cliente . Isto por qu\u00ea, em geral, o servidor executa alguma tarefa, serve, o cliente, embora isto n\u00e3o seja necessariamente verdade. Por completude, vamos tamb\u00e9m escrever o c\u00f3digo do cliente, agora que voc\u00ea j\u00e1 sabe que o servidor funciona. Do lado cliente, estabelece-se uma conex\u00e3o apontando-se para onde est\u00e1 o servidor. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #client.py #!/usr/bin/python # This is client.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . connect (( host , port )) data = s . recv ( 1024 ) print ( data . decode ()) s . close () # Close the socket when done E para se executar o cliente, fa\u00e7a: 1 python client.py Observe que o socket.close() encerra a conex\u00e3o do lado de quem invoca. Na contraparte, invoca\u00e7\u00f5es a socket.recv() retornam com 0 bytes lidos. A t\u00edtulo de compara\u00e7\u00e3o, em Java, a cria\u00e7\u00e3o do socket do lado do servidor seria muito mais simples, consistindo apenas em: 1 Socket s = new ServerSocket ( port ); O cliente em Java tamb\u00e9m \u00e9 simplificado. 1 Socket s = new Socket ( hostname , port ); Exerc\u00edcio: M\u00faltiplos Pacotes Fa\u00e7amos agora uma modifica\u00e7\u00e3o no c\u00f3digo do servidor para que envie n\u00e3o uma, mas duas mensagens para o cliente. Isto \u00e9, modifique seu servidor assim 1 2 3 4 ... c . send ( 'Thank you for connecting' . encode ()) c . send ( 'Come back often' . encode ()) ... Agora execute novamente o cliente e veja o que acontece. Consegue explicar o fen\u00f4meno? Modifiquemos o cliente agora, para que tenha dois recv , assim. 1 2 3 4 5 6 7 8 ... print ( \"1\" ) data = s . recv ( 1024 ) print ( data . decode ()) print ( \"2\" ) data = s . recv ( 1024 ) print ( data . decode ()) ... E agora, o que acontece? A sa\u00edda \u00e9 como esperava? Como explica este fen\u00f4meno e como poderia corrig\u00ed-lo? Exerc\u00edcio: Ping-Pong Modifique cliente e servidor tal que o cliente envie uma mensagem passada na linha de comando ao servidor e fique esperando uma resposta, e tal que o servidor fique esperando uma mensagem e ent\u00e3o solicite ao operador que digite uma resposta e a envie para o cliente. O loop continua at\u00e9 que o usu\u00e1rio digite SAIR, e a conex\u00e3o seja encerrada. Terminal 1 Terminal 2 python server.py python client.py Esperando conex\u00e3o. conectando-se ao servidor Conectado Conectado Esperando mensagem Digite mensagem: lalala Mensagem enviada Mensagem recebida: lalala Esperando resposta Digite resposta: lelele Resposta enviada. Resposta recebida: lelele Digite mensagem: SAIR Desconectando. Conex\u00e3o encerrada. Esperando conex\u00e3o. Observe que para ler do teclado em Python 2 voc\u00ea deve usar x = raw_input () , enquanto que em Python 3 seria x = input () . Al\u00e9m disso, em Python 2, voc\u00ea deve remover as invoca\u00e7\u00f5es para encode e decode . UDP No exemplo anterior, usamos o protocolo TCP (o padr\u00e3o da API). Caso quis\u00e9ssemos usar UDP, precisar\u00edamos nos atentar a alguns detalhes. A cria\u00e7\u00e3o do socket \u00e9 feita explicitando-se o uso de datagramas : s = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) Um servidor UDP n\u00e3o executa listen ou accept e, em Python, simplesmente executa data , addr = sock . recvfrom ( 4096 ) para receber o datagrama, onde data \u00e9 o conte\u00fado recebido e addr o endere\u00e7o de quem enviou o datagrama. Neste caso, um mesmo socket \u00e9 usado para manter comunica\u00e7\u00e3o com m\u00faltiplos interlocutores. Para enviar uma resposta a um interlocutor em espec\u00edfico, addr \u00e9 usado: sent = sock . sendto ( data , addr ) , onde sent \u00e9 a quantidade de bytes enviados. Al\u00e9m deste detalhe, \u00e9 importante manter em mente outras caracter\u00edsticas do UDP: falta de ordem falta de confiabilidade menos dados lidos que enviados. mais dados lidos que enviados (pode acontecer tamb\u00e9m no TCP) Com tantas dificuldades para se usar o UDP, fica a quest\u00e3o: para que serve UDP? Exerc\u00edcio: Ping-Pong UDP Modifique o c\u00f3digo do exerc\u00edcio Ping-Pong para usar UDP em vez de TCP na comunica\u00e7\u00e3o entre n\u00f3s. Execute m\u00faltiplos clientes ao mesmo tempo. Como o seu servidor lida com isso? Modifique-o para mandar um \"eco\" da mensagem recebida de volta ao remetente. IP-Multicast Imagine que voc\u00ea tenha que enviar um stream de v\u00eddeo para um amigo mostrando como voc\u00ea est\u00e1 jogando o mais novo jogo da velha no mercado. Qual protocolo de transporte voc\u00ea usaria? TCP, provavelmente, j\u00e1 que garante a entrega ordenada dos pacotes do v\u00eddeo. Como voc\u00ea j\u00e1 sabe, o TCP envia confirma\u00e7\u00f5es de pacotes recebidos e usa uma janela deslizante para determinar quais pacotes reenviar, o que pode causar interrup\u00e7\u00f5es na execu\u00e7\u00e3o do v\u00eddeo. Al\u00e9m do mais, as pessoas provavelmente preferir\u00e3o perder alguns quadros que perder a sincronia com sua excitante partida. Parece que uma op\u00e7\u00e3o melhor seria ent\u00e3o usar UDP, correto? Imagine agora que os mesmos dados devam ser enviados para m\u00faltiplos destinat\u00e1rios (voc\u00ea est\u00e1 ficando famoso!) Com m\u00faltiplos destinat\u00e1rios, m\u00faltiplos controles precisariam ser mantidos no TCP, o que pode se tornar custoso; mais uma raz\u00e3o para usar UDP! Para terminar, lhe darei uma raz\u00e3o final: IP-Multicast! Multicast, em oposi\u00e7\u00e3o ao Unicast, \u00e9 a capacidade de enviar mensagens para um grupo de destinat\u00e1rios, em vez de apenas um. IP-Multicast \u00e9 uma implementa\u00e7\u00e3o desta ideia, usando umaa configura\u00e7\u00e3o espec\u00edfica do UDP, associada a recursos dos comutadores de rede, para otimizar o envio dos mesmos dados a m\u00faltiplos destinat\u00e1rios. Grupos s\u00e3o identificados por endere\u00e7os IP especiais, conhecidos como Classe D (224.0.0.0-239.255.255.255), e propagados pela rede. A seguinte tabela descreve os usos das sub-faixas de endere\u00e7os. 4 Endere\u00e7o Uso 224.0.0.0-224.0.0.255 Multicast local - Usado por protocolos L2, como EIGRP e OSPF 224.0.1.0-224.0.1.255 Multicast roteaddo - Usado por protocolos L3 232.0.0.0-232.255.255.255 Source Specific Multicast - Receptores definem fontes confi\u00e1veis 233.0.0.0-233.255.255.255 Reservado para detentores Autonomous Systems 239.0.0.0-239.255.255.255 Reservado para IANA Resto Uso geral Quando um pacote \u00e9 enviado para o endere\u00e7o do grupo, todos os membros do grupo recebem tal mensagem. Melhor dizendo, todos os membros podem receber a mensagem, mas como estamos falando de UDP, \u00e9 poss\u00edvel que alguns n\u00e3o recebam . Al\u00e9m disso, n\u00e3o h\u00e1 garantia qualquer sobre a ordem de recep\u00e7\u00e3o das mensagens . Apenas refor\u00e7ando, IP-Multicast s\u00f3 funciona com UDP, pois lidar com retransmiss\u00f5es em um grupo grande levaria a um estado imenso sendo mantido na origem dos dados. Outro ponto importante \u00e9 que pelo podencial desestabilizador do IP-Multicast, ele \u00e9 normalemente limitado \u00e0 pequenas se\u00e7\u00f5es das redes. Mas experimentemos com esta tecnologia na pr\u00e1tica. Criemos um programa que criar Socket UDP , associa-o a um grupo , e recebe pacotes destinados ao grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // MReceiver.java import java.io.* ; import java.net.* ; public class MReceiver { public static void main ( String [] args ) { byte [] inBuf = new byte [ 256 ] ; try { MulticastSocket socket = new MulticastSocket ( 8888 ); InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); socket . joinGroup ( address ); while ( true ) { DatagramPacket inPacket = new DatagramPacket ( inBuf , inBuf . length ); socket . receive ( inPacket ); String msg = new String ( inBuf , 0 , inPacket . getLength ()); System . out . println ( \"From \" + inPacket . getAddress () + \" Msg : \" + msg ); } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Instancie m\u00faltiplos processos deste, na mesma m\u00e1quina e em m\u00e1quinas distintas. Agora criemos um programa que envia pacotes para o dito grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // MSender.java import java.io.* ; import java.net.* ; public class MSender { public static void main ( String [] args ) { byte [] outBuf ; final int PORT = 8888 ; try { DatagramSocket socket = new DatagramSocket (); long counter = 0 ; InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); while ( true ) { counter ++ ; outBuf = ( \"Multicast numero \" + counter + \" \" + address ). getBytes (); DatagramPacket outPacket = new DatagramPacket ( outBuf , outBuf . length , address , PORT ); socket . send ( outPacket ); try { Thread . sleep ( 500 ); } catch ( InterruptedException ie ) {} } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Observe como a mesma mensagem \u00e9 recebida pelos v\u00e1rios membros e que como diferentes fontes tem seus pacotes recebidos. A t\u00edtulo de curiosidade, IP-Multicast tamb\u00e9m est\u00e1 presente em IPv6, mas com algumas pequenas diferen\u00e7as IP-Multicast em IPv6 5 In IPv6, the left-most bits of an address are used to determine its type. For a multicast address, the first 8 bits are all ones, i.e. FF00::/8. Further, bit 113-116 represent the scope of the address, which can be either one of the following 4: Global, Site-local, Link-local, Node-local. In addition to unicast and multicast, IPv6 also supports anycast, in which a packet can be sent to any member of the group, but need not be sent to all members.'' Exerc\u00edcio: IP-Multicast Implemente e teste o seguinte receiver , colocando v\u00e1rias inst\u00e2ncias para executar em m\u00faltiplos terminais, ao mesmo tempo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import socket import struct MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) sock . bind (( '' , MCAST_PORT )) mreq = struct . pack ( \"=4sl\" , socket . inet_aton ( MCAST_GRP ), socket . INADDR_ANY ) #4 bytes (4s) seguidos de um long (l), usando ordem nativa (=) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_ADD_MEMBERSHIP , mreq ) while True : print ( sock . recv ( 10240 ) . decode ()) Implemente e teste o seguinte sender . 1 2 3 4 5 6 7 8 import socket MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_MULTICAST_TTL , 2 ) sock . sendto ( input () . encode (), ( MCAST_GRP , MCAST_PORT )) Endere\u00e7os IP n\u00e3o p\u00fablicos n\u00e3o servem como identificadores \u00fanicos na Internet. \u21a9 Voc\u00ea pode usar outro nome, desde que n\u00e3o seja socket.py , e que adapte o comando para sua execu\u00e7\u00e3o. \u21a9 O programa telnet \u00e9 normalmente instalado por padr\u00e3o tanto no Windows, OSX quanto no Linux. J\u00e1 o netcat normalmente precisa ser instalado por voc\u00ea. Em alguns sistemas, em vez de netcat o comando \u00e9 o nc . \u21a9 Understanding IP Multicast \u21a9 IP-Multicast em IPv6 \u21a9","title":"Sockets"},{"location":"comm/sockets/#tcp","text":"O fluxograma da cria\u00e7\u00e3o de um socket TCP \u00e9 apresentado na seguinte figura: stateDiagram-v2 Servidor --> Entrada/Sa\u00edda Cliente --> Entrada/Sa\u00edda Entrada/Sa\u00edda --> Encerramento state Servidor { ss: Cria socket sb: Associa porta sl: Escuta conex\u00f5es sa: Aceita conex\u00f5es ss --> sb sb --> sl sl --> sa } state Entrada/Sa\u00edda { leitura --> escrita escrita --> leitura } state Cliente { cs: Cria socket cc: Inicia conex\u00e3o cs --> cc } state Encerramento { sc: Fecha conex\u00e3o } Estabelecido o socket, o mesmo pode ser usado como um arquivo , isto \u00e9, lendo-se e escrevendo-se bytes. O que exatamente deve ser escrito e como o que \u00e9 lido deve ser interpretado \u00e9 o protocolo da camada 7, sua responsabilidade . Vejamos um exemplo do uso de sockets, em Python, descrito no arquivo server.py . 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #server.py #!/usr/bin/python # This is server.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . bind (( host , port )) # Bind to the port s . listen ( 5 ) # Now wait for client connections. while True : c , addr = s . accept () # Establish connection with client. print ( 'Got connection from' , addr ) c . send ( 'Thank you for connecting' . encode ()) c . close () # Close the connection Para execut\u00e1-lo, execute o seguinte comando em um terminal. 1 python server.py Em outro terminal, execute um dos dois comandos a seguir. 3 1 telnet localhost 12345 1 netcat localhost 12345 No segundo terminal a mensagem Thank you for connecting ser\u00e1 impressa, enquanto no primeiro veremos algo como ('Got connection from', ('127.0.0.1', 57801)) O que est\u00e1 acontecendo aqui \u00e9 um processo criou um socket e ficou aguardando uma conex\u00e3o, usando o c\u00f3digo em Python. Tanto o telnet quando o netcat s\u00e3o programas gen\u00e9ricos para se conversar com outro processo usando TCP/IP. Aqui, estes programas simplesmente se conectaram e imprimiram o que quer que o primeiro processo lhes tenha enviado, assumindo que correspondia a uma string, o que neste caso \u00e9 correto. Simples, n\u00e3o \u00e9 mesmo? Duas observa\u00e7\u00f5es importantes a serem feitas aqui. A primeira \u00e9 que, em geral, denominamos o processo que fica aguardando a conex\u00e3o de servidor e o processo que se conecta de cliente . Isto por qu\u00ea, em geral, o servidor executa alguma tarefa, serve, o cliente, embora isto n\u00e3o seja necessariamente verdade. Por completude, vamos tamb\u00e9m escrever o c\u00f3digo do cliente, agora que voc\u00ea j\u00e1 sabe que o servidor funciona. Do lado cliente, estabelece-se uma conex\u00e3o apontando-se para onde est\u00e1 o servidor. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #client.py #!/usr/bin/python # This is client.py file import socket # Import socket module s = socket . socket () # Create a socket object host = socket . gethostname () # Get local machine name port = 12345 # Reserve a port for your service. s . connect (( host , port )) data = s . recv ( 1024 ) print ( data . decode ()) s . close () # Close the socket when done E para se executar o cliente, fa\u00e7a: 1 python client.py Observe que o socket.close() encerra a conex\u00e3o do lado de quem invoca. Na contraparte, invoca\u00e7\u00f5es a socket.recv() retornam com 0 bytes lidos. A t\u00edtulo de compara\u00e7\u00e3o, em Java, a cria\u00e7\u00e3o do socket do lado do servidor seria muito mais simples, consistindo apenas em: 1 Socket s = new ServerSocket ( port ); O cliente em Java tamb\u00e9m \u00e9 simplificado. 1 Socket s = new Socket ( hostname , port ); Exerc\u00edcio: M\u00faltiplos Pacotes Fa\u00e7amos agora uma modifica\u00e7\u00e3o no c\u00f3digo do servidor para que envie n\u00e3o uma, mas duas mensagens para o cliente. Isto \u00e9, modifique seu servidor assim 1 2 3 4 ... c . send ( 'Thank you for connecting' . encode ()) c . send ( 'Come back often' . encode ()) ... Agora execute novamente o cliente e veja o que acontece. Consegue explicar o fen\u00f4meno? Modifiquemos o cliente agora, para que tenha dois recv , assim. 1 2 3 4 5 6 7 8 ... print ( \"1\" ) data = s . recv ( 1024 ) print ( data . decode ()) print ( \"2\" ) data = s . recv ( 1024 ) print ( data . decode ()) ... E agora, o que acontece? A sa\u00edda \u00e9 como esperava? Como explica este fen\u00f4meno e como poderia corrig\u00ed-lo? Exerc\u00edcio: Ping-Pong Modifique cliente e servidor tal que o cliente envie uma mensagem passada na linha de comando ao servidor e fique esperando uma resposta, e tal que o servidor fique esperando uma mensagem e ent\u00e3o solicite ao operador que digite uma resposta e a envie para o cliente. O loop continua at\u00e9 que o usu\u00e1rio digite SAIR, e a conex\u00e3o seja encerrada. Terminal 1 Terminal 2 python server.py python client.py Esperando conex\u00e3o. conectando-se ao servidor Conectado Conectado Esperando mensagem Digite mensagem: lalala Mensagem enviada Mensagem recebida: lalala Esperando resposta Digite resposta: lelele Resposta enviada. Resposta recebida: lelele Digite mensagem: SAIR Desconectando. Conex\u00e3o encerrada. Esperando conex\u00e3o. Observe que para ler do teclado em Python 2 voc\u00ea deve usar x = raw_input () , enquanto que em Python 3 seria x = input () . Al\u00e9m disso, em Python 2, voc\u00ea deve remover as invoca\u00e7\u00f5es para encode e decode .","title":"TCP"},{"location":"comm/sockets/#udp","text":"No exemplo anterior, usamos o protocolo TCP (o padr\u00e3o da API). Caso quis\u00e9ssemos usar UDP, precisar\u00edamos nos atentar a alguns detalhes. A cria\u00e7\u00e3o do socket \u00e9 feita explicitando-se o uso de datagramas : s = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) Um servidor UDP n\u00e3o executa listen ou accept e, em Python, simplesmente executa data , addr = sock . recvfrom ( 4096 ) para receber o datagrama, onde data \u00e9 o conte\u00fado recebido e addr o endere\u00e7o de quem enviou o datagrama. Neste caso, um mesmo socket \u00e9 usado para manter comunica\u00e7\u00e3o com m\u00faltiplos interlocutores. Para enviar uma resposta a um interlocutor em espec\u00edfico, addr \u00e9 usado: sent = sock . sendto ( data , addr ) , onde sent \u00e9 a quantidade de bytes enviados. Al\u00e9m deste detalhe, \u00e9 importante manter em mente outras caracter\u00edsticas do UDP: falta de ordem falta de confiabilidade menos dados lidos que enviados. mais dados lidos que enviados (pode acontecer tamb\u00e9m no TCP) Com tantas dificuldades para se usar o UDP, fica a quest\u00e3o: para que serve UDP? Exerc\u00edcio: Ping-Pong UDP Modifique o c\u00f3digo do exerc\u00edcio Ping-Pong para usar UDP em vez de TCP na comunica\u00e7\u00e3o entre n\u00f3s. Execute m\u00faltiplos clientes ao mesmo tempo. Como o seu servidor lida com isso? Modifique-o para mandar um \"eco\" da mensagem recebida de volta ao remetente.","title":"UDP"},{"location":"comm/sockets/#ip-multicast","text":"Imagine que voc\u00ea tenha que enviar um stream de v\u00eddeo para um amigo mostrando como voc\u00ea est\u00e1 jogando o mais novo jogo da velha no mercado. Qual protocolo de transporte voc\u00ea usaria? TCP, provavelmente, j\u00e1 que garante a entrega ordenada dos pacotes do v\u00eddeo. Como voc\u00ea j\u00e1 sabe, o TCP envia confirma\u00e7\u00f5es de pacotes recebidos e usa uma janela deslizante para determinar quais pacotes reenviar, o que pode causar interrup\u00e7\u00f5es na execu\u00e7\u00e3o do v\u00eddeo. Al\u00e9m do mais, as pessoas provavelmente preferir\u00e3o perder alguns quadros que perder a sincronia com sua excitante partida. Parece que uma op\u00e7\u00e3o melhor seria ent\u00e3o usar UDP, correto? Imagine agora que os mesmos dados devam ser enviados para m\u00faltiplos destinat\u00e1rios (voc\u00ea est\u00e1 ficando famoso!) Com m\u00faltiplos destinat\u00e1rios, m\u00faltiplos controles precisariam ser mantidos no TCP, o que pode se tornar custoso; mais uma raz\u00e3o para usar UDP! Para terminar, lhe darei uma raz\u00e3o final: IP-Multicast! Multicast, em oposi\u00e7\u00e3o ao Unicast, \u00e9 a capacidade de enviar mensagens para um grupo de destinat\u00e1rios, em vez de apenas um. IP-Multicast \u00e9 uma implementa\u00e7\u00e3o desta ideia, usando umaa configura\u00e7\u00e3o espec\u00edfica do UDP, associada a recursos dos comutadores de rede, para otimizar o envio dos mesmos dados a m\u00faltiplos destinat\u00e1rios. Grupos s\u00e3o identificados por endere\u00e7os IP especiais, conhecidos como Classe D (224.0.0.0-239.255.255.255), e propagados pela rede. A seguinte tabela descreve os usos das sub-faixas de endere\u00e7os. 4 Endere\u00e7o Uso 224.0.0.0-224.0.0.255 Multicast local - Usado por protocolos L2, como EIGRP e OSPF 224.0.1.0-224.0.1.255 Multicast roteaddo - Usado por protocolos L3 232.0.0.0-232.255.255.255 Source Specific Multicast - Receptores definem fontes confi\u00e1veis 233.0.0.0-233.255.255.255 Reservado para detentores Autonomous Systems 239.0.0.0-239.255.255.255 Reservado para IANA Resto Uso geral Quando um pacote \u00e9 enviado para o endere\u00e7o do grupo, todos os membros do grupo recebem tal mensagem. Melhor dizendo, todos os membros podem receber a mensagem, mas como estamos falando de UDP, \u00e9 poss\u00edvel que alguns n\u00e3o recebam . Al\u00e9m disso, n\u00e3o h\u00e1 garantia qualquer sobre a ordem de recep\u00e7\u00e3o das mensagens . Apenas refor\u00e7ando, IP-Multicast s\u00f3 funciona com UDP, pois lidar com retransmiss\u00f5es em um grupo grande levaria a um estado imenso sendo mantido na origem dos dados. Outro ponto importante \u00e9 que pelo podencial desestabilizador do IP-Multicast, ele \u00e9 normalemente limitado \u00e0 pequenas se\u00e7\u00f5es das redes. Mas experimentemos com esta tecnologia na pr\u00e1tica. Criemos um programa que criar Socket UDP , associa-o a um grupo , e recebe pacotes destinados ao grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // MReceiver.java import java.io.* ; import java.net.* ; public class MReceiver { public static void main ( String [] args ) { byte [] inBuf = new byte [ 256 ] ; try { MulticastSocket socket = new MulticastSocket ( 8888 ); InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); socket . joinGroup ( address ); while ( true ) { DatagramPacket inPacket = new DatagramPacket ( inBuf , inBuf . length ); socket . receive ( inPacket ); String msg = new String ( inBuf , 0 , inPacket . getLength ()); System . out . println ( \"From \" + inPacket . getAddress () + \" Msg : \" + msg ); } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Instancie m\u00faltiplos processos deste, na mesma m\u00e1quina e em m\u00e1quinas distintas. Agora criemos um programa que envia pacotes para o dito grupo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // MSender.java import java.io.* ; import java.net.* ; public class MSender { public static void main ( String [] args ) { byte [] outBuf ; final int PORT = 8888 ; try { DatagramSocket socket = new DatagramSocket (); long counter = 0 ; InetAddress address = InetAddress . getByName ( \"224.2.2.3\" ); while ( true ) { counter ++ ; outBuf = ( \"Multicast numero \" + counter + \" \" + address ). getBytes (); DatagramPacket outPacket = new DatagramPacket ( outBuf , outBuf . length , address , PORT ); socket . send ( outPacket ); try { Thread . sleep ( 500 ); } catch ( InterruptedException ie ) {} } } catch ( IOException ioe ) { System . out . println ( ioe ); } } } Observe como a mesma mensagem \u00e9 recebida pelos v\u00e1rios membros e que como diferentes fontes tem seus pacotes recebidos. A t\u00edtulo de curiosidade, IP-Multicast tamb\u00e9m est\u00e1 presente em IPv6, mas com algumas pequenas diferen\u00e7as IP-Multicast em IPv6 5 In IPv6, the left-most bits of an address are used to determine its type. For a multicast address, the first 8 bits are all ones, i.e. FF00::/8. Further, bit 113-116 represent the scope of the address, which can be either one of the following 4: Global, Site-local, Link-local, Node-local. In addition to unicast and multicast, IPv6 also supports anycast, in which a packet can be sent to any member of the group, but need not be sent to all members.'' Exerc\u00edcio: IP-Multicast Implemente e teste o seguinte receiver , colocando v\u00e1rias inst\u00e2ncias para executar em m\u00faltiplos terminais, ao mesmo tempo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import socket import struct MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) sock . bind (( '' , MCAST_PORT )) mreq = struct . pack ( \"=4sl\" , socket . inet_aton ( MCAST_GRP ), socket . INADDR_ANY ) #4 bytes (4s) seguidos de um long (l), usando ordem nativa (=) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_ADD_MEMBERSHIP , mreq ) while True : print ( sock . recv ( 10240 ) . decode ()) Implemente e teste o seguinte sender . 1 2 3 4 5 6 7 8 import socket MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM , socket . IPPROTO_UDP ) sock . setsockopt ( socket . IPPROTO_IP , socket . IP_MULTICAST_TTL , 2 ) sock . sendto ( input () . encode (), ( MCAST_GRP , MCAST_PORT )) Endere\u00e7os IP n\u00e3o p\u00fablicos n\u00e3o servem como identificadores \u00fanicos na Internet. \u21a9 Voc\u00ea pode usar outro nome, desde que n\u00e3o seja socket.py , e que adapte o comando para sua execu\u00e7\u00e3o. \u21a9 O programa telnet \u00e9 normalmente instalado por padr\u00e3o tanto no Windows, OSX quanto no Linux. J\u00e1 o netcat normalmente precisa ser instalado por voc\u00ea. Em alguns sistemas, em vez de netcat o comando \u00e9 o nc . \u21a9 Understanding IP Multicast \u21a9 IP-Multicast em IPv6 \u21a9","title":"IP-Multicast"},{"location":"coord/concurrency/","text":"Concorr\u00eancia Quando pensamos um sistema distribu\u00eddo, \u00e9 natural que o fa\u00e7amos em termos do paralelismo inato que surge do uso de m\u00faltiplos processos executando ao mesmo tempo em (normalmente) diferentes hosts . Contudo, \u00e9 importante pensar tamb\u00e9m em termos de paralelismo dentro de cada um dos processos que comp\u00f5em o sistema pois, no m\u00ednimo, componentes podem necessitar manter v\u00e1rias \"conversas\" em paralelo uns com os outros. Por isso, \u00e9 \"imposs\u00edvel\" pensar em sistemas distribu\u00eddos sem pensar em concorr\u00eancia na forma de m\u00faltiplos threads nos processos. Relembremos o exemplo de sistema implementado usando sockets, em que um processo cliente se conecta ao servidor para receber uma sauda\u00e7\u00e3o. A intera\u00e7\u00e3o entre tais processos acontece de forma sincronizada, lock-step , em que o cliente requisita o servi\u00e7o e ficava bloqueado esperando a resposta do servidor para ent\u00e3o prosseguir em seu processamento ( printf ), e o servidor fica bloqueado esperando requisi\u00e7\u00f5es que atende e ent\u00e3o volta a dormir. Este cen\u00e1rio, apresentado na figura a seguir, mostra que apesar do uso de processos distintos e da concorr\u00eancia na execu\u00e7\u00e3o dos processos, temos um baixo grau de efetivo paralelismo; a requisi\u00e7\u00e3o (2) s\u00f3 \u00e9 processada depois que a resposta (1) \u00e9 enviada. sequenceDiagram activate Cliente note left of Cliente: Ativo gerando requisi\u00e7\u00e3o note right of Servidor: Inativo esperando requisi\u00e7\u00e3o activate Cliente2 note right of Cliente2: Ativo gerando requisi\u00e7\u00e3o Cliente->>+Servidor: Request (1) deactivate Cliente note left of Cliente: Inativo esperando resposta Cliente2-->>Servidor: Request (2) deactivate Cliente2 note right of Cliente2: Inativo esperando resposta note right of Servidor: Ativo processando requisi\u00e7\u00e3o (1) Servidor->>-Cliente: Response (1) activate Cliente activate Servidor note left of Cliente: Ativo processando resposta (1) note right of Servidor: Ativo processando requisi\u00e7\u00e3o (2) Servidor-->>Cliente2: Response (2) deactivate Servidor activate Cliente2 note right of Servidor: Inativo esperando requisi\u00e7\u00e3o note right of Cliente2: Ativo processando resposta (2) deactivate Cliente deactivate Cliente2 Este modelo de sincroniza\u00e7\u00e3o entre as partes comunicantes \u00e9 um exemplo de E/S bloqueante . O principal ponto positivo desta estrat\u00e9gia \u00e9 a simplicidade do c\u00f3digo e o principal ponto negativo \u00e9 a limita\u00e7\u00e3o do paralelismo no uso de recursos, uma das raz\u00f5es de ser da computa\u00e7\u00e3o distribu\u00edda. Para usarmos melhor os recursos dispon\u00edveis, tanto do lado dos clientes quanto servidores, temos ent\u00e3o que pensar em termos de eventos sendo disparados entre os componentes, que devem ser tratados assim que recebidos ou t\u00e3o logo haja recursos para faz\u00ea-lo. Estes eventos correspondem tanto a requisi\u00e7\u00f5es quanto a respostas (efetivamente tornando dif\u00edcil a distin\u00e7\u00e3o). No modelo bloqueante, quando um evento \u00e9 disparado (no exemplo, a requisi\u00e7\u00e3o), o sistema fica bloqueado at\u00e9 que um evento espec\u00edfico seja observado (no exemplo, a chegada da resposta). Sempre que poss\u00edvel, um componente n\u00e3o deve ficar esperando por eventos em espec\u00edfico, aproveitando a chance executar outras tarefas; quando eventos s\u00e3o recebidos, s\u00e3o ent\u00e3o atendidos. Esta \u00e9 a forma de fazer E/S ass\u00edncrona . Dado que processos interagem com a rede usando sockets, cuja interface mais simples para opera\u00e7\u00f5es de leitura \u00e9 bloqueante, neste curso n\u00e3o falaremos especificamente sobre E/S ass\u00edncrono 1 e por isso, para vermos como aumentar a concorr\u00eancia no sistema, \u00e9 necess\u00e1rio falar de multithreading e as v\u00e1rias formas em que aparecem nos sistemas. H\u00e1 duas raz\u00f5es claras para estudarmos multithreading . A primeira, de ordem pr\u00e1tica, \u00e9 a discutida acima: permitir o desenvolvimento de componentes que utilizem \"melhormente\" os recursos em um host. A segunda, did\u00e1tica, \u00e9 o fato que muitos dos problemas que aparecem em programa\u00e7\u00e3o multithread , aparecem em programa\u00e7\u00e3o multi-processo (como nos sistemas distribu\u00eddos), apenas em um grau de complexidade maior. Para relembrar, h\u00e1 v\u00e1rias diferen\u00e7as entre threads e processos, mas a abstra\u00e7\u00e3o \u00e9 essencialmente a mesma: Processo Thread Quasi defini\u00e7\u00e3o Inst\u00e2ncia de um programa \"Processo leve\" Fun\u00e7\u00e3o de entrada main fun\u00e7\u00e3o \"qualquer\" Compartilhamento de c\u00f3digo e dados Privado ao processo Compartilhado pelos threads Estado C\u00f3digo, Stack, Heap, descritores (e.g, file descriptors), controle de acesso Stack, vari\u00e1veis locais Comunica\u00e7\u00e3o IPC ( Inter Process Communication ): sockets, FIFO, mem\u00f3ria compartilhada, etc IPC, mutex, vari\u00e1veis de condi\u00e7\u00e3o, sem\u00e1foros, etc N\u00edvel da implementa\u00e7\u00e3o Sistema operacional Diferentes implementa\u00e7\u00f5es API Posix, C++, Java, ... Efeito de E/S Mudan\u00e7a de contexto para outro thread mesmo sem terminar quantum Mudan\u00e7a de contexto para outro thread do mesmo processo Tempo de cria\u00e7\u00e3o, termina\u00e7\u00e3o e mudan\u00e7a de contexto Demora mais Demora menos Vejamos como o uso de m\u00faltiplos threads podem melhorar o desenvolvimento de sistemas distribu\u00eddos na pr\u00e1tica. Considere os exemplos de clientes e servidores vistos anteriormente . Imagine que em vez do servi\u00e7o simples feito no exemplo, o servidor retorne uma p\u00e1gina Web. Detalhes do protocolo seguido por navegadores e servidores ser\u00e3o vistos mais tarde. Por agora, considere apenas que uma requisi\u00e7\u00e3o GET arquivo.html ser\u00e1 enviada para o servidor que ler\u00e1 o arquivo especificado do sistema de arquivos; como voc\u00ea sabe, ler um arquivo \u00e9 uma opera\u00e7\u00e3o lenta e que n\u00e3o requer CPU. Threads no Cliente Do ponto de vista do cliente, a vantagem do uso de m\u00faltiplos threads s\u00e3o claras: permite lidar com v\u00e1rias tarefas concorrentemente , por exemplo solicitar CSS, HTML e imagens concorrentemente, escondendo lat\u00eancia das v\u00e1rias opera\u00e7\u00f5es, e permite organizar c\u00f3digo em blocos/m\u00f3dulos. Se voc\u00ea usar o console de desenvolvimento do navegador, ver\u00e1 como m\u00faltiplos arquivos s\u00e3o baixados em paralelo quando acessa um s\u00edtio. A figura a seguir mostra a carga do s\u00edtio da Facom . O primeiro arquivo, index.html \u00e9 baixado individualmente, mas uma vez que isso acontece e s\u00e3o determinados quais os demais arquivos necess\u00e1rios, requisi\u00e7\u00f5es concorrentes s\u00e3o disparadas, minimizando o tempo total da opera\u00e7\u00e3o. Como outros exemplos, considere um formul\u00e1rio online em que a valida\u00e7\u00e3o de um campo \u00e9 executada enquanto o campo seguinte est\u00e1 sendo preenchido, ou um servi\u00e7o de email em que arquivos s\u00e3o carregados enquanto a mensagem \u00e9 confeccionada. Threads Servidor Do lado dos servidores h\u00e1 diversas possibilidades de uso de threads para aumentar o paralelismo no processamento de requisi\u00e7\u00f5es, melhor utilizando recursos dispon\u00edveis e melhorando a experi\u00eancia do usu\u00e1rio. Single-threaded A estrat\u00e9gia mais simples de se implementar \u00e9 a de usar apenas um thread, como temos feito at\u00e9 agora. Considere um servidor Web com esta esta caracter\u00edstica; o fluxo no tratamento de uma requisi\u00e7\u00e3o \u00e9 exemplificado na pela figura a seguir: O servidor \u00e9 iniciado, criando o socket e invocando accept o cliente envia a requisi\u00e7\u00e3o para o servidor o servidor aceita a conex\u00e3o em seu \u00fanico thread uma tarefa \u00e9 gerada para ler o arquivo o arquivo \u00e9 lido, de forma bloqueante, e uma resposta para o cliente \u00e9 preparada a resposta \u00e9 enviada para o cliente, de forma bloqueante a requisi\u00e7\u00e3o \u00e9 descartada o thread do servidor volta a esperar uma nova requisi\u00e7\u00e3o Se novas requisi\u00e7\u00f5es forem recebidas enquanto o servidor est\u00e1 executando os passos de 2 a 6, sejam requisi\u00e7\u00f5es paralelas do mesmo cliente ou de um outro cliente, estas ficar\u00e3o bloqueadas. A espera ser\u00e1 maior quanto mais o servidor demorar para atender \u00e0 primeira requisi\u00e7\u00e3o, por exemplo, se precisar consultar um banco de dados ou carregar o arquivo requisitado do disco. Para evitar que isto ocorra, o servidor pode usar mais threads. Thread per request O servidor pode criar um novo thread para cada nova requisi\u00e7\u00e3o, permitindo que m\u00faltiplas requisi\u00e7\u00f5es sejam tratadas concorrentemente. Isto \u00e9, mesmo que um thread do servidor seja bloqueado por muito tempo, somente um cliente ter\u00e1 sua resposta atrasada (excluindo-se necessidades de coordena\u00e7\u00e3o entre m\u00faltiplos threads) e outros clientes podem continuar sendo atendidos normalmente, como mostrado na figura a seguir. Lembre-se, entretanto, que o n\u00famero de threads que se pode criar em um SO \u00e9 limitado, pois cada thread usa recursos do SO. Al\u00e9m disso, a cria\u00e7\u00e3o e destrui\u00e7\u00e3o de threads \u00e9 cara pois \u00e9 feita por meio de uma chamada de sistema, pelo kernel, e portanto implica em alternar entre modo usu\u00e1rio e modo protegido. Se poss\u00edvel, devemos evitar a cria\u00e7\u00e3o de novos threads em aplica\u00e7\u00f5es com requisitos de desempenho, e reclicl\u00e1-los pode ser uma boa estrat\u00e9gia. Thread pool Para reciclarmos threads, podemos criar pools , um balde de threads que s\u00e3o usados quando necess\u00e1rio e devolvidos para o balde quando n\u00e3o mais. No cerne desta abordagem, junto com o pool de threads, fica uma fila bloquenante na qual tarefas s\u00e3o inseridas e de onde os threads tentam retir\u00e1-las. Como a fila \u00e9 bloqueante, se estiver vazia, o thread \u00e9 bloqueado e para de consumir recursos. T\u00e3o logo nova tarefa seja inserida, a fila acorda os threads para que a processem. Para garantir a corretude no processamento, a fila deve ser thread-safe , isto \u00e9, que se mantem correta mesmo quando m\u00faltiplos threads operam nela tanto para inserir quanto remover tarefas. Na figura, um thread principal \u00e9 encarregado de receber as requisi\u00e7\u00f5es e colocar na fila bloqueante; se a fila fica cheia, o thread principal fica bloqueado esperando por espa\u00e7o, fazendo com que novas conex\u00f5es tenham que esperar. Os threads do pool removem uma tarefa da fila, a tratam e, ao final do atendimento, pegam nova requisi\u00e7\u00e3o na fila, em um loop infinito; requisi\u00e7\u00f5es que demandam menor processamento liberam o thread mais rapidamente para que pegue nova tarefa. Se todas as tarefas s\u00e3o pequenas, os threds ficar\u00e3o bloqueados por muito tempo. Se todas s\u00e3o grandes, as tarefas se acumular\u00e3o na fila. Por isso \u00e9 importante dimensionar bem o tamanho to pool , ou mesmo torn\u00e1-lo din\u00e2mico para que use menos recursos (threads) quando n\u00e3o necess\u00e1rio e n\u00e3o deixe tarefas pendentes por muito tempo. Se considerarmos que cada tarefa na verdade tem v\u00e1rias partes, \u00e9 poss\u00edvel refinar mais este modelo, quebrando o processamento em v\u00e1rios pools. Est\u00e1gios Na arquitetura baseada em est\u00e1gios, e.g., Staged Event-Driven Architecture , SEDA, cada est\u00e1gio , cada est\u00e1gio \u00e9 respons\u00e1vel por processar uma parte da tarefa, passada adiante at\u00e9 que seja completada. 2 Uma caracter\u00edstica importante deste modelo \u00e9 que cada est\u00e1gio pode ser escalado individualmente de acordo com a demanda uma vez que cada est\u00e1gio tem seu pr\u00f3prio pool . Por exemplo, se um est\u00e1gio faz algum c\u00e1lculo leve, ent\u00e3o poucos threads s\u00e3o necess\u00e1rios ao mesmo. J\u00e1 um est\u00e1gio que precise efetuar E/S talvez precise mais threads , uma vez que estes ficam bloqueandos enquanto a opera\u00e7\u00e3o \u00e9 executada. 3 Desafios Embora a ideia de usar m\u00faltiplos threads seja melhorar desempenho e experi\u00eancia do usu\u00e1rio, faz\u00ea-lo efetivamente \u00e9 n\u00e3o trivial. Vejamos por exemplo o problema do falso compartilhamento; considere o seguinte pseudo-c\u00f3digo: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ... int32 X ; int32 Y ; thread1 = tread_new ( threadfunction , & X ); thread2 = tread_new ( threadfunction , & Y ); void threadfunction ( int32 * exclusivo ) { int32 local = * exclusivo ; while ( true ) { local = processa ( local ); * exclusivo = local ; } } ... Cada um dos threads criados acessa exclusivamente uma das vari\u00e1veis. Logo, n\u00e3o h\u00e1 interfer\u00eancia entre as threads e se cada uma for colocada em um processador diferente, executar\u00e3o no m\u00e1ximo de seu potencial, correto? N\u00e3o exatamente, pois mesmo este c\u00f3digo simpl\u00edssimo pode sofrer de falso compartilhamento . Isto acontece, por exemplo, se cada linha da cache do sistema onde este programa executa tiver 8 ou mais bytes de comprimento. Como tanto X quanto Y no programa tem 4 bytes, as duas vari\u00e1veis poder\u00e3o ficar na mesma linha da cache e toda vez que uma thread modificar uma vari\u00e1vel a cache da outra ser\u00e1 invalidada para leitura. Para que isto n\u00e3o ocorra, \u00e9 preciso se certificar que as vari\u00e1veis fiquem em linhas diferentes da cache; no exemplo, poderia-se definir X e Y como vetores do tamanho da linha da cache e usar efetivamente apenas a primeira posi\u00e7\u00e3o de cada vetor. Se o compartilhamento for real, por exemplo se ambos os threads usarem a vari\u00e1vel X, ent\u00e3o o problema n\u00e3o ser\u00e1 t\u00e3o facilmente resolv\u00edvel. Neste caso, poder-se-ia definir afinidade entre threads, isto \u00e9, notar quais threads compartilham estado de forma que threads afins sejam colocados nos mesmos processadores e compartilhem as mesmas mem\u00f3rias. Isto torna muito mais f\u00e1cil e eficiente o controle de concorr\u00eancia, do ponto de vista do SO e hardware. Multiprograma\u00e7\u00e3o Fazer esta divis\u00e3o pode ser complicado pois a rela\u00e7\u00e3o de compartilhamento entre threads pode ser complexa em fun\u00e7\u00e3o da tarefa sendo resolvida, por exemplo, se diferentes threads compartilharem diferentes vari\u00e1veis uns com os outros. Ainda que que uma configura\u00e7\u00e3o \u00f3tima em termos de afinidade exista, encontr\u00e1-la pode ser custo. Ainda assim, precisamos lidar com estado compartilhado e enfrentar condi\u00e7\u00f5es de corrida de forma a n\u00e3o levar a inconsist\u00eancias na executa\u00e7\u00e3o de tarefas, nos referindo a inconsist\u00eancia aqui como qualquer desvio no comportamento do programa daquilo que foi especificado pelo desenvolvedor. Para isso, usamos as primitivas de controle de concorr\u00eancia que estudaram em SO, que tamb\u00e9m tem seus problemas em potencial, como deadlocks e inani\u00e7\u00e3o . Veja o seguinte v\u00eddeo para uma an\u00e1lise de diversos pontos importantes no uso de multithreads. Estado A quest\u00e3o das regi\u00f5es cr\u00edticas est\u00e1 intimamente relacionada \u00e0 quest\u00e3o da manuten\u00e7\u00e3o de estado nos servidores. Quanto a este respeito, podemos classificar servidores como stateful e stateless , dois termos que ouvir\u00e3o frequentemente enquanto trabalhando com SD. To state or not to state? Complexidade e desempenho Falhas Balanceamento O state nos dois nomes se refere ao estado mantido por um servi\u00e7o para atender a requisi\u00e7\u00f5es. Caso mantenha estado, por exemplo informando em quais arquivos o cliente est\u00e1 interessado, fica mais f\u00e1cil para o servidor continuar o trabalho feito em requisi\u00e7\u00f5es anteriores. Stateless Imagine por exemplo que um cliente esteja acessando linhas em um banco de dados, de forma paginada: a cada requisi\u00e7\u00e3o, o cliente recebe \\(n\\) novas linhas para processar e, quando estiver pronto, requisite \\(n\\) novas linhas. Imagine qu\u00e3o infeficiente seria se o servidor seguisse o seguinte fluxo: receba requisi\u00e7\u00e3o informando a \u00faltima linha lida recalcule todas as respostas para consulta salte at\u00e9 a linha informada pelo cliente retorne as pr\u00f3ximas \\(n\\) linhas para o cliente feche o resultado da consulta. Stateful Se em vez disso o servidor mantiver um mapa com consultas recentes, em que a chave seja algum identificador do cliente e o valor uma vis\u00e3o dos resultados; a cada nova requisi\u00e7\u00e3o, basta o servidor resgatar a vis\u00e3o usando o identificador do cliente e selecionar as seguintes \\(n\\) entradas da vis\u00e3o. Manter o mapa como estado acelera o processamento e melhora a experi\u00eancia do usu\u00e1rio, neste caso. Por outro lado, considere que m\u00faltiplos clientes fazem consultas concorrentemente: quanto recurso seria necess\u00e1rio para que o servidor mantenha a vis\u00e3o de todos os clientes? Tamb\u00e9m a complexidade do servidor aumenta. Considere as algumas de muitas perguntas poss\u00edveis neste cen\u00e1rio: Como o servidor mant\u00e9m as respostas a novas requisi\u00e7\u00f5es consistentes com as respostas anteriores? E se linhas s\u00e3o removidas ou inseridas no banco de dados? Se m\u00faltiplos servidores existem, como compartilhar os estado entre os mesmos? Se o cliente resolva n\u00e3o fazer mais requisi\u00e7\u00f5es, por exemplo por ter encontrado o que procurava, por quanto tempo o servidor deve manter a vis\u00e3o aberta? Como voc\u00ea j\u00e1 deve ter percebido, ambas as abordagens, stateless e stateful , tem suas vantagens e desvantagens. Sess\u00e3o Essencialmente, o servidor stateless n\u00e3o mantem informa\u00e7\u00e3o sobre a sess\u00e3o do cliente e requer que a cada nova requisi\u00e7\u00e3o, quaisquer informa\u00e7\u00f5es necess\u00e1rias para realizar a tarefa requisitada sejam novamente fornecidas ao servidor. No caso stateful , o servidor pode se lembrar, como no exemplo anterior, at\u00e9 onde o trabalho j\u00e1 foi executado, quais arquivos o cliente manipulou (e mant\u00ea-los abertos), qual o endere\u00e7o o cliente e enviar-lhe notifica\u00e7\u00f5es importantes (e.g., \"Novo dado inserido!\"). Falhas Enquanto servidores stateful obviamente levam a melhor desempenho no happy path (contanto que recursos suficientes sejam providos), no caso de falhas, servi\u00e7os stateless tendem a voltar ao ar mais rapidamente, uma vez que n\u00e3o h\u00e1 estado que precise ser recuperado. Pela mesma raz\u00e3o, clientes que percebem que um servidor falhou podem rapidamente se dirigir a outros servidores e continuar suas requisi\u00e7\u00f5es de onde estavam, uma vez que s\u00e3o detentores de toda a informa\u00e7\u00e3o necess\u00e1ria para o pr\u00f3ximo passo do processamento. Lidar com falhas tamb\u00e9m introduz outro requisito aos servidores: mem\u00f3ria est\u00e1vel. Para que possa o recuperar o estado anterior \u00e0 falha, o servidor precisa colocar o estado em algum lugar que independa do processo para se manter, por exemplo, nvRAM , SSD ou spindles . A perda deste estado implicaria na incapacidade de prover o servi\u00e7o corretamente. Um projeto stateless n\u00e3o depende deste estado e por isso pode ser mais rapidamente recuperado, replicado ou substitu\u00eddo. Stateless x Stateful N\u00e3o surpreendentemente, a resposta para \"qual abordagem \u00e9 melhor, stateful ou stateless ?\" \u00e9 depende . Ambos as op\u00e7\u00f5es tem suas vantagens e desvantagens e para alguns servi\u00e7os apenas uma op\u00e7\u00e3o ser\u00e1 vi\u00e1vel. Se seu servi\u00e7o precisa manter estado (um SGBD, por exemplo), ele ter\u00e1 que manter estado, mesmo que n\u00e3o sobre clientes. Veja um pequeno comparativo das caracter\u00edsticas das duas abordagens. Stateless Stateful Resultado depende da entrada Depende do hist\u00f3rico de entradas Qualquer servidor pode atender Mesmo servidor deve atender N\u00e3o promete notificar o cliente Assina contrato com o cliente Repete opera\u00e7\u00f5es Aproveita resultados anteriores N\u00e3o fica inconsistente com rela\u00e7\u00e3o ao cliente Pode ficar inconsistente se perder estado ou conex\u00e3o feita com outro servidor re-autentica\u00e7\u00e3o (mesmo que simplficada) a cada requisi\u00e7\u00e3o Autentica no come\u00e7o da sess\u00e3o Multithread na pr\u00e1tica POSIX POSIX Threads ou PThreads, s\u00e3o uma defini\u00e7\u00e3o aberta de como threads devem funcionar em sistemas operacionais. V\u00e1rias implementa\u00e7\u00f5es desta especifica\u00e7\u00e3o est\u00e3o dispon\u00edveis tanto para sistemas Unix, que se esfor\u00e7am para ser compat\u00edveis com especifi\u00e7\u00f5es POSIX, mas tamb\u00e9m para Windows, via subsistemas que compatibilizam diferentes API. Al\u00e9m disso, mesmo implementa\u00e7\u00f5es n\u00e3o POSIX tem funcionalidade equivalentes e, por este motivo, entender POSIX servir\u00e1 de base para entender quaisquer API para programa\u00e7\u00e3o multi-threaded . Para se definir um thread , \u00e9 necess\u00e1rio definir uma fun\u00e7\u00e3o de entrada, que ser\u00e1 para o thread como a fun\u00e7\u00e3o main \u00e9 para o processo em si. No exemplo a seguir a fun\u00e7\u00e3o foi definida com retorno void * e com \u00fanico par\u00e2metro, tamb\u00e9m void * ; esta \u00e9 uma obrigatoriedade para fun\u00e7\u00f5es de entrata PThread. Observe contudo que void * pode ser tratado como um blob para mascarar outros tipos de dados, por exemplo um vetor, um ponteiro para uma enumera\u00e7\u00e3o ou uma struct . Tamb\u00e9m observe que a fun\u00e7\u00e3o tem uma vari\u00e1vel local my_id que s\u00f3 est\u00e1 definida no contexto da thread (linha 8); se m\u00faltiplas threads forem instanciadas, cada uma ter\u00e1 a sua vers\u00e3o da vari\u00e1vel. H\u00e1 tamb\u00e9m uma vari\u00e1vel global thread_count , compartilhada por todas as inst\u00e2ncias (linha 5). 1 2 3 4 5 6 7 8 9 10 11 #include <stdio.h> #include <stdlib.h> #include <pthread.h> int thread_count ; void * hello ( void * id ) { long my_id = ( long ) id ; printf ( \"Hello from thread %ld of %d \\n \" , my_id , thread_count ); return NULL ; } Um thread \u00e9 criado pela fun\u00e7\u00e3o pthread_create (linha 14), que coloca em um pthread_t um handle para o thread . O handle do thread deve ser alocado previamente \u00e0 fun\u00e7\u00e3o de cria\u00e7\u00e3o do thread (linha 11). A fun\u00e7\u00e3o recebe como par\u00e2metros op\u00e7\u00f5es para configura\u00e7\u00e3o, a fun\u00e7\u00e3o de entrada, e o par\u00e2metro do tipo void * . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int main ( int argc , char * argv []) { long thread ; pthread_t * thread_handles ; if ( argc < 2 ) { printf ( \"usage: %s <number of threads>\" , argv [ 0 ]); return 1 ; } thread_count = strtol ( argv [ 1 ], NULL , 10 ); thread_handles = malloc ( thread_count * sizeof ( pthread_t )); for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_create ( & thread_handles [ thread ], NULL , hello , ( void * ) thread ); printf ( \"Hello from the main thread \\n \" ); \u00c9 poss\u00edvel esperar pelo fim da execu\u00e7\u00e3o do thread usando o pthread_join , que recebe como par\u00e2metro o handle do thread e um ponteiro para onde o resultado da fun\u00e7\u00e3o de entrada deve ser colocado, do tipo void ** (linha 2). No exemplo, nenhum retorno \u00e9 esperado, ent\u00e3o um endere\u00e7o nulo \u00e9 passado como par\u00e2metro. Ao final da execu\u00e7\u00e3o, o handle deve ser liberado (linha 4). 1 2 3 4 for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_join ( thread_handles [ thread ], NULL ); free ( thread_handles ); Para executar um programa PThread, compile com 1 gcc -pthread teste.c -o teste e execute com 1 ./teste 5 e observe que a sa\u00edda das threads \u00e9 ordenada . Agora experimente 1 ./teste 200 Observe que a sa\u00edda \u00e9 desordenada (pode ser necess\u00e1rio executar m\u00faltiplas vezes ou aumentar de 200 para, digamos, 1000 para observar a desordem. Isto acontece porqu\u00ea a execu\u00e7\u00e3o das threads independe da ordem de cria\u00e7\u00e3o. De fato, usando PThreads, temos pouco controle sobre os threads que criamos. Mas isto n\u00e3o quer dizer que estamos \"\u00f3rf\u00e3os\" de API; v\u00e1rias outras opera\u00e7\u00f5es podem ser executadas, e podem ser encontradas a partir do manual de pthread_create . Alguns exemplos interessantes: pthread_tryjoin - espera thread terminar pthread_exit - termina a thread e retorna resultado An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function's return value serves as the thread's exit status. Manual de pthread_exit . pthread_attr_setaffinity_np - ajusta afinidade dos threads. Python Em Python, como seria de se esperar, h\u00e1 v\u00e1rias formas de se trabalhar com threads . O exemplo a seguir usa o pacote thread e \u00e9 essencialmente um env\u00f3lucro POSIX. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/usr/bin/python import thread import time # Define a function for the thread def print_time ( threadName , delay ): count = 0 while count < 5 : time . sleep ( delay ) count += 1 print \" %s : %s \" % ( threadName , time . ctime ( time . time ()) ) # Create two threads as follows try : thread . start_new_thread ( print_time , ( \"Thread-1\" , 2 , ) ) thread . start_new_thread ( print_time , ( \"Thread-2\" , 4 , ) ) except : print \"Error: unable to start thread\" while True : pass J\u00e1 o pr\u00f3ximo exemplo usa o pacote threading e uma abordagem orientada a objetos. Observe que h\u00e1 momentos distintos no ciclo de vida do thread em que acontece a cria\u00e7\u00e3o e o in\u00edcio da execu\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/usr/bin/python import threading import time exitFlag = 0 class myThread ( threading . Thread ): def __init__ ( self , threadID , name , counter ): threading . Thread . __init__ ( self ) self . threadID = threadID self . name = name self . counter = counter def run ( self ): print \"Starting \" + self . name print_time ( self . name , self . counter , 5 ) print \"Exiting \" + self . name def print_time ( threadName , counter , delay ): while counter : if exitFlag : threadName . exit () time . sleep ( delay ) print \" %s : %s \" % ( threadName , time . ctime ( time . time ())) counter -= 1 # Create new threads thread1 = myThread ( 1 , \"Thread-1\" , 1 ) thread2 = myThread ( 2 , \"Thread-2\" , 2 ) # Start new Threads thread1 . start () thread2 . start () print \"Exiting Main Thread\" Uma consequ\u00eancia desta divis\u00e3o \u00e9 que um mesmo objeto do tipo Thread pode ser reciclado e executado v\u00e1rias vezes. Java Outro exemplo importante de API para multithreading \u00e9 a do Java, pois nesta linguagem h\u00e1, essencialmente, duas formas de se conseguir concorr\u00eancia. A primeira \u00e9 via inst\u00e2ncias expl\u00edcitas da classe Thread e, a segunda, via abstra\u00e7\u00f5es de mais alto n\u00edvel, os Executors . Aqui nos focaremos em aspectos b\u00e1sicos de concorr\u00eancia na linguagem, mas esteja ciente de que a mesma \u00e9 muito rica neste t\u00f3pico, por exemplo provendo diversas estruturas para comunica\u00e7\u00e3o e coordena\u00e7\u00e3o de threads no pacote java.util.concurrent . Uma \u00f3tima documenta\u00e7\u00e3o sobre o uso de threads e estruturas \u00e9 dispobinilizada pela Oracle . H\u00e1 duas formas b\u00e1sicas de definir um novo thread em Java, ou via extens\u00e3o da classe Thread ou via implementa\u00e7\u00e3o da interface Runnable ; observe o qu\u00e3o pouco muda no c\u00f3digo dos exemplos a seguir. Note tamb\u00e9m que, nos dois exemplos, um m\u00e9todo run() \u00e9 implementado com o c\u00f3digo a ser executado pelo thread mas que em nenhum momento tal m\u00e9todo \u00e9 invocado diretamente. Em vez disto, o m\u00e9todo start() \u00e9 que \u00e9 invocado, porqu\u00ea antes de executar as instru\u00e7\u00f5es definidas pelo pelo programador no m\u00e9todo run() , a m\u00e1quina virtual precisa executar alguma \"m\u00e1gica\" por baixo dos panos como, por exemplo, solicitar ao sistema operacional a cria\u00e7\u00e3o de um thread do SO, que servir\u00e1 de hospedeiro para o thread Java. Isto acontece dentro do start() , que em algum ponto de sua execu\u00e7\u00e3o levar\u00e1 \u00e0 invoca\u00e7\u00e3o do m\u00e9todo run() . Thread 1 2 3 4 5 6 7 8 9 10 public class Hello extends Thread { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new Hello (); t . start (); } } Runnable 1 2 3 4 5 6 7 8 9 10 public class Hello implements Runnable { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); t . start (); } } Al\u00e9m de servider base para outras classes, a classe Thread tamb\u00e9m prov\u00ea uma s\u00e9rie de m\u00e9todos que permitem gerenciar a vida dos threads criados. Por exemplo, o m\u00e9todo de classe Thread.sleep() permite bloquear o thread no qual a invoca\u00e7\u00e3o aconteceu por um determinado per\u00edodo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Hello implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ){ System . out . println ( \"Hello at instant \" + i ); try { Thread . sleep ( 1000 ); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); t . start (); } } Observe que a chamada a sleep() deve estar dentro de um bloco try/catch , pois \u00e9 permitido \u00e0 JVM acordar o thread em qualquer instante, antes ou ap\u00f3s o tempo especificado. Assim, embora normalmente o tempo \"dormido\" seja pr\u00f3ximo ao especificado, se h\u00e1 requisitos de precis\u00e3o, \u00e9 sugerido que a thread durma em pequenas fra\u00e7\u00f5es at\u00e9 chegar ao valor total e que, ao acordar, verifique se j\u00e1 n\u00e3o dormiu o suficiente. No exemplo seguinte, o thread dorme por pelo menos 1000 milissegundos a cada itera\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Hello implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ){ System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 1000 ; while ( before + timeout > System . currentTimeMillis ()){ try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); t . start (); } } Quando um thread est\u00e1 sendo executado, outros podem ter que esperar at\u00e9 que complete. Por exemplo, no caso de um navegador Web, o thread que faz a renderiza\u00e7\u00e3o da p\u00e1gina n\u00e3o pode come\u00e7ar a trabalhar enquanto o thread que solicitou o HTML do servidor n\u00e3o receber sua resposta. Um thread indica a inten\u00e7\u00e3o de esperar por outro usando o m\u00e9todo join() . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class Hello implements Runnable { public void run () { Random rand = new Random (); for ( int i = 0 ; i < 10 ; i ++ ){ System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 901 + rand . nextInt ( 200 ); while ( before + timeout > System . currentTimeMillis ()){ try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); //t.setDaemon(true); t . start (); try { t . join (); //t.join(10000); } catch ( InterruptedException ie ) { System . out . println ( \"Waiting was interrupted\" ); } if ( t . isAlive ()) System . out . println ( \"Got tired of waiting\" ); else System . out . println ( \"Wait is over\" ); } } Invocar t.join() far\u00e1 com que o thread corrente, neste caso o principal, espere indefinidamente at\u00e9 que t termine de executar. Caso seja necess\u00e1rio limitar o tempo de espera, um limite pode ser especificado como na linha comentada. Caso a espera termine por causa de um timeout , \u00e9 poss\u00edvel testar o estado atual do thread com Thread.isAlive() . Outro m\u00e9todo interessante, Thread.setDaemon() , especifica que o thread pode ser terminado quando a thread principal terminar. Descomente a invoca\u00e7\u00e3o e teste o efeito. Exerc\u00edcio: contador Fa\u00e7amos um exerc\u00edcio simples do uso de threads . Considere a classe e siga as instru\u00e7\u00f5es abaixo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Counter { private int c = 0 ; public int increment () { return ++ c ; } public int decrement () { return -- c ; } public int value () { return c ; } } Instancie um programa que gere 10 threads . Todos os threads devem compartilhar uma mesma inst\u00e2ncia de Counter Cada thread deve executar um loop em que incrementa o valor do contador 20 vezes a cada vez, imprime o resultado precedido do identificador do thread (use Thread.getName() ou Thread.currentThread().getName() ) A thread principal deve esperar todas as outras terminarem antes de terminar (use Thread.join() ). Analise a sa\u00edda do programa observando a ordem de execu\u00e7\u00e3o dos threads . An\u00e1lise \u00c9 f\u00e1cil observar que a sa\u00edda do programa \u00e9 aleat\u00f3ria nos identificadores e tende a ser incremental nos contadores, mas nem sempre isso \u00e9 verdade. Isso acontece porqu\u00ea a execu\u00e7\u00e3o dos threads \u00e9 n\u00e3o determin\u00edstica; uma vez que estejam prontos para executar, cabe ao escalonador do sistema operacional a decis\u00e3o sobre qual processo e em qual processador dever\u00e1 executar. Al\u00e9m de extens\u00e3o de Thread e implementa\u00e7\u00e3o de Runnable , Java disponibiliza tamb\u00e9m ExecutorService como abstra\u00e7\u00e3o de mais alto n\u00edvel para execu\u00e7\u00e3o de tarefas concorrentes. Os ExecutorService , de forma gen\u00e9rica, prov\u00ea o acesso a pools de thread e a API para submeter tarefas para este pool. Para iniciar tal processo, voc\u00ea pode criar um executor service usando uma das muitas f\u00e1bricas providas pela classe Executors ou pela instancia\u00e7\u00e3o de thread pools diretamente. O mais simples \u00e9 o de tamanho fixo em que h\u00e1 um n\u00famero inicial de threads criados e que, no caso de algum ser terminado, por exemplo por causa de uma exce\u00e7\u00e3o n\u00e3o tratada, cria substitutos para manter o n\u00famero constante. 1 2 ExecutorService es1 = Executors . newFixedThreadPool ( 10 ); ExecutorService es2 = new ThreadPoolExecutor ( 1 , 1 , 0 L , TimeUnit . MILLISECONDS , new LinkedBlockingQueue <> ()); Uma vez criado o executor, voc\u00ea atribui tarefas para serem executadas, que devem implementar Runnable ou Callable . No caso de Runnable , voc\u00ea pode usar o m\u00e9todo execute para execut\u00e1-las em algum momento, sem a possibilidade de retorno de resultados. Implements 1 2 3 4 5 6 7 8 9 10 11 class MyRunnable implements Runnable { public void run (){ System . out . println ( \"R0\" ); } } Runnable r = new MyRunnable (); es1 . execute ( r ); es1 . execute ( r ); es2 . execute ( r ); An\u00f4nimo 1 2 3 4 5 6 7 8 9 Runnable r = new Runnable () { public void run (){ System . out . println ( \"R1\" ); } } es1 . execute ( r ); es1 . execute ( r ); es2 . execute ( r ); Lambda 1 2 3 4 5 6 7 Runnable r = () -> { System . out . println ( \"R2\" ); } es1 . execute ( r ); es1 . execute ( r ); es2 . execute ( r ); J\u00e1 usando Callable , \u00e9 poss\u00edvel retornar resultados na forma de Future<T> . No exemplo a seguir, a c retorna um Integer , e portanto submit retorna Future<Integer> ; para acessar o resultado, use Future<>.get() : 1 2 3 4 5 6 7 8 9 10 Callable < Integer > c = () -> { System . out . println ( \"C1\" ); return 3 ; } Future < Integer > f = es1 . submit ( c ); /* Outras tarefas... */ int resultado = f . get (); Outros m\u00e9todos interessantes dos ExecutorService s\u00e3o invokeAny() e invokeAll() , que permitem passar uma lista de tarefas e retornam o resultado de qualquer tarefa ou implica na execu\u00e7\u00e3o de todas, respectivamente. Alguns executores s\u00e3o interessantes por raz\u00f5es diferentes. Primeiro, o ForkJoinPool \u00e9 um executor interessante por funcionar da seguinte forma: 1 2 3 4 5 if (my portion of the work is small enough) do the work directly else split my work into two pieces invoke the two pieces and wait for the results Segundo, os ScheduledExecutorService permitem a execu\u00e7\u00e3o agendada ou peri\u00f3dica de tarefas, por exemplo: 1 2 3 4 5 6 ScheduledExecutorService es3 = Executors . newSingleThreadScheduledExecutor (); Future < Integer > f = executorService . schedule ( c , 1 , TimeUnit . SECONDS ); //Executa a cada 5 segundos, depois de esperar por 1 segundo para come\u00e7ar. executorService . scheduleAtFixedDelay ( r1 , 1000 , 5000 , TimeUnit . MILLISECONDS ); //Como a anterior, mas pode atrasar a pr\u00f3xima invoca\u00e7\u00e3o para permiter \u00e0 anterior que termine. executorService . scheduleAtFixedRate ( r1 , 1000 , 5000 , TimeUnit . MILLISECONDS ); Coordena\u00e7\u00e3o Como visto no exerc\u00edcio anterior, a execu\u00e7\u00e3o de threads \u00e9 n\u00e3o determin\u00edstica. Contudo, estas execu\u00e7\u00f5es frequentemente precisam ser coordenadas para que n\u00e3o pisem uns nos calcanhares dos outros, por exemplo, decidindo quem deve ser o pr\u00f3ximo a entrar em uma regi\u00e3o cr\u00edtica ou ser\u00e1 o respons\u00e1vel por uma determinada tarefa. H\u00e1 v\u00e1rias astra\u00e7\u00f5es que podem ser usadas para coordenar as opera\u00e7\u00f5es de threads , como deve se lembrar no estudo de Sistemas Operacionais. Alguns exemplos s\u00e3o locks , vari\u00e1veis de condi\u00e7\u00e3o e sem\u00e1foros. Especificamente em Java, provavelmente a abstra\u00e7\u00e3o mais simples s\u00e3o os blocos synchronized . synchronized Ao definir m\u00e9todos como synchronized , garante-se que os mesmos nunca ser\u00e3o executados concorrentemente. Observe a classe a seguir, que modifica o contador do exerc\u00edcio anterior. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class SynchronizedCounter { private int c = 0 ; public synchronized int increment () { return ++ c ; } public synchronized int decrement () { return -- c ; } public synchronized int value () { return c ; } } Caso dois threads invoquem os m\u00e9todos increment e decrement ao mesmo tempo, por exemplo, a JVM far\u00e1 com que um dos threads pare sua execu\u00e7\u00e3o at\u00e9 que o outro tenha completado a invoca\u00e7\u00e3o. Isto n\u00e3o quer dizer que executar o exerc\u00edcio anterior com esta vers\u00e3o do contador levar\u00e1 a sa\u00eddas com incrementos completamente sequenciais, pois um thread poderia parar de ser executado logo ap\u00f3s incrementar o contador, depois de terminado o m\u00e9todo increment , e s\u00f3 voltar a executar depois que outro tenha incrementado e impresso na tela o valor obtido. O que quer dizer \u00e9 que, mesmo que sa\u00eddas estranhas existam, cada m\u00e9todo foi executada integralmente antes da opera\u00e7\u00e3o seguinte. Exerc\u00edcio: synchronized Modifique o c\u00f3digo do exerc\u00edcio anterior para usar a vers\u00e3o synchronized do contador. Depois de execut\u00e1-lo, adicione um println(\"Dentro: \" + c) dentro do m\u00e9todo de incremento para verificar que estas sa\u00eddas acontecem ordenadamente. synchronized funciona porqu\u00ea limita a concorr\u00eancia, mas \u00e9 problem\u00e1tico exatamente pela mesma raz\u00e3o. Por isso, \u00e9 essencial que o synchronized seja o mais limitado poss\u00edvel em termos de escopo, o que nos leva ao uso de synchronized em blocos de c\u00f3digo menores que m\u00e9todos. Por exemplo: 1 2 3 4 5 6 7 8 9 10 11 12 public class Namer { String lastName = null ; int nameCount = 0 ; public void addName ( String name ) { lastName = name ; synchronized ( this ) { nameCount ++ ; } nameList . add ( name ); } } Neste caso, blocos sincronizados no mesmo objeto , n\u00e3o s\u00e3o executados concorrentemente, mas outros blocos sim. Exerc\u00edcio: bloco synchronized Neste exerc\u00edcio, use dois objetos para travar o acesso a dois contadores. Instancie um programa com dois threads tal que: executem um loop 1000 vezes em que o primeiro thread primeiro invoca inc1 e depois inc2 o segundo thread primeiro invoca inc2 e depois inc1 ambos os threads imprimem o valor de c1 e c2 An\u00e1lise 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class MsLunch { private long c1 = 0 ; private long c2 = 0 ; private Object lock1 = new Object (); private Object lock2 = new Object (); public void inc1 () { synchronized ( lock1 ) { c1 ++ ; } } public void inc2 () { synchronized ( lock2 ) { c2 ++ ; } } } Sinaliza\u00e7\u00e3o Usados corretamente, o bloco synchronized \u00e9 executado de forma at\u00f4mica, isto \u00e9, indivis\u00edvel. Algumas opera\u00e7\u00f5es muito simples s\u00e3o naturalmente at\u00f4micas, e n\u00e3o precisam ser \"protegidas\" pelo synchronized . Por exemplo, leituras e escritas de tipos b\u00e1sicos como int , char e byte , mas n\u00e3o long ou double , pois usam mais de uma palavra em algumas arquiteturas, ou vari\u00e1veis declaradas volatile . Usando estas vari\u00e1veis, \u00e9 poss\u00edvel coordenar threads , como no exemplo a seguir. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 boolean condicao = false ; ... public void espereCondicao () { while ( ! condicao ) {} System . out . println ( \"condicao alcancada.\" ); } ... public void satisfacaCondicao () { condicao = true ; } Embora correta, esta abordagem, conhecida como espera ocupada , n\u00e3o \u00e9 eficiente pois desperdi\u00e7a computa\u00e7\u00e3o. Felizmente, em Java, todos os objetos implementam os m\u00e9todos wait e notify/notifyAll , que podem ser usados para sincronizar eficientemente threads . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Sync { Object synch = new Object (); boolean condicao = false ; public void espereCondicao () { while ( ! condicao ) { try { synchronized ( synch ){ synch . wait (); } } catch ( InterruptedException e ) {} } System . out . println ( \"Condicao alcancada\" ); } ... public void satisfacaCondicao () { condicao = true ; synchronized ( synch ){ synch . notifyAll (); } } } Neste exemplo a execu\u00e7\u00e3o da fun\u00e7\u00e3o espereCondicao \u00e9 \"pausada\" por synch . wait () at\u00e9 que uma notifica\u00e7\u00e3o seja enviada via sync . notifiyAll () , na fun\u00e7\u00e3o satisfacaCondicao () . Observe que estas opera\u00e7\u00f5es s\u00f3 podem ocorrer dentro de blocos sincronizados na vari\u00e1vel usada na sinaliza\u00e7\u00e3o. Locks Outras abstra\u00e7\u00f5es para coordena\u00e7\u00e3o de threads est\u00e3o dispon\u00edveis no pacote java.util.concurrent . As mais simples delas s\u00e3o java.util.concurrent.locks.Lock e java.util.concurrent.locks.ReentrantLock . Veja um exemplo de uso, notando o idioma de uso dentro de block try/catch/finally , que garante que o lock ser\u00e1 liberado a despeito de exce\u00e7\u00f5es no bloco. 1 2 3 4 5 6 7 Lock l = new ReentrantLock (); l . lock (); try { // access the resource protected by this lock } finally { l . unlock (); } Como bem sabido, o uso dos \"locks\" em ordens diferentes pode levar a um deadlock pois um ciclo de depend\u00eancias pode ser formado entre locks, detentores de locks e interessados em locks. O grafo de depend\u00eancia seguinte exemplifica o cen\u00e1rio, em que o thread T1 obteve o lock2 e tenta obter o lock1, e o thread T2 obteve o lock1 e tenta obter o lock2. graph LR T1 --> lock1 --> T2 --> lock2 --> T1 Estruturas thread-safe Finalmente, Java tamb\u00e9m disponibiliza estruturas de dados que podem ser acessadas concorrentemente por m\u00faltiplos threads sem risco de corrup\u00e7\u00e3o, denominadas thread-safe . BlockingQueue - bloqueia threads se n\u00e3o houver elementos na fila. ConcurrentMap/ConcurrentHashMap - opera\u00e7\u00f5es at\u00f4micas; if (!m.containsKey(k)) m.put(k,v); vOld = m.putIfAbsent(k,v); Tipos At\u00f4micos 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import java.util.concurrent.atomic.AtomicInteger ; class AtomicCounter { private AtomicInteger c = new AtomicInteger ( 0 ); public void increment () { c . incrementAndGet (); } public void decrement () { c . decrementAndGet (); } public int value () { return c . get (); } } ThreadLocal 1 2 3 4 5 6 7 8 9 private static ThreadLocal < Integer > myId = new ThreadLocal < Integer > () { public Integer initialValue () { return new Random (). nexInt (); } }; public static Integer getMyId () { return myId . get (); } Exerc\u00edcio - Anel Multithread Usando uma linguagem de alto-n\u00edvel como C/C++/Java, escrever um programa que crie 30 threads e fa\u00e7a com que uma mensagem circule entre os mesmos. A mensagem \u00e9 uma string aleat\u00f3ria de pelo menos 80 caracteres. A cada vez que um thread recebe a mensagem ele a imprime, modifica o primeiro caractere min\u00fasculo para mai\u00fasculo, caso exista, dorme por 1 segundo, e repassa a mensagem. Quando todos os caracteres forem mai\u00fasculos, o processo repassa a mensagem e ent\u00e3o termina. Antes de terminar, o processo deve imprimir a mensagem resultante. Refer\u00eancias Sockets UDP em Python UDP em Python Multicast em Java Multicast em Python Beej's Guide to Network Programming - Using Internet Sockets Concorr\u00eancia em Java Java Concurrency in Practice The Well-Grounded Java Developer Concorr\u00eancia em Java Futures e Promises Locks Tipos At\u00f4micos Concorr\u00eancia em Python Threads em Python Estado Uma vis\u00e3o interessante sobre estado \u00e9 apresentada em On stateless software design . Observe que n\u00e3o necessariamente eu concordo com tudo o que est\u00e1 escrito aqui, principalmente a quest\u00e3o sobre stateful ser sempre mais complexo. A discrep\u00e2ncia de vis\u00e3o est\u00e1 no fato de parte da complexidade ser levada para o cliente, no caso dos servidores stateless , mas n\u00e3o necessariamente ser eliminada. Sobre IO n\u00e3o bloqueante em Java. Um bom ponto de partida para o t\u00f3pico \u00e9 a sua entrada na wikipedia . \u21a9 O artigo SEDA: An Architecture for Well-Conditioned, Scalable Internet Services descreve em detalhes a arquitetura SEDA. \u21a9 Pode-se argumentar que E/S ass\u00edncrona resolveria o problema aqui, mas isso n\u00e3o vem ao caso. \u21a9","title":"Concorr\u00eancia"},{"location":"coord/concurrency/#concorrencia","text":"Quando pensamos um sistema distribu\u00eddo, \u00e9 natural que o fa\u00e7amos em termos do paralelismo inato que surge do uso de m\u00faltiplos processos executando ao mesmo tempo em (normalmente) diferentes hosts . Contudo, \u00e9 importante pensar tamb\u00e9m em termos de paralelismo dentro de cada um dos processos que comp\u00f5em o sistema pois, no m\u00ednimo, componentes podem necessitar manter v\u00e1rias \"conversas\" em paralelo uns com os outros. Por isso, \u00e9 \"imposs\u00edvel\" pensar em sistemas distribu\u00eddos sem pensar em concorr\u00eancia na forma de m\u00faltiplos threads nos processos. Relembremos o exemplo de sistema implementado usando sockets, em que um processo cliente se conecta ao servidor para receber uma sauda\u00e7\u00e3o. A intera\u00e7\u00e3o entre tais processos acontece de forma sincronizada, lock-step , em que o cliente requisita o servi\u00e7o e ficava bloqueado esperando a resposta do servidor para ent\u00e3o prosseguir em seu processamento ( printf ), e o servidor fica bloqueado esperando requisi\u00e7\u00f5es que atende e ent\u00e3o volta a dormir. Este cen\u00e1rio, apresentado na figura a seguir, mostra que apesar do uso de processos distintos e da concorr\u00eancia na execu\u00e7\u00e3o dos processos, temos um baixo grau de efetivo paralelismo; a requisi\u00e7\u00e3o (2) s\u00f3 \u00e9 processada depois que a resposta (1) \u00e9 enviada. sequenceDiagram activate Cliente note left of Cliente: Ativo gerando requisi\u00e7\u00e3o note right of Servidor: Inativo esperando requisi\u00e7\u00e3o activate Cliente2 note right of Cliente2: Ativo gerando requisi\u00e7\u00e3o Cliente->>+Servidor: Request (1) deactivate Cliente note left of Cliente: Inativo esperando resposta Cliente2-->>Servidor: Request (2) deactivate Cliente2 note right of Cliente2: Inativo esperando resposta note right of Servidor: Ativo processando requisi\u00e7\u00e3o (1) Servidor->>-Cliente: Response (1) activate Cliente activate Servidor note left of Cliente: Ativo processando resposta (1) note right of Servidor: Ativo processando requisi\u00e7\u00e3o (2) Servidor-->>Cliente2: Response (2) deactivate Servidor activate Cliente2 note right of Servidor: Inativo esperando requisi\u00e7\u00e3o note right of Cliente2: Ativo processando resposta (2) deactivate Cliente deactivate Cliente2 Este modelo de sincroniza\u00e7\u00e3o entre as partes comunicantes \u00e9 um exemplo de E/S bloqueante . O principal ponto positivo desta estrat\u00e9gia \u00e9 a simplicidade do c\u00f3digo e o principal ponto negativo \u00e9 a limita\u00e7\u00e3o do paralelismo no uso de recursos, uma das raz\u00f5es de ser da computa\u00e7\u00e3o distribu\u00edda. Para usarmos melhor os recursos dispon\u00edveis, tanto do lado dos clientes quanto servidores, temos ent\u00e3o que pensar em termos de eventos sendo disparados entre os componentes, que devem ser tratados assim que recebidos ou t\u00e3o logo haja recursos para faz\u00ea-lo. Estes eventos correspondem tanto a requisi\u00e7\u00f5es quanto a respostas (efetivamente tornando dif\u00edcil a distin\u00e7\u00e3o). No modelo bloqueante, quando um evento \u00e9 disparado (no exemplo, a requisi\u00e7\u00e3o), o sistema fica bloqueado at\u00e9 que um evento espec\u00edfico seja observado (no exemplo, a chegada da resposta). Sempre que poss\u00edvel, um componente n\u00e3o deve ficar esperando por eventos em espec\u00edfico, aproveitando a chance executar outras tarefas; quando eventos s\u00e3o recebidos, s\u00e3o ent\u00e3o atendidos. Esta \u00e9 a forma de fazer E/S ass\u00edncrona . Dado que processos interagem com a rede usando sockets, cuja interface mais simples para opera\u00e7\u00f5es de leitura \u00e9 bloqueante, neste curso n\u00e3o falaremos especificamente sobre E/S ass\u00edncrono 1 e por isso, para vermos como aumentar a concorr\u00eancia no sistema, \u00e9 necess\u00e1rio falar de multithreading e as v\u00e1rias formas em que aparecem nos sistemas. H\u00e1 duas raz\u00f5es claras para estudarmos multithreading . A primeira, de ordem pr\u00e1tica, \u00e9 a discutida acima: permitir o desenvolvimento de componentes que utilizem \"melhormente\" os recursos em um host. A segunda, did\u00e1tica, \u00e9 o fato que muitos dos problemas que aparecem em programa\u00e7\u00e3o multithread , aparecem em programa\u00e7\u00e3o multi-processo (como nos sistemas distribu\u00eddos), apenas em um grau de complexidade maior. Para relembrar, h\u00e1 v\u00e1rias diferen\u00e7as entre threads e processos, mas a abstra\u00e7\u00e3o \u00e9 essencialmente a mesma: Processo Thread Quasi defini\u00e7\u00e3o Inst\u00e2ncia de um programa \"Processo leve\" Fun\u00e7\u00e3o de entrada main fun\u00e7\u00e3o \"qualquer\" Compartilhamento de c\u00f3digo e dados Privado ao processo Compartilhado pelos threads Estado C\u00f3digo, Stack, Heap, descritores (e.g, file descriptors), controle de acesso Stack, vari\u00e1veis locais Comunica\u00e7\u00e3o IPC ( Inter Process Communication ): sockets, FIFO, mem\u00f3ria compartilhada, etc IPC, mutex, vari\u00e1veis de condi\u00e7\u00e3o, sem\u00e1foros, etc N\u00edvel da implementa\u00e7\u00e3o Sistema operacional Diferentes implementa\u00e7\u00f5es API Posix, C++, Java, ... Efeito de E/S Mudan\u00e7a de contexto para outro thread mesmo sem terminar quantum Mudan\u00e7a de contexto para outro thread do mesmo processo Tempo de cria\u00e7\u00e3o, termina\u00e7\u00e3o e mudan\u00e7a de contexto Demora mais Demora menos Vejamos como o uso de m\u00faltiplos threads podem melhorar o desenvolvimento de sistemas distribu\u00eddos na pr\u00e1tica. Considere os exemplos de clientes e servidores vistos anteriormente . Imagine que em vez do servi\u00e7o simples feito no exemplo, o servidor retorne uma p\u00e1gina Web. Detalhes do protocolo seguido por navegadores e servidores ser\u00e3o vistos mais tarde. Por agora, considere apenas que uma requisi\u00e7\u00e3o GET arquivo.html ser\u00e1 enviada para o servidor que ler\u00e1 o arquivo especificado do sistema de arquivos; como voc\u00ea sabe, ler um arquivo \u00e9 uma opera\u00e7\u00e3o lenta e que n\u00e3o requer CPU.","title":"Concorr\u00eancia"},{"location":"coord/concurrency/#threads-no-cliente","text":"Do ponto de vista do cliente, a vantagem do uso de m\u00faltiplos threads s\u00e3o claras: permite lidar com v\u00e1rias tarefas concorrentemente , por exemplo solicitar CSS, HTML e imagens concorrentemente, escondendo lat\u00eancia das v\u00e1rias opera\u00e7\u00f5es, e permite organizar c\u00f3digo em blocos/m\u00f3dulos. Se voc\u00ea usar o console de desenvolvimento do navegador, ver\u00e1 como m\u00faltiplos arquivos s\u00e3o baixados em paralelo quando acessa um s\u00edtio. A figura a seguir mostra a carga do s\u00edtio da Facom . O primeiro arquivo, index.html \u00e9 baixado individualmente, mas uma vez que isso acontece e s\u00e3o determinados quais os demais arquivos necess\u00e1rios, requisi\u00e7\u00f5es concorrentes s\u00e3o disparadas, minimizando o tempo total da opera\u00e7\u00e3o. Como outros exemplos, considere um formul\u00e1rio online em que a valida\u00e7\u00e3o de um campo \u00e9 executada enquanto o campo seguinte est\u00e1 sendo preenchido, ou um servi\u00e7o de email em que arquivos s\u00e3o carregados enquanto a mensagem \u00e9 confeccionada.","title":"Threads no Cliente"},{"location":"coord/concurrency/#threads-servidor","text":"Do lado dos servidores h\u00e1 diversas possibilidades de uso de threads para aumentar o paralelismo no processamento de requisi\u00e7\u00f5es, melhor utilizando recursos dispon\u00edveis e melhorando a experi\u00eancia do usu\u00e1rio.","title":"Threads Servidor"},{"location":"coord/concurrency/#single-threaded","text":"A estrat\u00e9gia mais simples de se implementar \u00e9 a de usar apenas um thread, como temos feito at\u00e9 agora. Considere um servidor Web com esta esta caracter\u00edstica; o fluxo no tratamento de uma requisi\u00e7\u00e3o \u00e9 exemplificado na pela figura a seguir: O servidor \u00e9 iniciado, criando o socket e invocando accept o cliente envia a requisi\u00e7\u00e3o para o servidor o servidor aceita a conex\u00e3o em seu \u00fanico thread uma tarefa \u00e9 gerada para ler o arquivo o arquivo \u00e9 lido, de forma bloqueante, e uma resposta para o cliente \u00e9 preparada a resposta \u00e9 enviada para o cliente, de forma bloqueante a requisi\u00e7\u00e3o \u00e9 descartada o thread do servidor volta a esperar uma nova requisi\u00e7\u00e3o Se novas requisi\u00e7\u00f5es forem recebidas enquanto o servidor est\u00e1 executando os passos de 2 a 6, sejam requisi\u00e7\u00f5es paralelas do mesmo cliente ou de um outro cliente, estas ficar\u00e3o bloqueadas. A espera ser\u00e1 maior quanto mais o servidor demorar para atender \u00e0 primeira requisi\u00e7\u00e3o, por exemplo, se precisar consultar um banco de dados ou carregar o arquivo requisitado do disco. Para evitar que isto ocorra, o servidor pode usar mais threads.","title":"Single-threaded"},{"location":"coord/concurrency/#thread-per-request","text":"O servidor pode criar um novo thread para cada nova requisi\u00e7\u00e3o, permitindo que m\u00faltiplas requisi\u00e7\u00f5es sejam tratadas concorrentemente. Isto \u00e9, mesmo que um thread do servidor seja bloqueado por muito tempo, somente um cliente ter\u00e1 sua resposta atrasada (excluindo-se necessidades de coordena\u00e7\u00e3o entre m\u00faltiplos threads) e outros clientes podem continuar sendo atendidos normalmente, como mostrado na figura a seguir. Lembre-se, entretanto, que o n\u00famero de threads que se pode criar em um SO \u00e9 limitado, pois cada thread usa recursos do SO. Al\u00e9m disso, a cria\u00e7\u00e3o e destrui\u00e7\u00e3o de threads \u00e9 cara pois \u00e9 feita por meio de uma chamada de sistema, pelo kernel, e portanto implica em alternar entre modo usu\u00e1rio e modo protegido. Se poss\u00edvel, devemos evitar a cria\u00e7\u00e3o de novos threads em aplica\u00e7\u00f5es com requisitos de desempenho, e reclicl\u00e1-los pode ser uma boa estrat\u00e9gia.","title":"Thread per request"},{"location":"coord/concurrency/#thread-pool","text":"Para reciclarmos threads, podemos criar pools , um balde de threads que s\u00e3o usados quando necess\u00e1rio e devolvidos para o balde quando n\u00e3o mais. No cerne desta abordagem, junto com o pool de threads, fica uma fila bloquenante na qual tarefas s\u00e3o inseridas e de onde os threads tentam retir\u00e1-las. Como a fila \u00e9 bloqueante, se estiver vazia, o thread \u00e9 bloqueado e para de consumir recursos. T\u00e3o logo nova tarefa seja inserida, a fila acorda os threads para que a processem. Para garantir a corretude no processamento, a fila deve ser thread-safe , isto \u00e9, que se mantem correta mesmo quando m\u00faltiplos threads operam nela tanto para inserir quanto remover tarefas. Na figura, um thread principal \u00e9 encarregado de receber as requisi\u00e7\u00f5es e colocar na fila bloqueante; se a fila fica cheia, o thread principal fica bloqueado esperando por espa\u00e7o, fazendo com que novas conex\u00f5es tenham que esperar. Os threads do pool removem uma tarefa da fila, a tratam e, ao final do atendimento, pegam nova requisi\u00e7\u00e3o na fila, em um loop infinito; requisi\u00e7\u00f5es que demandam menor processamento liberam o thread mais rapidamente para que pegue nova tarefa. Se todas as tarefas s\u00e3o pequenas, os threds ficar\u00e3o bloqueados por muito tempo. Se todas s\u00e3o grandes, as tarefas se acumular\u00e3o na fila. Por isso \u00e9 importante dimensionar bem o tamanho to pool , ou mesmo torn\u00e1-lo din\u00e2mico para que use menos recursos (threads) quando n\u00e3o necess\u00e1rio e n\u00e3o deixe tarefas pendentes por muito tempo. Se considerarmos que cada tarefa na verdade tem v\u00e1rias partes, \u00e9 poss\u00edvel refinar mais este modelo, quebrando o processamento em v\u00e1rios pools.","title":"Thread pool"},{"location":"coord/concurrency/#estagios","text":"Na arquitetura baseada em est\u00e1gios, e.g., Staged Event-Driven Architecture , SEDA, cada est\u00e1gio , cada est\u00e1gio \u00e9 respons\u00e1vel por processar uma parte da tarefa, passada adiante at\u00e9 que seja completada. 2 Uma caracter\u00edstica importante deste modelo \u00e9 que cada est\u00e1gio pode ser escalado individualmente de acordo com a demanda uma vez que cada est\u00e1gio tem seu pr\u00f3prio pool . Por exemplo, se um est\u00e1gio faz algum c\u00e1lculo leve, ent\u00e3o poucos threads s\u00e3o necess\u00e1rios ao mesmo. J\u00e1 um est\u00e1gio que precise efetuar E/S talvez precise mais threads , uma vez que estes ficam bloqueandos enquanto a opera\u00e7\u00e3o \u00e9 executada. 3","title":"Est\u00e1gios"},{"location":"coord/concurrency/#desafios","text":"Embora a ideia de usar m\u00faltiplos threads seja melhorar desempenho e experi\u00eancia do usu\u00e1rio, faz\u00ea-lo efetivamente \u00e9 n\u00e3o trivial. Vejamos por exemplo o problema do falso compartilhamento; considere o seguinte pseudo-c\u00f3digo: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ... int32 X ; int32 Y ; thread1 = tread_new ( threadfunction , & X ); thread2 = tread_new ( threadfunction , & Y ); void threadfunction ( int32 * exclusivo ) { int32 local = * exclusivo ; while ( true ) { local = processa ( local ); * exclusivo = local ; } } ... Cada um dos threads criados acessa exclusivamente uma das vari\u00e1veis. Logo, n\u00e3o h\u00e1 interfer\u00eancia entre as threads e se cada uma for colocada em um processador diferente, executar\u00e3o no m\u00e1ximo de seu potencial, correto? N\u00e3o exatamente, pois mesmo este c\u00f3digo simpl\u00edssimo pode sofrer de falso compartilhamento . Isto acontece, por exemplo, se cada linha da cache do sistema onde este programa executa tiver 8 ou mais bytes de comprimento. Como tanto X quanto Y no programa tem 4 bytes, as duas vari\u00e1veis poder\u00e3o ficar na mesma linha da cache e toda vez que uma thread modificar uma vari\u00e1vel a cache da outra ser\u00e1 invalidada para leitura. Para que isto n\u00e3o ocorra, \u00e9 preciso se certificar que as vari\u00e1veis fiquem em linhas diferentes da cache; no exemplo, poderia-se definir X e Y como vetores do tamanho da linha da cache e usar efetivamente apenas a primeira posi\u00e7\u00e3o de cada vetor. Se o compartilhamento for real, por exemplo se ambos os threads usarem a vari\u00e1vel X, ent\u00e3o o problema n\u00e3o ser\u00e1 t\u00e3o facilmente resolv\u00edvel. Neste caso, poder-se-ia definir afinidade entre threads, isto \u00e9, notar quais threads compartilham estado de forma que threads afins sejam colocados nos mesmos processadores e compartilhem as mesmas mem\u00f3rias. Isto torna muito mais f\u00e1cil e eficiente o controle de concorr\u00eancia, do ponto de vista do SO e hardware. Multiprograma\u00e7\u00e3o Fazer esta divis\u00e3o pode ser complicado pois a rela\u00e7\u00e3o de compartilhamento entre threads pode ser complexa em fun\u00e7\u00e3o da tarefa sendo resolvida, por exemplo, se diferentes threads compartilharem diferentes vari\u00e1veis uns com os outros. Ainda que que uma configura\u00e7\u00e3o \u00f3tima em termos de afinidade exista, encontr\u00e1-la pode ser custo. Ainda assim, precisamos lidar com estado compartilhado e enfrentar condi\u00e7\u00f5es de corrida de forma a n\u00e3o levar a inconsist\u00eancias na executa\u00e7\u00e3o de tarefas, nos referindo a inconsist\u00eancia aqui como qualquer desvio no comportamento do programa daquilo que foi especificado pelo desenvolvedor. Para isso, usamos as primitivas de controle de concorr\u00eancia que estudaram em SO, que tamb\u00e9m tem seus problemas em potencial, como deadlocks e inani\u00e7\u00e3o . Veja o seguinte v\u00eddeo para uma an\u00e1lise de diversos pontos importantes no uso de multithreads.","title":"Desafios"},{"location":"coord/concurrency/#estado","text":"A quest\u00e3o das regi\u00f5es cr\u00edticas est\u00e1 intimamente relacionada \u00e0 quest\u00e3o da manuten\u00e7\u00e3o de estado nos servidores. Quanto a este respeito, podemos classificar servidores como stateful e stateless , dois termos que ouvir\u00e3o frequentemente enquanto trabalhando com SD. To state or not to state? Complexidade e desempenho Falhas Balanceamento O state nos dois nomes se refere ao estado mantido por um servi\u00e7o para atender a requisi\u00e7\u00f5es. Caso mantenha estado, por exemplo informando em quais arquivos o cliente est\u00e1 interessado, fica mais f\u00e1cil para o servidor continuar o trabalho feito em requisi\u00e7\u00f5es anteriores.","title":"Estado"},{"location":"coord/concurrency/#multithread-na-pratica","text":"","title":"Multithread na pr\u00e1tica"},{"location":"coord/concurrency/#posix","text":"POSIX Threads ou PThreads, s\u00e3o uma defini\u00e7\u00e3o aberta de como threads devem funcionar em sistemas operacionais. V\u00e1rias implementa\u00e7\u00f5es desta especifica\u00e7\u00e3o est\u00e3o dispon\u00edveis tanto para sistemas Unix, que se esfor\u00e7am para ser compat\u00edveis com especifi\u00e7\u00f5es POSIX, mas tamb\u00e9m para Windows, via subsistemas que compatibilizam diferentes API. Al\u00e9m disso, mesmo implementa\u00e7\u00f5es n\u00e3o POSIX tem funcionalidade equivalentes e, por este motivo, entender POSIX servir\u00e1 de base para entender quaisquer API para programa\u00e7\u00e3o multi-threaded . Para se definir um thread , \u00e9 necess\u00e1rio definir uma fun\u00e7\u00e3o de entrada, que ser\u00e1 para o thread como a fun\u00e7\u00e3o main \u00e9 para o processo em si. No exemplo a seguir a fun\u00e7\u00e3o foi definida com retorno void * e com \u00fanico par\u00e2metro, tamb\u00e9m void * ; esta \u00e9 uma obrigatoriedade para fun\u00e7\u00f5es de entrata PThread. Observe contudo que void * pode ser tratado como um blob para mascarar outros tipos de dados, por exemplo um vetor, um ponteiro para uma enumera\u00e7\u00e3o ou uma struct . Tamb\u00e9m observe que a fun\u00e7\u00e3o tem uma vari\u00e1vel local my_id que s\u00f3 est\u00e1 definida no contexto da thread (linha 8); se m\u00faltiplas threads forem instanciadas, cada uma ter\u00e1 a sua vers\u00e3o da vari\u00e1vel. H\u00e1 tamb\u00e9m uma vari\u00e1vel global thread_count , compartilhada por todas as inst\u00e2ncias (linha 5). 1 2 3 4 5 6 7 8 9 10 11 #include <stdio.h> #include <stdlib.h> #include <pthread.h> int thread_count ; void * hello ( void * id ) { long my_id = ( long ) id ; printf ( \"Hello from thread %ld of %d \\n \" , my_id , thread_count ); return NULL ; } Um thread \u00e9 criado pela fun\u00e7\u00e3o pthread_create (linha 14), que coloca em um pthread_t um handle para o thread . O handle do thread deve ser alocado previamente \u00e0 fun\u00e7\u00e3o de cria\u00e7\u00e3o do thread (linha 11). A fun\u00e7\u00e3o recebe como par\u00e2metros op\u00e7\u00f5es para configura\u00e7\u00e3o, a fun\u00e7\u00e3o de entrada, e o par\u00e2metro do tipo void * . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int main ( int argc , char * argv []) { long thread ; pthread_t * thread_handles ; if ( argc < 2 ) { printf ( \"usage: %s <number of threads>\" , argv [ 0 ]); return 1 ; } thread_count = strtol ( argv [ 1 ], NULL , 10 ); thread_handles = malloc ( thread_count * sizeof ( pthread_t )); for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_create ( & thread_handles [ thread ], NULL , hello , ( void * ) thread ); printf ( \"Hello from the main thread \\n \" ); \u00c9 poss\u00edvel esperar pelo fim da execu\u00e7\u00e3o do thread usando o pthread_join , que recebe como par\u00e2metro o handle do thread e um ponteiro para onde o resultado da fun\u00e7\u00e3o de entrada deve ser colocado, do tipo void ** (linha 2). No exemplo, nenhum retorno \u00e9 esperado, ent\u00e3o um endere\u00e7o nulo \u00e9 passado como par\u00e2metro. Ao final da execu\u00e7\u00e3o, o handle deve ser liberado (linha 4). 1 2 3 4 for ( thread = 0 ; thread < thread_count ; thread ++ ) pthread_join ( thread_handles [ thread ], NULL ); free ( thread_handles ); Para executar um programa PThread, compile com 1 gcc -pthread teste.c -o teste e execute com 1 ./teste 5 e observe que a sa\u00edda das threads \u00e9 ordenada . Agora experimente 1 ./teste 200 Observe que a sa\u00edda \u00e9 desordenada (pode ser necess\u00e1rio executar m\u00faltiplas vezes ou aumentar de 200 para, digamos, 1000 para observar a desordem. Isto acontece porqu\u00ea a execu\u00e7\u00e3o das threads independe da ordem de cria\u00e7\u00e3o. De fato, usando PThreads, temos pouco controle sobre os threads que criamos. Mas isto n\u00e3o quer dizer que estamos \"\u00f3rf\u00e3os\" de API; v\u00e1rias outras opera\u00e7\u00f5es podem ser executadas, e podem ser encontradas a partir do manual de pthread_create . Alguns exemplos interessantes: pthread_tryjoin - espera thread terminar pthread_exit - termina a thread e retorna resultado An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function's return value serves as the thread's exit status. Manual de pthread_exit . pthread_attr_setaffinity_np - ajusta afinidade dos threads.","title":"POSIX"},{"location":"coord/concurrency/#python","text":"Em Python, como seria de se esperar, h\u00e1 v\u00e1rias formas de se trabalhar com threads . O exemplo a seguir usa o pacote thread e \u00e9 essencialmente um env\u00f3lucro POSIX. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/usr/bin/python import thread import time # Define a function for the thread def print_time ( threadName , delay ): count = 0 while count < 5 : time . sleep ( delay ) count += 1 print \" %s : %s \" % ( threadName , time . ctime ( time . time ()) ) # Create two threads as follows try : thread . start_new_thread ( print_time , ( \"Thread-1\" , 2 , ) ) thread . start_new_thread ( print_time , ( \"Thread-2\" , 4 , ) ) except : print \"Error: unable to start thread\" while True : pass J\u00e1 o pr\u00f3ximo exemplo usa o pacote threading e uma abordagem orientada a objetos. Observe que h\u00e1 momentos distintos no ciclo de vida do thread em que acontece a cria\u00e7\u00e3o e o in\u00edcio da execu\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/usr/bin/python import threading import time exitFlag = 0 class myThread ( threading . Thread ): def __init__ ( self , threadID , name , counter ): threading . Thread . __init__ ( self ) self . threadID = threadID self . name = name self . counter = counter def run ( self ): print \"Starting \" + self . name print_time ( self . name , self . counter , 5 ) print \"Exiting \" + self . name def print_time ( threadName , counter , delay ): while counter : if exitFlag : threadName . exit () time . sleep ( delay ) print \" %s : %s \" % ( threadName , time . ctime ( time . time ())) counter -= 1 # Create new threads thread1 = myThread ( 1 , \"Thread-1\" , 1 ) thread2 = myThread ( 2 , \"Thread-2\" , 2 ) # Start new Threads thread1 . start () thread2 . start () print \"Exiting Main Thread\" Uma consequ\u00eancia desta divis\u00e3o \u00e9 que um mesmo objeto do tipo Thread pode ser reciclado e executado v\u00e1rias vezes.","title":"Python"},{"location":"coord/concurrency/#java","text":"Outro exemplo importante de API para multithreading \u00e9 a do Java, pois nesta linguagem h\u00e1, essencialmente, duas formas de se conseguir concorr\u00eancia. A primeira \u00e9 via inst\u00e2ncias expl\u00edcitas da classe Thread e, a segunda, via abstra\u00e7\u00f5es de mais alto n\u00edvel, os Executors . Aqui nos focaremos em aspectos b\u00e1sicos de concorr\u00eancia na linguagem, mas esteja ciente de que a mesma \u00e9 muito rica neste t\u00f3pico, por exemplo provendo diversas estruturas para comunica\u00e7\u00e3o e coordena\u00e7\u00e3o de threads no pacote java.util.concurrent . Uma \u00f3tima documenta\u00e7\u00e3o sobre o uso de threads e estruturas \u00e9 dispobinilizada pela Oracle . H\u00e1 duas formas b\u00e1sicas de definir um novo thread em Java, ou via extens\u00e3o da classe Thread ou via implementa\u00e7\u00e3o da interface Runnable ; observe o qu\u00e3o pouco muda no c\u00f3digo dos exemplos a seguir. Note tamb\u00e9m que, nos dois exemplos, um m\u00e9todo run() \u00e9 implementado com o c\u00f3digo a ser executado pelo thread mas que em nenhum momento tal m\u00e9todo \u00e9 invocado diretamente. Em vez disto, o m\u00e9todo start() \u00e9 que \u00e9 invocado, porqu\u00ea antes de executar as instru\u00e7\u00f5es definidas pelo pelo programador no m\u00e9todo run() , a m\u00e1quina virtual precisa executar alguma \"m\u00e1gica\" por baixo dos panos como, por exemplo, solicitar ao sistema operacional a cria\u00e7\u00e3o de um thread do SO, que servir\u00e1 de hospedeiro para o thread Java. Isto acontece dentro do start() , que em algum ponto de sua execu\u00e7\u00e3o levar\u00e1 \u00e0 invoca\u00e7\u00e3o do m\u00e9todo run() . Thread 1 2 3 4 5 6 7 8 9 10 public class Hello extends Thread { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new Hello (); t . start (); } } Runnable 1 2 3 4 5 6 7 8 9 10 public class Hello implements Runnable { public void run () { System . out . println ( \"Hello from a thread!\" ); } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); t . start (); } } Al\u00e9m de servider base para outras classes, a classe Thread tamb\u00e9m prov\u00ea uma s\u00e9rie de m\u00e9todos que permitem gerenciar a vida dos threads criados. Por exemplo, o m\u00e9todo de classe Thread.sleep() permite bloquear o thread no qual a invoca\u00e7\u00e3o aconteceu por um determinado per\u00edodo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Hello implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ){ System . out . println ( \"Hello at instant \" + i ); try { Thread . sleep ( 1000 ); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); t . start (); } } Observe que a chamada a sleep() deve estar dentro de um bloco try/catch , pois \u00e9 permitido \u00e0 JVM acordar o thread em qualquer instante, antes ou ap\u00f3s o tempo especificado. Assim, embora normalmente o tempo \"dormido\" seja pr\u00f3ximo ao especificado, se h\u00e1 requisitos de precis\u00e3o, \u00e9 sugerido que a thread durma em pequenas fra\u00e7\u00f5es at\u00e9 chegar ao valor total e que, ao acordar, verifique se j\u00e1 n\u00e3o dormiu o suficiente. No exemplo seguinte, o thread dorme por pelo menos 1000 milissegundos a cada itera\u00e7\u00e3o. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Hello implements Runnable { public void run () { for ( int i = 0 ; i < 10 ; i ++ ){ System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 1000 ; while ( before + timeout > System . currentTimeMillis ()){ try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); t . start (); } } Quando um thread est\u00e1 sendo executado, outros podem ter que esperar at\u00e9 que complete. Por exemplo, no caso de um navegador Web, o thread que faz a renderiza\u00e7\u00e3o da p\u00e1gina n\u00e3o pode come\u00e7ar a trabalhar enquanto o thread que solicitou o HTML do servidor n\u00e3o receber sua resposta. Um thread indica a inten\u00e7\u00e3o de esperar por outro usando o m\u00e9todo join() . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class Hello implements Runnable { public void run () { Random rand = new Random (); for ( int i = 0 ; i < 10 ; i ++ ){ System . out . println ( \"Hello at instant \" + i ); long before = System . currentTimeMillis (); long timeout = 901 + rand . nextInt ( 200 ); while ( before + timeout > System . currentTimeMillis ()){ try { Thread . sleep ( Math . max ( 0 , System . currentTimeMillis () - ( before + timeout ))); } catch ( InterruptedException ie ) { System . out . println ( \"awoken\" ); } } } } public static void main ( String args [] ) { Thread t = new Thread ( new Hello ()); //t.setDaemon(true); t . start (); try { t . join (); //t.join(10000); } catch ( InterruptedException ie ) { System . out . println ( \"Waiting was interrupted\" ); } if ( t . isAlive ()) System . out . println ( \"Got tired of waiting\" ); else System . out . println ( \"Wait is over\" ); } } Invocar t.join() far\u00e1 com que o thread corrente, neste caso o principal, espere indefinidamente at\u00e9 que t termine de executar. Caso seja necess\u00e1rio limitar o tempo de espera, um limite pode ser especificado como na linha comentada. Caso a espera termine por causa de um timeout , \u00e9 poss\u00edvel testar o estado atual do thread com Thread.isAlive() . Outro m\u00e9todo interessante, Thread.setDaemon() , especifica que o thread pode ser terminado quando a thread principal terminar. Descomente a invoca\u00e7\u00e3o e teste o efeito. Exerc\u00edcio: contador Fa\u00e7amos um exerc\u00edcio simples do uso de threads . Considere a classe e siga as instru\u00e7\u00f5es abaixo. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Counter { private int c = 0 ; public int increment () { return ++ c ; } public int decrement () { return -- c ; } public int value () { return c ; } } Instancie um programa que gere 10 threads . Todos os threads devem compartilhar uma mesma inst\u00e2ncia de Counter Cada thread deve executar um loop em que incrementa o valor do contador 20 vezes a cada vez, imprime o resultado precedido do identificador do thread (use Thread.getName() ou Thread.currentThread().getName() ) A thread principal deve esperar todas as outras terminarem antes de terminar (use Thread.join() ). Analise a sa\u00edda do programa observando a ordem de execu\u00e7\u00e3o dos threads . An\u00e1lise \u00c9 f\u00e1cil observar que a sa\u00edda do programa \u00e9 aleat\u00f3ria nos identificadores e tende a ser incremental nos contadores, mas nem sempre isso \u00e9 verdade. Isso acontece porqu\u00ea a execu\u00e7\u00e3o dos threads \u00e9 n\u00e3o determin\u00edstica; uma vez que estejam prontos para executar, cabe ao escalonador do sistema operacional a decis\u00e3o sobre qual processo e em qual processador dever\u00e1 executar. Al\u00e9m de extens\u00e3o de Thread e implementa\u00e7\u00e3o de Runnable , Java disponibiliza tamb\u00e9m ExecutorService como abstra\u00e7\u00e3o de mais alto n\u00edvel para execu\u00e7\u00e3o de tarefas concorrentes. Os ExecutorService , de forma gen\u00e9rica, prov\u00ea o acesso a pools de thread e a API para submeter tarefas para este pool. Para iniciar tal processo, voc\u00ea pode criar um executor service usando uma das muitas f\u00e1bricas providas pela classe Executors ou pela instancia\u00e7\u00e3o de thread pools diretamente. O mais simples \u00e9 o de tamanho fixo em que h\u00e1 um n\u00famero inicial de threads criados e que, no caso de algum ser terminado, por exemplo por causa de uma exce\u00e7\u00e3o n\u00e3o tratada, cria substitutos para manter o n\u00famero constante. 1 2 ExecutorService es1 = Executors . newFixedThreadPool ( 10 ); ExecutorService es2 = new ThreadPoolExecutor ( 1 , 1 , 0 L , TimeUnit . MILLISECONDS , new LinkedBlockingQueue <> ()); Uma vez criado o executor, voc\u00ea atribui tarefas para serem executadas, que devem implementar Runnable ou Callable . No caso de Runnable , voc\u00ea pode usar o m\u00e9todo execute para execut\u00e1-las em algum momento, sem a possibilidade de retorno de resultados. Implements 1 2 3 4 5 6 7 8 9 10 11 class MyRunnable implements Runnable { public void run (){ System . out . println ( \"R0\" ); } } Runnable r = new MyRunnable (); es1 . execute ( r ); es1 . execute ( r ); es2 . execute ( r ); An\u00f4nimo 1 2 3 4 5 6 7 8 9 Runnable r = new Runnable () { public void run (){ System . out . println ( \"R1\" ); } } es1 . execute ( r ); es1 . execute ( r ); es2 . execute ( r ); Lambda 1 2 3 4 5 6 7 Runnable r = () -> { System . out . println ( \"R2\" ); } es1 . execute ( r ); es1 . execute ( r ); es2 . execute ( r ); J\u00e1 usando Callable , \u00e9 poss\u00edvel retornar resultados na forma de Future<T> . No exemplo a seguir, a c retorna um Integer , e portanto submit retorna Future<Integer> ; para acessar o resultado, use Future<>.get() : 1 2 3 4 5 6 7 8 9 10 Callable < Integer > c = () -> { System . out . println ( \"C1\" ); return 3 ; } Future < Integer > f = es1 . submit ( c ); /* Outras tarefas... */ int resultado = f . get (); Outros m\u00e9todos interessantes dos ExecutorService s\u00e3o invokeAny() e invokeAll() , que permitem passar uma lista de tarefas e retornam o resultado de qualquer tarefa ou implica na execu\u00e7\u00e3o de todas, respectivamente. Alguns executores s\u00e3o interessantes por raz\u00f5es diferentes. Primeiro, o ForkJoinPool \u00e9 um executor interessante por funcionar da seguinte forma: 1 2 3 4 5 if (my portion of the work is small enough) do the work directly else split my work into two pieces invoke the two pieces and wait for the results Segundo, os ScheduledExecutorService permitem a execu\u00e7\u00e3o agendada ou peri\u00f3dica de tarefas, por exemplo: 1 2 3 4 5 6 ScheduledExecutorService es3 = Executors . newSingleThreadScheduledExecutor (); Future < Integer > f = executorService . schedule ( c , 1 , TimeUnit . SECONDS ); //Executa a cada 5 segundos, depois de esperar por 1 segundo para come\u00e7ar. executorService . scheduleAtFixedDelay ( r1 , 1000 , 5000 , TimeUnit . MILLISECONDS ); //Como a anterior, mas pode atrasar a pr\u00f3xima invoca\u00e7\u00e3o para permiter \u00e0 anterior que termine. executorService . scheduleAtFixedRate ( r1 , 1000 , 5000 , TimeUnit . MILLISECONDS );","title":"Java"},{"location":"coord/concurrency/#referencias","text":"Sockets UDP em Python UDP em Python Multicast em Java Multicast em Python Beej's Guide to Network Programming - Using Internet Sockets Concorr\u00eancia em Java Java Concurrency in Practice The Well-Grounded Java Developer Concorr\u00eancia em Java Futures e Promises Locks Tipos At\u00f4micos Concorr\u00eancia em Python Threads em Python Estado Uma vis\u00e3o interessante sobre estado \u00e9 apresentada em On stateless software design . Observe que n\u00e3o necessariamente eu concordo com tudo o que est\u00e1 escrito aqui, principalmente a quest\u00e3o sobre stateful ser sempre mais complexo. A discrep\u00e2ncia de vis\u00e3o est\u00e1 no fato de parte da complexidade ser levada para o cliente, no caso dos servidores stateless , mas n\u00e3o necessariamente ser eliminada. Sobre IO n\u00e3o bloqueante em Java. Um bom ponto de partida para o t\u00f3pico \u00e9 a sua entrada na wikipedia . \u21a9 O artigo SEDA: An Architecture for Well-Conditioned, Scalable Internet Services descreve em detalhes a arquitetura SEDA. \u21a9 Pode-se argumentar que E/S ass\u00edncrona resolveria o problema aqui, mas isso n\u00e3o vem ao caso. \u21a9","title":"Refer\u00eancias"},{"location":"coord/coord/","text":"Coordena\u00e7\u00e3o Como visto na se\u00e7\u00e3o sobre concorr\u00eancia , diversas tarefas exigem coordena\u00e7\u00e3o entre threads em uma aplica\u00e7\u00e3o monol\u00edtica em que se faz uso de concorr\u00eancia para melhor uso de recursos computacionais, obten\u00e7\u00e3o de melhor desempenho, e modulariza\u00e7\u00e3o do c\u00f3digo. Sistemas distribu\u00eddos levam concorr\u00eancia a um novo patamar de complexidade, fazendo uso de m\u00faltiplos processos, cada um com possivelmente m\u00faltiplos threads , ainda por cima, espalhados geograficamente. Outras solu\u00e7\u00f5es e abstra\u00e7\u00f5es s\u00e3o portanto necess\u00e1rias. Exclus\u00e3o M\u00fatua Um dos problemas enfrentados em sistemas que fazem uso de concorr\u00eancia, distribu\u00eddos ou n\u00e3o, \u00e9 a exclus\u00e3o m\u00fatua. Em um sistema monol\u00edtico, uma vari\u00e1vel global, um lock, ou outra primitiva de sincroniza\u00e7\u00e3o podem ser usadas na sincroniza\u00e7\u00e3o, mas em um sistema distribu\u00eddo, primitivas simples como estas provavelmente n\u00e3o estar\u00e3o dispon\u00edveis ou o sistema ser\u00e1 muito restrito. Como, ent\u00e3o, controlar o acesso de m\u00faltiplos processos a um recurso compartilhado, garantindo que cada processo controla exclusivamente aquele recurso durante seu acesso? Qualquer solu\u00e7\u00e3o que se proponha a este problema de exclus\u00e3o m\u00fatua, precisa ter as propriedades 1, 2, 3, e, idealmente, a 4, a seguir: Exclus\u00e3o M\u00fatua exclus\u00e3o m\u00fatua - somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks - se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o-inani\u00e7\u00e3o - todos os processos interessados conseguem, em algum momento, acessar o recurso; espera limitada - o tempo de espera pelo recurso \u00e9 limitado. H\u00e1 diversas solu\u00e7\u00f5es para exclus\u00e3o m\u00fatua em sistemas distribu\u00eddos, em diversos cen\u00e1rios, com seus pr\u00f3s e contras. Tr\u00eas das mais simples, e que ilustram o universo de solu\u00e7\u00f5es s\u00e3o via um processo centralizador, em um anel em que \"a vez\" \u00e9 circulada, e baseada em qu\u00f3runs. Coordenador Enquanto em um sistema monol\u00edtico h\u00e1 um sistema operacional que prov\u00ea abstra\u00e7\u00f5es simples para os processos a serem coordenados, em um sistema distribu\u00eddo, n\u00e3o h\u00e1 naturalmente tal entidade. Uma poss\u00edvel solu\u00e7\u00e3o para o problema de exclus\u00e3o m\u00fatua em um ambiente distribu\u00eddo \u00e9 justamente dar um passo para tr\u00e1s e introduzir um coordenador. Nesta abordagem, os processos que precisam acessar a regi\u00e3o cr\u00edtica s\u00e3o denominados participantes e um dos processos assume o papel de coordenador . \u00c9 poss\u00edvel que um mesmo processo atue nos dois pap\u00e9is sem nenhum preju\u00edzo. Os processos executam o seguinte protocolo: Participante Envia requisi\u00e7\u00e3o de acesso ao coordenador Espera por resposta do coordenador Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o, marca o recurso como livre Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado O diagrama a seguir apresenta uma execu\u00e7\u00e3o deste protocolo em um cen\u00e1rio com tr\u00eas participantes. O estado do coordenador mostra se o recurso est\u00e1 livre ou ocupado e quais processos esperam por permiss\u00e3o de acesso. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Part2->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part3] Coordenador->>Part2: ResponseFree note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Este algoritmo satisfaz as caracter\u00edsticas elencadas acima. Exclus\u00e3o m\u00fatua - se o coordenador autoriza um participante X, somente ap\u00f3s o participante X liberar o recurso \u00e9 que outro participante poder\u00e1 obter nova autoriza\u00e7\u00e3o. Aus\u00eancia de deadlocks - Todo processo que requisitar o recurso, entrar\u00e1 em uma fila, em apenas uma posi\u00e7\u00e3o; assim, a fila prover\u00e1 uma ordem total para os acessos, sem a possibilidade de circularidade nesta ordem. N\u00e3o-inani\u00e7\u00e3o - Dado que ningu\u00e9m fura a fila e que a cada vez que o recurso \u00e9 liberado a fila anda, em algum momento a vez do processo chegar\u00e1. Espera limitada - Dado que a posi\u00e7\u00e3o na fila pode apenas decrementar, seria poss\u00edvel estimar quanto tempo o participante precisa esperar para acessar o recurso. Outra vantagem deste algoritmo \u00e9 sua simplicidade e, consequentemente, facilidade de implementa\u00e7\u00e3o. Contudo, este algoritmo tem tamb\u00e9m desvantagens, por exemplo, se muitas requisi\u00e7\u00f5es de acesso forem feitas, o coordenador pode ser sobrecarregado e se tornar um gargalo no acesso \u00e0 regi\u00e3o cr\u00edtica. Mais s\u00e9rio ainda \u00e9 a quest\u00e3o de como lidar com falhas, por exemplo, se ou o coordenador ou o participante que detem o direito de acesso ao recurso para de funcionar, ent\u00e3o nenhum outro processo conseguir\u00e1 acesso. Estes aspectos nos permitem mergulhar na \u00e1rea de toler\u00e2ncia a falhas, e o faremos, mas mais tarde. Por enquanto, consideraremos toler\u00e2ncia a falhas de forma superficial, ap\u00f3s discutirmos outra abordagem. Anel Nesta abordagem, os processos se organizam em um anel l\u00f3gico, com um processo antes e outro depois. Um dos processos \u00e9 iniciado com um token que d\u00e1 acesso ao recurso e o token \u00e9 passado adiante no anel; sempre que estiver de posse do token, o processo pode acessar o recurso. Ou seja, todos os participantes executam o seguinte protocolo: Participante Ao receber o token de acesso, se quiser acessar o recurso, acessa. Envia o token para o pr\u00f3ximo n\u00f3 do anel. O diagrama adiante mostra uma execu\u00e7\u00e3o do algoritmo em que apenas os participantes 1 e 3 acessam o recurso. sequenceDiagram Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso note over Part1: Acessa o recurso Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso Como o algoritmo centralizado, o algoritmo do anel tamb\u00e9m garante as propriedades 1, 2, 3 e 4, al\u00e9m de ser f\u00e1cil de implementar, testar e entender. Diferente do algoritmo centralizado, o algoritmo do anel n\u00e3o sofre com problemas de gargalo, pois nenhum processo precisa participar em todos os acessos, como o coordenador. Contudo, o algoritmo do anel desperdi\u00e7a tempo passando o token para quem n\u00e3o necessariamente quer acessar a regi\u00e3o cr\u00edtica. Tamb\u00e9m importante \u00e9 que este algoritmo tamb\u00e9m sofre com falhas: se um participante falha enquanto com o token , levando-o para al\u00e9m. Lidando com Falhas Em ambos os algoritmos, centralizado e do anel, se um processo falhar, o algoritmo pode ficar \"travado\". Vejamos alguns casos espec\u00edficos: No algoritmo centralizado, se o coordenador falha antes de liberar o acesso para algum processo, ele leva consigo a permiss\u00e3o. Em ambos os algoritmos, se o processo acessando o recurso falha, a permiss\u00e3o \u00e9 perdida e os demais processos sofrer\u00e3o inani\u00e7\u00e3o. No algoritmo do anel, se qualquer outro processo falha, o anel \u00e9 interrompido o anel n\u00e3o conseguir\u00e1 circular. Observe que nem falamos de falhas dos canais e j\u00e1 temos diversos cen\u00e1rios a serem resolvidos, para os quais se lhes pedir uma solu\u00e7\u00e3o, tenho certeza absoluta de que me oferecer\u00e3o alguma baseada em timeouts . Por exemplo, se o processo n\u00e3o devolver a permiss\u00e3o de acesso antes de que uma certa quantidade de tempo tenha passado, um timeout , ent\u00e3o assuma que o mesmo parou de funcionar e n\u00e3o voltar\u00e1 mais, e gere uma nova permiss\u00e3o a ser passada a outros requisitantes. Aplicada esta ideia do timeout no algoritmo com coordenador, teremos o efeito ilustrado a seguir. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>Part2: ResponseOK activate Part2 note over Coordenador: Recurso=ocupado/Fila = [Part3] note over Part2: \ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80 deactivate Part2 Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree O problema desta e outras \"solu\u00e7\u00f5es\" baseadas em timeouts est\u00e1 no assumir que o processo parou de funcionar , pois caso isso n\u00e3o seja verdade, teremos agora duas autoriza\u00e7\u00f5es ao mesmo tempo no sistema, podendo levar \u00e0 viola\u00e7\u00e3o da propriedade de exclus\u00e3o m\u00fatua. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] rect rgb(200, 0, 0) Coordenador->>+Part3: ResponseOK Part2->>-Coordenador: RequestFree Part3->>-Coordenador: RequestFree end note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Por mais que se ajuste o valor do temporizador, em um sistema distribu\u00eddo ass\u00edncrono, mesmo que aumentado com um rel\u00f3gio para medir a passagem do tempo local, o mesmo pode sempre estar errado. Impossibilidade de detec\u00e7\u00e3o de falhas Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir um processo falho de um processo lento. Mais tarde discutiremos as implica\u00e7\u00f5es desta impossibilidade. Por agora, tentemos responder \u00e0 seguinte quest\u00e3o. Pergunta! Qual deve ser um timeout razo\u00e1vel para o meu sistema? A resposta depende de mais perguntas, como: Qual o custo \\(E\\) de esperar por mais tempo? Qual o custo \\(C\\) de cometer um engano? Qual a probabilidade \\(p\\) de cometer um engano? O custo esperado por causa dos erros, isto \u00e9, a esperan\u00e7a matem\u00e1tica da vari\u00e1vel aleat\u00f3ria custo, \u00e9 menor que o custo de se esperar por mais tempo, isto \u00e9, \\(C * p < E\\) ? Embora esta an\u00e1lise possa ser feita para estes algoritmos, a verdade \u00e9 que s\u00e3o realmente limitados e outras abordagens seriam melhor destino dos seus esfor\u00e7os. Por exemplo, podemos partir para a an\u00e1lise de algoritmos probabil\u00edsticos, pois afinal, como disse certa vez Werner Vogels, CTO da Amazon Se o mundo \u00e9 probabil\u00edstico, porqu\u00ea meus algoritmos devem ser determin\u00edsticos?\" Uma abordagem probabil\u00edstica interessante \u00e9 baseada em qu\u00f3runs. Qu\u00f3rum De acordo com o Dicion\u00e1rio Priberam da L\u00edngua Portuguesa, consultado em 17-04-2019 , \"qu\u00f3rum\" \u00e9 o N\u00famero de pessoas imprescind\u00edvel para a realiza\u00e7\u00e3o de algo. Aqui, este este algo ser\u00e1 a libera\u00e7\u00e3o de acesso ao recurso almejado pelos processos no sistema distribu\u00eddo. Esta abordagem \u00e9 semelhante em v\u00e1rios aspectos \u00e0 coordenada. De fato, um dos pap\u00e9is na abordagem \u00e9 o de coordenador, que executa o mesmo protocolo que antes. Entretanto, em vez de apenas um coordenador no sistema, temos \\(n\\) , dos quais o participante precisa obter \\(m > n/2\\) autoriza\u00e7\u00f5es antes de acessar o recurso; \\(m\\) \u00e9 o qu\u00f3rum do sistema. Qu\u00f3rum \\(n\\) coordenadores. \\(m > n/2\\) coordenadores J\u00e1 os demais participantes devem agora considerar todo o conjunto de coordenadores antes de assumir que tem acesso a um recurso. O algoritmo completo \u00e9 o seguinte: Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o se do processo a quem autorizou, marca o recurso como livre sen\u00e3o e se de um processo na fila, remove o processo da fila 1 sen\u00e3o, ignore mensagem. Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado Participante Envia requisi\u00e7\u00e3o de acesso aos \\(n\\) coordenadores Espera por resposta de \\(m\\) coordenadores Acessa o recurso Envia libera\u00e7\u00e3o do recurso para os \\(n\\) coordenadores Vejamos uma execu\u00e7\u00e3o bem sucedida destes algoritmo, com \\(n=3\\) e \\(m=2\\) . sequenceDiagram participant Coord1 participant Coord2 participant Coord3 note over Coord1,Coord3: Recurso=livre/Fila = [] Part1->>Coord1: RequestAccess Part1->>Coord2: RequestAccess Part2->>Coord1: RequestAccess Part2->>Coord2: RequestAccess Part2->>Coord3: RequestAccess Part1->>Coord3: RequestAccess note over Coord1,Coord2: Recurso=ocupado/Fila = [Part2] Coord1->>Part1: ResponseOK Coord2->>+Part1: ResponseOK note over Coord3: Recurso=ocupado/Fila = [Part1] Coord3->>Part2: ResponseOK Part1->>-Coord1: RequestFree Part1->>Coord2: RequestFree Part1->>Coord3: RequestFree note over Coord3: Recurso=ocupado/Fila = [] note over Coord1,Coord2: Recurso=ocupado/Fila = [] Coord1->>+Part2: ResponseOK Coord2->>Part2: ResponseOK Part2->>-Coord1: RequestFree Part2->>Coord2: RequestFree Part2->>Coord3: RequestFree note over Coord1,Coord3: Recurso=livre/Fila = [] Para tornamos o problema mais interessante e demonstrar o potencial deste algoritmo, consideremos que as autoriza\u00e7\u00f5es s\u00e3o armazenadas somente em mem\u00f3ria, e que coordenadores, ao falhar e ent\u00e3o resumir suas atividades, esquecem das autoriza\u00e7\u00f5es j\u00e1 atribu\u00eddas. Perda de mem\u00f3ria Quando um coordenador falha, esquece que deu ok e reinicia seu estado. Este algoritmo \u00e9 bom? Suponhamos o seguinte cen\u00e1rio: Coordenadores = {Coord1,Coord2,Coord3} \\(n = 3\\) \\(m = 2\\) Participante Part1 consegue autoriza\u00e7\u00e3o de {Coord1,Coord2} e entra na regi\u00e3o cr\u00edtica. Coordenador Coord2 falha e se recupera Participante Part2 consegue autoriza\u00e7\u00e3o de {Coord2,Coord3} e entra na regi\u00e3o cr\u00edtica. sequenceDiagram participant Coord1 participant Coord2 participant Coord3 note over Coord1,Coord3: Recurso=livre/Fila = [] Part1->>Coord1: RequestAccess Part1->>Coord2: RequestAccess Part2->>Coord1: RequestAccess Part1->>Coord3: RequestAccess Part2->>Coord3: RequestAccess note over Coord1,Coord2: Recurso=livre/Fila = [Part1,Part2] note over Coord3: Recurso=livre/Fila = [Part2,Part1] note over Coord1,Coord2: Recurso=ocupado/Fila = [Part2] note over Coord3: Recurso=ocupado/Fila = [Part1] Coord1->>Part1: ResponseOK Coord2->>+Part1: ResponseOK Coord3->>Part2: ResponseOK note over Coord2: \ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80 note over Coord2: Recurso=livre/Fila = [] Part2->>Coord2: RequestAccess note over Coord2: Recurso=livre/Fila = [Part2] note over Coord2: Recurso=livre/Fila = [] rect rgb(200, 0, 0) Coord2->>+Part2: ResponseOk Part1->>-Coord1: RequestFree end Part1->>Coord2: RequestFree Part1->>Coord3: RequestFree Part2->>-Coord1: RequestFree Part2->>Coord2: RequestFree Part2->>Coord3: RequestFree Neste cen\u00e1rio, a propriedade de Exclus\u00e3o M\u00fatua \u00e9 violada. Isto porqu\u00ea, dados os dois qu\u00f3runs, todos os processos na interse\u00e7\u00e3o foram reiniciados. Mas de forma geral, qual a probabilidade de isso acontecer? Ou seja, dados dois qu\u00f3runs, de tamanho \\(m\\) , que se sobrep\u00f5em em \\(k\\) processos, qual a probabilidade \\(P_v\\) de que os \\(k\\) processos na interse\u00e7\u00e3o sejam reiniciados e levem \u00e0 viola\u00e7\u00e3o? Seja a \\(P\\) a probabilidade de um coordenador em espec\u00edfico falhar e se recuperar dentro de uma janela de tempo \\(\\delta t\\) . Temos Probabilidade de falha de exatamente 1 coordenador: \\(P^1(1-P)^{n-1}\\) Probabilidade de \\(k\\) coordenadores falharem: \\(P^k(1-P)^{n-k}\\) Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem: \\(\\binom{m}{k} P^k(1-P)^{m-k}\\) Mas qual \u00e9 o tamanho \\(k\\) da interse\u00e7\u00e3o? \\(\\left| A \\cup B\\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cap B \\right| \\Rightarrow n = m + m - k\\) \\(\\left| A \\cap B \\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cup B\\right| \\Rightarrow k = m + m - n = 2m - n\\) At\u00e9 agora consideramos que a \\(k\\) corresponde \u00e0 cardinalidade da interse\u00e7\u00e3o dos dois qu\u00f3runs, mas se mais do que a interse\u00e7\u00e3o forem reiniciados, tamb\u00e9m teremos problemas. Assim, se \\(k\\) assume qualquer valor entre o tamanho da interse\u00e7\u00e3o e o n\u00famero total de coordenadores, teremos problemas. Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem, para qualquer \\(k\\) variando de \\(2m-n\\) a \\(n\\) : \\(P_v = \\sum_{k=2m-n}^n \\binom{m}{k} P^k(1-P)^{m-k}\\) Para facilitar o entendimento desta grandeza, considere o exemplo: \\(P=0.0001\\) (1 minuto a cada 10 dias) \\(n = 32\\) \\(m = 0.75n\\) \\(P_v < 10^{-40}\\) ( Curiosidade sobre \\(10^{40}\\) ) A probabilidade de viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua, neste caso, \u00e9 muito pequena, a despeito de suportar falhas dos coordenadores. Pr\u00f3 Tolera falhas de coordenadores, com probabilidade controlada de viola\u00e7\u00e3o de exclus\u00e3o m\u00fatua. Mas e as outras propriedades desej\u00e1veis do algoritmo de exclus\u00e3o m\u00fatua, s\u00e3o alcan\u00e7adas? Relembrando: Contras Exclus\u00e3o M\u00fatua probabil\u00edstica: \\(1 - P_v\\) N\u00e3o-inani\u00e7\u00e3o E se cada participante obtiver o ok de um coordenador? Temporizador para quebrar o deadlock ? Espera limitada Aborts podem levar a espera infinita. Assim, este algoritmo tamb\u00e9m pode n\u00e3o ser adequado para certas situa\u00e7\u00f5es. Vamos tentar re-acessar os problemas da primeira abordagem. Por um lado, o uso de um l\u00edder para coordenar a\u00e7\u00f5es em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto \u00fanico de falha, como no algoritmo de exclus\u00e3o m\u00fatua centralizado. Mas e se substitu\u00edssemos o coordenador no caso de falhas? Este \u00e9 o problema conhecido como elei\u00e7\u00e3o de l\u00edderes. TODO Maekawa - Diminui n\u00famero de votos necess\u00e1rios ( descri\u00e7\u00e3o ) Lamport - Usa rel\u00f3gios l\u00f3gicos, mas \u00e9 poss\u00edvel entender sem este background ( descri\u00e7\u00e3o ) Ricart-Agrawala - Melhora algoritmo de Lamport ( descri\u00e7\u00e3o ) Distributed-Mutual-Exclusion-slides Elei\u00e7\u00e3o de L\u00edderes O problema da escolha de um processo centralizador, ou l\u00edder, pode ser posto informalmente como o procedimento pelo qual um processo \u00e9 escolhido dentre os demais processos, sendo que o processo escolhido \u00e9 ciente da escolha e todos os demais processos o identificam como eleito . Uma nova elei\u00e7\u00e3o deve acontecer sempre que o l\u00edder se tornar indispon\u00edvel . Formalmente, um algoritmo de elei\u00e7\u00e3o de l\u00edderes deve satisfazer as seguintes condi\u00e7\u00f5es. Elei\u00e7\u00e3o de L\u00edderes 2 Termina\u00e7\u00e3o: algum processo deve se considerar l\u00edder em algum momento. Unicidade: somente um processo se considera l\u00edder. Acordo: todos os outros processos sabem quem foi eleito l\u00edder. Para entendermos melhor o problema, tentemos desenvolver um protocolo simples para escolhermos um l\u00edder, por exemplo, em sua turma da disciplina de Sistemas Distribu\u00eddos. Vejamos algumas quest\u00f5es importantes. Candidatos: todos os membros s\u00e3o eleg\u00edveis ou apenas um subconjunto dos mesmos? Comunica\u00e7\u00e3o: todos se conhecem e se falam diretamente ou h\u00e1 grupos incomunic\u00e1veis dentro da turma? Estabilidade: de que adianta eleger um dos colegas se frequentemente n\u00e3o est\u00e1 presente quando necess\u00e1rio? Em termos computacionais, estas quest\u00f5es s\u00e3o relevantes pois todos os processos n\u00e3o nascem iguais; alguns residem em m\u00e1quinas com mais mem\u00f3ria, mais poder de processamento, melhor conex\u00e3o com o resto do mundo ou maior grau de conectividade. Talvez este processo seja um l\u00edder mais \u00fatil que os demais. Al\u00e9m disso, se o processo est\u00e1 frequentemente desconectado, mesmo que bem servido de recursos, n\u00e3o ser\u00e1 um bom l\u00edder. Ainda que assumamos um conjunto de processos indiferenci\u00e1veis entre si, com acesso equivalente a recursos e que estejam sempre dispon\u00edveis, ou exatamente por isso, temos um problem mais fundamental para resolver: para eleger um l\u00edder, precisamos diferenciar processos . Dentro de uma \u00fanica m\u00e1quina, identificamos processos facilmente usando seu PID , ou process id , um inteiro associado a cada processo instanciado pelo sistema operacional; o PID \u00e9 v\u00e1lido enquanto o processo estiver executando e pode ser reciclado uma vez que o processo para de executar, o que pode ser um problema. Al\u00e9m disso, se o host \u00e9 reiniciado, os PID tamb\u00e9m s\u00e3o, e portanto esta identifica\u00e7\u00e3o n\u00e3o \u00e9 duradoura. Mais importante, o PID s\u00f3 faz sentido dentro de uma \u00fanica m\u00e1quina e n\u00e3o em um sistema distribu\u00eddo. Se apenas uma inst\u00e2ncia do processo executa em um mesmo host , ent\u00e3o o identificador do host (e.g., endere\u00e7o IP) em si \u00e9 suficiente e, de fato, comumente utilizado. Se mais de um processo executa no mesmo host , ent\u00e3o cabe ao desenvolvedor criar um esquema que permita diferenciar os processos, e n\u00e3o precisa ser nada complicado; pode ser apenas um par\u00e2metro passado na inicializa\u00e7\u00e3o do processo ou a combina\u00e7\u00e3o IP/porta . Assumindo que um esquema de nomea\u00e7\u00e3o est\u00e1 dispon\u00edvel e que todos os processos se conhecem, voltemos ao problema de eleger um l\u00edder para sua turma. Uma abordagem que pode funcionar \u00e9 colocar todos os candidatos para brigar e quem sobrar em p\u00e9 no final, \u00e9 o novo l\u00edder. A despeito desta op\u00e7\u00e3o gerar um l\u00edder n\u00e3o muito popular, o algoritmo do brig\u00e3o \u00e9 um cl\u00e1ssico. Algoritmo do Brig\u00e3o ( Bully ) No algoritmo do brig\u00e3o, alguma caracter\u00edstica compar\u00e1vel dos processos \u00e9 escolhida e aquele processo funcional com o valor de tal caracter\u00edstica mais vantajoso para um l\u00edder \u00e9 escolhido como tal. Por exemplo, pode ser vantajoso ter um l\u00edder com maior quantidade de mem\u00f3ria, frequ\u00eancia da CPU ou largura de banda da conex\u00e3o com a Internet; no caso de empate, o identificador do processo pode ser usado para gerar uma ordem total entre os processos. Para simplificar, vamos assumir que o identificador do processo reflete as qualidades do mesmo para a lideran\u00e7a, tal que o processo com maior identificador seja o melhor candidato. Os maiores processos, os \"brig\u00f5es\", eliminam os processos menores da competi\u00e7\u00e3o, sempre que uma elei\u00e7\u00e3o acontecer. O algoritmo \u00e9 apresentado a seguir, onde \\(p\\) e \\(q\\) s\u00e3o usados para representar tanto identificadores de processos quando os processos em si. Algoritmo do Brig\u00e3o Quando \\(p\\) suspeita que o l\u00edder n\u00e3o est\u00e1 presente (muito tempo se receber mensagens do mesmo) \\(p\\) envia mensagem (ELEICAO, \\(p\\) ) para todos os processos com identificador maior que \\(p\\) Inicia temporizador de respostas Quando temporizador de respostas expira Envia (COORD, \\(p\\) ) para todos os processos Quando recebe (Ok, \\(p\\) ) Para temporizador de resposta Quando \\(p\\) recebe (ELEICAO, \\(q\\) ), \\(q < p\\) Envia (OK, \\(q\\) ) Quando um processo falho se recupera Inicia uma elei\u00e7\u00e3o Observe como o algoritmo foi descrito em termos de eventos e n\u00e3o de forma sequencial. Este tipo de especifica\u00e7\u00e3o \u00e9 comum para algoritmos paralelos e distribu\u00eddos, pois n\u00e3o h\u00e1 uma sequ\u00eancia pr\u00e9-estabelecida de passos a serem executados por todos os processos, apenas alguns pontos de coordena\u00e7\u00e3o. No exemplo a seguir, temos 5 processos, com identificadores de 1 a 5, passando por 7 passos at\u00e9 que a elei\u00e7\u00e3o se complete. Observe que os processos n\u00e3o sabem a priori como os eventos aconteceram e apenas reagem aos eventos de recep\u00e7\u00e3o de mensagens e expira\u00e7\u00e3o de temporizadores . o l\u00edder j\u00e1 \u00e9 o processo 5 (em rosa). os processos 2 e 3 (amarelo) se \"cansaram\" de esperar por 5, que falhou (em cinza, e se candidataram a l\u00edder, enviando (ELEICAO,2) e (ELEICAO,3), respectivamente, (verde). 4 responde a 2 a 3 com (OK,2) e (OK,3) como resposta a 2 e 3, respectivamente, e 3 envia (OK,2) para 2. 1 se candidata com enviando (ELEICAO,1). 2, 3 e 4 respondem com (OK,1). 4 se candidata enviando (ELEICAO,4) para 5, que n\u00e3o responde, j\u00e1 que est\u00e1 falho. 4 se declara l\u00edder e envia (COORD,4) a todos os processos. Como j\u00e1 discutido antes, a escolha do valor temporizador \u00e9 fundamental para o bom funcionamento do algoritmo. Se o temporizador usado pelos processos para esperar pelo l\u00edder for ajustado de forma agressiva, frequentemente ser\u00e3o iniciadas elei\u00e7\u00f5es mesmo que o l\u00edder n\u00e3o tenha falhado. J\u00e1 se o valor do temporizador for muito grande, o sistema demorar\u00e1 a eleger um novo l\u00edder . Da mesma forma, se o tempo esperado por um candidato antes de se declarar l\u00edder for muito curto, mais de um processo pode se declarar l\u00edder , uma situa\u00e7\u00e3o conhecida como split-brain . Idealmente, um processo deveria esperar por outro enquanto o outro estiver apto a responder, mas isso requer saber quando o outro processo n\u00e3o est\u00e1 mais apto, isto \u00e9, falhou. Como identificar exatamente quando isso aconteceu \u00e9 imposs\u00edvel em sistemas distribu\u00eddos ass\u00edncronos, o algoritmo do brig\u00e3o n\u00e3o resolve o problema neste ambiente. Mas se delimitarmos melhor o ambiente, podemos chegar a solu\u00e7\u00f5es melhores. Algoritmos em An\u00e9is Consideremos processos organizados em um anel l\u00f3gico em que processos troquem mensagens apenas com processos \u00e0 \"esquerda\" e \u00e0 \"direita\". Considere tamb\u00e9m que todos os processos s\u00e3o exatamente id\u00eanticos, inclusive n\u00e3o possuindo identificadores pr\u00f3prios. Suponha o seguinte algoritmo de elei\u00e7\u00e3o neste anel, em que um processo inicialmente Seguidor se torna Candidato, ent\u00e3o se declara Eleito, avisa a seus pares e, finalmente, se declara Empossado. Algoritmo do Anel 1 Na inicia\u00e7\u00e3o Organize os n\u00f3s em um anel l\u00f3gico \\(C \\gets\\) Seguidor Quando um processo acha que o l\u00edder est\u00e1 morto \\(C \\gets\\) Candidato Envia (VoteEmMim) para \"a direita\" no anel. Quando um processo recebe (VoteEmMim) Se \\(C =\\) Seguidor envia (VoteEmMim) para a direita Se \\(C =\\) Candidato \\(C \\gets\\) Eleito envia (HabemosLeader) para a direita Quando um processo recebe (HabemosLeader) Se \\(C =\\) Seguidor envia (HabemosLeader) para a direita Se \\(C =\\) Eleito \\(C \\gets\\) Empossado Imagine um cen\u00e1rio com dois processos, como na imagem a seguir. Os nomes dos processos s\u00e3o apenas para facilitar o entendimento do fluxo de mensagens e n\u00e3o est\u00e3o acess\u00edveis aos processos. Executando o algoritmo Anel 1, os processos enviam ( \\(\\rightarrow\\) ) e recebem ( \\(\\leftarrow\\) ) as seguintes mensagens e ajustam \\(C\\) da seguinte forma. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado Agora imagine que por um acaso, tanto processo 1 quanto o 2 se candidatassem ao mesmo tempo. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado \\(C \\gets\\) Empossado Como n\u00e3o h\u00e1 nada que diferencie os processos entre si, este cen\u00e1rio \u00e9 perfeitamente v\u00e1lido, e se no primeiro cen\u00e1rio o algoritmo estava correto ao eleger o processo 1, ent\u00e3o no segundo cen\u00e1rio o 1 tamb\u00e9m deve ser eleito, j\u00e1 que a sequ\u00eancia de evento observadas \u00e9 exatamente a mesma. Mas o processo 2 tamb\u00e9m v\u00ea a mesma sequ\u00eancia, ent\u00e3o tamb\u00e9m deve ser eleito. Assim, violamos a propriedade da Unicidade. Para quebrar essa simetria entre os processo, podemos permitir que saibam seus identificadores. No algoritmo seguinte, permitimos que os processos conhe\u00e7am seus identificadores e um processo que suspeite do l\u00edder atual, envia uma mensagem no anel para coletar os identificadores de todos os processos. Algoritmo do Anel 2 Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem [ \\(p\\) ] \"\u00e0 direita\". Quando \\(p\\) recebe \\(l\\) Se \\(p \\not \\in l\\) Envia \\([p:l]\\) para a direita. Se \\(p \\in l\\) Escolhe menor id em \\(l\\) como l\u00edder. Este algoritmo envia at\u00e9 \\(n^2\\) mensagens, se todos iniciarem a elei\u00e7\u00e3o ao mesmo tempo, e as mensagens crescem at\u00e9 o tamanho \\(n\\) . O algoritmo de Chang e Robert 3 limita o tamanho das mensagens ao pr\u00e9-selecionar candidatos vi\u00e1veis. Algoritmo de Chang e Robert Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem \\((p)\\) \u00e0 direita Quando \\(p\\) recebe \\((q)\\) Se \\(p = q\\) \\(p\\) se declara l\u00edder Sen\u00e3o e se \\(q > p\\) Envia \\((q)\\) para a direita. Neste algoritmo, todas as mensagens tem tamanho \\(O(1)\\) e somente uma mensagem d\u00e1 uma volta completa do anel; todas as outras s\u00e3o descartadas no meio do caminho. Apesar disso, pode-se demonstrar que o pior caso em termos de n\u00famero de mensagens do algoritmo at\u00e9 que algu\u00e9m se declare l\u00edder \u00e9 \\(O(n^2)\\) . Exerc\u00edcio: Quantidade de mensagens O pior caso em termos de n\u00famero de mensagens at\u00e9 que algu\u00e9m seja eleito \u00e9 \\(O(n^2)\\) . Descreva como os n\u00f3s devem estar organizados para que esta situa\u00e7\u00e3o ocorra. Observe que no algoritmo um processo apenas se \"declara l\u00edder\", mas os outros n\u00e3o necessariamente ficam sabendo disso. Como voc\u00ea o corrigiria para que terminasse? Diversos outros algoritmos existem para a topologia em anel. O algoritmo de Franklin \u00e9 um dos que prop\u00f5e melhorias para reduzir quantidade de mensagens usadas na elei\u00e7\u00e3o. Ele faz isso em rodadas, comparando identificadores com outros processos ativos tanto \u00e0 esquerda quanto \u00e0 direita e desativando os processos n\u00e3o vi\u00e1veis. Algoritmo de Franklin Organize os n\u00f3s em um anel l\u00f3gico Ativo \\(\\gets 1\\) Quando \\(p\\) acha que o l\u00edder est\u00e1 morto e se Ativo $ = 1$ : Envia mensagem \\((p)\\) \u00e0 direita e \u00e0 esquerda Quando \\(p\\) recebe \\(e\\) e \\(d\\) , da esquerda e da direita, respectivamente: Se Ativo \\(=1\\) Se \\(max(e,d) < p\\) Envia mensagem \\((p)\\) \u00e0 direita e \u00e0 esquerda Se \\(max(e,d) > p\\) Ativo \\(\\gets 0\\) Envia mensagem \\(-p\\) \u00e0 direita e \u00e0 esquerda Se \\(max(e,d) = p\\) \\(p\\) se declara l\u00edder. Se Ativo \\(=0\\) Repassa cada mensagem para o outro lado. No exemplo na figura, os n\u00f3s brancos s\u00e3o ativos e os amarelos inativos. Observe o papel do n\u00f3 no centro, supondo que tem o maior identificador entre todos os processos. Inicialmente ele envia as mensagens em verde para os lados, que levam seus vizinhos imediatos a se inativarem. Na segunda rodada, as mensagens s\u00e3o repassadas para os vizinhos dos vizinhos, que tamb\u00e9m se inativam. Observe o seguinte: Em cada fase, para qualquer par de vizinhos ativos, pelos um dos dois \u00e9 inativado e, portanto, o n\u00famero de ativos cai pela metade; logo h\u00e1 no m\u00e1ximo \\(O(log n)\\) fases. Na primeira fase, cada processo ativo leva a \\(4\\) mensagens serem enviadas na rede (sem nenhuma otimiza\u00e7\u00e3o). Dado que s\u00e3o \\(n\\) processos, temos \\(4n\\) mensagens, \\(O(n)\\) Na segunda fase, cada processo ativo leva a 8 mensagens. Contudo, metade dos processos, pelo menos, foram inativados na primeira fase. Logo, temos \\(8n \\times n/2, O(n)\\) Assim, no m\u00e1ximo \\(O(n log n)\\) mensagens s\u00e3o enviadas em uma execu\u00e7\u00e3o do algoritmo. Algoritmo do YoYo Saindo da topologia em anel, vejamos o algoritmo do Yoyo, que funciona em qualquer topologia conexa, mesmo se processos n\u00e3o puderem se falar diretamente. Inicialmente as arestas do formado pelos processos e seus canais de comunica\u00e7\u00e3o s\u00e3o n\u00e3o direcionadas, mas na medida em que o protocolo \u00e9 executado, as arestas s\u00e3o marcadas como tendo um ou outro sentido. Esta marca\u00e7\u00e3o \u00e9 apenas l\u00f3gica e mensagens fluem em ambos os sentidos. De acordo com o tipo de arestas que um processo tem, ele \u00e9 classificado como um de tr\u00eas tipos: Fonte (source) - processo que s\u00f3 tem arestas de sa\u00edda Vertedouro (sink) - processo que s\u00f3 tem arestas de chegada Interno - processo que tem arestas de chegada e de sa\u00edda O algoritmo executa em duas fases. Na primeira, cada processo marca sua arestas como apontando para o maior dentre si pr\u00f3prio e seus vizinhos. Na segunda fase, mensagens \"v\u00e3o e voltam\", o que d\u00e1 o nome ao algoritmo. Na \"ida\", as mensagens v\u00e3o das fontes para os vertedouros, que identificam quais fontes tem os menores identificadores e sinalizam para que continuem fontes na pr\u00f3xima etapa com mensagens de volta. As mensagens de volta reordenam as arestas para garantir este comportamento. Vejamos o algoritmo em mais detalhes. Algoritmo do YoYo Fase 1 \\(p\\) envia seu identificador para seus vizinhos. Quando \\(p\\) recebe \\(q\\) Se \\(p>q\\) Marca a aresta em que recebeu \\(q\\) como sendo de chegada ( \\(p\\leftarrow q\\) ) Sen\u00e3o Marca a aresta em que recebeu \\(q\\) como sendo de sa\u00edda ( \\(q\\leftarrow p\\) ) Fase 2 Se \\(p\\) \u00e9 uma fonte \\(p\\) envia seu identificador em todas as suas arestas de sa\u00edda. Quando \\(p\\) receber \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda Se recebeu apenas \\(S\\) Executa fase 2 novamente Se \\(p\\) \u00e9 um n\u00f3 interno Quando \\(p\\) receber identificadores em todas as suas arestas de entrada escolhe o menor id recebido \\(m\\) envia \\(m\\) em todas as suas arestas de sa\u00edda Quando \\(p\\) recebeu \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda Se recebeu algum \\(S\\) envia \\(S\\) para vizinhos de onde recebeu \\(m\\) envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) Se n\u00e3o recebeu \\(S\\) envia \\(N\\) para vizinhos de onde recebeu algum id. Se \\(p\\) \u00e9 um vertedouro Quando \\(p\\) receber identificadores em todas as suas arestas de entrada escolhe o menor id recebido \\(m\\) envia \\(S\\) para vizinhos de onde recebeu \\(m\\) envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) N inverte a dire\u00e7\u00e3o das arestas em que trafega. Fonte Veja um exemplo com 3 processos em destaque, uma fonte, um interno e um vertedouro. Veja o seguinte exemplo, em que cada figura mostra um est\u00e1gio da resolu\u00e7\u00e3o do problema de elei\u00e7\u00e3o de l\u00edderes. a) A rede em seu estado inicial. b) Rede orientada pela primera fase c) Propaga\u00e7\u00e3o de Fontes d) Propaga\u00e7\u00e3o de Vertedouros e) Inativa\u00e7\u00e3o dos vertedouros Exemplo: Embora interessante, este algoritmo tamb\u00e9m tem problemas, sendo um dos mais cr\u00edticos a forma de lidar com falhas, mesmo sem considerar falhas de processos. Suponha que o canal de comunica\u00e7\u00e3o entre os processos 2 e 10 pare de funcionar. O que acontecer\u00e1? Esta \u00e9 uma situa\u00e7\u00e3o que denominamos particionamento da rede e que neste caso levar\u00e1 a duas elei\u00e7\u00f5es concorrentes acontecerem e, consequentemente, a dois l\u00edderes sendo eleitos, o que \u00e9 conhecido na \u00e1rea como split-brain . Vejamos esta e outras situa\u00e7\u00f5es problem\u00e1ticas em elei\u00e7\u00e3o de l\u00edderes. Quest\u00f5es importantes Split-brain Se o algoritmo viola a propriedade de unicidade, ent\u00e3o fica com split-brain , em que parte da rede v\u00ea um processo como l\u00edder e parte v\u00ea outro. Se o l\u00edder \u00e9 o respons\u00e1vel por coordenar o acesso a uma regi\u00e3o cr\u00edtica, como visto no algoritmo coordenado de exclus\u00e3o m\u00fatua, ent\u00e3o ter dois l\u00edderes poder\u00e1 levar a dois processos na regi\u00e3o cr\u00edtica e portanto viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua. Uma das formas de evitar split-brain \u00e9 atribuir um \"peso\" para cada processo e s\u00f3 aceitar que um l\u00edder seja declarado se o mesmo seus votos carregarem mais da metade do peso do sistema. Ainda assim, temos problemas, pois \u00e9 necess\u00e1rio que rodadas sucessivas do algoritmo invalidem as elei\u00e7\u00f5es anteriores. O algoritmo Raft de difus\u00e3o at\u00f4mica, que estudaremos adiante, define mandatos e garante, com pesos, que somente um l\u00edder existe em cada mandato. Devido \u00e0 natureza ass\u00edncrona do sistema, processos podem se achar em mandatos distintos e, por isso, o mandato \u00e9 associado a todas as comunica\u00e7\u00f5es; mensagens recebidas de mandatos anteriores s\u00e3o sumariamente descartadas. Mas por qu\u00ea precisamos de mandatos sucessivos? Para substituir um l\u00edder que tenha falhado. O que nos leva a outros dois problemas, o da detec\u00e7\u00e3o de falhas e o da estabilidade do l\u00edder. Estabilidade Dizemos que um algoritmo de elei\u00e7\u00e3o de l\u00edderes \u00e9 est\u00e1vel se uma vez que um l\u00edder \u00e9 eleito, uma nova elei\u00e7\u00e3o s\u00f3 acontece se o l\u00edder falha. Considere o algoritmo do brig\u00e3o. Imagine, no exemplo apresentado, que o processo 5 teve problemas de comunica\u00e7\u00e3o e foi percebido como falho pelos demais. Neste caso, o 4 seria eleito l\u00edder. Mas se o problema que aflige 5 \u00e9 tempor\u00e1rio, 5 voltar\u00e1 e executar\u00e1 nova elei\u00e7\u00e3o, tornando-se l\u00edder novamente. Se este cen\u00e1rio se repente indefinidamente, o sistema poder\u00e1 ser seriamente comprometido em seu desempenho. Uma vers\u00e3o est\u00e1vel do algoritmo tentaria, por exemplo, associar ao peso do processo o tempo de execu\u00e7\u00e3o ininterrupta do mesmo. Assim, quanto mais tempo um processo execute, maior ser\u00e1 seu peso e sua capacidade de manter a lideran\u00e7a. Se o mesmo falhar, ent\u00e3o seu peso ser\u00e1 drasticamente reduzido e suas chances de ser eleito l\u00edder reduzidas temporariamente. Observe que os problemas enfrentados s\u00e3o ligados \u00e0 detec\u00e7\u00e3o e contorno de falhas. Detec\u00e7\u00e3o de falhas Como j\u00e1 mencionado antes, detec\u00e7\u00e3o de falhas \u00e9 o mecanismo pelo qual um processo monitora e percebe se outro falhou. Pensemos em como um processo monitora o outro em um sistema distribu\u00eddo. Claramente, por meio de troca de mensagens e temporizadores. Mas se estamos falando de sistemas distribu\u00eddos ass\u00edncronos, ent\u00e3o mensagens podem ser atrasadas indefinidamente ou rel\u00f3gios podem ser atrasados, ent\u00e3o n\u00e3o se pode confiar na falta de recep\u00e7\u00e3o de uma mensagem como garantia de que um processo parou de funcionar. Aprofundemo-nos nos pr\u00f3ximos cap\u00edtulo nos conceitos de tempo e toler\u00e2ncia a falhas, mas enquanto isso, fiquemos com o seguinte resultado. Detec\u00e7\u00e3o de falhas Detec\u00e7\u00e3o de falhas perfeita \u00e9 imposs\u00edvel... em sistemas distribu\u00eddos ass\u00edncronos (Internet) sujeitos \u00e0 parti\u00e7\u00f5es (Internet) com requisitos de disponibilidade total. para evitar que mensagens de requisi\u00e7\u00f5es distintas do mesmo processo se confundam, \u00e9 \u00fatil identificar cada requisi\u00e7\u00e3o, por exemplo, com um contador de requisi\u00e7\u00f5es. \u21a9 A Probabilistically Correct Leader Election Protocol for Large Groups \u21a9 An improved algorithm for decentralized extrema-finding in circular configurations of processes . \u21a9","title":"Coordena\u00e7\u00e3o"},{"location":"coord/coord/#coordenacao","text":"Como visto na se\u00e7\u00e3o sobre concorr\u00eancia , diversas tarefas exigem coordena\u00e7\u00e3o entre threads em uma aplica\u00e7\u00e3o monol\u00edtica em que se faz uso de concorr\u00eancia para melhor uso de recursos computacionais, obten\u00e7\u00e3o de melhor desempenho, e modulariza\u00e7\u00e3o do c\u00f3digo. Sistemas distribu\u00eddos levam concorr\u00eancia a um novo patamar de complexidade, fazendo uso de m\u00faltiplos processos, cada um com possivelmente m\u00faltiplos threads , ainda por cima, espalhados geograficamente. Outras solu\u00e7\u00f5es e abstra\u00e7\u00f5es s\u00e3o portanto necess\u00e1rias.","title":"Coordena\u00e7\u00e3o"},{"location":"coord/coord/#exclusao-mutua","text":"Um dos problemas enfrentados em sistemas que fazem uso de concorr\u00eancia, distribu\u00eddos ou n\u00e3o, \u00e9 a exclus\u00e3o m\u00fatua. Em um sistema monol\u00edtico, uma vari\u00e1vel global, um lock, ou outra primitiva de sincroniza\u00e7\u00e3o podem ser usadas na sincroniza\u00e7\u00e3o, mas em um sistema distribu\u00eddo, primitivas simples como estas provavelmente n\u00e3o estar\u00e3o dispon\u00edveis ou o sistema ser\u00e1 muito restrito. Como, ent\u00e3o, controlar o acesso de m\u00faltiplos processos a um recurso compartilhado, garantindo que cada processo controla exclusivamente aquele recurso durante seu acesso? Qualquer solu\u00e7\u00e3o que se proponha a este problema de exclus\u00e3o m\u00fatua, precisa ter as propriedades 1, 2, 3, e, idealmente, a 4, a seguir: Exclus\u00e3o M\u00fatua exclus\u00e3o m\u00fatua - somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks - se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o-inani\u00e7\u00e3o - todos os processos interessados conseguem, em algum momento, acessar o recurso; espera limitada - o tempo de espera pelo recurso \u00e9 limitado. H\u00e1 diversas solu\u00e7\u00f5es para exclus\u00e3o m\u00fatua em sistemas distribu\u00eddos, em diversos cen\u00e1rios, com seus pr\u00f3s e contras. Tr\u00eas das mais simples, e que ilustram o universo de solu\u00e7\u00f5es s\u00e3o via um processo centralizador, em um anel em que \"a vez\" \u00e9 circulada, e baseada em qu\u00f3runs.","title":"Exclus\u00e3o M\u00fatua"},{"location":"coord/coord/#coordenador","text":"Enquanto em um sistema monol\u00edtico h\u00e1 um sistema operacional que prov\u00ea abstra\u00e7\u00f5es simples para os processos a serem coordenados, em um sistema distribu\u00eddo, n\u00e3o h\u00e1 naturalmente tal entidade. Uma poss\u00edvel solu\u00e7\u00e3o para o problema de exclus\u00e3o m\u00fatua em um ambiente distribu\u00eddo \u00e9 justamente dar um passo para tr\u00e1s e introduzir um coordenador. Nesta abordagem, os processos que precisam acessar a regi\u00e3o cr\u00edtica s\u00e3o denominados participantes e um dos processos assume o papel de coordenador . \u00c9 poss\u00edvel que um mesmo processo atue nos dois pap\u00e9is sem nenhum preju\u00edzo. Os processos executam o seguinte protocolo: Participante Envia requisi\u00e7\u00e3o de acesso ao coordenador Espera por resposta do coordenador Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o, marca o recurso como livre Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado O diagrama a seguir apresenta uma execu\u00e7\u00e3o deste protocolo em um cen\u00e1rio com tr\u00eas participantes. O estado do coordenador mostra se o recurso est\u00e1 livre ou ocupado e quais processos esperam por permiss\u00e3o de acesso. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Part2->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part3] Coordenador->>Part2: ResponseFree note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Este algoritmo satisfaz as caracter\u00edsticas elencadas acima. Exclus\u00e3o m\u00fatua - se o coordenador autoriza um participante X, somente ap\u00f3s o participante X liberar o recurso \u00e9 que outro participante poder\u00e1 obter nova autoriza\u00e7\u00e3o. Aus\u00eancia de deadlocks - Todo processo que requisitar o recurso, entrar\u00e1 em uma fila, em apenas uma posi\u00e7\u00e3o; assim, a fila prover\u00e1 uma ordem total para os acessos, sem a possibilidade de circularidade nesta ordem. N\u00e3o-inani\u00e7\u00e3o - Dado que ningu\u00e9m fura a fila e que a cada vez que o recurso \u00e9 liberado a fila anda, em algum momento a vez do processo chegar\u00e1. Espera limitada - Dado que a posi\u00e7\u00e3o na fila pode apenas decrementar, seria poss\u00edvel estimar quanto tempo o participante precisa esperar para acessar o recurso. Outra vantagem deste algoritmo \u00e9 sua simplicidade e, consequentemente, facilidade de implementa\u00e7\u00e3o. Contudo, este algoritmo tem tamb\u00e9m desvantagens, por exemplo, se muitas requisi\u00e7\u00f5es de acesso forem feitas, o coordenador pode ser sobrecarregado e se tornar um gargalo no acesso \u00e0 regi\u00e3o cr\u00edtica. Mais s\u00e9rio ainda \u00e9 a quest\u00e3o de como lidar com falhas, por exemplo, se ou o coordenador ou o participante que detem o direito de acesso ao recurso para de funcionar, ent\u00e3o nenhum outro processo conseguir\u00e1 acesso. Estes aspectos nos permitem mergulhar na \u00e1rea de toler\u00e2ncia a falhas, e o faremos, mas mais tarde. Por enquanto, consideraremos toler\u00e2ncia a falhas de forma superficial, ap\u00f3s discutirmos outra abordagem.","title":"Coordenador"},{"location":"coord/coord/#anel","text":"Nesta abordagem, os processos se organizam em um anel l\u00f3gico, com um processo antes e outro depois. Um dos processos \u00e9 iniciado com um token que d\u00e1 acesso ao recurso e o token \u00e9 passado adiante no anel; sempre que estiver de posse do token, o processo pode acessar o recurso. Ou seja, todos os participantes executam o seguinte protocolo: Participante Ao receber o token de acesso, se quiser acessar o recurso, acessa. Envia o token para o pr\u00f3ximo n\u00f3 do anel. O diagrama adiante mostra uma execu\u00e7\u00e3o do algoritmo em que apenas os participantes 1 e 3 acessam o recurso. sequenceDiagram Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso note over Part1: Acessa o recurso Part1->>Part2: Permiss\u00e3o de Acesso Part2->>Part3: Permiss\u00e3o de Acesso note over Part3: Acessa o recurso Part3->>Part4: Permiss\u00e3o de Acesso Part4->>Part1: Permiss\u00e3o de Acesso Como o algoritmo centralizado, o algoritmo do anel tamb\u00e9m garante as propriedades 1, 2, 3 e 4, al\u00e9m de ser f\u00e1cil de implementar, testar e entender. Diferente do algoritmo centralizado, o algoritmo do anel n\u00e3o sofre com problemas de gargalo, pois nenhum processo precisa participar em todos os acessos, como o coordenador. Contudo, o algoritmo do anel desperdi\u00e7a tempo passando o token para quem n\u00e3o necessariamente quer acessar a regi\u00e3o cr\u00edtica. Tamb\u00e9m importante \u00e9 que este algoritmo tamb\u00e9m sofre com falhas: se um participante falha enquanto com o token , levando-o para al\u00e9m.","title":"Anel"},{"location":"coord/coord/#lidando-com-falhas","text":"Em ambos os algoritmos, centralizado e do anel, se um processo falhar, o algoritmo pode ficar \"travado\". Vejamos alguns casos espec\u00edficos: No algoritmo centralizado, se o coordenador falha antes de liberar o acesso para algum processo, ele leva consigo a permiss\u00e3o. Em ambos os algoritmos, se o processo acessando o recurso falha, a permiss\u00e3o \u00e9 perdida e os demais processos sofrer\u00e3o inani\u00e7\u00e3o. No algoritmo do anel, se qualquer outro processo falha, o anel \u00e9 interrompido o anel n\u00e3o conseguir\u00e1 circular. Observe que nem falamos de falhas dos canais e j\u00e1 temos diversos cen\u00e1rios a serem resolvidos, para os quais se lhes pedir uma solu\u00e7\u00e3o, tenho certeza absoluta de que me oferecer\u00e3o alguma baseada em timeouts . Por exemplo, se o processo n\u00e3o devolver a permiss\u00e3o de acesso antes de que uma certa quantidade de tempo tenha passado, um timeout , ent\u00e3o assuma que o mesmo parou de funcionar e n\u00e3o voltar\u00e1 mais, e gere uma nova permiss\u00e3o a ser passada a outros requisitantes. Aplicada esta ideia do timeout no algoritmo com coordenador, teremos o efeito ilustrado a seguir. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>Part2: ResponseOK activate Part2 note over Coordenador: Recurso=ocupado/Fila = [Part3] note over Part2: \ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80 deactivate Part2 Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] Coordenador->>+Part3: ResponseOK Part3->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree O problema desta e outras \"solu\u00e7\u00f5es\" baseadas em timeouts est\u00e1 no assumir que o processo parou de funcionar , pois caso isso n\u00e3o seja verdade, teremos agora duas autoriza\u00e7\u00f5es ao mesmo tempo no sistema, podendo levar \u00e0 viola\u00e7\u00e3o da propriedade de exclus\u00e3o m\u00fatua. sequenceDiagram participant Coordenador note over Coordenador: Recurso=livre/Fila = [] Part1->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part1] Coordenador->>+Part1: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [] Part2->>Coordenador: RequestAccess note over Coordenador: Recurso=ocupado/Fila = [Part2] Part1->>-Coordenador: RequestFree note over Coordenador: Recurso=livre/Fila = [Part2] Coordenador->>Part1: ResponseFree Part3->>Coordenador: RequestAccess note over Coordenador: Recurso=livre/Fila = [Part2,Part3] Coordenador->>+Part2: ResponseOK note over Coordenador: Recurso=ocupado/Fila = [Part3] Coordenador->>Coordenador: Timeout note over Coordenador: Recurso=livre/Fila = [Part3] note over Coordenador: Recurso=ocupado/Fila = [] rect rgb(200, 0, 0) Coordenador->>+Part3: ResponseOK Part2->>-Coordenador: RequestFree Part3->>-Coordenador: RequestFree end note over Coordenador: Recurso=livre/Fila = [] Coordenador->>Part3: ResponseFree Por mais que se ajuste o valor do temporizador, em um sistema distribu\u00eddo ass\u00edncrono, mesmo que aumentado com um rel\u00f3gio para medir a passagem do tempo local, o mesmo pode sempre estar errado. Impossibilidade de detec\u00e7\u00e3o de falhas Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir um processo falho de um processo lento. Mais tarde discutiremos as implica\u00e7\u00f5es desta impossibilidade. Por agora, tentemos responder \u00e0 seguinte quest\u00e3o. Pergunta! Qual deve ser um timeout razo\u00e1vel para o meu sistema? A resposta depende de mais perguntas, como: Qual o custo \\(E\\) de esperar por mais tempo? Qual o custo \\(C\\) de cometer um engano? Qual a probabilidade \\(p\\) de cometer um engano? O custo esperado por causa dos erros, isto \u00e9, a esperan\u00e7a matem\u00e1tica da vari\u00e1vel aleat\u00f3ria custo, \u00e9 menor que o custo de se esperar por mais tempo, isto \u00e9, \\(C * p < E\\) ? Embora esta an\u00e1lise possa ser feita para estes algoritmos, a verdade \u00e9 que s\u00e3o realmente limitados e outras abordagens seriam melhor destino dos seus esfor\u00e7os. Por exemplo, podemos partir para a an\u00e1lise de algoritmos probabil\u00edsticos, pois afinal, como disse certa vez Werner Vogels, CTO da Amazon Se o mundo \u00e9 probabil\u00edstico, porqu\u00ea meus algoritmos devem ser determin\u00edsticos?\" Uma abordagem probabil\u00edstica interessante \u00e9 baseada em qu\u00f3runs.","title":"Lidando com Falhas"},{"location":"coord/coord/#quorum","text":"De acordo com o Dicion\u00e1rio Priberam da L\u00edngua Portuguesa, consultado em 17-04-2019 , \"qu\u00f3rum\" \u00e9 o N\u00famero de pessoas imprescind\u00edvel para a realiza\u00e7\u00e3o de algo. Aqui, este este algo ser\u00e1 a libera\u00e7\u00e3o de acesso ao recurso almejado pelos processos no sistema distribu\u00eddo. Esta abordagem \u00e9 semelhante em v\u00e1rios aspectos \u00e0 coordenada. De fato, um dos pap\u00e9is na abordagem \u00e9 o de coordenador, que executa o mesmo protocolo que antes. Entretanto, em vez de apenas um coordenador no sistema, temos \\(n\\) , dos quais o participante precisa obter \\(m > n/2\\) autoriza\u00e7\u00f5es antes de acessar o recurso; \\(m\\) \u00e9 o qu\u00f3rum do sistema. Qu\u00f3rum \\(n\\) coordenadores. \\(m > n/2\\) coordenadores J\u00e1 os demais participantes devem agora considerar todo o conjunto de coordenadores antes de assumir que tem acesso a um recurso. O algoritmo completo \u00e9 o seguinte: Coordenador Inicializa recurso como livre Ao receber uma requisi\u00e7\u00e3o, a enfileira Ao receber uma libera\u00e7\u00e3o se do processo a quem autorizou, marca o recurso como livre sen\u00e3o e se de um processo na fila, remove o processo da fila 1 sen\u00e3o, ignore mensagem. Sempre que recurso estiver marcado como livre E a fila n\u00e3o estiver vazia remove primeiro processo da fila envia libera\u00e7\u00e3o para processo removido marca o recurso como ocupado Participante Envia requisi\u00e7\u00e3o de acesso aos \\(n\\) coordenadores Espera por resposta de \\(m\\) coordenadores Acessa o recurso Envia libera\u00e7\u00e3o do recurso para os \\(n\\) coordenadores Vejamos uma execu\u00e7\u00e3o bem sucedida destes algoritmo, com \\(n=3\\) e \\(m=2\\) . sequenceDiagram participant Coord1 participant Coord2 participant Coord3 note over Coord1,Coord3: Recurso=livre/Fila = [] Part1->>Coord1: RequestAccess Part1->>Coord2: RequestAccess Part2->>Coord1: RequestAccess Part2->>Coord2: RequestAccess Part2->>Coord3: RequestAccess Part1->>Coord3: RequestAccess note over Coord1,Coord2: Recurso=ocupado/Fila = [Part2] Coord1->>Part1: ResponseOK Coord2->>+Part1: ResponseOK note over Coord3: Recurso=ocupado/Fila = [Part1] Coord3->>Part2: ResponseOK Part1->>-Coord1: RequestFree Part1->>Coord2: RequestFree Part1->>Coord3: RequestFree note over Coord3: Recurso=ocupado/Fila = [] note over Coord1,Coord2: Recurso=ocupado/Fila = [] Coord1->>+Part2: ResponseOK Coord2->>Part2: ResponseOK Part2->>-Coord1: RequestFree Part2->>Coord2: RequestFree Part2->>Coord3: RequestFree note over Coord1,Coord3: Recurso=livre/Fila = [] Para tornamos o problema mais interessante e demonstrar o potencial deste algoritmo, consideremos que as autoriza\u00e7\u00f5es s\u00e3o armazenadas somente em mem\u00f3ria, e que coordenadores, ao falhar e ent\u00e3o resumir suas atividades, esquecem das autoriza\u00e7\u00f5es j\u00e1 atribu\u00eddas. Perda de mem\u00f3ria Quando um coordenador falha, esquece que deu ok e reinicia seu estado. Este algoritmo \u00e9 bom? Suponhamos o seguinte cen\u00e1rio: Coordenadores = {Coord1,Coord2,Coord3} \\(n = 3\\) \\(m = 2\\) Participante Part1 consegue autoriza\u00e7\u00e3o de {Coord1,Coord2} e entra na regi\u00e3o cr\u00edtica. Coordenador Coord2 falha e se recupera Participante Part2 consegue autoriza\u00e7\u00e3o de {Coord2,Coord3} e entra na regi\u00e3o cr\u00edtica. sequenceDiagram participant Coord1 participant Coord2 participant Coord3 note over Coord1,Coord3: Recurso=livre/Fila = [] Part1->>Coord1: RequestAccess Part1->>Coord2: RequestAccess Part2->>Coord1: RequestAccess Part1->>Coord3: RequestAccess Part2->>Coord3: RequestAccess note over Coord1,Coord2: Recurso=livre/Fila = [Part1,Part2] note over Coord3: Recurso=livre/Fila = [Part2,Part1] note over Coord1,Coord2: Recurso=ocupado/Fila = [Part2] note over Coord3: Recurso=ocupado/Fila = [Part1] Coord1->>Part1: ResponseOK Coord2->>+Part1: ResponseOK Coord3->>Part2: ResponseOK note over Coord2: \ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80\u2620\ufe0f\ud83d\udc80 note over Coord2: Recurso=livre/Fila = [] Part2->>Coord2: RequestAccess note over Coord2: Recurso=livre/Fila = [Part2] note over Coord2: Recurso=livre/Fila = [] rect rgb(200, 0, 0) Coord2->>+Part2: ResponseOk Part1->>-Coord1: RequestFree end Part1->>Coord2: RequestFree Part1->>Coord3: RequestFree Part2->>-Coord1: RequestFree Part2->>Coord2: RequestFree Part2->>Coord3: RequestFree Neste cen\u00e1rio, a propriedade de Exclus\u00e3o M\u00fatua \u00e9 violada. Isto porqu\u00ea, dados os dois qu\u00f3runs, todos os processos na interse\u00e7\u00e3o foram reiniciados. Mas de forma geral, qual a probabilidade de isso acontecer? Ou seja, dados dois qu\u00f3runs, de tamanho \\(m\\) , que se sobrep\u00f5em em \\(k\\) processos, qual a probabilidade \\(P_v\\) de que os \\(k\\) processos na interse\u00e7\u00e3o sejam reiniciados e levem \u00e0 viola\u00e7\u00e3o? Seja a \\(P\\) a probabilidade de um coordenador em espec\u00edfico falhar e se recuperar dentro de uma janela de tempo \\(\\delta t\\) . Temos Probabilidade de falha de exatamente 1 coordenador: \\(P^1(1-P)^{n-1}\\) Probabilidade de \\(k\\) coordenadores falharem: \\(P^k(1-P)^{n-k}\\) Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem: \\(\\binom{m}{k} P^k(1-P)^{m-k}\\) Mas qual \u00e9 o tamanho \\(k\\) da interse\u00e7\u00e3o? \\(\\left| A \\cup B\\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cap B \\right| \\Rightarrow n = m + m - k\\) \\(\\left| A \\cap B \\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cup B\\right| \\Rightarrow k = m + m - n = 2m - n\\) At\u00e9 agora consideramos que a \\(k\\) corresponde \u00e0 cardinalidade da interse\u00e7\u00e3o dos dois qu\u00f3runs, mas se mais do que a interse\u00e7\u00e3o forem reiniciados, tamb\u00e9m teremos problemas. Assim, se \\(k\\) assume qualquer valor entre o tamanho da interse\u00e7\u00e3o e o n\u00famero total de coordenadores, teremos problemas. Probabilidade de quaisquer \\(k\\) em \\(m\\) coordenadores falharem, para qualquer \\(k\\) variando de \\(2m-n\\) a \\(n\\) : \\(P_v = \\sum_{k=2m-n}^n \\binom{m}{k} P^k(1-P)^{m-k}\\) Para facilitar o entendimento desta grandeza, considere o exemplo: \\(P=0.0001\\) (1 minuto a cada 10 dias) \\(n = 32\\) \\(m = 0.75n\\) \\(P_v < 10^{-40}\\) ( Curiosidade sobre \\(10^{40}\\) ) A probabilidade de viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua, neste caso, \u00e9 muito pequena, a despeito de suportar falhas dos coordenadores. Pr\u00f3 Tolera falhas de coordenadores, com probabilidade controlada de viola\u00e7\u00e3o de exclus\u00e3o m\u00fatua. Mas e as outras propriedades desej\u00e1veis do algoritmo de exclus\u00e3o m\u00fatua, s\u00e3o alcan\u00e7adas? Relembrando: Contras Exclus\u00e3o M\u00fatua probabil\u00edstica: \\(1 - P_v\\) N\u00e3o-inani\u00e7\u00e3o E se cada participante obtiver o ok de um coordenador? Temporizador para quebrar o deadlock ? Espera limitada Aborts podem levar a espera infinita. Assim, este algoritmo tamb\u00e9m pode n\u00e3o ser adequado para certas situa\u00e7\u00f5es. Vamos tentar re-acessar os problemas da primeira abordagem. Por um lado, o uso de um l\u00edder para coordenar a\u00e7\u00f5es em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto \u00fanico de falha, como no algoritmo de exclus\u00e3o m\u00fatua centralizado. Mas e se substitu\u00edssemos o coordenador no caso de falhas? Este \u00e9 o problema conhecido como elei\u00e7\u00e3o de l\u00edderes. TODO Maekawa - Diminui n\u00famero de votos necess\u00e1rios ( descri\u00e7\u00e3o ) Lamport - Usa rel\u00f3gios l\u00f3gicos, mas \u00e9 poss\u00edvel entender sem este background ( descri\u00e7\u00e3o ) Ricart-Agrawala - Melhora algoritmo de Lamport ( descri\u00e7\u00e3o ) Distributed-Mutual-Exclusion-slides","title":"Qu\u00f3rum"},{"location":"coord/coord/#eleicao-de-lideres","text":"O problema da escolha de um processo centralizador, ou l\u00edder, pode ser posto informalmente como o procedimento pelo qual um processo \u00e9 escolhido dentre os demais processos, sendo que o processo escolhido \u00e9 ciente da escolha e todos os demais processos o identificam como eleito . Uma nova elei\u00e7\u00e3o deve acontecer sempre que o l\u00edder se tornar indispon\u00edvel . Formalmente, um algoritmo de elei\u00e7\u00e3o de l\u00edderes deve satisfazer as seguintes condi\u00e7\u00f5es. Elei\u00e7\u00e3o de L\u00edderes 2 Termina\u00e7\u00e3o: algum processo deve se considerar l\u00edder em algum momento. Unicidade: somente um processo se considera l\u00edder. Acordo: todos os outros processos sabem quem foi eleito l\u00edder. Para entendermos melhor o problema, tentemos desenvolver um protocolo simples para escolhermos um l\u00edder, por exemplo, em sua turma da disciplina de Sistemas Distribu\u00eddos. Vejamos algumas quest\u00f5es importantes. Candidatos: todos os membros s\u00e3o eleg\u00edveis ou apenas um subconjunto dos mesmos? Comunica\u00e7\u00e3o: todos se conhecem e se falam diretamente ou h\u00e1 grupos incomunic\u00e1veis dentro da turma? Estabilidade: de que adianta eleger um dos colegas se frequentemente n\u00e3o est\u00e1 presente quando necess\u00e1rio? Em termos computacionais, estas quest\u00f5es s\u00e3o relevantes pois todos os processos n\u00e3o nascem iguais; alguns residem em m\u00e1quinas com mais mem\u00f3ria, mais poder de processamento, melhor conex\u00e3o com o resto do mundo ou maior grau de conectividade. Talvez este processo seja um l\u00edder mais \u00fatil que os demais. Al\u00e9m disso, se o processo est\u00e1 frequentemente desconectado, mesmo que bem servido de recursos, n\u00e3o ser\u00e1 um bom l\u00edder. Ainda que assumamos um conjunto de processos indiferenci\u00e1veis entre si, com acesso equivalente a recursos e que estejam sempre dispon\u00edveis, ou exatamente por isso, temos um problem mais fundamental para resolver: para eleger um l\u00edder, precisamos diferenciar processos . Dentro de uma \u00fanica m\u00e1quina, identificamos processos facilmente usando seu PID , ou process id , um inteiro associado a cada processo instanciado pelo sistema operacional; o PID \u00e9 v\u00e1lido enquanto o processo estiver executando e pode ser reciclado uma vez que o processo para de executar, o que pode ser um problema. Al\u00e9m disso, se o host \u00e9 reiniciado, os PID tamb\u00e9m s\u00e3o, e portanto esta identifica\u00e7\u00e3o n\u00e3o \u00e9 duradoura. Mais importante, o PID s\u00f3 faz sentido dentro de uma \u00fanica m\u00e1quina e n\u00e3o em um sistema distribu\u00eddo. Se apenas uma inst\u00e2ncia do processo executa em um mesmo host , ent\u00e3o o identificador do host (e.g., endere\u00e7o IP) em si \u00e9 suficiente e, de fato, comumente utilizado. Se mais de um processo executa no mesmo host , ent\u00e3o cabe ao desenvolvedor criar um esquema que permita diferenciar os processos, e n\u00e3o precisa ser nada complicado; pode ser apenas um par\u00e2metro passado na inicializa\u00e7\u00e3o do processo ou a combina\u00e7\u00e3o IP/porta . Assumindo que um esquema de nomea\u00e7\u00e3o est\u00e1 dispon\u00edvel e que todos os processos se conhecem, voltemos ao problema de eleger um l\u00edder para sua turma. Uma abordagem que pode funcionar \u00e9 colocar todos os candidatos para brigar e quem sobrar em p\u00e9 no final, \u00e9 o novo l\u00edder. A despeito desta op\u00e7\u00e3o gerar um l\u00edder n\u00e3o muito popular, o algoritmo do brig\u00e3o \u00e9 um cl\u00e1ssico.","title":"Elei\u00e7\u00e3o de L\u00edderes"},{"location":"coord/coord/#algoritmo-do-brigao-bully","text":"No algoritmo do brig\u00e3o, alguma caracter\u00edstica compar\u00e1vel dos processos \u00e9 escolhida e aquele processo funcional com o valor de tal caracter\u00edstica mais vantajoso para um l\u00edder \u00e9 escolhido como tal. Por exemplo, pode ser vantajoso ter um l\u00edder com maior quantidade de mem\u00f3ria, frequ\u00eancia da CPU ou largura de banda da conex\u00e3o com a Internet; no caso de empate, o identificador do processo pode ser usado para gerar uma ordem total entre os processos. Para simplificar, vamos assumir que o identificador do processo reflete as qualidades do mesmo para a lideran\u00e7a, tal que o processo com maior identificador seja o melhor candidato. Os maiores processos, os \"brig\u00f5es\", eliminam os processos menores da competi\u00e7\u00e3o, sempre que uma elei\u00e7\u00e3o acontecer. O algoritmo \u00e9 apresentado a seguir, onde \\(p\\) e \\(q\\) s\u00e3o usados para representar tanto identificadores de processos quando os processos em si. Algoritmo do Brig\u00e3o Quando \\(p\\) suspeita que o l\u00edder n\u00e3o est\u00e1 presente (muito tempo se receber mensagens do mesmo) \\(p\\) envia mensagem (ELEICAO, \\(p\\) ) para todos os processos com identificador maior que \\(p\\) Inicia temporizador de respostas Quando temporizador de respostas expira Envia (COORD, \\(p\\) ) para todos os processos Quando recebe (Ok, \\(p\\) ) Para temporizador de resposta Quando \\(p\\) recebe (ELEICAO, \\(q\\) ), \\(q < p\\) Envia (OK, \\(q\\) ) Quando um processo falho se recupera Inicia uma elei\u00e7\u00e3o Observe como o algoritmo foi descrito em termos de eventos e n\u00e3o de forma sequencial. Este tipo de especifica\u00e7\u00e3o \u00e9 comum para algoritmos paralelos e distribu\u00eddos, pois n\u00e3o h\u00e1 uma sequ\u00eancia pr\u00e9-estabelecida de passos a serem executados por todos os processos, apenas alguns pontos de coordena\u00e7\u00e3o. No exemplo a seguir, temos 5 processos, com identificadores de 1 a 5, passando por 7 passos at\u00e9 que a elei\u00e7\u00e3o se complete. Observe que os processos n\u00e3o sabem a priori como os eventos aconteceram e apenas reagem aos eventos de recep\u00e7\u00e3o de mensagens e expira\u00e7\u00e3o de temporizadores . o l\u00edder j\u00e1 \u00e9 o processo 5 (em rosa). os processos 2 e 3 (amarelo) se \"cansaram\" de esperar por 5, que falhou (em cinza, e se candidataram a l\u00edder, enviando (ELEICAO,2) e (ELEICAO,3), respectivamente, (verde). 4 responde a 2 a 3 com (OK,2) e (OK,3) como resposta a 2 e 3, respectivamente, e 3 envia (OK,2) para 2. 1 se candidata com enviando (ELEICAO,1). 2, 3 e 4 respondem com (OK,1). 4 se candidata enviando (ELEICAO,4) para 5, que n\u00e3o responde, j\u00e1 que est\u00e1 falho. 4 se declara l\u00edder e envia (COORD,4) a todos os processos. Como j\u00e1 discutido antes, a escolha do valor temporizador \u00e9 fundamental para o bom funcionamento do algoritmo. Se o temporizador usado pelos processos para esperar pelo l\u00edder for ajustado de forma agressiva, frequentemente ser\u00e3o iniciadas elei\u00e7\u00f5es mesmo que o l\u00edder n\u00e3o tenha falhado. J\u00e1 se o valor do temporizador for muito grande, o sistema demorar\u00e1 a eleger um novo l\u00edder . Da mesma forma, se o tempo esperado por um candidato antes de se declarar l\u00edder for muito curto, mais de um processo pode se declarar l\u00edder , uma situa\u00e7\u00e3o conhecida como split-brain . Idealmente, um processo deveria esperar por outro enquanto o outro estiver apto a responder, mas isso requer saber quando o outro processo n\u00e3o est\u00e1 mais apto, isto \u00e9, falhou. Como identificar exatamente quando isso aconteceu \u00e9 imposs\u00edvel em sistemas distribu\u00eddos ass\u00edncronos, o algoritmo do brig\u00e3o n\u00e3o resolve o problema neste ambiente. Mas se delimitarmos melhor o ambiente, podemos chegar a solu\u00e7\u00f5es melhores.","title":"Algoritmo do Brig\u00e3o (Bully)"},{"location":"coord/coord/#algoritmos-em-aneis","text":"Consideremos processos organizados em um anel l\u00f3gico em que processos troquem mensagens apenas com processos \u00e0 \"esquerda\" e \u00e0 \"direita\". Considere tamb\u00e9m que todos os processos s\u00e3o exatamente id\u00eanticos, inclusive n\u00e3o possuindo identificadores pr\u00f3prios. Suponha o seguinte algoritmo de elei\u00e7\u00e3o neste anel, em que um processo inicialmente Seguidor se torna Candidato, ent\u00e3o se declara Eleito, avisa a seus pares e, finalmente, se declara Empossado. Algoritmo do Anel 1 Na inicia\u00e7\u00e3o Organize os n\u00f3s em um anel l\u00f3gico \\(C \\gets\\) Seguidor Quando um processo acha que o l\u00edder est\u00e1 morto \\(C \\gets\\) Candidato Envia (VoteEmMim) para \"a direita\" no anel. Quando um processo recebe (VoteEmMim) Se \\(C =\\) Seguidor envia (VoteEmMim) para a direita Se \\(C =\\) Candidato \\(C \\gets\\) Eleito envia (HabemosLeader) para a direita Quando um processo recebe (HabemosLeader) Se \\(C =\\) Seguidor envia (HabemosLeader) para a direita Se \\(C =\\) Eleito \\(C \\gets\\) Empossado Imagine um cen\u00e1rio com dois processos, como na imagem a seguir. Os nomes dos processos s\u00e3o apenas para facilitar o entendimento do fluxo de mensagens e n\u00e3o est\u00e3o acess\u00edveis aos processos. Executando o algoritmo Anel 1, os processos enviam ( \\(\\rightarrow\\) ) e recebem ( \\(\\leftarrow\\) ) as seguintes mensagens e ajustam \\(C\\) da seguinte forma. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado Agora imagine que por um acaso, tanto processo 1 quanto o 2 se candidatassem ao mesmo tempo. 1 2 \\(C \\gets\\) Seguidor \\(C \\gets\\) Seguidor \\(C \\gets\\) Candidato \\(C \\gets\\) Candidato (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\rightarrow\\) (VoteEmMim) \\(\\leftarrow\\) (VoteEmMim) \\(\\leftarrow\\) \\(C \\gets\\) Eleito \\(C \\gets\\) Eleito (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\rightarrow\\) (HabemosLider) \\(\\leftarrow\\) (HabemosLider) \\(\\leftarrow\\) \\(C \\gets\\) Empossado \\(C \\gets\\) Empossado Como n\u00e3o h\u00e1 nada que diferencie os processos entre si, este cen\u00e1rio \u00e9 perfeitamente v\u00e1lido, e se no primeiro cen\u00e1rio o algoritmo estava correto ao eleger o processo 1, ent\u00e3o no segundo cen\u00e1rio o 1 tamb\u00e9m deve ser eleito, j\u00e1 que a sequ\u00eancia de evento observadas \u00e9 exatamente a mesma. Mas o processo 2 tamb\u00e9m v\u00ea a mesma sequ\u00eancia, ent\u00e3o tamb\u00e9m deve ser eleito. Assim, violamos a propriedade da Unicidade. Para quebrar essa simetria entre os processo, podemos permitir que saibam seus identificadores. No algoritmo seguinte, permitimos que os processos conhe\u00e7am seus identificadores e um processo que suspeite do l\u00edder atual, envia uma mensagem no anel para coletar os identificadores de todos os processos. Algoritmo do Anel 2 Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem [ \\(p\\) ] \"\u00e0 direita\". Quando \\(p\\) recebe \\(l\\) Se \\(p \\not \\in l\\) Envia \\([p:l]\\) para a direita. Se \\(p \\in l\\) Escolhe menor id em \\(l\\) como l\u00edder. Este algoritmo envia at\u00e9 \\(n^2\\) mensagens, se todos iniciarem a elei\u00e7\u00e3o ao mesmo tempo, e as mensagens crescem at\u00e9 o tamanho \\(n\\) . O algoritmo de Chang e Robert 3 limita o tamanho das mensagens ao pr\u00e9-selecionar candidatos vi\u00e1veis. Algoritmo de Chang e Robert Organize os n\u00f3s em um anel l\u00f3gico Quando \\(p\\) acha que o l\u00edder est\u00e1 morto: Envia mensagem \\((p)\\) \u00e0 direita Quando \\(p\\) recebe \\((q)\\) Se \\(p = q\\) \\(p\\) se declara l\u00edder Sen\u00e3o e se \\(q > p\\) Envia \\((q)\\) para a direita. Neste algoritmo, todas as mensagens tem tamanho \\(O(1)\\) e somente uma mensagem d\u00e1 uma volta completa do anel; todas as outras s\u00e3o descartadas no meio do caminho. Apesar disso, pode-se demonstrar que o pior caso em termos de n\u00famero de mensagens do algoritmo at\u00e9 que algu\u00e9m se declare l\u00edder \u00e9 \\(O(n^2)\\) . Exerc\u00edcio: Quantidade de mensagens O pior caso em termos de n\u00famero de mensagens at\u00e9 que algu\u00e9m seja eleito \u00e9 \\(O(n^2)\\) . Descreva como os n\u00f3s devem estar organizados para que esta situa\u00e7\u00e3o ocorra. Observe que no algoritmo um processo apenas se \"declara l\u00edder\", mas os outros n\u00e3o necessariamente ficam sabendo disso. Como voc\u00ea o corrigiria para que terminasse? Diversos outros algoritmos existem para a topologia em anel. O algoritmo de Franklin \u00e9 um dos que prop\u00f5e melhorias para reduzir quantidade de mensagens usadas na elei\u00e7\u00e3o. Ele faz isso em rodadas, comparando identificadores com outros processos ativos tanto \u00e0 esquerda quanto \u00e0 direita e desativando os processos n\u00e3o vi\u00e1veis. Algoritmo de Franklin Organize os n\u00f3s em um anel l\u00f3gico Ativo \\(\\gets 1\\) Quando \\(p\\) acha que o l\u00edder est\u00e1 morto e se Ativo $ = 1$ : Envia mensagem \\((p)\\) \u00e0 direita e \u00e0 esquerda Quando \\(p\\) recebe \\(e\\) e \\(d\\) , da esquerda e da direita, respectivamente: Se Ativo \\(=1\\) Se \\(max(e,d) < p\\) Envia mensagem \\((p)\\) \u00e0 direita e \u00e0 esquerda Se \\(max(e,d) > p\\) Ativo \\(\\gets 0\\) Envia mensagem \\(-p\\) \u00e0 direita e \u00e0 esquerda Se \\(max(e,d) = p\\) \\(p\\) se declara l\u00edder. Se Ativo \\(=0\\) Repassa cada mensagem para o outro lado. No exemplo na figura, os n\u00f3s brancos s\u00e3o ativos e os amarelos inativos. Observe o papel do n\u00f3 no centro, supondo que tem o maior identificador entre todos os processos. Inicialmente ele envia as mensagens em verde para os lados, que levam seus vizinhos imediatos a se inativarem. Na segunda rodada, as mensagens s\u00e3o repassadas para os vizinhos dos vizinhos, que tamb\u00e9m se inativam. Observe o seguinte: Em cada fase, para qualquer par de vizinhos ativos, pelos um dos dois \u00e9 inativado e, portanto, o n\u00famero de ativos cai pela metade; logo h\u00e1 no m\u00e1ximo \\(O(log n)\\) fases. Na primeira fase, cada processo ativo leva a \\(4\\) mensagens serem enviadas na rede (sem nenhuma otimiza\u00e7\u00e3o). Dado que s\u00e3o \\(n\\) processos, temos \\(4n\\) mensagens, \\(O(n)\\) Na segunda fase, cada processo ativo leva a 8 mensagens. Contudo, metade dos processos, pelo menos, foram inativados na primeira fase. Logo, temos \\(8n \\times n/2, O(n)\\) Assim, no m\u00e1ximo \\(O(n log n)\\) mensagens s\u00e3o enviadas em uma execu\u00e7\u00e3o do algoritmo.","title":"Algoritmos em An\u00e9is"},{"location":"coord/coord/#algoritmo-do-yoyo","text":"Saindo da topologia em anel, vejamos o algoritmo do Yoyo, que funciona em qualquer topologia conexa, mesmo se processos n\u00e3o puderem se falar diretamente. Inicialmente as arestas do formado pelos processos e seus canais de comunica\u00e7\u00e3o s\u00e3o n\u00e3o direcionadas, mas na medida em que o protocolo \u00e9 executado, as arestas s\u00e3o marcadas como tendo um ou outro sentido. Esta marca\u00e7\u00e3o \u00e9 apenas l\u00f3gica e mensagens fluem em ambos os sentidos. De acordo com o tipo de arestas que um processo tem, ele \u00e9 classificado como um de tr\u00eas tipos: Fonte (source) - processo que s\u00f3 tem arestas de sa\u00edda Vertedouro (sink) - processo que s\u00f3 tem arestas de chegada Interno - processo que tem arestas de chegada e de sa\u00edda O algoritmo executa em duas fases. Na primeira, cada processo marca sua arestas como apontando para o maior dentre si pr\u00f3prio e seus vizinhos. Na segunda fase, mensagens \"v\u00e3o e voltam\", o que d\u00e1 o nome ao algoritmo. Na \"ida\", as mensagens v\u00e3o das fontes para os vertedouros, que identificam quais fontes tem os menores identificadores e sinalizam para que continuem fontes na pr\u00f3xima etapa com mensagens de volta. As mensagens de volta reordenam as arestas para garantir este comportamento. Vejamos o algoritmo em mais detalhes. Algoritmo do YoYo Fase 1 \\(p\\) envia seu identificador para seus vizinhos. Quando \\(p\\) recebe \\(q\\) Se \\(p>q\\) Marca a aresta em que recebeu \\(q\\) como sendo de chegada ( \\(p\\leftarrow q\\) ) Sen\u00e3o Marca a aresta em que recebeu \\(q\\) como sendo de sa\u00edda ( \\(q\\leftarrow p\\) ) Fase 2 Se \\(p\\) \u00e9 uma fonte \\(p\\) envia seu identificador em todas as suas arestas de sa\u00edda. Quando \\(p\\) receber \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda Se recebeu apenas \\(S\\) Executa fase 2 novamente Se \\(p\\) \u00e9 um n\u00f3 interno Quando \\(p\\) receber identificadores em todas as suas arestas de entrada escolhe o menor id recebido \\(m\\) envia \\(m\\) em todas as suas arestas de sa\u00edda Quando \\(p\\) recebeu \\(S\\) ou \\(N\\) em todas as suas arestas de sa\u00edda Se recebeu algum \\(S\\) envia \\(S\\) para vizinhos de onde recebeu \\(m\\) envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) Se n\u00e3o recebeu \\(S\\) envia \\(N\\) para vizinhos de onde recebeu algum id. Se \\(p\\) \u00e9 um vertedouro Quando \\(p\\) receber identificadores em todas as suas arestas de entrada escolhe o menor id recebido \\(m\\) envia \\(S\\) para vizinhos de onde recebeu \\(m\\) envia \\(N\\) para vizinhos de onde recebeu \\(m' \\neq m\\) N inverte a dire\u00e7\u00e3o das arestas em que trafega. Fonte Veja um exemplo com 3 processos em destaque, uma fonte, um interno e um vertedouro. Veja o seguinte exemplo, em que cada figura mostra um est\u00e1gio da resolu\u00e7\u00e3o do problema de elei\u00e7\u00e3o de l\u00edderes. a) A rede em seu estado inicial. b) Rede orientada pela primera fase c) Propaga\u00e7\u00e3o de Fontes d) Propaga\u00e7\u00e3o de Vertedouros e) Inativa\u00e7\u00e3o dos vertedouros Exemplo: Embora interessante, este algoritmo tamb\u00e9m tem problemas, sendo um dos mais cr\u00edticos a forma de lidar com falhas, mesmo sem considerar falhas de processos. Suponha que o canal de comunica\u00e7\u00e3o entre os processos 2 e 10 pare de funcionar. O que acontecer\u00e1? Esta \u00e9 uma situa\u00e7\u00e3o que denominamos particionamento da rede e que neste caso levar\u00e1 a duas elei\u00e7\u00f5es concorrentes acontecerem e, consequentemente, a dois l\u00edderes sendo eleitos, o que \u00e9 conhecido na \u00e1rea como split-brain . Vejamos esta e outras situa\u00e7\u00f5es problem\u00e1ticas em elei\u00e7\u00e3o de l\u00edderes.","title":"Algoritmo do YoYo"},{"location":"coord/coord/#questoes-importantes","text":"","title":"Quest\u00f5es importantes"},{"location":"coord/coord/#split-brain","text":"Se o algoritmo viola a propriedade de unicidade, ent\u00e3o fica com split-brain , em que parte da rede v\u00ea um processo como l\u00edder e parte v\u00ea outro. Se o l\u00edder \u00e9 o respons\u00e1vel por coordenar o acesso a uma regi\u00e3o cr\u00edtica, como visto no algoritmo coordenado de exclus\u00e3o m\u00fatua, ent\u00e3o ter dois l\u00edderes poder\u00e1 levar a dois processos na regi\u00e3o cr\u00edtica e portanto viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua. Uma das formas de evitar split-brain \u00e9 atribuir um \"peso\" para cada processo e s\u00f3 aceitar que um l\u00edder seja declarado se o mesmo seus votos carregarem mais da metade do peso do sistema. Ainda assim, temos problemas, pois \u00e9 necess\u00e1rio que rodadas sucessivas do algoritmo invalidem as elei\u00e7\u00f5es anteriores. O algoritmo Raft de difus\u00e3o at\u00f4mica, que estudaremos adiante, define mandatos e garante, com pesos, que somente um l\u00edder existe em cada mandato. Devido \u00e0 natureza ass\u00edncrona do sistema, processos podem se achar em mandatos distintos e, por isso, o mandato \u00e9 associado a todas as comunica\u00e7\u00f5es; mensagens recebidas de mandatos anteriores s\u00e3o sumariamente descartadas. Mas por qu\u00ea precisamos de mandatos sucessivos? Para substituir um l\u00edder que tenha falhado. O que nos leva a outros dois problemas, o da detec\u00e7\u00e3o de falhas e o da estabilidade do l\u00edder.","title":"Split-brain"},{"location":"coord/coord/#estabilidade","text":"Dizemos que um algoritmo de elei\u00e7\u00e3o de l\u00edderes \u00e9 est\u00e1vel se uma vez que um l\u00edder \u00e9 eleito, uma nova elei\u00e7\u00e3o s\u00f3 acontece se o l\u00edder falha. Considere o algoritmo do brig\u00e3o. Imagine, no exemplo apresentado, que o processo 5 teve problemas de comunica\u00e7\u00e3o e foi percebido como falho pelos demais. Neste caso, o 4 seria eleito l\u00edder. Mas se o problema que aflige 5 \u00e9 tempor\u00e1rio, 5 voltar\u00e1 e executar\u00e1 nova elei\u00e7\u00e3o, tornando-se l\u00edder novamente. Se este cen\u00e1rio se repente indefinidamente, o sistema poder\u00e1 ser seriamente comprometido em seu desempenho. Uma vers\u00e3o est\u00e1vel do algoritmo tentaria, por exemplo, associar ao peso do processo o tempo de execu\u00e7\u00e3o ininterrupta do mesmo. Assim, quanto mais tempo um processo execute, maior ser\u00e1 seu peso e sua capacidade de manter a lideran\u00e7a. Se o mesmo falhar, ent\u00e3o seu peso ser\u00e1 drasticamente reduzido e suas chances de ser eleito l\u00edder reduzidas temporariamente. Observe que os problemas enfrentados s\u00e3o ligados \u00e0 detec\u00e7\u00e3o e contorno de falhas.","title":"Estabilidade"},{"location":"coord/coord/#deteccao-de-falhas","text":"Como j\u00e1 mencionado antes, detec\u00e7\u00e3o de falhas \u00e9 o mecanismo pelo qual um processo monitora e percebe se outro falhou. Pensemos em como um processo monitora o outro em um sistema distribu\u00eddo. Claramente, por meio de troca de mensagens e temporizadores. Mas se estamos falando de sistemas distribu\u00eddos ass\u00edncronos, ent\u00e3o mensagens podem ser atrasadas indefinidamente ou rel\u00f3gios podem ser atrasados, ent\u00e3o n\u00e3o se pode confiar na falta de recep\u00e7\u00e3o de uma mensagem como garantia de que um processo parou de funcionar. Aprofundemo-nos nos pr\u00f3ximos cap\u00edtulo nos conceitos de tempo e toler\u00e2ncia a falhas, mas enquanto isso, fiquemos com o seguinte resultado. Detec\u00e7\u00e3o de falhas Detec\u00e7\u00e3o de falhas perfeita \u00e9 imposs\u00edvel... em sistemas distribu\u00eddos ass\u00edncronos (Internet) sujeitos \u00e0 parti\u00e7\u00f5es (Internet) com requisitos de disponibilidade total. para evitar que mensagens de requisi\u00e7\u00f5es distintas do mesmo processo se confundam, \u00e9 \u00fatil identificar cada requisi\u00e7\u00e3o, por exemplo, com um contador de requisi\u00e7\u00f5es. \u21a9 A Probabilistically Correct Leader Election Protocol for Large Groups \u21a9 An improved algorithm for decentralized extrema-finding in circular configurations of processes . \u21a9","title":"Detec\u00e7\u00e3o de falhas"},{"location":"fault/","text":"Toler\u00e2ncia a Faltas Sistemas distribu\u00eddos s\u00e3o usados para resolver problemas de um espectro muito amplo, indo do controle de bra\u00e7os rob\u00f3ticos em cirurgias remotas \u00e0 sistemas de com\u00e9rcio eletr\u00f4nico, do controle de usinas hidroel\u00e9tricas \u00e0 jogos de truco online. Cada um destes servi\u00e7os tem seus pr\u00f3prios requisitos de qualidade de servi\u00e7o, isto \u00e9, enquanto voc\u00ea perder uma partida de truco porqu\u00ea a conex\u00e3o caiu pode ter deixar chateado, certamente h\u00e1 de convir que perder a conex\u00e3o com um rob\u00f4 segurando um bisturi sobre uma pessoa \u00e9 algo bem mais grave. Independentemente do problema, um dos objetivos no desenvolvimento \u00e9 ter o sistema funcional quando precisarmos dele, mesmo quando fontes queimem, discos deixem de girar, fontes parem de alimentar, coolers parem de refrigerar, administradores parem de manter o sistema, hackers fa\u00e7am o que fazem, fibras sejam rompidas, sat\u00e9lites saiam de \u00f3rbita, funcion\u00e1rios demitidos se revoltem, etc. A lista de problemas que podem afligir sistemas \u00e9 t\u00e3o grande, que h\u00e1 uma \u00e1rea da computa\u00e7\u00e3o (e n\u00e3o somente da computa\u00e7\u00e3o) dedicada somente a lidar com estes problemas, a \u00e1rea de toler\u00e2ncia a faltas. 1 Ou falhas, dependendo de a quem voc\u00ea perguntar. \u21a9","title":"Introdu\u00e7\u00e3o"},{"location":"fault/#tolerancia-a-faltas","text":"Sistemas distribu\u00eddos s\u00e3o usados para resolver problemas de um espectro muito amplo, indo do controle de bra\u00e7os rob\u00f3ticos em cirurgias remotas \u00e0 sistemas de com\u00e9rcio eletr\u00f4nico, do controle de usinas hidroel\u00e9tricas \u00e0 jogos de truco online. Cada um destes servi\u00e7os tem seus pr\u00f3prios requisitos de qualidade de servi\u00e7o, isto \u00e9, enquanto voc\u00ea perder uma partida de truco porqu\u00ea a conex\u00e3o caiu pode ter deixar chateado, certamente h\u00e1 de convir que perder a conex\u00e3o com um rob\u00f4 segurando um bisturi sobre uma pessoa \u00e9 algo bem mais grave. Independentemente do problema, um dos objetivos no desenvolvimento \u00e9 ter o sistema funcional quando precisarmos dele, mesmo quando fontes queimem, discos deixem de girar, fontes parem de alimentar, coolers parem de refrigerar, administradores parem de manter o sistema, hackers fa\u00e7am o que fazem, fibras sejam rompidas, sat\u00e9lites saiam de \u00f3rbita, funcion\u00e1rios demitidos se revoltem, etc. A lista de problemas que podem afligir sistemas \u00e9 t\u00e3o grande, que h\u00e1 uma \u00e1rea da computa\u00e7\u00e3o (e n\u00e3o somente da computa\u00e7\u00e3o) dedicada somente a lidar com estes problemas, a \u00e1rea de toler\u00e2ncia a faltas. 1 Ou falhas, dependendo de a quem voc\u00ea perguntar. \u21a9","title":"Toler\u00e2ncia a Faltas"},{"location":"fault/agreement/","text":"Acordo H\u00e1 diversas primitivas de comunica\u00e7\u00e3o em grupo, das quais se destaca a difus\u00e3o at\u00f4mica , primitiva pela qual se pode facilmente implementar replica\u00e7\u00e3o de m\u00e1quina de estados. Difus\u00e3o at\u00f4mica, por sua vez, \u00e9 equivalente ao problema do consenso distribu\u00eddo , que est\u00e1 no cora\u00e7\u00e3o da classe de problemas de acordo . Problemas de acordo s\u00e3o aqueles em que processos devem concordar em alguma coisa, por exemplo, quais a\u00e7\u00f5es executar, quais processos considerar parte do sistema, quais transa\u00e7\u00f5es honrar. Dependendo do modelo computacional em que o problema deve ser resolvido, solu\u00e7\u00f5es v\u00e3o de triviais a imposs\u00edveis. Consenso O problema que os comandantes est\u00e3o tentando resolver \u00e9, essencialmente, o problema do Consenso Distribu\u00eddo. Neste problema, cada um de um conjunto de processos prop\u00f5e um \u00fanico valor, sua proposta . O objetivo \u00e9 decidir um dentre os valores propostos, garantindo as seguintes propriedades. Validade: Somente um valor proposto pode ser decidido. Acordo: Se um processo decide-se por \\(v\\) e outro por \\(w\\) , ent\u00e3o \\(v = w\\) Termina\u00e7\u00e3o: Todo processo n\u00e3o defeituoso decide-se. Um processo \u00e9 defeituoso se apresentou um defeito; como estamos considerando apenas defeitos do tipo quebra, um processo \u00e9 defeituoso se ele parou de funcionar. Um processo que n\u00e3o \u00e9 defeituoso \u00e9 um processo correto. Termina\u00e7\u00e3o Na pr\u00e1tica, algoritmos exploram oportunidades para progredir, mesmo que n\u00e3o garantam que v\u00e3o terminar. Dependendo do modelo computacional, \u00e9 poss\u00edvel resolver este problema. Contudo, \u00e9 imposs\u00edvel resolver deterministicamente o problema do consenso em sistema ass\u00edncrono sujeito a falhas , 1 e ass\u00edncrono sujeito a falhas \u00e9 exatamente o que temos, a rigor, na Internet. Mas o consenso \u00e9 resolvido frequentemente em sistemas ass\u00edncronos sujeitos a falhas. Isso porque normalmente estes sistemas se comportam sincronamente. H\u00e1 diversos algoritmos de consenso que terminam quando o sistema se comporta bem, sendo os mais famosos, atualmente, Raft e Paxos A grande raz\u00e3o para que seja imposs\u00edvel chegar a um acordo entre processos neste modelo \u00e9 a impossibilidade de diferenciar processos defeituosos de processos corretos, mas lentos. Em termos do paradoxo dos 2 generais, a resposta do comandante n\u00e3o chegou porqu\u00ea ele morreu ou porqu\u00ea ele est\u00e1 demorando para responder? Os detectores de defeito abstraem este problema. Detectores de Defeitos n\u00e3o Confi\u00e1veis Chandra e Toueg 2 introduziram o conceito de Detectores de Defeitos como forma de encapsular a percep\u00e7\u00e3o do estado funcional dos outros processos. Assim, um detector de defeitos pode ser visto como or\u00e1culo distribu\u00eddo , com m\u00f3dulos acoplados aos processos do sistema e que trabalha monitorando os outros processos. Chandra e Toueg classificaram os detectores de defeitos segundo suas caracter\u00edsticas de completude ( completeness ) e acur\u00e1cia ( accuracy ), ou seja, a capacidade de suspeitar de um processo defeituoso e a capacidade de n\u00e3o suspeitar de um processo correto, respectivamente. Embora n\u00e3o seja obrigat\u00f3rio, detectores de falhas s\u00e3o normalmente implementados por meio de trocas de mensagens de heartbeat . Mensagens s\u00e3o esperadas em momentos espec\u00edficos para sugerir que o remetente continua funcional. Quando os heartbeats n\u00e3o chegam at\u00e9 o limite de tempo, o processo remetente passa a ser considerado suspeito de falha. Heartbeats que chegam depois podem corrigir erros, mas tamb\u00e9m podem levar a atrasos na detec\u00e7\u00e3o de defeitos. Para capturar estas combina\u00e7\u00f5es de eventos, foram definidos os seguintes n\u00edveis de Os n\u00edveis destas propriedades s\u00e3o os seguintes: Completude Forte - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por todos os processos corretos. Completude Fraca - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por algum processo correto. Precis\u00e3o Forte - Todos os processos s\u00e3o suspeitos somente ap\u00f3s terem apresentado defeito. Precis\u00e3o Fraca - Algum processo correto nunca \u00e9 suspeito de ter apresentado defeito. Precis\u00e3o Eventual Forte - A partir de algum instante futuro, todos os processos s\u00e3o suspeitos somente ap\u00f3s apresentarem defeito. Precis\u00e3o Eventual Fraca - A partir de algum instante futuro, algum processo ativo nunca \u00e9 suspeito antes de ter apresentado defeito. Um detector ideal seria um com Completude Forte e Precis\u00e3o Forte, pois detectaria somente processos defeituosos e todos os processos defeituosos. Este detector \u00e9 conhecido como \\(P\\) ou Perfect . Infelizmente os detectores perfeitos s\u00f3 podem ser implementados em sistemas s\u00edncronos, onde se pode confiar que a falta de uma mensagem implica em que a mensagem n\u00e3o ser\u00e1 entregue por qu\u00ea o remetente deve ser defeituosos. Assim, \u00e9 preciso se focar em detectores n\u00e3o perfeitos ou n\u00e3o confi\u00e1veis . Em ambientes parcialmente s\u00edncronos , ou seja, ass\u00edncronos aumentados com algum tipo de sincronia, j\u00e1 \u00e9 poss\u00edvel implementar detectores n\u00e3o confi\u00e1veis. Por exemplo, se os processos disp\u00f5em de temporizadores precisos, um detector pode contar a passagem do tempo nos intervalos de comunica\u00e7\u00e3o com outros processos e, considerando um limite de tempo para estes intervalos, tentar determinar se tais processos encontram-se defeituosos ou n\u00e3o. Esta determina\u00e7\u00e3o \u00e9 por certo imprecisa e os detectores podem voltar atr\u00e1s em suas suspeitas t\u00e3o logo percebam um erro. Entretanto, a despeito desta incerteza, a informa\u00e7\u00e3o provida por estes detectores j\u00e1 pode ser suficiente para que se alcance o consenso se combinada a uma restri\u00e7\u00e3o de que uma maioria dos processos n\u00e3o seja defeituosa . Maioria Adicionar prova. Chandra, Hadzilacos e Toueg demonstram que o detector mais fraco com o qual se pode resolver consenso tem as propriedades de Completude Fraca e Acur\u00e1cia Eventual Fraca. 3 Este detector, conhecido como \\(\\Diamond W\\) , ou Eventual Weak , e \u00e9 implement\u00e1vel em sistemas nos quais h\u00e1 um limite superior de tempo para a transmiss\u00e3o de mensagens, mesmo que este limite seja desconhecido . V\u00e1rios protocolos de consenso utilizam o detector equivalente, \\(\\Diamond S\\) , equivalente ao \\(\\Diamond W\\) mas com completude forte, ou o eleitor de l\u00edderes \\(\\Omega\\) , que usa a informa\u00e7\u00e3o do \\(\\Diamond S\\) para sugerir um l\u00edder entre os processos. Estes protocolos s\u00e3o escritos de forma que se o limite superior n\u00e3o existe, o protocolo n\u00e3o termina e um resultado errado nunca \u00e9 alcan\u00e7ado , ou seja, os protocolos sempre garantem que as propriedades de corretude n\u00e3o s\u00e3o violadas, mesmo que n\u00e3o garanta que a termina\u00e7\u00e3o ser\u00e1 alcan\u00e7ada. Figura figura 2.2 da disserta\u00e7\u00e3o. SWIM https://www.youtube.com/watch?v=0bAJ4iNnf5M Paxos: Algoritmo do S\u00ednodo Algoritmo Descrever. Por enquanto, vejam esta explica\u00e7\u00e3o ou [ https://www.cs.rutgers.edu/~pxk/417/notes/paxos.html ] ou este v\u00eddeo [ https://www.youtube.com/watch?v=JEpsBg0AO6o ] ou este video [ https://www.youtube.com/watch?v=s8JqcZtvnsM ]. Difus\u00e3o Totalmente Ordenada Se pudermos resolver o consenso, podemos ent\u00e3o resolver o problema da difus\u00e3o totalmente ordenada ( total order multicast ) e com ela implementar a replica\u00e7\u00e3o de m\u00e1quinas de estados. Relembrando, na temos que: Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem. Para fazermos isso, precisamos primeiro formalizar as primitivas em v\u00e1rios n\u00edveis da resolu\u00e7\u00e3o do problema. No n\u00edvel do canal de comunica\u00e7\u00e3o, da rede, processos enviam e recebem mensagens. No n\u00edvel do consenso, processos fazem propostas e aprendem um valor decidido. Para chegar a uma \u00fanica decis\u00e3o, v\u00e1rias mensagens podem ser enviadas e recebidas. No n\u00edvel da difus\u00e3o at\u00f4mica, mensagens s\u00e3o difundidas e entregues . Se implementado sobre o consenso, para uma difus\u00e3o ser bem sucedida, uma inst\u00e2ncia de consenso \u00e9 necess\u00e1ria. Primitivas de comunica\u00e7\u00e3o enviar & receber ( send & receive ) - rede propor & decidir ( propose & decide ) - consenso difundir & entregar ( broadcast & deliver ) - difus\u00e3o Dado infinitas inst\u00e2ncias de consenso, pode-se us\u00e1-las para resolver difus\u00e3o at\u00f4mica usando o seguinte procedimento: Ordene as inst\u00e2ncias de consenso. Para difundir mensagem \\(m\\) , proponha a mensagem na menor inst\u00e2ncia \\(i\\) em que n\u00e3o tiver visto uma decis\u00e3o. Se a decis\u00e3o de \\(i\\) n\u00e3o \u00e9 \\(m\\) , volte para o passo anterior. Entregue as decis\u00f5es na ordem das inst\u00e2ncias. No exemplo a seguir, duas mensagens, \\(m\\) e \\(m'\\) foram difundidas pelas aplica\u00e7\u00f5es App1 e App2, respectivamente, por meio do m\u00f3dulo de difus\u00e3o at\u00f4mica junto a cada aplica\u00e7\u00e3o. O m\u00f3dulo de difus\u00e3o determina qual a menor inst\u00e2ncia de consenso ainda n\u00e3o decidida, azul, em que prop\u00f5em as mensagens. Ao final da inst\u00e2ncia de conseno, \\(m\\) \u00e9 decidida e \u00e9 entregue pelos m\u00f3dulos de difus\u00e3o. O m\u00f3dulo ABCast2 insiste na difus\u00e3o de \\(m'\\) , propondo-a na pr\u00f3xima inst\u00e2ncia, vermelha, que decide \\(m'\\) e leva esta mensagem a ser entregue. sequenceDiagram participant App1 participant ABCast1 participant Consenso participant ABCast2 participant App2 App1 -->>+ ABCast1: difundir m App2 -->>+ ABCast2: difundir m' rect rgb(100,255,255) ABCast1 ->>+ Consenso: propor m na inst 1 ABCast2 ->>+ Consenso: propor m' na inst 1 Consenso ->>- ABCast1: decidir m Consenso ->>- ABCast2: decidir m end ABCast1 -->>- App1: entregar m ABCast2 -->> App2: entregar m rect rgba(255,0,0,.5) ABCast2 ->>+ Consenso: propor m' na inst 2 Consenso ->> ABCast1: decidir m' Consenso ->>- ABCast2: decidir m' end ABCast1 -->> App1: entregar m' ABCast2 -->>- App2: entregar m' Ambas as aplica\u00e7\u00f5es, embora tivessem inten\u00e7\u00f5es diferentes sobre qual deveria ser a pr\u00f3xima mensagem entregue, entregam-nas na mesma ordem, isto \u00e9, primeiro \\(m\\) e depois \\(m'\\) . Se forem usadas como entrada para algum processamento, na ordem em que foram entregues, as aplica\u00e7\u00f5es chegar\u00e3o ao mesmo estado, em algum momento. Paxos: Difus\u00e3o at\u00f4mica Paxos Difus\u00e3o At\u00f4mica Raft: Difus\u00e3o at\u00f4mica Raft \u00e9 um protocolo de difus\u00e3o at\u00f4mica associado a um protocolo de elei\u00e7\u00e3o de l\u00edderes. L\u00edderes s\u00e3o eleitos para mandatos pelo voto de uma maioria de processos, o que garante que nunca existir\u00e3o dois l\u00edderes para um mesmo mandato. Um mandato se estende enquanto o l\u00edder mantiver seus seguidores cientes de sua presen\u00e7a, o que faz pelo envio peri\u00f3dico de heartbeats . Atrasos na comunica\u00e7\u00e3o ou a falha do l\u00edder atual levam a uma suspeita de que o l\u00edder falhou, levando a nova elei\u00e7\u00e3o e novo mandado. A comunica\u00e7\u00e3o necess\u00e1ria para implementar a difus\u00e3o at\u00f4mica acontece em piggyback nos heartbeats . No tutorial The Secret lives of data , podemos ver com mais detalhes como o protocolo funciona. O tutorial, entretanto, foge da nomenclatura padr\u00e3o da \u00e1rea usando log-replication no lugar de difus\u00e3o at\u00f4mica (ou totalmente ordenada). Outras Ordena\u00e7\u00f5es Como colocado diversas vezes, se todos os processos executam a mesma sequ\u00eancia de comandos determin\u00edsticos, todos avan\u00e7am pelos mesmos estados, implementando a t\u00e9cnica da replica\u00e7\u00e3o de m\u00e1quinas de estados. Se usada em um sistema de arquivos, por exemplo, a seguinte sequ\u00eancia de comandos levar\u00e1 sempre ao estado final em que h\u00e1 um arquivo /tmp/file2 e uma pasta denominada /dir1 . touch /tmp/file1 echo \"teste testando\" >> /tmp/file2 rm /tmp/file1 mkdir /dir1 H\u00e1 outras ordens dos mesmos comandos que levariam ao mesmo efeito, como a seguinte. Alguns protocolos de replica\u00e7\u00e3o de m\u00e1quinas de estados permitem que reordena\u00e7\u00f5es ocorram, desde que n\u00e3o afetem o resultado final dos comandos. Contudo, estes protocolos s\u00e3o mais complexos de se implementar e por isso raramente usados. echo \"teste testando\" >> /tmp/file2 mkdir /dir1 touch /tmp/file1 rm /tmp/file1 Arcabou\u00e7os para coordena\u00e7\u00e3o H\u00e1 muitas formas de se usar algoritmos de acordo em uma aplica\u00e7\u00e3o, embora se recomente que seu escopo seja minimizado a um n\u00facleo onde a consist\u00eancia forte \u00e9 absolutamente necess\u00e1ria e que este n\u00facleo seja usado para suportar outras partes do sistema 5 . Seja implementando a replica\u00e7\u00e3o de m\u00e1quinas de estados, seja implementando um core, ou qualquer outra abstra\u00e7\u00e3o sobre algoritmos de acordo ou comunica\u00e7\u00e3o em grupo, voc\u00ea tem a op\u00e7\u00e3o de implementar o protocolo zero, uma tarefa ingrata 4 . Felizmente, tamb\u00e9m tem a op\u00e7\u00e3o de usar arcabou\u00e7os prontos tanto para para comunica\u00e7\u00e3o em grupo quanto para diversos outros problemas de coordena\u00e7\u00e3o comuns em sistemas distribu\u00eddos. Impossibility of Distributed Consensus with One Faulty Process . Uma explica\u00e7\u00e3o da prova est\u00e1 dispon\u00edvel no Paper Trail \u21a9 Unreliable Failure Detectors for Reliable Distributed Systems \u21a9 The Weakest Failure Detector for Solving Consensus \u21a9 Um exemplo de como traduzir um algoritmo complexo para c\u00f3digo pode se ingrato \u00e9 reportado em Paxos Made Live - An Engineering Perspective . \u21a9 Consistent Core \u21a9","title":"Acordo"},{"location":"fault/agreement/#acordo","text":"H\u00e1 diversas primitivas de comunica\u00e7\u00e3o em grupo, das quais se destaca a difus\u00e3o at\u00f4mica , primitiva pela qual se pode facilmente implementar replica\u00e7\u00e3o de m\u00e1quina de estados. Difus\u00e3o at\u00f4mica, por sua vez, \u00e9 equivalente ao problema do consenso distribu\u00eddo , que est\u00e1 no cora\u00e7\u00e3o da classe de problemas de acordo . Problemas de acordo s\u00e3o aqueles em que processos devem concordar em alguma coisa, por exemplo, quais a\u00e7\u00f5es executar, quais processos considerar parte do sistema, quais transa\u00e7\u00f5es honrar. Dependendo do modelo computacional em que o problema deve ser resolvido, solu\u00e7\u00f5es v\u00e3o de triviais a imposs\u00edveis.","title":"Acordo"},{"location":"fault/agreement/#consenso","text":"O problema que os comandantes est\u00e3o tentando resolver \u00e9, essencialmente, o problema do Consenso Distribu\u00eddo. Neste problema, cada um de um conjunto de processos prop\u00f5e um \u00fanico valor, sua proposta . O objetivo \u00e9 decidir um dentre os valores propostos, garantindo as seguintes propriedades. Validade: Somente um valor proposto pode ser decidido. Acordo: Se um processo decide-se por \\(v\\) e outro por \\(w\\) , ent\u00e3o \\(v = w\\) Termina\u00e7\u00e3o: Todo processo n\u00e3o defeituoso decide-se. Um processo \u00e9 defeituoso se apresentou um defeito; como estamos considerando apenas defeitos do tipo quebra, um processo \u00e9 defeituoso se ele parou de funcionar. Um processo que n\u00e3o \u00e9 defeituoso \u00e9 um processo correto. Termina\u00e7\u00e3o Na pr\u00e1tica, algoritmos exploram oportunidades para progredir, mesmo que n\u00e3o garantam que v\u00e3o terminar. Dependendo do modelo computacional, \u00e9 poss\u00edvel resolver este problema. Contudo, \u00e9 imposs\u00edvel resolver deterministicamente o problema do consenso em sistema ass\u00edncrono sujeito a falhas , 1 e ass\u00edncrono sujeito a falhas \u00e9 exatamente o que temos, a rigor, na Internet. Mas o consenso \u00e9 resolvido frequentemente em sistemas ass\u00edncronos sujeitos a falhas. Isso porque normalmente estes sistemas se comportam sincronamente. H\u00e1 diversos algoritmos de consenso que terminam quando o sistema se comporta bem, sendo os mais famosos, atualmente, Raft e Paxos A grande raz\u00e3o para que seja imposs\u00edvel chegar a um acordo entre processos neste modelo \u00e9 a impossibilidade de diferenciar processos defeituosos de processos corretos, mas lentos. Em termos do paradoxo dos 2 generais, a resposta do comandante n\u00e3o chegou porqu\u00ea ele morreu ou porqu\u00ea ele est\u00e1 demorando para responder? Os detectores de defeito abstraem este problema.","title":"Consenso"},{"location":"fault/agreement/#detectores-de-defeitos-nao-confiaveis","text":"Chandra e Toueg 2 introduziram o conceito de Detectores de Defeitos como forma de encapsular a percep\u00e7\u00e3o do estado funcional dos outros processos. Assim, um detector de defeitos pode ser visto como or\u00e1culo distribu\u00eddo , com m\u00f3dulos acoplados aos processos do sistema e que trabalha monitorando os outros processos. Chandra e Toueg classificaram os detectores de defeitos segundo suas caracter\u00edsticas de completude ( completeness ) e acur\u00e1cia ( accuracy ), ou seja, a capacidade de suspeitar de um processo defeituoso e a capacidade de n\u00e3o suspeitar de um processo correto, respectivamente. Embora n\u00e3o seja obrigat\u00f3rio, detectores de falhas s\u00e3o normalmente implementados por meio de trocas de mensagens de heartbeat . Mensagens s\u00e3o esperadas em momentos espec\u00edficos para sugerir que o remetente continua funcional. Quando os heartbeats n\u00e3o chegam at\u00e9 o limite de tempo, o processo remetente passa a ser considerado suspeito de falha. Heartbeats que chegam depois podem corrigir erros, mas tamb\u00e9m podem levar a atrasos na detec\u00e7\u00e3o de defeitos. Para capturar estas combina\u00e7\u00f5es de eventos, foram definidos os seguintes n\u00edveis de Os n\u00edveis destas propriedades s\u00e3o os seguintes: Completude Forte - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por todos os processos corretos. Completude Fraca - A partir de algum instante futuro, todo processo defeituoso \u00e9 suspeito permanentemente por algum processo correto. Precis\u00e3o Forte - Todos os processos s\u00e3o suspeitos somente ap\u00f3s terem apresentado defeito. Precis\u00e3o Fraca - Algum processo correto nunca \u00e9 suspeito de ter apresentado defeito. Precis\u00e3o Eventual Forte - A partir de algum instante futuro, todos os processos s\u00e3o suspeitos somente ap\u00f3s apresentarem defeito. Precis\u00e3o Eventual Fraca - A partir de algum instante futuro, algum processo ativo nunca \u00e9 suspeito antes de ter apresentado defeito. Um detector ideal seria um com Completude Forte e Precis\u00e3o Forte, pois detectaria somente processos defeituosos e todos os processos defeituosos. Este detector \u00e9 conhecido como \\(P\\) ou Perfect . Infelizmente os detectores perfeitos s\u00f3 podem ser implementados em sistemas s\u00edncronos, onde se pode confiar que a falta de uma mensagem implica em que a mensagem n\u00e3o ser\u00e1 entregue por qu\u00ea o remetente deve ser defeituosos. Assim, \u00e9 preciso se focar em detectores n\u00e3o perfeitos ou n\u00e3o confi\u00e1veis . Em ambientes parcialmente s\u00edncronos , ou seja, ass\u00edncronos aumentados com algum tipo de sincronia, j\u00e1 \u00e9 poss\u00edvel implementar detectores n\u00e3o confi\u00e1veis. Por exemplo, se os processos disp\u00f5em de temporizadores precisos, um detector pode contar a passagem do tempo nos intervalos de comunica\u00e7\u00e3o com outros processos e, considerando um limite de tempo para estes intervalos, tentar determinar se tais processos encontram-se defeituosos ou n\u00e3o. Esta determina\u00e7\u00e3o \u00e9 por certo imprecisa e os detectores podem voltar atr\u00e1s em suas suspeitas t\u00e3o logo percebam um erro. Entretanto, a despeito desta incerteza, a informa\u00e7\u00e3o provida por estes detectores j\u00e1 pode ser suficiente para que se alcance o consenso se combinada a uma restri\u00e7\u00e3o de que uma maioria dos processos n\u00e3o seja defeituosa . Maioria Adicionar prova. Chandra, Hadzilacos e Toueg demonstram que o detector mais fraco com o qual se pode resolver consenso tem as propriedades de Completude Fraca e Acur\u00e1cia Eventual Fraca. 3 Este detector, conhecido como \\(\\Diamond W\\) , ou Eventual Weak , e \u00e9 implement\u00e1vel em sistemas nos quais h\u00e1 um limite superior de tempo para a transmiss\u00e3o de mensagens, mesmo que este limite seja desconhecido . V\u00e1rios protocolos de consenso utilizam o detector equivalente, \\(\\Diamond S\\) , equivalente ao \\(\\Diamond W\\) mas com completude forte, ou o eleitor de l\u00edderes \\(\\Omega\\) , que usa a informa\u00e7\u00e3o do \\(\\Diamond S\\) para sugerir um l\u00edder entre os processos. Estes protocolos s\u00e3o escritos de forma que se o limite superior n\u00e3o existe, o protocolo n\u00e3o termina e um resultado errado nunca \u00e9 alcan\u00e7ado , ou seja, os protocolos sempre garantem que as propriedades de corretude n\u00e3o s\u00e3o violadas, mesmo que n\u00e3o garanta que a termina\u00e7\u00e3o ser\u00e1 alcan\u00e7ada. Figura figura 2.2 da disserta\u00e7\u00e3o. SWIM https://www.youtube.com/watch?v=0bAJ4iNnf5M","title":"Detectores de Defeitos n\u00e3o Confi\u00e1veis"},{"location":"fault/agreement/#paxos-algoritmo-do-sinodo","text":"Algoritmo Descrever. Por enquanto, vejam esta explica\u00e7\u00e3o ou [ https://www.cs.rutgers.edu/~pxk/417/notes/paxos.html ] ou este v\u00eddeo [ https://www.youtube.com/watch?v=JEpsBg0AO6o ] ou este video [ https://www.youtube.com/watch?v=s8JqcZtvnsM ].","title":"Paxos: Algoritmo do S\u00ednodo"},{"location":"fault/agreement/#difusao-totalmente-ordenada","text":"Se pudermos resolver o consenso, podemos ent\u00e3o resolver o problema da difus\u00e3o totalmente ordenada ( total order multicast ) e com ela implementar a replica\u00e7\u00e3o de m\u00e1quinas de estados. Relembrando, na temos que: Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem. Para fazermos isso, precisamos primeiro formalizar as primitivas em v\u00e1rios n\u00edveis da resolu\u00e7\u00e3o do problema. No n\u00edvel do canal de comunica\u00e7\u00e3o, da rede, processos enviam e recebem mensagens. No n\u00edvel do consenso, processos fazem propostas e aprendem um valor decidido. Para chegar a uma \u00fanica decis\u00e3o, v\u00e1rias mensagens podem ser enviadas e recebidas. No n\u00edvel da difus\u00e3o at\u00f4mica, mensagens s\u00e3o difundidas e entregues . Se implementado sobre o consenso, para uma difus\u00e3o ser bem sucedida, uma inst\u00e2ncia de consenso \u00e9 necess\u00e1ria. Primitivas de comunica\u00e7\u00e3o enviar & receber ( send & receive ) - rede propor & decidir ( propose & decide ) - consenso difundir & entregar ( broadcast & deliver ) - difus\u00e3o Dado infinitas inst\u00e2ncias de consenso, pode-se us\u00e1-las para resolver difus\u00e3o at\u00f4mica usando o seguinte procedimento: Ordene as inst\u00e2ncias de consenso. Para difundir mensagem \\(m\\) , proponha a mensagem na menor inst\u00e2ncia \\(i\\) em que n\u00e3o tiver visto uma decis\u00e3o. Se a decis\u00e3o de \\(i\\) n\u00e3o \u00e9 \\(m\\) , volte para o passo anterior. Entregue as decis\u00f5es na ordem das inst\u00e2ncias. No exemplo a seguir, duas mensagens, \\(m\\) e \\(m'\\) foram difundidas pelas aplica\u00e7\u00f5es App1 e App2, respectivamente, por meio do m\u00f3dulo de difus\u00e3o at\u00f4mica junto a cada aplica\u00e7\u00e3o. O m\u00f3dulo de difus\u00e3o determina qual a menor inst\u00e2ncia de consenso ainda n\u00e3o decidida, azul, em que prop\u00f5em as mensagens. Ao final da inst\u00e2ncia de conseno, \\(m\\) \u00e9 decidida e \u00e9 entregue pelos m\u00f3dulos de difus\u00e3o. O m\u00f3dulo ABCast2 insiste na difus\u00e3o de \\(m'\\) , propondo-a na pr\u00f3xima inst\u00e2ncia, vermelha, que decide \\(m'\\) e leva esta mensagem a ser entregue. sequenceDiagram participant App1 participant ABCast1 participant Consenso participant ABCast2 participant App2 App1 -->>+ ABCast1: difundir m App2 -->>+ ABCast2: difundir m' rect rgb(100,255,255) ABCast1 ->>+ Consenso: propor m na inst 1 ABCast2 ->>+ Consenso: propor m' na inst 1 Consenso ->>- ABCast1: decidir m Consenso ->>- ABCast2: decidir m end ABCast1 -->>- App1: entregar m ABCast2 -->> App2: entregar m rect rgba(255,0,0,.5) ABCast2 ->>+ Consenso: propor m' na inst 2 Consenso ->> ABCast1: decidir m' Consenso ->>- ABCast2: decidir m' end ABCast1 -->> App1: entregar m' ABCast2 -->>- App2: entregar m' Ambas as aplica\u00e7\u00f5es, embora tivessem inten\u00e7\u00f5es diferentes sobre qual deveria ser a pr\u00f3xima mensagem entregue, entregam-nas na mesma ordem, isto \u00e9, primeiro \\(m\\) e depois \\(m'\\) . Se forem usadas como entrada para algum processamento, na ordem em que foram entregues, as aplica\u00e7\u00f5es chegar\u00e3o ao mesmo estado, em algum momento.","title":"Difus\u00e3o Totalmente Ordenada"},{"location":"fault/agreement/#paxos-difusao-atomica","text":"Paxos Difus\u00e3o At\u00f4mica","title":"Paxos: Difus\u00e3o at\u00f4mica"},{"location":"fault/agreement/#raft-difusao-atomica","text":"Raft \u00e9 um protocolo de difus\u00e3o at\u00f4mica associado a um protocolo de elei\u00e7\u00e3o de l\u00edderes. L\u00edderes s\u00e3o eleitos para mandatos pelo voto de uma maioria de processos, o que garante que nunca existir\u00e3o dois l\u00edderes para um mesmo mandato. Um mandato se estende enquanto o l\u00edder mantiver seus seguidores cientes de sua presen\u00e7a, o que faz pelo envio peri\u00f3dico de heartbeats . Atrasos na comunica\u00e7\u00e3o ou a falha do l\u00edder atual levam a uma suspeita de que o l\u00edder falhou, levando a nova elei\u00e7\u00e3o e novo mandado. A comunica\u00e7\u00e3o necess\u00e1ria para implementar a difus\u00e3o at\u00f4mica acontece em piggyback nos heartbeats . No tutorial The Secret lives of data , podemos ver com mais detalhes como o protocolo funciona. O tutorial, entretanto, foge da nomenclatura padr\u00e3o da \u00e1rea usando log-replication no lugar de difus\u00e3o at\u00f4mica (ou totalmente ordenada).","title":"Raft: Difus\u00e3o at\u00f4mica"},{"location":"fault/agreement/#outras-ordenacoes","text":"Como colocado diversas vezes, se todos os processos executam a mesma sequ\u00eancia de comandos determin\u00edsticos, todos avan\u00e7am pelos mesmos estados, implementando a t\u00e9cnica da replica\u00e7\u00e3o de m\u00e1quinas de estados. Se usada em um sistema de arquivos, por exemplo, a seguinte sequ\u00eancia de comandos levar\u00e1 sempre ao estado final em que h\u00e1 um arquivo /tmp/file2 e uma pasta denominada /dir1 . touch /tmp/file1 echo \"teste testando\" >> /tmp/file2 rm /tmp/file1 mkdir /dir1 H\u00e1 outras ordens dos mesmos comandos que levariam ao mesmo efeito, como a seguinte. Alguns protocolos de replica\u00e7\u00e3o de m\u00e1quinas de estados permitem que reordena\u00e7\u00f5es ocorram, desde que n\u00e3o afetem o resultado final dos comandos. Contudo, estes protocolos s\u00e3o mais complexos de se implementar e por isso raramente usados. echo \"teste testando\" >> /tmp/file2 mkdir /dir1 touch /tmp/file1 rm /tmp/file1","title":"Outras Ordena\u00e7\u00f5es"},{"location":"fault/agreement/#arcaboucos-para-coordenacao","text":"H\u00e1 muitas formas de se usar algoritmos de acordo em uma aplica\u00e7\u00e3o, embora se recomente que seu escopo seja minimizado a um n\u00facleo onde a consist\u00eancia forte \u00e9 absolutamente necess\u00e1ria e que este n\u00facleo seja usado para suportar outras partes do sistema 5 . Seja implementando a replica\u00e7\u00e3o de m\u00e1quinas de estados, seja implementando um core, ou qualquer outra abstra\u00e7\u00e3o sobre algoritmos de acordo ou comunica\u00e7\u00e3o em grupo, voc\u00ea tem a op\u00e7\u00e3o de implementar o protocolo zero, uma tarefa ingrata 4 . Felizmente, tamb\u00e9m tem a op\u00e7\u00e3o de usar arcabou\u00e7os prontos tanto para para comunica\u00e7\u00e3o em grupo quanto para diversos outros problemas de coordena\u00e7\u00e3o comuns em sistemas distribu\u00eddos. Impossibility of Distributed Consensus with One Faulty Process . Uma explica\u00e7\u00e3o da prova est\u00e1 dispon\u00edvel no Paper Trail \u21a9 Unreliable Failure Detectors for Reliable Distributed Systems \u21a9 The Weakest Failure Detector for Solving Consensus \u21a9 Um exemplo de como traduzir um algoritmo complexo para c\u00f3digo pode se ingrato \u00e9 reportado em Paxos Made Live - An Engineering Perspective . \u21a9 Consistent Core \u21a9","title":"Arcabou\u00e7os para coordena\u00e7\u00e3o"},{"location":"fault/bizantine/","text":"Falhas Bizantinas","title":"Falhas bizantinas"},{"location":"fault/bizantine/#falhas-bizantinas","text":"","title":"Falhas Bizantinas"},{"location":"fault/dependability/","text":"Dependabilidade Da necessidade de se poder depender de um sistema, surge a ideia de dependabilidade , isto \u00e9, de um sistema ter a propriedade de se poder depender do mesmo. Um pouco mais formalmente, dizemos que um componente \\(C\\) depende de um componente \\(C'\\) se a corretude do comportamento de \\(C\\) depende da corretude do componente \\(C'\\) e dizemos tamb\u00e9m que um componente \u00e9 \"depend\u00e1vel\" ( dependable ) na medida em que outros podem depender dele. A dependabilidade \u00e9 essencial aos componentes de sistemas distribu\u00eddos, pois como diz o ditado, uma corrente \u00e9 t\u00e3o forte quanto seu elo mais fraco. Esta propriedade por ser dividida em outras propriedades mais \"simples\": 1 Disponibilidade ( Availability ) - Prontid\u00e3o para uso. Confiabilidade/Fiabilidade ( Reliability ) - Continuidade do servi\u00e7o. Seguran\u00e7a ( Safety ) - Toler\u00e2ncia a cat\u00e1strofes. Integridade ( Integrity ) - Toler\u00e2ncia a modifica\u00e7\u00f5es. Manutenabilidade ( Maintainability ) - Facilidade de reparo. Disponibilidade A disponibilidade (em ingl\u00eas, availability ) especifica o qu\u00e3o pronto para uso o sistema est\u00e1. Disponibilidade The term 'availability' means ensuring timely and reliable access to and use of information. NIST SP 800-59 , no termo Availability 44 U.S.C., Sec. 3542 (b)(1)(C)) Na pr\u00e1tica, esta medida \u00e9 dada como a percentagem de tempo que o sistema est\u00e1 dispon\u00edvel para uso e, embora qualquer percentagem seja v\u00e1lida, normalmente se usa valores muito pr\u00f3ximos a 100% e descritos em termos de \"noves\". Por exemplo, tr\u00eas 9 quer disponibilidade de 99,9% e cinco 9 quer dizer 99,999%. A seguinte tabela resume o que significa na pr\u00e1ticas os valores mais comuns de disponibilidade: 2 Disponibilidade A porcentagem do tempo que infraestrutura, sistema ou solu\u00e7\u00e3o est\u00e1 operacional sob circunst\u00e2ncias normais ou a probabilidade do sistema estar operacional em um certo instante. Disponibilidade (%) \"noves\" downtime anual downtime mensal downtime semanal 90 1 36,5 dias 72 horas 16,8 horas 99 2 3,65 dias 7,2 horas 1,68 horas 99,9 3 8,76 horas 43,8 minutos 10.1 minutos 99,99 4 52,56 minutos 4,38 minutos 1,01 minutos 99,999 5 5,26 minutos 25,9 segundos 6,06 segundos 99,9999 6 31,5 segundos 2,59 segundos 0,605 segundos 99,99999 7 3,15 segundos 0,259 segundos 0,0605 segundos Apesar da precis\u00e3o dos valores, o que exatamente esta disponibilidade significa \u00e9 vari\u00e1vel. Se voc\u00ea contratar algum servi\u00e7o na nuvem, por exemplo, o fornecedor pode garantir 99,99% de disponibilidade, mas especificar que o servi\u00e7o considerado dispon\u00edvel desde que 80% das requisi\u00e7\u00f5es sejam atendidas em menos de 1s. Os detalhes do que exatamente \u00e9 considerado s\u00e3o especificados em um acordo de n\u00edvel de servi\u00e7o, ou SLA (do ingl\u00eas, service level agreement ). 3 O valor final da disponibilidade \u00e9 dado pela seguinte f\u00f3rmula, onde Tempo de disponibilidade acordado \u00e9 o tempo que o servi\u00e7o deve ficar no ar, de acordo com a SLA; e, Tempo de indisponibilidade \u00e9 o tempo que o servi\u00e7o ficou fora do ar. \\[ \\text{Disponbilidade} = \\frac{\\text{Tempo de disponibilidade acordado}-{\\text{Tempo de indisponibilidade}}}{\\text{Tempo de disponibilidade acordado}} \\] Confiabilidade A confiabilidade \u00e9 uma m\u00e9trica frequentemente confundida com a disponibilidade, mas enquanto esta \u00faltima mede a prontid\u00e3o para uso em algum instante, a primeira mede a prontid\u00e3o para uso por um per\u00edodo, tal que durante tal per\u00edodo o sistema n\u00e3o precise cesse o funcionamento e mantenha um n\u00edvel de desempenho previamente acordado. Para se falar em confiabilidade \u00e9 necess\u00e1rio pensar em termos defeitos , da frequ\u00eancia com que acontecem e dos atrasos que causam. Mais adiante discutiremos defeitos no contexto de sistemas distribu\u00eddos, mas por enquanto podemos pensar em defeitos simplesmente como manifesta\u00e7\u00f5es de problemas do sistema que o impede de executar as opera\u00e7\u00f5es para as quais foi constru\u00eddo ; se seu sistema \u00e9 uma l\u00e2mpada, ent\u00e3o um defeito pode ser a l\u00e2mpada queimar ou emitir menos luz do que o necess\u00e1rio. Com esta vis\u00e3o de defeitos, podemos definir quatro m\u00e9tricas Tempo m\u00e9dio para falha, MTTF (do ingl\u00eas, mean time to failure ) \u00e9 a expectativa de quanto tempo resta at\u00e9 que o sistema apresente o pr\u00f3ximo defeito (relevante); Tempo m\u00e9dio para diagn\u00f3stico, MTTD (do ingl\u00eas, mean time to diagnose ), \u00e9 a expectativa de quanto tempo leva perceber que o sistema apresentou um defeito e iniciar sua corre\u00e7\u00e3o; Tempo m\u00e9dio para reparo, MTTR (do ingl\u00eas, mean time to repair ) \u00e9 a expectativa de quanto tempo leva para corrigir o sistema e retorn\u00e1-lo ao estado funcional, uma vez que o defeito foi percebido Tempo m\u00e9dio entre defeitos, MTBF (do ingl\u00eas, mean time between failures ) \u00e9 a expectativa de quanto tempo transcorre entre falhas. A frequ\u00eancia de falhas de um \u00fanico componente \u00e9 dada por \\(\\lambda = \\frac{1}{MTBF}\\) e, dada a taxa de falhas de um componente, \u00e9 poss\u00edvel calcular sua confiabilidade em um certo instante \\(t\\) como \\(R(t) = e^{-\\lambda t}\\) . Calcular estas m\u00e9tricas para sistemas com m\u00faltiplos componentes, como um sistema distribu\u00eddo, \u00e9 poss\u00edvel mas requer uma imers\u00e3o em probabilidade condicional. Seguran\u00e7a ( Safety ) TODO Integridade TODO Manutenabilidde TODO Seguran\u00e7a ( Security ) Al\u00e9m da dependabilidade, outra propriedade importante e desej\u00e1vel para os sistemas \u00e9 a Confidencialidade , que quando combinada \u00e0 Integridade \u00e9 tamb\u00e9m chamada de Seguran\u00e7a ( Security ). Confidencialidade ( Confidentiality ) -- informa\u00e7\u00e3o somente \u00e9 acess\u00edvel a quem \u00e9 devido. Basic Concepts and Taxonomy of Dependable and Secure Computing . \u21a9 Availability Service Level 9\u2019s And What they Equate To \u21a9 A SLA especifica, por exemplo, como a qualidade do servi\u00e7o \u00e9 medida, qual o n\u00edvel de servi\u00e7o almejado (SLO, do ingl\u00eas, service level objetive ), e penalidades caso o SLO n\u00e3o seja alcan\u00e7ado. \u21a9","title":"Dependabilidade"},{"location":"fault/dependability/#dependabilidade","text":"Da necessidade de se poder depender de um sistema, surge a ideia de dependabilidade , isto \u00e9, de um sistema ter a propriedade de se poder depender do mesmo. Um pouco mais formalmente, dizemos que um componente \\(C\\) depende de um componente \\(C'\\) se a corretude do comportamento de \\(C\\) depende da corretude do componente \\(C'\\) e dizemos tamb\u00e9m que um componente \u00e9 \"depend\u00e1vel\" ( dependable ) na medida em que outros podem depender dele. A dependabilidade \u00e9 essencial aos componentes de sistemas distribu\u00eddos, pois como diz o ditado, uma corrente \u00e9 t\u00e3o forte quanto seu elo mais fraco. Esta propriedade por ser dividida em outras propriedades mais \"simples\": 1 Disponibilidade ( Availability ) - Prontid\u00e3o para uso. Confiabilidade/Fiabilidade ( Reliability ) - Continuidade do servi\u00e7o. Seguran\u00e7a ( Safety ) - Toler\u00e2ncia a cat\u00e1strofes. Integridade ( Integrity ) - Toler\u00e2ncia a modifica\u00e7\u00f5es. Manutenabilidade ( Maintainability ) - Facilidade de reparo.","title":"Dependabilidade"},{"location":"fault/failuredetector/","text":"Detectores de Falhas TODO Mover para c\u00e1, da sess\u00e3o de acordo. Falar sobre elei\u00e7\u00e3o de l\u00edderes aqui?","title":"Detectores de Falhas"},{"location":"fault/failuredetector/#detectores-de-falhas","text":"TODO Mover para c\u00e1, da sess\u00e3o de acordo. Falar sobre elei\u00e7\u00e3o de l\u00edderes aqui?","title":"Detectores de Falhas"},{"location":"fault/failures/","text":"Faltas, Erros e Falhas Os problemas enfrentados por sistemas computacionais podem ser classificados baseado no n\u00edvel em que se apresenta. Faltas No n\u00edvel mais b\u00e1sico dos problemas a serem contornados temos as faltas ( defect , fault , falha), que \u00e9 um erro no desenvolvimento do sistema, como bugs ou defeitos de fabrica\u00e7\u00e3o, que o leva a ficar diferente do que foi especificado, ou mesmo um erro na especifica\u00e7\u00e3o. Uma falta existe mesmo se for raramente ativada e mesmo se seus efeitos nunca forem percebidos. Por exemplo, se o c\u00f3digo tem um <= em vez de < na especifica\u00e7\u00e3o de uma itera\u00e7\u00e3o, mas se uma condi\u00e7\u00e3o faz com que a itera\u00e7\u00e3o seja interrompida antes, o c\u00f3digo ainda tem uma falta. 1 1 2 3 4 5 6 7 8 9 10 11 12 13 char minha_string [ 11 ]; int i ; initialize ( minha_string ); for ( i = 0 ; i <= 10 ; i ++ ){ if ( minha_string [ i ] == '.' ) break ; minha_string [ i ] = 'a' ; } minha_string [ i ] = '\\0' ; Erro No segundo n\u00edvel, temos o erro ( error ), que \u00e9 a manifesta\u00e7\u00e3o da falta levando a algum comportamento indevido. No exemplo acima, um erro seria quando a itera\u00e7\u00e3o passasse do ponto correto por causa do <= , por exemplo, na hora de escrever uma string em um array, estourando o limite do array na pilha mas sobrescrevendo uma vari\u00e1vel que n\u00e3o seja mais usada. O erro pode passar despercebido, mas ainda assim \u00e9 um erro. Falha Finalmente, no terceiro n\u00edvel, temos os falha ( failure , defeito, falha), 2 um erro percebido pelo usu\u00e1rio. Continuando o exemplo, um stack overflow que leva a uma falta de segmenta\u00e7\u00e3o, leva a uma falha. Quando um componente manifesta um falha, outros componentes que dele dependem, internalizar\u00e3o entradas indevidas, uma falta externa, o que levar\u00e1 a seu pr\u00f3prio estado interno a estar err\u00f4neo e possivelmente tamb\u00e9m manifestar uma falha. Esta cadeia pode levar cen\u00e1rios catastr\u00f3ficos. Falhas famosas Ariane 5 O Ariane 5 foi um foguete desenvolvido pela agencia espacial europ\u00e9ia que explodiu durante o lan\u00e7amento. The Explosion of the Ariane 5 On June 4, 1996 an unmanned Ariane 5 rocket launched by the European Space Agency exploded just forty seconds after its lift-off [...] after a decade of development costing $7B. The destroyed rocket and its cargo were valued at $500M. [...] the failure was a software error [...] a 64 bit floating point number [...] was converted to a 16 bit signed integer. The number was larger than 32,767, the largest integer storeable in a 16 bit signed integer, and thus the conversion failed. O erro gerado foi tratado como input, causando outros erros, que geraram instabilidade e que levou o sistema a se auto-destruir. 787 Dreamliner O avi\u00e3o 787 dreamliner, da Boeing, tem um problema que torna necess\u00e1rio reiniciar o sistema el\u00e9trico a cada 248 dias, ou o mesmo pode ter uma pane. Quote The plane\u2019s electrical generators fall into a failsafe mode if kept continuously powered on for 248 days. The 787 has four such main generator-control units that, if powered on at the same time, could fail simultaneously and cause a complete electrical shutdown. Segundo as \"m\u00e1s l\u00ednguas\", o problema \u00e9 que acontece um overflow em um contador de tempo Quote 248 days == 2^31 100ths of a second. even in 2015, our airplanes have integer overflow bugs https://t.co/6Z8d4y9gjM \u2014 Fiora @ \u65e5\u672c\u8a9e\u3067FF14 (@FioraAeterna) May 1, 2015 737 Max O Boeing 737 Max \u00e9 uma modifica\u00e7\u00e3o do 737 original em que o motores maiores foram usados sem modificar a estrutura do restante do avi\u00e3o e portanto alterando o seu centro de massa. Por causa da diferen\u00e7a, o avi\u00e3o pode subir r\u00e1pido demais, correndo o risco de perder sustenta\u00e7\u00e3o. Para auxiliar os pilotos e evitar a necessidade de treinamento espec\u00edfico, um sensor \u00e9 usado para detectar se o avi\u00e3o est\u00e1 nesta situa\u00e7\u00e3o e forcar o nariz do avi\u00e3o para baixo para corrigir o problema. Contudo, no 737 Max apenas um sensor \u00e9 usado e no caso de falha do mesmo, o avi\u00e3o \u00e9 for\u00e7ado para baixo e em dire\u00e7\u00e3o ao solo, o que levou \u00e0 morte de centenas de pessoas. 3 Subaru SUV Em 2018 a Subaru fez um recall gigante, de mais de 1 milh\u00e3o de unidades de um seus modelos de SUV, porqu\u00ea uma falha em um software fez com que soldagens fossem feitas incorretamente no chassis dos ve\u00edculos. O erro era irrepar\u00e1vel, levando a grandes preju\u00edzos. Shark attack! Quando falhas aparecem, \u00e9 importante identificar suas causas, isto \u00e9, a cadeia de eventos que os levaram a acontecer. Algumas empresas at\u00e9 publicam as root cause analysis ou a an\u00e1lise post-mortem para a comunidade como forma de compartilhar conhecimento e tamb\u00e9m por quest\u00f5es de transpar\u00eancia, mas mais importante, conhecer a causa pode ajudar a evitar que novas inst\u00e2ncias da mesma falha ou similares. 4 Classes de Falhas Faltas s\u00e3o um fato da vida, uma constante no desenvolvimento de sistemas, mas se precisamos lidar com elas, prevenindo e tolerando sua presen\u00e7a, precisamos entender como se manifestam e, para isso, uma classifica\u00e7\u00e3o \u00e9 essencial. Quebra Falha de quebra ( crash ) s\u00e3o falhas em que o componente para de funcionar, irreversivelmente. Uma vez que o componente cessa seu funcionamento, qualquer comunica\u00e7\u00e3o com o mesmo \u00e9 interrompida e pode dar bons indicativos do defeito aos outros componentes. Alguns sistemas, denominados fail-stop , for\u00e7am-se a parar de funcionar quando percebem um falha, imitando uma quebra, e implementando um comportamento fail-fast . 5 Estes sistemas podem emitir um \"canto do cisne\" para permitir que outros componentes detectem a falha. Ap\u00f3s pararem, alguns sistemas podem aplicar passos de recupera\u00e7\u00e3o e voltar a funcionar, no que \u00e9 denominado fail-recover . Ao retornar \u00e0 opera\u00e7\u00e3o, o processo poderia assumir uma nova identidade, mas se mantiver a anterior, pode ser for\u00e7ado a recuperar o estado em que estava logo antes do problema se manifestar, precisando, para isso, da capacidade de armazenar estado. Omiss\u00e3o Em uma falha de omiss\u00e3o ( omission failure ), um componente deixa de executar alguma a\u00e7\u00e3o. Por exemplo, uma requisi\u00e7\u00e3o recebida por um servidor n\u00e3o \u00e9 processada, um disco n\u00e3o armazena os dados no meio magn\u00e9tico, ou uma mensagem n\u00e3o \u00e9 transmitida. Este tipo de falha \u00e9 dif\u00edcil de ser identificado pois outros componentes n\u00e3o necessariamente tem acesso direto ao resultado da opera\u00e7\u00e3o. Por exemplo, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem, ent\u00e3o houve uma falha de omiss\u00e3o. Mas se a mensagem \u00e9 retransmitida at\u00e9 que tenha sua entrega confirmada, ent\u00e3o a falha de omiss\u00e3o \u00e9 mascarada como um simples atraso na comunica\u00e7\u00e3o, o que tamb\u00e9m pode ser uma falha. Temporiza\u00e7\u00e3o Em sistemas em que h\u00e1 limites de tempo para a execu\u00e7\u00e3o de a\u00e7\u00f5es, uma viola\u00e7\u00e3o destes limites \u00e9 uma falha de temporiza\u00e7\u00e3o . Por exemplo, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem, ent\u00e3o houve uma falha de omiss\u00e3o. Novamente considerando problemas de transmiss\u00e3o de mensagens, se o meio de comunica\u00e7\u00e3o se recusou a entregar uma mensagem que deveria ser entregue dentro de 3ms, ent\u00e3o houve uma falha de omiss\u00e3o. Mas se a mensagem \u00e9 retransmitida at\u00e9 que tenha sua entrega confirmada, mas a mesma \u00e9 entregue com 5ms, ent\u00e3o o defeito \u00e9 mascarado como uma falha de temporiza\u00e7\u00e3o. Falhas de temporiza\u00e7\u00e3o podem acontecer devido a problemas de sincroniza\u00e7\u00e3o de rel\u00f3gios, como no algoritmo de difus\u00e3o totalmente ordenada visto anteriormente. Arbitr\u00e1rios Uma falha arbitr\u00e1ria ou bizantina \u00e9 uma na qual qualquer comportamento pode acontecer. Por exemplo, uma mensagem pode ser modificada, um servidor pode reiniciar-se constantemente, todos os dados podem ser apagados, ou acesso pode ser dado a quem n\u00e3o \u00e9 devido. Estas falhas podem ser causadas por faltas no software, no hardware, ou at\u00e9 mesmo por agentes mal intencionados, como hackers e v\u00edrus. Hierarquia Os tipos de falhas apontadas acima podem ser hierarquizados como a seguir, o que quer dizer que uma quebra \u00e9 apenas uma omiss\u00e3o por tempo infinito: Fail-stop \\(\\subset\\) Quebra \\(\\subset\\) Omiss\u00e3o \\(\\subset\\) Temporiza\u00e7\u00e3o \\(\\subset\\) Arbitr\u00e1ria Falhas intermitentes Algumas falhas fogem \u00e0 classifica\u00e7\u00e3o acima por terem um comportamento especial, se manifestando de forma intermitente, por causa de eventos esparsos como picos de energia, ou pelo comportamento emergente da intera\u00e7\u00e3o com outros sistemas. Para capturar estas idiossincrasias, recorremos a uma outra classifica\u00e7\u00e3o , bem informal. Tipos de bugs Bohrbug A BohrBug is just your average, straight-forward bug. Simple like the Bohr model of the atom: A smallsphere. You push it, it moves. BohrBugs are reproducible, and hence are easily fixed once discovered. These are named after Niels Bohr, who proposed a simple and easy-to-understand atomic model in 1913. In Bohr\u2019s model, things like the path and momentum of an electron in an atom are predictable. Heisenbug A bug that disappears or alters its behavior when one attempts to probe or isolate it. No matter how much time and effort is spent trying to reproduce the problem, the bug eludes us. Such bugs were named Heisenbugs, after Werner Heisenberg, who is known for his \u201cuncertainty principle\u201d. According to his theory, it is not possible to accurately or certainly determine the position and velocity of an electron in an atom at a particular moment. Mandelbug When the cause of the bug is too complex to understand, and the resulting bug appears chaotic, it is called a Mandelbug. These are named after Beno\u00eet Mandelbrot, who is considered the father of fractal geometry (fractals are complex, self-similar structures). A bug in an operating system that depends on scheduling is an example of a Mandelbug. Schroedinbug Sometimes, you look into the code, and find that it has a bug or a problem that should never have allowed it to work in the first place. When you try out the code, the bug promptly shows up, and the software fails! Though it sounds very uncommon, such bugs do occur and are known as Schroedinbugs. They are named after the scientist Erwin Schr\u00f6dinger, who proposed that in quantum physics, quantum particles like atoms could exist in two or more quantum states. Fractal Bugs A bug, after which its resolution is found, reveals additional self-similar bugs elsewhere in the code, after which they are fixed, likewise appear elsewhere still. Como lidar com faltas? Mas se o objetivo \u00e9 ter um sistema que esteja funcional a despeito de problemas, precisamos de formas de lidar com faltas, previnindo , removendo e tolerando -as. Preven\u00e7\u00e3o A preven\u00e7\u00e3o de faltas acontece por meio de t\u00e9cnicas bem estabelecidas de engenharia. No caso de sistemas de software, modulariza\u00e7\u00e3o, uso de linguagens de programa\u00e7\u00e3o fortemente tipadas e encapsulamento s\u00e3o passos importantes. Outras t\u00e9cnicas envolvidas na preven\u00e7\u00e3o de faltas s\u00e3o an\u00e1lise est\u00e1tica, especifica\u00e7\u00e3o formal, teste e prova destas especifica\u00e7\u00f5es. Por exemplo, diversas empresas usam linguagens como TLA \\(^+\\) 6 e Promela , associados a verificadores de modelo como TLC e Spin, respectivamente, para testar e verificar a corretude de seus algoritmos. Remo\u00e7\u00e3o Mesmo uma especifica\u00e7\u00e3o correta pode produzir um sistema com faltas pois a tradu\u00e7\u00e3o de especifica\u00e7\u00f5es formais para c\u00f3digo \u00e9 um passo complexo. Testes e manuten\u00e7\u00e3o do sistema permitem a remo\u00e7\u00e3o de faltas que passarem despercebidas pelas tentativas de preven\u00e7\u00e3o. Toler\u00e2ncia Testes, contudo, apenas aumentam a confian\u00e7a no sistema, n\u00e3o sendo capazes de certificar a aus\u00eancia de problemas. Assim, tenta-se desenvolver os sistemas de forma que, mesmo se faltas ainda estiverem presentes, seus efeitos n\u00e3o sejam percebidos como falhas, isto \u00e9, sistemas que tenha toler\u00e2ncia a faltas (ou preven\u00e7\u00e3o de falhas ). Para se alcan\u00e7ar toler\u00e2ncia a faltas \u00e9 necess\u00e1rio detectar e se recuperar de erros. Por exemplo, um sistema de arquivos que mantenha um journal , como o Ext v3 , armazena informa\u00e7\u00e3o de forma redundante e, quando detecta que os dados em sua forma principal est\u00e3o corrompidos, usa o journal para recuperar os dados, mascarando o erro. De acordo como Avizienis et al. , 7 temos as seguintes t\u00e9cnicas para tolerar faltas: Um sistema que sofra de falhas recorrentes \u00e9 um bom candidato a previs\u00e3o de falhas, em que se estima quando uma falha ocorrer\u00e1 baseado no hist\u00f3rico. Por exemplo, um sistema que sofra falha por uso excessivo de mem\u00f3ria a cada dez dias em uso, pode ser reiniciado no nono dia, em condi\u00e7\u00f5es controladas, para evitar problemas maiores enquanto a raz\u00e3o do uso excessivo de mem\u00f3ria \u00e9 corrigido. Degrada\u00e7\u00e3o Graciosa Se remover todas as possibilidades de falhas de um componente \u00e9 algo dif\u00edcil, ao tolerar faltas permitimos permitir\u00e1 que o sistema continue funcional ainda que forma degradada, o que denominamos uma degrada\u00e7\u00e3o graciosa (do ingl\u00eas graceful degradation ). Quando n\u00e3o for poss\u00edvel tolerar a falha, o sistema ser\u00e1 quebradi\u00e7o (do ingl\u00eas brittle ). Neste caso, pode ser melhor fazer com o que o sistema pare de funcionar ao primeiro sinal de problema, falhando rapidamente (do ingl\u00eas fail-fast ) e evitando que erros se propagem. Redund\u00e2ncia De forma geral, qualquer processo para melhorar um sistema demandar\u00e1 redund\u00e2ncia. Para prevenir faltas, redund\u00e2ncia de tempo para refinar projetos. Para remov\u00ea-las, redund\u00e2ncia de tempo e recursos para executar mais testes. Para lidar com erros, redund\u00e2ncia de c\u00f3digo, seja c\u00f3digo para tratamento de exce\u00e7\u00f5es seja para replicar componentes. Por exemplo, pense no pneu estepe de um carro, no gerador de eletricidade de um hospital. Replica\u00e7\u00e3o permite remover os pontos \u00fanicos de falha (SPOF, Single Point of Failure ). Seja como for, redund\u00e2ncia implica em mais custos, ent\u00e3o o grau de redund\u00e2ncia a ser utilizado depende de uma an\u00e1lise custo x benef\u00edcio. No caso de um sistema distribu\u00eddo, quando falamos em redund\u00e2ncia, normalmente falamos em processos redundantes, c\u00f3pias ou r\u00e9plicas. Assim, com m\u00faltiplas c\u00f3pias, quando um processo apresenta um defeito, outro podem continuar executando o servi\u00e7o. Correla\u00e7\u00e3o entre falhas TODO Mover este texto para cima, para antes do gancho para replica\u00e7\u00e3o. Algumas falhas s\u00e3o ativadas por entradas e, neste caso, mesmo que se tenha v\u00e1rias c\u00f3pias do mesmo sistema, todas apresentar\u00e3o erros uma vez que a entrada problem\u00e1tica acontecer. Este \u00e9 um cen\u00e1rio em que as falhas n\u00e3o s\u00e3o independentes, mas correlatas. Para tentar evit\u00e1-lo, podemos usar t\u00e9cnicas como o n-version programming , que consiste basicamente em ter m\u00faltiplas implementa\u00e7\u00f5es do mesmo sistema desenvolvidas de forma independente, isto \u00e9, fazendo uso de um ou mais da seguintes op\u00e7\u00f5es: m\u00faltiplos times m\u00faltiplos sistemas operacionais m\u00faltiplas linguagens de programa\u00e7\u00e3o. Esta t\u00e9cnica \u00e9 interessante mas raramente usada devido ao seu alto custo e n\u00e3o ser garantia de sucesso pois, por exemplo, erros de especifica\u00e7\u00e3o s\u00e3o reproduzidos em todas as especifica\u00e7\u00f5es e m\u00faltiplas vers\u00f5es serem faltosas. Voc\u00ea pode pensar que \"falta corretude\" no software como maneira de se lembrar do termo. \u21a9 Observe que o termo falha \u00e9 usado em dois lugares. Isso \u00e9 basicamente um problema de tradu\u00e7\u00e3o da nomenclatura em ingl\u00eas, fault-error-failure que levou a uma hierarquia mais comum falha-erro-defeito e outra mais correta falta-erro-falha. Os adeptos da primeira falam em toler\u00e2ncia a falhas, enquanto os da \u00faltima falam em toler\u00e2ncia a faltas. \u21a9 Boeing 737 Max: why was it grounded, what has been fixed and is it enough? \u21a9 Post-mortems para uma extensa lista de an\u00e1lises. \u21a9 Fail Fast Is Failing\u2026 Fast! \u21a9 Using TLA+ in the Real World to Understand a Glibc Bug \u21a9 Basic Concepts and Taxonomy of Dependable and Secure Computing \u21a9","title":"Falta/Erros/Falhas"},{"location":"fault/failures/#faltas-erros-e-falhas","text":"Os problemas enfrentados por sistemas computacionais podem ser classificados baseado no n\u00edvel em que se apresenta.","title":"Faltas, Erros e Falhas"},{"location":"fault/failures/#classes-de-falhas","text":"Faltas s\u00e3o um fato da vida, uma constante no desenvolvimento de sistemas, mas se precisamos lidar com elas, prevenindo e tolerando sua presen\u00e7a, precisamos entender como se manifestam e, para isso, uma classifica\u00e7\u00e3o \u00e9 essencial.","title":"Classes de Falhas"},{"location":"fault/failures/#como-lidar-com-faltas","text":"Mas se o objetivo \u00e9 ter um sistema que esteja funcional a despeito de problemas, precisamos de formas de lidar com faltas, previnindo , removendo e tolerando -as.","title":"Como lidar com faltas?"},{"location":"fault/failures/#correlacao-entre-falhas","text":"TODO Mover este texto para cima, para antes do gancho para replica\u00e7\u00e3o. Algumas falhas s\u00e3o ativadas por entradas e, neste caso, mesmo que se tenha v\u00e1rias c\u00f3pias do mesmo sistema, todas apresentar\u00e3o erros uma vez que a entrada problem\u00e1tica acontecer. Este \u00e9 um cen\u00e1rio em que as falhas n\u00e3o s\u00e3o independentes, mas correlatas. Para tentar evit\u00e1-lo, podemos usar t\u00e9cnicas como o n-version programming , que consiste basicamente em ter m\u00faltiplas implementa\u00e7\u00f5es do mesmo sistema desenvolvidas de forma independente, isto \u00e9, fazendo uso de um ou mais da seguintes op\u00e7\u00f5es: m\u00faltiplos times m\u00faltiplos sistemas operacionais m\u00faltiplas linguagens de programa\u00e7\u00e3o. Esta t\u00e9cnica \u00e9 interessante mas raramente usada devido ao seu alto custo e n\u00e3o ser garantia de sucesso pois, por exemplo, erros de especifica\u00e7\u00e3o s\u00e3o reproduzidos em todas as especifica\u00e7\u00f5es e m\u00faltiplas vers\u00f5es serem faltosas. Voc\u00ea pode pensar que \"falta corretude\" no software como maneira de se lembrar do termo. \u21a9 Observe que o termo falha \u00e9 usado em dois lugares. Isso \u00e9 basicamente um problema de tradu\u00e7\u00e3o da nomenclatura em ingl\u00eas, fault-error-failure que levou a uma hierarquia mais comum falha-erro-defeito e outra mais correta falta-erro-falha. Os adeptos da primeira falam em toler\u00e2ncia a falhas, enquanto os da \u00faltima falam em toler\u00e2ncia a faltas. \u21a9 Boeing 737 Max: why was it grounded, what has been fixed and is it enough? \u21a9 Post-mortems para uma extensa lista de an\u00e1lises. \u21a9 Fail Fast Is Failing\u2026 Fast! \u21a9 Using TLA+ in the Real World to Understand a Glibc Bug \u21a9 Basic Concepts and Taxonomy of Dependable and Secure Computing \u21a9","title":"Correla\u00e7\u00e3o entre falhas"},{"location":"fault/reconfiguration/","text":"Reconfigura\u00e7\u00e3o E se mais de um, de um mesmo conjunto de r\u00e9plicas, falhar? Embora seja pequena a probabilidade de dois n\u00f3s de um mesmo grupo falharem em instantes pr\u00f3ximos, dado tempo suficiente, qualquer evento com probabilidade diferente de 0 acontecer\u00e1. Precisamos de uma forma de trocar n\u00f3s da aplica\u00e7\u00e3o que falharam por novos n\u00f3s. Este \u00e9 problema denominado Pertin\u00eancia de Grupo ( Group Membership ) TODO","title":"Reconfigura\u00e7\u00e3o"},{"location":"fault/reconfiguration/#reconfiguracao","text":"E se mais de um, de um mesmo conjunto de r\u00e9plicas, falhar? Embora seja pequena a probabilidade de dois n\u00f3s de um mesmo grupo falharem em instantes pr\u00f3ximos, dado tempo suficiente, qualquer evento com probabilidade diferente de 0 acontecer\u00e1. Precisamos de uma forma de trocar n\u00f3s da aplica\u00e7\u00e3o que falharam por novos n\u00f3s. Este \u00e9 problema denominado Pertin\u00eancia de Grupo ( Group Membership ) TODO","title":"Reconfigura\u00e7\u00e3o"},{"location":"fault/replication/","text":"Replica\u00e7\u00e3o Embora a ideia de replica\u00e7\u00e3o seja simples, isto \u00e9, criar c\u00f3pias de um componente para garantir que algum est\u00e1 sempre dispon\u00edvel para continuar a entregar as funcionalidades do sistema, a implementa\u00e7\u00e3o pode estar longe de ser trivial, pois para que tenhamos realmente c\u00f3pias, \u00e9 preciso que as a\u00e7\u00f5es tomada por um componente sejam tamb\u00e9m tomadas pelas r\u00e9plicas. H\u00e1 v\u00e1rias possibilidades de como replicar, em um grau ou em outro de corretude, cada uma com seus pr\u00f3s e contras. Uma forma de olhar para este problema \u00e9 considerar em quais r\u00e9plicas as opera\u00e7\u00f5es de modifica\u00e7\u00e3o de dados podem ser inicialmente executadas, levando a distin\u00e7\u00e3o entre sistema com m\u00faltiplos ou simplesmente um escritor (do ingl\u00eas, multi ou single writer ). Multi-Escritores Nos sistemas multi-escritores, clientes podem disparar opera\u00e7\u00f5es de modifica\u00e7\u00f5es de dados (escritas) e de recupera\u00e7\u00e3o de dados (leituras) para qualquer r\u00e9plica. Encaminhamento de mensagens A abordagem mais b\u00e1sica para a replica\u00e7\u00e3o consiste em permitir que todas as r\u00e9plicas aceitem opera\u00e7\u00f5es dos clientes e fazer com que as r\u00e9plicas repassem as opera\u00e7\u00f5es que receberam para as demais. Esta abordagem pode ser implementada com diferentes mecanismo de comunica\u00e7\u00e3o, com diferentes resultados. Por exemplo, se implementada o uso de UDP, todas as r\u00e9plicas receber\u00e3o as mesmas opera\u00e7\u00f5es, exceto por alguma eventualmente perdida. Se em vez disso usarem v\u00e1rias conex\u00f5es TCP conectado todas as r\u00e9plicas, desde que as r\u00e9plicas estejam sempre ativas, todas receber\u00e3o, em algum momento, todas as opera\u00e7\u00f5es enviadas pelos clientes. Mesmo que todas as mensagens sejam entregues, a falta de ordena\u00e7\u00e3o no processamento de opera\u00e7\u00f5es pode levar a estados inconsistentes entre as r\u00e9plicas. Por exemplo, se dois comandos s\u00e3o enviados, um para esvaziar o conte\u00fado de um arquivo e o outro pra apag\u00e1-lo, o processamento desordenado poder\u00e1 levar uma r\u00e9plica a ter um arquivo vazio e a outra a n\u00e3o ter o arquivo. Anti-entropia Para corrigir inconsist\u00eancias, r\u00e9plicas podem comunicar-se frequentemente identificando e corrigindo diverg\u00eancias em seus dados. Este tipo de protocolo, denominado Anti-Entropia, pode ser implementado com um mecanismo de gossiping e usando rel\u00f3gios vetoriais para concordar nas vers\u00f5es de dados conflitantes a se manter. Usando anti-entropia r\u00e9plicas podem garantir que, se novas opera\u00e7\u00f5es cessarem, em algum momento estar\u00e3o consistentes. O termo em ingl\u00eas para esta garantia \u00e9 eventual consistency 1 e \u00e9 como funcionam diversos bancos de dados n\u00e3o relacionais como Cassandra, Redis e Dynamo. Apesar de levar \u00e0 consist\u00eancia entre r\u00e9plicas, o estado alcan\u00e7ado n\u00e3o necessariamente faz sentido do ponto de vista da aplica\u00e7\u00e3o pois pode corresponder, por exemplo, a uma ordena\u00e7\u00e3o errada dos comandos emitidos por um dado cliente. Por isso, esta t\u00e9cnica n\u00e3o pode ser aplicada em todas as situa\u00e7\u00f5es. \u00danico Escritor No caso de \u00fanico escritor, as opera\u00e7\u00f5es de escrita s\u00e3o direcionadas para uma \u00fanica r\u00e9plica e, dependendo dos requisitos de consist\u00eancia dos clientes, as opera\u00e7\u00f5es e leitura podem ser direcionadas \u00e0 mesma r\u00e9plica ou a quaisquer das r\u00e9plicas. Prim\u00e1rio/Secund\u00e1rio Nos foquemos na raiz do problema que aparentemente \u00e9 a ordena\u00e7\u00e3o das opera\u00e7\u00f5es. Se cada processo pode receber as mensagens em qualquer ordem, ou seja, cada uma tem uma fila de mensagens independente, ent\u00e3o as r\u00e9plicas podem chegar a estados distintos. Mas e se tiv\u00e9ssemos uma fila \u00fanica? No caso da replica\u00e7\u00e3o prim\u00e1rio/c\u00f3pia , 2 o prim\u00e1rio \u00e9 respons\u00e1vel por lidar com clientes e por informar c\u00f3pias das modifica\u00e7\u00f5es de estado, efetivamente mantendo a fila \u00fanica e impondo uma ordena\u00e7\u00e3o de opera\u00e7\u00f5es que faz sentido, correspondendo a ordem de entrega das mensagens. Algumas observa\u00e7\u00f5es s\u00e3o importantes sobre a forma como as opera\u00e7\u00f5es s\u00e3o repassadas para as r\u00e9plicas aqui. Opera\u00e7\u00f5es x Estado Outro fator importante \u00e9 que o prim\u00e1rio n\u00e3o necessariamente precisa repassar a opera\u00e7\u00e3o para r\u00e9plica, podendo passar algo equivalente. Por exemplo, se a opera\u00e7\u00e3o \u00e9 um comando SQL que demanda muito tempo para executar mas que altera poucos dados no banco, ent\u00e3o o prim\u00e1rio poderia enviar as atualiza\u00e7\u00f5es para r\u00e9plicas em vez de lhes exigir que reexecutem o SQL. Por outro lado, um pequeno comando SQL poderia gerar uma grande modifica\u00e7\u00e3o nos dados e, neste caso, repassar o SQL seria mais econ\u00f4mico em termos de comunica\u00e7\u00e3o. A melhor abordagem depende de cada aplica\u00e7\u00e3o. C\u00f3pias desatualizadas Opera\u00e7\u00f5es que levam a atualiza\u00e7\u00f5es nos dados devem ser feitas sempre no processo prim\u00e1rio, ou este n\u00e3o processaria as opera\u00e7\u00f5es, podendo levar o prim\u00e1rio a virar um gargalo do sistema. Para amenizar esta situa\u00e7\u00e3o, opera\u00e7\u00f5es que apenas leiam dados poderiam ser enviadas para as r\u00e9plicas, em vez de para o prim\u00e1rio. Contudo, como o prim\u00e1rio primeiro executa a opera\u00e7\u00e3o antes de repass\u00e1-la para as r\u00e9plicas, h\u00e1 um atraso na execu\u00e7\u00e3o pelas r\u00e9plicas, o que quer dizer que as leituras poderiam retornar dados antigos. Replica\u00e7\u00e3o em Cadeia A replica\u00e7\u00e3o em cadeia \u00e9 uma generaliza\u00e7\u00e3o de prim\u00e1rio/c\u00f3pia em que os processos se organizam em um sequ\u00eancia para executar opera\u00e7\u00f5es. Como na abordagem original, atualiza\u00e7\u00f5es no sistema s\u00e3o sempre direcionadas ao prim\u00e1rio , a cabe\u00e7a da sequ\u00eancia. Leituras , se absolutamente necessitarem dos dados escritos mais recentemente, tamb\u00e9m devem ser direcionadas \u00e0 cabe\u00e7a . Caso contr\u00e1rio, podem ser direcionadas aos processos na cauda , diminuindo a carga de trabalho na cabe\u00e7a; quanto mais relaxado for a exig\u00eancia de \"frescor\" dos dados, mais para o fim da cauda a requisi\u00e7\u00e3o pode ser enviada. Lidando com falhas Em abordagens baseadas em um prim\u00e1rio, um passo essencial \u00e9 identificar as falhas do processo prim\u00e1rio para ativar um backup para que tome seu lugar. Nesta situa\u00e7\u00e3o, o primeiro desafio est\u00e1 em identificar a falha. Como j\u00e1 mencionamos e ainda iremos discutir, identificar corretamente a falha de um processo em um ambiente onde a comunica\u00e7\u00e3o acontece por troca de mensagens e ass\u00edncrono \u00e9 imposs\u00edvel, pois n\u00e3o se pode diferenciar um processo falho de um lento. Mesmo que a identifica\u00e7\u00e3o fosse perfeita, ainda temos o problema das opera\u00e7\u00f5es que j\u00e1 foram entregues para o prim\u00e1rio mas que ainda n\u00e3o foram propagadas para as r\u00e9plicas. Quanto o backup assume, ele ter\u00e1 ent\u00e3o um estado que est\u00e1 no passado do estado o prim\u00e1rio, o que pode levar comportamento inaceit\u00e1vel. Se este for o caso, replica\u00e7\u00e3o ativa pode ser usada. Replica\u00e7\u00e3o ativa No caso da replica\u00e7\u00e3o ativa, as v\u00e1rias c\u00f3pias executam todos os comandos enviados para o sistema, estando assim todas aptas a continuar a executar o servi\u00e7o a qualquer instante, pelo menos se as opera\u00e7\u00f5es de leitura forem enfileiradas tamb\u00e9m, ou poderiam chegar a uma r\u00e9plica antes de uma escrita disparada anteriormente. A t\u00e9cnica de replica\u00e7\u00e3o de m\u00e1quinas de estados , brevemente discutida anteriormente \u00e9 uma materializa\u00e7\u00e3o da replica\u00e7\u00e3o ativa. Como vimos anteriormente, replica\u00e7\u00e3o de m\u00e1quinas de estados utiliza primitivas de comunica\u00e7\u00e3o em grupo, mas as primitivas vistas anteriormente n\u00e3o s\u00e3o funcionais principalmente por n\u00e3o serem tolerantes a falhas. Vejamos a porqu\u00ea \u00e9 dif\u00edcil desenvolver primitivas tolerantes a falhas. Event sourcing TODO Relacionar primitivas de comunica\u00e7\u00e3o com filas de mensagem Relacionar filas de mensagens com um log Relacionar log com event sourcing e stream processing Usar time warp como exemplo (Jefferson 1985) Usar Kafka como exemplo Eventual , no ingl\u00eas, quer dizer que algo vai acontecer, embora n\u00e3o se saiba quando. \u21a9 Esta t\u00e9cnica tamb\u00e9m \u00e9 conhecida como mestre/escravo , mas esta nomenclatura tem ca\u00eddo em desuso por raz\u00f5es \u00f3bvias. \u21a9","title":"Replica\u00e7\u00e3o"},{"location":"fault/replication/#replicacao","text":"Embora a ideia de replica\u00e7\u00e3o seja simples, isto \u00e9, criar c\u00f3pias de um componente para garantir que algum est\u00e1 sempre dispon\u00edvel para continuar a entregar as funcionalidades do sistema, a implementa\u00e7\u00e3o pode estar longe de ser trivial, pois para que tenhamos realmente c\u00f3pias, \u00e9 preciso que as a\u00e7\u00f5es tomada por um componente sejam tamb\u00e9m tomadas pelas r\u00e9plicas. H\u00e1 v\u00e1rias possibilidades de como replicar, em um grau ou em outro de corretude, cada uma com seus pr\u00f3s e contras. Uma forma de olhar para este problema \u00e9 considerar em quais r\u00e9plicas as opera\u00e7\u00f5es de modifica\u00e7\u00e3o de dados podem ser inicialmente executadas, levando a distin\u00e7\u00e3o entre sistema com m\u00faltiplos ou simplesmente um escritor (do ingl\u00eas, multi ou single writer ).","title":"Replica\u00e7\u00e3o"},{"location":"fault/replication/#multi-escritores","text":"Nos sistemas multi-escritores, clientes podem disparar opera\u00e7\u00f5es de modifica\u00e7\u00f5es de dados (escritas) e de recupera\u00e7\u00e3o de dados (leituras) para qualquer r\u00e9plica.","title":"Multi-Escritores"},{"location":"fault/replication/#encaminhamento-de-mensagens","text":"A abordagem mais b\u00e1sica para a replica\u00e7\u00e3o consiste em permitir que todas as r\u00e9plicas aceitem opera\u00e7\u00f5es dos clientes e fazer com que as r\u00e9plicas repassem as opera\u00e7\u00f5es que receberam para as demais. Esta abordagem pode ser implementada com diferentes mecanismo de comunica\u00e7\u00e3o, com diferentes resultados. Por exemplo, se implementada o uso de UDP, todas as r\u00e9plicas receber\u00e3o as mesmas opera\u00e7\u00f5es, exceto por alguma eventualmente perdida. Se em vez disso usarem v\u00e1rias conex\u00f5es TCP conectado todas as r\u00e9plicas, desde que as r\u00e9plicas estejam sempre ativas, todas receber\u00e3o, em algum momento, todas as opera\u00e7\u00f5es enviadas pelos clientes. Mesmo que todas as mensagens sejam entregues, a falta de ordena\u00e7\u00e3o no processamento de opera\u00e7\u00f5es pode levar a estados inconsistentes entre as r\u00e9plicas. Por exemplo, se dois comandos s\u00e3o enviados, um para esvaziar o conte\u00fado de um arquivo e o outro pra apag\u00e1-lo, o processamento desordenado poder\u00e1 levar uma r\u00e9plica a ter um arquivo vazio e a outra a n\u00e3o ter o arquivo.","title":"Encaminhamento de mensagens"},{"location":"fault/replication/#anti-entropia","text":"Para corrigir inconsist\u00eancias, r\u00e9plicas podem comunicar-se frequentemente identificando e corrigindo diverg\u00eancias em seus dados. Este tipo de protocolo, denominado Anti-Entropia, pode ser implementado com um mecanismo de gossiping e usando rel\u00f3gios vetoriais para concordar nas vers\u00f5es de dados conflitantes a se manter. Usando anti-entropia r\u00e9plicas podem garantir que, se novas opera\u00e7\u00f5es cessarem, em algum momento estar\u00e3o consistentes. O termo em ingl\u00eas para esta garantia \u00e9 eventual consistency 1 e \u00e9 como funcionam diversos bancos de dados n\u00e3o relacionais como Cassandra, Redis e Dynamo. Apesar de levar \u00e0 consist\u00eancia entre r\u00e9plicas, o estado alcan\u00e7ado n\u00e3o necessariamente faz sentido do ponto de vista da aplica\u00e7\u00e3o pois pode corresponder, por exemplo, a uma ordena\u00e7\u00e3o errada dos comandos emitidos por um dado cliente. Por isso, esta t\u00e9cnica n\u00e3o pode ser aplicada em todas as situa\u00e7\u00f5es.","title":"Anti-entropia"},{"location":"fault/replication/#unico-escritor","text":"No caso de \u00fanico escritor, as opera\u00e7\u00f5es de escrita s\u00e3o direcionadas para uma \u00fanica r\u00e9plica e, dependendo dos requisitos de consist\u00eancia dos clientes, as opera\u00e7\u00f5es e leitura podem ser direcionadas \u00e0 mesma r\u00e9plica ou a quaisquer das r\u00e9plicas.","title":"\u00danico Escritor"},{"location":"fault/replication/#primariosecundario","text":"Nos foquemos na raiz do problema que aparentemente \u00e9 a ordena\u00e7\u00e3o das opera\u00e7\u00f5es. Se cada processo pode receber as mensagens em qualquer ordem, ou seja, cada uma tem uma fila de mensagens independente, ent\u00e3o as r\u00e9plicas podem chegar a estados distintos. Mas e se tiv\u00e9ssemos uma fila \u00fanica? No caso da replica\u00e7\u00e3o prim\u00e1rio/c\u00f3pia , 2 o prim\u00e1rio \u00e9 respons\u00e1vel por lidar com clientes e por informar c\u00f3pias das modifica\u00e7\u00f5es de estado, efetivamente mantendo a fila \u00fanica e impondo uma ordena\u00e7\u00e3o de opera\u00e7\u00f5es que faz sentido, correspondendo a ordem de entrega das mensagens. Algumas observa\u00e7\u00f5es s\u00e3o importantes sobre a forma como as opera\u00e7\u00f5es s\u00e3o repassadas para as r\u00e9plicas aqui.","title":"Prim\u00e1rio/Secund\u00e1rio"},{"location":"fault/replication/#replicacao-em-cadeia","text":"A replica\u00e7\u00e3o em cadeia \u00e9 uma generaliza\u00e7\u00e3o de prim\u00e1rio/c\u00f3pia em que os processos se organizam em um sequ\u00eancia para executar opera\u00e7\u00f5es. Como na abordagem original, atualiza\u00e7\u00f5es no sistema s\u00e3o sempre direcionadas ao prim\u00e1rio , a cabe\u00e7a da sequ\u00eancia. Leituras , se absolutamente necessitarem dos dados escritos mais recentemente, tamb\u00e9m devem ser direcionadas \u00e0 cabe\u00e7a . Caso contr\u00e1rio, podem ser direcionadas aos processos na cauda , diminuindo a carga de trabalho na cabe\u00e7a; quanto mais relaxado for a exig\u00eancia de \"frescor\" dos dados, mais para o fim da cauda a requisi\u00e7\u00e3o pode ser enviada.","title":"Replica\u00e7\u00e3o em Cadeia"},{"location":"fault/replication/#lidando-com-falhas","text":"Em abordagens baseadas em um prim\u00e1rio, um passo essencial \u00e9 identificar as falhas do processo prim\u00e1rio para ativar um backup para que tome seu lugar. Nesta situa\u00e7\u00e3o, o primeiro desafio est\u00e1 em identificar a falha. Como j\u00e1 mencionamos e ainda iremos discutir, identificar corretamente a falha de um processo em um ambiente onde a comunica\u00e7\u00e3o acontece por troca de mensagens e ass\u00edncrono \u00e9 imposs\u00edvel, pois n\u00e3o se pode diferenciar um processo falho de um lento. Mesmo que a identifica\u00e7\u00e3o fosse perfeita, ainda temos o problema das opera\u00e7\u00f5es que j\u00e1 foram entregues para o prim\u00e1rio mas que ainda n\u00e3o foram propagadas para as r\u00e9plicas. Quanto o backup assume, ele ter\u00e1 ent\u00e3o um estado que est\u00e1 no passado do estado o prim\u00e1rio, o que pode levar comportamento inaceit\u00e1vel. Se este for o caso, replica\u00e7\u00e3o ativa pode ser usada.","title":"Lidando com falhas"},{"location":"fault/replication/#replicacao-ativa","text":"No caso da replica\u00e7\u00e3o ativa, as v\u00e1rias c\u00f3pias executam todos os comandos enviados para o sistema, estando assim todas aptas a continuar a executar o servi\u00e7o a qualquer instante, pelo menos se as opera\u00e7\u00f5es de leitura forem enfileiradas tamb\u00e9m, ou poderiam chegar a uma r\u00e9plica antes de uma escrita disparada anteriormente. A t\u00e9cnica de replica\u00e7\u00e3o de m\u00e1quinas de estados , brevemente discutida anteriormente \u00e9 uma materializa\u00e7\u00e3o da replica\u00e7\u00e3o ativa. Como vimos anteriormente, replica\u00e7\u00e3o de m\u00e1quinas de estados utiliza primitivas de comunica\u00e7\u00e3o em grupo, mas as primitivas vistas anteriormente n\u00e3o s\u00e3o funcionais principalmente por n\u00e3o serem tolerantes a falhas. Vejamos a porqu\u00ea \u00e9 dif\u00edcil desenvolver primitivas tolerantes a falhas.","title":"Replica\u00e7\u00e3o ativa"},{"location":"fault/replication/#event-sourcing","text":"TODO Relacionar primitivas de comunica\u00e7\u00e3o com filas de mensagem Relacionar filas de mensagens com um log Relacionar log com event sourcing e stream processing Usar time warp como exemplo (Jefferson 1985) Usar Kafka como exemplo Eventual , no ingl\u00eas, quer dizer que algo vai acontecer, embora n\u00e3o se saiba quando. \u21a9 Esta t\u00e9cnica tamb\u00e9m \u00e9 conhecida como mestre/escravo , mas esta nomenclatura tem ca\u00eddo em desuso por raz\u00f5es \u00f3bvias. \u21a9","title":"Event sourcing"},{"location":"models/","text":"Introdu\u00e7\u00e3o Agora que j\u00e1 est\u00e3o convencidos de que n\u00e3o temos alternativas \u00e0 distribui\u00e7\u00e3o, conhecem algumas das arquiteturas algumas das tecnologias usadas, vamos dar um passo para tr\u00e1s e para entendermos os fundamentos necess\u00e1rios \u00e0 cria\u00e7\u00e3o de sistemas escal\u00e1veis e tolerantes a falhas. Comecemos por consider um problema abstrato, que pode ser mapeado para um problema de computa\u00e7\u00e3o distribu\u00edda. Uma hist\u00f3ria de tr\u00eas ex\u00e9rcitos Era uma vez uma cidade estado no alto de uma montanha. A despeito de sofrer de falta de \u00e1gua, afinal, estava no alto de uma montanha, a cidade era invejada pelos vizinhos. Como a cidade era muito bem fortificada, ela poderia se defender de qualquer ataque em uma \u00fanica frente . Se atacada em duas frentes , contudo, cairia. Sabendo disso, o rei de uma das cidades vizinhas resolveu tomar a cidade e repartiu suas for\u00e7as em dois ex\u00e9rcitos sob o comando de Alice (a sociedade era feminista) e Basti\u00e3o (sim, Basti\u00e3o, n\u00e3o Bob). 1 Um complicador no ataque \u00e9 que a comunica\u00e7\u00e3o entre os dois ex\u00e9rcitos \u00e9 feita por mensageiros que devem contornar a montanha para alcan\u00e7ar o outro ex\u00e9rcito. O trajeto \u00e9 complexo e cheio de armadilhas e por isso mensageiros podem se perder e demorar um longo tempo para chegar ou at\u00e9 mesmo serem mortos e nunca entregarem suas mensagens. Alice, a comandante mais s\u00eanior, deve decidir quando atacar e informar a Basti\u00e3o, por exemplo, simplesmente ordenando \" Atacar no dia 3, ao nascer do sol. \" Basti\u00e3o obedecer\u00e1 a ordem de atacar contanto que esteja certo de que Alice tamb\u00e9m atacar\u00e1, e \u00e9 justamente da\u00ed que vem a dificuldade do problema. Se mensagens podem ser perdidas, Alice n\u00e3o tem garantias de que Basti\u00e3o recebeu o comando e por isso n\u00e3o pode simplesmente considerar como certo o ataque de Basti\u00e3o. Como o problema pode ser resolvido? Uma resposta natural \u00e9 usar mensagens de confirma\u00e7\u00e3o . Isto \u00e9, quando Basti\u00e3o recebe uma ordem, envia um mensageiro de volta para Alice com uma confirma\u00e7\u00e3o da recep\u00e7\u00e3o. Alice ao receber tal mensagem, sabe que Basti\u00e3o executar\u00e1 a ordem, correto? Mas n\u00e3o \u00e9 t\u00e3o simples assim no caso da ordem de atacar. Lembre-se que qualquer ex\u00e9rcito que ataque sozinho, perder\u00e1, seja Alice ou Basti\u00e3o. Por isso, ao enviar uma mensagem de confirma\u00e7\u00e3o do ataque, Basti\u00e3o precisa estar certo de que Alice a recebeu, ou atacar\u00e1 sozinho. Novamente podemos apelar para uma mensagem de confirma\u00e7\u00e3o ou, neste caso, uma confirma\u00e7\u00e3o da confirma\u00e7\u00e3o. E o problema se repete indefinidamente. Paradoxo dos 2 Ex\u00e9rcitos \\(A\\) e \\(B\\) devem concordar na hora do ataque. \\(A\\) ataca se estiver certo que \\(B\\) atacar\u00e1. \\(B\\) ataca se estiver certo que \\(A\\) atacar\u00e1. A comunica\u00e7\u00e3o por troca de mensagens. Mensagens podem ser arbitrariamente atrasadas. Mensagens podem ser perdidas. Como um ex\u00e9rcito tem certeza que o outro ir\u00e1 atacar? Suponhamos que h\u00e1 um algoritmo correto que executa uma sequ\u00eancia finita de troca de mensagens em que ao final tanto Alice quanto Basti\u00e3o est\u00e3o seguros, e corretos em sua seguran\u00e7a, de que o outro tamb\u00e9m atacar\u00e1. Seja \\(n\\) o n\u00famero m\u00e1ximo de mensagens trocadas. Em uma execu\u00e7\u00e3o em que todas as \\(n\\) mensagens poss\u00edveis s\u00e3o usadas, suponha sem perda de generalidade que Alice enviou a \\(n\\) -\u00e9sima mensagem. Observe que, do ponto de vista de Alice, uma execu\u00e7\u00e3o do algoritmo em que a nenhuma mensagem \u00e9 perdida, \u00e9 indistingu\u00edvel de uma execu\u00e7\u00e3o em que a \\(n\\) -\u00e9sima mensagem \u00e9 perdida. Dado que ao final da primeira execu\u00e7\u00e3o completa Alice ataca , no final da execu\u00e7\u00e3o onde a mensagem \\(n\\) \u00e9 perdida, Alice tamb\u00e9m deve atacar. Mas se o algoritmo \u00e9 correto, ent\u00e3o tamb\u00e9m Basti\u00e3o ataca , mesmo sem ter recebido a en\u00e9sima mensagem. Logo, a en\u00e9sima mensagem \u00e9 desnecess\u00e1ria ao algoritmo, que deve funcionar com \\(n-1\\) mensagens. Repetindo-se o argumento mais \\(n-1\\) vezes, temos que o algoritmo deve funcionar com zero mensagens, o que \u00e9 um absurdo . Logo n\u00e3o existem algoritmos corretos para o problema como definido, isto \u00e9, em que mensagens podem ser perdidas; \u00e9 imposs\u00edvel resolver o problema. Impossibilidades Impossibilidade de resolu\u00e7\u00e3o x resolu\u00e7\u00e3o na pr\u00e1tica. Apesar de ser imposs\u00edvel resolver este problema aparentemente simples, devemos faz\u00ea-lo frequentemente no mundo real. A resposta est\u00e1 no que consideramos como premissas v\u00e1lidas no ambiente em que tentamos solucionar o problema e quais exatamente s\u00e3o as propriedades de uma solu\u00e7\u00e3o aceit\u00e1vel. Impossibilidades Quando dizemos que \u00e9 imposs\u00edvel resolver um problema n\u00e3o queremos dizer que \u00e9 imposs\u00edvel resolver o problem em quaisquer circunst\u00e2ncias, mas apenas nas circunst\u00e2ncias nas quais a prova foi feita. No caso do exemplo anterior, a impossibilidade implica que \u00e9 imposs\u00edvel produzir um algoritmo que sempre levar\u00e1 a uma resposta correta com um n\u00famero finito de mensagens, como havia sido assumido. Isto quer dizer, excluindo-se algoritmos que sempre levar\u00e3o a respostas incorretas, ainda podemos produzir algoritmos que ou \u00e0s vezes levar\u00e3o a respostas incorretas ou que, mesmo que nunca levem a respostas incorretas, \u00e0s vezes n\u00e3o levar\u00e3o a respostas alguma; ambos podem ser \u00fateis na pr\u00e1tica. Por exemplo, ainda no problema dos tr\u00eas ex\u00e9rcitos tentando tomar a cidade, suponha que em vez de mandar um \u00fanico mensageiro com a ordem de ataque, Alice envie 100, ou 200, ou 1000. A confian\u00e7a de Alice de que Basti\u00e3o tamb\u00e9m atacaria, seria muito maior e n\u00e3o precisaria receber uma confirma\u00e7\u00e3o de entrega de mensagens. Esta abordagem faria com com que o ataque funcionasse com uma alta probabilidade \\(P\\) , mas com uma pequena probabilidade \\(P-1\\) de levar a um ataque fracassado, onde \\(P\\) pode ser feita t\u00e3o grande quanto se \"queira\" . Resultados de impossibilidade abundam na \u00e1rea de computa\u00e7\u00e3o distribu\u00edda 2 e n\u00e3o podem nos desencorajar de continuar a buscar solu\u00e7\u00f5es pr\u00e1ticas. Frequentemente a solu\u00e7\u00e3o est\u00e1 em identificar premissas mais \"amig\u00e1veis\" que possam ser assumidas e, com isso, enfraquecer o problema. Esta \u00e9 uma varia\u00e7\u00e3o do problema de coordena\u00e7\u00e3o de gangsters apresentado no em Some constraints and trade-offs in the design of network communications \u21a9 Hundred Impossibility Proofs for Distributed Computing , Impossibility Results for Distributed Computing \u21a9","title":"Introdu\u00e7\u00e3o"},{"location":"models/#introducao","text":"Agora que j\u00e1 est\u00e3o convencidos de que n\u00e3o temos alternativas \u00e0 distribui\u00e7\u00e3o, conhecem algumas das arquiteturas algumas das tecnologias usadas, vamos dar um passo para tr\u00e1s e para entendermos os fundamentos necess\u00e1rios \u00e0 cria\u00e7\u00e3o de sistemas escal\u00e1veis e tolerantes a falhas. Comecemos por consider um problema abstrato, que pode ser mapeado para um problema de computa\u00e7\u00e3o distribu\u00edda.","title":"Introdu\u00e7\u00e3o"},{"location":"models/#uma-historia-de-tres-exercitos","text":"Era uma vez uma cidade estado no alto de uma montanha. A despeito de sofrer de falta de \u00e1gua, afinal, estava no alto de uma montanha, a cidade era invejada pelos vizinhos. Como a cidade era muito bem fortificada, ela poderia se defender de qualquer ataque em uma \u00fanica frente . Se atacada em duas frentes , contudo, cairia. Sabendo disso, o rei de uma das cidades vizinhas resolveu tomar a cidade e repartiu suas for\u00e7as em dois ex\u00e9rcitos sob o comando de Alice (a sociedade era feminista) e Basti\u00e3o (sim, Basti\u00e3o, n\u00e3o Bob). 1 Um complicador no ataque \u00e9 que a comunica\u00e7\u00e3o entre os dois ex\u00e9rcitos \u00e9 feita por mensageiros que devem contornar a montanha para alcan\u00e7ar o outro ex\u00e9rcito. O trajeto \u00e9 complexo e cheio de armadilhas e por isso mensageiros podem se perder e demorar um longo tempo para chegar ou at\u00e9 mesmo serem mortos e nunca entregarem suas mensagens. Alice, a comandante mais s\u00eanior, deve decidir quando atacar e informar a Basti\u00e3o, por exemplo, simplesmente ordenando \" Atacar no dia 3, ao nascer do sol. \" Basti\u00e3o obedecer\u00e1 a ordem de atacar contanto que esteja certo de que Alice tamb\u00e9m atacar\u00e1, e \u00e9 justamente da\u00ed que vem a dificuldade do problema. Se mensagens podem ser perdidas, Alice n\u00e3o tem garantias de que Basti\u00e3o recebeu o comando e por isso n\u00e3o pode simplesmente considerar como certo o ataque de Basti\u00e3o. Como o problema pode ser resolvido? Uma resposta natural \u00e9 usar mensagens de confirma\u00e7\u00e3o . Isto \u00e9, quando Basti\u00e3o recebe uma ordem, envia um mensageiro de volta para Alice com uma confirma\u00e7\u00e3o da recep\u00e7\u00e3o. Alice ao receber tal mensagem, sabe que Basti\u00e3o executar\u00e1 a ordem, correto? Mas n\u00e3o \u00e9 t\u00e3o simples assim no caso da ordem de atacar. Lembre-se que qualquer ex\u00e9rcito que ataque sozinho, perder\u00e1, seja Alice ou Basti\u00e3o. Por isso, ao enviar uma mensagem de confirma\u00e7\u00e3o do ataque, Basti\u00e3o precisa estar certo de que Alice a recebeu, ou atacar\u00e1 sozinho. Novamente podemos apelar para uma mensagem de confirma\u00e7\u00e3o ou, neste caso, uma confirma\u00e7\u00e3o da confirma\u00e7\u00e3o. E o problema se repete indefinidamente. Paradoxo dos 2 Ex\u00e9rcitos \\(A\\) e \\(B\\) devem concordar na hora do ataque. \\(A\\) ataca se estiver certo que \\(B\\) atacar\u00e1. \\(B\\) ataca se estiver certo que \\(A\\) atacar\u00e1. A comunica\u00e7\u00e3o por troca de mensagens. Mensagens podem ser arbitrariamente atrasadas. Mensagens podem ser perdidas. Como um ex\u00e9rcito tem certeza que o outro ir\u00e1 atacar? Suponhamos que h\u00e1 um algoritmo correto que executa uma sequ\u00eancia finita de troca de mensagens em que ao final tanto Alice quanto Basti\u00e3o est\u00e3o seguros, e corretos em sua seguran\u00e7a, de que o outro tamb\u00e9m atacar\u00e1. Seja \\(n\\) o n\u00famero m\u00e1ximo de mensagens trocadas. Em uma execu\u00e7\u00e3o em que todas as \\(n\\) mensagens poss\u00edveis s\u00e3o usadas, suponha sem perda de generalidade que Alice enviou a \\(n\\) -\u00e9sima mensagem. Observe que, do ponto de vista de Alice, uma execu\u00e7\u00e3o do algoritmo em que a nenhuma mensagem \u00e9 perdida, \u00e9 indistingu\u00edvel de uma execu\u00e7\u00e3o em que a \\(n\\) -\u00e9sima mensagem \u00e9 perdida. Dado que ao final da primeira execu\u00e7\u00e3o completa Alice ataca , no final da execu\u00e7\u00e3o onde a mensagem \\(n\\) \u00e9 perdida, Alice tamb\u00e9m deve atacar. Mas se o algoritmo \u00e9 correto, ent\u00e3o tamb\u00e9m Basti\u00e3o ataca , mesmo sem ter recebido a en\u00e9sima mensagem. Logo, a en\u00e9sima mensagem \u00e9 desnecess\u00e1ria ao algoritmo, que deve funcionar com \\(n-1\\) mensagens. Repetindo-se o argumento mais \\(n-1\\) vezes, temos que o algoritmo deve funcionar com zero mensagens, o que \u00e9 um absurdo . Logo n\u00e3o existem algoritmos corretos para o problema como definido, isto \u00e9, em que mensagens podem ser perdidas; \u00e9 imposs\u00edvel resolver o problema. Impossibilidades Impossibilidade de resolu\u00e7\u00e3o x resolu\u00e7\u00e3o na pr\u00e1tica. Apesar de ser imposs\u00edvel resolver este problema aparentemente simples, devemos faz\u00ea-lo frequentemente no mundo real. A resposta est\u00e1 no que consideramos como premissas v\u00e1lidas no ambiente em que tentamos solucionar o problema e quais exatamente s\u00e3o as propriedades de uma solu\u00e7\u00e3o aceit\u00e1vel.","title":"Uma hist\u00f3ria de tr\u00eas ex\u00e9rcitos"},{"location":"models/#impossibilidades","text":"Quando dizemos que \u00e9 imposs\u00edvel resolver um problema n\u00e3o queremos dizer que \u00e9 imposs\u00edvel resolver o problem em quaisquer circunst\u00e2ncias, mas apenas nas circunst\u00e2ncias nas quais a prova foi feita. No caso do exemplo anterior, a impossibilidade implica que \u00e9 imposs\u00edvel produzir um algoritmo que sempre levar\u00e1 a uma resposta correta com um n\u00famero finito de mensagens, como havia sido assumido. Isto quer dizer, excluindo-se algoritmos que sempre levar\u00e3o a respostas incorretas, ainda podemos produzir algoritmos que ou \u00e0s vezes levar\u00e3o a respostas incorretas ou que, mesmo que nunca levem a respostas incorretas, \u00e0s vezes n\u00e3o levar\u00e3o a respostas alguma; ambos podem ser \u00fateis na pr\u00e1tica. Por exemplo, ainda no problema dos tr\u00eas ex\u00e9rcitos tentando tomar a cidade, suponha que em vez de mandar um \u00fanico mensageiro com a ordem de ataque, Alice envie 100, ou 200, ou 1000. A confian\u00e7a de Alice de que Basti\u00e3o tamb\u00e9m atacaria, seria muito maior e n\u00e3o precisaria receber uma confirma\u00e7\u00e3o de entrega de mensagens. Esta abordagem faria com com que o ataque funcionasse com uma alta probabilidade \\(P\\) , mas com uma pequena probabilidade \\(P-1\\) de levar a um ataque fracassado, onde \\(P\\) pode ser feita t\u00e3o grande quanto se \"queira\" . Resultados de impossibilidade abundam na \u00e1rea de computa\u00e7\u00e3o distribu\u00edda 2 e n\u00e3o podem nos desencorajar de continuar a buscar solu\u00e7\u00f5es pr\u00e1ticas. Frequentemente a solu\u00e7\u00e3o est\u00e1 em identificar premissas mais \"amig\u00e1veis\" que possam ser assumidas e, com isso, enfraquecer o problema. Esta \u00e9 uma varia\u00e7\u00e3o do problema de coordena\u00e7\u00e3o de gangsters apresentado no em Some constraints and trade-offs in the design of network communications \u21a9 Hundred Impossibility Proofs for Distributed Computing , Impossibility Results for Distributed Computing \u21a9","title":"Impossibilidades"},{"location":"models/models/","text":"Modelos Dado a quantidade de ambientes reais em que as solu\u00e7\u00f5es dos nossos problemas abstratos precisam executar, com sua diversidade de sistemas operacionais, lat\u00eancias de rede, tamanhos de mensagens, etc, seria praticamente imposs\u00edvel provar alguma coisa geral e interessante sobre os algoritmos, como por exemplo se ele funciona . Por isso, em vez de considerar cada ambiente espec\u00edfico, abstra\u00edmos os ambientes por meio de modelos computacionais , que capturam as premissas gerais dos ambientes, e s\u00f3 ent\u00e3o escrevemos os algoritmos para tais modelos. Isso que dizer que, na pr\u00e1tica, antes de distribuir a computa\u00e7\u00e3o/armazenamento em diversas m\u00e1quinas e de forma a coordenar a\u00e7\u00f5es das diversas partes de forma a entregar o servi\u00e7o de acordo com expectativas dos usu\u00e1rios, precisamos responder a algumas perguntas, como por exemplo: Qual a probabilidade de um n\u00f3 parar de funcionar? Como os n\u00f3s se comunicam? Eles compartilham um espa\u00e7o de endere\u00e7amento ou enviam mensagens uns para os outros? A quais atrasos a comunica\u00e7\u00e3o est\u00e1 sujeita? Pode haver atrasos infinitos? A comunica\u00e7\u00e3o pode ser corrompida? Os rel\u00f3gios dos hospedeiros marcam o mesmo valor no mesmo instante, ou melhor, s\u00e3o sincronizados? H\u00e1 agentes que possam querer perturbar o sistema, por exemplo para ganhar acesso a mais recursos do que seria justo? Modelos Comunica\u00e7\u00e3o Sincronismo Falhas Estas perguntas s\u00e3o normalmente divididas em tr\u00eas eixos, Comunica\u00e7\u00e3o , Sincronismo e Falhas , e a combina\u00e7\u00e3o das respostas define o modelo computacional adotado. Comunica\u00e7\u00e3o De uma forma ou de outra, sistemas distribu\u00eddos tem \u00e0 sua disposi\u00e7\u00e3o m\u00faltiplos processadores e permitem o desenvolvimento de aplica\u00e7\u00f5es paralelas, isto \u00e9, onde m\u00faltiplas tarefas s\u00e3o executadas ao mesmo tempo ou paralelamente . Contudo, por um lado, quando falamos em sistemas multiprocessados, normalmente estamos falando de sistemas em que os processadores est\u00e3o pr\u00f3ximos e compartilham um mesmo espa\u00e7o de endere\u00e7amento, sejam computadores com m\u00faltiplos processadores ou sejam clusters de computadores conectados por um barramento de comunica\u00e7\u00e3o de alt\u00edssima largura de banda, como Infiniband que abstraiam m\u00faltiplos segmentos de mem\u00f3ria como um \u00fanico espa\u00e7o de endere\u00e7amento. Seja como for, estes sistemas com mem\u00f3ria compartilhada s\u00e3o normalmente usados para aplica\u00e7\u00f5es de computa\u00e7\u00e3o intensiva e em cujo os componentes s\u00e3o mais fortemente acoplados e melhor estudados em um curso de computa\u00e7\u00e3o paralela. Comunica\u00e7\u00e3o mem\u00f3ria compartilhada troca de mensagens Por outro lado, estamos mais interessados aqui em sistemas de maior escala geogr\u00e1fica, o que se adequa melhor ao modelo de troca de mensagens, isto \u00e9, onde cada n\u00f3 mantem controle total do seu espa\u00e7o de endere\u00e7amento e s\u00f3 exp\u00f5e seu estado via mensagens enviadas para os outros n\u00f3s. Este modelo \u00e9 mais adequado ao desenvolvimento de aplica\u00e7\u00f5es com componentes fracamente acoplados , em que atrasos de comunica\u00e7\u00e3o e ocorr\u00eancia de falhas independentes s\u00e3o intr\u00ednsecas. Mem\u00f3ria Compartilhada Distribu\u00edda (DSM, do ingl\u00eas, Distributed Shared Memory ) \u00e9 uma abordagem h\u00edbrida que tenta integrar a facilidade de se programar usando um \u00fanico espa\u00e7o de endere\u00e7amento mas com o n\u00edvel de distribui\u00e7\u00e3o necess\u00e1ria a aplica\u00e7\u00f5es de larga escala, inclusive geogr\u00e1fica. Considere uma poss\u00edvel implementa\u00e7\u00e3o em software da DSM, apresentada na pr\u00f3xima figura. Nesta abordagem, cada host contribui uma por\u00e7\u00e3o de sua mem\u00f3ria para um pool global. Processos acessam o pool via gerentes de mem\u00f3ria , que traduzem os endere\u00e7os de um espa\u00e7o de endere\u00e7amento virtual para um host e um endere\u00e7o local a tal host, e usam message passing para implementar o acesso. Esta abordagem resulta em uma arquitetura NUMA, isto \u00e9, Non-Uniform Memory Access , j\u00e1 que os acessos a endere\u00e7os locais s\u00e3o mais r\u00e1pidos que aos remotos. O modelo de comunica\u00e7\u00e3o usado no problema dos 3 ex\u00e9rcitos \u00e9 claramente de passagem de mensagens. Sincronismo Sincronismo opera\u00e7\u00f5es comunica\u00e7\u00e3o rel\u00f3gio sincroniza\u00e7\u00e3o Quanto ao sincronismo, considera-se se os processos tem a capacidade de medir a passagem de tempo , isto \u00e9, se tem a acesso a rel\u00f3gios, o qu\u00e3o acurazes este s\u00e3o e o qu\u00e3o sincronizados s\u00e3o estes rel\u00f3gios uns com os outros. No problema dos tr\u00eas ex\u00e9rcitos, podemos considerar que amos os atacantes tinha acesso a um rel\u00f3gio perfeitamente sincronizado, bastando olhar para o c\u00e9u para ver o hor\u00e1rio. Claramente enquanto varia\u00e7\u00f5es na ordem de v\u00e1rios minutos ou at\u00e9 mesmo uma hora na leitura de um rel\u00f3gio solar n\u00e3o teriam grande impacto na vida dos ex\u00e9rcitos, alguns sistemas computacionais podem exigir que os rel\u00f3gios de seus componentes n\u00e3o distem mais que alguns milissegundos. Revisitaremos este t\u00f3pico em uma se\u00e7\u00e3o espec\u00edfica sobre Tempo . Al\u00e9m do acesso a rel\u00f3gios, considera-se no modelo de sincronismo a exist\u00eancia ou n\u00e3o de limites de tempo para execu\u00e7\u00e3o de opera\u00e7\u00f5es, por exemplo, quanto tempo um processador leva para executar uma opera\u00e7\u00e3o de soma de dois inteiros, ou quanto tempo \u00e9 necess\u00e1rio para a entrega de uma mensagem enviada na rede. Falhas Quanto \u00e0s falhas, primeiro \u00e9 preciso aceitar o fato de que componentes independentes podem falhar independentemente e que quanto mais hosts , maior \u00e9 a probabilidade de que pelo menos um deles tenha uma CPU, disco, fonte, ou que quer que seja, apresentando problemas; e estejam certos, problemas acontecem o tempo todo. 1 Isto \u00e9 importante pois se em sistemas monol\u00edticos uma falha pode facilmente fazer com que o sistema todo pare e, portanto, n\u00e3o tente progredir na aus\u00eancia de um componente essencial, em um sistema distribu\u00eddo queremos exatamente o contr\u00e1rio, isto \u00e9, que apesar da falha de um componente, os outros continuem prestando o servi\u00e7o, mesmo de forma deteriorada, mas sem comprometer a corretude do sistema. Falhas detect\u00e1vel temporiza\u00e7\u00e3o quebras maliciosas perda e corrup\u00e7\u00e3o de mensagens Para lidar com falhas, precisamos entender quais s\u00e3o suas poss\u00edveis formas, isto \u00e9, se o levam componentes falhos a parar de funcionar totalmente e de forma identific\u00e1vel por outros ou n\u00e3o, se h\u00e1 falhas \"maliciosas\", se os limites de tempo estabelecidos acima podem ser violados, se mensagens podem ser perdidas ou corrompidas. Revisitaremos este t\u00f3pico na sess\u00e3o Toler\u00e2ncia a Faltas . Modelo Assumido Outros carga de trabalho Embora modelos cl\u00e1ssicos sejam normalmente definidos em termos dos fatores acima, outras quest\u00f5es s\u00e3o tamb\u00e9m importantes, como o padr\u00e3o da carga de trabalho do sistema (maior carga \u00e0 noite? Na hora do almo\u00e7o? Black friday ?). Al\u00e9m de ignorarmos estes outros fatores, por enquanto assumiremos um modelo computacional amig\u00e1vel, com comunica\u00e7\u00e3o por troca de mensagens, rel\u00f3gios e limites de tempo para opera\u00e7\u00f5es, mesmo que desconhecidos. Tamb\u00e9m assumiremos aus\u00eancia de falhas, a n\u00e3o ser quando quisermos provocar a an\u00e1lise de situa\u00e7\u00f5es mais interessantes. Este modelo ser\u00e1 ajustado na medida em que avan\u00e7armos, para tornar nossas an\u00e1lises mais realistas. SD s\u00e3o como cebolas! Uma vez definido o modelo computacional e identificado os algoritmos adequados aos problemas que queremos resolver, passamos \u00e0 implementa\u00e7\u00e3o. Distribuir \u00e9 dividir a computa\u00e7\u00e3o/armazenamento em diversos componentes, possivelmente geograficamente distantes , e coordenar suas a\u00e7\u00f5es para que resolvam a tarefa em quest\u00e3o de forma correta. Com a distribui\u00e7\u00e3o objetiva-se usar recursos dispon\u00edveis nos hosts onde os componentes s\u00e3o executados 2 e usar de redund\u00e2ncia para garantir que o servi\u00e7o sofra degrada\u00e7\u00e3o graciosa em caso de falhas, ou seja, fazer com que o servi\u00e7o continue funcionando, mesmo que com vaz\u00e3o reduzida , lat\u00eancia aumentada , menor capacidade de tratamento de requisi\u00e7\u00f5es concorrentes, ou com funcionalidades desabilitadas . Abstra\u00e7\u00f5es Comunica\u00e7\u00e3o Ordena\u00e7\u00e3o Confiabilidade Invoca\u00e7\u00e3o de procedimentos remotos Heterogeneidade Linguagens Arquiteturas Sistemas Operacionais Times Para colaborar, as diversas partes do sistema distribu\u00eddo devem se comunicar, o que pode pode ser feito de diversas formas e em diversos n\u00edveis de abstra\u00e7\u00e3o. Por exemplo, no caso troca de mensagens, estas podem ser desde pacotes de bytes entregues pelo IP/UDP como por troca de mensagens ordenadas, fluxos de dados , ou invoca\u00e7\u00e3o remota de procedimentos . Implementar estas abstra\u00e7\u00f5es em si j\u00e1 \u00e9 uma tarefa complicada, pois \u00e9 preciso levar em considera\u00e7\u00e3o que os componentes de um sistema distribu\u00eddo falham independentemente , executam em hosts com rel\u00f3gios dessincronizados , s\u00e3o desenvolvidos usando-se linguagens diversas , sistemas operacionais distintos , com arquiteturas diferentes e por times independentes . Apesar de tantas vari\u00e1veis, as abstra\u00e7\u00f5es precisam permitir que as aplica\u00e7\u00f5es que as usem possam se coordenar nos m\u00ednimos detalhes. Dado que a complexidade de se implementar estas abstra\u00e7\u00f5es j\u00e1 \u00e9 grande por si s\u00f3, se formos reinventar a roda a cada novo sistema, n\u00e3o faremos muitos avan\u00e7os. Mas, como voc\u00eas bem sabem, camadas de abstra\u00e7\u00e3o s\u00e3o a chave para se lidar com complexidade. Assim, sistemas distribu\u00eddos s\u00e3o como cebolas, cheias de camadas e que nos fazem chorar quando precisamos descasc\u00e1-las. 3 Felizmente, para cada problema que tenha que resolver, h\u00e1 uma boa probabilidade de que algu\u00e9m j\u00e1 o tenha atacado e disponibilizado uma solu\u00e7\u00e3o, de forma comercial ou n\u00e3o. Annual failure rates - servers \u21a9 Os recursos compartilhados v\u00e3o desde alguns \u00f3bvios, como capacidade de armazenamento e de processamento , a pr\u00f3pria localiza\u00e7\u00e3o de um n\u00f3, que pode ser geograficamente mais pr\u00f3xima e de menor lat\u00eancia at\u00e9 um ponto de interesse, ou at\u00e9 mesmo a disponibilidade de uma conex\u00e3o f\u00edsica com um recurso especial, como uma impressora. \u21a9 Lembrem-se que tamb\u00e9m e voc\u00ea n\u00e3o quer que seu sistema seja como ogros, temperamentais e mal-cheirosos. Logo, planeje bem suas camadas de abstra\u00e7\u00e3o. \u21a9","title":"Tipos"},{"location":"models/models/#modelos","text":"Dado a quantidade de ambientes reais em que as solu\u00e7\u00f5es dos nossos problemas abstratos precisam executar, com sua diversidade de sistemas operacionais, lat\u00eancias de rede, tamanhos de mensagens, etc, seria praticamente imposs\u00edvel provar alguma coisa geral e interessante sobre os algoritmos, como por exemplo se ele funciona . Por isso, em vez de considerar cada ambiente espec\u00edfico, abstra\u00edmos os ambientes por meio de modelos computacionais , que capturam as premissas gerais dos ambientes, e s\u00f3 ent\u00e3o escrevemos os algoritmos para tais modelos. Isso que dizer que, na pr\u00e1tica, antes de distribuir a computa\u00e7\u00e3o/armazenamento em diversas m\u00e1quinas e de forma a coordenar a\u00e7\u00f5es das diversas partes de forma a entregar o servi\u00e7o de acordo com expectativas dos usu\u00e1rios, precisamos responder a algumas perguntas, como por exemplo: Qual a probabilidade de um n\u00f3 parar de funcionar? Como os n\u00f3s se comunicam? Eles compartilham um espa\u00e7o de endere\u00e7amento ou enviam mensagens uns para os outros? A quais atrasos a comunica\u00e7\u00e3o est\u00e1 sujeita? Pode haver atrasos infinitos? A comunica\u00e7\u00e3o pode ser corrompida? Os rel\u00f3gios dos hospedeiros marcam o mesmo valor no mesmo instante, ou melhor, s\u00e3o sincronizados? H\u00e1 agentes que possam querer perturbar o sistema, por exemplo para ganhar acesso a mais recursos do que seria justo? Modelos Comunica\u00e7\u00e3o Sincronismo Falhas Estas perguntas s\u00e3o normalmente divididas em tr\u00eas eixos, Comunica\u00e7\u00e3o , Sincronismo e Falhas , e a combina\u00e7\u00e3o das respostas define o modelo computacional adotado.","title":"Modelos"},{"location":"models/models/#comunicacao","text":"De uma forma ou de outra, sistemas distribu\u00eddos tem \u00e0 sua disposi\u00e7\u00e3o m\u00faltiplos processadores e permitem o desenvolvimento de aplica\u00e7\u00f5es paralelas, isto \u00e9, onde m\u00faltiplas tarefas s\u00e3o executadas ao mesmo tempo ou paralelamente . Contudo, por um lado, quando falamos em sistemas multiprocessados, normalmente estamos falando de sistemas em que os processadores est\u00e3o pr\u00f3ximos e compartilham um mesmo espa\u00e7o de endere\u00e7amento, sejam computadores com m\u00faltiplos processadores ou sejam clusters de computadores conectados por um barramento de comunica\u00e7\u00e3o de alt\u00edssima largura de banda, como Infiniband que abstraiam m\u00faltiplos segmentos de mem\u00f3ria como um \u00fanico espa\u00e7o de endere\u00e7amento. Seja como for, estes sistemas com mem\u00f3ria compartilhada s\u00e3o normalmente usados para aplica\u00e7\u00f5es de computa\u00e7\u00e3o intensiva e em cujo os componentes s\u00e3o mais fortemente acoplados e melhor estudados em um curso de computa\u00e7\u00e3o paralela. Comunica\u00e7\u00e3o mem\u00f3ria compartilhada troca de mensagens Por outro lado, estamos mais interessados aqui em sistemas de maior escala geogr\u00e1fica, o que se adequa melhor ao modelo de troca de mensagens, isto \u00e9, onde cada n\u00f3 mantem controle total do seu espa\u00e7o de endere\u00e7amento e s\u00f3 exp\u00f5e seu estado via mensagens enviadas para os outros n\u00f3s. Este modelo \u00e9 mais adequado ao desenvolvimento de aplica\u00e7\u00f5es com componentes fracamente acoplados , em que atrasos de comunica\u00e7\u00e3o e ocorr\u00eancia de falhas independentes s\u00e3o intr\u00ednsecas. Mem\u00f3ria Compartilhada Distribu\u00edda (DSM, do ingl\u00eas, Distributed Shared Memory ) \u00e9 uma abordagem h\u00edbrida que tenta integrar a facilidade de se programar usando um \u00fanico espa\u00e7o de endere\u00e7amento mas com o n\u00edvel de distribui\u00e7\u00e3o necess\u00e1ria a aplica\u00e7\u00f5es de larga escala, inclusive geogr\u00e1fica. Considere uma poss\u00edvel implementa\u00e7\u00e3o em software da DSM, apresentada na pr\u00f3xima figura. Nesta abordagem, cada host contribui uma por\u00e7\u00e3o de sua mem\u00f3ria para um pool global. Processos acessam o pool via gerentes de mem\u00f3ria , que traduzem os endere\u00e7os de um espa\u00e7o de endere\u00e7amento virtual para um host e um endere\u00e7o local a tal host, e usam message passing para implementar o acesso. Esta abordagem resulta em uma arquitetura NUMA, isto \u00e9, Non-Uniform Memory Access , j\u00e1 que os acessos a endere\u00e7os locais s\u00e3o mais r\u00e1pidos que aos remotos. O modelo de comunica\u00e7\u00e3o usado no problema dos 3 ex\u00e9rcitos \u00e9 claramente de passagem de mensagens.","title":"Comunica\u00e7\u00e3o"},{"location":"models/models/#sincronismo","text":"Sincronismo opera\u00e7\u00f5es comunica\u00e7\u00e3o rel\u00f3gio sincroniza\u00e7\u00e3o Quanto ao sincronismo, considera-se se os processos tem a capacidade de medir a passagem de tempo , isto \u00e9, se tem a acesso a rel\u00f3gios, o qu\u00e3o acurazes este s\u00e3o e o qu\u00e3o sincronizados s\u00e3o estes rel\u00f3gios uns com os outros. No problema dos tr\u00eas ex\u00e9rcitos, podemos considerar que amos os atacantes tinha acesso a um rel\u00f3gio perfeitamente sincronizado, bastando olhar para o c\u00e9u para ver o hor\u00e1rio. Claramente enquanto varia\u00e7\u00f5es na ordem de v\u00e1rios minutos ou at\u00e9 mesmo uma hora na leitura de um rel\u00f3gio solar n\u00e3o teriam grande impacto na vida dos ex\u00e9rcitos, alguns sistemas computacionais podem exigir que os rel\u00f3gios de seus componentes n\u00e3o distem mais que alguns milissegundos. Revisitaremos este t\u00f3pico em uma se\u00e7\u00e3o espec\u00edfica sobre Tempo . Al\u00e9m do acesso a rel\u00f3gios, considera-se no modelo de sincronismo a exist\u00eancia ou n\u00e3o de limites de tempo para execu\u00e7\u00e3o de opera\u00e7\u00f5es, por exemplo, quanto tempo um processador leva para executar uma opera\u00e7\u00e3o de soma de dois inteiros, ou quanto tempo \u00e9 necess\u00e1rio para a entrega de uma mensagem enviada na rede.","title":"Sincronismo"},{"location":"models/models/#falhas","text":"Quanto \u00e0s falhas, primeiro \u00e9 preciso aceitar o fato de que componentes independentes podem falhar independentemente e que quanto mais hosts , maior \u00e9 a probabilidade de que pelo menos um deles tenha uma CPU, disco, fonte, ou que quer que seja, apresentando problemas; e estejam certos, problemas acontecem o tempo todo. 1 Isto \u00e9 importante pois se em sistemas monol\u00edticos uma falha pode facilmente fazer com que o sistema todo pare e, portanto, n\u00e3o tente progredir na aus\u00eancia de um componente essencial, em um sistema distribu\u00eddo queremos exatamente o contr\u00e1rio, isto \u00e9, que apesar da falha de um componente, os outros continuem prestando o servi\u00e7o, mesmo de forma deteriorada, mas sem comprometer a corretude do sistema. Falhas detect\u00e1vel temporiza\u00e7\u00e3o quebras maliciosas perda e corrup\u00e7\u00e3o de mensagens Para lidar com falhas, precisamos entender quais s\u00e3o suas poss\u00edveis formas, isto \u00e9, se o levam componentes falhos a parar de funcionar totalmente e de forma identific\u00e1vel por outros ou n\u00e3o, se h\u00e1 falhas \"maliciosas\", se os limites de tempo estabelecidos acima podem ser violados, se mensagens podem ser perdidas ou corrompidas. Revisitaremos este t\u00f3pico na sess\u00e3o Toler\u00e2ncia a Faltas .","title":"Falhas"},{"location":"models/models/#modelo-assumido","text":"Outros carga de trabalho Embora modelos cl\u00e1ssicos sejam normalmente definidos em termos dos fatores acima, outras quest\u00f5es s\u00e3o tamb\u00e9m importantes, como o padr\u00e3o da carga de trabalho do sistema (maior carga \u00e0 noite? Na hora do almo\u00e7o? Black friday ?). Al\u00e9m de ignorarmos estes outros fatores, por enquanto assumiremos um modelo computacional amig\u00e1vel, com comunica\u00e7\u00e3o por troca de mensagens, rel\u00f3gios e limites de tempo para opera\u00e7\u00f5es, mesmo que desconhecidos. Tamb\u00e9m assumiremos aus\u00eancia de falhas, a n\u00e3o ser quando quisermos provocar a an\u00e1lise de situa\u00e7\u00f5es mais interessantes. Este modelo ser\u00e1 ajustado na medida em que avan\u00e7armos, para tornar nossas an\u00e1lises mais realistas.","title":"Modelo Assumido"},{"location":"models/models/#sd-sao-como-cebolas","text":"Uma vez definido o modelo computacional e identificado os algoritmos adequados aos problemas que queremos resolver, passamos \u00e0 implementa\u00e7\u00e3o. Distribuir \u00e9 dividir a computa\u00e7\u00e3o/armazenamento em diversos componentes, possivelmente geograficamente distantes , e coordenar suas a\u00e7\u00f5es para que resolvam a tarefa em quest\u00e3o de forma correta. Com a distribui\u00e7\u00e3o objetiva-se usar recursos dispon\u00edveis nos hosts onde os componentes s\u00e3o executados 2 e usar de redund\u00e2ncia para garantir que o servi\u00e7o sofra degrada\u00e7\u00e3o graciosa em caso de falhas, ou seja, fazer com que o servi\u00e7o continue funcionando, mesmo que com vaz\u00e3o reduzida , lat\u00eancia aumentada , menor capacidade de tratamento de requisi\u00e7\u00f5es concorrentes, ou com funcionalidades desabilitadas . Abstra\u00e7\u00f5es Comunica\u00e7\u00e3o Ordena\u00e7\u00e3o Confiabilidade Invoca\u00e7\u00e3o de procedimentos remotos Heterogeneidade Linguagens Arquiteturas Sistemas Operacionais Times Para colaborar, as diversas partes do sistema distribu\u00eddo devem se comunicar, o que pode pode ser feito de diversas formas e em diversos n\u00edveis de abstra\u00e7\u00e3o. Por exemplo, no caso troca de mensagens, estas podem ser desde pacotes de bytes entregues pelo IP/UDP como por troca de mensagens ordenadas, fluxos de dados , ou invoca\u00e7\u00e3o remota de procedimentos . Implementar estas abstra\u00e7\u00f5es em si j\u00e1 \u00e9 uma tarefa complicada, pois \u00e9 preciso levar em considera\u00e7\u00e3o que os componentes de um sistema distribu\u00eddo falham independentemente , executam em hosts com rel\u00f3gios dessincronizados , s\u00e3o desenvolvidos usando-se linguagens diversas , sistemas operacionais distintos , com arquiteturas diferentes e por times independentes . Apesar de tantas vari\u00e1veis, as abstra\u00e7\u00f5es precisam permitir que as aplica\u00e7\u00f5es que as usem possam se coordenar nos m\u00ednimos detalhes. Dado que a complexidade de se implementar estas abstra\u00e7\u00f5es j\u00e1 \u00e9 grande por si s\u00f3, se formos reinventar a roda a cada novo sistema, n\u00e3o faremos muitos avan\u00e7os. Mas, como voc\u00eas bem sabem, camadas de abstra\u00e7\u00e3o s\u00e3o a chave para se lidar com complexidade. Assim, sistemas distribu\u00eddos s\u00e3o como cebolas, cheias de camadas e que nos fazem chorar quando precisamos descasc\u00e1-las. 3 Felizmente, para cada problema que tenha que resolver, h\u00e1 uma boa probabilidade de que algu\u00e9m j\u00e1 o tenha atacado e disponibilizado uma solu\u00e7\u00e3o, de forma comercial ou n\u00e3o. Annual failure rates - servers \u21a9 Os recursos compartilhados v\u00e3o desde alguns \u00f3bvios, como capacidade de armazenamento e de processamento , a pr\u00f3pria localiza\u00e7\u00e3o de um n\u00f3, que pode ser geograficamente mais pr\u00f3xima e de menor lat\u00eancia at\u00e9 um ponto de interesse, ou at\u00e9 mesmo a disponibilidade de uma conex\u00e3o f\u00edsica com um recurso especial, como uma impressora. \u21a9 Lembrem-se que tamb\u00e9m e voc\u00ea n\u00e3o quer que seu sistema seja como ogros, temperamentais e mal-cheirosos. Logo, planeje bem suas camadas de abstra\u00e7\u00e3o. \u21a9","title":"SD s\u00e3o como cebolas!"},{"location":"models/processor/","text":"Do processador \u00e0 nuvem em 42 passos O primeiro desafio \u00e9 entender o ambiente no qual est\u00e3o inseridos, suas limita\u00e7\u00f5es e fragilidades e, para isso, precisamos entender como a computa\u00e7\u00e3o \u00e9 executada em cada uma das partes do sistema. 1 2 3 4 5 6 7 8 9 10 11 42","title":"Processador"},{"location":"models/processor/#do-processador-a-nuvem-em-42-passos","text":"O primeiro desafio \u00e9 entender o ambiente no qual est\u00e3o inseridos, suas limita\u00e7\u00f5es e fragilidades e, para isso, precisamos entender como a computa\u00e7\u00e3o \u00e9 executada em cada uma das partes do sistema. 1 2 3 4 5 6 7 8 9 10 11 42","title":"Do processador \u00e0 nuvem em 42 passos"},{"location":"time/","text":"Tempo Mesmo sem nos aprofundarmos na natureza do tempo, uma discuss\u00e3o muito filos\u00f3fica 1 para este curso, \u00e9 f\u00e1cil perceber que este tem implica\u00e7\u00f5es na forma como os sistemas distribu\u00eddos funcionam. Para n\u00f3s, como colocado por Einstein, Tempo \u00e9 o que os rel\u00f3gios medem. Neste cap\u00edtulo discutiremos como o tempo e os rel\u00f3gios s\u00e3o importantes no desenvolvimento de sistemas distribu\u00eddos. Comecemos por analisar o funcionamento de uma aplica\u00e7\u00e3o distribu\u00edda muito comum, o armazenamento de arquivos na nuvem , sincronizado com o sistema de arquivos local. Alguns exemplos do mundo real s\u00e3o Dropbox, Box, Google Drive and OneDrive; chamemos este servi\u00e7o genericamente de cloud-drive . No exemplo a seguir, um arquivo \u00e9 sincronizado com uma nova c\u00f3pia, Cliente 1, que altera o arquivo e sincroniza de volta com o servidor. Na sequ\u00eancia, um novo cliente se registra, Cliente 2, recebe o arquivo, o altera e sincroniza com o servidor, que propaga a nova vers\u00e3o para Cliente 1. Ao final da execu\u00e7\u00e3o, todos os envolvidos tem c\u00f3pias id\u00eanticas do arquivo. Se um mesmo arquivo no cloud-drive \u00e9 modificado em duas m\u00e1quinas diferentes, enquanto as mesmas est\u00e3o desconectadas, o qu\u00ea acontece quando elas se reconectam \u00e0 Internet? Mais especificamente, quando as duas m\u00e1quinas se conectam e enviam suas vers\u00f5es do arquivo modificado para o servidor, sendo que ambas foram geradas a partir de um ancestral comum, qual vers\u00e3o deve ser armazenada e qual deve ser descartada? Voc\u00ea pode se perguntar se isso realmente poderia acontecer, afinal, voc\u00ea n\u00e3o estar\u00e1 em dois lugares para fazer modifica\u00e7\u00f5es concorrentes. Ignorando-se o fato de que outra pessoa poderia estar editando em paralelo, uma falha de comunica\u00e7\u00e3o poderia lhe permitir editar nos dois computadores concorrentemente . Uma possibilidade simples \u00e9 sempre aceitar cada nova vers\u00e3o como uma modifica\u00e7\u00e3o do arquivo. Assim, efetivamente, quando a primeira vers\u00e3o for entregue, ser\u00e1 aceita e viver\u00e1 momentaneamente at\u00e9 que a outra vers\u00e3o seja recebida e a sobrescreva. No exemplo seguinte, o resultado deveria ser A, seguindo esta abordagem. Contudo, vemos alguns problemas pois, pelo gr\u00e1fico, vemos que a \"Vers\u00e3o B\" foi criada depois da \"Vers\u00e3o A\", mas que a vers\u00e3o final vista pelo servidor \u00e9 exatamente a \"A\". Al\u00e9m disso, se encolhermos um pouco a desconex\u00e3o do n\u00f3 na parte de cima, o resultado final se inverte. Isso quer dizer que a decis\u00e3o de qual a vers\u00e3o deve ser mantida depende mais da rede que das edi\u00e7\u00f5es do arquivo em si. Mas isso n\u00e3o parece fazer sentido, certo? Afinal, a ordem de chegada dos arquivos ao servidor n\u00e3o reflete necessariamente a ordem em que os arquivos foram modificados. Assim, podemos pensar em outras alternativas de aproveitamento e descarte de arquivos baseadas no hor\u00e1rio de cria\u00e7\u00e3o e modifica\u00e7\u00e3o do arquivo. Contudo, o hor\u00e1rios s\u00e3o relativos a onde a opera\u00e7\u00e3o aconteceu e n\u00e3o aos componentes do sistema, o que pode levar uma modifica\u00e7\u00e3o que tenha acontecido mais tarde, do ponto de vista de um observador externo , a ter um hor\u00e1rio de cria\u00e7\u00e3o oficial anterior. Se for poss\u00edvel identificar a causalidade entre as modifica\u00e7\u00f5es, isto \u00e9, qual vers\u00e3o originou qual outra, ent\u00e3o \u00e9 claro que se deve manter vers\u00f5es de acordo com a ordem causal. Contudo, edi\u00e7\u00f5es concorrentes, como a cria\u00e7\u00e3o das vers\u00f5es A e B no exemplo anterior, n\u00e3o tem rela\u00e7\u00e3o de causalidade entre si. Assim, em qualquer destas linhas de atua\u00e7\u00e3o, voc\u00ea tem em m\u00e3os um conflito para resolver , e automatizar a resolu\u00e7\u00e3o do mesmo \u00e9 muito complicado. \u00c9 por isso que o Dropbox, por exemplo, deixa os dois arquivos para que o usu\u00e1rio analise e decida o que fazer, que servidores git exigem que o usu\u00e1rio pegue a vers\u00e3o salva mais recentemente e compatibilize suas mudan\u00e7as com ela antes de submeter novas mudan\u00e7as, e o Perforce trabalha com locks de arquivos. Se pensarmos em termos n\u00e3o de arquivos sendo enviados para um servidor, mas de opera\u00e7\u00f5es de modifica\u00e7\u00f5es sendo executadas, ent\u00e3o dada esta problem\u00e1tica, podemos simplificar a quest\u00e3o em nossas m\u00e3os. Como ordenar opera\u00e7\u00f5es de clientes? Se duas opera\u00e7\u00f5es originadas em clientes s\u00e3o enviadas ao servidor, qual deve ser executada primeiro? Embora, como j\u00e1 vimos, usar a ordem temporal da cria\u00e7\u00e3o das opera\u00e7\u00f5es tamb\u00e9m seja problem\u00e1tico, j\u00e1 que rel\u00f3gios s\u00e3o dessincronizados em sistemas distribu\u00eddos t\u00edpicos, alguns sistemas tentam resolver automaticamente os conflitos usando exatamente estes rel\u00f3gios. O CassandraDB, por exemplo, usa last write wins ou latest version wins , onde last \u00e9 definido em termos do rel\u00f3gio do cliente. Neste cen\u00e1rio, temos novo problema: Pergunta Como determinar qual foi enviada primeiro, em um sistema ass\u00edncrono? Como sincronizar? Como sincronizar rel\u00f3gios em um sistema distribu\u00eddo? Para usar esta abordagem, precisamos encontrar uma fonte de tempo confi\u00e1vel e distribu\u00edda , constru\u00edda pelo uso de protocolos de sincroniza\u00e7\u00e3o de rel\u00f3gios f\u00edsicos . The New Thermodynamic Understanding of Clocks \u21a9","title":"Introdu\u00e7\u00e3o"},{"location":"time/#tempo","text":"Mesmo sem nos aprofundarmos na natureza do tempo, uma discuss\u00e3o muito filos\u00f3fica 1 para este curso, \u00e9 f\u00e1cil perceber que este tem implica\u00e7\u00f5es na forma como os sistemas distribu\u00eddos funcionam. Para n\u00f3s, como colocado por Einstein, Tempo \u00e9 o que os rel\u00f3gios medem. Neste cap\u00edtulo discutiremos como o tempo e os rel\u00f3gios s\u00e3o importantes no desenvolvimento de sistemas distribu\u00eddos. Comecemos por analisar o funcionamento de uma aplica\u00e7\u00e3o distribu\u00edda muito comum, o armazenamento de arquivos na nuvem , sincronizado com o sistema de arquivos local. Alguns exemplos do mundo real s\u00e3o Dropbox, Box, Google Drive and OneDrive; chamemos este servi\u00e7o genericamente de cloud-drive . No exemplo a seguir, um arquivo \u00e9 sincronizado com uma nova c\u00f3pia, Cliente 1, que altera o arquivo e sincroniza de volta com o servidor. Na sequ\u00eancia, um novo cliente se registra, Cliente 2, recebe o arquivo, o altera e sincroniza com o servidor, que propaga a nova vers\u00e3o para Cliente 1. Ao final da execu\u00e7\u00e3o, todos os envolvidos tem c\u00f3pias id\u00eanticas do arquivo. Se um mesmo arquivo no cloud-drive \u00e9 modificado em duas m\u00e1quinas diferentes, enquanto as mesmas est\u00e3o desconectadas, o qu\u00ea acontece quando elas se reconectam \u00e0 Internet? Mais especificamente, quando as duas m\u00e1quinas se conectam e enviam suas vers\u00f5es do arquivo modificado para o servidor, sendo que ambas foram geradas a partir de um ancestral comum, qual vers\u00e3o deve ser armazenada e qual deve ser descartada? Voc\u00ea pode se perguntar se isso realmente poderia acontecer, afinal, voc\u00ea n\u00e3o estar\u00e1 em dois lugares para fazer modifica\u00e7\u00f5es concorrentes. Ignorando-se o fato de que outra pessoa poderia estar editando em paralelo, uma falha de comunica\u00e7\u00e3o poderia lhe permitir editar nos dois computadores concorrentemente . Uma possibilidade simples \u00e9 sempre aceitar cada nova vers\u00e3o como uma modifica\u00e7\u00e3o do arquivo. Assim, efetivamente, quando a primeira vers\u00e3o for entregue, ser\u00e1 aceita e viver\u00e1 momentaneamente at\u00e9 que a outra vers\u00e3o seja recebida e a sobrescreva. No exemplo seguinte, o resultado deveria ser A, seguindo esta abordagem. Contudo, vemos alguns problemas pois, pelo gr\u00e1fico, vemos que a \"Vers\u00e3o B\" foi criada depois da \"Vers\u00e3o A\", mas que a vers\u00e3o final vista pelo servidor \u00e9 exatamente a \"A\". Al\u00e9m disso, se encolhermos um pouco a desconex\u00e3o do n\u00f3 na parte de cima, o resultado final se inverte. Isso quer dizer que a decis\u00e3o de qual a vers\u00e3o deve ser mantida depende mais da rede que das edi\u00e7\u00f5es do arquivo em si. Mas isso n\u00e3o parece fazer sentido, certo? Afinal, a ordem de chegada dos arquivos ao servidor n\u00e3o reflete necessariamente a ordem em que os arquivos foram modificados. Assim, podemos pensar em outras alternativas de aproveitamento e descarte de arquivos baseadas no hor\u00e1rio de cria\u00e7\u00e3o e modifica\u00e7\u00e3o do arquivo. Contudo, o hor\u00e1rios s\u00e3o relativos a onde a opera\u00e7\u00e3o aconteceu e n\u00e3o aos componentes do sistema, o que pode levar uma modifica\u00e7\u00e3o que tenha acontecido mais tarde, do ponto de vista de um observador externo , a ter um hor\u00e1rio de cria\u00e7\u00e3o oficial anterior. Se for poss\u00edvel identificar a causalidade entre as modifica\u00e7\u00f5es, isto \u00e9, qual vers\u00e3o originou qual outra, ent\u00e3o \u00e9 claro que se deve manter vers\u00f5es de acordo com a ordem causal. Contudo, edi\u00e7\u00f5es concorrentes, como a cria\u00e7\u00e3o das vers\u00f5es A e B no exemplo anterior, n\u00e3o tem rela\u00e7\u00e3o de causalidade entre si. Assim, em qualquer destas linhas de atua\u00e7\u00e3o, voc\u00ea tem em m\u00e3os um conflito para resolver , e automatizar a resolu\u00e7\u00e3o do mesmo \u00e9 muito complicado. \u00c9 por isso que o Dropbox, por exemplo, deixa os dois arquivos para que o usu\u00e1rio analise e decida o que fazer, que servidores git exigem que o usu\u00e1rio pegue a vers\u00e3o salva mais recentemente e compatibilize suas mudan\u00e7as com ela antes de submeter novas mudan\u00e7as, e o Perforce trabalha com locks de arquivos. Se pensarmos em termos n\u00e3o de arquivos sendo enviados para um servidor, mas de opera\u00e7\u00f5es de modifica\u00e7\u00f5es sendo executadas, ent\u00e3o dada esta problem\u00e1tica, podemos simplificar a quest\u00e3o em nossas m\u00e3os. Como ordenar opera\u00e7\u00f5es de clientes? Se duas opera\u00e7\u00f5es originadas em clientes s\u00e3o enviadas ao servidor, qual deve ser executada primeiro? Embora, como j\u00e1 vimos, usar a ordem temporal da cria\u00e7\u00e3o das opera\u00e7\u00f5es tamb\u00e9m seja problem\u00e1tico, j\u00e1 que rel\u00f3gios s\u00e3o dessincronizados em sistemas distribu\u00eddos t\u00edpicos, alguns sistemas tentam resolver automaticamente os conflitos usando exatamente estes rel\u00f3gios. O CassandraDB, por exemplo, usa last write wins ou latest version wins , onde last \u00e9 definido em termos do rel\u00f3gio do cliente. Neste cen\u00e1rio, temos novo problema: Pergunta Como determinar qual foi enviada primeiro, em um sistema ass\u00edncrono? Como sincronizar? Como sincronizar rel\u00f3gios em um sistema distribu\u00eddo? Para usar esta abordagem, precisamos encontrar uma fonte de tempo confi\u00e1vel e distribu\u00edda , constru\u00edda pelo uso de protocolos de sincroniza\u00e7\u00e3o de rel\u00f3gios f\u00edsicos . The New Thermodynamic Understanding of Clocks \u21a9","title":"Tempo"},{"location":"time/logical/","text":"Tempo L\u00f3gico A ideia por tr\u00e1s do \"tempo l\u00f3gico\" \u00e9 de o que importa s\u00e3o eventos e n\u00e3o a passagem do tempo, uma vez que tempo \u00e9 relativo aos processos 1 . Assim, surgem os rel\u00f3gios l\u00f3gicos, que ``ticam'' quando um evento importante acontece. Para chegarmos aos rel\u00f3gios l\u00f3gicos, precisamos primeiro entender a rela\u00e7\u00e3o Happened-Before , proposta por Leslie Lamport 2 e que lhe rendeu um Pr\u00eamio Turing em 2014 . Hoje \u00e9 comum usar a rela\u00e7\u00e3o happened-before e o vocabul\u00e1rio associado para falar sobre ordem de eventos em um sistema computacional, em especial um distribu\u00eddo. Happened-Before A rela\u00e7\u00e3o happened-before captura a causalidade entre eventos. Isto \u00e9, se um evento \\(e\\) aconteceu-antes de um evento \\(e'\\) , ent\u00e3o \\(e\\) potencialmente causou \\(e'\\) . Tamb\u00e9m podemos dizer que \\(e\\) precede \\(e'\\) em uma ordem causal. O evento \\(a\\) aconteceu-antes \\(b\\) , notado como \\(a \\rightarrow b\\) , se uma das tr\u00eas condi\u00e7\u00f5es seguintes \u00e9 v\u00e1lida: Happened-Before Se \\(e\\) e \\(e'\\) s\u00e3o eventos em um mesmo processo (ou thread ) e \\(e\\) foi executado antes de \\(e'\\) . Se \\(e\\) e \\(e'\\) s\u00e3o eventos de processos distintos e \\(e\\) \u00e9 o envio de uma mensagem e \\(e'\\) a sua recep\u00e7\u00e3o. Se h\u00e1 transitividade, isto \u00e9, se existe um evento \\(e''\\) tal que \\(e \\rightarrow e''\\) e \\(e'' \\rightarrow e'\\) . Na figura abaixo, as tr\u00eas regras s\u00e3o exemplificadas pelos eventos de cor vermelha, amarela e verde, respectivamente. Note que se \\(e \\rightarrow e'\\) \u00e9 falso e \\(e' \\rightarrow e\\) \u00e9 falso, ent\u00e3o \\(e\\) e \\(e'\\) s\u00e3o concorrentes , e que ser concorrente n\u00e3o quer dizer que aconteceram exatamente no mesmo instante, do ponto de vista de um observador externo, como exemplificado na figura anterior pelos eventos de cor roxa. Ser concorrente quer dizer que um evento \\(e\\) n\u00e3o pode ter influenciado o evento \\(e'\\) , dado que os efeitos de \\(e\\) n\u00e3o poderiam ser conhecidos pelo processo onde \\(e'\\) ocorreu, quando \\(e'\\) ocorreu. O cone de luz na figura seguinte mostra esta rela\u00e7\u00e3o entre eventos. Somente os efeitos dos eventos uma dist\u00e2ncia no espa\u00e7o/tempo menor ou igual \u00e0s dos pontos mais distantes ao evento em quest\u00e3o, podem ter influenciado tal evento. No caso dos eventos \\(o\\) e \\(v\\) na figura, os mesmos n\u00e3o figuram no mesmo cone de luz. Mas para que nos serve capturar a causalidade entre os eventos? Bem, se capturarmos a causalidade, podemos usar esta informa\u00e7\u00e3o para ordenar os seu processamento, de forma a fazer sentido. Por exemplo, considere um sistema em que o primeiro usu\u00e1rio de um servi\u00e7o de emails recebe primeiro a resposta da mensagem A, R:A, para somente depois receber A. Para que a troca de mensagens fa\u00e7a sentido, o usu\u00e1rio posterga a leitura de R:A at\u00e9 depois de ter lido A. Observe que em nenhum momento a informa\u00e7\u00e3o sobre quando as mensagens foram enviadas foi necess\u00e1ria, apenas a ordem das mesmas. Rel\u00f3gios l\u00f3gicos permitem que sistemas capturem a rela\u00e7\u00e3o de causalidade entre eventos e implementem esquemas como o apenas descrito, para coordenar as a\u00e7\u00f5es dos processos em sistemas distribu\u00eddos. Rel\u00f3gios l\u00f3gicos Para que computadores possam usar a causalidade, precisamos capturar a rela\u00e7\u00e3o de acontecer antes em um sistema. Lamport prop\u00f4s uma tal forma, que denominou rel\u00f3gio l\u00f3gico , mas que hoje \u00e9 conhecido universalmente como rel\u00f3gio de Lamport . Estes rel\u00f3gios permitem associar um timestamp a eventos de forma a se garantir a seguinte propriedade: seja \\(e\\) um evento seja \\(C(e)\\) o valor do rel\u00f3gio l\u00f3gico quando associado a \\(e\\) se \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) Mas como definir a fun\u00e7\u00e3o \\(C\\) ? Experimentemos a seguinte defini\u00e7\u00e3o: Quase Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. \\(C(e) = ++c_p\\) no momento em que \\(e\\) ocorreu. Usamos como \\(<\\) a rela\u00e7\u00e3o normal de inteiros. Observe que n\u00e3o h\u00e1 fonte da verdade em termos de tempo l\u00f3gico, j\u00e1 que cada processo mant\u00e9m seu pr\u00f3prio rel\u00f3gio que pode ser relacionado com rel\u00f3gios de outros processos. Veja um exemplo desta defini\u00e7\u00e3o em a\u00e7\u00e3o. \u00c9 verdade neste cen\u00e1rio que se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) ? Observe com aten\u00e7\u00e3o os eventos \\(j\\) e \\(q\\) , pois para estes, a regra n\u00e3o \u00e9 respeitada. Rel\u00f3gio de Lamport Para que a regra \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) seja v\u00e1lida, precisamos modificar a tentativa anterior para que, na recep\u00e7\u00e3o de uma mensagem, os contadores sejam atualizados para que sejam maiores tanto que os rel\u00f3gios dos eventos locais quanto dos eventos que antecederam o envio da mensagem sendo recebida. Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. Se o evento \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) Se o evento \\(e\\) \u00e9 o envio de uma mensagem \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) \\(C(e)\\) \u00e9 enviado com a mensagem como seu timestamp . Se o evento \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) \\(c_p \\gets max(c_p,ts)+1\\) . \\(C(e) \\gets c_p\\) Com este ajuste, temos os Rel\u00f3gios de Lamport . Neste caso, temos que para quaisquer eventos \\(e,e'\\) , se \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) . Todo Exemplo em que n\u00e3o \u00e9 bom o suficiente. Se \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) . Contudo, a volta n\u00e3o \u00e9 verdade, isto \u00e9, se \\(C(e) < C(e')\\) ent\u00e3o \\(e \\rightarrow e'\\) . Esta propriedade \u00e9 interessante na ordena\u00e7\u00e3o de eventos, pois evita que eventos concorrentes sejam ordenados. Entram os rel\u00f3gios vetoriais. Rel\u00f3gio Vetorial Rel\u00f3gios vetoriais s\u00e3o rel\u00f3gios l\u00f3gicos em que cada processo mant\u00e9m n\u00e3o apenas um contador dos seus eventos locais, mas tamb\u00e9m sua vis\u00e3o dos contadores dos outros processos. Estas vis\u00f5es s\u00e3o atualizadas a cada recep\u00e7\u00e3o de mensagem, de acordo com a seguinte especifica\u00e7\u00e3o, onde assume-se que \\(n\\) processos fazem parte do sistema. Rel\u00f3gio Vetorial Considerando o ponto de vista do processo \\(p\\) Seja \\(c_p[i], 1 \\leq i \\leq n\\) inicialmente igual a 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) \\(V(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p[p] \\gets c_p[p] + 1\\) \\(c_p[i] \\gets max(c_p[i], ts[i]), \\forall i \\neq p\\) \\(V(e) \\gets c_p\\) Uma observa\u00e7\u00e3o interessante a ser feita aqui \u00e9 que embora o algoritmo pare\u00e7a indicar que cada processo precisa saber quantos mais processos existem no sistema, isto n\u00e3o \u00e9 verdade, pois pode-se assumir que para todo processo desconhecido \\(q\\) , \\(c_p[q] = 0\\) . Como dito, este rel\u00f3gio l\u00f3gico tem a propriedade \\(e \\rightarrow e' \\iff V(e) < V(e')\\) , considerando-se a seguinte defini\u00e7\u00e3o de \\(<\\) para vetores: Compara\u00e7\u00e3o entre vetores \\(v = v' \\iff v[i] = v'[i], 1 \\leq i \\leq n\\) \\(v \\leq v' \\iff v[i] \\leq v'[i], 1 \\leq i \\leq n\\) \\(v < v' \\iff v \\leq v' \\land v \\neq v'\\) Assim, sejam dois eventos \\(e \\neq e'\\) : \\(e \\rightarrow e' \\iff V(e) < V(e')\\) Se \\(V(e) \\not < V(e')\\) e \\(V(e') \\not < V(e)\\) , ent\u00e3o \\(e\\) e \\(e'\\) s\u00e3o concorrentes. Para entender melhor como esta defini\u00e7\u00e3o funciona, considere a seguinte execu\u00e7\u00e3o. O que quer dizer \\(c_p[q] = k\\) , ou tomando o evento \\(d\\) como exemplo, o que quer dizer \\(V(d) = (4,1,0)\\) ? Quer dizer que \\(p1\\) est\u00e1 ciente de 1 eventos locais a \\(p2\\) , assim com est\u00e1 ciente de 0 eventos em \\(p3\\) e de que \\(d\\) \u00e9 o quarto evento em \\(p1\\) . Agora compare os eventos \\(o\\) e \\(v\\) . \\(o\\) e \\(v\\) s\u00e3o concorrentes pois embora as posi\u00e7\u00f5es 1 e 2 de \\(V(o)\\) sejam maiores que em \\(V(v)\\) , a posi\u00e7\u00e3o 3 \u00e9 menor. Isso quer dizer que o nem \\(o\\) est\u00e1 ciente do evento \\(v\\) e nem \\(v\\) est\u00e1 ciente do evento \\(o\\) , ou melhor, que um n\u00e3o pode ter causado o outro. Esta abstra\u00e7\u00e3o simples j\u00e1 \u00e9 muito poderosa e, embora possa ser melhorada, 3 j\u00e1 \u00e9 suficiente para se implementar outras abstra\u00e7\u00f5es interessantes, como ser\u00e1 visto adiante. Antes, \u00e9 necess\u00e1rio mencionar mais um tipo de rel\u00f3gio l\u00f3gico, os h\u00edbridos. Rel\u00f3gios H\u00edbridos A grande vantagem dos rel\u00f3gios l\u00f3gicos sobre os f\u00edsicos \u00e9 de ignorar a passagem do tempo, s\u00f3 se importanto com a ordem de eventos. Esta vantagem tamb\u00e9m \u00e9 uma desvantagem quando eventos precisam ser associados a eventos externos ao sistema, por exemplo, durante uma sess\u00e3o de depura\u00e7\u00e3o. Suponha que ap\u00f3s uma atualiza\u00e7\u00e3o de um sistema, voc\u00ea note um problema nos dados e, em depurando o problema, identifique o evento problem\u00e1tico nos logs do sistema, associado ao seu rel\u00f3gio l\u00f3gico. Como identificar se este evento problem\u00e1tico aconteceu antes ou depois da atualiza\u00e7\u00e3o? Rel\u00f3gios h\u00edbridos tentam resolver este problema combinando rel\u00f3gios f\u00edsicos e l\u00f3gicos em um. No seguinte algoritmo, cada processo mantem um rel\u00f3gio f\u00edsico e um l\u00f3gico e sempre que um evento acontece, usa como novo valor do rel\u00f3gio l\u00f3gico o m\u00e1ximo entre o valor anterior + 1, o valor do timestamp na mensagem sendo recebida + 1, se for o recebimento de uma mensagem, e o valor do rel\u00f3gio f\u00edsico. Isto \u00e9, se poucos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico acompanhar\u00e1 o valor do f\u00edsico. Rel\u00f3gio H\u00edbrido Simples Considerando o ponto de vista do processo \\(p\\) \\(c_p.f\\) \u00e9 o rel\u00f3gio f\u00edsico de \\(p\\) , incrementado automaticamente \\(c_p.l\\) \u00e9 o rel\u00f3gio l\u00f3gico de \\(p\\) , inicialmente 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) \\(H(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p.l \\gets max(c_p.l + 1, ts + 1, c_p.f)\\) \\(V(e) = c_p.l\\) Nesta vers\u00e3o do algoritmo, contudo, se muitos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico pode ser incrementadado muito rapidamente, perdendo a rela\u00e7\u00e3o com o rel\u00f3gio f\u00edsico. Em uma vers\u00e3o melhorada do algoritmo, 4 a dist\u00e2ncia entre os dois rel\u00f3gios \u00e9 limitada, mantendo a propriedade que faz o rel\u00f3gios h\u00edbridos interessantes. 5 Comunica\u00e7\u00e3o em Grupo Rel\u00f3gios l\u00f3gicos podem e s\u00e3o usados diretamente em sistemas, por exemplo, para controlar vers\u00f5es no sistema de identidade da Microsoft, Active Directory . Outra forma de uso \u00e9 como bloco de constru\u00e7\u00e3o de outras abstra\u00e7\u00f5es, por exemplo, primitivas de comunica\u00e7\u00e3o em grupo, pelas quais um processo envia mensagens para um conjunto de processos. Difus\u00e3o Totalmente Ordenada ( Total Order Multicast ): Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem Difus\u00e3o Causalmente Ordenada: Causalmente Ordenada: uma mensagem s\u00f3 \u00e9 entregue se todas as que causalmente a precedem j\u00e1 foram entregues. Com estas abstra\u00e7\u00f5es, podemos resolver o problema apresentado no in\u00edcio deste cap\u00edtulo, relembrando, cloud-drive , da seguinte forma. Considere um programa qualquer, que se comporte de forma determin\u00edstica (isto \u00e9, dada uma mesma entrada, gera sempre uma mesma sa\u00edda). Como todo programa, este \u00e9 uma m\u00e1quina de estados, com a peculiaridade de ser determin\u00edstica. Logo, se tivermos v\u00e1rias c\u00f3pias deste programa, executando em locais distintos, mas garantirmos que cada c\u00f3pia veja exatamente a mesma entrada de dados , ent\u00e3o garantiremos que todas as c\u00f3pias transitar\u00e3o pelos mesmos estados e chegar\u00e3o ao mesmo estado final. Como difus\u00e3o totalmente ordenada pode ser usado para garantir que todas as c\u00f3pias receber\u00e3o a mesma entrada, pode ser usado para implementar esta t\u00e9cnica, conhecida como Replica\u00e7\u00e3o de M\u00e1quinas de Estados (em ingl\u00eas, State Machine Replication , ou pelo menos o seu princ\u00edpio. Mas como podemos implementar estas primitivas de difus\u00e3o usando rel\u00f3gios l\u00f3gicos? Vejamos um algoritmo, onde consideramos que todas as mensagens s\u00e3o enviadas a todos os processos, inclusive o pr\u00f3prio remetente. Difus\u00e3o Totalmente Ordenado Considerando o ponto de vista do processo \\(p\\) \\(f_p\\) \u00e9 uma fila de mensagens ordenadas pelo seus timestamps , mantida em \\(p\\) Para difundir uma mensagem \\(m\\) colocar \\(m\\) na fila enviar \\(m\\) para todos os demais processos Quando uma mensagem \\(m\\) \u00e9 recebida colocar \\(m\\) na fila se \\(m\\) n\u00e3o \u00e9 um ack enviar \\(m ack\\) de volta ao remetente de \\(m\\) (com timestamp maior que de \\(m\\) ) Seja \\(m\\) a mensagem com timestamp ts na cabe\u00e7a da fila Se para cada processo \\(q\\) , h\u00e1 uma mensagem \\(m'\\) de \\(q\\) com timestamp ts' na fila de \\(p\\) tal que \\(ts < ts'\\) entregar \\(m\\) para a aplica\u00e7\u00e3o O objetivo deste algoritmo \u00e9 de entregar mensagens na ordem de seus timestamps . Para isso, antes de entregar a mensagem \\(m\\) de menor tmestamp ts conhecido atualmente por \\(p\\) , \\(p\\) espera por mensagens com \\(timestamps\\) maiores que ts de todos os processos. Uma vez que isso aconte\u00e7a, \\(p\\) sabe que nenhuma outra mensagem que chegue depois poderia ter \\(timestamp\\) menor que ts. Para que isto funcione, \u00e9 necess\u00e1rio que os canais de comunica\u00e7\u00e3o usados sejam confi\u00e1veis (todas as mensagens enviadas s\u00e3o entregues) e FIFO (a primeira a ser enviada \u00e9 primeira a ser recebida). Exerc\u00edcio - FIFO e Confi\u00e1veis \u00c9 necess\u00e1rio que canais de comunica\u00e7\u00e3o sejam FIFO e confi\u00e1veis para que mensagens com timestamp maiores n\u00e3o sejam perdidas e para que mensagens com timestamps maiores n\u00e3o sejam reordenadas e entregues primeiro. Explique porqu\u00ea isto seria um problema; descreva execu\u00e7\u00f5es problem\u00e1ticas. Vejamos um outro algoritmo, de difus\u00e3o causalmente ordenada. Difus\u00e3o Causalmente Ordenada Considerando o ponto de vista do processo \\(p\\) \\(p\\) incrementa \\(c_p[p]\\) somente no envio de mensagens. \\(p\\) s\u00f3 entrega uma mensagem recebida de \\(q\\) , com timestamp \\(ts\\) quando \\(ts[q] = c_p[q]+1\\) \\(ts[k] \\leq c_p[k], k \\neq q\\) Difus\u00e3o Causalmente Ordenada Considere \\(c_{p3}[0,2,2]\\) e \\(ts=[1,3,0]\\) , de \\(p1\\) . O que \\(p3\\) est\u00e1 esperando? Como age ao receber mensagem com \\(ts\\) ? Interceptadores Um aspecto interessante da implementa\u00e7\u00e3o de primitivas de comunica\u00e7\u00e3o em grupo que usa rel\u00f3gios para ordena\u00e7\u00e3o de mensagens \u00e9 que elas podem ser feitas de forma transparente para a aplica\u00e7\u00e3o que as usa. Isto \u00e9, no exemplo descrito anteriormente em que processos mandam mensagens para r\u00e9plicas usando difus\u00e3o totalmente ordenada, os clientes n\u00e3o precisam estar cientes disto, e podem simplesmente mandar suas requisi\u00e7\u00f5es como faziam antes do servi\u00e7o ser replicado. Mas como ent\u00e3o as mensagens tem seus rel\u00f3gios l\u00f3gicos atualizados e usados para a gera\u00e7\u00e3o de timestamps ? Isto pode ser feito por meio de interceptadores em uma camada de middleware . Quando a aplica\u00e7\u00e3o envia uma mensagem, o rel\u00f3gio l\u00f3gico mantido no middleware \u00e9 atualizado e seu valor usado como timestamp em uma vers\u00e3o estendida da mensagem, efetivamente enviada na rede. Quando a mensagem estendida \u00e9 entregue ao destinat\u00e1rio, a mensagem \u00e9 passada para o interceptador que extrai o timestamp e atualiza seu rel\u00f3gio. A mensagem sem o timestamp \u00e9 entregue para a aplica\u00e7\u00e3o quando apropriado, e aplica\u00e7\u00e3o n\u00e3o percebe a manipula\u00e7\u00e3o. Exclus\u00e3o M\u00fatua Revisitada Todo Algoritmos de Exclu\u00e3o m\u00fatua baeados em LC Algoritmo de Lamport, Ricart e agrawalla Algoritmo de Maekawa Reza a lenda que Leslie Lamport desenvolveu o conceito de rel\u00f3gios l\u00f3gicos pensando na teoria da relatividade geral. \u21a9 Time, Clocks and the Ordering of Events in a Distributed System. July 5, 1978 . \u21a9 Matrix Clock \u21a9 O blog de um dos autores descreve ambas as vers\u00f5es de forma resumida. Para a vers\u00e3o completa dos algoritmos, consulte o artigo . \u21a9 Tanto no artigo quanto no blog, a imagem que descreve um exemplo do HLC parece ter um erro e onde se l\u00ea (3,13) deve-se ler (3,10,3). \u21a9","title":"Tempo L\u00f3gico"},{"location":"time/logical/#tempo-logico","text":"A ideia por tr\u00e1s do \"tempo l\u00f3gico\" \u00e9 de o que importa s\u00e3o eventos e n\u00e3o a passagem do tempo, uma vez que tempo \u00e9 relativo aos processos 1 . Assim, surgem os rel\u00f3gios l\u00f3gicos, que ``ticam'' quando um evento importante acontece. Para chegarmos aos rel\u00f3gios l\u00f3gicos, precisamos primeiro entender a rela\u00e7\u00e3o Happened-Before , proposta por Leslie Lamport 2 e que lhe rendeu um Pr\u00eamio Turing em 2014 . Hoje \u00e9 comum usar a rela\u00e7\u00e3o happened-before e o vocabul\u00e1rio associado para falar sobre ordem de eventos em um sistema computacional, em especial um distribu\u00eddo.","title":"Tempo L\u00f3gico"},{"location":"time/logical/#happened-before","text":"A rela\u00e7\u00e3o happened-before captura a causalidade entre eventos. Isto \u00e9, se um evento \\(e\\) aconteceu-antes de um evento \\(e'\\) , ent\u00e3o \\(e\\) potencialmente causou \\(e'\\) . Tamb\u00e9m podemos dizer que \\(e\\) precede \\(e'\\) em uma ordem causal. O evento \\(a\\) aconteceu-antes \\(b\\) , notado como \\(a \\rightarrow b\\) , se uma das tr\u00eas condi\u00e7\u00f5es seguintes \u00e9 v\u00e1lida: Happened-Before Se \\(e\\) e \\(e'\\) s\u00e3o eventos em um mesmo processo (ou thread ) e \\(e\\) foi executado antes de \\(e'\\) . Se \\(e\\) e \\(e'\\) s\u00e3o eventos de processos distintos e \\(e\\) \u00e9 o envio de uma mensagem e \\(e'\\) a sua recep\u00e7\u00e3o. Se h\u00e1 transitividade, isto \u00e9, se existe um evento \\(e''\\) tal que \\(e \\rightarrow e''\\) e \\(e'' \\rightarrow e'\\) . Na figura abaixo, as tr\u00eas regras s\u00e3o exemplificadas pelos eventos de cor vermelha, amarela e verde, respectivamente. Note que se \\(e \\rightarrow e'\\) \u00e9 falso e \\(e' \\rightarrow e\\) \u00e9 falso, ent\u00e3o \\(e\\) e \\(e'\\) s\u00e3o concorrentes , e que ser concorrente n\u00e3o quer dizer que aconteceram exatamente no mesmo instante, do ponto de vista de um observador externo, como exemplificado na figura anterior pelos eventos de cor roxa. Ser concorrente quer dizer que um evento \\(e\\) n\u00e3o pode ter influenciado o evento \\(e'\\) , dado que os efeitos de \\(e\\) n\u00e3o poderiam ser conhecidos pelo processo onde \\(e'\\) ocorreu, quando \\(e'\\) ocorreu. O cone de luz na figura seguinte mostra esta rela\u00e7\u00e3o entre eventos. Somente os efeitos dos eventos uma dist\u00e2ncia no espa\u00e7o/tempo menor ou igual \u00e0s dos pontos mais distantes ao evento em quest\u00e3o, podem ter influenciado tal evento. No caso dos eventos \\(o\\) e \\(v\\) na figura, os mesmos n\u00e3o figuram no mesmo cone de luz. Mas para que nos serve capturar a causalidade entre os eventos? Bem, se capturarmos a causalidade, podemos usar esta informa\u00e7\u00e3o para ordenar os seu processamento, de forma a fazer sentido. Por exemplo, considere um sistema em que o primeiro usu\u00e1rio de um servi\u00e7o de emails recebe primeiro a resposta da mensagem A, R:A, para somente depois receber A. Para que a troca de mensagens fa\u00e7a sentido, o usu\u00e1rio posterga a leitura de R:A at\u00e9 depois de ter lido A. Observe que em nenhum momento a informa\u00e7\u00e3o sobre quando as mensagens foram enviadas foi necess\u00e1ria, apenas a ordem das mesmas. Rel\u00f3gios l\u00f3gicos permitem que sistemas capturem a rela\u00e7\u00e3o de causalidade entre eventos e implementem esquemas como o apenas descrito, para coordenar as a\u00e7\u00f5es dos processos em sistemas distribu\u00eddos.","title":"Happened-Before"},{"location":"time/logical/#relogios-logicos","text":"Para que computadores possam usar a causalidade, precisamos capturar a rela\u00e7\u00e3o de acontecer antes em um sistema. Lamport prop\u00f4s uma tal forma, que denominou rel\u00f3gio l\u00f3gico , mas que hoje \u00e9 conhecido universalmente como rel\u00f3gio de Lamport . Estes rel\u00f3gios permitem associar um timestamp a eventos de forma a se garantir a seguinte propriedade: seja \\(e\\) um evento seja \\(C(e)\\) o valor do rel\u00f3gio l\u00f3gico quando associado a \\(e\\) se \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) Mas como definir a fun\u00e7\u00e3o \\(C\\) ? Experimentemos a seguinte defini\u00e7\u00e3o: Quase Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. \\(C(e) = ++c_p\\) no momento em que \\(e\\) ocorreu. Usamos como \\(<\\) a rela\u00e7\u00e3o normal de inteiros. Observe que n\u00e3o h\u00e1 fonte da verdade em termos de tempo l\u00f3gico, j\u00e1 que cada processo mant\u00e9m seu pr\u00f3prio rel\u00f3gio que pode ser relacionado com rel\u00f3gios de outros processos. Veja um exemplo desta defini\u00e7\u00e3o em a\u00e7\u00e3o. \u00c9 verdade neste cen\u00e1rio que se \\(a \\rightarrow b\\) ent\u00e3o \\(C(a) < C(b)\\) ? Observe com aten\u00e7\u00e3o os eventos \\(j\\) e \\(q\\) , pois para estes, a regra n\u00e3o \u00e9 respeitada.","title":"Rel\u00f3gios l\u00f3gicos"},{"location":"time/logical/#relogio-de-lamport","text":"Para que a regra \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) seja v\u00e1lida, precisamos modificar a tentativa anterior para que, na recep\u00e7\u00e3o de uma mensagem, os contadores sejam atualizados para que sejam maiores tanto que os rel\u00f3gios dos eventos locais quanto dos eventos que antecederam o envio da mensagem sendo recebida. Rel\u00f3gio de Lamport Seja \\(c_p\\) um contador em \\(p\\) com valor inicialmente igual a 0. Se o evento \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) Se o evento \\(e\\) \u00e9 o envio de uma mensagem \\(c_p \\gets c_p + 1\\) \\(C(e) \\gets c_p\\) \\(C(e)\\) \u00e9 enviado com a mensagem como seu timestamp . Se o evento \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) \\(c_p \\gets max(c_p,ts)+1\\) . \\(C(e) \\gets c_p\\) Com este ajuste, temos os Rel\u00f3gios de Lamport . Neste caso, temos que para quaisquer eventos \\(e,e'\\) , se \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) . Todo Exemplo em que n\u00e3o \u00e9 bom o suficiente. Se \\(e \\rightarrow e'\\) ent\u00e3o \\(C(e) < C(e')\\) . Contudo, a volta n\u00e3o \u00e9 verdade, isto \u00e9, se \\(C(e) < C(e')\\) ent\u00e3o \\(e \\rightarrow e'\\) . Esta propriedade \u00e9 interessante na ordena\u00e7\u00e3o de eventos, pois evita que eventos concorrentes sejam ordenados. Entram os rel\u00f3gios vetoriais.","title":"Rel\u00f3gio de Lamport"},{"location":"time/logical/#relogio-vetorial","text":"Rel\u00f3gios vetoriais s\u00e3o rel\u00f3gios l\u00f3gicos em que cada processo mant\u00e9m n\u00e3o apenas um contador dos seus eventos locais, mas tamb\u00e9m sua vis\u00e3o dos contadores dos outros processos. Estas vis\u00f5es s\u00e3o atualizadas a cada recep\u00e7\u00e3o de mensagem, de acordo com a seguinte especifica\u00e7\u00e3o, onde assume-se que \\(n\\) processos fazem parte do sistema. Rel\u00f3gio Vetorial Considerando o ponto de vista do processo \\(p\\) Seja \\(c_p[i], 1 \\leq i \\leq n\\) inicialmente igual a 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p[p] \\gets c_p[p] + 1\\) \\(V(e) \\gets c_p\\) \\(V(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p[p] \\gets c_p[p] + 1\\) \\(c_p[i] \\gets max(c_p[i], ts[i]), \\forall i \\neq p\\) \\(V(e) \\gets c_p\\) Uma observa\u00e7\u00e3o interessante a ser feita aqui \u00e9 que embora o algoritmo pare\u00e7a indicar que cada processo precisa saber quantos mais processos existem no sistema, isto n\u00e3o \u00e9 verdade, pois pode-se assumir que para todo processo desconhecido \\(q\\) , \\(c_p[q] = 0\\) . Como dito, este rel\u00f3gio l\u00f3gico tem a propriedade \\(e \\rightarrow e' \\iff V(e) < V(e')\\) , considerando-se a seguinte defini\u00e7\u00e3o de \\(<\\) para vetores: Compara\u00e7\u00e3o entre vetores \\(v = v' \\iff v[i] = v'[i], 1 \\leq i \\leq n\\) \\(v \\leq v' \\iff v[i] \\leq v'[i], 1 \\leq i \\leq n\\) \\(v < v' \\iff v \\leq v' \\land v \\neq v'\\) Assim, sejam dois eventos \\(e \\neq e'\\) : \\(e \\rightarrow e' \\iff V(e) < V(e')\\) Se \\(V(e) \\not < V(e')\\) e \\(V(e') \\not < V(e)\\) , ent\u00e3o \\(e\\) e \\(e'\\) s\u00e3o concorrentes. Para entender melhor como esta defini\u00e7\u00e3o funciona, considere a seguinte execu\u00e7\u00e3o. O que quer dizer \\(c_p[q] = k\\) , ou tomando o evento \\(d\\) como exemplo, o que quer dizer \\(V(d) = (4,1,0)\\) ? Quer dizer que \\(p1\\) est\u00e1 ciente de 1 eventos locais a \\(p2\\) , assim com est\u00e1 ciente de 0 eventos em \\(p3\\) e de que \\(d\\) \u00e9 o quarto evento em \\(p1\\) . Agora compare os eventos \\(o\\) e \\(v\\) . \\(o\\) e \\(v\\) s\u00e3o concorrentes pois embora as posi\u00e7\u00f5es 1 e 2 de \\(V(o)\\) sejam maiores que em \\(V(v)\\) , a posi\u00e7\u00e3o 3 \u00e9 menor. Isso quer dizer que o nem \\(o\\) est\u00e1 ciente do evento \\(v\\) e nem \\(v\\) est\u00e1 ciente do evento \\(o\\) , ou melhor, que um n\u00e3o pode ter causado o outro. Esta abstra\u00e7\u00e3o simples j\u00e1 \u00e9 muito poderosa e, embora possa ser melhorada, 3 j\u00e1 \u00e9 suficiente para se implementar outras abstra\u00e7\u00f5es interessantes, como ser\u00e1 visto adiante. Antes, \u00e9 necess\u00e1rio mencionar mais um tipo de rel\u00f3gio l\u00f3gico, os h\u00edbridos.","title":"Rel\u00f3gio Vetorial"},{"location":"time/logical/#relogios-hibridos","text":"A grande vantagem dos rel\u00f3gios l\u00f3gicos sobre os f\u00edsicos \u00e9 de ignorar a passagem do tempo, s\u00f3 se importanto com a ordem de eventos. Esta vantagem tamb\u00e9m \u00e9 uma desvantagem quando eventos precisam ser associados a eventos externos ao sistema, por exemplo, durante uma sess\u00e3o de depura\u00e7\u00e3o. Suponha que ap\u00f3s uma atualiza\u00e7\u00e3o de um sistema, voc\u00ea note um problema nos dados e, em depurando o problema, identifique o evento problem\u00e1tico nos logs do sistema, associado ao seu rel\u00f3gio l\u00f3gico. Como identificar se este evento problem\u00e1tico aconteceu antes ou depois da atualiza\u00e7\u00e3o? Rel\u00f3gios h\u00edbridos tentam resolver este problema combinando rel\u00f3gios f\u00edsicos e l\u00f3gicos em um. No seguinte algoritmo, cada processo mantem um rel\u00f3gio f\u00edsico e um l\u00f3gico e sempre que um evento acontece, usa como novo valor do rel\u00f3gio l\u00f3gico o m\u00e1ximo entre o valor anterior + 1, o valor do timestamp na mensagem sendo recebida + 1, se for o recebimento de uma mensagem, e o valor do rel\u00f3gio f\u00edsico. Isto \u00e9, se poucos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico acompanhar\u00e1 o valor do f\u00edsico. Rel\u00f3gio H\u00edbrido Simples Considerando o ponto de vista do processo \\(p\\) \\(c_p.f\\) \u00e9 o rel\u00f3gio f\u00edsico de \\(p\\) , incrementado automaticamente \\(c_p.l\\) \u00e9 o rel\u00f3gio l\u00f3gico de \\(p\\) , inicialmente 0 Seja um evento \\(e\\) Se \\(e\\) \u00e9 uma opera\u00e7\u00e3o local \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) Se \\(e\\) \u00e9 o envio de uma mensagem \\(c_p.l \\gets max(c_p.l + 1, c_p.f)\\) \\(H(e) \\gets c_p.l\\) \\(H(e)\\) \u00e9 enviado com a mensagem como seu timestamp. Se \\(e\\) \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp \\(ts\\) de \\(q\\) , ent\u00e3o \\(c_p.l \\gets max(c_p.l + 1, ts + 1, c_p.f)\\) \\(V(e) = c_p.l\\) Nesta vers\u00e3o do algoritmo, contudo, se muitos eventos acontecerem, o valor do rel\u00f3gio l\u00f3gico pode ser incrementadado muito rapidamente, perdendo a rela\u00e7\u00e3o com o rel\u00f3gio f\u00edsico. Em uma vers\u00e3o melhorada do algoritmo, 4 a dist\u00e2ncia entre os dois rel\u00f3gios \u00e9 limitada, mantendo a propriedade que faz o rel\u00f3gios h\u00edbridos interessantes. 5","title":"Rel\u00f3gios H\u00edbridos"},{"location":"time/logical/#comunicacao-em-grupo","text":"Rel\u00f3gios l\u00f3gicos podem e s\u00e3o usados diretamente em sistemas, por exemplo, para controlar vers\u00f5es no sistema de identidade da Microsoft, Active Directory . Outra forma de uso \u00e9 como bloco de constru\u00e7\u00e3o de outras abstra\u00e7\u00f5es, por exemplo, primitivas de comunica\u00e7\u00e3o em grupo, pelas quais um processo envia mensagens para um conjunto de processos. Difus\u00e3o Totalmente Ordenada ( Total Order Multicast ): Difus\u00e3o: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) Totalmente Ordenada: todos os processos entregam as mensagens na mesma ordem Difus\u00e3o Causalmente Ordenada: Causalmente Ordenada: uma mensagem s\u00f3 \u00e9 entregue se todas as que causalmente a precedem j\u00e1 foram entregues. Com estas abstra\u00e7\u00f5es, podemos resolver o problema apresentado no in\u00edcio deste cap\u00edtulo, relembrando, cloud-drive , da seguinte forma. Considere um programa qualquer, que se comporte de forma determin\u00edstica (isto \u00e9, dada uma mesma entrada, gera sempre uma mesma sa\u00edda). Como todo programa, este \u00e9 uma m\u00e1quina de estados, com a peculiaridade de ser determin\u00edstica. Logo, se tivermos v\u00e1rias c\u00f3pias deste programa, executando em locais distintos, mas garantirmos que cada c\u00f3pia veja exatamente a mesma entrada de dados , ent\u00e3o garantiremos que todas as c\u00f3pias transitar\u00e3o pelos mesmos estados e chegar\u00e3o ao mesmo estado final. Como difus\u00e3o totalmente ordenada pode ser usado para garantir que todas as c\u00f3pias receber\u00e3o a mesma entrada, pode ser usado para implementar esta t\u00e9cnica, conhecida como Replica\u00e7\u00e3o de M\u00e1quinas de Estados (em ingl\u00eas, State Machine Replication , ou pelo menos o seu princ\u00edpio. Mas como podemos implementar estas primitivas de difus\u00e3o usando rel\u00f3gios l\u00f3gicos? Vejamos um algoritmo, onde consideramos que todas as mensagens s\u00e3o enviadas a todos os processos, inclusive o pr\u00f3prio remetente. Difus\u00e3o Totalmente Ordenado Considerando o ponto de vista do processo \\(p\\) \\(f_p\\) \u00e9 uma fila de mensagens ordenadas pelo seus timestamps , mantida em \\(p\\) Para difundir uma mensagem \\(m\\) colocar \\(m\\) na fila enviar \\(m\\) para todos os demais processos Quando uma mensagem \\(m\\) \u00e9 recebida colocar \\(m\\) na fila se \\(m\\) n\u00e3o \u00e9 um ack enviar \\(m ack\\) de volta ao remetente de \\(m\\) (com timestamp maior que de \\(m\\) ) Seja \\(m\\) a mensagem com timestamp ts na cabe\u00e7a da fila Se para cada processo \\(q\\) , h\u00e1 uma mensagem \\(m'\\) de \\(q\\) com timestamp ts' na fila de \\(p\\) tal que \\(ts < ts'\\) entregar \\(m\\) para a aplica\u00e7\u00e3o O objetivo deste algoritmo \u00e9 de entregar mensagens na ordem de seus timestamps . Para isso, antes de entregar a mensagem \\(m\\) de menor tmestamp ts conhecido atualmente por \\(p\\) , \\(p\\) espera por mensagens com \\(timestamps\\) maiores que ts de todos os processos. Uma vez que isso aconte\u00e7a, \\(p\\) sabe que nenhuma outra mensagem que chegue depois poderia ter \\(timestamp\\) menor que ts. Para que isto funcione, \u00e9 necess\u00e1rio que os canais de comunica\u00e7\u00e3o usados sejam confi\u00e1veis (todas as mensagens enviadas s\u00e3o entregues) e FIFO (a primeira a ser enviada \u00e9 primeira a ser recebida). Exerc\u00edcio - FIFO e Confi\u00e1veis \u00c9 necess\u00e1rio que canais de comunica\u00e7\u00e3o sejam FIFO e confi\u00e1veis para que mensagens com timestamp maiores n\u00e3o sejam perdidas e para que mensagens com timestamps maiores n\u00e3o sejam reordenadas e entregues primeiro. Explique porqu\u00ea isto seria um problema; descreva execu\u00e7\u00f5es problem\u00e1ticas. Vejamos um outro algoritmo, de difus\u00e3o causalmente ordenada. Difus\u00e3o Causalmente Ordenada Considerando o ponto de vista do processo \\(p\\) \\(p\\) incrementa \\(c_p[p]\\) somente no envio de mensagens. \\(p\\) s\u00f3 entrega uma mensagem recebida de \\(q\\) , com timestamp \\(ts\\) quando \\(ts[q] = c_p[q]+1\\) \\(ts[k] \\leq c_p[k], k \\neq q\\) Difus\u00e3o Causalmente Ordenada Considere \\(c_{p3}[0,2,2]\\) e \\(ts=[1,3,0]\\) , de \\(p1\\) . O que \\(p3\\) est\u00e1 esperando? Como age ao receber mensagem com \\(ts\\) ?","title":"Comunica\u00e7\u00e3o em Grupo"},{"location":"time/logical/#exclusao-mutua-revisitada","text":"Todo Algoritmos de Exclu\u00e3o m\u00fatua baeados em LC Algoritmo de Lamport, Ricart e agrawalla Algoritmo de Maekawa Reza a lenda que Leslie Lamport desenvolveu o conceito de rel\u00f3gios l\u00f3gicos pensando na teoria da relatividade geral. \u21a9 Time, Clocks and the Ordering of Events in a Distributed System. July 5, 1978 . \u21a9 Matrix Clock \u21a9 O blog de um dos autores descreve ambas as vers\u00f5es de forma resumida. Para a vers\u00e3o completa dos algoritmos, consulte o artigo . \u21a9 Tanto no artigo quanto no blog, a imagem que descreve um exemplo do HLC parece ter um erro e onde se l\u00ea (3,13) deve-se ler (3,10,3). \u21a9","title":"Exclus\u00e3o M\u00fatua Revisitada"},{"location":"time/physical/","text":"Tempo F\u00edsico Para falarmos sobre sincroniza\u00e7\u00e3o de rel\u00f3gios em um cen\u00e1rio distribu\u00eddo, primeiro devemos entender como funcionam os rel\u00f3gios em n\u00edvel de uma \u00fanica m\u00e1quina, isto \u00e9, seus rel\u00f3gios f\u00edsicos e como s\u00e3o usados pelo sistema operacional. Rel\u00f3gios de Quartzo e At\u00f4micos Quando falamos em rel\u00f3gios, provavelmente falamos sobre rel\u00f3gios a base de quartzo. Para uma introdu\u00e7\u00e3o r\u00e1pida, assista ao seguinte v\u00eddeo. Quartzo Efeito piezoel\u00e9trico 32768Hz Erro de 0,5s por dia Em suma, um rel\u00f3gio de quartzo consiste em um diapaz\u00e3o de quartzo cortado a laser que, devido ao efeito Piezoel\u00e9trico 2 e sua forma particular, vibra a \\(32768 = 2^{15}\\) Hz 3 , e em um contador que conta cada vibra\u00e7\u00e3o, medindo a passagem do tempo. Estes rel\u00f3gios erram na medi\u00e7\u00e3o do tempo em no m\u00e1ximo \u00bds por dia , desde que operem dentro da faixa de 5 a 35C, mas isso tamb\u00e9m muda com a idade do cristal, a corrente el\u00e9trica passando por ele e tamb\u00e9m devido a imperfei\u00e7\u00f5es no cristal 1 . Computadores em geral usam rel\u00f3gios de quartzo, por serem baratos, como base de um rel\u00f3gio mantido em software. Isto \u00e9, do ponto de vista de um computador comum, o tempo \u00e9 medido com base em um rel\u00f3gio quartzo, cujos incrementos s\u00e3o capturados em um contador; o contador gera interrup\u00e7\u00f5es em intervalos programados (e.g., Linux >2.6 usa 250Hz por padr\u00e3o; m\u00e1ximo 1000Hz) e as interrup\u00e7\u00f5es causam ajustes em um rel\u00f3gio em software , um contador indireto \\(C\\) . Precis\u00e3o Dado a frequ\u00eancia padr\u00e3o de 250Hz, medi\u00e7\u00f5es de tempo menores que 4ms s\u00e3o altamente imprecisas. Como medir o tempo gasto em uma fun\u00e7\u00e3o do seu c\u00f3digo? Este rel\u00f3gio em software, \\(C\\) , que usa um rel\u00f3gio de quartzo, impreciso, pode marcar a passagem do tempo com erro para mais ou para menos. Embora o erro exato do rel\u00f3gio seja desconhecido, o mesmo \u00e9 limitado probabilisticamente. A taxa de erro \u00e9 denominada drift , \u00e9 representada por \\(\\rho\\) . Assumindo um rel\u00f3gio perfeito, \\(t\\) , temos que \\(1 - \\rho \\leq \\frac{dC}{dt} \\leq 1 + \\rho\\) . Assim, um \\(\\rho\\) de 0.1 implica em um erro de mais ou menos 10%; a figura a seguir mostra a faixa em que \\(C\\) pode operar e que o erro em rela\u00e7\u00e3o a \\(t\\) vai aumentando com a passagem do tempo. Embora adequado para humanos, o erro dos rel\u00f3gios de quartzo \u00e9 inaceit\u00e1vel em algumas opera\u00e7\u00f5es computacionais. Felizmente, os erros do destes rel\u00f3gios podem ser minimizados ao ponto de termos um erros menores que 1s em milh\u00f5es de anos, nos dispositivos conhecidos como rel\u00f3gios at\u00f4micos . Embora muito bons, os rel\u00f3gios at\u00f4micos tamb\u00e9m n\u00e3o s\u00e3o perfeitos e, devido a v\u00e1rias raz\u00f5es, podem levar tamb\u00e9m a erros. Mas o qu\u00ea mais se pode fazer no sentido de melhorar a precis\u00e3o dos rel\u00f3gios ? A resposta est\u00e1 no UTC. Tempo Universal Coordenado O UTC, de uma mistura dos nomes em Ingl\u00eas e Franc\u00eas do Tempo Universal Coordenado , um padr\u00e3o global para coordena\u00e7\u00e3o da medi\u00e7\u00e3o da passagem do tempo. Segundo o UTC, o sol est\u00e1 a pino \u00e0s 12:00 na latitude 0, ou a no m\u00e1ximo 1s deste instante; ao redor da latitude 0 grau estabelece-se uma faixa em que todos os pontos tem o mesmo hor\u00e1rio, e outras 23 faixas como esta com deslocamentos consecutivos de +-1 hora. Estas faixas, conhecidas coloquialmente como fusos, sofrem ajustes por fatores pol\u00edticos; a China, por exemplo, apesar de seu tamanho, est\u00e1 toda dentro de um mesmo hor\u00e1rio, \"correto\" para Beijing. O UTC \u00e9 definido com base no TAI, Tempo At\u00f4mico Internacional, calculado como a m\u00e9dia dos valores de rel\u00f3gios at\u00f4micos espalhados pelo globo. O TAI mede \"perfeitamente\" a passagem do tempo, mas como a rota\u00e7\u00e3o da terra \u00e9 irregular, medir perfeitamente n\u00e3o \u00e9 o adequado. Assim, o UTC leva em considera\u00e7\u00e3o o fato do dia n\u00e3o ter exatamente 24 horas e, de fato, n\u00e3o ter dura\u00e7\u00e3o constante. Por exemplo, ap\u00f3s um grande terremoto o centro de massa da terra pode ser alterado e a rota\u00e7\u00e3o ter sua velocidade aumentada ou diminu\u00edda. UTC Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60 seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61 seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2 milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59 seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary. Uma vez que tenhamos um tempo global, com o qual todos os rel\u00f3gios concordam, resolvemos os problemas apresentados acima, correto? N\u00e3o exatamente, pois os rel\u00f3gios precisam ser sincronizados com o UTC e, como vimos, mesmo que sincronizados inicialmente, rel\u00f3gios podem se distanciar uns dos outros na marca\u00e7\u00e3o do tempo. Sincroniza\u00e7\u00e3o de Rel\u00f3gios Dado o UTC, temos ent\u00e3o uma refer\u00eancia de tempo adequada para uso em sistemas computacionais, colocamos nova pergunta: Se o rel\u00f3gio se dist\u00e2ncia da medida correta da passagem do tempo, \u00e9 poss\u00edvel corrigir este distanciamento, sincronizando-o com uma fonte correta, da qual UTC \u00e9 nossa melhor aproxima\u00e7\u00e3o, para que todos percebam a mesma passagem do tempo? Embora a resposta seja negativa, no sentido de que n\u00e3o \u00e9 poss\u00edvel alcan\u00e7ar sincroniza\u00e7\u00e3o perfeita, nada nos impede de fazer um melhor esfor\u00e7o e, neste sentido, tamb\u00e9m temos que nos perguntar qual a frequ\u00eancia de sincroniza\u00e7\u00e3o? Frequ\u00eancia de Sincroniza\u00e7\u00e3o Como garantir que um rel\u00f3gio com erro m\u00e1ximo igual a \\(\\rho\\) n\u00e3o diferir\u00e1 em mais que \\(\\delta\\) unidades de tempo do UTC? Vejamos um exemplo: \\(\\rho = 0,1\\) (10%) \\(\\delta\\) = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Logo, a sincroniza\u00e7\u00e3o deve ser feita a cada 10s, i.e, \\(\\frac{\\delta}{\\rho} = \\frac{1s}{0,1} = \\frac{1s}{\\frac{1}{10}} = 10s\\) Mas, e se quisermos sincronizar dois rel\u00f3gios com UTC, um com erro \\(\\rho\\) , de forma que estes dois rel\u00f3gios n\u00e3o se distanciem mais que \\(\\delta\\) unidades, o problema \u00e9 mais dif\u00edcil? Se todos se sincronizarem com a mesma fonte, a cada \\(\\frac{\\delta}{\\rho}\\) segundos, como ambos tem um erro m\u00e1ximo de \\(\\delta\\) em rela\u00e7\u00e3o \u00e0 fonte, o erro m\u00e1ximo entre os dois n\u00f3s \u00e9 \\(2\\delta\\) . Como este erro \u00e9 o dobro do desejado, basta dobrar a frequ\u00eancia de sincroniza\u00e7\u00e3o para cortar o erro pela metade. Vejamos novamente o exemplo \\(\\rho = 0,1\\) \\(\\delta\\) = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Como cada n\u00f3 poderia estar errando em \"dire\u00e7\u00f5es\" diferentes, ap\u00f3s 5s, um n\u00f3 poderia se adiantar em 0,5s enquanto o outro poderia se atrasar pela mesma quantidade de tempo, somando 1s de diferen\u00e7a. Logo, eles tem que se sincronizar a cada 5s, i.e, \\(\\frac{\\delta}{2\\rho} = \\frac{1s}{2 \\times 0,1} = \\frac{1s}{0,2} = 5s\\) Finalmente, se considerarmos rel\u00f3gios com erros distintos, \\(\\rho, \\rho'\\) , a sincroniza\u00e7\u00e3o deve ser feita pela m\u00e9dia dos erros, isto \u00e9, \\(\\frac{\\delta}{2\\frac{\\rho + \\rho'}{2}} = \\frac{\\delta}{\\rho + \\rho'}\\) . Agora que voc\u00ea j\u00e1 tem uma fonte confi\u00e1vel de tempo, o UTC, e sabe com que frequ\u00eancia sincronizar os rel\u00f3gios, s\u00f3 nos falta fazer a sincroniza\u00e7\u00e3o. Contudo, falta ainda definir o protocolo pelo qual a sincroniza\u00e7\u00e3o \u00e9 feita e exatamente com quem, uma vez que simplesmente UTC \u00e9 muito gen\u00e9rico. Comecemos com vetor \"pr\u00f3ximo\" do UTC, os rel\u00f3gios at\u00f4micos em sat\u00e9lites GPS. Global Positioning System Receptores GPS, com seus rel\u00f3gios sincronizados com os dos sat\u00e9lites, que difundem regularmente sua posi\u00e7\u00e3o e o instante em que a difus\u00e3o \u00e9 feita, determinam sua posi\u00e7\u00e3o relativa aos sat\u00e9lites, em uma t\u00e9cnica conhecida como trilatera\u00e7\u00e3o, que consiste em determinar a dist\u00e2ncia do receptor em termos dos eixos \\(x\\) , \\(y\\) e \\(z\\) em rela\u00e7\u00e3o a cada um dos sat\u00e9lites. Em outras palavras, baseado na informa\u00e7\u00e3o de um sat\u00e9lite, o receptor determina sua dist\u00e2ncia ao mesmo e, portanto, determina que est\u00e1 em uma esfera no entorno do sat\u00e9lite. Combinando a informa\u00e7\u00e3o de 2 sat\u00e9lites, a posi\u00e7\u00e3o do receptor \u00e9 limitada a uma circunfer\u00eancia, isto \u00e9, a interse\u00e7\u00e3o de duas esferas. Com um terceiro sat\u00e9lite, a posi\u00e7\u00e3o \u00e9 reduzida a dois pontos, a interse\u00e7\u00e3o de uma esfera e uma circunfer\u00eancia, sendo um no espa\u00e7o e que pode ser facilmente descartado. Contudo, para que funcione, rel\u00f3gios dos sat\u00e9lites e receptores precisam estar sincronizados para que o c\u00e1lculo da dist\u00e2ncia possa ser feito, mas sincronizar os rel\u00f3gios \u00e9 exatamente o problema que estamos tentando resolver. Para contornar esta restri\u00e7\u00e3o, usa-se um quarto sat\u00e9lite, para determinar a dist\u00e2ncia na dimens\u00e3o do tempo . Assim, temos uma receita simples para sincroniza\u00e7\u00e3o de rel\u00f3gios com UTC: Coloque um receptor GPS em cada n\u00f3 do seu sistema Tenha erro de 0,1ns a 1ms do UTC Apesar da queda dos pre\u00e7os dos receptores, colocar um GPS em cada dispositivo pode ser custoso demais. Em vez disso, podemos usar um recurso amplamente dispon\u00edvel, redes de computadores, e sincronizar com outra m\u00e1quina, que fez o investimento necess\u00e1rio para manter o erro baixo. Para estes computadores \"de segundo escal\u00e3o\", a receita ent\u00e3o \u00e9: Pergunte que horas s\u00e3o. Use a resposta para ajustar o rel\u00f3gio local. Considere o erro introduzido pela lat\u00eancia vari\u00e1vel da rede. Sendo mais espec\u00edfico, nomeemos os processos como cliente, quem pergunta, e servidor, quem responde, e os instantes em que os eventos acontecem: Cliente pergunta \"que horas s\u00e3o?\" - \\(t_0\\) Servidor recebe pergunta - \\(t_1\\) Servidor anota o valor do rel\u00f3gio - \\(t_s\\) Servidor envia resposta - \\(t_2\\) Cliente recebe resposta - \\(t_3\\) Esta receita b\u00e1sica pode ser ajustada de diversas formas, sendo a primeira dada pelo algoritmo de Cristian. Algoritmo de Cristian No algoritmo de Cristian, assumimos que o rel\u00f3gio do Cliente \u00e9 bom o suficiente para medir a passagem de tempo em per\u00edodos curtos, mesmo que tenha uma drift rate consider\u00e1vel em per\u00edodos mais longos. Assim, podemos executar o algoritmo gen\u00e9rico, adicionando o seguinte: Assuma \\(t_1 = t_s = t_2\\) Assuma \\(\\frac{t_3-t_0}{2}\\) como o tempo de transmiss\u00e3o da resposta (m\u00e9dia da ida e da volta) Cliente ajusta rel\u00f3gio para \\(C = t_s + \\frac{t_3-t_0}{2}\\) Mas e a aproxima\u00e7\u00e3o \\(\\frac{t_3-t_0}{2}\\) , \u00e9 boa? \u00c9 uma aproxima\u00e7\u00e3o t\u00e3o boa quanto poss\u00edvel, pois medir a lat\u00eancia em uma \u00fanica dire\u00e7\u00e3o demandaria rel\u00f3gios sincronizados, exatamente o que estamos tentando resolver com este algoritmo. Quero dizer, temos uma depend\u00eancia circular aqui, como o v\u00eddeo a seguir mostra. Bom, na verdade no nosso caso \u00e9 um pouco mais f\u00e1cil de dizer que as duas dire\u00e7\u00f5es tem lat\u00eancias diferentes, pois sabemos que, em uma rede de larga escala, \u00e9 poss\u00edvel e comum que pacotes tomem caminhos diferentes na ida e na volta. Neste caso, podemos estimar o erro que a aproxima\u00e7\u00e3o introduz na sincroniza\u00e7\u00e3o, desde que tenhamos estimativas de tempo m\u00ednimo para a transmiss\u00e3o em cada sentido, \\(T_{min}\\) . A figura a seguir demonstra o erro desta t\u00e9cnica 4 , onde \\(t_3 - t_0\\) corresponde ao tempo medido entre o envio da requisi\u00e7\u00e3o e recep\u00e7\u00e3o da resposta as setas vermelhas indicam o caso em que a requisi\u00e7\u00e3o foi muito mais r\u00e1pida que resposta ( \\(T_{min}\\) ) as setas verdes indicam o caso em que a resposta foi muito mais r\u00e1pida que requisi\u00e7\u00e3o ( \\(T_{min}\\) ) No caso vermelho, a aproxima\u00e7\u00e3o \\(\\frac{t_3-t_0}{2}\\) \u00e9 muito menor que o tempo de propaga\u00e7\u00e3o da resposta, \\(t3 - t1\\) , e no caso verde a aproxima\u00e7\u00e3o \u00e9 maior que o tempo \\(t_3 - t_2\\) . Em ambos os casos, o erro \u00e9 est\u00e1 limitado a \\(\\frac{t_2 - t1}{2}\\) , ou seja, \\(+- \\frac{t_3 - t_0}{2} - T_{min}\\) . Algoritmo de Berkeley Enquanto o algoritmo de Cristian permite sincronizar um n\u00f3 com uma fonte, outro algoritmo, de Berkeley, permite sincronizar m\u00faltiplos n\u00f3s uns com os outros. Este algoritmo assume o que n\u00e3o h\u00e1 uma \"fonte da verdade\" do tempo, mas sim a necessidade de que todos os processos convirjam para um mesmo valor do rel\u00f3gio. \u00c9 como nos filmes de espi\u00e3o em que os rel\u00f3gios s\u00e3o sincronizados; pouco importa se a bomba explodir\u00e1 10:57 ou 10:59, desde que todos concordem quando isso vai acontecer. Isso \u00e9 o que chamamos de sincroniza\u00e7\u00e3o interna em vez de externa, como provido pelo algoritmo de Cristian. O algoritmo de Berkeley requer que todo n\u00f3 execute um processo de sincroniza\u00e7\u00e3o, um \"daemon\", e separa seus pap\u00e9is em dois tipos, prim\u00e1rio e secund\u00e1rio . O papel do prim\u00e1rio pode ser rotacionado entre os v\u00e1rios processos, sem perdas para sua execu\u00e7\u00e3o. O algoritmo ent\u00e3o \u00e9 executa como se segue: Prim\u00e1rio pergunta \"que horas s\u00e3o\" para cada secund\u00e1rio (mensages 1,2,3 e 4) Secund\u00e1rio responde com valor atual do rel\u00f3gio (mensagens 5,6,7 e 8) Prim\u00e1rio ajusta as respostas de acordo com o algoritmo de Cristian, para minimizar erros. Prim\u00e1rio computa m\u00e9dia dos valores recebidos, ignorando outliers (como o da mensagem 8). Prim\u00e1rio envia ajustes para secund\u00e1rios (mensagens 8,9,10 e 11) Secund\u00e1rio executa ajuste sugerido pelo prim\u00e1rio. sequenceDiagram autonumber note over Prim\u00e1rio: 10:00 note over Secund\u00e1rio1: 10:06 note over Secund\u00e1rio2: 10:15 note over Secund\u00e1rio3: 23:18 par Pergunta Prim\u00e1rio->>Prim\u00e1rio: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio1: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio2: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio3: Que horas s\u00e3o? end par Resposta Prim\u00e1rio->>Prim\u00e1rio: 10:00 and Secund\u00e1rio1->>Prim\u00e1rio: 10:06 and Secund\u00e1rio2->>Prim\u00e1rio: 10:15 and rect rgb(255, 0, 0) Secund\u00e1rio3->>Prim\u00e1rio: 23:18 end end par Ajuste Prim\u00e1rio->>Prim\u00e1rio: 10:07 and Prim\u00e1rio->>Secund\u00e1rio1: 10:07 and Prim\u00e1rio->>Secund\u00e1rio2: 10:07 and Prim\u00e1rio->>Secund\u00e1rio3: 10:07 end Embora interessantes, estes algoritmos n\u00e3o s\u00e3o normalmente usados, pelo menos n\u00e3o em sua forma \"pura\", em sistemas computacionais. Em vez deles, usamos o Network Time Protocol (NTP). Network Time Protocol. O NTP foi especificado originalmente na RFC 1305 6 e estendido pelas RFC 5905-5908 7 essencialmente para suportar IPv6 e reduzir o erro de sincroniza\u00e7\u00e3o para at\u00e9 10 \\(\\mu\\) s. Os diversos componentes do NTP s\u00e3o organizados em camadas, ou estrata , de forma que a informa\u00e7\u00e3o do tempo flui da camada 0 ( stratum 0 ) at\u00e9 a camada 15 ( stratum 15). Os componentes n\u00e3o est\u00e3o presos a camadas, que podem ser alteradas a medida que falhas acontecem e s\u00e3o dedicadas, e novos caminhos s\u00e3o encontrados usando-se o algoritmo de \u00e1rvore geradora m\u00ednima Bellman-Ford, al\u00e9m de caminhos redundantes que conferem propriedades de toler\u00e2ncia a falhas \u00e0 topologia. 5 Esta organiza\u00e7\u00e3o hier\u00e1rquica leva a cada camada garantir um n\u00edvel de sincroniza\u00e7\u00e3o diferente e permite escalar o uso do protocolo para n\u00edveis globais , usando a Internet como meio . Stratum 0: rel\u00f3gios at\u00f4micos/receptores GPS Stratum 1: ms to stratum 0 Stratum 2: contata m\u00faltiplos stratum 1 e pares Strata 3...15 Stratum 16: dessincronizado Toda a comunica\u00e7\u00e3o entre n\u00f3s pode ser autenticada , garantindo que a sincroniza\u00e7\u00e3o n\u00e3o seja facilmente manipulada e erros s\u00e3o minimizados pela coleta e uso de estat\u00edsticas de lat\u00eancia de comunica\u00e7\u00e3o, para evitar desvios quando fontes se tornam problem\u00e1ticas. NTP tem m\u00faltiplas formas de execu\u00e7\u00e3o, adequadas para diferentes ambientes. Modo multicast: propaga tempo em rede local RPC: algoritmo de Cristian Sim\u00e9trico: parecido com Berkeley Na pr\u00e1tica, boa parte dos dispositivos usa uma vers\u00e3o simplificada do NTP, o SNTP ( Simple Network Time Protocol ), adequada aos n\u00f3s nas folhas da hierarquia . O SNTP \u00e9 essencialmente o algoritmo de Cristian: \\(\\delta = (t_4-t_1)-(t_2-t_3)\\) \\(t = \\frac{(t_2-t_1)+(t3-t_4)}{2}\\) \\(t_c = t_4+t\\) Por exemplo, \\(t_1 = 1100, t_2 = 800, t_3=850, t_4=1200\\) \\(t = ((800-1100)+(850-1200))/2 = (-300 -350)/ = -325\\) \\(t_c = 1200-325 = 875\\) O Comit\u00ea Gestor da Internet, CGI , mantem uma excelente p\u00e1gina sobre o NTP, com mais detalhes do que apresentado aqui, em NTP.br . PTP - Precision Time Protocol Mesmo com melhoria do protocolo e baratemento de dispositivos GPS, h\u00e1 ainda a necessidade de sincroniza\u00e7\u00e3o sub-microssegundo e barata. O Precision Time Protocol , PTP, especifica\u00e7\u00e3o IEEE 1588 8 tenta cobrir este nicho. Se escrutinarmos o PTP, veremos que o protocolo em si n\u00e3o difere muito do NTP. Contudo, o PTP usa interfaces de rede especilizadas para fazer o timestamping dos eventos do protocolo, conseguindo remover a lat\u00eancia nos dispositivos processando as mensagens e reduzindo o erro do protocolo at\u00e9 sub \\(\\mu\\) (versus ordem de \\(ms\\) no NTP). Mais detalhes sobre o protocolo est\u00e3o fora do escopo deste documento, mas podem ser facilmente encontrados nos links dados. Nunca volte no tempo Qualquer que seja o algoritmo utilizado, \u00e9 provavelmente uma boa ideia nunca voltar no tempo . Mesmo que o universo n\u00e3o seja destru\u00eddo no processo, voltar no tempo poderia levar a situa\u00e7\u00f5es estranhas como um dado ter data de edi\u00e7\u00e3o anterior a data de cria\u00e7\u00e3o. Para evitar estas situa\u00e7\u00f5es, devem ser feitos de ajustes graduais nos rel\u00f3gios, que acelerem ou desacelerem o rel\u00f3gio \\(C\\) em rela\u00e7\u00e3o a \\(t\\) (ou sua melhor aproxima\u00e7\u00e3o, pelo ajuste frequ\u00eancia de interrup\u00e7\u00e3o para atrasar/adiantar rel\u00f3gio ou ajustes dos incrementos com cada interrup\u00e7\u00e3o . Isso far\u00e1 com que as curvas no seguinte gr\u00e1fico convirjam. A exce\u00e7\u00e3o a esta regra deve ser restrita a corre\u00e7\u00f5es ap\u00f3s longos per\u00edodos em que o rel\u00f3gio dorme. Usos de rel\u00f3gios sincronizados Assumindo que tenhamos sincronizado os rel\u00f3gios de um sistema computacional, o que podemos fazer agora? H\u00e1 uma s\u00e9rie de problemas interessantes que podem ser resolvidos, como autentica\u00e7\u00e3o , termina\u00e7\u00e3o de transa\u00e7\u00f5es , aloca\u00e7\u00e3o de leases e diversos outros exemplos. 9 Um exemplo interessante \u00e9 a ordena\u00e7\u00e3o de eventos em um banco de dados. Para entender este problema, considere um cen\u00e1rio com um Sistema Banc\u00e1rio replicado, isto \u00e9, com v\u00e1rias c\u00f3pias. No exemplo, sem perda de generalidade, nos focamos em duas c\u00f3pias em lados opostos de uma rede de larga escala. Clientes disparam opera\u00e7\u00f5es como saques, dep\u00f3sitos e transfer\u00eancias, por meio de mensagens para as duas c\u00f3pias. Mensagens para a c\u00f3pia pr\u00f3xima do cliente (em verde) s\u00e3o entregues rapidamente, enquanto mensagens para a c\u00f3pia distante (em vermelho), demoram mais para ser entregues. Imagine que o usu\u00e1rio U1 envie o comando C1 atualizar saldo da conta para USD 10 10 e que o usu\u00e1rio U2 envie o comando C2 atualizar saldo da conta para USD 20 . Se os comandos chegam primeiro para a r\u00e9plica mais pr\u00f3xima e s\u00e3o executados na ordem em que chegam, ao final da execu\u00e7\u00e3o a r\u00e9plica R1 ter\u00e1 executado C1 seguido de C2, tendo saldo da conta como USD 20, enquanto R2 ter\u00e1 executado C2 seguido de C1 e ter\u00e1 como saldo na conta USD 10. O problema est\u00e1 na ordem de execu\u00e7\u00e3o das opera\u00e7\u00f5es. Assuma que rel\u00f3gios est\u00e3o perfeitamente sincronizados e que toda mensagem/update carrega consigo o timestamp de quando foi enviada. E se as r\u00e9plicas processarem mensagens na ordem que foram enviadas, como identificado pelos seus timestamps ? 11 Assim, se C1 foi enviado antes de C2, C1 tem um timestamp menor que C2 e ser\u00e1 executada primeiro em ambas as r\u00e9plicas, o que resolve nosso problema, correto? Parcialmente, pois ainda temos o problema de identificar que nenhuma outra mensagem ainda por ser entregue foi enviada antes. Para isto, precisamos estender o modelo e assumir que o tempo de propaga\u00e7\u00e3o m\u00e1ximo de uma mensagem, \\(\\tau\\) , \u00e9 finito e conhecido . Assim, ao receber um comando com timestamp \\(t\\) , uma r\u00e9plica espera at\u00e9 \\(t + \\tau\\) antes de execut\u00e1-lo, pois qualquer comando com timestamp \\(t' < t\\) deve ter sido entregue at\u00e9 \\(t+\\tau\\) . Implementar este protocolo \u00e9 muito simples: Ordena\u00e7\u00e3o de Mensagens por Timestamp Quando enviar uma mensagem, aumente-a com o valor atual do rel\u00f3gio. Quando receber uma mensagem, coloque-a em uma fila ordenada por timestamp . Quando o rel\u00f3gio marcar um tempo maior que \\(t + \\tau\\) , onde \\(t\\) \u00e9 o timestamp da mensagem na cabe\u00e7a da fila, retire a mensagem da cabe\u00e7a da fila e execute o comando correspondente. Embora correto, este protocolo, ou melhor, o modelo, n\u00e3o leva em considera\u00e7\u00e3o a dessincroniza\u00e7\u00e3o inerente dos rel\u00f3gios em um sistema distribu\u00eddo. Como faz\u00ea-lo, supondo uma diverg\u00eancia m\u00e1xima de \\(\\Delta\\) entre quaisquer dois rel\u00f3gios, algo que pode ser arranjado, como visto antes, sincronizando-se os rel\u00f3gios a cada \\(\\frac{\\Delta}{2\\rho}\\) . Se \\(\\Delta\\) \u00e9 a diferen\u00e7a m\u00e1xima entre rel\u00f3gios, ent\u00e3o se uma mensagem \u00e9 enviada no instante \\(t\\) , ent\u00e3o at\u00e9 \\(\\Delta +t\\) , outro processo, atrasado em rela\u00e7\u00e3o ao primeiro, poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) . Tal mensagem pode demorar at\u00e9 \\(\\tau\\) para ser entregue \u00e0 r\u00e9plica, ou seja, no instante \\(t + \\tau + \\Delta\\) , do ponto de vista do primeiro cliente. Se a r\u00e9plica estiver sincronizada com cliente, ent\u00e3o se esperar at\u00e9 \\(t + \\tau + \\Delta\\) para executar o comando, o far\u00e1 de forma segura. Se estiver atrasada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o acabar\u00e1 por esperar al\u00e9m do necess\u00e1rio, mas sem violar a corretude do sistema. Finalmente, se a r\u00e9plica estiver adiantada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o seu rel\u00f3gio alcan\u00e7ar\u00e1 \\(t + \\tau + \\Delta\\) antes do rel\u00f3gio do primeiro cliente, mas isso n\u00e3o \u00e9 um problema. Isto porqu\u00ea, o \u00faltimo instante em que o cliente 2 poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) \u00e9 o instante em que o rel\u00f3gio da r\u00e9plica marcar \\(t + \\Delta\\) , e portanto dever\u00e1 tamb\u00e9m ser recebido at\u00e9 que o mesmo rel\u00f3gio marque \\(t + \\tau + \\Delta\\) . O mesmo racioc\u00ednio pode ser usado para definir um protocolo de acesso recursos para os quais leases s\u00e3o distribu\u00eddos, onde um lease \u00e9 uma permiss\u00e3o de acesso durante uma janela de tempo , emitida por um coordenador (possivelmente eleito usando os algoritmos vistos anteriormente), e \\(\\Delta\\) \u00e9 o m\u00e1ximo de dessincronismo entre os rel\u00f3gios. O seguinte protocolo resolve este problema: Aloca\u00e7\u00e3o de Lease Ao receber um lease para a janela de tempo \\(t_1\\) a \\(t_2\\) espera at\u00e9 \\(t_1 + \\Delta\\) usa o recurso at\u00e9 \\(t_2\\) . Se rel\u00f3gio estiver adiantado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1+\\Delta\\) enquanto o anterior acha que \u00e9 \\(t_1\\) ; exclus\u00e3o m\u00fatua garantida. Se rel\u00f3gio estiver atrasado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1 - \\Delta\\) , e continua esperando, enquanto ele acha que j\u00e1 \u00e9 \\(t_1\\) e para de usar; exclus\u00e3o m\u00fatua garantida. Recurso fica ocioso por \\(\\Delta\\) , em m\u00e9dia, a cada lease. Devido ao alto custo de se manter o recurso n\u00e3o utilizado, \\(\\Delta\\) deve ser feito t\u00e3o pequeno quanto poss\u00edvel, como feito, por exemplo, o Google True Time que consegue manter a diferen\u00e7a em sub-milisegundos usando rel\u00f3gios at\u00f4micos dentro de seus datacenters e um API para gera\u00e7\u00e3o de timestamps. Nas solu\u00e7\u00f5es anteriores, um n\u00f3 precisa esperar por muito tempo antes de usar um recurso . E se ele aprendesse antes que os outros n\u00f3s n\u00e3o far\u00e3o requisi\u00e7\u00f5es, que n\u00e3o haver\u00e3o sobreposi\u00e7\u00f5es de requisi\u00e7\u00f5es? E se houvesse um rel\u00f3gio que avan\u00e7asse n\u00e3o com o tempo, mas com eventos interessantes do sistema? Esta \u00e9 a ideia dos rel\u00f3gios l\u00f3gicos . Refer\u00eancias Google TrueTime Explain that stuff. \u21a9 Distor\u00e7\u00e3o mec\u00e2nica gera corrente el\u00e9trica e submiss\u00e3o a uma corrente el\u00e9trica gera uma distor\u00e7\u00e3o mec\u00e2nica. \u21a9 32768 \u00e9 a primeira pot\u00eancia de 2 maior que 20000, a maior frequ\u00eancia sonora aud\u00edvel aos seres humanos. \u21a9 Adaptado das notas de aula dispon\u00edveis aqui . \u21a9 Fonte: Benjamin D. Esham, (bdesham) - Based upon Ntp.png by Kim Meyrick \u21a9 RFC 1305 , 1991/1992 \u21a9 RFC 5905-5908,2010 \u21a9 IEEE 1588TM Standard for A Precision Clock Synchronization Protocol for Networked Measurement and Control Systems . \u21a9 Liskov, B.: Distrib Comput (1993) 6: 211. doi:10.1007/BF02242709 \u21a9 Unidade Simples de Dinheiros. \u21a9 Empates s\u00e3o quebrados pelo identificador do processo, isto \u00e9, se duas mensagens s\u00e3o produzidas ao mesmo tempo por U1 e U2, ent\u00e3o o a mensagem de U1 tem preced\u00eancia na execu\u00e7\u00e3o. \u21a9","title":"Tempo F\u00edsico"},{"location":"time/physical/#tempo-fisico","text":"Para falarmos sobre sincroniza\u00e7\u00e3o de rel\u00f3gios em um cen\u00e1rio distribu\u00eddo, primeiro devemos entender como funcionam os rel\u00f3gios em n\u00edvel de uma \u00fanica m\u00e1quina, isto \u00e9, seus rel\u00f3gios f\u00edsicos e como s\u00e3o usados pelo sistema operacional.","title":"Tempo F\u00edsico"},{"location":"time/physical/#relogios-de-quartzo-e-atomicos","text":"Quando falamos em rel\u00f3gios, provavelmente falamos sobre rel\u00f3gios a base de quartzo. Para uma introdu\u00e7\u00e3o r\u00e1pida, assista ao seguinte v\u00eddeo. Quartzo Efeito piezoel\u00e9trico 32768Hz Erro de 0,5s por dia Em suma, um rel\u00f3gio de quartzo consiste em um diapaz\u00e3o de quartzo cortado a laser que, devido ao efeito Piezoel\u00e9trico 2 e sua forma particular, vibra a \\(32768 = 2^{15}\\) Hz 3 , e em um contador que conta cada vibra\u00e7\u00e3o, medindo a passagem do tempo. Estes rel\u00f3gios erram na medi\u00e7\u00e3o do tempo em no m\u00e1ximo \u00bds por dia , desde que operem dentro da faixa de 5 a 35C, mas isso tamb\u00e9m muda com a idade do cristal, a corrente el\u00e9trica passando por ele e tamb\u00e9m devido a imperfei\u00e7\u00f5es no cristal 1 . Computadores em geral usam rel\u00f3gios de quartzo, por serem baratos, como base de um rel\u00f3gio mantido em software. Isto \u00e9, do ponto de vista de um computador comum, o tempo \u00e9 medido com base em um rel\u00f3gio quartzo, cujos incrementos s\u00e3o capturados em um contador; o contador gera interrup\u00e7\u00f5es em intervalos programados (e.g., Linux >2.6 usa 250Hz por padr\u00e3o; m\u00e1ximo 1000Hz) e as interrup\u00e7\u00f5es causam ajustes em um rel\u00f3gio em software , um contador indireto \\(C\\) . Precis\u00e3o Dado a frequ\u00eancia padr\u00e3o de 250Hz, medi\u00e7\u00f5es de tempo menores que 4ms s\u00e3o altamente imprecisas. Como medir o tempo gasto em uma fun\u00e7\u00e3o do seu c\u00f3digo? Este rel\u00f3gio em software, \\(C\\) , que usa um rel\u00f3gio de quartzo, impreciso, pode marcar a passagem do tempo com erro para mais ou para menos. Embora o erro exato do rel\u00f3gio seja desconhecido, o mesmo \u00e9 limitado probabilisticamente. A taxa de erro \u00e9 denominada drift , \u00e9 representada por \\(\\rho\\) . Assumindo um rel\u00f3gio perfeito, \\(t\\) , temos que \\(1 - \\rho \\leq \\frac{dC}{dt} \\leq 1 + \\rho\\) . Assim, um \\(\\rho\\) de 0.1 implica em um erro de mais ou menos 10%; a figura a seguir mostra a faixa em que \\(C\\) pode operar e que o erro em rela\u00e7\u00e3o a \\(t\\) vai aumentando com a passagem do tempo. Embora adequado para humanos, o erro dos rel\u00f3gios de quartzo \u00e9 inaceit\u00e1vel em algumas opera\u00e7\u00f5es computacionais. Felizmente, os erros do destes rel\u00f3gios podem ser minimizados ao ponto de termos um erros menores que 1s em milh\u00f5es de anos, nos dispositivos conhecidos como rel\u00f3gios at\u00f4micos . Embora muito bons, os rel\u00f3gios at\u00f4micos tamb\u00e9m n\u00e3o s\u00e3o perfeitos e, devido a v\u00e1rias raz\u00f5es, podem levar tamb\u00e9m a erros. Mas o qu\u00ea mais se pode fazer no sentido de melhorar a precis\u00e3o dos rel\u00f3gios ? A resposta est\u00e1 no UTC.","title":"Rel\u00f3gios de Quartzo e At\u00f4micos"},{"location":"time/physical/#tempo-universal-coordenado","text":"O UTC, de uma mistura dos nomes em Ingl\u00eas e Franc\u00eas do Tempo Universal Coordenado , um padr\u00e3o global para coordena\u00e7\u00e3o da medi\u00e7\u00e3o da passagem do tempo. Segundo o UTC, o sol est\u00e1 a pino \u00e0s 12:00 na latitude 0, ou a no m\u00e1ximo 1s deste instante; ao redor da latitude 0 grau estabelece-se uma faixa em que todos os pontos tem o mesmo hor\u00e1rio, e outras 23 faixas como esta com deslocamentos consecutivos de +-1 hora. Estas faixas, conhecidas coloquialmente como fusos, sofrem ajustes por fatores pol\u00edticos; a China, por exemplo, apesar de seu tamanho, est\u00e1 toda dentro de um mesmo hor\u00e1rio, \"correto\" para Beijing. O UTC \u00e9 definido com base no TAI, Tempo At\u00f4mico Internacional, calculado como a m\u00e9dia dos valores de rel\u00f3gios at\u00f4micos espalhados pelo globo. O TAI mede \"perfeitamente\" a passagem do tempo, mas como a rota\u00e7\u00e3o da terra \u00e9 irregular, medir perfeitamente n\u00e3o \u00e9 o adequado. Assim, o UTC leva em considera\u00e7\u00e3o o fato do dia n\u00e3o ter exatamente 24 horas e, de fato, n\u00e3o ter dura\u00e7\u00e3o constante. Por exemplo, ap\u00f3s um grande terremoto o centro de massa da terra pode ser alterado e a rota\u00e7\u00e3o ter sua velocidade aumentada ou diminu\u00edda. UTC Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60 seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61 seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2 milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59 seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary. Uma vez que tenhamos um tempo global, com o qual todos os rel\u00f3gios concordam, resolvemos os problemas apresentados acima, correto? N\u00e3o exatamente, pois os rel\u00f3gios precisam ser sincronizados com o UTC e, como vimos, mesmo que sincronizados inicialmente, rel\u00f3gios podem se distanciar uns dos outros na marca\u00e7\u00e3o do tempo.","title":"Tempo Universal Coordenado"},{"location":"time/physical/#sincronizacao-de-relogios","text":"Dado o UTC, temos ent\u00e3o uma refer\u00eancia de tempo adequada para uso em sistemas computacionais, colocamos nova pergunta: Se o rel\u00f3gio se dist\u00e2ncia da medida correta da passagem do tempo, \u00e9 poss\u00edvel corrigir este distanciamento, sincronizando-o com uma fonte correta, da qual UTC \u00e9 nossa melhor aproxima\u00e7\u00e3o, para que todos percebam a mesma passagem do tempo? Embora a resposta seja negativa, no sentido de que n\u00e3o \u00e9 poss\u00edvel alcan\u00e7ar sincroniza\u00e7\u00e3o perfeita, nada nos impede de fazer um melhor esfor\u00e7o e, neste sentido, tamb\u00e9m temos que nos perguntar qual a frequ\u00eancia de sincroniza\u00e7\u00e3o? Frequ\u00eancia de Sincroniza\u00e7\u00e3o Como garantir que um rel\u00f3gio com erro m\u00e1ximo igual a \\(\\rho\\) n\u00e3o diferir\u00e1 em mais que \\(\\delta\\) unidades de tempo do UTC? Vejamos um exemplo: \\(\\rho = 0,1\\) (10%) \\(\\delta\\) = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Logo, a sincroniza\u00e7\u00e3o deve ser feita a cada 10s, i.e, \\(\\frac{\\delta}{\\rho} = \\frac{1s}{0,1} = \\frac{1s}{\\frac{1}{10}} = 10s\\) Mas, e se quisermos sincronizar dois rel\u00f3gios com UTC, um com erro \\(\\rho\\) , de forma que estes dois rel\u00f3gios n\u00e3o se distanciem mais que \\(\\delta\\) unidades, o problema \u00e9 mais dif\u00edcil? Se todos se sincronizarem com a mesma fonte, a cada \\(\\frac{\\delta}{\\rho}\\) segundos, como ambos tem um erro m\u00e1ximo de \\(\\delta\\) em rela\u00e7\u00e3o \u00e0 fonte, o erro m\u00e1ximo entre os dois n\u00f3s \u00e9 \\(2\\delta\\) . Como este erro \u00e9 o dobro do desejado, basta dobrar a frequ\u00eancia de sincroniza\u00e7\u00e3o para cortar o erro pela metade. Vejamos novamente o exemplo \\(\\rho = 0,1\\) \\(\\delta\\) = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Como cada n\u00f3 poderia estar errando em \"dire\u00e7\u00f5es\" diferentes, ap\u00f3s 5s, um n\u00f3 poderia se adiantar em 0,5s enquanto o outro poderia se atrasar pela mesma quantidade de tempo, somando 1s de diferen\u00e7a. Logo, eles tem que se sincronizar a cada 5s, i.e, \\(\\frac{\\delta}{2\\rho} = \\frac{1s}{2 \\times 0,1} = \\frac{1s}{0,2} = 5s\\) Finalmente, se considerarmos rel\u00f3gios com erros distintos, \\(\\rho, \\rho'\\) , a sincroniza\u00e7\u00e3o deve ser feita pela m\u00e9dia dos erros, isto \u00e9, \\(\\frac{\\delta}{2\\frac{\\rho + \\rho'}{2}} = \\frac{\\delta}{\\rho + \\rho'}\\) . Agora que voc\u00ea j\u00e1 tem uma fonte confi\u00e1vel de tempo, o UTC, e sabe com que frequ\u00eancia sincronizar os rel\u00f3gios, s\u00f3 nos falta fazer a sincroniza\u00e7\u00e3o. Contudo, falta ainda definir o protocolo pelo qual a sincroniza\u00e7\u00e3o \u00e9 feita e exatamente com quem, uma vez que simplesmente UTC \u00e9 muito gen\u00e9rico. Comecemos com vetor \"pr\u00f3ximo\" do UTC, os rel\u00f3gios at\u00f4micos em sat\u00e9lites GPS.","title":"Sincroniza\u00e7\u00e3o de Rel\u00f3gios"},{"location":"time/physical/#global-positioning-system","text":"Receptores GPS, com seus rel\u00f3gios sincronizados com os dos sat\u00e9lites, que difundem regularmente sua posi\u00e7\u00e3o e o instante em que a difus\u00e3o \u00e9 feita, determinam sua posi\u00e7\u00e3o relativa aos sat\u00e9lites, em uma t\u00e9cnica conhecida como trilatera\u00e7\u00e3o, que consiste em determinar a dist\u00e2ncia do receptor em termos dos eixos \\(x\\) , \\(y\\) e \\(z\\) em rela\u00e7\u00e3o a cada um dos sat\u00e9lites. Em outras palavras, baseado na informa\u00e7\u00e3o de um sat\u00e9lite, o receptor determina sua dist\u00e2ncia ao mesmo e, portanto, determina que est\u00e1 em uma esfera no entorno do sat\u00e9lite. Combinando a informa\u00e7\u00e3o de 2 sat\u00e9lites, a posi\u00e7\u00e3o do receptor \u00e9 limitada a uma circunfer\u00eancia, isto \u00e9, a interse\u00e7\u00e3o de duas esferas. Com um terceiro sat\u00e9lite, a posi\u00e7\u00e3o \u00e9 reduzida a dois pontos, a interse\u00e7\u00e3o de uma esfera e uma circunfer\u00eancia, sendo um no espa\u00e7o e que pode ser facilmente descartado. Contudo, para que funcione, rel\u00f3gios dos sat\u00e9lites e receptores precisam estar sincronizados para que o c\u00e1lculo da dist\u00e2ncia possa ser feito, mas sincronizar os rel\u00f3gios \u00e9 exatamente o problema que estamos tentando resolver. Para contornar esta restri\u00e7\u00e3o, usa-se um quarto sat\u00e9lite, para determinar a dist\u00e2ncia na dimens\u00e3o do tempo . Assim, temos uma receita simples para sincroniza\u00e7\u00e3o de rel\u00f3gios com UTC: Coloque um receptor GPS em cada n\u00f3 do seu sistema Tenha erro de 0,1ns a 1ms do UTC Apesar da queda dos pre\u00e7os dos receptores, colocar um GPS em cada dispositivo pode ser custoso demais. Em vez disso, podemos usar um recurso amplamente dispon\u00edvel, redes de computadores, e sincronizar com outra m\u00e1quina, que fez o investimento necess\u00e1rio para manter o erro baixo. Para estes computadores \"de segundo escal\u00e3o\", a receita ent\u00e3o \u00e9: Pergunte que horas s\u00e3o. Use a resposta para ajustar o rel\u00f3gio local. Considere o erro introduzido pela lat\u00eancia vari\u00e1vel da rede. Sendo mais espec\u00edfico, nomeemos os processos como cliente, quem pergunta, e servidor, quem responde, e os instantes em que os eventos acontecem: Cliente pergunta \"que horas s\u00e3o?\" - \\(t_0\\) Servidor recebe pergunta - \\(t_1\\) Servidor anota o valor do rel\u00f3gio - \\(t_s\\) Servidor envia resposta - \\(t_2\\) Cliente recebe resposta - \\(t_3\\) Esta receita b\u00e1sica pode ser ajustada de diversas formas, sendo a primeira dada pelo algoritmo de Cristian.","title":"Global Positioning System"},{"location":"time/physical/#algoritmo-de-cristian","text":"No algoritmo de Cristian, assumimos que o rel\u00f3gio do Cliente \u00e9 bom o suficiente para medir a passagem de tempo em per\u00edodos curtos, mesmo que tenha uma drift rate consider\u00e1vel em per\u00edodos mais longos. Assim, podemos executar o algoritmo gen\u00e9rico, adicionando o seguinte: Assuma \\(t_1 = t_s = t_2\\) Assuma \\(\\frac{t_3-t_0}{2}\\) como o tempo de transmiss\u00e3o da resposta (m\u00e9dia da ida e da volta) Cliente ajusta rel\u00f3gio para \\(C = t_s + \\frac{t_3-t_0}{2}\\) Mas e a aproxima\u00e7\u00e3o \\(\\frac{t_3-t_0}{2}\\) , \u00e9 boa? \u00c9 uma aproxima\u00e7\u00e3o t\u00e3o boa quanto poss\u00edvel, pois medir a lat\u00eancia em uma \u00fanica dire\u00e7\u00e3o demandaria rel\u00f3gios sincronizados, exatamente o que estamos tentando resolver com este algoritmo. Quero dizer, temos uma depend\u00eancia circular aqui, como o v\u00eddeo a seguir mostra. Bom, na verdade no nosso caso \u00e9 um pouco mais f\u00e1cil de dizer que as duas dire\u00e7\u00f5es tem lat\u00eancias diferentes, pois sabemos que, em uma rede de larga escala, \u00e9 poss\u00edvel e comum que pacotes tomem caminhos diferentes na ida e na volta. Neste caso, podemos estimar o erro que a aproxima\u00e7\u00e3o introduz na sincroniza\u00e7\u00e3o, desde que tenhamos estimativas de tempo m\u00ednimo para a transmiss\u00e3o em cada sentido, \\(T_{min}\\) . A figura a seguir demonstra o erro desta t\u00e9cnica 4 , onde \\(t_3 - t_0\\) corresponde ao tempo medido entre o envio da requisi\u00e7\u00e3o e recep\u00e7\u00e3o da resposta as setas vermelhas indicam o caso em que a requisi\u00e7\u00e3o foi muito mais r\u00e1pida que resposta ( \\(T_{min}\\) ) as setas verdes indicam o caso em que a resposta foi muito mais r\u00e1pida que requisi\u00e7\u00e3o ( \\(T_{min}\\) ) No caso vermelho, a aproxima\u00e7\u00e3o \\(\\frac{t_3-t_0}{2}\\) \u00e9 muito menor que o tempo de propaga\u00e7\u00e3o da resposta, \\(t3 - t1\\) , e no caso verde a aproxima\u00e7\u00e3o \u00e9 maior que o tempo \\(t_3 - t_2\\) . Em ambos os casos, o erro \u00e9 est\u00e1 limitado a \\(\\frac{t_2 - t1}{2}\\) , ou seja, \\(+- \\frac{t_3 - t_0}{2} - T_{min}\\) .","title":"Algoritmo de Cristian"},{"location":"time/physical/#algoritmo-de-berkeley","text":"Enquanto o algoritmo de Cristian permite sincronizar um n\u00f3 com uma fonte, outro algoritmo, de Berkeley, permite sincronizar m\u00faltiplos n\u00f3s uns com os outros. Este algoritmo assume o que n\u00e3o h\u00e1 uma \"fonte da verdade\" do tempo, mas sim a necessidade de que todos os processos convirjam para um mesmo valor do rel\u00f3gio. \u00c9 como nos filmes de espi\u00e3o em que os rel\u00f3gios s\u00e3o sincronizados; pouco importa se a bomba explodir\u00e1 10:57 ou 10:59, desde que todos concordem quando isso vai acontecer. Isso \u00e9 o que chamamos de sincroniza\u00e7\u00e3o interna em vez de externa, como provido pelo algoritmo de Cristian. O algoritmo de Berkeley requer que todo n\u00f3 execute um processo de sincroniza\u00e7\u00e3o, um \"daemon\", e separa seus pap\u00e9is em dois tipos, prim\u00e1rio e secund\u00e1rio . O papel do prim\u00e1rio pode ser rotacionado entre os v\u00e1rios processos, sem perdas para sua execu\u00e7\u00e3o. O algoritmo ent\u00e3o \u00e9 executa como se segue: Prim\u00e1rio pergunta \"que horas s\u00e3o\" para cada secund\u00e1rio (mensages 1,2,3 e 4) Secund\u00e1rio responde com valor atual do rel\u00f3gio (mensagens 5,6,7 e 8) Prim\u00e1rio ajusta as respostas de acordo com o algoritmo de Cristian, para minimizar erros. Prim\u00e1rio computa m\u00e9dia dos valores recebidos, ignorando outliers (como o da mensagem 8). Prim\u00e1rio envia ajustes para secund\u00e1rios (mensagens 8,9,10 e 11) Secund\u00e1rio executa ajuste sugerido pelo prim\u00e1rio. sequenceDiagram autonumber note over Prim\u00e1rio: 10:00 note over Secund\u00e1rio1: 10:06 note over Secund\u00e1rio2: 10:15 note over Secund\u00e1rio3: 23:18 par Pergunta Prim\u00e1rio->>Prim\u00e1rio: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio1: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio2: Que horas s\u00e3o? and Prim\u00e1rio->>Secund\u00e1rio3: Que horas s\u00e3o? end par Resposta Prim\u00e1rio->>Prim\u00e1rio: 10:00 and Secund\u00e1rio1->>Prim\u00e1rio: 10:06 and Secund\u00e1rio2->>Prim\u00e1rio: 10:15 and rect rgb(255, 0, 0) Secund\u00e1rio3->>Prim\u00e1rio: 23:18 end end par Ajuste Prim\u00e1rio->>Prim\u00e1rio: 10:07 and Prim\u00e1rio->>Secund\u00e1rio1: 10:07 and Prim\u00e1rio->>Secund\u00e1rio2: 10:07 and Prim\u00e1rio->>Secund\u00e1rio3: 10:07 end Embora interessantes, estes algoritmos n\u00e3o s\u00e3o normalmente usados, pelo menos n\u00e3o em sua forma \"pura\", em sistemas computacionais. Em vez deles, usamos o Network Time Protocol (NTP).","title":"Algoritmo de Berkeley"},{"location":"time/physical/#network-time-protocol","text":"O NTP foi especificado originalmente na RFC 1305 6 e estendido pelas RFC 5905-5908 7 essencialmente para suportar IPv6 e reduzir o erro de sincroniza\u00e7\u00e3o para at\u00e9 10 \\(\\mu\\) s. Os diversos componentes do NTP s\u00e3o organizados em camadas, ou estrata , de forma que a informa\u00e7\u00e3o do tempo flui da camada 0 ( stratum 0 ) at\u00e9 a camada 15 ( stratum 15). Os componentes n\u00e3o est\u00e3o presos a camadas, que podem ser alteradas a medida que falhas acontecem e s\u00e3o dedicadas, e novos caminhos s\u00e3o encontrados usando-se o algoritmo de \u00e1rvore geradora m\u00ednima Bellman-Ford, al\u00e9m de caminhos redundantes que conferem propriedades de toler\u00e2ncia a falhas \u00e0 topologia. 5 Esta organiza\u00e7\u00e3o hier\u00e1rquica leva a cada camada garantir um n\u00edvel de sincroniza\u00e7\u00e3o diferente e permite escalar o uso do protocolo para n\u00edveis globais , usando a Internet como meio . Stratum 0: rel\u00f3gios at\u00f4micos/receptores GPS Stratum 1: ms to stratum 0 Stratum 2: contata m\u00faltiplos stratum 1 e pares Strata 3...15 Stratum 16: dessincronizado Toda a comunica\u00e7\u00e3o entre n\u00f3s pode ser autenticada , garantindo que a sincroniza\u00e7\u00e3o n\u00e3o seja facilmente manipulada e erros s\u00e3o minimizados pela coleta e uso de estat\u00edsticas de lat\u00eancia de comunica\u00e7\u00e3o, para evitar desvios quando fontes se tornam problem\u00e1ticas. NTP tem m\u00faltiplas formas de execu\u00e7\u00e3o, adequadas para diferentes ambientes. Modo multicast: propaga tempo em rede local RPC: algoritmo de Cristian Sim\u00e9trico: parecido com Berkeley Na pr\u00e1tica, boa parte dos dispositivos usa uma vers\u00e3o simplificada do NTP, o SNTP ( Simple Network Time Protocol ), adequada aos n\u00f3s nas folhas da hierarquia . O SNTP \u00e9 essencialmente o algoritmo de Cristian: \\(\\delta = (t_4-t_1)-(t_2-t_3)\\) \\(t = \\frac{(t_2-t_1)+(t3-t_4)}{2}\\) \\(t_c = t_4+t\\) Por exemplo, \\(t_1 = 1100, t_2 = 800, t_3=850, t_4=1200\\) \\(t = ((800-1100)+(850-1200))/2 = (-300 -350)/ = -325\\) \\(t_c = 1200-325 = 875\\) O Comit\u00ea Gestor da Internet, CGI , mantem uma excelente p\u00e1gina sobre o NTP, com mais detalhes do que apresentado aqui, em NTP.br .","title":"Network Time Protocol."},{"location":"time/physical/#ptp-precision-time-protocol","text":"Mesmo com melhoria do protocolo e baratemento de dispositivos GPS, h\u00e1 ainda a necessidade de sincroniza\u00e7\u00e3o sub-microssegundo e barata. O Precision Time Protocol , PTP, especifica\u00e7\u00e3o IEEE 1588 8 tenta cobrir este nicho. Se escrutinarmos o PTP, veremos que o protocolo em si n\u00e3o difere muito do NTP. Contudo, o PTP usa interfaces de rede especilizadas para fazer o timestamping dos eventos do protocolo, conseguindo remover a lat\u00eancia nos dispositivos processando as mensagens e reduzindo o erro do protocolo at\u00e9 sub \\(\\mu\\) (versus ordem de \\(ms\\) no NTP). Mais detalhes sobre o protocolo est\u00e3o fora do escopo deste documento, mas podem ser facilmente encontrados nos links dados.","title":"PTP - Precision Time Protocol"},{"location":"time/physical/#nunca-volte-no-tempo","text":"Qualquer que seja o algoritmo utilizado, \u00e9 provavelmente uma boa ideia nunca voltar no tempo . Mesmo que o universo n\u00e3o seja destru\u00eddo no processo, voltar no tempo poderia levar a situa\u00e7\u00f5es estranhas como um dado ter data de edi\u00e7\u00e3o anterior a data de cria\u00e7\u00e3o. Para evitar estas situa\u00e7\u00f5es, devem ser feitos de ajustes graduais nos rel\u00f3gios, que acelerem ou desacelerem o rel\u00f3gio \\(C\\) em rela\u00e7\u00e3o a \\(t\\) (ou sua melhor aproxima\u00e7\u00e3o, pelo ajuste frequ\u00eancia de interrup\u00e7\u00e3o para atrasar/adiantar rel\u00f3gio ou ajustes dos incrementos com cada interrup\u00e7\u00e3o . Isso far\u00e1 com que as curvas no seguinte gr\u00e1fico convirjam. A exce\u00e7\u00e3o a esta regra deve ser restrita a corre\u00e7\u00f5es ap\u00f3s longos per\u00edodos em que o rel\u00f3gio dorme.","title":"Nunca volte no tempo"},{"location":"time/physical/#usos-de-relogios-sincronizados","text":"Assumindo que tenhamos sincronizado os rel\u00f3gios de um sistema computacional, o que podemos fazer agora? H\u00e1 uma s\u00e9rie de problemas interessantes que podem ser resolvidos, como autentica\u00e7\u00e3o , termina\u00e7\u00e3o de transa\u00e7\u00f5es , aloca\u00e7\u00e3o de leases e diversos outros exemplos. 9 Um exemplo interessante \u00e9 a ordena\u00e7\u00e3o de eventos em um banco de dados. Para entender este problema, considere um cen\u00e1rio com um Sistema Banc\u00e1rio replicado, isto \u00e9, com v\u00e1rias c\u00f3pias. No exemplo, sem perda de generalidade, nos focamos em duas c\u00f3pias em lados opostos de uma rede de larga escala. Clientes disparam opera\u00e7\u00f5es como saques, dep\u00f3sitos e transfer\u00eancias, por meio de mensagens para as duas c\u00f3pias. Mensagens para a c\u00f3pia pr\u00f3xima do cliente (em verde) s\u00e3o entregues rapidamente, enquanto mensagens para a c\u00f3pia distante (em vermelho), demoram mais para ser entregues. Imagine que o usu\u00e1rio U1 envie o comando C1 atualizar saldo da conta para USD 10 10 e que o usu\u00e1rio U2 envie o comando C2 atualizar saldo da conta para USD 20 . Se os comandos chegam primeiro para a r\u00e9plica mais pr\u00f3xima e s\u00e3o executados na ordem em que chegam, ao final da execu\u00e7\u00e3o a r\u00e9plica R1 ter\u00e1 executado C1 seguido de C2, tendo saldo da conta como USD 20, enquanto R2 ter\u00e1 executado C2 seguido de C1 e ter\u00e1 como saldo na conta USD 10. O problema est\u00e1 na ordem de execu\u00e7\u00e3o das opera\u00e7\u00f5es. Assuma que rel\u00f3gios est\u00e3o perfeitamente sincronizados e que toda mensagem/update carrega consigo o timestamp de quando foi enviada. E se as r\u00e9plicas processarem mensagens na ordem que foram enviadas, como identificado pelos seus timestamps ? 11 Assim, se C1 foi enviado antes de C2, C1 tem um timestamp menor que C2 e ser\u00e1 executada primeiro em ambas as r\u00e9plicas, o que resolve nosso problema, correto? Parcialmente, pois ainda temos o problema de identificar que nenhuma outra mensagem ainda por ser entregue foi enviada antes. Para isto, precisamos estender o modelo e assumir que o tempo de propaga\u00e7\u00e3o m\u00e1ximo de uma mensagem, \\(\\tau\\) , \u00e9 finito e conhecido . Assim, ao receber um comando com timestamp \\(t\\) , uma r\u00e9plica espera at\u00e9 \\(t + \\tau\\) antes de execut\u00e1-lo, pois qualquer comando com timestamp \\(t' < t\\) deve ter sido entregue at\u00e9 \\(t+\\tau\\) . Implementar este protocolo \u00e9 muito simples: Ordena\u00e7\u00e3o de Mensagens por Timestamp Quando enviar uma mensagem, aumente-a com o valor atual do rel\u00f3gio. Quando receber uma mensagem, coloque-a em uma fila ordenada por timestamp . Quando o rel\u00f3gio marcar um tempo maior que \\(t + \\tau\\) , onde \\(t\\) \u00e9 o timestamp da mensagem na cabe\u00e7a da fila, retire a mensagem da cabe\u00e7a da fila e execute o comando correspondente. Embora correto, este protocolo, ou melhor, o modelo, n\u00e3o leva em considera\u00e7\u00e3o a dessincroniza\u00e7\u00e3o inerente dos rel\u00f3gios em um sistema distribu\u00eddo. Como faz\u00ea-lo, supondo uma diverg\u00eancia m\u00e1xima de \\(\\Delta\\) entre quaisquer dois rel\u00f3gios, algo que pode ser arranjado, como visto antes, sincronizando-se os rel\u00f3gios a cada \\(\\frac{\\Delta}{2\\rho}\\) . Se \\(\\Delta\\) \u00e9 a diferen\u00e7a m\u00e1xima entre rel\u00f3gios, ent\u00e3o se uma mensagem \u00e9 enviada no instante \\(t\\) , ent\u00e3o at\u00e9 \\(\\Delta +t\\) , outro processo, atrasado em rela\u00e7\u00e3o ao primeiro, poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) . Tal mensagem pode demorar at\u00e9 \\(\\tau\\) para ser entregue \u00e0 r\u00e9plica, ou seja, no instante \\(t + \\tau + \\Delta\\) , do ponto de vista do primeiro cliente. Se a r\u00e9plica estiver sincronizada com cliente, ent\u00e3o se esperar at\u00e9 \\(t + \\tau + \\Delta\\) para executar o comando, o far\u00e1 de forma segura. Se estiver atrasada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o acabar\u00e1 por esperar al\u00e9m do necess\u00e1rio, mas sem violar a corretude do sistema. Finalmente, se a r\u00e9plica estiver adiantada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o seu rel\u00f3gio alcan\u00e7ar\u00e1 \\(t + \\tau + \\Delta\\) antes do rel\u00f3gio do primeiro cliente, mas isso n\u00e3o \u00e9 um problema. Isto porqu\u00ea, o \u00faltimo instante em que o cliente 2 poder\u00e1 enviar uma mensagem com timestamp \\(t' < t\\) \u00e9 o instante em que o rel\u00f3gio da r\u00e9plica marcar \\(t + \\Delta\\) , e portanto dever\u00e1 tamb\u00e9m ser recebido at\u00e9 que o mesmo rel\u00f3gio marque \\(t + \\tau + \\Delta\\) . O mesmo racioc\u00ednio pode ser usado para definir um protocolo de acesso recursos para os quais leases s\u00e3o distribu\u00eddos, onde um lease \u00e9 uma permiss\u00e3o de acesso durante uma janela de tempo , emitida por um coordenador (possivelmente eleito usando os algoritmos vistos anteriormente), e \\(\\Delta\\) \u00e9 o m\u00e1ximo de dessincronismo entre os rel\u00f3gios. O seguinte protocolo resolve este problema: Aloca\u00e7\u00e3o de Lease Ao receber um lease para a janela de tempo \\(t_1\\) a \\(t_2\\) espera at\u00e9 \\(t_1 + \\Delta\\) usa o recurso at\u00e9 \\(t_2\\) . Se rel\u00f3gio estiver adiantado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1+\\Delta\\) enquanto o anterior acha que \u00e9 \\(t_1\\) ; exclus\u00e3o m\u00fatua garantida. Se rel\u00f3gio estiver atrasado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 \\(t_1 - \\Delta\\) , e continua esperando, enquanto ele acha que j\u00e1 \u00e9 \\(t_1\\) e para de usar; exclus\u00e3o m\u00fatua garantida. Recurso fica ocioso por \\(\\Delta\\) , em m\u00e9dia, a cada lease. Devido ao alto custo de se manter o recurso n\u00e3o utilizado, \\(\\Delta\\) deve ser feito t\u00e3o pequeno quanto poss\u00edvel, como feito, por exemplo, o Google True Time que consegue manter a diferen\u00e7a em sub-milisegundos usando rel\u00f3gios at\u00f4micos dentro de seus datacenters e um API para gera\u00e7\u00e3o de timestamps. Nas solu\u00e7\u00f5es anteriores, um n\u00f3 precisa esperar por muito tempo antes de usar um recurso . E se ele aprendesse antes que os outros n\u00f3s n\u00e3o far\u00e3o requisi\u00e7\u00f5es, que n\u00e3o haver\u00e3o sobreposi\u00e7\u00f5es de requisi\u00e7\u00f5es? E se houvesse um rel\u00f3gio que avan\u00e7asse n\u00e3o com o tempo, mas com eventos interessantes do sistema? Esta \u00e9 a ideia dos rel\u00f3gios l\u00f3gicos .","title":"Usos de rel\u00f3gios sincronizados"},{"location":"time/physical/#referencias","text":"Google TrueTime Explain that stuff. \u21a9 Distor\u00e7\u00e3o mec\u00e2nica gera corrente el\u00e9trica e submiss\u00e3o a uma corrente el\u00e9trica gera uma distor\u00e7\u00e3o mec\u00e2nica. \u21a9 32768 \u00e9 a primeira pot\u00eancia de 2 maior que 20000, a maior frequ\u00eancia sonora aud\u00edvel aos seres humanos. \u21a9 Adaptado das notas de aula dispon\u00edveis aqui . \u21a9 Fonte: Benjamin D. Esham, (bdesham) - Based upon Ntp.png by Kim Meyrick \u21a9 RFC 1305 , 1991/1992 \u21a9 RFC 5905-5908,2010 \u21a9 IEEE 1588TM Standard for A Precision Clock Synchronization Protocol for Networked Measurement and Control Systems . \u21a9 Liskov, B.: Distrib Comput (1993) 6: 211. doi:10.1007/BF02242709 \u21a9 Unidade Simples de Dinheiros. \u21a9 Empates s\u00e3o quebrados pelo identificador do processo, isto \u00e9, se duas mensagens s\u00e3o produzidas ao mesmo tempo por U1 e U2, ent\u00e3o o a mensagem de U1 tem preced\u00eancia na execu\u00e7\u00e3o. \u21a9","title":"Refer\u00eancias"}]}