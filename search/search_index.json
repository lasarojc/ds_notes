{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pr\u00f3logo Escrever \"bons\" sistemas distribu\u00eddos \u00e9 uma tarefa que esbarra em diversos obst\u00e1culos, cujo n\u00e3o menos importante \u00e9 a defini\u00e7\u00e3o de \"bom\", o que \u00e9 extremamente subjetivo. Aqui diremos que um sistema \u00e9 bom se est\u00e1 sempre no ar (despeito de falhas), com bom desempenho (boa experi\u00eancia de usu\u00e1rio) e com baixo custo (usa o m\u00ednimo de recursos necess\u00e1rios ao trabalho). Enquanto ainda subjetiva, nossa defin\u00e7\u00e3o j\u00e1 nos permite estabelecer um pano de fundo para delinear as dificuldades de se implementar tais sistemas. Na pr\u00e1tica, as barreiras v\u00e3o desde o uso de premissas inv\u00e1lidas, como confiabilidade e custo zero da transmiss\u00e3o de dados via Internet, ao n\u00e3o entendimento de conceitos fundamentais de programa\u00e7\u00e3o concorrente, da falta de frameworks para resolver certos problemas, ao excesso de op\u00e7\u00f5es para outros. Do ponto de vista te\u00f3rico, a complexidade vai da dificuldade de abstra\u00e7\u00e3o de problemas ao n\u00edvel de abstra\u00e7\u00e3o de problemas bem definidos, da impossibilidade de se resolver problemas aparentemente simples \u00e0 realiza\u00e7\u00e3o de que com o uso da abstra\u00e7\u00e3o correta se consegue resolver facilmente problemas complexos. Para ajud\u00e1-lo a navegar neste mar de dificuldades, este conjunto de notas de aulas est\u00e1 sendo organizado para apresentar gradualmente o desenvolvimento de sistemas distribu\u00eddos ao estudante. Iniciamos com um trabalho de convencimento de que tais aplica\u00e7\u00f5es s\u00e3o importantes por j\u00e1 serem parte inexpurg\u00e1vel da infraestrutura computacional que usamos. Revisamos ent\u00e3o conceitos de redes de computadores e sistemas operacionais enquanto falamos sobre a arquitetura mais fundamental de computa\u00e7\u00e3o distribu\u00edda, Cliente/Servidor, e de como \u00e9 usada para implementar um proto banco de dados distribu\u00eddo, uma Tabela de Espalhamento Distribu\u00edda em mem\u00f3ria. \u00c0 medida em que apresentamos problemas com o modelo assumido inicialmente e com nossa implementa\u00e7\u00e3o inicial, buscaremos por solu\u00e7\u00f5es enquanto introduzimos novas abstra\u00e7\u00f5es, mais poderosas e mais complexas. Ao final desta jornada, teremos fundamentado a constru\u00e7\u00e3o de uma Tabela de Espalhamento Distribu\u00eddo com particionamento de dados entre n\u00f3s, usando protocolos par-a-par e replica\u00e7\u00e3o de m\u00e1quinas de estados. Em paralelo, teremos estudado diversos frameworks de computa\u00e7\u00e3o distribu\u00edda atuais, como modelo ou bloco de constru\u00e7\u00e3o para a resolu\u00e7\u00e3o de nossos problemas. Estas notas, em sua forma atual, s\u00e3o fortemente baseadas em uma literatura j\u00e1 antiquada, como a segunda edi\u00e7\u00e3o do livro Distributed Systems: Principles and Paradigms , de Andrew Tanenbaum, mas tamb\u00e9m em alguns materiais mais recentes dispon\u00edveis livremente na Internet. Em futuras itera\u00e7\u00f5es, as notas ser\u00e3o atualizadas para conter cada vez mais material autoral e refer\u00eancias mais atuais; fique ligado. Aten\u00e7\u00e3o Para navegar no material, utilize o menu \u00e0 esquerda ou os bot\u00f5es abaixo.","title":"Pr\u00f3logo"},{"location":"#prologo","text":"Escrever \"bons\" sistemas distribu\u00eddos \u00e9 uma tarefa que esbarra em diversos obst\u00e1culos, cujo n\u00e3o menos importante \u00e9 a defini\u00e7\u00e3o de \"bom\", o que \u00e9 extremamente subjetivo. Aqui diremos que um sistema \u00e9 bom se est\u00e1 sempre no ar (despeito de falhas), com bom desempenho (boa experi\u00eancia de usu\u00e1rio) e com baixo custo (usa o m\u00ednimo de recursos necess\u00e1rios ao trabalho). Enquanto ainda subjetiva, nossa defin\u00e7\u00e3o j\u00e1 nos permite estabelecer um pano de fundo para delinear as dificuldades de se implementar tais sistemas. Na pr\u00e1tica, as barreiras v\u00e3o desde o uso de premissas inv\u00e1lidas, como confiabilidade e custo zero da transmiss\u00e3o de dados via Internet, ao n\u00e3o entendimento de conceitos fundamentais de programa\u00e7\u00e3o concorrente, da falta de frameworks para resolver certos problemas, ao excesso de op\u00e7\u00f5es para outros. Do ponto de vista te\u00f3rico, a complexidade vai da dificuldade de abstra\u00e7\u00e3o de problemas ao n\u00edvel de abstra\u00e7\u00e3o de problemas bem definidos, da impossibilidade de se resolver problemas aparentemente simples \u00e0 realiza\u00e7\u00e3o de que com o uso da abstra\u00e7\u00e3o correta se consegue resolver facilmente problemas complexos. Para ajud\u00e1-lo a navegar neste mar de dificuldades, este conjunto de notas de aulas est\u00e1 sendo organizado para apresentar gradualmente o desenvolvimento de sistemas distribu\u00eddos ao estudante. Iniciamos com um trabalho de convencimento de que tais aplica\u00e7\u00f5es s\u00e3o importantes por j\u00e1 serem parte inexpurg\u00e1vel da infraestrutura computacional que usamos. Revisamos ent\u00e3o conceitos de redes de computadores e sistemas operacionais enquanto falamos sobre a arquitetura mais fundamental de computa\u00e7\u00e3o distribu\u00edda, Cliente/Servidor, e de como \u00e9 usada para implementar um proto banco de dados distribu\u00eddo, uma Tabela de Espalhamento Distribu\u00edda em mem\u00f3ria. \u00c0 medida em que apresentamos problemas com o modelo assumido inicialmente e com nossa implementa\u00e7\u00e3o inicial, buscaremos por solu\u00e7\u00f5es enquanto introduzimos novas abstra\u00e7\u00f5es, mais poderosas e mais complexas. Ao final desta jornada, teremos fundamentado a constru\u00e7\u00e3o de uma Tabela de Espalhamento Distribu\u00eddo com particionamento de dados entre n\u00f3s, usando protocolos par-a-par e replica\u00e7\u00e3o de m\u00e1quinas de estados. Em paralelo, teremos estudado diversos frameworks de computa\u00e7\u00e3o distribu\u00edda atuais, como modelo ou bloco de constru\u00e7\u00e3o para a resolu\u00e7\u00e3o de nossos problemas. Estas notas, em sua forma atual, s\u00e3o fortemente baseadas em uma literatura j\u00e1 antiquada, como a segunda edi\u00e7\u00e3o do livro Distributed Systems: Principles and Paradigms , de Andrew Tanenbaum, mas tamb\u00e9m em alguns materiais mais recentes dispon\u00edveis livremente na Internet. Em futuras itera\u00e7\u00f5es, as notas ser\u00e3o atualizadas para conter cada vez mais material autoral e refer\u00eancias mais atuais; fique ligado. Aten\u00e7\u00e3o Para navegar no material, utilize o menu \u00e0 esquerda ou os bot\u00f5es abaixo.","title":"Pr\u00f3logo"},{"location":"basics/","text":"Fundamentos A pedra fundamental da constru\u00e7\u00e3o de sistemas distribu\u00eddos \u00e9 a capacidade de comunica\u00e7\u00e3o entre seus componentes. No mundo de hoje, isto quer dizer que os hosts dos componentes devem possuir interfaces de rede e que estas interfaces estejam ligadas a uma rede com capacidade de roteamento de dados, estabelecendo um canal de comunica\u00e7\u00e3o entre os componentes. Al\u00e9m do canal, \u00e9 tamb\u00e9m necess\u00e1rio que se estabele\u00e7a um protocolo de comunica\u00e7\u00e3o , que define as regras para que a comunica\u00e7\u00e3o aconte\u00e7a, por exemplo, a gram\u00e1tica para forma\u00e7\u00e3o de mensagens. Tamb\u00e9m importantes, de um ponto de vista pr\u00e1tico do desenvolvimento, s\u00e3o os conceitos de concorr\u00eancia e paralelismo. Afinal, um componente pode necessitar manter v\u00e1rias \"conversas\" em paralelo com m\u00faltiplos outros componentes. Neste cap\u00edtulo, revisaremos de forma r\u00e1pida tanto conceitos de redes de computadores quanto de concorr\u00eancia e paralelismo. Canais e Protocolos de Comunica\u00e7\u00e3o Um canal de comunica\u00e7\u00e3o \u00e9 o meio pelo qual os elementos da conversa entre os componentes do sistema distribu\u00eddo s\u00e3o transmitidos e o protocolo s\u00e3o as regras codificam tal conversa. Por exemplo, quando voc\u00ea fala com uma pessoa, cara-a-cara, o meio de comunica\u00e7\u00e3o \u00e9 o ar e o protocolo utilizado \u00e9 a linguagem conhecida pelas duas partes, o Portugu\u00eas por exemplo. Na pr\u00e1tica, canais de comunica\u00e7\u00e3o podem ter diversas formas e caracter\u00edsticas, por exemplo: Ponto-a-ponto Eficiente Caro para muitos n\u00f3s Roteamento trivial Compartilhado Colis\u00f5es Menor custo Roteamento mais complicado Nas redes atuais, pode se dizer que o meio mais utilizado \u00e9 provido pela arquitetura Ethernet , que trata da comunica\u00e7\u00e3o n\u00f3s usando um barramento compartilhado . Sobre este meio, s\u00e3o usados protocolos para, por exemplo, Controle de acesso ao meio Transmiss\u00e3o de mensagens Evitar e tratar colis\u00f5es As redes Ethernet, contudo, cobrem pequenas \u00e1reas e para se ter conversas \"mais interessantes\", \u00e9 necess\u00e1rio que se conecte diversas destas redes. A conversa ent\u00e3o \u00e9 feita por meio de intermedi\u00e1rios, gateways que conectam duas ou mais redes, permitindo que mensagens de um interlocutor sejam roteadas para o outro, via tais intermedi\u00e1rios. Um exemplo interessante das quest\u00f5es ligadas \u00e0 manuten\u00e7\u00e3o da conversa entre dois pontos \u00e9 a decis\u00e3o sobre o uso de comuta\u00e7\u00e3o de pacotes ( packet switching ) ou de circuitos ( circuit switching ). Comuta\u00e7ao de pacotes Dados divididos em pacotes Cada pacote viaja independentemente Pacotes s\u00e3o perdidos Lat\u00eancia vari\u00e1vel Circuit switching Caminho dedicado Recursos reservados Pacotes de tamanho fixo Lat\u00eancia constante Outro fator importante \u00e9 o MTU, o tamanho m\u00e1ximo de um pacote em determinada rede. \u00c9 necess\u00e1rio entender que qualquer quantidade de dados maior que o MTU precisar\u00e1 ser dividida em m\u00faltiplos pacotes. Tamb\u00e9m \u00e9 importante perceber que redes s\u00e3o heterog\u00eaneas, e que o v\u00e1rios segmentos no caminho entre origem e destino podem ter MTU diferentes, levando \u00e0 fragmenta\u00e7\u00e3o de pacotes em tr\u00e2nsito e, possivelmente, entrega desordenada dos mesmos. Finalmente, h\u00e1 a quest\u00e3o importante \u00e9 relativa \u00e0 confiabilidade na transmiss\u00e3o dos elementos da conversa, isto \u00e9, se a rede deve garantir ou n\u00e3o que algo \"dito\" por um interlocutor deve garantidamente ser \"ouvido\" pelo outro, ou se a mensagem pode ser perdida no meio. Felizmente boa parte da complexidade da resolu\u00e7\u00e3o destas quest\u00f5es \u00e9 abstra\u00edda do desenvolvedor dos sistemas distribu\u00eddos, isto \u00e9, voc\u00ea , lhe cabendo apenas a decis\u00e3o de qual protocolo utilizar. Nas redes atuais, a conversa em componentes ser\u00e1 feita, em algum n\u00edvel, por meio dos protocolos da arquitetura Internet . A Internet A Internet tem este nome por usar o protocolo de interconex\u00e3o de redes indepententes, o internetworking protocol , ou IP. Para a aplica\u00e7\u00e3u usando o IP, todas as redes se comportam com uma \u00fanica e coerente rede, exceto por alguns detalhes. Os elementos que conectam as diversas redes s\u00e3o denominados roteadores e fazem um melhor esfor\u00e7o para encaminhar os pacotes de dados do remetente ao destinat\u00e1rio. Se voc\u00ea se lembrar da pilha de protocolos de comunica\u00e7\u00e3o de refer\u00eancia OSI, lembrar\u00e1 que h\u00e1 sete camadas na mesma. Cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel e serve de funda\u00e7\u00e3o para a funcionalidade da camada de cima. Cada camada tem um cabe\u00e7alho ( header ) e uma carga ( payload ) e o conjunto de cabe\u00e7alho + carga de uma camada \u00e9 considerado carga da camada inferior. Assim, embora tenha-se a impress\u00e3o de que cada camada conversa com a equivalente do outro lado da comunica\u00e7\u00e3o, na pr\u00e1tica, a comunica\u00e7\u00e3o desce e sobe a pilha. Bits Frames/quadros; controle de fluxo; acesso ao meio. Datagramas/pacotes; roteamento Controle de fluxo; fim a fim; confiabilidade; tcp e udp Streams/fluxos; conex\u00f5es l\u00f3gicas; restart; checkpoint; http, ssl Objetos; json, xml; criptografia Aplica\u00e7\u00f5es; http, pop, ftp Embora o IP se refira estritamente ao protocolo da camada 3 da pilha, nos referimos \u00e0 pilha que usa este protocolo como a pilha IP. Comparada \u00e0 pilha OSI, a IP \u00e9 mais simples, como se v\u00ea na figura. Como usu\u00e1rios da pilha IP, temos que entender como a camada 3 funciona, mas dificilmente interagiremos com algo al\u00e9m da camada 4, a camada de transporte . Como se v\u00ea, as camadas 5 e 6 n\u00e3o est\u00e3o presentes na pilha IP e as funcionalidades correspondentes s\u00e3o implementadas na camada 7, de aplica\u00e7ao. Contudo, n\u00e3o tema! Estas funcionalidades podem se normalmente implementadas por meio de frameworks ou do middleware em uso. Alguns exemplos de tais funcionalidades s\u00e3o (De)Serializa\u00e7\u00e3o Nomeamento Criptografia Replica\u00e7\u00e3o Invoca\u00e7\u00e3o remota de procedimentos A grande vantagem desta abordagem \u00e9 que se pode implementar exatamente e somente as funcionalidades desejadas. Este caracter\u00edstica \u00e9 conhecida como o argumento fim-a-fim no projeto de sistemas ; uma an\u00e1lise recente deste argumento foi feita aqui . No princ\u00edpio, era o Socket Na pr\u00e1tica, para implementarmos a comunica\u00e7\u00e3o entre processos, usamos sockets . Para se definir um socket a partir de um host \u00e9 necess\u00e1rio identificar o outro fim da comunica\u00e7\u00e3o, isto \u00e9, o outro host , ou melhor, uma de suas interfaces de rede. Os sockets s\u00e3o ent\u00e3o a abstra\u00e7\u00e3o dos canais de comunica\u00e7\u00e3o, mas como dito antes, \u00e9 necess\u00e1rio definir tamb\u00e9m os protocolos usados por estes sockets. O primeiro protocolo \u00e9 o de endere\u00e7amento, que define qual pilha de protocolos usar, na camada 3. No caso da pilha IP, usa-se o protocolo AF_INET ou PF_INET. Escolhido o protocolo, cada interface tem um endere\u00e7o MAC, na camada 2, que o identifica entre as interfaces na mesma rede local, e cada interface tem um endere\u00e7o IPv4/IPv6 de 32/128 bits, que o indentifica entre todos os hosts na Internet 1 . Mas dentro de um host , podem haver diversas aplica\u00e7\u00f5es sendo executadas. Como identificar exatamente com qual se quer conversar? Isto \u00e9 feito pela defini\u00e7\u00e3o uma porta: Porta: 16 bits IANA (Internet Assigned Numbers Authority) Bem conhecidas -- 0-1023 Propriet\u00e1rias -- 49151 Din\u00e2micas -- 65535 Tamb\u00e9m \u00e9 necess\u00e1rio definir tamb\u00e9m o protocolo de transporte dos dados, na camada 4. Novamente, no caso da pilha IP, pode-se usar TCP ( SOCK_STREAM ) ou UPD ( SOCK_DGRAM ). A API usada para estabelecer a conversa via socket tem v\u00e1rias chamadas, que devem ser executadas na ordem certa no processo iniciando a conversa e naquele que aceita participar da mesma. Comecemos estudando o TCP. TCP O fluxograma da cria\u00e7\u00e3o de um socket TCP \u00e9 apresentado na seguinte figura: criar socket bind listen accept connect Estabelecido o socket, o mesmo pode ser usado como arquivo , isto \u00e9, lendo-se e escrevendo-se bytes. O que exatamente deve ser escrito e como o que \u00e9 lido deve ser interpretado \u00e9 o protocolo da camada 7, sua responsabilidade . Vejamos um exemplo do uso de sockets, em Python. O seguinte arquivo pode ser nomeado, por exemplo, server.py , mas n\u00e3o pode, de forma alguma, ser nomeado socket.py . #server.py #!/usr/bin/python # This is server.py file import socket # Import socket module s = socket.socket() # Create a socket object host = socket.gethostname() # Get local machine name port = 12345 # Reserve a port for your service. s.bind((host, port)) # Bind to the port s.listen(5) # Now wait for client connections. while True: c, addr = s.accept() # Establish connection with client. print('Got connection from', addr) c.send('Thank you for connecting'.encode()) c.close() # Close the connection Para execut\u00e1-lo, execute o seguinte comando em um terminal. python server.py Em outro terminal, execute um dos dois comandos a seguir 2 : telnet localhost 12345 netcat localhost 12345 O que est\u00e1 acontecendo aqui \u00e9 um processo criou um socket e ficou aguardando uma conex\u00e3o, usando o c\u00f3digo em Python. Tanto o telnet quando o netcat s\u00e3o programas gen\u00e9ricos para se conversar com outro processo usando TCP/IP. Aqui, estes programas simplesmente se conectaram e imprimiram o que quer que o primeiro processo lhes tenha enviado, assumindo que correspondia a uma string, o que neste caso \u00e9 correto. Simples, n\u00e3o \u00e9 mesmo? Em geral, denominamos o processo que fica aguardando a conex\u00e3o de servidor e o processo que se conecta de cliente . Isto por qu\u00ea, em geral, o servidor executa alguma tarefa, serve, o cliente, embora isto n\u00e3o seja necessariamente verdade. Por completude, vamos tamb\u00e9m escrever o c\u00f3digo do cliente, agora que voc\u00ea j\u00e1 sabe que o servidor funciona. Do lado cliente, estabelece-se uma conex\u00e3o apontando-se para onde est\u00e1 o servidor. #client.py #!/usr/bin/python # This is client.py file import socket # Import socket module s = socket.socket() # Create a socket object host = socket.gethostname() # Get local machine name port = 12345 # Reserve a port for your service. s.connect((host, port)) data = s.recv(1024) print(data.decode()) s.close() # Close the socket when done E para se executar o cliente, fa\u00e7a: python client.py Observe que o socket.close() encerra a conex\u00e3o do lado de quem invoca. Na contraparte, invoca\u00e7\u00f5es a socket.recv() retornam com 0 bytes lidos. A t\u00edtulo de compara\u00e7\u00e3o, em Java, a cria\u00e7\u00e3o do socket do lado do servidor seria muito mais simples, consistindo apenas em: Socket s = new ServerSocket(port); O cliente em Java tamb\u00e9m \u00e9 simplificado. Socket s = new Socket(hostname,port); Exerc\u00edcio: M\u00faltiplos Pacotes Fa\u00e7amos agora uma modifica\u00e7\u00e3o no c\u00f3digo do servidor para que envie n\u00e3o uma, mas duas mensagens para o cliente. Isto \u00e9, modifique seu servidor assim ... c.send('Thank you for connecting'.encode()) c.send('Come back often'.encode()) ... Agora execute novamente o cliente e veja o que acontece. Consegue explicar o fen\u00f4meno? Modifiquemos o cliente agora, para que tenha dois recv , assim. ... print(\"1\") data = s.recv(1024) print(data.decode()) print(\"2\") data = s.recv(1024) print(data.decode()) ... E agora, o que acontece? A sa\u00edda \u00e9 como esperava? Como explica este fen\u00f4meno e como poderia corrig\u00ed-lo? Exerc\u00edcio: Ping-Pong Modifique cliente e servidor tal que o cliente envie uma mensagem passada na linha de comando ao servidor e fique esperando uma resposta, e tal que o servidor fique esperando uma mensagem e ent\u00e3o solicite ao operador que digite uma resposta e a envie para o cliente. O loop continua at\u00e9 que o usu\u00e1rio digite SAIR, e a conex\u00e3o seja encerrada. Terminal 1 Terminal 2 python server.py Esperando conex\u00e3o. Esperando mensagem. Mensagem recebida: lalala Digite resposta: lelele Resposta enviada. Conex\u00e3o encerrada. Esperando conex\u00e3o. python client.py Digite mensagem: lalala Mensagem enviada. Esperando resposta. Resposta recebida: lelele Digite mensagem: SAIR Desconectando. Observe que para ler do teclado em Python 2 voc\u00ea deve usar x = raw_input() , enquanto que em Python 3 seria x = input() . Al\u00e9m disso, em Python 2, voc\u00ea deve remover as invoca\u00e7\u00f5es para encode e decode . UDP No exemplo anterior, usamos o protocolo TCP (o padr\u00e3o da API). Caso quis\u00e9ssemos usar UDP, precisar\u00edamos nos atentar a alguns detalhes. A cria\u00e7\u00e3o do socket \u00e9 feita explicitando-se o uso de datagramas : s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) Um servidor UDP n\u00e3o executa listen ou accept e, em Python, simplesmente executa data, addr = sock.recvfrom(4096) para receber o datagrama, onde data \u00e9 o conte\u00fado recebido e addr o endere\u00e7o de quem enviou o datagrama. Neste caso, um mesmo socket \u00e9 usado para manter comunica\u00e7\u00e3o com m\u00faltiplos interlocutores. Para enviar uma resposta a um interlocutor em espec\u00edfico, addr \u00e9 usado: sent = sock.sendto(data, addr) , onde sent \u00e9 a quantidade de bytes enviados. Al\u00e9m deste detalhe, \u00e9 importante manter em mente outras caracter\u00edsticas do UDP: falta de ordem falta de confiabilidade menos dados lidos que enviados. mais dados lidos que enviados (pode acontecer tamb\u00e9m no TCP) Com tantas dificuldades para se usar o UDP, fica a quest\u00e3o: para que serve UDP? Exerc\u00edcio: Ping-Pong UDP Modifique o c\u00f3digo do exerc\u00edcio Ping-Pong para usar UDP em vez de TCP na comunica\u00e7\u00e3o entre n\u00f3s. Execute m\u00faltiplos clientes ao mesmo tempo. Como o seu servidor lida com isso? Modifique-o para mandar um \"eco\" da mensagem recebida de volta ao remetente. IP-Multicast Imagine que voc\u00ea tenha que enviar um stream de v\u00eddeo para um destinat\u00e1rio, mostrando como voc\u00ea est\u00e1 jogando o mais novo jogo da velha no mercado. Qual protocolo de transporte voc\u00ea usaria? TCP, provavelmente, j\u00e1 que garante a entrega ordenada dos pacotes do v\u00eddeo. Como voc\u00ea j\u00e1 sabe, o TCP envia confirma\u00e7\u00f5es de pacotes recebidos e usa uma janela deslizante para determinar quais pacotes reenviar, o que pode causar interrup\u00e7\u00f5es na execu\u00e7\u00e3o do v\u00eddeo. Al\u00e9m do mais, as pessoas provavelmente preferir\u00e3o perder alguns quadros que perder a sincronia com sua excitante partida. Parece que uma op\u00e7\u00e3o melhor seria ent\u00e3o usar UDP, correto? Imagine agora que os mesmos dados devam ser enviados para m\u00faltiplos destinat\u00e1rios (voc\u00ea est\u00e1 ficando famoso!) Com m\u00faltiplos destinat\u00e1rios, m\u00faltiplos controles precisariam ser mantidos no TCP, o que pode se tornar custoso; mais uma raz\u00e3o para usar UDP! Para terminar, lhe darei uma raz\u00e3o final: IP-Multicast! Multicast, em oposi\u00e7\u00e3o ao Unicast, \u00e9 a capacidade de enviar mensagens para um grupo de destinat\u00e1rios, em vez de apenas um. IP-Multicast \u00e9 uma implementa\u00e7\u00e3o desta ideia, usando umaa configura\u00e7\u00e3o espec\u00edfica do UDP, associada a recursos dos comutadores de rede, para otimizar o envio dos mesmos dados a m\u00faltiplos destinat\u00e1rios. Grupos s\u00e3o identificados por endere\u00e7os IP especiais, conhecidos como Classe D (224.0.0.0-239.255.255.255), e propagados pela rede. Quando um pacote \u00e9 enviado para o endere\u00e7o do grupo, todos os membros do grupo recebem tal mensagem. Melhor dizendo, todos os membros podem receber a mensagem, mas como estamos falando de UDP, \u00e9 poss\u00edvel que alguns n\u00e3o recebam . Al\u00e9m disso, n\u00e3o h\u00e1 garantia qualquer sobre a ordem de recep\u00e7\u00e3o das mensagens . Apenas refor\u00e7ando, IP-Multicast s\u00f3 funciona com UDP, pois lidar com retransmiss\u00f5es em um grupo grande levaria a um estado imenso sendo mantido na origem dos dados. Outro ponto importante \u00e9 que pelo podencial desestabilizador do IP-Multicast, ele \u00e9 normalemente limitado \u00e0 pequenas se\u00e7\u00f5es das redes. Mas experimentemos com esta tecnologia na pr\u00e1tica. Criemos um programa que criar Socket UDP , associa-o a um grupo , e recebe pacotes destinados ao grupo. // MReceiver.java import java.io.*; import java.net.*; public class MReceiver { public static void main(String[] args) { byte[] inBuf = new byte[256]; try { MulticastSocket socket = new MulticastSocket(8888); InetAddress address = InetAddress.getByName(\"224.2.2.3\"); socket.joinGroup(address); while (true) { DatagramPacket inPacket = new DatagramPacket(inBuf, inBuf.length); socket.receive(inPacket); String msg = new String(inBuf, 0, inPacket.getLength()); System.out.println(\"From \" + inPacket.getAddress() + \" Msg : \" + msg); } }catch (IOException ioe) { System.out.println(ioe); } } } Instancie m\u00faltiplos processos deste, na mesma m\u00e1quina e em m\u00e1quinas distintas. Agora criemos um programa que envia pacotes para o dito grupo. // MSender.java import java.io.*; import java.net.*; public class MSender { public static void main(String[] args) { byte[] outBuf; final int PORT = 8888; try { DatagramSocket socket = new DatagramSocket(); long counter = 0; InetAddress address = InetAddress.getByName(\"224.2.2.3\"); while (true) { counter++; outBuf = (\"Multicast numero \" + counter + \" \" + address).getBytes(); DatagramPacket outPacket = new DatagramPacket(outBuf, outBuf.length, address, PORT); socket.send(outPacket); try { Thread.sleep(500); }catch (InterruptedException ie) {} } } catch (IOException ioe) { System.out.println(ioe); } } } Observe como a mesma mensagem \u00e9 recebida pelos v\u00e1rios membros e que como diferentes fontes tem seus pacotes recebidos. A t\u00edtulo de curiosidade, IP-Multicast tamb\u00e9m est\u00e1 presente em IPv6, mas com algumas pequenas diferen\u00e7as IP-Multicast em IPv6 3 In IPv6, the left-most bits of an address are used to determine its type. For a multicast address, the first 8 bits are all ones, i.e. FF00::/8. Further, bit 113-116 represent the scope of the address, which can be either one of the following 4: Global, Site-local, Link-local, Node-local. In addition to unicast and multicast, IPv6 also supports anycast, in which a packet can be sent to any member of the group, but need not be sent to all members.'' Exerc\u00edcio: IP-Multicast Implemente e teste o seguinte sevidor. import socket import struct MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((MCAST_GRP, MCAST_PORT)) mreq = struct.pack(\"=4sl\", socket.inet_aton(MCAST_GRP), socket.INADDR_ANY) #4 bytes (4s) seguidos de um long (l), usando ordem nativa (=) sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq) while True: print(sock.recv(10240).decode()) Implemente e teste o seguinte cliente. import socket MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2) sock.sendto(input().encode(), (MCAST_GRP, MCAST_PORT)) Refer\u00eancias UDP em Python UDP em Python Multicast em Java Multicast em Python Multiprograma\u00e7\u00e3o e Multithreading em Sistemas Distribu\u00eddos \u00c9 imposs\u00edvel pensar em sistemas distribu\u00eddos sem pensar em concorr\u00eancia na forma de m\u00faltiplos processos executando, normalmente, em hosts distintos. De fato, os exemplos que apresentamos at\u00e9 agora consistem todos em um processo cliente requisitando a\u00e7\u00f5es de algum processo servidor. Apesar disso, a intera\u00e7\u00e3o entre tais processos aconteceu sempre de forma sincronizada, lock-step , em que o cliente requisitava o servi\u00e7o e ficava bloqueado esperando a resposta do servidor, para ent\u00e3o prosseguir em seu processamento. O servidor, de sua parte, fica bloqueado esperando requisi\u00e7\u00f5es, que atende e ent\u00e3o volta a dormir. Assim, apesar do uso de processadores distintos e da concorr\u00eancia na execu\u00e7\u00e3o dos processos, temos um baixo grau de efetivo paralelismo. Para usarmos melhor os recursos dispon\u00edveis, tanto do lado dos clientes quanto servidores, uma das raz\u00f5es de ser da computa\u00e7\u00e3o distribu\u00edda, temos ent\u00e3o que pensar em termos eventos sendo disparados entre os componentes, que devem ser tratados assim que recebidos ou t\u00e3o logo haja recursos para faz\u00ea-lo. Estes eventos correspondem tanto a requisi\u00e7\u00f5es quanto a respostas (efetivamente tornando dif\u00edcil a distin\u00e7\u00e3o). Al\u00e9m disso, sempre que poss\u00edvel, um componente n\u00e3o deve ficar exclusivamente esperando por eventos, aproveitando a chance executar outras tarefas at\u00e9 que eventos sejam recebidos. Dada que processos interagem com a rede usando sockets, cuja opera\u00e7\u00e3o de leitura \u00e9 bloqueante, para aumentar a concorr\u00eancia em um processo, precisamos falar de multi-threading. H\u00e1 duas raz\u00f5es claras para estudarmos multi-threading. A primeira, de ordem pr\u00e1tica, \u00e9 a discutida acima: permitir o desenvolvimento de componentes que utilizem \"melhormente\" os recursos em um host. A segunda, did\u00e1tica, \u00e9 o fato que muitos dos problemas que aparecem em programa\u00e7\u00e3o multi-thread, aparecem em programa\u00e7\u00e3o multi-processo (como nos sistemas distribu\u00eddos), apenas em um grau de complexidade maior. Para relembrar, h\u00e1 v\u00e1rias diferen\u00e7as entre threads e processos, mas a abstra\u00e7\u00e3o \u00e9 essencialmente a mesma: Processo Thread Inst\u00e2ncia de um programa \"Processo leve\" Estado do processo Estado do thread Fun\u00e7\u00e3o main \"qualquer\" fun\u00e7\u00e3o Mem\u00f3ria privada ao processo Compartilha estado do processo que os cont\u00e9m C\u00f3digo, Stack, Heap, descritores (e.g, file descriptors), controle de acesso Stack, vari\u00e1veis locais IPC - Inter process communication IPC -- Inter process communication Sistema operacional Diferentes implementa\u00e7\u00f5es Posix, C++, Java, ... Vejamos como o uso de m\u00faltiplos threads podem melhorar o desenvolvimento de sistemas distribu\u00eddos na pr\u00e1tica. Considere os exemplos de clientes e servidores vistos anteriormente . Imagine que em vez do servi\u00e7o simples feito no exemplo, o servidor retorne uma p\u00e1gina Web. Detalhes do protocolo seguido por navegadores e servidores ser\u00e3o vistos mais tarde. Por agora, considere apenas que uma requi\u00e7\u00e3o GET arquivo.html ser\u00e1 enviada para o servidor que ler\u00e1 o arquivo especificado do sistema de arquivos; como voc\u00ea sabe, ler um arquivo \u00e9 uma opera\u00e7\u00e3o lenta e que n\u00e3o requer CPU. Cliente multithreaded Do ponto de vista do cliente, a vantagem do uso de m\u00faltiplos threads s\u00e3o claras: permite lidar com v\u00e1rias tarefas concorrentemente , por exemplo solicitar CSS, HTML e imagens concorrentemente, escondendo lat\u00eancia das v\u00e1rias opera\u00e7\u00f5es, e permite organizar c\u00f3digo em blocos/m\u00f3dulos. Se voc\u00ea usar o console de desenvolvimento do navegador, ver\u00e1 que trinta e seis requisi\u00e7\u00f5es s\u00e3o feitas para carregar a p\u00e1gina www.google.com ; um n\u00famero muito maior \u00e9 feito na carga de www.bing.com . TODO Servidor multithreaded Single-threaded H\u00e1 diversas possibilidades de uso de threads em servidores. A mais simples \u00e9 usar apenas um, com temos feito at\u00e9 agora: o cliente envia a requisi\u00e7\u00e3o para o servidor o servidor aceita a conex\u00e3o em seu \u00fanico thread uma tarefa \u00e9 gerada para ler o arquivo o arquivo \u00e9 lido, de forma bloqueante, e uma resposta para o cliente \u00e9 preparada a resposta \u00e9 enviada para o cliente, de forma bloqueante a requisi\u00e7\u00e3o \u00e9 descartada o thread do servidor volta a esperar uma nova requisi\u00e7\u00e3o Thread per request Outra op\u00e7\u00e3o \u00e9 criar um novo thread para cada nova requisi\u00e7\u00e3o, levando a m\u00faltiplos threads atendendo a m\u00faltiplas requisi\u00e7\u00f5es concorrentemente. Desta forma, quando um thread \u00e9 bloqueado para leitura de arquivos do disco, outros clientes podem continuar sendo atendidos. Contudo, o n\u00famero de threads que se pode criar em um SO \u00e9 limitado. Al\u00e9m disso, a cria\u00e7\u00e3o e destrui\u00e7\u00e3o de threads \u00e9 cara e por isso devemos evitar este processo. Thread pool Assim, temos uma outra op\u00e7\u00e3o que tamb\u00e9m usa m\u00faltiplos threads, que usa pools de threads para lidar com as requi\u00e7\u00f5es. No cerne desta abordagem, junto com um pool de threads, fica uma fila bloquenante thread-safe , isto \u00e9, que se mantem correta mesmo quando m\u00faltiplos threads operam nela tanto para inserir quanto remover tarefas, e que bloqueia os threads que tentam inserir quando a fila est\u00e1 cheia ou remover quando ela est\u00e1 vazia. Um thread principal \u00e9 encarregado de receber as requisi\u00e7\u00f5es e colocar na fila bloqueante; se a fila fica cheia, o thread principal fica bloqueado esperando por espa\u00e7o, fazendo com que novas conex\u00f5es tenham que esperar. Os threads do pool removem uma tarefa da fila, a tratam e, ao final do atendimento, pegam nova requisi\u00e7\u00e3o na fila, em um loop infinito; se a fila se esvazia, os threads ficam bloqueados esperando novas requisi\u00e7\u00f5es. \u00c9 poss\u00edvel refinar mais este modelo, quebrando o processamento em v\u00e1rios pools, no que \u00e9 conhecido como Staged Event-Driven Architecture , SEDA. Nesta abordagem, cada est\u00e1gio , por ter seu pr\u00f3prio pool , pode ser escalado individualmente de acordo com a demanda do est\u00e1gio. Esta abordagem tamb\u00e9m \u00e9 \u00fatil quando m\u00faltiplas partes da tarefa consistem em E/S. Uma extrapola\u00e7\u00e3o que pode ser feita aqui, refor\u00e7ando a observa\u00e7\u00e3o que problemas (e solu\u00e7\u00f5es) de sistemas distribu\u00eddos s\u00e3o refletidos em n\u00edvel de processamento paralelo e concorrente, \u00e9 que a uma arquitetura SEDA lembra em muito a arquitetura de micro-servi\u00e7os . Para aprender mais sobre SEDA, v\u00e1 aqui . TODO Problemas com multithreading Embora a ideia de usar m\u00faltiplos threads seja resolver problemas, faz\u00ea-lo efetivamente n\u00e3o trivial. Vejamos, por exemplo, o problema de definir afinidade entre threads, isto \u00e9, de definir quais threads compartilham o mesmo estado de forma que threads afins sejam colocados nos mesmos processadores e compartilhem as mesmas mem\u00f3rias. Isto torna muito mais f\u00e1cil e eficiente o controle de concorr\u00eancia, do ponto de vista do SO e hardware. A realidade, contudo, \u00e9 outra e simplesmente criar m\u00faltiplos threads n\u00e3o garante paralelismo perfeito, pois o SO \u00e9 quem \u00e9 respons\u00e1vel por escalonar os mesmos, e \u00e9 dif\u00edcil determinar (se existir) uma configura\u00e7\u00e3o \u00f3tima em termos de afinidade que seja tamb\u00e9m eficiente. Memes bonitinhos \u00e0 parte, precisamos lidar com estado compartilhado e enfrentar condi\u00e7\u00f5es de corrida de forma a n\u00e3o levar a inconsist\u00eancias na executa\u00e7\u00e3o de tarefas, nos referindo a inconsist\u00eancia aqui como qualquer desvio no comportamento do programa daquilo que foi especificado pelo desenvolvedor. Para isso, usamos as primitivas de controle de concorr\u00eancia que estudaram em SO, que tamb\u00e9m tem seus problemas em potencial, como deadlocks e inani\u00e7\u00e3o . Veja o seguinte v\u00eddeo para uma an\u00e1lise de diversos pontos importantes no uso de multithreads. Estado em Servidores A quest\u00e3o das regi\u00f5es cr\u00edticas no servidor est\u00e1 intimamente relacionada \u00e0 quest\u00e3o da manuten\u00e7\u00e3o de estado nos servidores. Quanto a este respeito, podemos classificar servidores como stateful e stateless , dois termos que ouvir\u00e3o frequentemente enquanto trabalhando com SD. O \"state\" nos dois nomes se refere ao estado mantido por um servi\u00e7o para atender a requisi\u00e7\u00f5es. Caso mantenha estado, por exemplo informando em quais arquivos o cliente est\u00e1 interessado, fica mais f\u00e1cil para o servidor continuar o trabalho feito em requisi\u00e7\u00f5es anteriores. Imagine por exemplo que um cliente esteja acessando linhas em um banco de dados, de forma paginada: a cada requisi\u00e7\u00e3o, o cliente recebe $n$ novas linhas para processar e, quando estiver pronto, requisite $n$ novas linhas. Imagine qu\u00e3o infeficiente seria se o servidor seguisse o seguinte flxo: receba requisi\u00e7\u00e3o informando a \u00faltima linha lida re calcule todas as respostas para consulta salte at\u00e9 a linha informada pelo cliente retorne as pr\u00f3ximas $n$ linhas para o cliente feche o resultado da consulta. Se em vez disso o servidor mantiver um mapa com consultas recentes, em que a chave seja algum identificador do cliente e o valor uma vis\u00e3o dos resultados; a cada nova requisi\u00e7\u00e3o, basta o servidor preparar rapidamente uma nova resposta. Em contrapartida, considere que m\u00faltiplos clientes fazem consultas concorrentemente: quanto recurso seria necess\u00e1rio para que o servidor mantenha a vis\u00e3o de todos os clientes? Tamb\u00e9m a complexidade do servidor aumenta, uma vez que ele precisa manter as respostas a novas requisi\u00e7\u00f5es consistentes com as respostas anteriores e portanto, caso o servi\u00e7o seja implementado por m\u00faltiplos servidores acess\u00edveis ao cliente, o estado deve ser compartilhado por tais servidores. Al\u00e9m disso, imagine que o cliente resolva n\u00e3o fazer mais requisi\u00e7\u00f5es, por exemplo por ter encontrado o que procurava: por quanto tempo o servidor deve manter a vis\u00e3o aberta? Voc\u00ea j\u00e1 deve ter adivinhado que no primeiro exemplo temos um servidor stateless e no segundo um stateful , e percebido que cada um tem suas vantagens e desvantagens. Vejamos mais algumas. Informa\u00e7\u00e3o sobre Sess\u00e3o Essencialmente, o servidor stateless n\u00e3o mantem informa\u00e7\u00e3o sobre a sess\u00e3o do cliente e requer que a cada nova requisi\u00e7\u00e3o, quaisquer informa\u00e7\u00f5es necess\u00e1rias para realizar a tarefa requisitada sejam novamente fornecidas ao servidor. No caso stateful , o servidor pode se lembrar, como no exemplo anterior, at\u00e9 onde o trabalho j\u00e1 foi executado, quais arquivos o cliente manipulou (e mant\u00ea-los abertos), qual o endere\u00e7o o cliente e enviar-lhe notifica\u00e7\u00f5es importantes (e.g., \"Novo dado inserido!\"). Tratamento de falhas Enquanto servidores stateful obviamente levam a melhor desempenho no happy path (contanto que recursos suficientes sejam providos), no caso de falhas, servi\u00e7os stateless tendem a voltar ao ar mais rapidamente, uma vez que n\u00e3o h\u00e1 estado que precise ser recuperado. Pela mesma raz\u00e3o, clientes que percebem que um servidor falhou, podem rapidamente se dirigirem a outros servidores e continuar suas requisi\u00e7\u00f5es de onde estavam, uma vez que s\u00e3o detentores de toda a informa\u00e7\u00e3o necess\u00e1ria para o pr\u00f3ximo passo do processamento. Lidar com falhas tamb\u00e9m introduz outro requisito aos servidores: mem\u00f3ria est\u00e1vel. Para que possa o recuperar o estado anterior \u00e0 falha, o servidor precisa colocar o estado em algum lugar que independa do processo para se manter, por exemplo, nvRAM , SSD ou spindles . A perda deste estado implicaria na incapacidade de prover o servi\u00e7o corretamente. Um projeto stateless n\u00e3o depende deste estado e por isso pode ser mais rapidamente recuperado, replicado ou substitu\u00eddo. Qual \u00e9 melhor? N\u00e3o surpreendentemente, a resposta para \"qual abordagem \u00e9 melhor, stateful ou stateless ?\" \u00e9 depende . Ambos as op\u00e7\u00f5es tem suas vantagens e desvantagens e para algums servi\u00e7os apenas uma op\u00e7\u00e3o ser\u00e1 vi\u00e1vel. Se seu servi\u00e7o precisa manter estado (um SGBD, por exemplo), ele ter\u00e1 que manter estado, mesmo que n\u00e3o sobre clientes. Veja um pequeno comparativo das caracter\u00edsticas das duas abordagens. Stateless Stateful Resultado depende da entrada Depende do hist\u00f3rico de entradas Qualquer servidor pode atender Mesmo servidor deve atender N\u00e3o promete notificar o cliente Assina contrato com o cliente Repete opera\u00e7\u00f5es Aproveita resultados anteriores N\u00e3o fica inconsistente com rela\u00e7\u00e3o ao cliente Pode ficar inconsistente se perder estado ou conex\u00e3o feita com outro servidor re-autentica\u00e7\u00e3o (mesmo que simplficada) a cada requisi\u00e7\u00e3o Autentica no come\u00e7o da sess\u00e3o Leia mais Uma vis\u00e3o interessante sobre estado \u00e9 apresentada em On stateless software design . Observe que n\u00e3o necessariamente eu concordo com tudo o que est\u00e1 escrito aqui, principalmente a quest\u00e3o sobre stateful ser sempre mais complexo. A discrep\u00e2ncia de vis\u00e3o est\u00e1 no fato de parte da complexidade ser levada para o cliente, no caso dos servidores stateless , mas n\u00e3o necessariamente ser eliminada. Sobre IO n\u00e3o bloqueante em Java. Multithread na pr\u00e1tica PThreads POSIX Threads ou PThreads, s\u00e3o uma defini\u00e7\u00e3o aberta de como threads devem funcionar em sistemas operacionais. V\u00e1rias implementa\u00e7\u00f5es desta especifica\u00e7\u00e3o est\u00e3o dispon\u00edveis tanto para sistemas Unix, compat\u00edveis com especifi\u00e7\u00f5es POSIX, mas tamb\u00e9m para Windows, via subsistemas. Al\u00e9m disso, mesmo implementa\u00e7\u00f5es n\u00e3o POSIX tem funcionalidade equivalentes e, por este motivo, entender POSIX servir\u00e1 de base para entender quaisquer API para programa\u00e7\u00e3o multi-threaded . Fun\u00e7\u00e3o de entrada Para se definir um thread , \u00e9 necess\u00e1rio definir uma fun\u00e7\u00e3o de entrada, que ser\u00e1 para o thread como a fun\u00e7\u00e3o main \u00e9 para o processo em si. No exemplo a seguir a fun\u00e7\u00e3o foi definida com retorno void * e com \u00fanico par\u00e2metro tambem void * ; esta \u00e9 uma obrigatoriedade para fun\u00e7\u00f5es de entrata PThread. Observe contudo que void * pode ser tratado como um blob para mascarar outros tipos de dado, por exemplo um vetor, um enumera\u00e7\u00e3o ou uma struct . #include <stdio.h> #include <stdlib.h> #include <pthread.h> int thread_count; void* hello(void* rank) { long my_rank = (long) rank; printf(\"Hello from thread %ld of %d\\n\", my_rank, thread_count); return NULL; } Cria\u00e7\u00e3o Um thread \u00e9 criado pela fun\u00e7\u00e3o pthread_create , que coloca em um pthread_t um handle para o thread . A fun\u00e7\u00e3o recebe como par\u00e2metros op\u00e7\u00f5es para configura\u00e7\u00e3o, a fun\u00e7\u00e3o de entrada, e o par\u00e2metro do tipo void * . int main(int argc, char* argv[]) { long thread; pthread_t* thread_handles; if(argc < 2) { printf(\"usage: %s <number of threads>\", argv[0]); return 1; } thread_count = strtol(argv[1], NULL, 10); thread_handles = malloc(thread_count*sizeof(pthread_t)); for (thread = 0; thread < thread_count; thread++) pthread_create(&thread_handles[thread], NULL, hello, (void*) thread); printf(\"Hello from the main thread\\n\"); Destrui\u00e7\u00e3o O handle do thread deve ser alocado previamente \u00e0 fun\u00e7\u00e3o de cria\u00e7\u00e3o e liberado ap\u00f3s o fim da execu\u00e7\u00e3o do thread . \u00c9 poss\u00edvel esperar pelo fim da execu\u00e7\u00e3o usando o pthread_join , que recebe como par\u00e2metro o handle do thread e um ponteiro para onde o resultado da fun\u00e7\u00e3o de entrada deve ser colocado, do tipo void ** . for (thread = 0; thread < thread_count; thread++) pthread_join(thread_handles[thread], NULL); free(thread_handles); Execu\u00e7\u00e3o Para executar um programa PThread, compile com gcc -pthread teste.c -o teste e execute com ./teste 5 e observe que a sa\u00edda das threads \u00e9 ordenada . Agora experimente ./teste 200 Observe que a sa\u00edda \u00e9 desordenada (pode ser necess\u00e1rio executar m\u00faltiplas vezes ou aumentar de 200 para, digamos, 1000 para observar a desordem. Isto acontece porqu\u00ea a execu\u00e7\u00e3o das threads independe da ordem de cria\u00e7\u00e3o. De fato, usando PThreads, temos pouco controle sobre os threads que criamos. Mas isto n\u00e3o quer dizer que estamos \"\u00f3rf\u00e3os\" de API; v\u00e1rias outras opera\u00e7\u00f5es podem ser executadas, e podem ser encontradas a partir do manual de pthread_create . Alguns exemplos interessantes: pthread_tryjoin - espera thread terminar pthread_exit - termina a thread e retorna resultado An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function's return value serves as the thread's exit status. Manual de pthread_exit . pthread_attr_setaffinity_np * - ajusta afinidade dos threads. Threads Java Neste tutorial, baseado neste outro , exploraremos formas de se obter concorr\u00eancia em Java. Isto \u00e9, exploraremos como iniciar m\u00faltiplas linhas de execu\u00e7\u00e3o de instru\u00e7\u00f5es, que podem ou n\u00e3o, ser executadas em paralelo. Em Java, h\u00e1 essencialmente duas formas de se conseguir concorr\u00eancia. A primeira \u00e9 via inst\u00e2ncias expl\u00edcitas da classe Thread , e a segunda \u00e9 via abstra\u00e7\u00f5es de mais alto n\u00edvel, os Executors . Thread Executor Al\u00e9m de formas de definir as linhas de execu\u00e7\u00e3o, Java prov\u00ea diversas estruturas para comunica\u00e7\u00e3o e coordena\u00e7\u00e3o destas linhas, desde de a vers\u00e3o 5 da linguagem, no pacote java.util.concurrent . Cria\u00e7\u00e3o de Threads Java H\u00e1 duas formas b\u00e1sicas de se usar a classe Thread , via extens\u00e3o ou delega\u00e7\u00e3o de um objeto implementando Runnable . Extender Thread public class HelloThread extends Thread { public void run() { System.out.println(\"Hello from a thread!\"); } public static void main(String args[]) { Thread t = new HelloThread(); t.start(); } } Implementar Runnable public class HelloRunnable implements Runnable { public void run() { System.out.println(\"Hello from a thread!\"); } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); t.start(); } } Observe que nos dois exemplos, um m\u00e9todo run() \u00e9 implementado com o c\u00f3digo a ser executado pelo thread . Em nenhum dos exemplos, contudo, o m\u00e9todo \u00e9 invocado diretamente. Em vez disto, o m\u00e9todo start() , sim, \u00e9 invocado. Isto ocorre pq antes de executar as instru\u00e7\u00f5es definidas pelo pelo programador no m\u00e9todo run() , a m\u00e1quina virtual precisa executar alguma \"m\u00e1gica\" por baixo dos panos como, por exemplo, solicitar ao sistema operacional a cria\u00e7\u00e3o de um thread do SO, que servir\u00e1 de hospedeiro para o thread Java. Isto acontece dentro do start() , que em algum ponto de sua execu\u00e7\u00e3o levar\u00e1 \u00e0 invoca\u00e7\u00e3o do m\u00e9todo run() . API Thread A classe Thread tamb\u00e9m prov\u00ea uma s\u00e9rie de m\u00e9todos que permitem gerenciar a vida do thread criado. Por exemplo, o m\u00e9todo de classe ( static ) Thread.sleep() permite bloquear um thread por um determinado per\u00edodo. Thread.sleep() public class HelloRunnable implements Runnable { public void run() { for (int i = 0; i < 10; i ++) { System.out.println(\"Hello at instant \" + i); try { Thread.sleep(1000); } catch (InterruptedException ie) { System.out.println(\"awoken\"); } } } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); t.start(); } } Observe que a chamada a sleep() est\u00e1 dentro de um bloco try/catch . Isto \u00e9 necess\u00e1rio pois \u00e9 permitido \u00e0 JVM acordar o thread em qualquer instante, antes ou ap\u00f3s o tempo especificado. Assim, embora normalmente o tempo \"dormido\" seja pr\u00f3ximo ao especificado, se h\u00e1 requisitos de precis\u00e3o, \u00e9 necess\u00e1rio que o thread , ao acordar, verifique se j\u00e1 dormiu o suficiente. InterruptedException public class HelloRunnable implements Runnable { public void run() { for (int i = 0; i < 10; i ++) { System.out.println(\"Hello at instant \" + i); long before = System.currentTimeMillis(); long timeout = 1000; while(before + timeout > System.currentTimeMillis()) { try { Thread.sleep(Math.max(0,System.currentTimeMillis() - (before + timeout))); } catch (InterruptedException ie) { System.out.println(\"awoken\"); } } } } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); t.start(); } } Quando um thread est\u00e1 sendo executado, outros podem ter que esperar at\u00e9 que complete. Por exemplo, no caso de um navegador Web, o thread que faz a renderiza\u00e7\u00e3o da p\u00e1gina n\u00e3o pode come\u00e7ar a trabalhar enquanto o thread que solicitou o HTML do servidor n\u00e3o receber sua resposta. Um thread indica a inten\u00e7\u00e3o de esperar por outro usando o m\u00e9todo join() . Thread.join() public class HelloRunnable implements Runnable { public void run() { Random rand = new Random(); for (int i = 0; i < 10; i ++) { System.out.println(\"Hello at instant \" + i); long before = System.currentTimeMillis(); long timeout = 901 + rand.nextInt(200); while(before + timeout > System.currentTimeMillis()) { try { Thread.sleep(Math.max(0,System.currentTimeMillis() - (before + timeout))); } catch (InterruptedException ie) { System.out.println(\"awoken\"); } } } } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); //t.setDaemon(true); t.start(); try { t.join(); //t.join(10000); } catch (InterruptedException ie) { System.out.println(\"Waiting was interrupted\"); } if (t.isAlive()) System.out.println(\"Got tired of waiting\"); else System.out.println(\"Wait is over\"); } } Invocar t.join() far\u00e1 com que o thread principal espere indefinidamente at\u00e9 que t termine de executar. Caso seja necess\u00e1rio limitar o tempo de espera, o tempo pode ser especificado como na linha comentada. Caso a espera termine por causa de um timeout , \u00e9 poss\u00edvel testar o estado atual do thread com Thread.isAlive() . Outro m\u00e9todo interessante, Thread.setDaemon() , especifica que o thread pode ser terminado quando a thread principal terminar. Descomente a invoca\u00e7\u00e3o e teste o efeito. Exerc\u00edcio Vejamos um exemplo simples do uso de threads . Instancie um programa que gere 10 threads . Todos os threads devem compartilhar uma mesma inst\u00e2ncia de Counter Cada thread deve executar um loop em que incrementa o valor do contador 20 vezes a cada vez, imprime o resultado precedido do identificador do thread (use Thread.getName() ou Thread.currentThread().getName() ) A thread principal deve esperar todas as outras terminarem antes de terminar (use Thread.join() ). Analise a sa\u00edda do programa observando a ordem de execu\u00e7\u00e3o dos threads . Counter.java class Counter { private int c = 0; public int increment() { return ++c; } public int decrement() { return --c; } public int value() { return c; } } \u00c9 f\u00e1cil observar que a sa\u00edda do programa \u00e9 aleat\u00f3ria nos identificadores e tende a ser incremental nos contadores, mas nem sempre isso \u00e9 verdade. Como discutido anteriormente, frequentemente threads tem que coordenar suas a\u00e7\u00f5es para que n\u00e3o pisem uns nos outros, por exemplo decidindo quem deve ser o pr\u00f3ximo a entrar em uma regi\u00e3o cr\u00edtica ou ser\u00e1 o respons\u00e1vel por uma tarefa. Em Java, esta coordena\u00e7\u00e3o pode ser feita por diversas abstra\u00e7\u00f5es: synchronized , Lock , vari\u00e1veis at\u00f4micas, ... synchronized Ao definir m\u00e9todos como synchronized , garante-se que os mesmos nunca ser\u00e3o executados concorrentemente. Observe a classe a seguir, que modifica o contador do exerc\u00edcio anterior. public class SynchronizedCounter { private int c = 0; public synchronized int increment() { return ++c; } public synchronized int decrement() { return --c; } public synchronized int value() { return c; } } Caso dois threads invoquem os m\u00e9todos increment e decrement ao mesmo tempo, por exemplo, a JVM far\u00e1 com que um dos threads pare sua execu\u00e7\u00e3o at\u00e9 que o outro tenha completado a invoca\u00e7\u00e3o. Isto n\u00e3o quer dizer que executar o exerc\u00edcio anterior com esta vers\u00e3o do contador n\u00e3o levar\u00e1 a sa\u00eddas com incrementos completamente sequenciais, pois um thread poderia parar de ser executado logo ap\u00f3s incrementar o contador, depois de terminado o m\u00e9todo increment , e s\u00f3 voltar a executar depois que outro tenha incrementado e impresso na tela o valor obtido. O que quer dizer \u00e9 que, mesmo que sa\u00eddas estranhas existam, cada opera\u00e7\u00e3o foi executada integralmente antes da opera\u00e7\u00e3o seguinte. Exerc\u00edcio Modifique o c\u00f3digo do exerc\u00edcio anterior para usar a vers\u00e3o synchronized do contador. Depois de execut\u00e1-lo, adicione um println(\"Dentro: \" + c) dentro do m\u00e9todo de incremento para verificar que estas sa\u00eddas acontecem ordenadamente. Blocos synchronized synchronized funciona porqu\u00ea limita a concorr\u00eancia, e \u00e9 problem\u00e1tico exatamente pela mesma raz\u00e3o. Por isso, \u00e9 essencial que o synchronized seja o mais limitado poss\u00edvel em termos de escopo, o que nos leva ao uso de synchronized em blocos de c\u00f3digo menores que m\u00e9todos. Por exemplo: public class Namer { String lastName = null; int nameCount = 0; public void addName(String name) { lastName = name; synchronized(this) { nameCount++; } nameList.add(name); } } Neste caso, blocos sincronizados no mesmo objeto , n\u00e3o s\u00e3o executados concorrentemente, mas outros blocos sim. Exerc\u00edcio Neste exerc\u00edcio, use dois objetos para travar o acesso a dois contadores. Instancie um programa com dois threads tal que: * executem um loop 1000 vezes em que * o primeiro thread primeiro invoca inc1 e depois inc2 * o segundo thread primeiro invoca inc2 e depois inc1 * ambos os threads imprimem o valor de c1 e c2 synchronized public class MsLunch { private long c1 = 0; private long c2 = 0; private Object lock1 = new Object(); private Object lock2 = new Object(); public void inc1() { synchronized(lock1) { c1++; } } public void inc2() { synchronized(lock2) { c2++; } } } Deadlock O uso dos \"locks\" em ordens diferentes pode levar a um deadlock, pois o seguinte grafo de depend\u00eancia poder\u00e1 ser gerado: Deadlock graph LR T1 --> lock1 T2 --> lock2 lock1 --> T2 lock2 --> T1 Sinaliza\u00e7\u00e3o Usados corretamente, o bloco synchronized \u00e9 executado de forma at\u00f4mica, isto \u00e9, indivis\u00edvel. Algumas opera\u00e7\u00f5es muito simples s\u00e3o naturalmente at\u00f4micas, e n\u00e3o precisam ser \"protegidas\" pelo synchronized . Por exemplo, leituras e escritas de tipos b\u00e1sicos como ( int , char , byte , mas n\u00e3o long ou double ), ou vari\u00e1veis declaradas volatile . Usando estas vari\u00e1veis, \u00e9 poss\u00edvel coordenar threads , por exemplo, assim: Espera ocupada boolean condicao = false; ... public void espereCondicao() { while(!condicao) {} System.out.println(\"condicao alcancada.\"); } ... public void satisfacaCondicao() { condicao = true; } Embora correto, esta abordagem n\u00e3o \u00e9 eficiente, pois o primeiro m\u00e9todo desperdi\u00e7a computa\u00e7\u00e3o. Felizmente, em Java, todos os objetos implementam os m\u00e9todos wait e notify/notifyAll , que podem ser usados para sincronizar eficientemente threads . Wait/Notify public class Sync{ Object synch = new Object(); boolean condicao = false; public void espereCondicao() { while(!condicao) { try { synch.wait(); } catch (InterruptedException e) {} } System.out.println(\"Condicao alcancada\"); } ... public void satisfacaCondicao() { condicao = true; synch.notifyAll(); } } Locks Outras abstra\u00e7\u00f5es para coordena\u00e7\u00e3o de threads est\u00e3o dispon\u00edveis no pacote java.util.concurrent . As mais simples delas s\u00e3o java.util.concurrent.locks.Lock e java.util.concurrent.locks.ReentrantLock . Veja um exemplo de uso, notando o idioma de uso dentro de block try/catch . Lock l = new ReentrantLock(); l.lock(); try { // access the resource protected by this lock } finally { l.unlock(); } Executor Al\u00e9m de threads , Java disponibiliza Executor como abstra\u00e7\u00e3o de mais alto n\u00edvel para execu\u00e7\u00e3o de tarefas concorrentes. Executor ExecutorService ScheduledExecutorService Executor e = ...; Runnable r = ...; e.execute(r); Executors normalmente implementam thread pools , que podem ser de diferentes tipos. O mais simples \u00e9 o de tamanho fixo em que h\u00e1 um n\u00famero inicial de threads criados e que, no caso de algum ser terminado, por exemplo por causa de uma exce\u00e7\u00e3o n\u00e3o tratada, cria substitutos para manter o n\u00famero constante. ThreadPool Executor e = java.util.concurrent.Executors.newFixedThreadPool(); newCachedThreadPool() - expandable thread pool newSingleThreadExecutor() - single task at a time e outras vers\u00f5es ForkJoinPool Fork/Join if (my portion of the work is small enough) do the work directly else split my work into two pieces invoke the two pieces and wait for the results Estrutura para Coordena\u00e7\u00e3o de Threads Finalmente, Java tamb\u00e9m disponibiliza estruturas de dados que podem ser acessadas concorrentemente por m\u00faltiplos threads sem risco de corrup\u00e7\u00e3o. BlockingQueue - bloquei threads se n\u00e3o houver elementos na filq. ConcurrentMap/ConcurrentHashMap - opera\u00e7\u00f5es at\u00f4micas; if (!m.containsKey(k)) m.put(k,v); vOld = m.putIfAbsent(k,v); Tipos At\u00f4micos import java.util.concurrent.atomic.AtomicInteger; class AtomicCounter { private AtomicInteger c = new AtomicInteger(0); public void increment() { c.incrementAndGet(); } public void decrement() { c.decrementAndGet(); } public int value() { return c.get(); } } ThreadLocal private static ThreadLocal<Integer> myId = new ThreadLocal<Integer>() { public Integer initialValue() { return new Random().nexInt(); } }; public static Integer getMyId() { return myId.get(); } Leia mais Para aprender mais, muito mais sobre concorr\u00eancia em Java, \u00f3timas refer\u00eancias s\u00e3o: Java Concurrency in Practice The Well-Grounded Java Developer Concorr\u00eancia em Java Futures e Promises Locks Tipos At\u00f4micos Threads em Python Em Python, como seria de se esperar, h\u00e1 v\u00e1rias formas de se trabalhar com threads . A seguir s\u00e3o apresentados dois exemplos, usando o pacote thread ou threading . #!/usr/bin/python import thread import time # Define a function for the thread def print_time( threadName, delay): count = 0 while count < 5: time.sleep(delay) count += 1 print \"%s: %s\" % ( threadName, time.ctime(time.time()) ) # Create two threads as follows try: thread.start_new_thread( print_time, (\"Thread-1\", 2, ) ) thread.start_new_thread( print_time, (\"Thread-2\", 4, ) ) except: print \"Error: unable to start thread\" while True: pass Ou #!/usr/bin/python import threading import time exitFlag = 0 class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print \"Starting \" + self.name print_time(self.name, self.counter, 5) print \"Exiting \" + self.name def print_time(threadName, counter, delay): while counter: if exitFlag: threadName.exit() time.sleep(delay) print \"%s: %s\" % (threadName, time.ctime(time.time())) counter -= 1 # Create new threads thread1 = myThread(1, \"Thread-1\", 1) thread2 = myThread(2, \"Thread-2\", 2) # Start new Threads thread1.start() thread2.start() print \"Exiting Main Thread\" Leia mais Threads em Python Exerc\u00edcio - Anel Multithread Usando uma linguagem de alto-n\u00edvel como C/C++/Java, escrever um programa que crie 30 threads e fa\u00e7a com que uma mensagem circule entre os mesmos. A mensagem \u00e9 uma string aleat\u00f3ria de pelo menos 80 caracteres. A cada vez que um thread recebe a mensagem ele a imprime, modifica o primeiro caractere min\u00fasculo para mai\u00fasculo, caso exista, dorme por 1 segundo, e repassa a mensagem. Quando todos os caracteres forem mai\u00fasculos, o processo repassa a mensagem e ent\u00e3o termina. Antes de terminar, o processo deve imprimir a mensagem resultante. Endere\u00e7os IP n\u00e3o p\u00fablicos n\u00e3o server como identificadores \u00fanicos na Internet. \u21a9 Se o segundo comando n\u00e3o funcionar, tente nc em vez de netcat . \u21a9 IP-Multicast em IPv6 \u21a9","title":"Fundamentos"},{"location":"basics/#fundamentos","text":"A pedra fundamental da constru\u00e7\u00e3o de sistemas distribu\u00eddos \u00e9 a capacidade de comunica\u00e7\u00e3o entre seus componentes. No mundo de hoje, isto quer dizer que os hosts dos componentes devem possuir interfaces de rede e que estas interfaces estejam ligadas a uma rede com capacidade de roteamento de dados, estabelecendo um canal de comunica\u00e7\u00e3o entre os componentes. Al\u00e9m do canal, \u00e9 tamb\u00e9m necess\u00e1rio que se estabele\u00e7a um protocolo de comunica\u00e7\u00e3o , que define as regras para que a comunica\u00e7\u00e3o aconte\u00e7a, por exemplo, a gram\u00e1tica para forma\u00e7\u00e3o de mensagens. Tamb\u00e9m importantes, de um ponto de vista pr\u00e1tico do desenvolvimento, s\u00e3o os conceitos de concorr\u00eancia e paralelismo. Afinal, um componente pode necessitar manter v\u00e1rias \"conversas\" em paralelo com m\u00faltiplos outros componentes. Neste cap\u00edtulo, revisaremos de forma r\u00e1pida tanto conceitos de redes de computadores quanto de concorr\u00eancia e paralelismo.","title":"Fundamentos"},{"location":"basics/#canais-e-protocolos-de-comunicacao","text":"Um canal de comunica\u00e7\u00e3o \u00e9 o meio pelo qual os elementos da conversa entre os componentes do sistema distribu\u00eddo s\u00e3o transmitidos e o protocolo s\u00e3o as regras codificam tal conversa. Por exemplo, quando voc\u00ea fala com uma pessoa, cara-a-cara, o meio de comunica\u00e7\u00e3o \u00e9 o ar e o protocolo utilizado \u00e9 a linguagem conhecida pelas duas partes, o Portugu\u00eas por exemplo. Na pr\u00e1tica, canais de comunica\u00e7\u00e3o podem ter diversas formas e caracter\u00edsticas, por exemplo: Ponto-a-ponto Eficiente Caro para muitos n\u00f3s Roteamento trivial Compartilhado Colis\u00f5es Menor custo Roteamento mais complicado Nas redes atuais, pode se dizer que o meio mais utilizado \u00e9 provido pela arquitetura Ethernet , que trata da comunica\u00e7\u00e3o n\u00f3s usando um barramento compartilhado . Sobre este meio, s\u00e3o usados protocolos para, por exemplo, Controle de acesso ao meio Transmiss\u00e3o de mensagens Evitar e tratar colis\u00f5es As redes Ethernet, contudo, cobrem pequenas \u00e1reas e para se ter conversas \"mais interessantes\", \u00e9 necess\u00e1rio que se conecte diversas destas redes. A conversa ent\u00e3o \u00e9 feita por meio de intermedi\u00e1rios, gateways que conectam duas ou mais redes, permitindo que mensagens de um interlocutor sejam roteadas para o outro, via tais intermedi\u00e1rios. Um exemplo interessante das quest\u00f5es ligadas \u00e0 manuten\u00e7\u00e3o da conversa entre dois pontos \u00e9 a decis\u00e3o sobre o uso de comuta\u00e7\u00e3o de pacotes ( packet switching ) ou de circuitos ( circuit switching ). Comuta\u00e7ao de pacotes Dados divididos em pacotes Cada pacote viaja independentemente Pacotes s\u00e3o perdidos Lat\u00eancia vari\u00e1vel Circuit switching Caminho dedicado Recursos reservados Pacotes de tamanho fixo Lat\u00eancia constante Outro fator importante \u00e9 o MTU, o tamanho m\u00e1ximo de um pacote em determinada rede. \u00c9 necess\u00e1rio entender que qualquer quantidade de dados maior que o MTU precisar\u00e1 ser dividida em m\u00faltiplos pacotes. Tamb\u00e9m \u00e9 importante perceber que redes s\u00e3o heterog\u00eaneas, e que o v\u00e1rios segmentos no caminho entre origem e destino podem ter MTU diferentes, levando \u00e0 fragmenta\u00e7\u00e3o de pacotes em tr\u00e2nsito e, possivelmente, entrega desordenada dos mesmos. Finalmente, h\u00e1 a quest\u00e3o importante \u00e9 relativa \u00e0 confiabilidade na transmiss\u00e3o dos elementos da conversa, isto \u00e9, se a rede deve garantir ou n\u00e3o que algo \"dito\" por um interlocutor deve garantidamente ser \"ouvido\" pelo outro, ou se a mensagem pode ser perdida no meio. Felizmente boa parte da complexidade da resolu\u00e7\u00e3o destas quest\u00f5es \u00e9 abstra\u00edda do desenvolvedor dos sistemas distribu\u00eddos, isto \u00e9, voc\u00ea , lhe cabendo apenas a decis\u00e3o de qual protocolo utilizar. Nas redes atuais, a conversa em componentes ser\u00e1 feita, em algum n\u00edvel, por meio dos protocolos da arquitetura Internet .","title":"Canais e Protocolos de Comunica\u00e7\u00e3o"},{"location":"basics/#a-internet","text":"A Internet tem este nome por usar o protocolo de interconex\u00e3o de redes indepententes, o internetworking protocol , ou IP. Para a aplica\u00e7\u00e3u usando o IP, todas as redes se comportam com uma \u00fanica e coerente rede, exceto por alguns detalhes. Os elementos que conectam as diversas redes s\u00e3o denominados roteadores e fazem um melhor esfor\u00e7o para encaminhar os pacotes de dados do remetente ao destinat\u00e1rio. Se voc\u00ea se lembrar da pilha de protocolos de comunica\u00e7\u00e3o de refer\u00eancia OSI, lembrar\u00e1 que h\u00e1 sete camadas na mesma. Cada camada \u00e9 respons\u00e1vel pela comunica\u00e7\u00e3o em um n\u00edvel e serve de funda\u00e7\u00e3o para a funcionalidade da camada de cima. Cada camada tem um cabe\u00e7alho ( header ) e uma carga ( payload ) e o conjunto de cabe\u00e7alho + carga de uma camada \u00e9 considerado carga da camada inferior. Assim, embora tenha-se a impress\u00e3o de que cada camada conversa com a equivalente do outro lado da comunica\u00e7\u00e3o, na pr\u00e1tica, a comunica\u00e7\u00e3o desce e sobe a pilha. Bits Frames/quadros; controle de fluxo; acesso ao meio. Datagramas/pacotes; roteamento Controle de fluxo; fim a fim; confiabilidade; tcp e udp Streams/fluxos; conex\u00f5es l\u00f3gicas; restart; checkpoint; http, ssl Objetos; json, xml; criptografia Aplica\u00e7\u00f5es; http, pop, ftp Embora o IP se refira estritamente ao protocolo da camada 3 da pilha, nos referimos \u00e0 pilha que usa este protocolo como a pilha IP. Comparada \u00e0 pilha OSI, a IP \u00e9 mais simples, como se v\u00ea na figura. Como usu\u00e1rios da pilha IP, temos que entender como a camada 3 funciona, mas dificilmente interagiremos com algo al\u00e9m da camada 4, a camada de transporte . Como se v\u00ea, as camadas 5 e 6 n\u00e3o est\u00e3o presentes na pilha IP e as funcionalidades correspondentes s\u00e3o implementadas na camada 7, de aplica\u00e7ao. Contudo, n\u00e3o tema! Estas funcionalidades podem se normalmente implementadas por meio de frameworks ou do middleware em uso. Alguns exemplos de tais funcionalidades s\u00e3o (De)Serializa\u00e7\u00e3o Nomeamento Criptografia Replica\u00e7\u00e3o Invoca\u00e7\u00e3o remota de procedimentos A grande vantagem desta abordagem \u00e9 que se pode implementar exatamente e somente as funcionalidades desejadas. Este caracter\u00edstica \u00e9 conhecida como o argumento fim-a-fim no projeto de sistemas ; uma an\u00e1lise recente deste argumento foi feita aqui .","title":"A Internet"},{"location":"basics/#no-principio-era-o-socket","text":"Na pr\u00e1tica, para implementarmos a comunica\u00e7\u00e3o entre processos, usamos sockets . Para se definir um socket a partir de um host \u00e9 necess\u00e1rio identificar o outro fim da comunica\u00e7\u00e3o, isto \u00e9, o outro host , ou melhor, uma de suas interfaces de rede. Os sockets s\u00e3o ent\u00e3o a abstra\u00e7\u00e3o dos canais de comunica\u00e7\u00e3o, mas como dito antes, \u00e9 necess\u00e1rio definir tamb\u00e9m os protocolos usados por estes sockets. O primeiro protocolo \u00e9 o de endere\u00e7amento, que define qual pilha de protocolos usar, na camada 3. No caso da pilha IP, usa-se o protocolo AF_INET ou PF_INET. Escolhido o protocolo, cada interface tem um endere\u00e7o MAC, na camada 2, que o identifica entre as interfaces na mesma rede local, e cada interface tem um endere\u00e7o IPv4/IPv6 de 32/128 bits, que o indentifica entre todos os hosts na Internet 1 . Mas dentro de um host , podem haver diversas aplica\u00e7\u00f5es sendo executadas. Como identificar exatamente com qual se quer conversar? Isto \u00e9 feito pela defini\u00e7\u00e3o uma porta: Porta: 16 bits IANA (Internet Assigned Numbers Authority) Bem conhecidas -- 0-1023 Propriet\u00e1rias -- 49151 Din\u00e2micas -- 65535 Tamb\u00e9m \u00e9 necess\u00e1rio definir tamb\u00e9m o protocolo de transporte dos dados, na camada 4. Novamente, no caso da pilha IP, pode-se usar TCP ( SOCK_STREAM ) ou UPD ( SOCK_DGRAM ). A API usada para estabelecer a conversa via socket tem v\u00e1rias chamadas, que devem ser executadas na ordem certa no processo iniciando a conversa e naquele que aceita participar da mesma. Comecemos estudando o TCP.","title":"No princ\u00edpio, era o Socket"},{"location":"basics/#tcp","text":"O fluxograma da cria\u00e7\u00e3o de um socket TCP \u00e9 apresentado na seguinte figura: criar socket bind listen accept connect Estabelecido o socket, o mesmo pode ser usado como arquivo , isto \u00e9, lendo-se e escrevendo-se bytes. O que exatamente deve ser escrito e como o que \u00e9 lido deve ser interpretado \u00e9 o protocolo da camada 7, sua responsabilidade . Vejamos um exemplo do uso de sockets, em Python. O seguinte arquivo pode ser nomeado, por exemplo, server.py , mas n\u00e3o pode, de forma alguma, ser nomeado socket.py . #server.py #!/usr/bin/python # This is server.py file import socket # Import socket module s = socket.socket() # Create a socket object host = socket.gethostname() # Get local machine name port = 12345 # Reserve a port for your service. s.bind((host, port)) # Bind to the port s.listen(5) # Now wait for client connections. while True: c, addr = s.accept() # Establish connection with client. print('Got connection from', addr) c.send('Thank you for connecting'.encode()) c.close() # Close the connection Para execut\u00e1-lo, execute o seguinte comando em um terminal. python server.py Em outro terminal, execute um dos dois comandos a seguir 2 : telnet localhost 12345 netcat localhost 12345 O que est\u00e1 acontecendo aqui \u00e9 um processo criou um socket e ficou aguardando uma conex\u00e3o, usando o c\u00f3digo em Python. Tanto o telnet quando o netcat s\u00e3o programas gen\u00e9ricos para se conversar com outro processo usando TCP/IP. Aqui, estes programas simplesmente se conectaram e imprimiram o que quer que o primeiro processo lhes tenha enviado, assumindo que correspondia a uma string, o que neste caso \u00e9 correto. Simples, n\u00e3o \u00e9 mesmo? Em geral, denominamos o processo que fica aguardando a conex\u00e3o de servidor e o processo que se conecta de cliente . Isto por qu\u00ea, em geral, o servidor executa alguma tarefa, serve, o cliente, embora isto n\u00e3o seja necessariamente verdade. Por completude, vamos tamb\u00e9m escrever o c\u00f3digo do cliente, agora que voc\u00ea j\u00e1 sabe que o servidor funciona. Do lado cliente, estabelece-se uma conex\u00e3o apontando-se para onde est\u00e1 o servidor. #client.py #!/usr/bin/python # This is client.py file import socket # Import socket module s = socket.socket() # Create a socket object host = socket.gethostname() # Get local machine name port = 12345 # Reserve a port for your service. s.connect((host, port)) data = s.recv(1024) print(data.decode()) s.close() # Close the socket when done E para se executar o cliente, fa\u00e7a: python client.py Observe que o socket.close() encerra a conex\u00e3o do lado de quem invoca. Na contraparte, invoca\u00e7\u00f5es a socket.recv() retornam com 0 bytes lidos. A t\u00edtulo de compara\u00e7\u00e3o, em Java, a cria\u00e7\u00e3o do socket do lado do servidor seria muito mais simples, consistindo apenas em: Socket s = new ServerSocket(port); O cliente em Java tamb\u00e9m \u00e9 simplificado. Socket s = new Socket(hostname,port);","title":"TCP"},{"location":"basics/#exercicio-multiplos-pacotes","text":"Fa\u00e7amos agora uma modifica\u00e7\u00e3o no c\u00f3digo do servidor para que envie n\u00e3o uma, mas duas mensagens para o cliente. Isto \u00e9, modifique seu servidor assim ... c.send('Thank you for connecting'.encode()) c.send('Come back often'.encode()) ... Agora execute novamente o cliente e veja o que acontece. Consegue explicar o fen\u00f4meno? Modifiquemos o cliente agora, para que tenha dois recv , assim. ... print(\"1\") data = s.recv(1024) print(data.decode()) print(\"2\") data = s.recv(1024) print(data.decode()) ... E agora, o que acontece? A sa\u00edda \u00e9 como esperava? Como explica este fen\u00f4meno e como poderia corrig\u00ed-lo?","title":"Exerc\u00edcio: M\u00faltiplos Pacotes"},{"location":"basics/#exercicio-ping-pong","text":"Modifique cliente e servidor tal que o cliente envie uma mensagem passada na linha de comando ao servidor e fique esperando uma resposta, e tal que o servidor fique esperando uma mensagem e ent\u00e3o solicite ao operador que digite uma resposta e a envie para o cliente. O loop continua at\u00e9 que o usu\u00e1rio digite SAIR, e a conex\u00e3o seja encerrada. Terminal 1 Terminal 2 python server.py Esperando conex\u00e3o. Esperando mensagem. Mensagem recebida: lalala Digite resposta: lelele Resposta enviada. Conex\u00e3o encerrada. Esperando conex\u00e3o. python client.py Digite mensagem: lalala Mensagem enviada. Esperando resposta. Resposta recebida: lelele Digite mensagem: SAIR Desconectando. Observe que para ler do teclado em Python 2 voc\u00ea deve usar x = raw_input() , enquanto que em Python 3 seria x = input() . Al\u00e9m disso, em Python 2, voc\u00ea deve remover as invoca\u00e7\u00f5es para encode e decode .","title":"Exerc\u00edcio: Ping-Pong"},{"location":"basics/#udp","text":"No exemplo anterior, usamos o protocolo TCP (o padr\u00e3o da API). Caso quis\u00e9ssemos usar UDP, precisar\u00edamos nos atentar a alguns detalhes. A cria\u00e7\u00e3o do socket \u00e9 feita explicitando-se o uso de datagramas : s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) Um servidor UDP n\u00e3o executa listen ou accept e, em Python, simplesmente executa data, addr = sock.recvfrom(4096) para receber o datagrama, onde data \u00e9 o conte\u00fado recebido e addr o endere\u00e7o de quem enviou o datagrama. Neste caso, um mesmo socket \u00e9 usado para manter comunica\u00e7\u00e3o com m\u00faltiplos interlocutores. Para enviar uma resposta a um interlocutor em espec\u00edfico, addr \u00e9 usado: sent = sock.sendto(data, addr) , onde sent \u00e9 a quantidade de bytes enviados. Al\u00e9m deste detalhe, \u00e9 importante manter em mente outras caracter\u00edsticas do UDP: falta de ordem falta de confiabilidade menos dados lidos que enviados. mais dados lidos que enviados (pode acontecer tamb\u00e9m no TCP) Com tantas dificuldades para se usar o UDP, fica a quest\u00e3o: para que serve UDP?","title":"UDP"},{"location":"basics/#exercicio-ping-pong-udp","text":"Modifique o c\u00f3digo do exerc\u00edcio Ping-Pong para usar UDP em vez de TCP na comunica\u00e7\u00e3o entre n\u00f3s. Execute m\u00faltiplos clientes ao mesmo tempo. Como o seu servidor lida com isso? Modifique-o para mandar um \"eco\" da mensagem recebida de volta ao remetente.","title":"Exerc\u00edcio: Ping-Pong UDP"},{"location":"basics/#ip-multicast","text":"Imagine que voc\u00ea tenha que enviar um stream de v\u00eddeo para um destinat\u00e1rio, mostrando como voc\u00ea est\u00e1 jogando o mais novo jogo da velha no mercado. Qual protocolo de transporte voc\u00ea usaria? TCP, provavelmente, j\u00e1 que garante a entrega ordenada dos pacotes do v\u00eddeo. Como voc\u00ea j\u00e1 sabe, o TCP envia confirma\u00e7\u00f5es de pacotes recebidos e usa uma janela deslizante para determinar quais pacotes reenviar, o que pode causar interrup\u00e7\u00f5es na execu\u00e7\u00e3o do v\u00eddeo. Al\u00e9m do mais, as pessoas provavelmente preferir\u00e3o perder alguns quadros que perder a sincronia com sua excitante partida. Parece que uma op\u00e7\u00e3o melhor seria ent\u00e3o usar UDP, correto? Imagine agora que os mesmos dados devam ser enviados para m\u00faltiplos destinat\u00e1rios (voc\u00ea est\u00e1 ficando famoso!) Com m\u00faltiplos destinat\u00e1rios, m\u00faltiplos controles precisariam ser mantidos no TCP, o que pode se tornar custoso; mais uma raz\u00e3o para usar UDP! Para terminar, lhe darei uma raz\u00e3o final: IP-Multicast! Multicast, em oposi\u00e7\u00e3o ao Unicast, \u00e9 a capacidade de enviar mensagens para um grupo de destinat\u00e1rios, em vez de apenas um. IP-Multicast \u00e9 uma implementa\u00e7\u00e3o desta ideia, usando umaa configura\u00e7\u00e3o espec\u00edfica do UDP, associada a recursos dos comutadores de rede, para otimizar o envio dos mesmos dados a m\u00faltiplos destinat\u00e1rios. Grupos s\u00e3o identificados por endere\u00e7os IP especiais, conhecidos como Classe D (224.0.0.0-239.255.255.255), e propagados pela rede. Quando um pacote \u00e9 enviado para o endere\u00e7o do grupo, todos os membros do grupo recebem tal mensagem. Melhor dizendo, todos os membros podem receber a mensagem, mas como estamos falando de UDP, \u00e9 poss\u00edvel que alguns n\u00e3o recebam . Al\u00e9m disso, n\u00e3o h\u00e1 garantia qualquer sobre a ordem de recep\u00e7\u00e3o das mensagens . Apenas refor\u00e7ando, IP-Multicast s\u00f3 funciona com UDP, pois lidar com retransmiss\u00f5es em um grupo grande levaria a um estado imenso sendo mantido na origem dos dados. Outro ponto importante \u00e9 que pelo podencial desestabilizador do IP-Multicast, ele \u00e9 normalemente limitado \u00e0 pequenas se\u00e7\u00f5es das redes. Mas experimentemos com esta tecnologia na pr\u00e1tica. Criemos um programa que criar Socket UDP , associa-o a um grupo , e recebe pacotes destinados ao grupo. // MReceiver.java import java.io.*; import java.net.*; public class MReceiver { public static void main(String[] args) { byte[] inBuf = new byte[256]; try { MulticastSocket socket = new MulticastSocket(8888); InetAddress address = InetAddress.getByName(\"224.2.2.3\"); socket.joinGroup(address); while (true) { DatagramPacket inPacket = new DatagramPacket(inBuf, inBuf.length); socket.receive(inPacket); String msg = new String(inBuf, 0, inPacket.getLength()); System.out.println(\"From \" + inPacket.getAddress() + \" Msg : \" + msg); } }catch (IOException ioe) { System.out.println(ioe); } } } Instancie m\u00faltiplos processos deste, na mesma m\u00e1quina e em m\u00e1quinas distintas. Agora criemos um programa que envia pacotes para o dito grupo. // MSender.java import java.io.*; import java.net.*; public class MSender { public static void main(String[] args) { byte[] outBuf; final int PORT = 8888; try { DatagramSocket socket = new DatagramSocket(); long counter = 0; InetAddress address = InetAddress.getByName(\"224.2.2.3\"); while (true) { counter++; outBuf = (\"Multicast numero \" + counter + \" \" + address).getBytes(); DatagramPacket outPacket = new DatagramPacket(outBuf, outBuf.length, address, PORT); socket.send(outPacket); try { Thread.sleep(500); }catch (InterruptedException ie) {} } } catch (IOException ioe) { System.out.println(ioe); } } } Observe como a mesma mensagem \u00e9 recebida pelos v\u00e1rios membros e que como diferentes fontes tem seus pacotes recebidos. A t\u00edtulo de curiosidade, IP-Multicast tamb\u00e9m est\u00e1 presente em IPv6, mas com algumas pequenas diferen\u00e7as IP-Multicast em IPv6 3 In IPv6, the left-most bits of an address are used to determine its type. For a multicast address, the first 8 bits are all ones, i.e. FF00::/8. Further, bit 113-116 represent the scope of the address, which can be either one of the following 4: Global, Site-local, Link-local, Node-local. In addition to unicast and multicast, IPv6 also supports anycast, in which a packet can be sent to any member of the group, but need not be sent to all members.''","title":"IP-Multicast"},{"location":"basics/#exercicio-ip-multicast","text":"Implemente e teste o seguinte sevidor. import socket import struct MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((MCAST_GRP, MCAST_PORT)) mreq = struct.pack(\"=4sl\", socket.inet_aton(MCAST_GRP), socket.INADDR_ANY) #4 bytes (4s) seguidos de um long (l), usando ordem nativa (=) sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq) while True: print(sock.recv(10240).decode()) Implemente e teste o seguinte cliente. import socket MCAST_GRP = '224.1.1.1' MCAST_PORT = 5007 sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2) sock.sendto(input().encode(), (MCAST_GRP, MCAST_PORT))","title":"Exerc\u00edcio: IP-Multicast"},{"location":"basics/#referencias","text":"UDP em Python UDP em Python Multicast em Java Multicast em Python","title":"Refer\u00eancias"},{"location":"basics/#multiprogramacao-e-multithreading-em-sistemas-distribuidos","text":"\u00c9 imposs\u00edvel pensar em sistemas distribu\u00eddos sem pensar em concorr\u00eancia na forma de m\u00faltiplos processos executando, normalmente, em hosts distintos. De fato, os exemplos que apresentamos at\u00e9 agora consistem todos em um processo cliente requisitando a\u00e7\u00f5es de algum processo servidor. Apesar disso, a intera\u00e7\u00e3o entre tais processos aconteceu sempre de forma sincronizada, lock-step , em que o cliente requisitava o servi\u00e7o e ficava bloqueado esperando a resposta do servidor, para ent\u00e3o prosseguir em seu processamento. O servidor, de sua parte, fica bloqueado esperando requisi\u00e7\u00f5es, que atende e ent\u00e3o volta a dormir. Assim, apesar do uso de processadores distintos e da concorr\u00eancia na execu\u00e7\u00e3o dos processos, temos um baixo grau de efetivo paralelismo. Para usarmos melhor os recursos dispon\u00edveis, tanto do lado dos clientes quanto servidores, uma das raz\u00f5es de ser da computa\u00e7\u00e3o distribu\u00edda, temos ent\u00e3o que pensar em termos eventos sendo disparados entre os componentes, que devem ser tratados assim que recebidos ou t\u00e3o logo haja recursos para faz\u00ea-lo. Estes eventos correspondem tanto a requisi\u00e7\u00f5es quanto a respostas (efetivamente tornando dif\u00edcil a distin\u00e7\u00e3o). Al\u00e9m disso, sempre que poss\u00edvel, um componente n\u00e3o deve ficar exclusivamente esperando por eventos, aproveitando a chance executar outras tarefas at\u00e9 que eventos sejam recebidos. Dada que processos interagem com a rede usando sockets, cuja opera\u00e7\u00e3o de leitura \u00e9 bloqueante, para aumentar a concorr\u00eancia em um processo, precisamos falar de multi-threading. H\u00e1 duas raz\u00f5es claras para estudarmos multi-threading. A primeira, de ordem pr\u00e1tica, \u00e9 a discutida acima: permitir o desenvolvimento de componentes que utilizem \"melhormente\" os recursos em um host. A segunda, did\u00e1tica, \u00e9 o fato que muitos dos problemas que aparecem em programa\u00e7\u00e3o multi-thread, aparecem em programa\u00e7\u00e3o multi-processo (como nos sistemas distribu\u00eddos), apenas em um grau de complexidade maior. Para relembrar, h\u00e1 v\u00e1rias diferen\u00e7as entre threads e processos, mas a abstra\u00e7\u00e3o \u00e9 essencialmente a mesma: Processo Thread Inst\u00e2ncia de um programa \"Processo leve\" Estado do processo Estado do thread Fun\u00e7\u00e3o main \"qualquer\" fun\u00e7\u00e3o Mem\u00f3ria privada ao processo Compartilha estado do processo que os cont\u00e9m C\u00f3digo, Stack, Heap, descritores (e.g, file descriptors), controle de acesso Stack, vari\u00e1veis locais IPC - Inter process communication IPC -- Inter process communication Sistema operacional Diferentes implementa\u00e7\u00f5es Posix, C++, Java, ... Vejamos como o uso de m\u00faltiplos threads podem melhorar o desenvolvimento de sistemas distribu\u00eddos na pr\u00e1tica. Considere os exemplos de clientes e servidores vistos anteriormente . Imagine que em vez do servi\u00e7o simples feito no exemplo, o servidor retorne uma p\u00e1gina Web. Detalhes do protocolo seguido por navegadores e servidores ser\u00e3o vistos mais tarde. Por agora, considere apenas que uma requi\u00e7\u00e3o GET arquivo.html ser\u00e1 enviada para o servidor que ler\u00e1 o arquivo especificado do sistema de arquivos; como voc\u00ea sabe, ler um arquivo \u00e9 uma opera\u00e7\u00e3o lenta e que n\u00e3o requer CPU.","title":"Multiprograma\u00e7\u00e3o e Multithreading em Sistemas Distribu\u00eddos"},{"location":"basics/#cliente-multithreaded","text":"Do ponto de vista do cliente, a vantagem do uso de m\u00faltiplos threads s\u00e3o claras: permite lidar com v\u00e1rias tarefas concorrentemente , por exemplo solicitar CSS, HTML e imagens concorrentemente, escondendo lat\u00eancia das v\u00e1rias opera\u00e7\u00f5es, e permite organizar c\u00f3digo em blocos/m\u00f3dulos. Se voc\u00ea usar o console de desenvolvimento do navegador, ver\u00e1 que trinta e seis requisi\u00e7\u00f5es s\u00e3o feitas para carregar a p\u00e1gina www.google.com ; um n\u00famero muito maior \u00e9 feito na carga de www.bing.com .","title":"Cliente multithreaded"},{"location":"basics/#servidor-multithreaded","text":"","title":"Servidor multithreaded"},{"location":"basics/#single-threaded","text":"H\u00e1 diversas possibilidades de uso de threads em servidores. A mais simples \u00e9 usar apenas um, com temos feito at\u00e9 agora: o cliente envia a requisi\u00e7\u00e3o para o servidor o servidor aceita a conex\u00e3o em seu \u00fanico thread uma tarefa \u00e9 gerada para ler o arquivo o arquivo \u00e9 lido, de forma bloqueante, e uma resposta para o cliente \u00e9 preparada a resposta \u00e9 enviada para o cliente, de forma bloqueante a requisi\u00e7\u00e3o \u00e9 descartada o thread do servidor volta a esperar uma nova requisi\u00e7\u00e3o","title":"Single-threaded"},{"location":"basics/#thread-per-request","text":"Outra op\u00e7\u00e3o \u00e9 criar um novo thread para cada nova requisi\u00e7\u00e3o, levando a m\u00faltiplos threads atendendo a m\u00faltiplas requisi\u00e7\u00f5es concorrentemente. Desta forma, quando um thread \u00e9 bloqueado para leitura de arquivos do disco, outros clientes podem continuar sendo atendidos. Contudo, o n\u00famero de threads que se pode criar em um SO \u00e9 limitado. Al\u00e9m disso, a cria\u00e7\u00e3o e destrui\u00e7\u00e3o de threads \u00e9 cara e por isso devemos evitar este processo.","title":"Thread per request"},{"location":"basics/#thread-pool","text":"Assim, temos uma outra op\u00e7\u00e3o que tamb\u00e9m usa m\u00faltiplos threads, que usa pools de threads para lidar com as requi\u00e7\u00f5es. No cerne desta abordagem, junto com um pool de threads, fica uma fila bloquenante thread-safe , isto \u00e9, que se mantem correta mesmo quando m\u00faltiplos threads operam nela tanto para inserir quanto remover tarefas, e que bloqueia os threads que tentam inserir quando a fila est\u00e1 cheia ou remover quando ela est\u00e1 vazia. Um thread principal \u00e9 encarregado de receber as requisi\u00e7\u00f5es e colocar na fila bloqueante; se a fila fica cheia, o thread principal fica bloqueado esperando por espa\u00e7o, fazendo com que novas conex\u00f5es tenham que esperar. Os threads do pool removem uma tarefa da fila, a tratam e, ao final do atendimento, pegam nova requisi\u00e7\u00e3o na fila, em um loop infinito; se a fila se esvazia, os threads ficam bloqueados esperando novas requisi\u00e7\u00f5es. \u00c9 poss\u00edvel refinar mais este modelo, quebrando o processamento em v\u00e1rios pools, no que \u00e9 conhecido como Staged Event-Driven Architecture , SEDA. Nesta abordagem, cada est\u00e1gio , por ter seu pr\u00f3prio pool , pode ser escalado individualmente de acordo com a demanda do est\u00e1gio. Esta abordagem tamb\u00e9m \u00e9 \u00fatil quando m\u00faltiplas partes da tarefa consistem em E/S. Uma extrapola\u00e7\u00e3o que pode ser feita aqui, refor\u00e7ando a observa\u00e7\u00e3o que problemas (e solu\u00e7\u00f5es) de sistemas distribu\u00eddos s\u00e3o refletidos em n\u00edvel de processamento paralelo e concorrente, \u00e9 que a uma arquitetura SEDA lembra em muito a arquitetura de micro-servi\u00e7os . Para aprender mais sobre SEDA, v\u00e1 aqui .","title":"Thread pool"},{"location":"basics/#problemas-com-multithreading","text":"Embora a ideia de usar m\u00faltiplos threads seja resolver problemas, faz\u00ea-lo efetivamente n\u00e3o trivial. Vejamos, por exemplo, o problema de definir afinidade entre threads, isto \u00e9, de definir quais threads compartilham o mesmo estado de forma que threads afins sejam colocados nos mesmos processadores e compartilhem as mesmas mem\u00f3rias. Isto torna muito mais f\u00e1cil e eficiente o controle de concorr\u00eancia, do ponto de vista do SO e hardware. A realidade, contudo, \u00e9 outra e simplesmente criar m\u00faltiplos threads n\u00e3o garante paralelismo perfeito, pois o SO \u00e9 quem \u00e9 respons\u00e1vel por escalonar os mesmos, e \u00e9 dif\u00edcil determinar (se existir) uma configura\u00e7\u00e3o \u00f3tima em termos de afinidade que seja tamb\u00e9m eficiente. Memes bonitinhos \u00e0 parte, precisamos lidar com estado compartilhado e enfrentar condi\u00e7\u00f5es de corrida de forma a n\u00e3o levar a inconsist\u00eancias na executa\u00e7\u00e3o de tarefas, nos referindo a inconsist\u00eancia aqui como qualquer desvio no comportamento do programa daquilo que foi especificado pelo desenvolvedor. Para isso, usamos as primitivas de controle de concorr\u00eancia que estudaram em SO, que tamb\u00e9m tem seus problemas em potencial, como deadlocks e inani\u00e7\u00e3o . Veja o seguinte v\u00eddeo para uma an\u00e1lise de diversos pontos importantes no uso de multithreads.","title":"Problemas com multithreading"},{"location":"basics/#estado-em-servidores","text":"A quest\u00e3o das regi\u00f5es cr\u00edticas no servidor est\u00e1 intimamente relacionada \u00e0 quest\u00e3o da manuten\u00e7\u00e3o de estado nos servidores. Quanto a este respeito, podemos classificar servidores como stateful e stateless , dois termos que ouvir\u00e3o frequentemente enquanto trabalhando com SD. O \"state\" nos dois nomes se refere ao estado mantido por um servi\u00e7o para atender a requisi\u00e7\u00f5es. Caso mantenha estado, por exemplo informando em quais arquivos o cliente est\u00e1 interessado, fica mais f\u00e1cil para o servidor continuar o trabalho feito em requisi\u00e7\u00f5es anteriores. Imagine por exemplo que um cliente esteja acessando linhas em um banco de dados, de forma paginada: a cada requisi\u00e7\u00e3o, o cliente recebe $n$ novas linhas para processar e, quando estiver pronto, requisite $n$ novas linhas. Imagine qu\u00e3o infeficiente seria se o servidor seguisse o seguinte flxo: receba requisi\u00e7\u00e3o informando a \u00faltima linha lida re calcule todas as respostas para consulta salte at\u00e9 a linha informada pelo cliente retorne as pr\u00f3ximas $n$ linhas para o cliente feche o resultado da consulta. Se em vez disso o servidor mantiver um mapa com consultas recentes, em que a chave seja algum identificador do cliente e o valor uma vis\u00e3o dos resultados; a cada nova requisi\u00e7\u00e3o, basta o servidor preparar rapidamente uma nova resposta. Em contrapartida, considere que m\u00faltiplos clientes fazem consultas concorrentemente: quanto recurso seria necess\u00e1rio para que o servidor mantenha a vis\u00e3o de todos os clientes? Tamb\u00e9m a complexidade do servidor aumenta, uma vez que ele precisa manter as respostas a novas requisi\u00e7\u00f5es consistentes com as respostas anteriores e portanto, caso o servi\u00e7o seja implementado por m\u00faltiplos servidores acess\u00edveis ao cliente, o estado deve ser compartilhado por tais servidores. Al\u00e9m disso, imagine que o cliente resolva n\u00e3o fazer mais requisi\u00e7\u00f5es, por exemplo por ter encontrado o que procurava: por quanto tempo o servidor deve manter a vis\u00e3o aberta? Voc\u00ea j\u00e1 deve ter adivinhado que no primeiro exemplo temos um servidor stateless e no segundo um stateful , e percebido que cada um tem suas vantagens e desvantagens. Vejamos mais algumas.","title":"Estado em Servidores"},{"location":"basics/#informacao-sobre-sessao","text":"Essencialmente, o servidor stateless n\u00e3o mantem informa\u00e7\u00e3o sobre a sess\u00e3o do cliente e requer que a cada nova requisi\u00e7\u00e3o, quaisquer informa\u00e7\u00f5es necess\u00e1rias para realizar a tarefa requisitada sejam novamente fornecidas ao servidor. No caso stateful , o servidor pode se lembrar, como no exemplo anterior, at\u00e9 onde o trabalho j\u00e1 foi executado, quais arquivos o cliente manipulou (e mant\u00ea-los abertos), qual o endere\u00e7o o cliente e enviar-lhe notifica\u00e7\u00f5es importantes (e.g., \"Novo dado inserido!\").","title":"Informa\u00e7\u00e3o sobre Sess\u00e3o"},{"location":"basics/#tratamento-de-falhas","text":"Enquanto servidores stateful obviamente levam a melhor desempenho no happy path (contanto que recursos suficientes sejam providos), no caso de falhas, servi\u00e7os stateless tendem a voltar ao ar mais rapidamente, uma vez que n\u00e3o h\u00e1 estado que precise ser recuperado. Pela mesma raz\u00e3o, clientes que percebem que um servidor falhou, podem rapidamente se dirigirem a outros servidores e continuar suas requisi\u00e7\u00f5es de onde estavam, uma vez que s\u00e3o detentores de toda a informa\u00e7\u00e3o necess\u00e1ria para o pr\u00f3ximo passo do processamento. Lidar com falhas tamb\u00e9m introduz outro requisito aos servidores: mem\u00f3ria est\u00e1vel. Para que possa o recuperar o estado anterior \u00e0 falha, o servidor precisa colocar o estado em algum lugar que independa do processo para se manter, por exemplo, nvRAM , SSD ou spindles . A perda deste estado implicaria na incapacidade de prover o servi\u00e7o corretamente. Um projeto stateless n\u00e3o depende deste estado e por isso pode ser mais rapidamente recuperado, replicado ou substitu\u00eddo.","title":"Tratamento de falhas"},{"location":"basics/#qual-e-melhor","text":"N\u00e3o surpreendentemente, a resposta para \"qual abordagem \u00e9 melhor, stateful ou stateless ?\" \u00e9 depende . Ambos as op\u00e7\u00f5es tem suas vantagens e desvantagens e para algums servi\u00e7os apenas uma op\u00e7\u00e3o ser\u00e1 vi\u00e1vel. Se seu servi\u00e7o precisa manter estado (um SGBD, por exemplo), ele ter\u00e1 que manter estado, mesmo que n\u00e3o sobre clientes. Veja um pequeno comparativo das caracter\u00edsticas das duas abordagens. Stateless Stateful Resultado depende da entrada Depende do hist\u00f3rico de entradas Qualquer servidor pode atender Mesmo servidor deve atender N\u00e3o promete notificar o cliente Assina contrato com o cliente Repete opera\u00e7\u00f5es Aproveita resultados anteriores N\u00e3o fica inconsistente com rela\u00e7\u00e3o ao cliente Pode ficar inconsistente se perder estado ou conex\u00e3o feita com outro servidor re-autentica\u00e7\u00e3o (mesmo que simplficada) a cada requisi\u00e7\u00e3o Autentica no come\u00e7o da sess\u00e3o","title":"Qual \u00e9 melhor?"},{"location":"basics/#leia-mais","text":"Uma vis\u00e3o interessante sobre estado \u00e9 apresentada em On stateless software design . Observe que n\u00e3o necessariamente eu concordo com tudo o que est\u00e1 escrito aqui, principalmente a quest\u00e3o sobre stateful ser sempre mais complexo. A discrep\u00e2ncia de vis\u00e3o est\u00e1 no fato de parte da complexidade ser levada para o cliente, no caso dos servidores stateless , mas n\u00e3o necessariamente ser eliminada. Sobre IO n\u00e3o bloqueante em Java.","title":"Leia mais"},{"location":"basics/#multithread-na-pratica","text":"","title":"Multithread na pr\u00e1tica"},{"location":"basics/#pthreads","text":"POSIX Threads ou PThreads, s\u00e3o uma defini\u00e7\u00e3o aberta de como threads devem funcionar em sistemas operacionais. V\u00e1rias implementa\u00e7\u00f5es desta especifica\u00e7\u00e3o est\u00e3o dispon\u00edveis tanto para sistemas Unix, compat\u00edveis com especifi\u00e7\u00f5es POSIX, mas tamb\u00e9m para Windows, via subsistemas. Al\u00e9m disso, mesmo implementa\u00e7\u00f5es n\u00e3o POSIX tem funcionalidade equivalentes e, por este motivo, entender POSIX servir\u00e1 de base para entender quaisquer API para programa\u00e7\u00e3o multi-threaded .","title":"PThreads"},{"location":"basics/#funcao-de-entrada","text":"Para se definir um thread , \u00e9 necess\u00e1rio definir uma fun\u00e7\u00e3o de entrada, que ser\u00e1 para o thread como a fun\u00e7\u00e3o main \u00e9 para o processo em si. No exemplo a seguir a fun\u00e7\u00e3o foi definida com retorno void * e com \u00fanico par\u00e2metro tambem void * ; esta \u00e9 uma obrigatoriedade para fun\u00e7\u00f5es de entrata PThread. Observe contudo que void * pode ser tratado como um blob para mascarar outros tipos de dado, por exemplo um vetor, um enumera\u00e7\u00e3o ou uma struct . #include <stdio.h> #include <stdlib.h> #include <pthread.h> int thread_count; void* hello(void* rank) { long my_rank = (long) rank; printf(\"Hello from thread %ld of %d\\n\", my_rank, thread_count); return NULL; }","title":"Fun\u00e7\u00e3o de entrada"},{"location":"basics/#criacao","text":"Um thread \u00e9 criado pela fun\u00e7\u00e3o pthread_create , que coloca em um pthread_t um handle para o thread . A fun\u00e7\u00e3o recebe como par\u00e2metros op\u00e7\u00f5es para configura\u00e7\u00e3o, a fun\u00e7\u00e3o de entrada, e o par\u00e2metro do tipo void * . int main(int argc, char* argv[]) { long thread; pthread_t* thread_handles; if(argc < 2) { printf(\"usage: %s <number of threads>\", argv[0]); return 1; } thread_count = strtol(argv[1], NULL, 10); thread_handles = malloc(thread_count*sizeof(pthread_t)); for (thread = 0; thread < thread_count; thread++) pthread_create(&thread_handles[thread], NULL, hello, (void*) thread); printf(\"Hello from the main thread\\n\");","title":"Cria\u00e7\u00e3o"},{"location":"basics/#destruicao","text":"O handle do thread deve ser alocado previamente \u00e0 fun\u00e7\u00e3o de cria\u00e7\u00e3o e liberado ap\u00f3s o fim da execu\u00e7\u00e3o do thread . \u00c9 poss\u00edvel esperar pelo fim da execu\u00e7\u00e3o usando o pthread_join , que recebe como par\u00e2metro o handle do thread e um ponteiro para onde o resultado da fun\u00e7\u00e3o de entrada deve ser colocado, do tipo void ** . for (thread = 0; thread < thread_count; thread++) pthread_join(thread_handles[thread], NULL); free(thread_handles);","title":"Destrui\u00e7\u00e3o"},{"location":"basics/#execucao","text":"Para executar um programa PThread, compile com gcc -pthread teste.c -o teste e execute com ./teste 5 e observe que a sa\u00edda das threads \u00e9 ordenada . Agora experimente ./teste 200 Observe que a sa\u00edda \u00e9 desordenada (pode ser necess\u00e1rio executar m\u00faltiplas vezes ou aumentar de 200 para, digamos, 1000 para observar a desordem. Isto acontece porqu\u00ea a execu\u00e7\u00e3o das threads independe da ordem de cria\u00e7\u00e3o. De fato, usando PThreads, temos pouco controle sobre os threads que criamos. Mas isto n\u00e3o quer dizer que estamos \"\u00f3rf\u00e3os\" de API; v\u00e1rias outras opera\u00e7\u00f5es podem ser executadas, e podem ser encontradas a partir do manual de pthread_create . Alguns exemplos interessantes: pthread_tryjoin - espera thread terminar pthread_exit - termina a thread e retorna resultado An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function's return value serves as the thread's exit status. Manual de pthread_exit . pthread_attr_setaffinity_np * - ajusta afinidade dos threads.","title":"Execu\u00e7\u00e3o"},{"location":"basics/#threads-java","text":"Neste tutorial, baseado neste outro , exploraremos formas de se obter concorr\u00eancia em Java. Isto \u00e9, exploraremos como iniciar m\u00faltiplas linhas de execu\u00e7\u00e3o de instru\u00e7\u00f5es, que podem ou n\u00e3o, ser executadas em paralelo. Em Java, h\u00e1 essencialmente duas formas de se conseguir concorr\u00eancia. A primeira \u00e9 via inst\u00e2ncias expl\u00edcitas da classe Thread , e a segunda \u00e9 via abstra\u00e7\u00f5es de mais alto n\u00edvel, os Executors . Thread Executor Al\u00e9m de formas de definir as linhas de execu\u00e7\u00e3o, Java prov\u00ea diversas estruturas para comunica\u00e7\u00e3o e coordena\u00e7\u00e3o destas linhas, desde de a vers\u00e3o 5 da linguagem, no pacote java.util.concurrent .","title":"Threads Java"},{"location":"basics/#criacao-de-threads-java","text":"H\u00e1 duas formas b\u00e1sicas de se usar a classe Thread , via extens\u00e3o ou delega\u00e7\u00e3o de um objeto implementando Runnable .","title":"Cria\u00e7\u00e3o de Threads Java"},{"location":"basics/#extender-thread","text":"public class HelloThread extends Thread { public void run() { System.out.println(\"Hello from a thread!\"); } public static void main(String args[]) { Thread t = new HelloThread(); t.start(); } }","title":"Extender Thread"},{"location":"basics/#implementar-runnable","text":"public class HelloRunnable implements Runnable { public void run() { System.out.println(\"Hello from a thread!\"); } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); t.start(); } } Observe que nos dois exemplos, um m\u00e9todo run() \u00e9 implementado com o c\u00f3digo a ser executado pelo thread . Em nenhum dos exemplos, contudo, o m\u00e9todo \u00e9 invocado diretamente. Em vez disto, o m\u00e9todo start() , sim, \u00e9 invocado. Isto ocorre pq antes de executar as instru\u00e7\u00f5es definidas pelo pelo programador no m\u00e9todo run() , a m\u00e1quina virtual precisa executar alguma \"m\u00e1gica\" por baixo dos panos como, por exemplo, solicitar ao sistema operacional a cria\u00e7\u00e3o de um thread do SO, que servir\u00e1 de hospedeiro para o thread Java. Isto acontece dentro do start() , que em algum ponto de sua execu\u00e7\u00e3o levar\u00e1 \u00e0 invoca\u00e7\u00e3o do m\u00e9todo run() .","title":"Implementar Runnable"},{"location":"basics/#api-thread","text":"A classe Thread tamb\u00e9m prov\u00ea uma s\u00e9rie de m\u00e9todos que permitem gerenciar a vida do thread criado. Por exemplo, o m\u00e9todo de classe ( static ) Thread.sleep() permite bloquear um thread por um determinado per\u00edodo.","title":"API Thread"},{"location":"basics/#threadsleep","text":"public class HelloRunnable implements Runnable { public void run() { for (int i = 0; i < 10; i ++) { System.out.println(\"Hello at instant \" + i); try { Thread.sleep(1000); } catch (InterruptedException ie) { System.out.println(\"awoken\"); } } } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); t.start(); } } Observe que a chamada a sleep() est\u00e1 dentro de um bloco try/catch . Isto \u00e9 necess\u00e1rio pois \u00e9 permitido \u00e0 JVM acordar o thread em qualquer instante, antes ou ap\u00f3s o tempo especificado. Assim, embora normalmente o tempo \"dormido\" seja pr\u00f3ximo ao especificado, se h\u00e1 requisitos de precis\u00e3o, \u00e9 necess\u00e1rio que o thread , ao acordar, verifique se j\u00e1 dormiu o suficiente.","title":"Thread.sleep()"},{"location":"basics/#interruptedexception","text":"public class HelloRunnable implements Runnable { public void run() { for (int i = 0; i < 10; i ++) { System.out.println(\"Hello at instant \" + i); long before = System.currentTimeMillis(); long timeout = 1000; while(before + timeout > System.currentTimeMillis()) { try { Thread.sleep(Math.max(0,System.currentTimeMillis() - (before + timeout))); } catch (InterruptedException ie) { System.out.println(\"awoken\"); } } } } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); t.start(); } } Quando um thread est\u00e1 sendo executado, outros podem ter que esperar at\u00e9 que complete. Por exemplo, no caso de um navegador Web, o thread que faz a renderiza\u00e7\u00e3o da p\u00e1gina n\u00e3o pode come\u00e7ar a trabalhar enquanto o thread que solicitou o HTML do servidor n\u00e3o receber sua resposta. Um thread indica a inten\u00e7\u00e3o de esperar por outro usando o m\u00e9todo join() .","title":"InterruptedException"},{"location":"basics/#threadjoin","text":"public class HelloRunnable implements Runnable { public void run() { Random rand = new Random(); for (int i = 0; i < 10; i ++) { System.out.println(\"Hello at instant \" + i); long before = System.currentTimeMillis(); long timeout = 901 + rand.nextInt(200); while(before + timeout > System.currentTimeMillis()) { try { Thread.sleep(Math.max(0,System.currentTimeMillis() - (before + timeout))); } catch (InterruptedException ie) { System.out.println(\"awoken\"); } } } } public static void main(String args[]) { Thread t = new Thread(new HelloRunnable()); //t.setDaemon(true); t.start(); try { t.join(); //t.join(10000); } catch (InterruptedException ie) { System.out.println(\"Waiting was interrupted\"); } if (t.isAlive()) System.out.println(\"Got tired of waiting\"); else System.out.println(\"Wait is over\"); } } Invocar t.join() far\u00e1 com que o thread principal espere indefinidamente at\u00e9 que t termine de executar. Caso seja necess\u00e1rio limitar o tempo de espera, o tempo pode ser especificado como na linha comentada. Caso a espera termine por causa de um timeout , \u00e9 poss\u00edvel testar o estado atual do thread com Thread.isAlive() . Outro m\u00e9todo interessante, Thread.setDaemon() , especifica que o thread pode ser terminado quando a thread principal terminar. Descomente a invoca\u00e7\u00e3o e teste o efeito.","title":"Thread.join()"},{"location":"basics/#exercicio","text":"Vejamos um exemplo simples do uso de threads . Instancie um programa que gere 10 threads . Todos os threads devem compartilhar uma mesma inst\u00e2ncia de Counter Cada thread deve executar um loop em que incrementa o valor do contador 20 vezes a cada vez, imprime o resultado precedido do identificador do thread (use Thread.getName() ou Thread.currentThread().getName() ) A thread principal deve esperar todas as outras terminarem antes de terminar (use Thread.join() ). Analise a sa\u00edda do programa observando a ordem de execu\u00e7\u00e3o dos threads .","title":"Exerc\u00edcio"},{"location":"basics/#counterjava","text":"class Counter { private int c = 0; public int increment() { return ++c; } public int decrement() { return --c; } public int value() { return c; } } \u00c9 f\u00e1cil observar que a sa\u00edda do programa \u00e9 aleat\u00f3ria nos identificadores e tende a ser incremental nos contadores, mas nem sempre isso \u00e9 verdade. Como discutido anteriormente, frequentemente threads tem que coordenar suas a\u00e7\u00f5es para que n\u00e3o pisem uns nos outros, por exemplo decidindo quem deve ser o pr\u00f3ximo a entrar em uma regi\u00e3o cr\u00edtica ou ser\u00e1 o respons\u00e1vel por uma tarefa. Em Java, esta coordena\u00e7\u00e3o pode ser feita por diversas abstra\u00e7\u00f5es: synchronized , Lock , vari\u00e1veis at\u00f4micas, ...","title":"Counter.java"},{"location":"basics/#synchronized","text":"Ao definir m\u00e9todos como synchronized , garante-se que os mesmos nunca ser\u00e3o executados concorrentemente. Observe a classe a seguir, que modifica o contador do exerc\u00edcio anterior. public class SynchronizedCounter { private int c = 0; public synchronized int increment() { return ++c; } public synchronized int decrement() { return --c; } public synchronized int value() { return c; } } Caso dois threads invoquem os m\u00e9todos increment e decrement ao mesmo tempo, por exemplo, a JVM far\u00e1 com que um dos threads pare sua execu\u00e7\u00e3o at\u00e9 que o outro tenha completado a invoca\u00e7\u00e3o. Isto n\u00e3o quer dizer que executar o exerc\u00edcio anterior com esta vers\u00e3o do contador n\u00e3o levar\u00e1 a sa\u00eddas com incrementos completamente sequenciais, pois um thread poderia parar de ser executado logo ap\u00f3s incrementar o contador, depois de terminado o m\u00e9todo increment , e s\u00f3 voltar a executar depois que outro tenha incrementado e impresso na tela o valor obtido. O que quer dizer \u00e9 que, mesmo que sa\u00eddas estranhas existam, cada opera\u00e7\u00e3o foi executada integralmente antes da opera\u00e7\u00e3o seguinte.","title":"synchronized"},{"location":"basics/#exercicio_1","text":"Modifique o c\u00f3digo do exerc\u00edcio anterior para usar a vers\u00e3o synchronized do contador. Depois de execut\u00e1-lo, adicione um println(\"Dentro: \" + c) dentro do m\u00e9todo de incremento para verificar que estas sa\u00eddas acontecem ordenadamente.","title":"Exerc\u00edcio"},{"location":"basics/#blocos-synchronized","text":"synchronized funciona porqu\u00ea limita a concorr\u00eancia, e \u00e9 problem\u00e1tico exatamente pela mesma raz\u00e3o. Por isso, \u00e9 essencial que o synchronized seja o mais limitado poss\u00edvel em termos de escopo, o que nos leva ao uso de synchronized em blocos de c\u00f3digo menores que m\u00e9todos. Por exemplo: public class Namer { String lastName = null; int nameCount = 0; public void addName(String name) { lastName = name; synchronized(this) { nameCount++; } nameList.add(name); } } Neste caso, blocos sincronizados no mesmo objeto , n\u00e3o s\u00e3o executados concorrentemente, mas outros blocos sim.","title":"Blocos synchronized"},{"location":"basics/#exercicio_2","text":"Neste exerc\u00edcio, use dois objetos para travar o acesso a dois contadores. Instancie um programa com dois threads tal que: * executem um loop 1000 vezes em que * o primeiro thread primeiro invoca inc1 e depois inc2 * o segundo thread primeiro invoca inc2 e depois inc1 * ambos os threads imprimem o valor de c1 e c2","title":"Exerc\u00edcio"},{"location":"basics/#synchronized_1","text":"public class MsLunch { private long c1 = 0; private long c2 = 0; private Object lock1 = new Object(); private Object lock2 = new Object(); public void inc1() { synchronized(lock1) { c1++; } } public void inc2() { synchronized(lock2) { c2++; } } }","title":"synchronized"},{"location":"basics/#deadlock","text":"O uso dos \"locks\" em ordens diferentes pode levar a um deadlock, pois o seguinte grafo de depend\u00eancia poder\u00e1 ser gerado:","title":"Deadlock"},{"location":"basics/#deadlock_1","text":"graph LR T1 --> lock1 T2 --> lock2 lock1 --> T2 lock2 --> T1","title":"Deadlock"},{"location":"basics/#sinalizacao","text":"Usados corretamente, o bloco synchronized \u00e9 executado de forma at\u00f4mica, isto \u00e9, indivis\u00edvel. Algumas opera\u00e7\u00f5es muito simples s\u00e3o naturalmente at\u00f4micas, e n\u00e3o precisam ser \"protegidas\" pelo synchronized . Por exemplo, leituras e escritas de tipos b\u00e1sicos como ( int , char , byte , mas n\u00e3o long ou double ), ou vari\u00e1veis declaradas volatile . Usando estas vari\u00e1veis, \u00e9 poss\u00edvel coordenar threads , por exemplo, assim:","title":"Sinaliza\u00e7\u00e3o"},{"location":"basics/#espera-ocupada","text":"boolean condicao = false; ... public void espereCondicao() { while(!condicao) {} System.out.println(\"condicao alcancada.\"); } ... public void satisfacaCondicao() { condicao = true; } Embora correto, esta abordagem n\u00e3o \u00e9 eficiente, pois o primeiro m\u00e9todo desperdi\u00e7a computa\u00e7\u00e3o. Felizmente, em Java, todos os objetos implementam os m\u00e9todos wait e notify/notifyAll , que podem ser usados para sincronizar eficientemente threads .","title":"Espera ocupada"},{"location":"basics/#waitnotify","text":"public class Sync{ Object synch = new Object(); boolean condicao = false; public void espereCondicao() { while(!condicao) { try { synch.wait(); } catch (InterruptedException e) {} } System.out.println(\"Condicao alcancada\"); } ... public void satisfacaCondicao() { condicao = true; synch.notifyAll(); } }","title":"Wait/Notify"},{"location":"basics/#locks","text":"Outras abstra\u00e7\u00f5es para coordena\u00e7\u00e3o de threads est\u00e3o dispon\u00edveis no pacote java.util.concurrent . As mais simples delas s\u00e3o java.util.concurrent.locks.Lock e java.util.concurrent.locks.ReentrantLock . Veja um exemplo de uso, notando o idioma de uso dentro de block try/catch . Lock l = new ReentrantLock(); l.lock(); try { // access the resource protected by this lock } finally { l.unlock(); }","title":"Locks"},{"location":"basics/#executor","text":"Al\u00e9m de threads , Java disponibiliza Executor como abstra\u00e7\u00e3o de mais alto n\u00edvel para execu\u00e7\u00e3o de tarefas concorrentes. Executor ExecutorService ScheduledExecutorService Executor e = ...; Runnable r = ...; e.execute(r); Executors normalmente implementam thread pools , que podem ser de diferentes tipos. O mais simples \u00e9 o de tamanho fixo em que h\u00e1 um n\u00famero inicial de threads criados e que, no caso de algum ser terminado, por exemplo por causa de uma exce\u00e7\u00e3o n\u00e3o tratada, cria substitutos para manter o n\u00famero constante.","title":"Executor"},{"location":"basics/#threadpool","text":"Executor e = java.util.concurrent.Executors.newFixedThreadPool(); newCachedThreadPool() - expandable thread pool newSingleThreadExecutor() - single task at a time e outras vers\u00f5es ForkJoinPool","title":"ThreadPool"},{"location":"basics/#forkjoin","text":"if (my portion of the work is small enough) do the work directly else split my work into two pieces invoke the two pieces and wait for the results","title":"Fork/Join"},{"location":"basics/#estrutura-para-coordenacao-de-threads","text":"Finalmente, Java tamb\u00e9m disponibiliza estruturas de dados que podem ser acessadas concorrentemente por m\u00faltiplos threads sem risco de corrup\u00e7\u00e3o. BlockingQueue - bloquei threads se n\u00e3o houver elementos na filq. ConcurrentMap/ConcurrentHashMap - opera\u00e7\u00f5es at\u00f4micas; if (!m.containsKey(k)) m.put(k,v); vOld = m.putIfAbsent(k,v);","title":"Estrutura para Coordena\u00e7\u00e3o de Threads"},{"location":"basics/#tipos-atomicos","text":"import java.util.concurrent.atomic.AtomicInteger; class AtomicCounter { private AtomicInteger c = new AtomicInteger(0); public void increment() { c.incrementAndGet(); } public void decrement() { c.decrementAndGet(); } public int value() { return c.get(); } }","title":"Tipos At\u00f4micos"},{"location":"basics/#threadlocal","text":"private static ThreadLocal<Integer> myId = new ThreadLocal<Integer>() { public Integer initialValue() { return new Random().nexInt(); } }; public static Integer getMyId() { return myId.get(); }","title":"ThreadLocal"},{"location":"basics/#leia-mais_1","text":"Para aprender mais, muito mais sobre concorr\u00eancia em Java, \u00f3timas refer\u00eancias s\u00e3o: Java Concurrency in Practice The Well-Grounded Java Developer Concorr\u00eancia em Java Futures e Promises Locks Tipos At\u00f4micos","title":"Leia mais"},{"location":"basics/#threads-em-python","text":"Em Python, como seria de se esperar, h\u00e1 v\u00e1rias formas de se trabalhar com threads . A seguir s\u00e3o apresentados dois exemplos, usando o pacote thread ou threading . #!/usr/bin/python import thread import time # Define a function for the thread def print_time( threadName, delay): count = 0 while count < 5: time.sleep(delay) count += 1 print \"%s: %s\" % ( threadName, time.ctime(time.time()) ) # Create two threads as follows try: thread.start_new_thread( print_time, (\"Thread-1\", 2, ) ) thread.start_new_thread( print_time, (\"Thread-2\", 4, ) ) except: print \"Error: unable to start thread\" while True: pass Ou #!/usr/bin/python import threading import time exitFlag = 0 class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print \"Starting \" + self.name print_time(self.name, self.counter, 5) print \"Exiting \" + self.name def print_time(threadName, counter, delay): while counter: if exitFlag: threadName.exit() time.sleep(delay) print \"%s: %s\" % (threadName, time.ctime(time.time())) counter -= 1 # Create new threads thread1 = myThread(1, \"Thread-1\", 1) thread2 = myThread(2, \"Thread-2\", 2) # Start new Threads thread1.start() thread2.start() print \"Exiting Main Thread\"","title":"Threads em Python"},{"location":"basics/#leia-mais_2","text":"Threads em Python","title":"Leia mais"},{"location":"basics/#exercicio-anel-multithread","text":"Usando uma linguagem de alto-n\u00edvel como C/C++/Java, escrever um programa que crie 30 threads e fa\u00e7a com que uma mensagem circule entre os mesmos. A mensagem \u00e9 uma string aleat\u00f3ria de pelo menos 80 caracteres. A cada vez que um thread recebe a mensagem ele a imprime, modifica o primeiro caractere min\u00fasculo para mai\u00fasculo, caso exista, dorme por 1 segundo, e repassa a mensagem. Quando todos os caracteres forem mai\u00fasculos, o processo repassa a mensagem e ent\u00e3o termina. Antes de terminar, o processo deve imprimir a mensagem resultante. Endere\u00e7os IP n\u00e3o p\u00fablicos n\u00e3o server como identificadores \u00fanicos na Internet. \u21a9 Se o segundo comando n\u00e3o funcionar, tente nc em vez de netcat . \u21a9 IP-Multicast em IPv6 \u21a9","title":"Exerc\u00edcio - Anel Multithread"},{"location":"comm/","text":"Communica\u00e7\u00e3o O desenvolvimento de sistemas distribu\u00eddos usando diretamente Sockets como forma de comunica\u00e7\u00e3o entre componentes n\u00e3o \u00e9 para os fracos de cora\u00e7\u00e3o. Sua grande vantagem est\u00e1 no acesso baixo n\u00edvel \u00e0 rede , e todo o ganho de desempenho que isso pode trazer. Suas desvantagens, entretanto, s\u00e3o v\u00e1rias: interface de \"arquivo\" para se ler e escrever bytes; controle de fluxo de \"objetos\" \u00e9 por conta da aplica\u00e7\u00e3o, isto \u00e9, a aplica\u00e7\u00e3o precisa sinalizar quantos bytes ser\u00e3o escritos de um lado, para que o outro saiba quanto ler para obter um \"objeto\" correto; logo, a serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o de objetos \u00e9 tamb\u00e9m por conta da aplica\u00e7\u00e3o; tratamento de desconex\u00f5es e eventuais reconex\u00f5es tamb\u00e9m \u00e9 gerenciado pela aplica\u00e7\u00e3o e nem a t\u00e3o famosa confiabilidade do TCP ajuda. Enquanto se poderia argumentar que algumas destas desvantagens podem ser descartadas em fun\u00e7\u00e3o da discuss\u00e3o de incluir ou n\u00e3o API na comunica\u00e7\u00e3o fim-a-fim , \u00e9 certo que algumas funcionalidades s\u00e3o ub\u00edquas em aplica\u00e7\u00f5es distribu\u00eddas. Aqui discutiremos algumas destas funcionalidades e como podem e s\u00e3o implementadas por frameworks de comunica\u00e7\u00e3o de mais alto n\u00edvel. Representa\u00e7\u00e3o de dados Exceto por aplica\u00e7\u00f5es muito simples, processos em um sistema distribu\u00eddos trocam dados complexos, por exemplo estruturas ou classes com diversos campos, incluindo valores num\u00e9ricos de diversos tipos, strings e vetores de bytes, com diversos n\u00edveis de aninhamento e somando v\u00e1rios KB. Neste cen\u00e1rio, v\u00e1rios fatores precisam ser levados em considera\u00e7\u00e3o na hora de colocar esta estrutura no fio , por exemplo: Diferentes linguagens de programa\u00e7\u00e3o usadas para desenvolver os componentes. tipos com defini\u00e7\u00e3o imprecisa, por exemplo \"inteiro\": 8: 16, 32, 64 ou bits? paradigmas distintos: classe x estrutura conjunto de caracteres diferentes: ASCII x UTF Arquiteturas diferentes. ordem dos bytes little endian? x64 IA-32 big endian? IP SPARC (< V9) Motorola PowerPC bi-endian? ARM, MIPS, IA-64 representa\u00e7\u00e3o de ponto flutuante alinhamento de bytes Sistemas operacionais diferentes crlf (DOS) x lf (Unix) fragmenta\u00e7\u00e3o Representa\u00e7\u00e3o Textual Uma abordagem comumente usada \u00e9 a representa\u00e7\u00e3o em formato textual \"amig\u00e1vel a humanos\". Veja o exemplo de como o protocolo HTTP requisita e recebe uma p\u00e1gina HTML. telnet www.google.com 80 Trying 187.72.192.217... Connected to www.google.com. Escape character is '^]'. GET / HTTP/1.1 host: www.google.com As linhas 5 e 6 s\u00e3o entradas pelo cliente para requisitar a p\u00e1gina raiz do s\u00edtio www.google.com . A linha 7, vazia, indica ao servidor que a requisi\u00e7\u00e3o est\u00e1 terminada. Em resposta a esta requisi\u00e7\u00e3o, o servidor envia o seguinte, em que as primeiras linhas trazem metadados da p\u00e1gina requisitada e, ap\u00f3s a linha em branco, vem a resposta em HTML \u00e0 requisi\u00e7\u00e3o. HTTP/1.1 302 Found Location: http://www.google.com.br/?gws_rd=cr&ei=HTDqWJ3BDYe-wATs_a3ACA Cache-Control: private Content-Type: text/html; charset=UTF-8 P3P: CP=\"This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info.\" Date: Sun, 09 Apr 2017 12:59:09 GMT Server: gws Content-Length: 262 X-XSS-Protection: 1; mode=block X-Frame-Options: SAMEORIGIN Set-Cookie: NID=100=NB_AruuFWL0hXk2-h7VDduHO_UkjAr6RaqgG7VbccTsfLzFfhxEKx21Xpa2EH7IgshgczE9vU4W1TyKsa07wQeuZosl5DbyZluR1ViDRf0C-5lRpd9cCpCD5JXXjy-UE; expires=Mon, 09-Oct-2017 12:59:09 GMT; path=/; domain=.google.com; HttpOnly <HTML><HEAD><meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\"> <TITLE>302 Moved</TITLE></HEAD><BODY> <H1>302 Moved</H1> The document has moved <A HREF=\"http://www.google.com.br/?gws_rd=cr&amp;ei=HTDqWJ3BDYe-wATs_a3ACA\">here</A>. </BODY></HTML> Representa\u00e7\u00f5es textuais s\u00e3o usadas em diversos protocolos como SMTP, POP, e telnet. Algumas destas representa\u00e7\u00f5es seguem padr\u00f5es formalizados, o que facilita a gera\u00e7\u00e3o e interpreta\u00e7\u00e3o dos dados. Dois padr\u00f5es bem conhecidas s\u00e3o XML e JSON. XML \u00e9 o acr\u00f4nimo para Extensible Markup Language , ou seja, uma linguagem marca\u00e7\u00e3o que pode ser estendida para representar diferentes tipos de informa\u00e7\u00e3o. A HTML, por exemplo, \u00e9 uma inst\u00e2ncia de XML destinada \u00e0 representa\u00e7\u00e3o de hipertexto (A bem da verdade, XML foi uma generaliza\u00e7\u00e3o de HTML). Por exemplo, para representarmos os dados relativos \u00e0 uma pessoa, podemos ter uma inst\u00e2ncia XML assim: <person> <name>John Doe</name> <id>112234556</id> <email>jdoe@example.com</email> <telephones> <telephone type=\"mobile\">123 321 123</telephone> <telephone type=\"home\">321 123 321</telephone> </telephones> </person> Uma das grandes vantagens do uso de XML \u00e9 a possibilidade de se formalizar o que pode ou n\u00e3o estar em um arquivo para um certo dom\u00ednio utilizando um XML Domain Object Model . H\u00e1, por exemplo, modelos para representa\u00e7\u00e3o de documentos de texto, governos eletr\u00f4nicos, representa\u00e7\u00e3o de conhecimento, etc . Sua maior desvantagem \u00e9 que \u00e9 muito verborr\u00e1gico e por vezes complicado de se usar, abrindo alas para o seu mais famoso concorrente, JSON. JSON \u00e9 o acr\u00f4nimo de Javascript Object Notation , isto \u00e9, o formato para representa\u00e7\u00e3o de objetos da linguagem Javascript. Devido \u00e0 sua simplicidade e versatilidade, entretanto, foi adotado como forma de representa\u00e7\u00e3o de dados em sistemas desenvolvidos nas mais diferentes linguagens. O mesmo exemplo visto anteriormente, em XML, \u00e9 representado em JSON assim: { \"name\": \"John Doe\", \"id\": 112234556, \"email\": \"jdoe@example.com\", \"telephones\": [ { \"type\": \"mobile\", \"number\": \"123 321 123\"}, { \"type\": \"home\", \"number\": \"321 123 321\"}, ] } Em Python, por exemplo, JSON s\u00e3o gerados e interpretados nativamente, sem a necessidade de frameworks externos, facilitando seu uso. Mas de fato, a op\u00e7\u00e3o final por XML ou JSON \u00e9 quest\u00e3o de prefer\u00eancia, uma vez que os dois formatos s\u00e3o, de fato, equivalentes na quest\u00e3o da representa\u00e7\u00e3o de informa\u00e7\u00e3o. Outros formatos, bin\u00e1rios, oferecem vantagens no uso de espa\u00e7o para armazenar e transmitir dados, e por isso s\u00e3o frequentemente usados como forma de serializa\u00e7\u00e3o de dados em sistemas distribu\u00eddos, isto \u00e9, na transforma\u00e7\u00e3o de TAD para sequ\u00eancias de bytes que seguir\u00e3o \"no fio\". ASN.1 (Abstract Syntax Notation), pela ISO XDR (eXternal Data Representation) Java serialization Google Protocol Buffers Thrift ASN.1 e XDR s\u00e3o de interesse hist\u00f3rico, mas n\u00e3o os discutiremos aqui. Quanto \u00e0 serializa\u00e7\u00e3o feita nativamente pelo Java, por meio de ObjectOutputStreams , como neste exemplo , embora seja tentadora para quem usa Java, \u00e9 necess\u00e1rio saber que ela \u00e9 restrita \u00e0 JVM e que usa muito espa\u00e7o, embora minimize riscos de uma desserializa\u00e7\u00e3o para uma classe diferente. Nos foquemos nas autras alternativas listadas, ProtoBuffers e Thrift, que podem levar a representa\u00e7\u00f5es bin\u00e1rias e textuais. ProtoBuffers Nas palavras dos criadores , Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Por meio de protobuffers, \u00e9 poss\u00edvel estruturar dados e gerar o c\u00f3digo correspondente em diversas linguagens, for forma compartilh\u00e1vel entre as mesmas. Veja o exemplo a seguir, que especifica os dados referentes a uma pessoa. Observe a presen\u00e7a de campos de preenchimento opcional ( optional ), de enumera\u00e7\u00f5es ( enum ), e de cole\u00e7\u00f5es ( repeated ). message Person { required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { required string number = 1; optional PhoneType type = 2 [default = HOME]; } repeated PhoneNumber phone = 4; } Com tal defini\u00e7\u00e3o \u00e9 poss\u00edvel gerar c\u00f3digo como o seguinte, em C++, que serializa os dados para escrita em um arquivo... Person person; person.set_name(\"John Doe\"); person.set_id(1234); person.set_email(\"jdoe@example.com\"); fstream output(\"myfile\", ios::out | ios::binary); person.SerializeToOstream(&output); e l\u00ea do arquivo e desserializa para hidratar um novo objeto. fstream input(\"myfile\", ios::in | ios::binary); Person person; person.ParseFromIstream(&input); cout << \"Name: \" << person.name() << endl; cout << \"E-mail: \" << person.email() << endl; De acordo com benchmarks do pr\u00f3prio projeto , a opera\u00e7\u00e3o em XML seria mais \u00f3rdens de grandeza mais lenta e ocuparia mais espa\u00e7o. When this message is encoded to the protocol buffer binary format, it would probably be 28 bytes long and take around 100-200 nanoseconds to parse. The XML version is at least 69 bytes if you remove whitespace, and would take around 5,000-10,000 nanoseconds to parse. Thrift TODO Invoca\u00e7\u00e3o Remota de Procedimentos - RPC Em 1984, Birrel e Nelson 1 introduziram o mecanismo de Invoca\u00e7\u00e3o Remota de Procedimentos ( Remote Procedure Calls ), que permite que processos fa\u00e7am, pasmem, invoca\u00e7\u00f5es de procedimentos remotos! \u00d3bvio, a inova\u00e7\u00e3o n\u00e3o est\u00e1 na capacidade de uma m\u00e1quina conversar com outra, mas em como esta conversa acontece, do ponto de vista do programador. Por exemplo, RPC permita que se procure a substring \"teste\" dentro da string apontada por a , a partir da posi\u00e7\u00e3o 3, usando x = substring(a,3,\"teste\"); , mas com o invocador da fun\u00e7\u00e3o em um processo e a implementa\u00e7\u00e3o da fun\u00e7\u00e3o propriamente dita, em outro, possivelmente em outra m\u00e1quina. Stubs Antes de nos aprofundarmos, vejamos como uma invoca\u00e7\u00e3o de fun\u00e7\u00f5es acontece normalmente dentro de um \u00fanico processo 2 . O c\u00f3digo x = substring(a,3,\"teste\"); , que procura \"teste\" em *a , \u00e9 traduzido nos seguintes passos em linguagem de m\u00e1quina: coloque o endere\u00e7o de \"teste\" na pilha coloque 3 na pilha coloque o valor de a na pilha coloque o endere\u00e7o de retorno na pilha (junto com outros dados de controle) salte para substring ajustando o instruction pointer ... procure substring ... coloque o resultado no acumulador limpe a pilha salte de volta recuperando o endere\u00e7o de retorno da pilha e ajustando o IP coloque resultado em x Se o que queremos \u00e9 colocar o c\u00f3digo da fun\u00e7\u00e3o substring em um outro processo e execut\u00e1-lo como se estiv\u00e9ssemos no mesmo processo que faz a invoca\u00e7\u00e3o, precisamos pensar em v\u00e1rias quest\u00f5es relativas ao fluxo mostrado acima. Claramente n\u00e3o podemos usar o mesmo fluxo para invocar uma fun\u00e7\u00e3o, mas precisamos de c\u00f3digo de simule a invoca\u00e7\u00e3o local mas que, por baixo do cap\u00f4, use sockets para se comunicar com o processo remoto. Estq simula\u00e7\u00e3o usar\u00e1 c\u00f3digo extra, que finge implementar substring para o invocador mas delega ao c\u00f3digo remoto o trabalho real da busca. Este c\u00f3digo extra \u00e9 conhecido como stub , ou para ser mais preciso, stub cliente , que faz parte do processo invocando a opera\u00e7\u00e3o, e stub servidor, que faz parte do processo executando a opera\u00e7\u00e3o invocada 3 . Assim, o cliente invoca fun\u00e7\u00e3o no stub cliente, achando que \u00e9 a fun\u00e7\u00e3o que quer executar. Stub cliente faz o marshaling 4 dos par\u00e2metros e usa o SO para transferir os dados via rede para o stub servidor. Quando recebe a resposta do servidor, o stub cliente retorna a mesma resposta, como se tivesse calculado localmente. Stub cliente Implementa uma fun\u00e7\u00e3o substring(char*, int, char*) que abre socket para servidor envia par\u00e2metros especifica fun\u00e7\u00e3o espera resposta retorna resultado J\u00e1 o stub servidor fica esperando o contato do cliente. Quando acontece, faz o \"unmarshalling\" dos dados, invoca a fun\u00e7\u00e3o localmente na aplica\u00e7\u00e3o servidor e pega o resultado, que retona ao cliente. Stub servidor espera conex\u00e3o recebe par\u00e2metros recebe especifica\u00e7\u00e3o da fun\u00e7\u00e3o invoca fun\u00e7\u00e3o localmente envia resultado para cliente Transpar\u00eancia \u00c9 para o programador a grande vantagem do uso de RPC, pois se pode escrever c\u00f3digo distribu\u00eddo \"igual\" ao centralizado, certo? Isto \u00e9, interface baseada em procedimentos e sem a necessidade de detalhar portas, sockets, e representa\u00e7\u00e3o de dados . Ou seja, tudo \u00e9 transparente! Como j\u00e1 discutimos, v\u00e1rios fatores trabalham contra a transpar\u00eancia em sistemas distribu\u00eddos . Em espec\u00edfico quanto \u00e0 transpar\u00eancia dada pelo RPC, tamb\u00e9m temos limita\u00e7\u00f5es. O problema \u00e9 que h\u00e1 uma distin\u00e7\u00e3o clara em pelo menos dois processos e se pensarmos no c\u00f3digo descrito acima, temos que entender que processos independentes n\u00e3o compartilham um espa\u00e7o de endere\u00e7amento, e processos independentes n\u00e3o compartilham uma pilha. Assim, como fica a passagem de par\u00e2metro por refer\u00eancia , uma vez que o stub servidor n\u00e3o pode usar endere\u00e7os do espa\u00e7o de endere\u00e7amento do cliente? Algumas abordagens para simular a passagem por refer\u00eancia s\u00e3o poss\u00edveis. Por exemplo, o valor apontado pelo ponteiro \u00e9 passado para o servidor , que armazena o valor e alguma posi\u00e7\u00e3o de mem\u00f3ria e passa o endere\u00e7o de tal posi\u00e7\u00e3o para a fun\u00e7\u00e3o invocada. Contudo, a modifica\u00e7\u00e3o do valor pela fun\u00e7\u00e3o n\u00e3o reflete imediatamente no invocador; tais valores tem que ser copiados novamente e usados para sobrescrever o valor original no cliente. Al\u00e9m disso, esta abordagem s\u00f3 \u00e9 poss\u00edvel se o valor apontado for delimitado, o que nem sempre \u00e9 f\u00e1cil de determinar. Por exemplo, se o ponteiro for para o primeiro elemento de uma lista, o que deve ser copiado para o servidor? S\u00f3 o primeiro elemento? Toda a lista? Como ensinar para o framework RPC o que \u00e9 \"toda\" a lista? Java \"resolve\" o problema da passagem de par\u00e2metro por refer\u00eancia passando todo o grafo do objeto passado como par\u00e2metro para o servidor. Isto \u00e9, al\u00e9m de serializar o objeto apontado no par\u00e2metro, se o mesmo aponta para outros objetos, estes tamb\u00e9m ser\u00e3o serializados e transferidos; o servidor ir\u00e1 ent\u00e3o reconstruir todo o grafo e passar para o m\u00e9todo sendo invocado. \u00c9 muito f\u00e1cil ver que esta abordagem pode se tornar invi\u00e1vel rapidamente. Quando for o caso, Java permite marcar objetos como remotos e, em vez de serializar este objeto e enviar para o servidor, envia informa\u00e7\u00e3o suficiente para que o servidor possa invocar m\u00e9todos em tal objeto no cliente, tornando nebulosa a defini\u00e7\u00e3o de quem \u00e9 quem. Outros fatores tamb\u00e9m trabalham contra a transpar\u00eancia para o desenvolvedor. Vejamos alguns Descoberta de Servi\u00e7os Por exemplo, mesmo que o socket seja ocultado, ele ainda existe e precisa de informa\u00e7\u00f5es sobre onde se conectar (endere\u00e7o e porta), que de alguma forma deve ser passada para o framework de RPC. Esta informa\u00e7\u00e3o pode ser configurada a priori por um administrador de sistemas, mas requer atualiza\u00e7\u00f5es sempre que a localiza\u00e7\u00e3o do servi\u00e7o for alterada ou novos servidores adicionados. Mais interessante seria um mecanismo que permitisse uma indire\u00e7\u00e3o para o servi\u00e7o; o pr\u00f3prio DNS pode ser uma op\u00e7\u00e3o inicial, mas um servi\u00e7o dedicado pode ser mais apropriado, pois permite descobrir servi\u00e7os e n\u00e3o apenas servidores. Birrel e Nelson propuseram um servi\u00e7o de P\u00e1ginas Amarelas , no qual clientes podem questionar quem oferece um certo servi\u00e7o e serem redirecionados automaticamente. Esta abordagem tem seus pr\u00f3prios problemas, como por exemplo determinar quem administra o servi\u00e7o para incluir novos servidores. E como determinar qual servi\u00e7o acessar, caso hajam m\u00faltiplas op\u00e7\u00f5es de servidores . Apesar dos problemas, p\u00e1ginas amarelas foram usadas em abordagens muito mais recentes para descobertas de servi\u00e7os, por exemplo Web Services Discovery , que permite a descoberta de Web Services em escala global, e Java Remote Object Registry que permite a descoberta de objetos remotos Java. Tratamento de Exce\u00e7\u00f5es Uma vez que a invoca\u00e7\u00e3o \u00e9 remota, h\u00e1 sempre o risco de problemas de comunica\u00e7\u00e3o entre cliente e servidor. Logo, \u00e9 necess\u00e1ria a introdu\u00e7\u00e3o de c\u00f3digo para tratamento de erros deste tipo, o que absolutamente n\u00e3o era necess\u00e1rio no caso do c\u00f3digo centralizado. Assim, o que era um simples x = substring(a,3,\"teste\"); passa para algo assim (em uma linguagem fict\u00edcia): int x = -2; try { x = substring(a,3,\"teste\");` } catch(CommunicationFailureException cfe) { log_error(\"Como pode substring falhar? Desespero!!!\"); } if (x == -2) system_exit(-2) else if (x == -1) //n\u00e3o achou else //achou \"teste\" na posi\u00e7\u00e3o x O que nos leva novamente ao ponto sobre n\u00e3o haver transpar\u00eancia total em sistemas distribu\u00eddos... e esta falta de transpar\u00eancia pode ser muito mais complicada do que simplesmente adicionar try e catch ao seu c\u00f3digo. Mais que isso, imagine que a opera\u00e7\u00e3o sendo executada altere algum estado no servidor. Se esta fosse uma operac\u00e3o local, cada invoca\u00e7\u00e3o da opera\u00e7\u00e3o corresponderia a exatamente uma execu\u00e7\u00e3o da opera\u00e7\u00e3o, na aus\u00eancia de falhas. No caso de falhas, se o processo quebra como um todo, no seu rein\u00edcio, pode-se identificar se a opera\u00e7\u00e3o foi ou n\u00e3o executada e aplicar a\u00e7\u00f5es corretivas. Mas e no caso remoto? Reexecu\u00e7\u00f5es No caso da opera\u00e7\u00e3o distribu\u00edda, se o servidor quebra, isso levar\u00e1 a um erro ser percebido do lado do cliente como uma falha na conex\u00e3o . Se o cliente havia invocado uma opera\u00e7\u00e3o mas percebeu o erro antes de receber uma confirma\u00e7\u00e3o de sua execu\u00e7\u00e3o, isto pode indicar que: (i) ou a requisi\u00e7\u00e3o nunca foi recebida pelo servidor e, portanto, n\u00e3o foi executada, (ii) ou a execu\u00e7\u00e3o foi recebida e executada, mas a resposta n\u00e3o foi enviada. O cliente tem que tratar o erro, mas como? Se a opera\u00e7\u00e3o precisa ser executada a qualquer custo , o cliente pode retent\u00e1-la quando conseguir novo contato com o servidor (ou mesmo com outro). Neste caso, se o que de fato aconteceu foi a situa\u00e7\u00e3o (i), ent\u00e3o retentar garantir\u00e1 que a opera\u00e7\u00e3o seja executada pelo servidor, mesmo que v\u00e1rias tentativas sejam necess\u00e1rias. Contudo, se o que o ocorreu foi a situa\u00e7\u00e3o (ii), ent\u00e3o reenviar a opera\u00e7\u00e3o levar\u00e1 a mesma a ser executada m\u00faltiplas vezes, o que pode ou n\u00e3o ser ok. Esta abordagem \u00e9 garantir\u00e1 que a execu\u00e7\u00e3o acontece pelo menos 1 vez . Imagine que a opera\u00e7\u00e3o se tratasse de uma transfer\u00eancia de saldo, ou a encomenda de de um caminh\u00e3o carregado de algum produto caro. Neste caso, reexecutar n\u00e3o parece ser uma op\u00e7\u00e3o. Neste caso, talvez a melhor op\u00e7\u00e3o seja n\u00e3o retentar a opera\u00e7\u00e3o, o que levar\u00e1 a zero execu\u00e7\u00f5es na situa\u00e7\u00e3o (ii) e uma execu\u00e7\u00e3o na situa\u00e7\u00e3o, ou seja, a no m\u00e1ximo uma execu\u00e7\u00e3o. Uma situa\u00e7\u00e3o em que esta abordagem \u00e9 claramente prefer\u00edvel \u00e9 a entrega de quadros em um stream de v\u00eddeo ou \u00e1udio, devido \u00e0 import\u00e2ncia da opera\u00e7\u00e3o ser atrelada ao momento de sua execu\u00e7\u00e3o. Nenhuma destas abordagens \u00e9 igual ao que \u00e9 garantido na vers\u00e3o centralizada e que \u00e9 provelmente o que todo desenvolvedor desejaria para suas invoca\u00e7\u00f5es de m\u00e9todos, que fossem executados exatamente uma vez. Garantir esta sem\u00e2ntica na comunica\u00e7\u00e3o \u00e9 muito dif\u00edcil, pois \u00e9 imposs\u00edvel ter certeza de que uma mensagem n\u00e3o foi processada pelo servidor ainda. De fato, \u00e9 imposs\u00edvel ter certeza se o servidor falhou; pode ter sido apenas uma falha na comunica\u00e7\u00e3o. Quantidade de execu\u00e7\u00f5es No m\u00e1ximo uma - n\u00e3o retentar Exatamente uma - impedir que falhas aconte\u00e7am :/ Pelo menos uma - retentar at\u00e9 ter confirma\u00e7\u00e3o Como \u00e9 imposs\u00edvel evitar falhas, se uma opera\u00e7\u00e3o deve executada, ela deve ser retentada. Mas ela n\u00e3o pode ser repetida, ent\u00e3o a alternativa \u00e9 tornar as opera\u00e7\u00f5es idempotentes , o que quer dizer que o efeito desejado \u00e9 alcan\u00e7ado pela primeira execu\u00e7\u00e3o e que execu\u00e7\u00f5es seguintes n\u00e3o alteram o estado. Opera\u00e7\u00f5es idempotentes M\u00faltiplas execu\u00e7\u00f5es tem o mesmo efeito uma execu\u00e7\u00e3o. Exemplo: x = 10 Anti-exemplo: x = x+1 . Infelizmente n\u00e3o \u00e9 trivial programar para idempot\u00eancia, principalmente se o servidor for acessado concorrentemente por m\u00faltiplos clientes, tornando seu estado uam regi\u00e3o cr\u00edtica. Concorr\u00eancia no servidor \u00c9 importante notar que um servidor n\u00e3o est\u00e1 obrigado a atender requisi\u00e7\u00f5es de somente um cliente. Logo, se m\u00faltiplos clientes acessam o mesmo servidor, o estado do servidor ser\u00e1 \"compartilhado\" pelos v\u00e1rios clientes e passos s\u00e3o necess\u00e1rios para que o comportamento no acesso deste estado seja coerente com a especifica\u00e7\u00e3o. Pense por exemplo em um servidor que conta o n\u00famero de acessos feitos por clientes. O incremento do contador deve ser considerado uma regi\u00e3o cr\u00edtica, caso m\u00faltiplos threads tratem as requisi\u00e7\u00f5es dos clientes, o que j\u00e1 vimos ser uma boa idia. Claro que dificilmente seu servidor seria algo t\u00e3o simples assim. Em vez disso, ele provavelmente executar\u00e1 l\u00f3gicas complicadas, como por exemplo, armazenar o estado de contas banc\u00e1rias e, neste caso, as fun\u00e7\u00f5es expostas por RPC incluir\u00edam a opera\u00e7\u00e3o transferir saldo de A para B , o que nos leva a mais um problema interessante, o do risco de reexecu\u00e7\u00f5es. Al\u00e9m disso, o servidor provavelmente suportar\u00e1 diversas opera\u00e7\u00f5es e por isso dever\u00e1 identificar qual a opera\u00e7\u00e3o sendo requisitada. Isto \u00e9 feito por um dispatcher , que demultiplexa as opera\u00e7\u00f5es requisitadas; o dispatcher pode, em algumas arquiteturas, ser independente do skeleton em si. Frameworks H\u00e1 diversas op\u00e7\u00f5e de frameworks para RPC, com diferentes caracter\u00edsticas, focos, e garantias. Alguns s\u00e3o parte da linguagem e outros s\u00e3o implementados como bibliotecas. Alguns suportam m\u00faltiplas linguagens e alguns apenas uma. Suporte a RPC na linguagem Sem RPC: C, C++, Java < 5.0 (1.5), Python Com RPC: Java, Go, Erlang, Scala, Haskell Ambientes heterog\u00eaneos: Thrift, gRPC, Akka, SOAP Frameworks mais modernos permitem escolher a forma de serializa\u00e7\u00e3o dos dados, se leg\u00edvel para humanos ou bin\u00e1rio, se o transporte \u00e9 via HTTP ou protocolo mais baixo n\u00edvel, se os dados trafegam abertamente ou se faz uso de comunica\u00e7\u00e3o criptografada (SSL). Outros permitem escolher sem\u00e2ntica de execu\u00e7\u00e3o entre no m\u00e1ximo uma e pelo menos uma , e h\u00e1 at\u00e9 quem prometa exatamente uma . Mas todos os frameworks tem algumas caracter\u00edsticas em comum e uma delas \u00e9 o uso de uma Linguagem de Defini\u00e7\u00e3o de Interface (IDL). Interface Definition Language - IDL Uma IDL \u00e9 a linguagem pela qual desenvolvedor define quais as opera\u00e7\u00f5es (fun\u00e7\u00f5es, procedimentos, m\u00e9todos) ser\u00e3o acess\u00edveis via RPC e quais os seus operandos. H\u00e1 v\u00e1rias IDL definidas, para os diversos frameworks dispon\u00edveis. A imagem a seguir mostra um exemplo gen\u00e9rico da cria\u00e7\u00e3o cliente e servidor usando um framework RPC gen\u00e9rico, inclusive o processamento da defini\u00e7\u00e3o feita em IDL do servi\u00e7o e a jun\u00e7\u00e3o deste c\u00f3digo gerado ao c\u00f3digo escrito pelo desenvolvedor. O fluxo de processamento \u00e9 o seguinte: Arquivo em IDL \u00e9 compilado por um compilador IDL e gera diversos arquivos: stub cliente - c\u00f3digo que implementa a interface, com c\u00f3digo para repassar invoca\u00e7\u00f5es para o servidor. stub servidor ( skeleton ) - c\u00f3digo que atende a conex\u00f5es do stub cliente e repassa para a implementa\u00e7\u00e3o pr\u00f3pria da fun\u00e7\u00e3o. convers\u00e3o de dados - c\u00f3digo que serializa e deserializa dados para serem trafegados de e para o servidor cabe\u00e7alhos - defini\u00e7\u00f5es da interface na linguagem de desenvolvimento da aplica\u00e7\u00e3o; se linguagem C, por exemplo, estes ser\u00e3o arquivos .h , se em Java, ent\u00e3o estes ser\u00e3o arquivos .java , com defini\u00e7\u00e3o de interface . O c\u00f3digo cliente \u00e9 compilado e gera o cliente, que deve inicializar a infraestrutura RPC Tipo de transporte SSL? Localizar servidor Lidar com falhas O c\u00f3digo servidor \u00e9 compilado e gera o servidor, que deve exportar e localizar servi\u00e7os (servi\u00e7o de nomea\u00e7\u00e3o) Gerenciamento de portas Conex\u00f5es Mas para entendermos melhor o fluxo, vejamos algumas ferramentas reais. Estudo de Caso RPC: gRPC gRPC \u00e9 um framework para invoca\u00e7\u00e3o remota de procedimentos multi-linguagem e sistema operacional, usando internamente pelo Google h\u00e1 v\u00e1rios anos para implementar sua arquitetura de micro-servi\u00e7os. Inicialmente desenvolvido pelo Google, o gRPC \u00e9 hoje de c\u00f3digo livre encubado pela Cloud Native Computing Foundation. O s\u00edtio https://grpc.io documenta muito bem o gRPC, inclusive os princ\u00edpios que nortearam seu projeto. O seu uso segue, em linhas gerais, o modelo discutido nas se\u00e7\u00f5es anteriores, isto \u00e9, inicia-se pela defini\u00e7\u00e3o de estruturas de dados e servi\u00e7os, \"compila-se\" a defini\u00e7\u00e3o para gerar stubs na linguagem desejada, e compila-se os stubs juntamente com os c\u00f3digos cliente e servidor para gerar os bin\u00e1rios correspondentes. Vejamos a seguir um tutorial passo a passo, em Java, baseado no quickstart guide . Instala\u00e7\u00e3o Os procedimentos de instala\u00e7\u00e3o dependem da linguagem em que pretende usar o gRPC, tanto para cliente quanto para servidor. No caso do Java , n\u00e3o h\u00e1 instala\u00e7\u00e3o propriamente dita . Exemplo Java Observe que o reposit\u00f3rio base apontado no tutorial serve de exemplo para diversas linguagens e diversos servi\u00e7os, ent\u00e3o sua estrutura \u00e9 meio complicada. N\u00f3s nos focaremos aqui no exemplo mais simples, uma esp\u00e9cie de \"hello word\" do RPC. Pegando o c\u00f3digo Para usar os exemplos, voc\u00ea precisa clonar o reposit\u00f3rio com o tutorial, usando o comando a seguir. git clone -b v1.19.0 https://github.com/grpc/grpc-java Uma vez clonado, entre na pasta de exemplo do Java e certifique-se que est\u00e1 na vers\u00e3o 1.19, usada neste tutorial. cd grpc-java\\examples git checkout v1.19.0 Compilando e executando O projeto usa gradle para gerenciar as depend\u00eancias. Para, use o wrapper do gradle como se segue. ./gradlew installDist Caso esteja na UFU, coloque tamb\u00e9m informa\u00e7\u00e3o sobre o proxy no comando. ./gradlew -Dhttp.proxyHost=proxy.ufu.br -Dhttp.proxyPort=3128 -Dhttps.proxyHost=proxy.ufu.br -Dhttps.proxyPort=3128 installDist Como quando usamos sockets diretamente, para usar o servi\u00e7o definido neste exemplo, primeiros temos que executar o servidor. ./build/install/examples/bin/hello-world-server Agora, em um terminal distinto e a partir da mesma localiza\u00e7\u00e3o, execute o cliente, quantas vezes quiser. ./build/install/examples/bin/hello-world-client O servi\u00e7o O exemplo n\u00e3o \u00e9 muito excitante, pois tudo o que o servi\u00e7o faz \u00e9 enviar uma sauda\u00e7\u00e3o aos clientes. O servi\u00e7o \u00e9 definido no seguinte arquivo .proto , localizado em ./src/main/proto/helloworld.proto . message HelloRequest { string name = 1; } message HelloReply { string message = 1; } // The greeting service definition. service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {} } No arquivo, inicialmente s\u00e3o definidas duas mensagens, usadas como requisi\u00e7\u00e3o (cliente para servidor) e outra como resposta (servidor para cliente) do servi\u00e7o definido em seguida. A mensagem HelloRequest tem apenas um campo denominado name , do tipo string . Esta mensagem conter\u00e1 o nome do cliente, usado na resposta gerada pelo servidor. A mensagem HelloReply tamb\u00e9m tem um campo do tipo string , denominado message , que conter\u00e1 a resposta do servidor. O servi\u00e7o dispon\u00edvel \u00e9 definido pela palavra chave service e de nome Greeter ; \u00e9 importante entender que este nome ser\u00e1 usado em todo o c\u00f3digo gerado pelo compilador gRPC e que se for mudado, todas as refer\u00eancias ao c\u00f3digo gerado devem ser atualizadas. O servi\u00e7o possui apenas uma opera\u00e7\u00e3o, SayHello , que recebe como entrada uma mensagem HelloRequest e gera como resposta uma mensagem HelloReply . Caso a opera\u00e7\u00e3o precisasse de mais do que o conte\u00fado de name para executar, a mensagem HelloRequest deveria ser estendida, pois n\u00e3o h\u00e1 passar mais de uma mensagem para a opera\u00e7\u00e3o. Por outro lado, embora seja poss\u00edvel passar zero mensagens, esta n\u00e3o \u00e9 uma pr\u00e1tica recomendada. Isto porqu\u00ea caso o servi\u00e7o precisasse ser modificado no futuro, embora seja poss\u00edvel estender uma mensagem, n\u00e3o \u00e9 poss\u00edvel modificar a assinatura do servi\u00e7o. Assim, caso n\u00e3o haja a necessidade de se passar qualquer informa\u00e7\u00e3o para a opera\u00e7\u00e3o, recomenda-se que seja usada uma mensagem de entrada vazia, que poderia ser estendida no futuro. O mesmo se aplica ao resultado da opera\u00e7\u00e3o. Observe tamb\u00e9m que embora o servi\u00e7o de exemplo tenha apenas uma opera\u00e7\u00e3o, poderia ter m\u00faltiplas. Por exemplo, para definir uma vers\u00e3o em portugu\u00eas da opera\u00e7\u00e3o SayHello , podemos fazer da seguinte forma. message HelloRequest { string name = 1; } message HelloReply { string message = 1; } message OlaRequest { // <<<<<==== string name = 1; } message OlaReply { // <<<<<==== string message = 1; } service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {} rpc DigaOla (OlaRequest) returns (OlaReply) {}// <<<<<==== } ... Observe que a nova opera\u00e7\u00e3o recebe como entrada mensagens OlaRequest e OlaReply , que tem defini\u00e7\u00f5es exatamente iguais a HellorRequest e HelloReply . Logo, em vez de definir novas mensagens, poder\u00edamos ter usado as j\u00e1 definidas. Novamente, esta n\u00e3o \u00e9 uma boa pr\u00e1tica, pois caso fosse necess\u00e1rio evoluir uma das opera\u00e7\u00f5es para atender a novos requisitos e estender suas mensagens, n\u00e3o ser\u00e1 necess\u00e1rio tocar o restante do servi\u00e7o. Apenas refor\u00e7ando, \u00e9 boa pr\u00e1tica definir requests e responses para cada m\u00e9todo, a n\u00e3o ser que n\u00e3o haja d\u00favida de que ser\u00e3o para sempre iguais. Implementando um servi\u00e7o Agora modifique o arquivo .proto como acima, para incluir a opera\u00e7\u00e3o DigaOla , recompile e reexecute o servi\u00e7o. N\u00e3o d\u00e1 certo, n\u00e3o \u00e9 mesmo? Isto porqu\u00ea voc\u00ea adicionou a defini\u00e7\u00e3o de uma nova opera\u00e7\u00e3o, mas n\u00e3o incluiu o c\u00f3digo para implement\u00e1-la. Fa\u00e7amos ent\u00e3o a modifica\u00e7\u00e3o do c\u00f3digo, come\u00e7ando por ./src/main/java/io/grpc/examples/helloworld/HelloWorldServer.java . Este arquivo define a classe que implementa o servi\u00e7o Greeter , GreeterImpl , com um m\u00e9todo para cada uma das opera\u00e7\u00f5es definidas. Para confirmar, procure por sayHello para encontrar a implementa\u00e7\u00e3o de SayHello ; observe que a diferen\u00e7a do casing vem das boas pr\u00e1ticas de Java, de definir m\u00e9todos e vari\u00e1veis em Camel casing . Para que sua vers\u00e3o estendida do servi\u00e7o Greeter funcione, defina um m\u00e9todo correspondendo \u00e0 DigaOla , sem consultar o c\u00f3digo exemplo abaixo, mas usando o c\u00f3digo de sayHello como base; n\u00e3o se importe por enquanto com os m\u00e9todos sendo invocados. Note que os ... indicam que parte do c\u00f3digo, que n\u00e3o sofreu modifica\u00e7\u00f5es, foi omitido. ... private class GreeterImpl extends GreeterGrpc.GreeterImplBase { ... @Override public void sayHello(HelloRequest req, StreamObserver<HelloReply> responseObserver) { ... } @Override public void digaOla(OlaRequest req, StreamObserver<OlaReply> responseObserver) { OlaReply reply = OlaReply.newBuilder().setMessage(\"Ola \" + req.getName()).build(); responseObserver.onNext(reply); responseObserver.onCompleted(); } } Se voc\u00ea recompilar e reexecutar o c\u00f3digo, n\u00e3o perceber\u00e1 qualquer mudan\u00e7a na sa\u00edda do programa. Isto porqu\u00ea embora tenha definido um novo servi\u00e7o, voc\u00ea n\u00e3o o utilizou. Para tanto, agora modifique o cliente, em src/main/java/io/grpc/examples/helloworld/HelloWorldClient.java , novamente se baseando no c\u00f3digo existente e n\u00e3o se preocupando com \"detalhes\". public void greet(String name) { logger.info(\"Will try to greet \" + name + \" ...\"); ... OlaRequest request2 = OlaRequest.newBuilder().setName(name).build(); OlaReply response2; try { response2 = blockingStub.digaOla(request2); } catch (StatusRuntimeException e) { logger.log(Level.WARNING, \"RPC failed: {0}\", e.getStatus()); return; } logger.info(\"Greeting: \" + response2.getMessage()); } Agora sim, voc\u00ea pode reexecutar cliente e servidor. ./gradlew installDist ./build/install/examples/bin/hello-world-server & ./build/install/examples/bin/hello-world-client Percebeu como foi f\u00e1cil adicionar uma opera\u00e7\u00e3o ao servi\u00e7o? Agora nos foquemos nos detalhes. Stub do servidor Como criar o servidor Como definir o servi\u00e7o Como \"startar\" o servidor. Stub do cliente Stub bloqueante Stub n\u00e3o bloqueante IDL gRPC Outras caracter\u00edsticas da IDL do gRPC Tipos b\u00e1sicos bool: boolean (true/false) double: 64-bit; ponto-flutuante float: 32-bit; ponto-flutuante i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado siXX: signed uiXX: unsigned sfixedXX: codifica\u00e7\u00e3o de tamanho fixo bytes: 8-bit; inteiro sinalizado string: string UTF-8 ou ASCII 7-bit Any: tipo indefinido Diferentes tradu\u00e7\u00f5es Cole\u00e7\u00f5es Defina e implemente uma opera\u00e7\u00e3o DigaOlas em que uma lista de nomes \u00e9 enviada ao servidor e tal que o servidor responda com uma longa string cumprimentando todos os nomes, um ap;os o outro. Streams Do lado do servidor ```java List listOfHi = Arrays.asList(\"e aih\", \"ola\", \"ciao\", \"bao\", \"howdy\", \"s'up\"); @Override public void digaOlas(OlaRequest req, StreamObserver responseObserver) { for (String hi: listOfHi) { OlaReply reply = OlaReply.newBuilder().setMessage(hi + \", \" req.getName()).build(); responseObserver.onNext(reply); } responseObserver.onCompleted(); } ``` - Do lado do cliente java OlaRequest request = OlaRequest.newBuilder().setName(name).build(); try { Iterator<OlaReply> it = blockingStub.digaOlas(request); while (it.hasNext()){ OlaReply response = it.next(); logger.info(\"Greeting: \" + response.getMessage()); } } catch (StatusRuntimeException e) { logger.log(Level.WARNING, \"RPC failed: {0}\", e.getStatus()); return; } Exemplo Python apt-get install python3 apt-get install python3-pip python3 -m pip install --upgrade pip python3 -m pip install grpcio python3 -m pip install grpcio-tools git clone -b v1.10.x https://github.com/grpc/grpc cd grpc/examples/python/helloworld python3 greeter\\_server.py python3 greeter\\_client.py Para recompilar os stubs, fa\u00e7a python3 -m grpc_tools.protoc -I../../protos --python_out=. --grpc_python_out=. ../../protos/helloworld.proto Modifique o servidor def DigaOla(self, request, context): return helloworld_pb2.OlaReply(message='Ola, %s!' + request.name) Modifique o cliente response = stub.DigaOla(helloworld_pb2.OlaRequest(name='zelelele')) print(\"Greeter client received: \" + response.message) Estudo de Caso RPC: Thrift Thrift Instala\u00e7\u00e3o Baixe e compile o thrift ou instale-o usando apt-get, por exemplo. apt-get install thrift-compiler execute \"thrift\" na linha de comando. Para thrift com Java, tamb\u00e9m precisar\u00e3o dos seguintes arquivos slf4j libthrift0.9.3.jar coloque-os na pasta jars IDL Thrift Tipos b\u00e1sicos bool: boolean (true/false) byte: 8-bit; inteiro sinalizado i16: 16-bit; inteiro sinalizado i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado double: 64-bit; ponto-flutuante string: string UTF-8 binary: sequ\u00eancia de bytes Estruturas struct Example { 1:i32 number, 2:i64 bigNumber, 3:double decimals, 4:string name=\"thrifty\" } Servi\u00e7os service ChaveValor { void set(1:i32 key, 2:string value), string get(1:i32 key) throws (1:KeyNotFound knf), void delete(1:i32 key) } N\u00e3o se pode retornar NULL!!! Exce\u00e7\u00f5es exception KeyNotFound { 1:i64 hora r, 2:string chaveProcurada=\"thrifty\" } Containers List Map Set Exemplo: chavevalor.thrift namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV(1:i32 key) throws (1:KeyNotFound knf), bool setKV(1:i32 key, 2:string value), void delKV(1:i32 key) } Compila\u00e7\u00e3o thrift --gen java chavevalor.thrift thrift --gen py chavevalor.thrift ChaveValorHandler.java namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV(1:i32 key) throws (1:KeyNotFound knf), bool setKV(1:i32 key, 2:string value), void delKV(1:i32 key) } package chavevalor; import org.apache.thrift.TException; import java.util.HashMap; import chavevalor.*; public class ChaveValorHandler implements ChaveValor.Iface { private HashMap<Integer,String> kv = new HashMap<>(); @Override public String getKV(int key) throws TException { if(kv.containsKey(key)) return kv.get(key); else throw new KeyNotFound(); } @Override public boolean setKV(int key, String valor) throws TException { kv.put(key,valor); return true; } @Override public void delKV(int key) throws TException { kv.remove(key); } } Arquitetura Runtime library -- componentes podem ser selecionados em tempo de execu\u00e7\u00e3o e implementa\u00e7\u00f5es podem ser trocadas Protocol -- respons\u00e1vel pela serializa\u00e7\u00e3oo dos dados TBinaryProtocol TJSONProtocol TDebugProtocol ... Transport -- I/O no ``fio'' TSocket TFramedTransport (non-blocking server) TFileTransport TMemoryTransport Processor -- Conecta protocolos de entrada e sa\u00edda com o \\emph{handler} Handler -- Implementa\u00e7\u00e3o das opera\u00e7\u00f5es oferecidas Server -- Escuta portas e repassa dados (protocolo) para o processors TSimpleServer TThreadPool TNonBlockingChannel Classpath javac -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java -d . *.java java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorServer java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorClient Refer\u00eancias Tutorial Estudo de Caso RPC: RMI TODO Comunica\u00e7\u00e3o orientada a Mensagens TODO MOM Enterprise Message Bus To Message Bus or Not: distributed system design Implementing RPC \u21a9 Omitirei alguns detalhes aqui, em nome da genericidade, mas voc\u00eas podem recuper\u00e1-los em seus livros de Arquitetura de Computadores. \u21a9 O stub do servidor tamb\u00e9m \u00e9 conhecido como skeleton . \u21a9 Marshalling: representar par\u00e2metros de forma pr\u00f3pria para transmiss\u00e3o \"no fio\". \u21a9","title":"Comunica\u00e7\u00e3o"},{"location":"comm/#communicacao","text":"O desenvolvimento de sistemas distribu\u00eddos usando diretamente Sockets como forma de comunica\u00e7\u00e3o entre componentes n\u00e3o \u00e9 para os fracos de cora\u00e7\u00e3o. Sua grande vantagem est\u00e1 no acesso baixo n\u00edvel \u00e0 rede , e todo o ganho de desempenho que isso pode trazer. Suas desvantagens, entretanto, s\u00e3o v\u00e1rias: interface de \"arquivo\" para se ler e escrever bytes; controle de fluxo de \"objetos\" \u00e9 por conta da aplica\u00e7\u00e3o, isto \u00e9, a aplica\u00e7\u00e3o precisa sinalizar quantos bytes ser\u00e3o escritos de um lado, para que o outro saiba quanto ler para obter um \"objeto\" correto; logo, a serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o de objetos \u00e9 tamb\u00e9m por conta da aplica\u00e7\u00e3o; tratamento de desconex\u00f5es e eventuais reconex\u00f5es tamb\u00e9m \u00e9 gerenciado pela aplica\u00e7\u00e3o e nem a t\u00e3o famosa confiabilidade do TCP ajuda. Enquanto se poderia argumentar que algumas destas desvantagens podem ser descartadas em fun\u00e7\u00e3o da discuss\u00e3o de incluir ou n\u00e3o API na comunica\u00e7\u00e3o fim-a-fim , \u00e9 certo que algumas funcionalidades s\u00e3o ub\u00edquas em aplica\u00e7\u00f5es distribu\u00eddas. Aqui discutiremos algumas destas funcionalidades e como podem e s\u00e3o implementadas por frameworks de comunica\u00e7\u00e3o de mais alto n\u00edvel.","title":"Communica\u00e7\u00e3o"},{"location":"comm/#representacao-de-dados","text":"Exceto por aplica\u00e7\u00f5es muito simples, processos em um sistema distribu\u00eddos trocam dados complexos, por exemplo estruturas ou classes com diversos campos, incluindo valores num\u00e9ricos de diversos tipos, strings e vetores de bytes, com diversos n\u00edveis de aninhamento e somando v\u00e1rios KB. Neste cen\u00e1rio, v\u00e1rios fatores precisam ser levados em considera\u00e7\u00e3o na hora de colocar esta estrutura no fio , por exemplo: Diferentes linguagens de programa\u00e7\u00e3o usadas para desenvolver os componentes. tipos com defini\u00e7\u00e3o imprecisa, por exemplo \"inteiro\": 8: 16, 32, 64 ou bits? paradigmas distintos: classe x estrutura conjunto de caracteres diferentes: ASCII x UTF Arquiteturas diferentes. ordem dos bytes little endian? x64 IA-32 big endian? IP SPARC (< V9) Motorola PowerPC bi-endian? ARM, MIPS, IA-64 representa\u00e7\u00e3o de ponto flutuante alinhamento de bytes Sistemas operacionais diferentes crlf (DOS) x lf (Unix) fragmenta\u00e7\u00e3o","title":"Representa\u00e7\u00e3o de dados"},{"location":"comm/#representacao-textual","text":"Uma abordagem comumente usada \u00e9 a representa\u00e7\u00e3o em formato textual \"amig\u00e1vel a humanos\". Veja o exemplo de como o protocolo HTTP requisita e recebe uma p\u00e1gina HTML. telnet www.google.com 80 Trying 187.72.192.217... Connected to www.google.com. Escape character is '^]'. GET / HTTP/1.1 host: www.google.com As linhas 5 e 6 s\u00e3o entradas pelo cliente para requisitar a p\u00e1gina raiz do s\u00edtio www.google.com . A linha 7, vazia, indica ao servidor que a requisi\u00e7\u00e3o est\u00e1 terminada. Em resposta a esta requisi\u00e7\u00e3o, o servidor envia o seguinte, em que as primeiras linhas trazem metadados da p\u00e1gina requisitada e, ap\u00f3s a linha em branco, vem a resposta em HTML \u00e0 requisi\u00e7\u00e3o. HTTP/1.1 302 Found Location: http://www.google.com.br/?gws_rd=cr&ei=HTDqWJ3BDYe-wATs_a3ACA Cache-Control: private Content-Type: text/html; charset=UTF-8 P3P: CP=\"This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info.\" Date: Sun, 09 Apr 2017 12:59:09 GMT Server: gws Content-Length: 262 X-XSS-Protection: 1; mode=block X-Frame-Options: SAMEORIGIN Set-Cookie: NID=100=NB_AruuFWL0hXk2-h7VDduHO_UkjAr6RaqgG7VbccTsfLzFfhxEKx21Xpa2EH7IgshgczE9vU4W1TyKsa07wQeuZosl5DbyZluR1ViDRf0C-5lRpd9cCpCD5JXXjy-UE; expires=Mon, 09-Oct-2017 12:59:09 GMT; path=/; domain=.google.com; HttpOnly <HTML><HEAD><meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\"> <TITLE>302 Moved</TITLE></HEAD><BODY> <H1>302 Moved</H1> The document has moved <A HREF=\"http://www.google.com.br/?gws_rd=cr&amp;ei=HTDqWJ3BDYe-wATs_a3ACA\">here</A>. </BODY></HTML> Representa\u00e7\u00f5es textuais s\u00e3o usadas em diversos protocolos como SMTP, POP, e telnet. Algumas destas representa\u00e7\u00f5es seguem padr\u00f5es formalizados, o que facilita a gera\u00e7\u00e3o e interpreta\u00e7\u00e3o dos dados. Dois padr\u00f5es bem conhecidas s\u00e3o XML e JSON. XML \u00e9 o acr\u00f4nimo para Extensible Markup Language , ou seja, uma linguagem marca\u00e7\u00e3o que pode ser estendida para representar diferentes tipos de informa\u00e7\u00e3o. A HTML, por exemplo, \u00e9 uma inst\u00e2ncia de XML destinada \u00e0 representa\u00e7\u00e3o de hipertexto (A bem da verdade, XML foi uma generaliza\u00e7\u00e3o de HTML). Por exemplo, para representarmos os dados relativos \u00e0 uma pessoa, podemos ter uma inst\u00e2ncia XML assim: <person> <name>John Doe</name> <id>112234556</id> <email>jdoe@example.com</email> <telephones> <telephone type=\"mobile\">123 321 123</telephone> <telephone type=\"home\">321 123 321</telephone> </telephones> </person> Uma das grandes vantagens do uso de XML \u00e9 a possibilidade de se formalizar o que pode ou n\u00e3o estar em um arquivo para um certo dom\u00ednio utilizando um XML Domain Object Model . H\u00e1, por exemplo, modelos para representa\u00e7\u00e3o de documentos de texto, governos eletr\u00f4nicos, representa\u00e7\u00e3o de conhecimento, etc . Sua maior desvantagem \u00e9 que \u00e9 muito verborr\u00e1gico e por vezes complicado de se usar, abrindo alas para o seu mais famoso concorrente, JSON. JSON \u00e9 o acr\u00f4nimo de Javascript Object Notation , isto \u00e9, o formato para representa\u00e7\u00e3o de objetos da linguagem Javascript. Devido \u00e0 sua simplicidade e versatilidade, entretanto, foi adotado como forma de representa\u00e7\u00e3o de dados em sistemas desenvolvidos nas mais diferentes linguagens. O mesmo exemplo visto anteriormente, em XML, \u00e9 representado em JSON assim: { \"name\": \"John Doe\", \"id\": 112234556, \"email\": \"jdoe@example.com\", \"telephones\": [ { \"type\": \"mobile\", \"number\": \"123 321 123\"}, { \"type\": \"home\", \"number\": \"321 123 321\"}, ] } Em Python, por exemplo, JSON s\u00e3o gerados e interpretados nativamente, sem a necessidade de frameworks externos, facilitando seu uso. Mas de fato, a op\u00e7\u00e3o final por XML ou JSON \u00e9 quest\u00e3o de prefer\u00eancia, uma vez que os dois formatos s\u00e3o, de fato, equivalentes na quest\u00e3o da representa\u00e7\u00e3o de informa\u00e7\u00e3o. Outros formatos, bin\u00e1rios, oferecem vantagens no uso de espa\u00e7o para armazenar e transmitir dados, e por isso s\u00e3o frequentemente usados como forma de serializa\u00e7\u00e3o de dados em sistemas distribu\u00eddos, isto \u00e9, na transforma\u00e7\u00e3o de TAD para sequ\u00eancias de bytes que seguir\u00e3o \"no fio\". ASN.1 (Abstract Syntax Notation), pela ISO XDR (eXternal Data Representation) Java serialization Google Protocol Buffers Thrift ASN.1 e XDR s\u00e3o de interesse hist\u00f3rico, mas n\u00e3o os discutiremos aqui. Quanto \u00e0 serializa\u00e7\u00e3o feita nativamente pelo Java, por meio de ObjectOutputStreams , como neste exemplo , embora seja tentadora para quem usa Java, \u00e9 necess\u00e1rio saber que ela \u00e9 restrita \u00e0 JVM e que usa muito espa\u00e7o, embora minimize riscos de uma desserializa\u00e7\u00e3o para uma classe diferente. Nos foquemos nas autras alternativas listadas, ProtoBuffers e Thrift, que podem levar a representa\u00e7\u00f5es bin\u00e1rias e textuais.","title":"Representa\u00e7\u00e3o Textual"},{"location":"comm/#protobuffers","text":"Nas palavras dos criadores , Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Por meio de protobuffers, \u00e9 poss\u00edvel estruturar dados e gerar o c\u00f3digo correspondente em diversas linguagens, for forma compartilh\u00e1vel entre as mesmas. Veja o exemplo a seguir, que especifica os dados referentes a uma pessoa. Observe a presen\u00e7a de campos de preenchimento opcional ( optional ), de enumera\u00e7\u00f5es ( enum ), e de cole\u00e7\u00f5es ( repeated ). message Person { required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { required string number = 1; optional PhoneType type = 2 [default = HOME]; } repeated PhoneNumber phone = 4; } Com tal defini\u00e7\u00e3o \u00e9 poss\u00edvel gerar c\u00f3digo como o seguinte, em C++, que serializa os dados para escrita em um arquivo... Person person; person.set_name(\"John Doe\"); person.set_id(1234); person.set_email(\"jdoe@example.com\"); fstream output(\"myfile\", ios::out | ios::binary); person.SerializeToOstream(&output); e l\u00ea do arquivo e desserializa para hidratar um novo objeto. fstream input(\"myfile\", ios::in | ios::binary); Person person; person.ParseFromIstream(&input); cout << \"Name: \" << person.name() << endl; cout << \"E-mail: \" << person.email() << endl; De acordo com benchmarks do pr\u00f3prio projeto , a opera\u00e7\u00e3o em XML seria mais \u00f3rdens de grandeza mais lenta e ocuparia mais espa\u00e7o. When this message is encoded to the protocol buffer binary format, it would probably be 28 bytes long and take around 100-200 nanoseconds to parse. The XML version is at least 69 bytes if you remove whitespace, and would take around 5,000-10,000 nanoseconds to parse.","title":"ProtoBuffers"},{"location":"comm/#thrift","text":"","title":"Thrift"},{"location":"comm/#invocacao-remota-de-procedimentos-rpc","text":"Em 1984, Birrel e Nelson 1 introduziram o mecanismo de Invoca\u00e7\u00e3o Remota de Procedimentos ( Remote Procedure Calls ), que permite que processos fa\u00e7am, pasmem, invoca\u00e7\u00f5es de procedimentos remotos! \u00d3bvio, a inova\u00e7\u00e3o n\u00e3o est\u00e1 na capacidade de uma m\u00e1quina conversar com outra, mas em como esta conversa acontece, do ponto de vista do programador. Por exemplo, RPC permita que se procure a substring \"teste\" dentro da string apontada por a , a partir da posi\u00e7\u00e3o 3, usando x = substring(a,3,\"teste\"); , mas com o invocador da fun\u00e7\u00e3o em um processo e a implementa\u00e7\u00e3o da fun\u00e7\u00e3o propriamente dita, em outro, possivelmente em outra m\u00e1quina.","title":"Invoca\u00e7\u00e3o Remota de Procedimentos - RPC"},{"location":"comm/#stubs","text":"Antes de nos aprofundarmos, vejamos como uma invoca\u00e7\u00e3o de fun\u00e7\u00f5es acontece normalmente dentro de um \u00fanico processo 2 . O c\u00f3digo x = substring(a,3,\"teste\"); , que procura \"teste\" em *a , \u00e9 traduzido nos seguintes passos em linguagem de m\u00e1quina: coloque o endere\u00e7o de \"teste\" na pilha coloque 3 na pilha coloque o valor de a na pilha coloque o endere\u00e7o de retorno na pilha (junto com outros dados de controle) salte para substring ajustando o instruction pointer ... procure substring ... coloque o resultado no acumulador limpe a pilha salte de volta recuperando o endere\u00e7o de retorno da pilha e ajustando o IP coloque resultado em x Se o que queremos \u00e9 colocar o c\u00f3digo da fun\u00e7\u00e3o substring em um outro processo e execut\u00e1-lo como se estiv\u00e9ssemos no mesmo processo que faz a invoca\u00e7\u00e3o, precisamos pensar em v\u00e1rias quest\u00f5es relativas ao fluxo mostrado acima. Claramente n\u00e3o podemos usar o mesmo fluxo para invocar uma fun\u00e7\u00e3o, mas precisamos de c\u00f3digo de simule a invoca\u00e7\u00e3o local mas que, por baixo do cap\u00f4, use sockets para se comunicar com o processo remoto. Estq simula\u00e7\u00e3o usar\u00e1 c\u00f3digo extra, que finge implementar substring para o invocador mas delega ao c\u00f3digo remoto o trabalho real da busca. Este c\u00f3digo extra \u00e9 conhecido como stub , ou para ser mais preciso, stub cliente , que faz parte do processo invocando a opera\u00e7\u00e3o, e stub servidor, que faz parte do processo executando a opera\u00e7\u00e3o invocada 3 . Assim, o cliente invoca fun\u00e7\u00e3o no stub cliente, achando que \u00e9 a fun\u00e7\u00e3o que quer executar. Stub cliente faz o marshaling 4 dos par\u00e2metros e usa o SO para transferir os dados via rede para o stub servidor. Quando recebe a resposta do servidor, o stub cliente retorna a mesma resposta, como se tivesse calculado localmente. Stub cliente Implementa uma fun\u00e7\u00e3o substring(char*, int, char*) que abre socket para servidor envia par\u00e2metros especifica fun\u00e7\u00e3o espera resposta retorna resultado J\u00e1 o stub servidor fica esperando o contato do cliente. Quando acontece, faz o \"unmarshalling\" dos dados, invoca a fun\u00e7\u00e3o localmente na aplica\u00e7\u00e3o servidor e pega o resultado, que retona ao cliente. Stub servidor espera conex\u00e3o recebe par\u00e2metros recebe especifica\u00e7\u00e3o da fun\u00e7\u00e3o invoca fun\u00e7\u00e3o localmente envia resultado para cliente","title":"Stubs"},{"location":"comm/#transparencia","text":"\u00c9 para o programador a grande vantagem do uso de RPC, pois se pode escrever c\u00f3digo distribu\u00eddo \"igual\" ao centralizado, certo? Isto \u00e9, interface baseada em procedimentos e sem a necessidade de detalhar portas, sockets, e representa\u00e7\u00e3o de dados . Ou seja, tudo \u00e9 transparente! Como j\u00e1 discutimos, v\u00e1rios fatores trabalham contra a transpar\u00eancia em sistemas distribu\u00eddos . Em espec\u00edfico quanto \u00e0 transpar\u00eancia dada pelo RPC, tamb\u00e9m temos limita\u00e7\u00f5es. O problema \u00e9 que h\u00e1 uma distin\u00e7\u00e3o clara em pelo menos dois processos e se pensarmos no c\u00f3digo descrito acima, temos que entender que processos independentes n\u00e3o compartilham um espa\u00e7o de endere\u00e7amento, e processos independentes n\u00e3o compartilham uma pilha. Assim, como fica a passagem de par\u00e2metro por refer\u00eancia , uma vez que o stub servidor n\u00e3o pode usar endere\u00e7os do espa\u00e7o de endere\u00e7amento do cliente? Algumas abordagens para simular a passagem por refer\u00eancia s\u00e3o poss\u00edveis. Por exemplo, o valor apontado pelo ponteiro \u00e9 passado para o servidor , que armazena o valor e alguma posi\u00e7\u00e3o de mem\u00f3ria e passa o endere\u00e7o de tal posi\u00e7\u00e3o para a fun\u00e7\u00e3o invocada. Contudo, a modifica\u00e7\u00e3o do valor pela fun\u00e7\u00e3o n\u00e3o reflete imediatamente no invocador; tais valores tem que ser copiados novamente e usados para sobrescrever o valor original no cliente. Al\u00e9m disso, esta abordagem s\u00f3 \u00e9 poss\u00edvel se o valor apontado for delimitado, o que nem sempre \u00e9 f\u00e1cil de determinar. Por exemplo, se o ponteiro for para o primeiro elemento de uma lista, o que deve ser copiado para o servidor? S\u00f3 o primeiro elemento? Toda a lista? Como ensinar para o framework RPC o que \u00e9 \"toda\" a lista? Java \"resolve\" o problema da passagem de par\u00e2metro por refer\u00eancia passando todo o grafo do objeto passado como par\u00e2metro para o servidor. Isto \u00e9, al\u00e9m de serializar o objeto apontado no par\u00e2metro, se o mesmo aponta para outros objetos, estes tamb\u00e9m ser\u00e3o serializados e transferidos; o servidor ir\u00e1 ent\u00e3o reconstruir todo o grafo e passar para o m\u00e9todo sendo invocado. \u00c9 muito f\u00e1cil ver que esta abordagem pode se tornar invi\u00e1vel rapidamente. Quando for o caso, Java permite marcar objetos como remotos e, em vez de serializar este objeto e enviar para o servidor, envia informa\u00e7\u00e3o suficiente para que o servidor possa invocar m\u00e9todos em tal objeto no cliente, tornando nebulosa a defini\u00e7\u00e3o de quem \u00e9 quem. Outros fatores tamb\u00e9m trabalham contra a transpar\u00eancia para o desenvolvedor. Vejamos alguns","title":"Transpar\u00eancia"},{"location":"comm/#descoberta-de-servicos","text":"Por exemplo, mesmo que o socket seja ocultado, ele ainda existe e precisa de informa\u00e7\u00f5es sobre onde se conectar (endere\u00e7o e porta), que de alguma forma deve ser passada para o framework de RPC. Esta informa\u00e7\u00e3o pode ser configurada a priori por um administrador de sistemas, mas requer atualiza\u00e7\u00f5es sempre que a localiza\u00e7\u00e3o do servi\u00e7o for alterada ou novos servidores adicionados. Mais interessante seria um mecanismo que permitisse uma indire\u00e7\u00e3o para o servi\u00e7o; o pr\u00f3prio DNS pode ser uma op\u00e7\u00e3o inicial, mas um servi\u00e7o dedicado pode ser mais apropriado, pois permite descobrir servi\u00e7os e n\u00e3o apenas servidores. Birrel e Nelson propuseram um servi\u00e7o de P\u00e1ginas Amarelas , no qual clientes podem questionar quem oferece um certo servi\u00e7o e serem redirecionados automaticamente. Esta abordagem tem seus pr\u00f3prios problemas, como por exemplo determinar quem administra o servi\u00e7o para incluir novos servidores. E como determinar qual servi\u00e7o acessar, caso hajam m\u00faltiplas op\u00e7\u00f5es de servidores . Apesar dos problemas, p\u00e1ginas amarelas foram usadas em abordagens muito mais recentes para descobertas de servi\u00e7os, por exemplo Web Services Discovery , que permite a descoberta de Web Services em escala global, e Java Remote Object Registry que permite a descoberta de objetos remotos Java.","title":"Descoberta de Servi\u00e7os"},{"location":"comm/#tratamento-de-excecoes","text":"Uma vez que a invoca\u00e7\u00e3o \u00e9 remota, h\u00e1 sempre o risco de problemas de comunica\u00e7\u00e3o entre cliente e servidor. Logo, \u00e9 necess\u00e1ria a introdu\u00e7\u00e3o de c\u00f3digo para tratamento de erros deste tipo, o que absolutamente n\u00e3o era necess\u00e1rio no caso do c\u00f3digo centralizado. Assim, o que era um simples x = substring(a,3,\"teste\"); passa para algo assim (em uma linguagem fict\u00edcia): int x = -2; try { x = substring(a,3,\"teste\");` } catch(CommunicationFailureException cfe) { log_error(\"Como pode substring falhar? Desespero!!!\"); } if (x == -2) system_exit(-2) else if (x == -1) //n\u00e3o achou else //achou \"teste\" na posi\u00e7\u00e3o x O que nos leva novamente ao ponto sobre n\u00e3o haver transpar\u00eancia total em sistemas distribu\u00eddos... e esta falta de transpar\u00eancia pode ser muito mais complicada do que simplesmente adicionar try e catch ao seu c\u00f3digo. Mais que isso, imagine que a opera\u00e7\u00e3o sendo executada altere algum estado no servidor. Se esta fosse uma operac\u00e3o local, cada invoca\u00e7\u00e3o da opera\u00e7\u00e3o corresponderia a exatamente uma execu\u00e7\u00e3o da opera\u00e7\u00e3o, na aus\u00eancia de falhas. No caso de falhas, se o processo quebra como um todo, no seu rein\u00edcio, pode-se identificar se a opera\u00e7\u00e3o foi ou n\u00e3o executada e aplicar a\u00e7\u00f5es corretivas. Mas e no caso remoto?","title":"Tratamento de Exce\u00e7\u00f5es"},{"location":"comm/#reexecucoes","text":"No caso da opera\u00e7\u00e3o distribu\u00edda, se o servidor quebra, isso levar\u00e1 a um erro ser percebido do lado do cliente como uma falha na conex\u00e3o . Se o cliente havia invocado uma opera\u00e7\u00e3o mas percebeu o erro antes de receber uma confirma\u00e7\u00e3o de sua execu\u00e7\u00e3o, isto pode indicar que: (i) ou a requisi\u00e7\u00e3o nunca foi recebida pelo servidor e, portanto, n\u00e3o foi executada, (ii) ou a execu\u00e7\u00e3o foi recebida e executada, mas a resposta n\u00e3o foi enviada. O cliente tem que tratar o erro, mas como? Se a opera\u00e7\u00e3o precisa ser executada a qualquer custo , o cliente pode retent\u00e1-la quando conseguir novo contato com o servidor (ou mesmo com outro). Neste caso, se o que de fato aconteceu foi a situa\u00e7\u00e3o (i), ent\u00e3o retentar garantir\u00e1 que a opera\u00e7\u00e3o seja executada pelo servidor, mesmo que v\u00e1rias tentativas sejam necess\u00e1rias. Contudo, se o que o ocorreu foi a situa\u00e7\u00e3o (ii), ent\u00e3o reenviar a opera\u00e7\u00e3o levar\u00e1 a mesma a ser executada m\u00faltiplas vezes, o que pode ou n\u00e3o ser ok. Esta abordagem \u00e9 garantir\u00e1 que a execu\u00e7\u00e3o acontece pelo menos 1 vez . Imagine que a opera\u00e7\u00e3o se tratasse de uma transfer\u00eancia de saldo, ou a encomenda de de um caminh\u00e3o carregado de algum produto caro. Neste caso, reexecutar n\u00e3o parece ser uma op\u00e7\u00e3o. Neste caso, talvez a melhor op\u00e7\u00e3o seja n\u00e3o retentar a opera\u00e7\u00e3o, o que levar\u00e1 a zero execu\u00e7\u00f5es na situa\u00e7\u00e3o (ii) e uma execu\u00e7\u00e3o na situa\u00e7\u00e3o, ou seja, a no m\u00e1ximo uma execu\u00e7\u00e3o. Uma situa\u00e7\u00e3o em que esta abordagem \u00e9 claramente prefer\u00edvel \u00e9 a entrega de quadros em um stream de v\u00eddeo ou \u00e1udio, devido \u00e0 import\u00e2ncia da opera\u00e7\u00e3o ser atrelada ao momento de sua execu\u00e7\u00e3o. Nenhuma destas abordagens \u00e9 igual ao que \u00e9 garantido na vers\u00e3o centralizada e que \u00e9 provelmente o que todo desenvolvedor desejaria para suas invoca\u00e7\u00f5es de m\u00e9todos, que fossem executados exatamente uma vez. Garantir esta sem\u00e2ntica na comunica\u00e7\u00e3o \u00e9 muito dif\u00edcil, pois \u00e9 imposs\u00edvel ter certeza de que uma mensagem n\u00e3o foi processada pelo servidor ainda. De fato, \u00e9 imposs\u00edvel ter certeza se o servidor falhou; pode ter sido apenas uma falha na comunica\u00e7\u00e3o. Quantidade de execu\u00e7\u00f5es No m\u00e1ximo uma - n\u00e3o retentar Exatamente uma - impedir que falhas aconte\u00e7am :/ Pelo menos uma - retentar at\u00e9 ter confirma\u00e7\u00e3o Como \u00e9 imposs\u00edvel evitar falhas, se uma opera\u00e7\u00e3o deve executada, ela deve ser retentada. Mas ela n\u00e3o pode ser repetida, ent\u00e3o a alternativa \u00e9 tornar as opera\u00e7\u00f5es idempotentes , o que quer dizer que o efeito desejado \u00e9 alcan\u00e7ado pela primeira execu\u00e7\u00e3o e que execu\u00e7\u00f5es seguintes n\u00e3o alteram o estado. Opera\u00e7\u00f5es idempotentes M\u00faltiplas execu\u00e7\u00f5es tem o mesmo efeito uma execu\u00e7\u00e3o. Exemplo: x = 10 Anti-exemplo: x = x+1 . Infelizmente n\u00e3o \u00e9 trivial programar para idempot\u00eancia, principalmente se o servidor for acessado concorrentemente por m\u00faltiplos clientes, tornando seu estado uam regi\u00e3o cr\u00edtica.","title":"Reexecu\u00e7\u00f5es"},{"location":"comm/#concorrencia-no-servidor","text":"\u00c9 importante notar que um servidor n\u00e3o est\u00e1 obrigado a atender requisi\u00e7\u00f5es de somente um cliente. Logo, se m\u00faltiplos clientes acessam o mesmo servidor, o estado do servidor ser\u00e1 \"compartilhado\" pelos v\u00e1rios clientes e passos s\u00e3o necess\u00e1rios para que o comportamento no acesso deste estado seja coerente com a especifica\u00e7\u00e3o. Pense por exemplo em um servidor que conta o n\u00famero de acessos feitos por clientes. O incremento do contador deve ser considerado uma regi\u00e3o cr\u00edtica, caso m\u00faltiplos threads tratem as requisi\u00e7\u00f5es dos clientes, o que j\u00e1 vimos ser uma boa idia. Claro que dificilmente seu servidor seria algo t\u00e3o simples assim. Em vez disso, ele provavelmente executar\u00e1 l\u00f3gicas complicadas, como por exemplo, armazenar o estado de contas banc\u00e1rias e, neste caso, as fun\u00e7\u00f5es expostas por RPC incluir\u00edam a opera\u00e7\u00e3o transferir saldo de A para B , o que nos leva a mais um problema interessante, o do risco de reexecu\u00e7\u00f5es. Al\u00e9m disso, o servidor provavelmente suportar\u00e1 diversas opera\u00e7\u00f5es e por isso dever\u00e1 identificar qual a opera\u00e7\u00e3o sendo requisitada. Isto \u00e9 feito por um dispatcher , que demultiplexa as opera\u00e7\u00f5es requisitadas; o dispatcher pode, em algumas arquiteturas, ser independente do skeleton em si.","title":"Concorr\u00eancia no servidor"},{"location":"comm/#frameworks","text":"H\u00e1 diversas op\u00e7\u00f5e de frameworks para RPC, com diferentes caracter\u00edsticas, focos, e garantias. Alguns s\u00e3o parte da linguagem e outros s\u00e3o implementados como bibliotecas. Alguns suportam m\u00faltiplas linguagens e alguns apenas uma. Suporte a RPC na linguagem Sem RPC: C, C++, Java < 5.0 (1.5), Python Com RPC: Java, Go, Erlang, Scala, Haskell Ambientes heterog\u00eaneos: Thrift, gRPC, Akka, SOAP Frameworks mais modernos permitem escolher a forma de serializa\u00e7\u00e3o dos dados, se leg\u00edvel para humanos ou bin\u00e1rio, se o transporte \u00e9 via HTTP ou protocolo mais baixo n\u00edvel, se os dados trafegam abertamente ou se faz uso de comunica\u00e7\u00e3o criptografada (SSL). Outros permitem escolher sem\u00e2ntica de execu\u00e7\u00e3o entre no m\u00e1ximo uma e pelo menos uma , e h\u00e1 at\u00e9 quem prometa exatamente uma . Mas todos os frameworks tem algumas caracter\u00edsticas em comum e uma delas \u00e9 o uso de uma Linguagem de Defini\u00e7\u00e3o de Interface (IDL).","title":"Frameworks"},{"location":"comm/#interface-definition-language-idl","text":"Uma IDL \u00e9 a linguagem pela qual desenvolvedor define quais as opera\u00e7\u00f5es (fun\u00e7\u00f5es, procedimentos, m\u00e9todos) ser\u00e3o acess\u00edveis via RPC e quais os seus operandos. H\u00e1 v\u00e1rias IDL definidas, para os diversos frameworks dispon\u00edveis. A imagem a seguir mostra um exemplo gen\u00e9rico da cria\u00e7\u00e3o cliente e servidor usando um framework RPC gen\u00e9rico, inclusive o processamento da defini\u00e7\u00e3o feita em IDL do servi\u00e7o e a jun\u00e7\u00e3o deste c\u00f3digo gerado ao c\u00f3digo escrito pelo desenvolvedor. O fluxo de processamento \u00e9 o seguinte: Arquivo em IDL \u00e9 compilado por um compilador IDL e gera diversos arquivos: stub cliente - c\u00f3digo que implementa a interface, com c\u00f3digo para repassar invoca\u00e7\u00f5es para o servidor. stub servidor ( skeleton ) - c\u00f3digo que atende a conex\u00f5es do stub cliente e repassa para a implementa\u00e7\u00e3o pr\u00f3pria da fun\u00e7\u00e3o. convers\u00e3o de dados - c\u00f3digo que serializa e deserializa dados para serem trafegados de e para o servidor cabe\u00e7alhos - defini\u00e7\u00f5es da interface na linguagem de desenvolvimento da aplica\u00e7\u00e3o; se linguagem C, por exemplo, estes ser\u00e3o arquivos .h , se em Java, ent\u00e3o estes ser\u00e3o arquivos .java , com defini\u00e7\u00e3o de interface . O c\u00f3digo cliente \u00e9 compilado e gera o cliente, que deve inicializar a infraestrutura RPC Tipo de transporte SSL? Localizar servidor Lidar com falhas O c\u00f3digo servidor \u00e9 compilado e gera o servidor, que deve exportar e localizar servi\u00e7os (servi\u00e7o de nomea\u00e7\u00e3o) Gerenciamento de portas Conex\u00f5es Mas para entendermos melhor o fluxo, vejamos algumas ferramentas reais.","title":"Interface Definition Language - IDL"},{"location":"comm/#estudo-de-caso-rpc-grpc","text":"gRPC \u00e9 um framework para invoca\u00e7\u00e3o remota de procedimentos multi-linguagem e sistema operacional, usando internamente pelo Google h\u00e1 v\u00e1rios anos para implementar sua arquitetura de micro-servi\u00e7os. Inicialmente desenvolvido pelo Google, o gRPC \u00e9 hoje de c\u00f3digo livre encubado pela Cloud Native Computing Foundation. O s\u00edtio https://grpc.io documenta muito bem o gRPC, inclusive os princ\u00edpios que nortearam seu projeto. O seu uso segue, em linhas gerais, o modelo discutido nas se\u00e7\u00f5es anteriores, isto \u00e9, inicia-se pela defini\u00e7\u00e3o de estruturas de dados e servi\u00e7os, \"compila-se\" a defini\u00e7\u00e3o para gerar stubs na linguagem desejada, e compila-se os stubs juntamente com os c\u00f3digos cliente e servidor para gerar os bin\u00e1rios correspondentes. Vejamos a seguir um tutorial passo a passo, em Java, baseado no quickstart guide .","title":"Estudo de Caso RPC: gRPC"},{"location":"comm/#instalacao","text":"Os procedimentos de instala\u00e7\u00e3o dependem da linguagem em que pretende usar o gRPC, tanto para cliente quanto para servidor. No caso do Java , n\u00e3o h\u00e1 instala\u00e7\u00e3o propriamente dita .","title":"Instala\u00e7\u00e3o"},{"location":"comm/#exemplo-java","text":"Observe que o reposit\u00f3rio base apontado no tutorial serve de exemplo para diversas linguagens e diversos servi\u00e7os, ent\u00e3o sua estrutura \u00e9 meio complicada. N\u00f3s nos focaremos aqui no exemplo mais simples, uma esp\u00e9cie de \"hello word\" do RPC.","title":"Exemplo Java"},{"location":"comm/#pegando-o-codigo","text":"Para usar os exemplos, voc\u00ea precisa clonar o reposit\u00f3rio com o tutorial, usando o comando a seguir. git clone -b v1.19.0 https://github.com/grpc/grpc-java Uma vez clonado, entre na pasta de exemplo do Java e certifique-se que est\u00e1 na vers\u00e3o 1.19, usada neste tutorial. cd grpc-java\\examples git checkout v1.19.0","title":"Pegando o c\u00f3digo"},{"location":"comm/#compilando-e-executando","text":"O projeto usa gradle para gerenciar as depend\u00eancias. Para, use o wrapper do gradle como se segue. ./gradlew installDist Caso esteja na UFU, coloque tamb\u00e9m informa\u00e7\u00e3o sobre o proxy no comando. ./gradlew -Dhttp.proxyHost=proxy.ufu.br -Dhttp.proxyPort=3128 -Dhttps.proxyHost=proxy.ufu.br -Dhttps.proxyPort=3128 installDist Como quando usamos sockets diretamente, para usar o servi\u00e7o definido neste exemplo, primeiros temos que executar o servidor. ./build/install/examples/bin/hello-world-server Agora, em um terminal distinto e a partir da mesma localiza\u00e7\u00e3o, execute o cliente, quantas vezes quiser. ./build/install/examples/bin/hello-world-client","title":"Compilando e executando"},{"location":"comm/#o-servico","text":"O exemplo n\u00e3o \u00e9 muito excitante, pois tudo o que o servi\u00e7o faz \u00e9 enviar uma sauda\u00e7\u00e3o aos clientes. O servi\u00e7o \u00e9 definido no seguinte arquivo .proto , localizado em ./src/main/proto/helloworld.proto . message HelloRequest { string name = 1; } message HelloReply { string message = 1; } // The greeting service definition. service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {} } No arquivo, inicialmente s\u00e3o definidas duas mensagens, usadas como requisi\u00e7\u00e3o (cliente para servidor) e outra como resposta (servidor para cliente) do servi\u00e7o definido em seguida. A mensagem HelloRequest tem apenas um campo denominado name , do tipo string . Esta mensagem conter\u00e1 o nome do cliente, usado na resposta gerada pelo servidor. A mensagem HelloReply tamb\u00e9m tem um campo do tipo string , denominado message , que conter\u00e1 a resposta do servidor. O servi\u00e7o dispon\u00edvel \u00e9 definido pela palavra chave service e de nome Greeter ; \u00e9 importante entender que este nome ser\u00e1 usado em todo o c\u00f3digo gerado pelo compilador gRPC e que se for mudado, todas as refer\u00eancias ao c\u00f3digo gerado devem ser atualizadas. O servi\u00e7o possui apenas uma opera\u00e7\u00e3o, SayHello , que recebe como entrada uma mensagem HelloRequest e gera como resposta uma mensagem HelloReply . Caso a opera\u00e7\u00e3o precisasse de mais do que o conte\u00fado de name para executar, a mensagem HelloRequest deveria ser estendida, pois n\u00e3o h\u00e1 passar mais de uma mensagem para a opera\u00e7\u00e3o. Por outro lado, embora seja poss\u00edvel passar zero mensagens, esta n\u00e3o \u00e9 uma pr\u00e1tica recomendada. Isto porqu\u00ea caso o servi\u00e7o precisasse ser modificado no futuro, embora seja poss\u00edvel estender uma mensagem, n\u00e3o \u00e9 poss\u00edvel modificar a assinatura do servi\u00e7o. Assim, caso n\u00e3o haja a necessidade de se passar qualquer informa\u00e7\u00e3o para a opera\u00e7\u00e3o, recomenda-se que seja usada uma mensagem de entrada vazia, que poderia ser estendida no futuro. O mesmo se aplica ao resultado da opera\u00e7\u00e3o. Observe tamb\u00e9m que embora o servi\u00e7o de exemplo tenha apenas uma opera\u00e7\u00e3o, poderia ter m\u00faltiplas. Por exemplo, para definir uma vers\u00e3o em portugu\u00eas da opera\u00e7\u00e3o SayHello , podemos fazer da seguinte forma. message HelloRequest { string name = 1; } message HelloReply { string message = 1; } message OlaRequest { // <<<<<==== string name = 1; } message OlaReply { // <<<<<==== string message = 1; } service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) {} rpc DigaOla (OlaRequest) returns (OlaReply) {}// <<<<<==== } ... Observe que a nova opera\u00e7\u00e3o recebe como entrada mensagens OlaRequest e OlaReply , que tem defini\u00e7\u00f5es exatamente iguais a HellorRequest e HelloReply . Logo, em vez de definir novas mensagens, poder\u00edamos ter usado as j\u00e1 definidas. Novamente, esta n\u00e3o \u00e9 uma boa pr\u00e1tica, pois caso fosse necess\u00e1rio evoluir uma das opera\u00e7\u00f5es para atender a novos requisitos e estender suas mensagens, n\u00e3o ser\u00e1 necess\u00e1rio tocar o restante do servi\u00e7o. Apenas refor\u00e7ando, \u00e9 boa pr\u00e1tica definir requests e responses para cada m\u00e9todo, a n\u00e3o ser que n\u00e3o haja d\u00favida de que ser\u00e3o para sempre iguais.","title":"O servi\u00e7o"},{"location":"comm/#implementando-um-servico","text":"Agora modifique o arquivo .proto como acima, para incluir a opera\u00e7\u00e3o DigaOla , recompile e reexecute o servi\u00e7o. N\u00e3o d\u00e1 certo, n\u00e3o \u00e9 mesmo? Isto porqu\u00ea voc\u00ea adicionou a defini\u00e7\u00e3o de uma nova opera\u00e7\u00e3o, mas n\u00e3o incluiu o c\u00f3digo para implement\u00e1-la. Fa\u00e7amos ent\u00e3o a modifica\u00e7\u00e3o do c\u00f3digo, come\u00e7ando por ./src/main/java/io/grpc/examples/helloworld/HelloWorldServer.java . Este arquivo define a classe que implementa o servi\u00e7o Greeter , GreeterImpl , com um m\u00e9todo para cada uma das opera\u00e7\u00f5es definidas. Para confirmar, procure por sayHello para encontrar a implementa\u00e7\u00e3o de SayHello ; observe que a diferen\u00e7a do casing vem das boas pr\u00e1ticas de Java, de definir m\u00e9todos e vari\u00e1veis em Camel casing . Para que sua vers\u00e3o estendida do servi\u00e7o Greeter funcione, defina um m\u00e9todo correspondendo \u00e0 DigaOla , sem consultar o c\u00f3digo exemplo abaixo, mas usando o c\u00f3digo de sayHello como base; n\u00e3o se importe por enquanto com os m\u00e9todos sendo invocados. Note que os ... indicam que parte do c\u00f3digo, que n\u00e3o sofreu modifica\u00e7\u00f5es, foi omitido. ... private class GreeterImpl extends GreeterGrpc.GreeterImplBase { ... @Override public void sayHello(HelloRequest req, StreamObserver<HelloReply> responseObserver) { ... } @Override public void digaOla(OlaRequest req, StreamObserver<OlaReply> responseObserver) { OlaReply reply = OlaReply.newBuilder().setMessage(\"Ola \" + req.getName()).build(); responseObserver.onNext(reply); responseObserver.onCompleted(); } } Se voc\u00ea recompilar e reexecutar o c\u00f3digo, n\u00e3o perceber\u00e1 qualquer mudan\u00e7a na sa\u00edda do programa. Isto porqu\u00ea embora tenha definido um novo servi\u00e7o, voc\u00ea n\u00e3o o utilizou. Para tanto, agora modifique o cliente, em src/main/java/io/grpc/examples/helloworld/HelloWorldClient.java , novamente se baseando no c\u00f3digo existente e n\u00e3o se preocupando com \"detalhes\". public void greet(String name) { logger.info(\"Will try to greet \" + name + \" ...\"); ... OlaRequest request2 = OlaRequest.newBuilder().setName(name).build(); OlaReply response2; try { response2 = blockingStub.digaOla(request2); } catch (StatusRuntimeException e) { logger.log(Level.WARNING, \"RPC failed: {0}\", e.getStatus()); return; } logger.info(\"Greeting: \" + response2.getMessage()); } Agora sim, voc\u00ea pode reexecutar cliente e servidor. ./gradlew installDist ./build/install/examples/bin/hello-world-server & ./build/install/examples/bin/hello-world-client Percebeu como foi f\u00e1cil adicionar uma opera\u00e7\u00e3o ao servi\u00e7o? Agora nos foquemos nos detalhes.","title":"Implementando um servi\u00e7o"},{"location":"comm/#stub-do-servidor","text":"Como criar o servidor Como definir o servi\u00e7o Como \"startar\" o servidor.","title":"Stub do servidor"},{"location":"comm/#stub-do-cliente","text":"Stub bloqueante Stub n\u00e3o bloqueante","title":"Stub do cliente"},{"location":"comm/#idl-grpc","text":"Outras caracter\u00edsticas da IDL do gRPC Tipos b\u00e1sicos bool: boolean (true/false) double: 64-bit; ponto-flutuante float: 32-bit; ponto-flutuante i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado siXX: signed uiXX: unsigned sfixedXX: codifica\u00e7\u00e3o de tamanho fixo bytes: 8-bit; inteiro sinalizado string: string UTF-8 ou ASCII 7-bit Any: tipo indefinido Diferentes tradu\u00e7\u00f5es Cole\u00e7\u00f5es Defina e implemente uma opera\u00e7\u00e3o DigaOlas em que uma lista de nomes \u00e9 enviada ao servidor e tal que o servidor responda com uma longa string cumprimentando todos os nomes, um ap;os o outro. Streams Do lado do servidor ```java List listOfHi = Arrays.asList(\"e aih\", \"ola\", \"ciao\", \"bao\", \"howdy\", \"s'up\"); @Override public void digaOlas(OlaRequest req, StreamObserver responseObserver) { for (String hi: listOfHi) { OlaReply reply = OlaReply.newBuilder().setMessage(hi + \", \" req.getName()).build(); responseObserver.onNext(reply); } responseObserver.onCompleted(); } ``` - Do lado do cliente java OlaRequest request = OlaRequest.newBuilder().setName(name).build(); try { Iterator<OlaReply> it = blockingStub.digaOlas(request); while (it.hasNext()){ OlaReply response = it.next(); logger.info(\"Greeting: \" + response.getMessage()); } } catch (StatusRuntimeException e) { logger.log(Level.WARNING, \"RPC failed: {0}\", e.getStatus()); return; }","title":"IDL gRPC"},{"location":"comm/#exemplo-python","text":"apt-get install python3 apt-get install python3-pip python3 -m pip install --upgrade pip python3 -m pip install grpcio python3 -m pip install grpcio-tools git clone -b v1.10.x https://github.com/grpc/grpc cd grpc/examples/python/helloworld python3 greeter\\_server.py python3 greeter\\_client.py Para recompilar os stubs, fa\u00e7a python3 -m grpc_tools.protoc -I../../protos --python_out=. --grpc_python_out=. ../../protos/helloworld.proto Modifique o servidor def DigaOla(self, request, context): return helloworld_pb2.OlaReply(message='Ola, %s!' + request.name) Modifique o cliente response = stub.DigaOla(helloworld_pb2.OlaRequest(name='zelelele')) print(\"Greeter client received: \" + response.message)","title":"Exemplo Python"},{"location":"comm/#estudo-de-caso-rpc-thrift","text":"Thrift","title":"Estudo de Caso RPC: Thrift"},{"location":"comm/#instalacao_1","text":"Baixe e compile o thrift ou instale-o usando apt-get, por exemplo. apt-get install thrift-compiler execute \"thrift\" na linha de comando. Para thrift com Java, tamb\u00e9m precisar\u00e3o dos seguintes arquivos slf4j libthrift0.9.3.jar coloque-os na pasta jars","title":"Instala\u00e7\u00e3o"},{"location":"comm/#idl-thrift","text":"Tipos b\u00e1sicos bool: boolean (true/false) byte: 8-bit; inteiro sinalizado i16: 16-bit; inteiro sinalizado i32: 32-bit; inteiro sinalizado i64: 64-bit; inteiro sinalizado double: 64-bit; ponto-flutuante string: string UTF-8 binary: sequ\u00eancia de bytes Estruturas struct Example { 1:i32 number, 2:i64 bigNumber, 3:double decimals, 4:string name=\"thrifty\" } Servi\u00e7os service ChaveValor { void set(1:i32 key, 2:string value), string get(1:i32 key) throws (1:KeyNotFound knf), void delete(1:i32 key) } N\u00e3o se pode retornar NULL!!! Exce\u00e7\u00f5es exception KeyNotFound { 1:i64 hora r, 2:string chaveProcurada=\"thrifty\" } Containers List Map Set Exemplo: chavevalor.thrift namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV(1:i32 key) throws (1:KeyNotFound knf), bool setKV(1:i32 key, 2:string value), void delKV(1:i32 key) } Compila\u00e7\u00e3o thrift --gen java chavevalor.thrift thrift --gen py chavevalor.thrift ChaveValorHandler.java namespace java chavevalor namespace py chavevalor exception KeyNotFound { } service ChaveValor { string getKV(1:i32 key) throws (1:KeyNotFound knf), bool setKV(1:i32 key, 2:string value), void delKV(1:i32 key) } package chavevalor; import org.apache.thrift.TException; import java.util.HashMap; import chavevalor.*; public class ChaveValorHandler implements ChaveValor.Iface { private HashMap<Integer,String> kv = new HashMap<>(); @Override public String getKV(int key) throws TException { if(kv.containsKey(key)) return kv.get(key); else throw new KeyNotFound(); } @Override public boolean setKV(int key, String valor) throws TException { kv.put(key,valor); return true; } @Override public void delKV(int key) throws TException { kv.remove(key); } }","title":"IDL Thrift"},{"location":"comm/#arquitetura","text":"Runtime library -- componentes podem ser selecionados em tempo de execu\u00e7\u00e3o e implementa\u00e7\u00f5es podem ser trocadas Protocol -- respons\u00e1vel pela serializa\u00e7\u00e3oo dos dados TBinaryProtocol TJSONProtocol TDebugProtocol ... Transport -- I/O no ``fio'' TSocket TFramedTransport (non-blocking server) TFileTransport TMemoryTransport Processor -- Conecta protocolos de entrada e sa\u00edda com o \\emph{handler} Handler -- Implementa\u00e7\u00e3o das opera\u00e7\u00f5es oferecidas Server -- Escuta portas e repassa dados (protocolo) para o processors TSimpleServer TThreadPool TNonBlockingChannel","title":"Arquitetura"},{"location":"comm/#classpath","text":"javac -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java -d . *.java java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorServer java -cp jars/libthrift0.9.3.jar:jars/slf4japi1.7.21.jar:gen-java:. chavevalor.ChaveValorClient","title":"Classpath"},{"location":"comm/#referencias","text":"Tutorial","title":"Refer\u00eancias"},{"location":"comm/#estudo-de-caso-rpc-rmi","text":"","title":"Estudo de Caso RPC: RMI"},{"location":"comm/#comunicacao-orientada-a-mensagens","text":"","title":"Comunica\u00e7\u00e3o orientada a Mensagens"},{"location":"coordenacao/0_intro/","text":"Neste cap\u00edtulo discutimos problemas ligados \u00e0 coordena\u00e7\u00e3o de processos em um sistema distribu\u00eddo.","title":"Coordena\u00e7\u00e3o"},{"location":"coordenacao/1_mutex/","text":"Coordena\u00e7\u00e3o Exclus\u00e3o M\u00fatua Como visto em Concorr\u00eancia , diversas tarefas exigem coordena\u00e7\u00e3o entre threads em uma aplica\u00e7\u00e3o centralizada em que se faz uso de concorr\u00eancia para melhor uso de recursos computacionais, obten\u00e7\u00e3o de melhor desempenho, modulariza\u00e7\u00e3o do c\u00f3digo. Sistemas distribu\u00eddos levam a concorr\u00eancia a um novo patamar de complexidade, fazendo uso de m\u00faltiplos processos, cada um com possivelmente m\u00faltiplos threads , ainda por cima, espalhados geograficamente. Contudo, ee em um sistema centralizado, uma vari\u00e1vel global, um lock, ou outra primitiva de sincroniza\u00e7\u00e3o podem ser usadas na sincroniza\u00e7\u00e3o, em um sistema distribu\u00eddo, primitivas simples como estas provavelmente n\u00e3o estar\u00e3o dispon\u00edveis ou o sistema ser\u00e1 muito restrito. Um dos problemas enfrentados \u00e9 o da exclus\u00e3o m\u00fatua. Exclus\u00e3o M\u00fatua Em um sistema distribu\u00eddo, como controlar o acesso de m\u00faltiplos processos a um recurso compartilhado, garantindo que cada processo controla exclusivamente aquele recurso durante seu acesso? Qualquer solu\u00e7\u00e3o que se proponha a este problema problema de exclus\u00e3o m\u00fatua, precisa ter as propriedades 1, 2 e 3, e, idealmente, tamb\u00e9m a 4, a seguir: Exclus\u00e3o M\u00fatua exclus\u00e3o m\u00fatua: somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks : se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o inani\u00e7\u00e3o: todos os processos interessados consguem, em algum momento, acessar o recurso; espera limitada: idealmente, o tempo de espera pelo recurso \u00e9 limitado. H\u00e1 diversas solu\u00e7\u00f5es para exclus\u00e3o m\u00fatua em sistemas distribu\u00eddos, em diversos cen\u00e1rios e com resultados mais ou menos eficientes. Tr\u00eas das mais simples e que ilustram o universo de solu\u00e7\u00f5es s\u00e3o as seguintes: Exclus\u00e3o M\u00fatua - Solu\u00e7\u00f5es Centralizado: Um processo acessa quando um coordenador diz que pode. Anel: Um processo acessa quando estiver com o ``token'' de acesso. Quorum: Um processo acessa quando houver acordo que \u00e9 sua vez. Centralizado Enquanto em um sistema centralizado h\u00e1 um sistema operacional que prov\u00ea abstra\u00e7\u00f5es simples para os processos a serem coordenados, em um sistema distribu\u00eddo, n\u00e3o h\u00e1 esta entidade coordenadora. Uma poss\u00edvel solu\u00e7\u00e3o para o problem de exclus\u00e3o m\u00fatua em um ambiente distribu\u00eddo \u00e9 justamente dar um passo para tr\u00e1s e introduzir um coordenador. Nesta abordagem, o seguinte protocolo \u00e9 implementado: Participante: Envia requisi\u00e7\u00e3o de acesso ao coordenador Espera por resposta do coordenador Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Coordenador Inicializa recurso como livre Ao receber requisi\u00e7\u00e3o enfileira requisi\u00e7\u00e3o Ao receber libera\u00e7\u00e3o, marca recurso como livre Sempre que recurso marcado como livre E fila n\u00e3o vazia: envie libera\u00e7\u00e3o para primeiro da fila e o remova da fila. Centralizado Este algoritmo tem diversas caracter\u00edsticas positivas: Pr\u00f3s Justo: requests s\u00e3o processados em ordem (FCFS) N\u00e3o inani\u00e7\u00e3o Espera limitada F\u00e1cil de implementar, testar, entender Contudo, tem tamb\u00e9m alguns aspectos negativos: Contras Coordenador pode se tornar um gargalo; Como lidar com falhas? Processos n\u00e3o sabem se recurso est\u00e1 bloqueado ou se usu\u00e1rio morreu e n\u00e3o devolveu a permiss\u00e3o; Coordenador pode falhar e congelar o sistema. Estes aspectos nos permitem mergulhar na \u00e1rea de toler\u00e2ncia a falhas, e o faremos, mas mais tarde. Por enquanto, consideraremos toler\u00e2ncia a falhas de forma superficial, ap\u00f3s discutirmos outra abordagem abordagem. Anel Nesta abordagem, os processos se organizam em um anel l\u00f3gico, com um processo antes e outro depois. Um dos processos \u00e9 iniciado com um token , que d\u00e1 acesso ao recurso e o token \u00e9 passado adiante no anel; sempre que estiver de posse do token, o processo pode acessar o recurso. Ou seja, todos os participantes executam o seguinte protocolo: Participante: Ao receber o token de acesso, se quiser acessar o recurso, acessa. Envia o token para o pr\u00f3ximo n\u00f3 do anel. Anel ![Anel](images/06-16.png} Como o algoritmo centralizado, o algoritmo do anel tamb\u00e9m em suas vantagens e desvantagens. Pr\u00f3s Justo: Todos acessam N\u00e3o inani\u00e7\u00e3o Espera limitada F\u00e1cil de implementar, testar, entender Contras Token passado para quem n\u00e3o necessariamente quer acessar; Tempo de espera linear no n\u00famero de processos; Como lidar com falhas? Lidando com falhas usando timeouts Em ambos os algoritmos, centralizado e do anel, se um processo falhar, o algoritmo pode ficar \"travado\". Vejamos alguns casos espec\u00edficos: No algoritmo centralizado, se o coordenador falha antes de liberar o acesso para algum processo, ele leva consigo a permiss\u00e3o. Em ambos os algoritmos, se o processo acessando o recurso falha, a permiss\u00e3o \u00e9 perdida e os demais processos sofrer\u00e3o inani\u00e7\u00e3o. No algoritmo do anel, se qualquer outro processo falha, o anel \u00e9 interrompido o anel n\u00e3o conseguir\u00e1 circular. Observe que nem falamos de falhas dos canais e j\u00e1 temos diversos cen\u00e1rios a serem resolvidos, para os quais se lhes pedir uma solu\u00e7\u00e3o, tenho certeza absoluta de que me ofere\u00e7\u00e3o alguma baseada em timeouts . Por exemplo, se o processo n\u00e3o devolver a permiss\u00e3o de acesso antes de um timeout , ent\u00e3o assuma que o mesmo est\u00e1 falho e gere nova permiss\u00e3o, a ser passada a outros requisitantes. O problema desta e outras \"solu\u00e7\u00f5es\" baseadas em timeouts\" est\u00e1 no assumir que o processo est\u00e1 falho , pois caso isso n\u00e3o seja verdade, teremos agora dois tokens* no sistema, podendo levar \u00e0 viola\u00e7\u00e3o da propriedade de exclus\u00e3o m\u00fatua. Por mais que se ajuste o valor do temporizador, em um sistema distribu\u00eddo ass\u00edncrono, o mesmo pode sempre estar errado. De fato, temos que Impossibilidade de detec\u00e7\u00e3o de falhas Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir um processo falho de um processo lento. Tamb\u00e9m mais tarde discutiremos as implica\u00e7\u00f5es desta impossibilidade. Por agora, pense apenas no seguinte: Pergunta: Qual deve ser um timeout razo\u00e1vel para o meu sistema? A resposta depende de m\u00faltiplos fatores como: ~~Resposta~~ Mais perguntas Qual o custo $E$ de esperar por mais tempo? Qual o custo $C$ de cometer um engano? Qual a probabilidade $p$ de cometer um engano? $C * p < E$ Embora esta an\u00e1lise possa ser feita para estes algoritmos, a verdade \u00e9 que s\u00e3o realmente limitados e outras abordagens seriam melhor destino dos seus esfor\u00e7os. Se o mundo \u00e9 probabil\u00edstico, porqu\u00ea meus algoritmos devem ser determin\u00edsticos?\" Werner Fogels, CTO da Amazon. Uma abordagem probabil\u00edstica interessante \u00e9 baseada em qu\u00f3runs. Qu\u00f3rum De acordo com o Dicion\u00e1rio Priberam da L\u00edngua Portuguesa, consultado em 17-04-2019 , \"qu\u00f3rum\" \u00e9 o \"N\u00famero de pessoas imprescind\u00edvel para a realiza\u00e7\u00e3o de algo.\" Aqui, este este algo ser\u00e1 a libera\u00e7\u00e3o de acesso ao recurso almejado pelos processos no sistema distribu\u00eddo. Esta abordagem \u00e9 semelhante em v\u00e1rios aspectos \u00e0 centralizada. De fato, um dos pap\u00e9is na abordagem \u00e9 o de coordenador, que executa o mesmo protocolo que antes. Quorum - Coordenador Inicializa recurso como livre Ao receber requisi\u00e7\u00e3o enfileira requisi\u00e7\u00e3o Ao receber libera\u00e7\u00e3o, marca recurso como livre Sempre que recurso marcado como livre E fila n\u00e3o vazia: envie libera\u00e7\u00e3o para primeiro da fila e o remova da fila. Entretanto, em vez de apenas um coordenador no sistema, temos $n$, dos quais o participante precisa obter $m > n/2$ autoriza\u00e7\u00f5es antes de acessar o recurso; $m$ \u00e9 o qu\u00f3rum do sistema. Quorum - Qu\u00f3rum $n$ coordenadores. $m > n/2$ coordenadores Quorum - Participante Envia requisi\u00e7\u00e3o de acesso aos $n$ coordenadores Espera por resposta de $m$ coordenadores Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Al\u00e9m disso, para tornamos os problema mais interessante e demonstrar o potencial deste algoritmo, consideremos que as autoriza\u00e7\u00f5es s\u00e3o armazenadas somente em mem\u00f3ria, e que coordenadores, ao falhar e ent\u00e3o resumir suas atividades, esque\u00e7am-se das autoriza\u00e7\u00f5es j\u00e1 atribu\u00eddas. Falhas Quando um coordenador falha, esquece que deu ok e reseta seu estado. Suponha o seguinte cen\u00e1rio: Qu\u00f3rum - Exemplo Coordenadores = {$c_1,c_2,c_3,c_4,c_5,c_6,c_7$} $n = 7$ $m = 4$ Participante $p_1$ consegue autoriza\u00e7\u00e3o de {$c_1,c_2,c_3,c_4$} e entra na regi\u00e3o cr\u00edtica. Coordenador $c_4$ falha e se recupera Participante $p_2$ consegue autoriza\u00e7\u00e3o de {$c_4,c_5,c_6,c_7$} e entra na regi\u00e3o cr\u00edtica. Exclus\u00e3o M\u00fatua \u00e9 violada. Qual a probabilidade $P_v$ desta viola\u00e7\u00e3o ocorrer? C\u00e1lculo de $P_v$ Seja $P$ a probabilidade de um coordenador falhar e se recuperar em $\\delta t$, dentro de uma janela $T$. Probabilidade de falha de exatamente 1 coordenador $P^1(1-P)^{n-1}$ Probabilidade de $k$ coordenadores falharem? $P^k(1-P)^{n-k}$ Probabilidade de quaisquer $k$ em $m$ coordenadores falharem $\\binom{m}{k} P^k(1-P)^{m-k}$ Probabilidade de quaisquer $k$ em $m$ coordenadores falharem $\\binom{m}{k} P^k(1-P)^{m-k}$ Diferentes valores de $k$ que s\u00e3o problem\u00e1ticos? TODO: desenho dos qu\u00f3runs sobrepostos $\\left| A \\cup B\\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cap B \\right| \\Rightarrow n = m + m - k$ $\\left| A \\cap B \\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cup B\\right| \\Rightarrow k = m + m - n = 2m - n$ Probabilidade de quaisquer $k$ em $m$ coordenadores falharem, para qualquer $k$ que seja problem\u00e1tico $P_v = \\sum_{2m-n}^n \\binom{m}{k} P^k(1-P)^{m-k}$ Para facilitar o entendimento desta grandeza, considere o exemplo: Exemplo $p=0.0001$ (1 minuto a cada 10 dias) $n = 32$ $m = 0.75n$ $P_v < 10^{-40}$ ( Curiosidade sobre $10^40$ ) A probabilidade de viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua, neste caso, \u00e9 muito pequena, a despeito de suportar falhas dos coordenadores. Pr\u00f3s Tolera falhas de coordenadores, com probabilidade controlada de viola\u00e7\u00e3o de exclus\u00e3o m\u00fatua Mas e as outras propriedades desej\u00e1veis do algoritmo de exclus\u00e3o m\u00fatua, s\u00e3o alcan\u00e7adas? Relembrando: Exclus\u00e3o M\u00fatua exclus\u00e3o m\u00fatua: somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks : se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o inani\u00e7\u00e3o: todos os processos interessados consguem, em algum momento, acessar o recurso; espera limitada: idealmente, o tempo de espera pelo recurso \u00e9 limitado. Contras Exclus\u00e3o M\u00fatua: $1 - P_v$ N\u00e3o-inani\u00e7\u00e3o E se cada participante obter o ok de um coordenador? Temporizador para quebrar o deadlock ? Espera limitada Aborts podem levar a espera infinita. Assim, este agoritmo tamb\u00e9m pode n\u00e3o ser adequado para certas situa\u00e7\u00f5es. Vamos tentar reacessar os problemas da primeira abordagem. Por um lado, o uso de um l\u00edder para coordenar a\u00e7\u00f5es em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto \u00fanico de falha, como no algoritmo de exclus\u00e3o m\u00fatua centralizado. Mas e se substitu\u00edssemos o coordenador no caso de falhas? Este \u00e9 o problema conhecido como elei\u00e7\u00e3o de l\u00edderes.","title":"Exclus\u00e3o M\u00fatua"},{"location":"coordenacao/1_mutex/#coordenacao","text":"","title":"Coordena\u00e7\u00e3o"},{"location":"coordenacao/1_mutex/#exclusao-mutua","text":"Como visto em Concorr\u00eancia , diversas tarefas exigem coordena\u00e7\u00e3o entre threads em uma aplica\u00e7\u00e3o centralizada em que se faz uso de concorr\u00eancia para melhor uso de recursos computacionais, obten\u00e7\u00e3o de melhor desempenho, modulariza\u00e7\u00e3o do c\u00f3digo. Sistemas distribu\u00eddos levam a concorr\u00eancia a um novo patamar de complexidade, fazendo uso de m\u00faltiplos processos, cada um com possivelmente m\u00faltiplos threads , ainda por cima, espalhados geograficamente. Contudo, ee em um sistema centralizado, uma vari\u00e1vel global, um lock, ou outra primitiva de sincroniza\u00e7\u00e3o podem ser usadas na sincroniza\u00e7\u00e3o, em um sistema distribu\u00eddo, primitivas simples como estas provavelmente n\u00e3o estar\u00e3o dispon\u00edveis ou o sistema ser\u00e1 muito restrito. Um dos problemas enfrentados \u00e9 o da exclus\u00e3o m\u00fatua.","title":"Exclus\u00e3o M\u00fatua"},{"location":"coordenacao/1_mutex/#exclusao-mutua_1","text":"Em um sistema distribu\u00eddo, como controlar o acesso de m\u00faltiplos processos a um recurso compartilhado, garantindo que cada processo controla exclusivamente aquele recurso durante seu acesso? Qualquer solu\u00e7\u00e3o que se proponha a este problema problema de exclus\u00e3o m\u00fatua, precisa ter as propriedades 1, 2 e 3, e, idealmente, tamb\u00e9m a 4, a seguir:","title":"Exclus\u00e3o M\u00fatua"},{"location":"coordenacao/1_mutex/#exclusao-mutua_2","text":"exclus\u00e3o m\u00fatua: somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks : se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o inani\u00e7\u00e3o: todos os processos interessados consguem, em algum momento, acessar o recurso; espera limitada: idealmente, o tempo de espera pelo recurso \u00e9 limitado. H\u00e1 diversas solu\u00e7\u00f5es para exclus\u00e3o m\u00fatua em sistemas distribu\u00eddos, em diversos cen\u00e1rios e com resultados mais ou menos eficientes. Tr\u00eas das mais simples e que ilustram o universo de solu\u00e7\u00f5es s\u00e3o as seguintes:","title":"Exclus\u00e3o M\u00fatua"},{"location":"coordenacao/1_mutex/#exclusao-mutua-solucoes","text":"Centralizado: Um processo acessa quando um coordenador diz que pode. Anel: Um processo acessa quando estiver com o ``token'' de acesso. Quorum: Um processo acessa quando houver acordo que \u00e9 sua vez.","title":"Exclus\u00e3o M\u00fatua - Solu\u00e7\u00f5es"},{"location":"coordenacao/1_mutex/#centralizado","text":"Enquanto em um sistema centralizado h\u00e1 um sistema operacional que prov\u00ea abstra\u00e7\u00f5es simples para os processos a serem coordenados, em um sistema distribu\u00eddo, n\u00e3o h\u00e1 esta entidade coordenadora. Uma poss\u00edvel solu\u00e7\u00e3o para o problem de exclus\u00e3o m\u00fatua em um ambiente distribu\u00eddo \u00e9 justamente dar um passo para tr\u00e1s e introduzir um coordenador. Nesta abordagem, o seguinte protocolo \u00e9 implementado: Participante: Envia requisi\u00e7\u00e3o de acesso ao coordenador Espera por resposta do coordenador Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Coordenador Inicializa recurso como livre Ao receber requisi\u00e7\u00e3o enfileira requisi\u00e7\u00e3o Ao receber libera\u00e7\u00e3o, marca recurso como livre Sempre que recurso marcado como livre E fila n\u00e3o vazia: envie libera\u00e7\u00e3o para primeiro da fila e o remova da fila.","title":"Centralizado"},{"location":"coordenacao/1_mutex/#centralizado_1","text":"Este algoritmo tem diversas caracter\u00edsticas positivas:","title":"Centralizado"},{"location":"coordenacao/1_mutex/#pros","text":"Justo: requests s\u00e3o processados em ordem (FCFS) N\u00e3o inani\u00e7\u00e3o Espera limitada F\u00e1cil de implementar, testar, entender Contudo, tem tamb\u00e9m alguns aspectos negativos:","title":"Pr\u00f3s"},{"location":"coordenacao/1_mutex/#contras","text":"Coordenador pode se tornar um gargalo; Como lidar com falhas? Processos n\u00e3o sabem se recurso est\u00e1 bloqueado ou se usu\u00e1rio morreu e n\u00e3o devolveu a permiss\u00e3o; Coordenador pode falhar e congelar o sistema. Estes aspectos nos permitem mergulhar na \u00e1rea de toler\u00e2ncia a falhas, e o faremos, mas mais tarde. Por enquanto, consideraremos toler\u00e2ncia a falhas de forma superficial, ap\u00f3s discutirmos outra abordagem abordagem.","title":"Contras"},{"location":"coordenacao/1_mutex/#anel","text":"Nesta abordagem, os processos se organizam em um anel l\u00f3gico, com um processo antes e outro depois. Um dos processos \u00e9 iniciado com um token , que d\u00e1 acesso ao recurso e o token \u00e9 passado adiante no anel; sempre que estiver de posse do token, o processo pode acessar o recurso. Ou seja, todos os participantes executam o seguinte protocolo: Participante: Ao receber o token de acesso, se quiser acessar o recurso, acessa. Envia o token para o pr\u00f3ximo n\u00f3 do anel.","title":"Anel"},{"location":"coordenacao/1_mutex/#anel_1","text":"![Anel](images/06-16.png} Como o algoritmo centralizado, o algoritmo do anel tamb\u00e9m em suas vantagens e desvantagens.","title":"Anel"},{"location":"coordenacao/1_mutex/#pros_1","text":"Justo: Todos acessam N\u00e3o inani\u00e7\u00e3o Espera limitada F\u00e1cil de implementar, testar, entender","title":"Pr\u00f3s"},{"location":"coordenacao/1_mutex/#contras_1","text":"Token passado para quem n\u00e3o necessariamente quer acessar; Tempo de espera linear no n\u00famero de processos; Como lidar com falhas?","title":"Contras"},{"location":"coordenacao/1_mutex/#lidando-com-falhas-usando-timeouts","text":"Em ambos os algoritmos, centralizado e do anel, se um processo falhar, o algoritmo pode ficar \"travado\". Vejamos alguns casos espec\u00edficos: No algoritmo centralizado, se o coordenador falha antes de liberar o acesso para algum processo, ele leva consigo a permiss\u00e3o. Em ambos os algoritmos, se o processo acessando o recurso falha, a permiss\u00e3o \u00e9 perdida e os demais processos sofrer\u00e3o inani\u00e7\u00e3o. No algoritmo do anel, se qualquer outro processo falha, o anel \u00e9 interrompido o anel n\u00e3o conseguir\u00e1 circular. Observe que nem falamos de falhas dos canais e j\u00e1 temos diversos cen\u00e1rios a serem resolvidos, para os quais se lhes pedir uma solu\u00e7\u00e3o, tenho certeza absoluta de que me ofere\u00e7\u00e3o alguma baseada em timeouts . Por exemplo, se o processo n\u00e3o devolver a permiss\u00e3o de acesso antes de um timeout , ent\u00e3o assuma que o mesmo est\u00e1 falho e gere nova permiss\u00e3o, a ser passada a outros requisitantes. O problema desta e outras \"solu\u00e7\u00f5es\" baseadas em timeouts\" est\u00e1 no assumir que o processo est\u00e1 falho , pois caso isso n\u00e3o seja verdade, teremos agora dois tokens* no sistema, podendo levar \u00e0 viola\u00e7\u00e3o da propriedade de exclus\u00e3o m\u00fatua. Por mais que se ajuste o valor do temporizador, em um sistema distribu\u00eddo ass\u00edncrono, o mesmo pode sempre estar errado. De fato, temos que","title":"Lidando com falhas usando timeouts"},{"location":"coordenacao/1_mutex/#impossibilidade-de-deteccao-de-falhas","text":"Em um sistema distribu\u00eddo ass\u00edncrono, \u00e9 imposs\u00edvel distinguir um processo falho de um processo lento. Tamb\u00e9m mais tarde discutiremos as implica\u00e7\u00f5es desta impossibilidade. Por agora, pense apenas no seguinte:","title":"Impossibilidade de detec\u00e7\u00e3o de falhas"},{"location":"coordenacao/1_mutex/#pergunta","text":"Qual deve ser um timeout razo\u00e1vel para o meu sistema? A resposta depende de m\u00faltiplos fatores como:","title":"Pergunta:"},{"location":"coordenacao/1_mutex/#resposta-mais-perguntas","text":"Qual o custo $E$ de esperar por mais tempo? Qual o custo $C$ de cometer um engano? Qual a probabilidade $p$ de cometer um engano? $C * p < E$ Embora esta an\u00e1lise possa ser feita para estes algoritmos, a verdade \u00e9 que s\u00e3o realmente limitados e outras abordagens seriam melhor destino dos seus esfor\u00e7os. Se o mundo \u00e9 probabil\u00edstico, porqu\u00ea meus algoritmos devem ser determin\u00edsticos?\" Werner Fogels, CTO da Amazon. Uma abordagem probabil\u00edstica interessante \u00e9 baseada em qu\u00f3runs.","title":"~~Resposta~~ Mais perguntas"},{"location":"coordenacao/1_mutex/#quorum","text":"De acordo com o Dicion\u00e1rio Priberam da L\u00edngua Portuguesa, consultado em 17-04-2019 , \"qu\u00f3rum\" \u00e9 o \"N\u00famero de pessoas imprescind\u00edvel para a realiza\u00e7\u00e3o de algo.\" Aqui, este este algo ser\u00e1 a libera\u00e7\u00e3o de acesso ao recurso almejado pelos processos no sistema distribu\u00eddo. Esta abordagem \u00e9 semelhante em v\u00e1rios aspectos \u00e0 centralizada. De fato, um dos pap\u00e9is na abordagem \u00e9 o de coordenador, que executa o mesmo protocolo que antes.","title":"Qu\u00f3rum"},{"location":"coordenacao/1_mutex/#quorum-coordenador","text":"Inicializa recurso como livre Ao receber requisi\u00e7\u00e3o enfileira requisi\u00e7\u00e3o Ao receber libera\u00e7\u00e3o, marca recurso como livre Sempre que recurso marcado como livre E fila n\u00e3o vazia: envie libera\u00e7\u00e3o para primeiro da fila e o remova da fila. Entretanto, em vez de apenas um coordenador no sistema, temos $n$, dos quais o participante precisa obter $m > n/2$ autoriza\u00e7\u00f5es antes de acessar o recurso; $m$ \u00e9 o qu\u00f3rum do sistema.","title":"Quorum - Coordenador"},{"location":"coordenacao/1_mutex/#quorum-quorum","text":"$n$ coordenadores. $m > n/2$ coordenadores","title":"Quorum - Qu\u00f3rum"},{"location":"coordenacao/1_mutex/#quorum-participante","text":"Envia requisi\u00e7\u00e3o de acesso aos $n$ coordenadores Espera por resposta de $m$ coordenadores Acessa o recurso Envia libera\u00e7\u00e3o do recurso para o coordenador Al\u00e9m disso, para tornamos os problema mais interessante e demonstrar o potencial deste algoritmo, consideremos que as autoriza\u00e7\u00f5es s\u00e3o armazenadas somente em mem\u00f3ria, e que coordenadores, ao falhar e ent\u00e3o resumir suas atividades, esque\u00e7am-se das autoriza\u00e7\u00f5es j\u00e1 atribu\u00eddas.","title":"Quorum - Participante"},{"location":"coordenacao/1_mutex/#falhas","text":"Quando um coordenador falha, esquece que deu ok e reseta seu estado. Suponha o seguinte cen\u00e1rio:","title":"Falhas"},{"location":"coordenacao/1_mutex/#quorum-exemplo","text":"Coordenadores = {$c_1,c_2,c_3,c_4,c_5,c_6,c_7$} $n = 7$ $m = 4$ Participante $p_1$ consegue autoriza\u00e7\u00e3o de {$c_1,c_2,c_3,c_4$} e entra na regi\u00e3o cr\u00edtica. Coordenador $c_4$ falha e se recupera Participante $p_2$ consegue autoriza\u00e7\u00e3o de {$c_4,c_5,c_6,c_7$} e entra na regi\u00e3o cr\u00edtica. Exclus\u00e3o M\u00fatua \u00e9 violada. Qual a probabilidade $P_v$ desta viola\u00e7\u00e3o ocorrer?","title":"Qu\u00f3rum - Exemplo"},{"location":"coordenacao/1_mutex/#calculo-de-p_v","text":"Seja $P$ a probabilidade de um coordenador falhar e se recuperar em $\\delta t$, dentro de uma janela $T$. Probabilidade de falha de exatamente 1 coordenador $P^1(1-P)^{n-1}$ Probabilidade de $k$ coordenadores falharem? $P^k(1-P)^{n-k}$ Probabilidade de quaisquer $k$ em $m$ coordenadores falharem $\\binom{m}{k} P^k(1-P)^{m-k}$ Probabilidade de quaisquer $k$ em $m$ coordenadores falharem $\\binom{m}{k} P^k(1-P)^{m-k}$ Diferentes valores de $k$ que s\u00e3o problem\u00e1ticos? TODO: desenho dos qu\u00f3runs sobrepostos $\\left| A \\cup B\\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cap B \\right| \\Rightarrow n = m + m - k$ $\\left| A \\cap B \\right| = \\left| A \\right| + \\left|B\\right| - \\left| A \\cup B\\right| \\Rightarrow k = m + m - n = 2m - n$ Probabilidade de quaisquer $k$ em $m$ coordenadores falharem, para qualquer $k$ que seja problem\u00e1tico $P_v = \\sum_{2m-n}^n \\binom{m}{k} P^k(1-P)^{m-k}$ Para facilitar o entendimento desta grandeza, considere o exemplo:","title":"C\u00e1lculo de $P_v$"},{"location":"coordenacao/1_mutex/#exemplo","text":"$p=0.0001$ (1 minuto a cada 10 dias) $n = 32$ $m = 0.75n$ $P_v < 10^{-40}$ ( Curiosidade sobre $10^40$ ) A probabilidade de viola\u00e7\u00e3o da exclus\u00e3o m\u00fatua, neste caso, \u00e9 muito pequena, a despeito de suportar falhas dos coordenadores.","title":"Exemplo"},{"location":"coordenacao/1_mutex/#pros_2","text":"Tolera falhas de coordenadores, com probabilidade controlada de viola\u00e7\u00e3o de exclus\u00e3o m\u00fatua Mas e as outras propriedades desej\u00e1veis do algoritmo de exclus\u00e3o m\u00fatua, s\u00e3o alcan\u00e7adas? Relembrando:","title":"Pr\u00f3s"},{"location":"coordenacao/1_mutex/#exclusao-mutua_3","text":"exclus\u00e3o m\u00fatua: somente um processo pode estar na regi\u00e3o cr\u00edtica em qualquer instante de tempo; aus\u00eancia de deadlocks : se processos est\u00e3o tentando acessar o recurso, ent\u00e3o algum processo deve conseguir acesso em algum instante, dado que nenhum processo fique na regi\u00e3o cr\u00edtica indefinidamente; n\u00e3o inani\u00e7\u00e3o: todos os processos interessados consguem, em algum momento, acessar o recurso; espera limitada: idealmente, o tempo de espera pelo recurso \u00e9 limitado.","title":"Exclus\u00e3o M\u00fatua"},{"location":"coordenacao/1_mutex/#contras_2","text":"Exclus\u00e3o M\u00fatua: $1 - P_v$ N\u00e3o-inani\u00e7\u00e3o E se cada participante obter o ok de um coordenador? Temporizador para quebrar o deadlock ? Espera limitada Aborts podem levar a espera infinita. Assim, este agoritmo tamb\u00e9m pode n\u00e3o ser adequado para certas situa\u00e7\u00f5es. Vamos tentar reacessar os problemas da primeira abordagem. Por um lado, o uso de um l\u00edder para coordenar a\u00e7\u00f5es em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto \u00fanico de falha, como no algoritmo de exclus\u00e3o m\u00fatua centralizado. Mas e se substitu\u00edssemos o coordenador no caso de falhas? Este \u00e9 o problema conhecido como elei\u00e7\u00e3o de l\u00edderes.","title":"Contras"},{"location":"coordenacao/2_leader/","text":"Assim, este agoritmo tamb\u00e9m pode n\u00e3o ser adequado para certas situa\u00e7\u00f5es. Vamos tentar reacessar os problemas da primeira abordagem. Por um lado, o uso de um l\u00edder para coordenar a\u00e7\u00f5es em um SD simplifica o projeto, mas, por outro, o coordenador pode se tornar um ponto \u00fanico de falha, como no algoritmo de exclus\u00e3o m\u00fatua centralizado. Mas e se substitu\u00edssemos o coordenador no caso de falhas? Este \u00e9 o problema conhecido como elei\u00e7\u00e3o de l\u00edderes. Elei\u00e7\u00e3o de L\u00edderes O problema da escolha de um processo centralizador pode ser posto informamente como: Elei\u00e7\u00e3o de L\u00edderes Procedimento pelo qual um processo \u00e9 escolhido dentre os demais processos. Todos os processos identificam o mesmo processo como eleito. Uma nova elei\u00e7\u00e3o deve acontecer sempre que o l\u00edder corrente se tornar indispon\u00edvel. Experimentemos com protocolos triviais. Vamos eleger um l\u00edder na sala. Do que precisamos? Elei\u00e7\u00e3o de representate de sala Vota\u00e7\u00e3o? Identidade Teste de for\u00e7a? Estabilidade? PARA SER TERMINADO \\begin{frame}{Identidade} Antes de qualquer coisa, \u00e9 preciso ser poss\u00edvel identificar um processo. Como isso pode ser feito, na pr\u00e1tica? \\pause \\begin{itemize} \\item PID -- Process Identier \\item IP -- Internet Protocol Address \\item Socket -- IP + Port \\end{itemize} \\end{frame} \\begin{frame}{Algoritmo do Brig\u00e3o/Bully} \\begin{itemize} \\item Selecione o processo <code>vivo'' com o maior identificador! \\item Quando $p$ acha que o l\u00edder est\u00e1 morto: \\begin{itemize} \\item Envia mensagem</code>elei\u00e7\u00e3o,$p$'' para todos os processo com identificador maior \\item Se ningu\u00e9m responde, $p$ assume como l\u00edder \\item Se algum responde, aguarda notifica\u00e7\u00e3o. \\end{itemize} \\item Quando $q$ recebe elei\u00e7\u00e3o,$p$'' \\begin{itemize} \\item Envia ok'' para $p$ \\item Fica ciente de que o coordenador atual est\u00e1 morto \\end{itemize} \\pause \\item Ao assumir como l\u00edder, o processo notifica a todos os outros \\item Se um processo falho se recupera, inicia uma elei\u00e7\u00e3o. \\end{itemize} \\end{frame} \\begin{frame}{Algoritmo do Brig\u00e3o/Bully} \\includegraphics[width=.75\\textwidth]{images/bully} \\href{https://my.oschina.net/juliashine/blog/88173}{Fonte} \\end{frame} \\begin{frame}{Algoritmo do Anel} \\begin{itemize} \\item Organize os n\u00f3s em um anel l\u00f3gico \\item Quando $p$ acha que o l\u00edder est\u00e1 morto: \\begin{itemize} \\item Envia mensagem \\{$p$\\} para ``a direita'' no anel. \\item Se processo \u00e0 direita est\u00e1 falho, salte-o, e assim por diante. \\end{itemize} \\pause \\item Quando $q$ recebe \\{$p$\\} \\begin{itemize} \\item Envia \\{$p,q$\\} para a direita. \\end{itemize} \\pause \\item Quando $p$ recebe $S$ tal que $q \\in S$ \\begin{itemize} \\item Escolhe menor id em $S$, por exemplo, e anuncia como l\u00edder. \\end{itemize} \\end{itemize} \\end{frame} \\begin{frame}{Chang \\& Robert's} \\begin{itemize} \\item Organize os n\u00f3s em um anel l\u00f3gico \\item Quando $p$ acha que o l\u00edder est\u00e1 morto: \\begin{itemize} \\item Envia mensagem $p$ para <code>a direita'' no anel, saltando falhos. \\item Liga flag</code>participante'' \\end{itemize} \\pause \\item Quando $q$ recebe $p$ \\begin{itemize} \\item Se $p &gt; q$, repassa $p$ para a direita. \\item Sen\u00e3o, envia $q$ para a direita. \\item Liga flag <code>participante'' \\end{itemize} \\pause \\item Quando $p$ recebe $q$ da esquerda \\begin{itemize} \\item Se</code>participante'' est\u00e1 ligado, identifica $q$ como l\u00edder. \\item Desliga ``participante'' \\item Se $p \\neq q$, repassa $q$ \u00e0 direita \\end{itemize} \\end{itemize} \\end{frame} \\begin{frame}[allowframebreaks]{Yo-Yo} \\begin{itemize} \\item Grafos incompletos \\item Duas fases \\end{itemize} \\framebreak \\begin{block}{Fase 1} \\begin{itemize} \\item $p$ envia seu identificador para seus vizinhos. \\item Quando $q$ recebe $p$ \\begin{itemize} \\item Se $p>q$, adiciona aresta $q\\rightarrow p$ \\item Sen\u00e3o, adiciona aresta $q\\leftarrow p$ \\item Fonte (source) \\item Vertedouro (sink) \\item Interno \\end{itemize} \\end{itemize} \\end{block} \\framebreak \\begin{block}{Fase 2: Yo-\\alert{Yo}} \\begin{itemize} \\item Fontes enviam seus identificadores para seus vizinhos. \\item Interno espera msg de todas as arestas de entrada, escolhe o menor id, e repassa para arestas de sa\u00edda. \\item Vertedouro espera msg de todas as arestas de entrada e escolhe o menor id. \\end{itemize} \\end{block} \\framebreak \\begin{block}{Fase 2: \\alert{Yo}-Yo} \\begin{itemize} \\item Vertedouro envia S para vizinhos de onde viu menor valor e N para os demais. \\item Interno repassa S para o vizinho correspondente ao menor id e N para os demais. \\item Fonte espera por todos os votos. Se todos s\u00e3o S, continua; caso contr\u00e1rio, desiste. \\item N inverte a dire\u00e7\u00e3o das arestas em que trafega. \\item Poss\u00edvel otimizar para eliminar n\u00f3s e arestas irrelevantes. \\end{itemize} \\end{block} \\framebreak \\includegraphics[width=.8\\textwidth]{images/yoyo}* \\begin{small} a) The network, b) Oriented network after setup phase, c) YO- phase in which source values are passed, d)-YO phase sending responses from sinks, e) updated structure after -YO phase. ** *\\href{https://commons.wikimedia.org/w/index.php?curid=36757409}{Fonte: Hemis62 - Own work, CC BY-SA 4.0, } **\\href{https://en.wikipedia.org/wiki/Leader_election}{Fonte} \\end{small} \\end{frame} \\begin{frame}{Problemas?} O que acontece se a rede \u00e9 particionada? \\end{frame} \\begin{frame}{Split Brain} \\begin{itemize} \\item Network Partitioning: rede dividida em duas partes incomunic\u00e1veis. \\item M\u00faltiplas elei\u00e7\u00f5es podem acontecer em paralelo. \\item M\u00faltiplos l\u00edderes em paralelo. \\item Como lidar com este problema? \\pause \\begin{itemize} \\item Use primeiro algoritmo e s\u00f3 eleja l\u00edder ap\u00f3s maioria de votos. \\item Rede redundante, disco compartilhado \\pause ,... centraliza\u00e7\u00e3o...\\pause volta ao primeiro caso. \\end{itemize} \\end{itemize} \\end{frame} \\begin{frame}{Detec\u00e7\u00e3o de Falhas} Elei\u00e7\u00e3o de l\u00edderes perfeita \u00e9 imposs\u00edvel em cen\u00e1rios real\u00edsticos. \\begin{itemize} \\item Detec\u00e7\u00e3o de falhas perfeita \u00e9 imposs\u00edvel... \\item em sistemas distribu\u00eddos ass\u00edncronos (Internet) \\item sujeitos \u00e0 parti\u00e7\u00f5es (Internet) \\item com requisitos de disponibilidade total. \\pause \\item Falemos mais sobre este problema depois. \\end{itemize} \\end{frame} Fim da aula 12","title":"Elei\u00e7\u00e3o de L\u00edderes"},{"location":"coordenacao/2_leader/#eleicao-de-lideres","text":"O problema da escolha de um processo centralizador pode ser posto informamente como:","title":"Elei\u00e7\u00e3o de L\u00edderes"},{"location":"coordenacao/2_leader/#eleicao-de-lideres_1","text":"Procedimento pelo qual um processo \u00e9 escolhido dentre os demais processos. Todos os processos identificam o mesmo processo como eleito. Uma nova elei\u00e7\u00e3o deve acontecer sempre que o l\u00edder corrente se tornar indispon\u00edvel. Experimentemos com protocolos triviais. Vamos eleger um l\u00edder na sala. Do que precisamos?","title":"Elei\u00e7\u00e3o de L\u00edderes"},{"location":"coordenacao/2_leader/#eleicao-de-representate-de-sala","text":"Vota\u00e7\u00e3o? Identidade Teste de for\u00e7a? Estabilidade?","title":"Elei\u00e7\u00e3o de representate de sala"},{"location":"coordenacao/2_leader/#para-ser-terminado","text":"\\begin{frame}{Identidade} Antes de qualquer coisa, \u00e9 preciso ser poss\u00edvel identificar um processo. Como isso pode ser feito, na pr\u00e1tica? \\pause \\begin{itemize} \\item PID -- Process Identier \\item IP -- Internet Protocol Address \\item Socket -- IP + Port \\end{itemize} \\end{frame} \\begin{frame}{Algoritmo do Brig\u00e3o/Bully} \\begin{itemize} \\item Selecione o processo <code>vivo'' com o maior identificador! \\item Quando $p$ acha que o l\u00edder est\u00e1 morto: \\begin{itemize} \\item Envia mensagem</code>elei\u00e7\u00e3o,$p$'' para todos os processo com identificador maior \\item Se ningu\u00e9m responde, $p$ assume como l\u00edder \\item Se algum responde, aguarda notifica\u00e7\u00e3o. \\end{itemize} \\item Quando $q$ recebe elei\u00e7\u00e3o,$p$'' \\begin{itemize} \\item Envia ok'' para $p$ \\item Fica ciente de que o coordenador atual est\u00e1 morto \\end{itemize} \\pause \\item Ao assumir como l\u00edder, o processo notifica a todos os outros \\item Se um processo falho se recupera, inicia uma elei\u00e7\u00e3o. \\end{itemize} \\end{frame} \\begin{frame}{Algoritmo do Brig\u00e3o/Bully} \\includegraphics[width=.75\\textwidth]{images/bully} \\href{https://my.oschina.net/juliashine/blog/88173}{Fonte} \\end{frame} \\begin{frame}{Algoritmo do Anel} \\begin{itemize} \\item Organize os n\u00f3s em um anel l\u00f3gico \\item Quando $p$ acha que o l\u00edder est\u00e1 morto: \\begin{itemize} \\item Envia mensagem \\{$p$\\} para ``a direita'' no anel. \\item Se processo \u00e0 direita est\u00e1 falho, salte-o, e assim por diante. \\end{itemize} \\pause \\item Quando $q$ recebe \\{$p$\\} \\begin{itemize} \\item Envia \\{$p,q$\\} para a direita. \\end{itemize} \\pause \\item Quando $p$ recebe $S$ tal que $q \\in S$ \\begin{itemize} \\item Escolhe menor id em $S$, por exemplo, e anuncia como l\u00edder. \\end{itemize} \\end{itemize} \\end{frame} \\begin{frame}{Chang \\& Robert's} \\begin{itemize} \\item Organize os n\u00f3s em um anel l\u00f3gico \\item Quando $p$ acha que o l\u00edder est\u00e1 morto: \\begin{itemize} \\item Envia mensagem $p$ para <code>a direita'' no anel, saltando falhos. \\item Liga flag</code>participante'' \\end{itemize} \\pause \\item Quando $q$ recebe $p$ \\begin{itemize} \\item Se $p &gt; q$, repassa $p$ para a direita. \\item Sen\u00e3o, envia $q$ para a direita. \\item Liga flag <code>participante'' \\end{itemize} \\pause \\item Quando $p$ recebe $q$ da esquerda \\begin{itemize} \\item Se</code>participante'' est\u00e1 ligado, identifica $q$ como l\u00edder. \\item Desliga ``participante'' \\item Se $p \\neq q$, repassa $q$ \u00e0 direita \\end{itemize} \\end{itemize} \\end{frame} \\begin{frame}[allowframebreaks]{Yo-Yo} \\begin{itemize} \\item Grafos incompletos \\item Duas fases \\end{itemize} \\framebreak \\begin{block}{Fase 1} \\begin{itemize} \\item $p$ envia seu identificador para seus vizinhos. \\item Quando $q$ recebe $p$ \\begin{itemize} \\item Se $p>q$, adiciona aresta $q\\rightarrow p$ \\item Sen\u00e3o, adiciona aresta $q\\leftarrow p$ \\item Fonte (source) \\item Vertedouro (sink) \\item Interno \\end{itemize} \\end{itemize} \\end{block} \\framebreak \\begin{block}{Fase 2: Yo-\\alert{Yo}} \\begin{itemize} \\item Fontes enviam seus identificadores para seus vizinhos. \\item Interno espera msg de todas as arestas de entrada, escolhe o menor id, e repassa para arestas de sa\u00edda. \\item Vertedouro espera msg de todas as arestas de entrada e escolhe o menor id. \\end{itemize} \\end{block} \\framebreak \\begin{block}{Fase 2: \\alert{Yo}-Yo} \\begin{itemize} \\item Vertedouro envia S para vizinhos de onde viu menor valor e N para os demais. \\item Interno repassa S para o vizinho correspondente ao menor id e N para os demais. \\item Fonte espera por todos os votos. Se todos s\u00e3o S, continua; caso contr\u00e1rio, desiste. \\item N inverte a dire\u00e7\u00e3o das arestas em que trafega. \\item Poss\u00edvel otimizar para eliminar n\u00f3s e arestas irrelevantes. \\end{itemize} \\end{block} \\framebreak \\includegraphics[width=.8\\textwidth]{images/yoyo}* \\begin{small} a) The network, b) Oriented network after setup phase, c) YO- phase in which source values are passed, d)-YO phase sending responses from sinks, e) updated structure after -YO phase. ** *\\href{https://commons.wikimedia.org/w/index.php?curid=36757409}{Fonte: Hemis62 - Own work, CC BY-SA 4.0, } **\\href{https://en.wikipedia.org/wiki/Leader_election}{Fonte} \\end{small} \\end{frame} \\begin{frame}{Problemas?} O que acontece se a rede \u00e9 particionada? \\end{frame} \\begin{frame}{Split Brain} \\begin{itemize} \\item Network Partitioning: rede dividida em duas partes incomunic\u00e1veis. \\item M\u00faltiplas elei\u00e7\u00f5es podem acontecer em paralelo. \\item M\u00faltiplos l\u00edderes em paralelo. \\item Como lidar com este problema? \\pause \\begin{itemize} \\item Use primeiro algoritmo e s\u00f3 eleja l\u00edder ap\u00f3s maioria de votos. \\item Rede redundante, disco compartilhado \\pause ,... centraliza\u00e7\u00e3o...\\pause volta ao primeiro caso. \\end{itemize} \\end{itemize} \\end{frame} \\begin{frame}{Detec\u00e7\u00e3o de Falhas} Elei\u00e7\u00e3o de l\u00edderes perfeita \u00e9 imposs\u00edvel em cen\u00e1rios real\u00edsticos. \\begin{itemize} \\item Detec\u00e7\u00e3o de falhas perfeita \u00e9 imposs\u00edvel... \\item em sistemas distribu\u00eddos ass\u00edncronos (Internet) \\item sujeitos \u00e0 parti\u00e7\u00f5es (Internet) \\item com requisitos de disponibilidade total. \\pause \\item Falemos mais sobre este problema depois. \\end{itemize} \\end{frame}","title":"PARA SER TERMINADO"},{"location":"coordenacao/2_leader/#fim-da-aula-12","text":"","title":"Fim da aula 12"},{"location":"ft/0_intro/","text":"Neste cap\u00edtulo discutiremos o qu\u00ea s\u00e3o sistemas distribu\u00eddos, por qu\u00ea os desenvolvemos, e damos uma vis\u00e3o geral de como isto \u00e9 feito.","title":"Toler\u00e2ncia a Falhas"},{"location":"ft/1_dependabilidade/","text":"Dependabilidade Ao escrevermos nossos softwares, queremos que sejam usados para resolver problemas, mesmo que import\u00e2ncia do problema esteja em um espectro bem vasto, indo, por exemplo, da execu\u00e7\u00e3o de um cirurgia ocular remota, ao controle de uma usina hidrel\u00e9trica, \u00e0 jogar truco contra um computador. Independentemente do problema sendo resolvido, gostar\u00edamos de poder contar com o sistema, de poder depender nele para executar sua tarefa. Desta situa\u00e7\u00e3o, surge a ideia de dependabilidade, isto \u00e9, de um sistema ter a propriedade de que podemos depender do mesmo. Em computa\u00e7\u00e3o distribu\u00edda, componentes dependem uns dos outros para a realiza\u00e7\u00e3o de tarefas. Assim, componentes que quer ser \"depend\u00e1veis\" (do ingl\u00eas, dependable ), pois se n\u00e3o o forem, os demais componentes n\u00e3o poder\u00e3o executar suas tarefas, rendendo o sistema como um todo in\u00fatil. Defini\u00e7\u00e3o Assim, dizemos que um componente $C$ depende de um componente $C'$ se a corretude do comportamento de $C$ depende da corretude do componente $C'$. e que um componente \u00e9 ``depend\u00e1vel'' (\\emph{dependable}) na medida que outros podem depender dele. De acordo com Laprie et al , tem-se dependabilidade quando os seguintes atributos est\u00e3o presentes. Atributos Disponibilidade ( Availability ) - Prontid\u00e3o para uso. Confiabilidade/Fiabilidade (*Reliability) - Continuidade do servi\u00e7o. Manutenabilidade ( Maintainability ) - Facilidade de reparo. Seguran\u00e7a ( Safety ) - Toler\u00e2ncia a cat\u00e1strofes. Integridade ( Integrity ) - Toler\u00e2ncia a modifica\u00e7\u00f5es. Confidencialidade (*Confidentiality) - Informa\u00e7\u00e3o somente a quem devido. A combin\u00e7\u00e3o das tr\u00eas \u00faltimas propriedades \u00e9 tamb\u00e9m chamadas de Seguran\u00e7a ( Security ). Como obst\u00e1culos para se conseguir estes atributos est\u00e3o os seguintes obst\u00e1culos, ou amea\u00e7as: Amea\u00e7as Fault - Falha (Falta): bug -- \\lstinline|<=| em vez de \\lstinline|<| (pode nunca afetar a execu\u00e7\u00e3o). Error - Erro (Erro): manifesta\u00e7\u00e3o do bug -- itera\u00e7\u00e3o passa do ponto. (Pode n\u00e3o ser observ\u00e1vel pelo usu\u00e1rio.) Failure - Defeito (Falha): problema vis\u00edvel -- tela azul","title":"Dependabilidade"},{"location":"ft/1_dependabilidade/#dependabilidade","text":"Ao escrevermos nossos softwares, queremos que sejam usados para resolver problemas, mesmo que import\u00e2ncia do problema esteja em um espectro bem vasto, indo, por exemplo, da execu\u00e7\u00e3o de um cirurgia ocular remota, ao controle de uma usina hidrel\u00e9trica, \u00e0 jogar truco contra um computador. Independentemente do problema sendo resolvido, gostar\u00edamos de poder contar com o sistema, de poder depender nele para executar sua tarefa. Desta situa\u00e7\u00e3o, surge a ideia de dependabilidade, isto \u00e9, de um sistema ter a propriedade de que podemos depender do mesmo. Em computa\u00e7\u00e3o distribu\u00edda, componentes dependem uns dos outros para a realiza\u00e7\u00e3o de tarefas. Assim, componentes que quer ser \"depend\u00e1veis\" (do ingl\u00eas, dependable ), pois se n\u00e3o o forem, os demais componentes n\u00e3o poder\u00e3o executar suas tarefas, rendendo o sistema como um todo in\u00fatil.","title":"Dependabilidade"},{"location":"ft/1_dependabilidade/#definicao","text":"Assim, dizemos que um componente $C$ depende de um componente $C'$ se a corretude do comportamento de $C$ depende da corretude do componente $C'$. e que um componente \u00e9 ``depend\u00e1vel'' (\\emph{dependable}) na medida que outros podem depender dele. De acordo com Laprie et al , tem-se dependabilidade quando os seguintes atributos est\u00e3o presentes.","title":"Defini\u00e7\u00e3o"},{"location":"ft/1_dependabilidade/#atributos","text":"Disponibilidade ( Availability ) - Prontid\u00e3o para uso. Confiabilidade/Fiabilidade (*Reliability) - Continuidade do servi\u00e7o. Manutenabilidade ( Maintainability ) - Facilidade de reparo. Seguran\u00e7a ( Safety ) - Toler\u00e2ncia a cat\u00e1strofes. Integridade ( Integrity ) - Toler\u00e2ncia a modifica\u00e7\u00f5es. Confidencialidade (*Confidentiality) - Informa\u00e7\u00e3o somente a quem devido. A combin\u00e7\u00e3o das tr\u00eas \u00faltimas propriedades \u00e9 tamb\u00e9m chamadas de Seguran\u00e7a ( Security ). Como obst\u00e1culos para se conseguir estes atributos est\u00e3o os seguintes obst\u00e1culos, ou amea\u00e7as:","title":"Atributos"},{"location":"ft/1_dependabilidade/#ameacas","text":"Fault - Falha (Falta): bug -- \\lstinline|<=| em vez de \\lstinline|<| (pode nunca afetar a execu\u00e7\u00e3o). Error - Erro (Erro): manifesta\u00e7\u00e3o do bug -- itera\u00e7\u00e3o passa do ponto. (Pode n\u00e3o ser observ\u00e1vel pelo usu\u00e1rio.) Failure - Defeito (Falha): problema vis\u00edvel -- tela azul","title":"Amea\u00e7as"},{"location":"ft/2_modelos/","text":"","title":"Modelos"},{"location":"intro/","text":"Introdu\u00e7\u00e3o As \u00e1reas ligadas ao desenvolvimentos de sistemas computacionais, como Ci\u00eancia e Engenharia de Computa\u00e7\u00e3o e Sistemas de Informa\u00e7\u00e3o, est\u00e3o extremamente em voga e tem atra\u00eddo mais e mais profissionais, mais ou menos qualificados, tornando este mercado cada vez mais competitivo . Ter conhecimentos espec\u00edficos da sub\u00e1rea de desenvolvimento de sistemas distribu\u00eddos e pode ser uma excelente vantagem e forma de se destacar de seus colegas e competidores. \"Como assim?\", voc\u00ea pergunta, j\u00e1 que nunca ouviu falar em sistemas distribu\u00eddos at\u00e9 ter que se matricular nesta disciplina. Bem, o desenvolvimento da teoria da computa\u00e7\u00e3o distribu\u00edda, na forma do estudo de algoritmos e t\u00e9cnicas de implementa\u00e7\u00e3o, e sua coloca\u00e7\u00e3o em pr\u00e1tica, na forma do desenvolvimento de sistemas distribu\u00eddos, n\u00e3o \u00e9 t\u00e3o \"quente\" como outras \u00e1reas, por exemplo intelig\u00eancia artificial e ci\u00eancia de dados. Mas acontece que sem a computa\u00e7\u00e3o distribu\u00edda, nenhum desenvolvimento s\u00e9rio destas outras \u00e1reas, sedentas por desempenho, escalaria para problemas reais. Veja por exemplo a seguinte descri\u00e7\u00e3o dos skills necess\u00e1rios para atuar como cientista de dados ou como engenheiro no Facebook . Se estiver convencido de que esta \u00e9 uma \u00e1rea importante, \u00f3timo! Neste curso apesentaremos uma vis\u00e3o geral do que s\u00e3o sistemas distribu\u00eddos, por qu\u00eas t\u00e9cnicos para os desenvolvemos, e como faz\u00ea-lo, com uma forte componente pr\u00e1tica, por meio do desenvolvimento de um projeto com (um dos) p\u00e9s na realidade. Caso contr\u00e1rio, bem, voc\u00ea n\u00e3o tem muita escolha, certo? Ent\u00e3o tente aproveitar esta vis\u00e3o geral para praticar um pouco de programa\u00e7\u00e3o neuro-ligu\u00edstica e repita o seguinte mantra: heeeeeeeuuuuummmmmm amo computa\u00e7\u00e3o distribu\u00edda. Brincadeiras a parte, voc\u00ea desenvolver\u00e1 um projeto em v\u00e1rias etapas que lhe permitir\u00e1 exercitar os conceitos vistos aqui e que te levar\u00e1 a: programar processos que se comuniquem via redes de computadores; conhecer arquiteturas cl\u00e1ssicas de sistemas distribu\u00eddos (e.g, cliente/servidor, p2p e h\u00edbrida), seus usos e limita\u00e7\u00f5es; escrever programas multithreaded simples e a entender como o uso de multithreading afeta os componentes de um sistema distribu\u00eddo; entender a problem\u00e1tica da coordena\u00e7\u00e3o e do controle de concorr\u00eancia em sistemas distribu\u00eddos; entender o uso de sistemas de nomea\u00e7\u00e3o em sistemas distribu\u00eddos bem como diversas formas de se implementar tais sistemas de nomea\u00e7\u00e3o; entender os conceitos b\u00e1sicos de replica\u00e7\u00e3o e toler\u00e2ncia a falhas; entender as implica\u00e7\u00f5es da dessincroniza\u00e7\u00e3o de rel\u00f3gios na coordena\u00e7\u00e3o, replica\u00e7\u00e3o e toler\u00e2ncia a falhas; projetar sistemas com componentes geograficamente distantes, fracamente acoplados; entender onde os diversos middleware podem ser usados para acoplar tais componentes; conhecer v\u00e1rias t\u00e9cnicas que controle de concorr\u00eancia controlar o acesso a um recurso compartilhado; O qu\u00ea? Mas afinal, o qu\u00ea \u00e9 um sistema distribu\u00eddo? Talvez seja mais f\u00e1cil come\u00e7armos por sistemas n\u00e3o distribu\u00eddos, ou como normalmente os denominamos, sistemas centralizados. Pense na maioria das aplica\u00e7\u00f5es que desenvolveu no curso at\u00e9 agora. Elas provavelmente executam integralmente em um \u00fanico processo, executando em uma \u00fanica m\u00e1quina. Mesmo que use diferentes bibliotecas e frameworks , toda l\u00f3gica de neg\u00f3cio, armazenamento e interface com usu\u00e1rio est\u00e1 contida em um mesmo lugar, e por isso s\u00e3o chamadas centralizadas. Quando come\u00e7ou a programar este tipo de aplica\u00e7\u00e3o, o trabalho era basicamente colar blocos Lego, que se encaixavam perfeitamente, bastando importar a biblioteca correta e invocar suas fun\u00e7\u00f5es. O cen\u00e1rio deve ter mudado um pouco no decorrer do curso e com o in\u00edcio de sua atividade profissional, quando passou a ter muito mais blocos, de muito mais tipos, para encaixar uns nos outros, aumentando consideravelmente a complexidade do desenvolvimento. Mesmo que haja diferentes bibliotecas a serem usadas, com desenvolvedores e estilos diferentes, bem ou mal testadas, seus encaixes ainda fazem sentido. Infelizmente, programar sistemas distribu\u00eddos \u00e9 muito mais complexo que sistemas centralizados. Frequentemente temos pe\u00e7as que nunca foram pensadas para trabalharem juntas, e nos resta usar um pouco de crazy glue , persuas\u00e3o, e muito arame. No caso, o arame \u00e9 de um tipo especial conhecido como cabo de rede, usado para estabelecer um canal de comunica\u00e7\u00e3o entre as diferentes partes do sistema. De fato, a principal caracter\u00edstica de um sistema distribu\u00eddo em rela\u00e7\u00e3o a um n\u00e3o distribu\u00eddo, \u00e9 a separa\u00e7\u00e3o de suas partes em v\u00e1rios componentes independentes (processos, sensores, atuadores), mas que se coordenam por meio de canais de comunica\u00e7\u00e3o para execu\u00e7\u00e3o de alguma tarefa. Assim, uma poss\u00edvel defini\u00e7\u00e3o de Sistema Distribu\u00eddo, que me agrada, \u00e9 a seguinte: Sistema Distribu\u00eddo Cole\u00e7\u00e3o de sistemas computacionais (software ou hardware), independentes mas com alguma forma de comunica\u00e7\u00e3o, que colaboram na execu\u00e7\u00e3o de alguma tarefa. Uma defini\u00e7\u00e3o mais c\u00ednica mas definitivamente realista \u00e9 a de Leslie Lamport , que certa vez disse: A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable. Mas se esta \u00e9 a realidade da programa\u00e7\u00e3o distribu\u00edda, por qu\u00ea faz\u00ea-lo? Por qu\u00ea? Todos estamos a par de que aplica\u00e7\u00f5es importantes nos dias de hoje s\u00e3o aplica\u00e7\u00f5es distribu\u00eddas rodando em grandes data centers com milhares de m\u00e1quinas . Alguns exemplos \u00f3bvios s\u00e3o Amazon.com , Facebook , e GMail . Mas as raz\u00f5es que levam a este cen\u00e1rio s\u00e3o v\u00e1lidas para diversas outras aplica\u00e7\u00f5es. De fato, praticamente qualquer sistema de informa\u00e7\u00e3o que precise atingir um p\u00fablico consider\u00e1vel, necessitar\u00e1 aplicar t\u00e9cnicas de computa\u00e7\u00e3o distribu\u00edda para conseguir escalar , isto \u00e9, \"ser grande\", seja no n\u00famero de clientes que atende (computacionais ou humanos), seja em sua \u00e1rea de cobertura, ou na qualidade do servi\u00e7o que presta, mesmo que n\u00e3o cheguem a estas escalas. Este \u00faltimo ponto, sobre qualidade do servi\u00e7o, tem a ver com a capacidade de um sistema se manter no ar a despeito de problemas, isto \u00e9, de ser tolerante a falhas. Toler\u00e2ncia a falhas implica em redund\u00e2ncia, em c\u00f3pias, o que fatidicamente implica em distribui\u00e7\u00e3o e em Sistemas Distribu\u00eddos . H\u00e1 quem diga que somos todos desenvolvedores de sistemas distribu\u00eddos agora . O fato \u00e9 que computadores individuais tem capacidade limitada de processamento e armazenamento, mas nossa necessidade de poder computacional cresce exponencialmente. Assim, precisamos crescer nosso poder computacional, mas aumentar a capacidade de um dispositivo ( scale up ) mesmo de forma linear tem custo exponencial. O que nos resta ent\u00e3o \u00e9 agregar o poder computacional de diversos computadores \"baratos\" ( scale out ) para satisfazer nossas necessidades. O rem\u00e9dio, contudo, \u00e9 bem amargo: com muitos computadores conectados, vem a necessidade de coorden\u00e1-los, de forma a agir de forma coerente, mesmo quando alguns deles falhem, e quanto mais computadores, maior \u00e9 a probabilidade de que pelo menos um deles tenha uma CPU, disco, fonte, ou que quer que seja, falhando. E estejam certos, computadores falham o tempo todo! N\u00f3s precisamos ent\u00e3o entender este ambiente e determinar qual a probabilidade de um n\u00f3 falhar; como os computadores, ou melhor, como os processos se comunicam; se mensagens podem ser perdidas, atrasadas, corrompidas; se os rel\u00f3gios dos computadores s\u00e3o sincronizados; se h\u00e1 agentes maliciosos que possam querer perturbar o sistema; quais os padr\u00f5es de acesso ao servi\u00e7os, isto \u00e9, se aumentam \u00e0 noite, diminuem no ver\u00e3o, etc. Assim, definimos modelos computacionais , que nos permitem desenvolver algoritmos adequados aos diversos problemas que enfrentamos. Modelos cl\u00e1ssicos englobam tr\u00eas vari\u00e1veis: Comunica\u00e7\u00e3o; Sincronismo; e, Falhas. Definido o modelo computacional, podemos distribuir nosso sistema, isto \u00e9, dividir a computa\u00e7\u00e3o/armazenamento em diversas m\u00e1quinas, e coordenar suas a\u00e7\u00f5es para que sejam consistentes com a especifica\u00e7\u00e3o, de forma a minimizar o tempo que o servi\u00e7o fica fora do ar, entregando o servi\u00e7o de acordo com expectativas especificadas. Para isto, precisamos entender como falhas (bugs, por exemplo) afetam a execu\u00e7\u00e3o; como evitar que a falha de algum componente possa levar o sistema a parar como um todo; e garantir que clientes em qualquer lugar do mundo tenham a mesma facilidade em acessar o servi\u00e7o. Vejamos algumas exemplos de tarefas executadas por sistemas distribu\u00eddos, que voc\u00ea usa hoje. Entregue este email para fulano@knowhere.uni. Envie o item X para este endere\u00e7o, ap\u00f3s cobran\u00e7a de Y dinheiros da conta Z. Em um ambiente de simula\u00e7\u00e3o de batalhas em 3D, simule o disparo de um proj\u00e9til nesta dire\u00e7\u00e3o e sentido, com velocidade v, enquanto movimenta o avatar A para a esquerda. Autorize a transfer\u00eancia de X dinheiros da conta C para a conta C'. Movimente o bra\u00e7o mec\u00e2nico que est\u00e1 segurando um bisturi, 3cm \u00e0 direita, ent\u00e3o abaixe-o 3mm, e movimente-o 4cm para a esquerda Inclua o coment\u00e1rio ``LOL!!!'' na lista de coment\u00e1rios do item XYZ, com marca de tempo T Leia o valor do sensor de temperatura S e, caso seu valor supere V, emita alarme luminoso vermelho intermitente e alarme sonoro Um sistema distribu\u00eddo implica em algum tipo de colabora\u00e7\u00e3o entre componentes, para permitir que recursos de um sejam usados por outro. Por exemplo, capacidade de armazenamento, de processamento, conex\u00e3o f\u00edsica com uma impressora, ou localiza\u00e7\u00e3o geogr\u00e1fica. Por qu\u00ea distribuir? As principais raz\u00f5es para se desenvolver sistemas distribu\u00eddos s\u00e3o duas, ambas resultantes da agrega\u00e7\u00e3o (correta) do poder computacional de m\u00faltiplas m\u00e1quinas: escalabilidade e toler\u00e2ncia a falhas. Como? Refor\u00e7ando, distribuir \u00e9 dividir a computa\u00e7\u00e3o/armazenamento em diversos componentes, possivelmente geograficamente distantes , e coordenar suas a\u00e7\u00f5es para que resolvam a tarefa em quest\u00e3o de forma correta. Com a distribui\u00e7\u00e3o objetiva-se usar recursos dispon\u00edveis nos hosts onde os componentes s\u00e3o executados e usar de redund\u00e2ncia para garantir que o servi\u00e7o sofra degrada\u00e7\u00e3o graciosa em caso de falhas. Ou seja, fazer com que o servi\u00e7o continue funcionando, mesmo que com vaz\u00e3o reduzida, lat\u00eancia aumentada, com limita\u00e7\u00e3o no quantidade de conex\u00f5es paralelas suportadas, ou nas funcionalidades que mantem dispon\u00edvel. Para colaborar, as diversas partes do sistema distribu\u00eddo devem se comunicar. Isto pode ser feito de diversas formas e em diversos n\u00edveis de abstra\u00e7\u00e3o. Por exemplo, troca de mensagens , streams de dados , ou invoca\u00e7\u00e3o remota de procedimentos . Implementar estas abstra\u00e7\u00f5es em si j\u00e1 \u00e9 uma tarefa complicada, pois \u00e9 preciso levar em considera\u00e7\u00e3o que os componentes de um sistema distribu\u00eddo falham independentemente , executam em hosts com rel\u00f3gios dessincronizados , s\u00e3o desenvolvidos usando-se linguagens diversas , sistemas operacionais distintos , com arquiteturas diferentes e por times independentes . Apesar de tantas vari\u00e1veis, as abstra\u00e7\u00f5es precisam permitir que as aplica\u00e7\u00f5es que as usem possam se coordenar nos m\u00ednimos detalhes. Quero dizer, a complexidade de se implementar estas abstra\u00e7\u00f5es j\u00e1 \u00e9 grande por si s\u00f3 e se formos reinventar a roda a cada novo sistema, n\u00e3o faremos muitos avan\u00e7os. Mas, como voc\u00eas bem sabem, camadas de abstra\u00e7\u00e3o s\u00e3o a chave para se lidar com complexidade. Assim, sistemas distribu\u00eddos s\u00e3o como cebolas, cheias de camadas e que nos fazem chorar quando precisamos manipul\u00e1-las. Mas lembrem-se, tamb\u00e9m que e voc\u00ea n\u00e3o quer que seu sistema seja como ogros, temperamentais e mal-cheirosos. Felizmente, para cada problema que tenha que resolver, h\u00e1 uma boa probabilidade de que algu\u00e9m j\u00e1 o tenha atacado e disponibilizado uma solu\u00e7\u00e3o, de forma comercial ou n\u00e3o. Com sistemas distribu\u00eddos, n\u00e3o \u00e9 diferente, e no caso da comunica\u00e7\u00e3o entre componentes distribu\u00eddos, a solu\u00e7\u00e3o normalmente \u00e9 usar um middleware . Middleware De acordo com Tanenbaum & Van Steen , middleware \u00e9 ... the software layer that lies between the operating system and applications on each side of a distributed computing system in a network. Isto \u00e9, o middleware \u00e9 a camada ware que fica no middle , entre, o software e o hardware . Software, no caso, \u00e9 a aplica\u00e7\u00e3o distribu\u00edda sendo desenvolvida e hardware \u00e9 a abstra\u00e7\u00e3o do host em que se executam os componentes, provida pelo sistema operacional. Uso aqui o termo abstra\u00e7\u00e3o porqu\u00ea o sistema operacional pode encapsular hardware real, mas tamb\u00e9m pode encapsular outra abstra\u00e7\u00e3o de hardware , por exemplo, uma m\u00e1quina virtual ou cont\u00eainer. A figura seguinte 1 mostra um exemplo com tr\u00eas aplica\u00e7\u00f5es executando sobre um middleware , que por sua vez \u00e9 executado sobre diferentes sistemas operacionais, em hosts conectados por uma rede de comunica\u00e7\u00e3o. Com este cen\u00e1rio em mente, \u00e9 importante entender o que diz Sacha Krakowiak quando afirma que as principais fun\u00e7\u00f5es do middleware s\u00e3o: esconder a distribui\u00e7\u00e3o e o fato de que um aplica\u00e7\u00e3o \u00e9 geralmente composta por m\u00faltiplas partes, executando em localiza\u00e7\u00f5es geograficamente distintas, esconder a heterogeneidade dos v\u00e1rios componentes de hardware, sistemas operacionais e protocolos de comunica\u00e7\u00e3o prover interfaces uniformes, de alto n\u00edvel e padronizadas para os desenvolvedores de aplica\u00e7\u00e3o e integradores, de forma que aplica\u00e7\u00f5es possam ser facilmente compostas, reusadas, portadas e feitas interoper\u00e1veis. Assim, os middleware facilitam a conex\u00e3o entre componentes e permitem o uso de protocolos mais abstratos que as opera\u00e7\u00f5es de write(byte[]) e read(): byte[] dos de baixo n\u00edvel, escondendo a complexidade da coordena\u00e7\u00e3o de sistemas independentes. Desenvolver sistemas distribu\u00eddos sem usar um middleware \u00e9 como desenvolver um aplicativo qualquer, sem usar bibliotecas: poss\u00edvel, mas complicado, e estar\u00e1 certamente reinventando a roda. Isto \u00e9, voc\u00ea praticamente tem que refazer o middleware antes de desenvolver o sistema em si. Idealmente, com o middleware se obteria transpar\u00eancia total do fato da aplica\u00e7\u00e3o estar distribu\u00edda, levando o sistema, uma cole\u00e7\u00e3o de sistemas computacionais (software ou hardware) independentes, a se apresentar para o usu\u00e1rio como um sistema \u00fanico , centralizado. Pense no browser e na WWW: o quanto voc\u00ea sabe sobre as p\u00e1ginas estarem particionadas em milh\u00f5es de servidores? Transpar\u00eancia Podemos quebrar esta \"transpar\u00eancia total\" em v\u00e1rias transpar\u00eancias mais simples: Acesso , Localiza\u00e7\u00e3o , Reloca\u00e7\u00e3o , Migra\u00e7\u00e3o , Replica\u00e7\u00e3o , e Falha . Vejamos cada uma destas separadamente. Transpar\u00eancia de Acesso A transpar\u00eancia de acesso diz respeito \u00e0 representa\u00e7\u00e3o de dados e mecanismos de invoca\u00e7\u00e3o (arquitetura, formatos, linguagens...). Cada computador tem uma arquitetura e uma forma de representar seus dados. Por exemplo, considere os padr\u00f5es para representa\u00e7\u00e3o de n\u00fameros em ponto flutuante IEEE e IBM. Ambos dividem os bits em sinal, expoente e mantissa, mas com tamanhos diferentes. IEEE 2 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Half 16 1 5 10 Single 32 1 8 23 Double 64 1 11 52 Quadruple 128 1 15 112 IBM 3 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Single 32 1 7 24 Double 64 1 7 56 Quadruple 128 1 7 112 (8b ignorados) E se dois componentes de um SD executam em m\u00e1quinas com arquiteturas diferentes, como trocam n\u00fameros em ponto flutuante? \u00c9 preciso que usem um padr\u00e3o conhecido por ambos os hosts , seja o padr\u00e3o \"nativo\" da mesma, ou um padr\u00e3o intermedi\u00e1rio, definido pelo middleware . A mesma quest\u00e3o \u00e9 v\u00e1lida para representa\u00e7\u00f5es de strings e classes, e diferen\u00e7as de sistemas operacionais e linguagens. No caso espec\u00edfico das strings, pense em um programa escrito em linguagem C; uma string \u00e9 uma sequ\u00eancia de bytes imprim\u00edveis terminadas por um \\0 . J\u00e1 em um programa escrito em Java, uma string \u00e9 uma classe que encapsula uma sequ\u00eancia de chars, sendo que cada char \u00e9 um c\u00f3digo 16 bits representativo de um c\u00f3digo Unicode 4 . Como transferir strings entre duas plataforms? N\u00e3o faz\u00ea-lo? Simplificar a string Java? Estender a string C? Transpar\u00eancia de Acesso Para se tentar obter transapar\u00eancia de acesso, \u00e9 importante que se use padr\u00f5es implementados em m\u00faltiplas arquiteturas, abertos e bem conhecidos, com interfaces bem definidas . Transpar\u00eancia de Localiza\u00e7\u00e3o A transpar\u00eancia de localiza\u00e7\u00e3o diz respeito a onde est\u00e1 o objeto: pouco importa ao usu\u00e1rio, se o servi\u00e7o est\u00e1 dentro da mesma m\u00e1quina em que acessa o servi\u00e7o, se na sala do lado, ou na nuvem, do outro lado do globo, desde que o servi\u00e7o seja provido de forma r\u00e1pida e confi\u00e1vel. A esta transpar\u00eancia \u00e9 essencial uma boa distribui\u00e7\u00e3o do servi\u00e7o, sobre uma rede com baixa lat\u00eancia, ou o uso de t\u00e9cnicas que permitam esconder a lat\u00eancia. Escondendo a Lat\u00eancia Para se esconder a lat\u00eancia, v\u00e1rias t\u00e1ticas s\u00e3o utiliz\u00e1veis: Caching de dados Em vez de sempre buscar os dados no servidor, mantenha c\u00f3pias locais dos dados que mudam menos (e.g., o CSS do stackoverflow). Use paralelismo Em vez de validar formul\u00e1rio ap\u00f3s preenchimento de cada campo, valide em paralelo enquanto usu\u00e1rio preenche o campo seguinte. Use callbacks para indicar campos com problemas a serem corrigidos. Saiba que nem todo problema \u00e9 paraleliz\u00e1vel, por exemplo, autentica\u00e7\u00e3o Use programa\u00e7\u00e3o ass\u00edncrona AsyncIO C# await/async Futures e Promises Outra forma de diminuir lat\u00eancia \u00e9 trazer para pr\u00f3ximo do usu\u00e1rio parte da computa\u00e7\u00e3o. Isto \u00e9 comumente feito com a interface com usu\u00e1rio, mas pode ser usado tamb\u00e9m para outras partes do sistema. Como exemplo do primeiro, pense em consoles de video-game que fazem o processamento gr\u00e1fico pesado de jogos online na casa do usu\u00e1rio 5 . Como exemplo do segundo, pense em aplicativos que mant\u00e9m os dados em celulares at\u00e9 que uma boa conex\u00e3o, por exemplo WiFi, esteja dispon\u00edvel para sincronizar com o servidor. De forma geral, pense em esconder lat\u00eancia pelos seguintes passos: Distribua tarefas Delegue computa\u00e7\u00e3o aos clientes (e.g., JavaScript e Applets Java) Particione dados entre servidores (e.g., Domain Name Service e World Wide Web) para dividir a carga e aumentar a vaz\u00e3o Aproxime dados dos clientes Mantenha c\u00f3pias de dados em m\u00faltiplos lugares. Atualize dados de acordo com necessidade (e.g., cache do navegador, com c\u00f3digo do google.com sendo atualizado a cada 4 dias) Transpar\u00eancia de Reloca\u00e7\u00e3o As vezes componentes do sistema distribu\u00eddo precisam ser movimentados de uma localiza\u00e7\u00e3o \u00e0 outra, por exemplo porqu\u00ea um novo host foi contratado. Se implementadas corretamente, as t\u00e9cnicas que entregam transpar\u00eancia de localiza\u00e7\u00e3o n\u00e3o deixam que o cliente perceba a movimenta\u00e7\u00e3o, no que chamamos transpar\u00eancia de Reloca\u00e7\u00e3o. Rede de baixa lat\u00eancia Distribui\u00e7\u00e3o inteligente E.g: Servi\u00e7os de nome M\u00faltiplas c\u00f3pias C\u00f3pias tempor\u00e1rias Transpar\u00eancia de Migra\u00e7\u00e3o Do ponto de vista do pr\u00f3prio servi\u00e7o, n\u00e3o perceber que se est\u00e1 sendo movimentado \u00e9 chamado transpar\u00eancia de Migra\u00e7\u00e3o. Um servi\u00e7o com esta propriedade, n\u00e3o precisa ser parado e reconfigurado quando a mudan\u00e7a acontece. Uma das formas de se implementar esta propriedade \u00e9 atrav\u00e9s da migra\u00e7\u00e3o provida por m\u00e1quinas virtuais, usado, por exemplo, para consolidar o uso de servidores em nuvens computacionais. Veja o exemplo do VMotion da VMware Na verdade, a movimenta\u00e7\u00e3o neste cen\u00e1rio, \u00e9 uma c\u00f3pia da m\u00e1quina virtual. Uma vez que a c\u00f3pia esteja pr\u00f3xima do fim, a imagem original \u00e9 congelada, a c\u00f3pia conclu\u00edda, e h\u00e1 um chaveamento na rede para se direcionar toda comunica\u00e7\u00e3o para nova c\u00f3pia. O m\u00e1quina original \u00e9 ent\u00e3o descartada. Transpar\u00eancia de Replica\u00e7\u00e3o A capacidade de ter c\u00f3pias de um servi\u00e7o e de direcionar trabalho de uma para outra \u00e9 tamb\u00e9m \u00fatil para se obter transpar\u00eancia no caso de falhas. Isto porqu\u00ea para se manter um servi\u00e7o funcional a despeito de falhas, \u00e9 preciso ter m\u00faltiplas c\u00f3pias, prontas para funcionar a qualquer momento. Dependendo das garantias desejadas na manuten\u00e7\u00e3o da consist\u00eancia entre as c\u00f3pias, o custo pode variar muito, de forma que para se ter um custo menor, tem-se garantias mais fracas, por exemplo, que as r\u00e9plicas tem um atraso entre elas de no m\u00e1ximo $X$ minutos. Este \u00e9 um dilema parecido com o TCP x UDP, em que mais garantias implicam em maior custo de comunica\u00e7\u00e3o. Algumas aplica\u00e7\u00f5es toleram inconsist\u00eancias e podem viver com menores custos. Um exemplo famoso \u00e9 o dos \"carrinhos de compra\" da Amazon.com , que podem fechar pedidos com conte\u00fado diferente do desejado pelo cliente. Outras aplica\u00e7\u00f5es s\u00e3o normalmente constru\u00eddas com requisitos de consist\u00eancia forte entre as r\u00e9plicas, como sistemas financeiros. Para estas aplica\u00e7\u00f5es, uma t\u00e9cnica importante para se conseguir replica\u00e7\u00e3o \u00e9 o uso de frameworks de comunica\u00e7\u00e3o em grupo , que entregam para m\u00faltiplas inst\u00e2ncias de um mesmo servi\u00e7o, as mesmas mensagens, permitindo que elas se mantenham como c\u00f3pias. Esta t\u00e9cnica funciona se os servi\u00e7os forem m\u00e1quinas de estado determin\u00edsticas, que consideram como eventos as mensagens entregues pelo protocolo de comunica\u00e7\u00e3o em grupo e \u00e9 denominada **replica\u00e7\u00e3o de m\u00e1quinas de estado . TODO: Figura com state machine replication Novamente \u00e9 preciso chamar \u00e0 aten\u00e7\u00e3o a quest\u00e3o dos custos desta t\u00e9cnica. Replica\u00e7\u00e3o de M\u00e1quinas de Estados \u00e9 muito custosa e por isso faz-se um esfor\u00e7o para n\u00e3o utiliz\u00e1-la ou para utiliz\u00e1-la em \"cantinhos\" do sistema ondo inconsist\u00eancias s\u00e3o absolutamente caras demais para sere permitidas. Isto porqu\u00ea manter m\u00faltiplas c\u00f3pias $\\Rightarrow$ sincroniza\u00e7\u00e3o $\\Rightarrow$ custos. Se houver mudan\u00e7as frequentes nos dados, tal custo precisa ser pago tamb\u00e9m frequentemente. Mitiga\u00e7\u00f5es incluem uso de r\u00e9plicas tempor\u00e1rias, protocolos de invalida\u00e7\u00e3o de cache, contrata\u00e7\u00e3o de redes com mais largura de banda e menor lat\u00eancia, sendo que estes \u00faltimos esbarram em limita\u00e7\u00f5es financeiras e f\u00edsicas. Transpar\u00eancia de Concorr\u00eancia Outra transpar\u00eancia almej\u00e1vel \u00e9 de concorr\u00eancia. Isto \u00e9, quem acessa um servi\u00e7o deveria ser indiferente ao fato de que o mesmo pode estar sendo acessado por outros. Isto \u00e9 importante tanto em termos de seguran\u00e7a, no sentido de que um cliente n\u00e3o deveria acessar os dados do outro, caso isso seja um requisito do sistema, quanto tem termos de desempenho. Nuvens computacionais s\u00e3o um exemplo de onde este tipo de transpar\u00eancia \u00e9 essencial. Considere um servi\u00e7o de banco de dados em uma nuvem qualquer. Para prover a mesma interface com a qual usu\u00e1rios est\u00e3o acostumados a anos, \u00e9 poss\u00edvel que este servi\u00e7o seja simplesmente um wrapper ao redor do SGBD que se comprava e instalava in-house anteriormente. Para se tornar vi\u00e1vel, contudo, uma mesma inst\u00e2ncia deve servir m\u00faltiplos clientes, os tenants , sem que a carga de trabalho introduzida por um, interfira no desempenho do outro. No meio, chamamos esta propriedade de multi-tenancy , mas \u00e9 apenas um exemplo de transpar\u00eancia de concorr\u00eancia. Esta transpar\u00eancia est\u00e1 fundamentalmente ligada \u00e0 escalabilidade, isto \u00e9, \u00e0 adequa\u00e7\u00e3o dos pool de recursos \u00e0s demandas dos clientes: se mais clientes est\u00e3o presentes, ent\u00e3o aumente a quantidade de servidores ( scale up ) e separe as cargas ( sharding ); se menos clientes est\u00e3o presentes, ent\u00e3o desligue algumas m\u00e1quinas ( scale down ) e consolide recursos. Desafios para se obter transpar\u00eancia Apesar de desej\u00e1veis, as transpar\u00eancia discutidas s\u00e3o dif\u00edceis de se conseguir, principalmente se em conjunto. Isto porqu\u00ea, do ponto de vista de usu\u00e1rios espalhados pelo globo, atr\u00e1s de redes heterog\u00eaneas e com possibilidade de erros, acontecer\u00e3o atrasos e perdas na comunica\u00e7\u00e3o, denunciando a distribui\u00e7\u00e3o. Do ponto de vista do desenvolvedor , \u00e9 preciso tomar decis\u00f5es baseado em premissas ligadas \u00e0 realidade da rede. Por exemplo, se uma requisi\u00e7\u00e3o n\u00e3o foi respondida, quanto tempo um cliente deve esperar antes de reenvi\u00e1-la, possivelmente para outro servidor, sem incorrer em risco significativo da requisi\u00e7\u00e3o ser processada duas vezes? A resposta para esta pergunta \u00e9 muito mais complicada do que pode parecer. De forma geral , qualquer aumento de transpar\u00eancia tem um custo, seja em termos monet\u00e1rios (e.g., contrata\u00e7\u00e3o de enlace dedicado ou de host em outra posi\u00e7\u00e3o geogr\u00e1fica), ou em termos de desempenho (e.g., coordenar a entrega de mensagens em sistemas de comunica\u00e7\u00e3o em grupo). Provavelmente os maiores obst\u00e1culos para se alcan\u00e7ar os diversos tipos de transpar\u00eancia s\u00e3o impostos pela parte da infraestrutura que torna o sistema distribu\u00eddo poss\u00edvel, a rede. Para entender o porqu\u00ea, vejamos algumas premissas normalmente assumidas sobre a rede que n\u00e3o s\u00e3o, definitivamente, verdade: A lat\u00eancia \u00e9 zero. A largura de banda \u00e9 infinita. A rede \u00e9 confi\u00e1vel. A rede \u00e9 segura. A rede \u00e9 homog\u00eanea. A rede \u00e9 est\u00e1tica. A rede tem acesso gr\u00e1tis. A rede \u00e9 administrada por voc\u00ea ou algu\u00e9m acess\u00edvel. Escalabilidade Para terminar, deixem-me apenas retomar um termo usado acima, escalabilidade . O termo est\u00e1 muito em voga e \u00e9 usado, normalmente, para descrever a capacidade de um sistema de se adequar a varia\u00e7\u00f5es de carga de trabalho. Embora seja um uso v\u00e1lido, h\u00e1 outros tipos de escalabilidade. Escalabilidade Tamanho: N\u00famero de usu\u00e1rios que suporta. Geogr\u00e1fica: Regi\u00e3o que cobre. Administrativa: N\u00famero de dom\u00ednios administrativos. H\u00e1 v\u00e1rias possibilidades: seja espec\u00edfico e exija especificidade. Tipos Diversas s\u00e3o as finalidades dos sistemas distribu\u00eddos que constru\u00edmos, assim como s\u00e3o diversas as arquiteturas que usamos. Classifica\u00e7\u00f5es nos ajudam a pensar sobre sistemas e a encontrar e reusar solu\u00e7\u00f5es previamente testadas. Computa\u00e7\u00e3o de Alto Desempelho - High Performance Computing A possibilidade de agregar poder de processamento de muitos computadores em um rede de comunica\u00e7\u00e3o com alt\u00edssima largura de banda nos permite atacar problemas computacionalmente muito intensos. Clusters como o da imagem a seguir, do Hight Performance Computing Center de Stuttgart, s\u00e3o compartilhados por pesquisadores resolvendo problemas \u00e1reas como bio-inform\u00e1tica, engenharia, economia, intelig\u00eancia artificial, etc. Na engenharia, por exemplo, HPC pode ser usada para testar a efici\u00eancia de projetos sem construir prot\u00f3tipos, seja de uma turbina um carro ou uma vaca Os n\u00f3s de um cluster s\u00e3o normalmente divididos em tr\u00eas categorias: administra\u00e7ao, computa\u00e7\u00e3o e armazenamento. N\u00f3s de administra\u00e7\u00e3o implementam um monitoramento distribu\u00eddo dos demais n\u00f3s, servem de ponto de entrada para usu\u00e1rios e prov\u00eaem interface para submiss\u00e3o de tarefas. O Oscar , por exemplo, \u00e9 uma \u00e9 conjunto de softwares para gerenciamento de clusters. Uma das ferramentas inclusas no Oscar \u00e9 o OpenPBS, pelo qual tarefas s\u00e3o atribu\u00eddas aos diversos n\u00f3s do sistema que sejam alocados para tal tarefa. O OpenPBS portanto \u00e9 tamb\u00e9m um sistema distribu\u00eddo. Finalmente, as tarefas submetidas em si s\u00e3o normalmente aplica\u00e7\u00f5es distribu\u00eddas. Cada processo executando em uma m\u00e1quina distrinta \u00e9 normalmente respons\u00e1vel por resolver uma parte do problema. Para facilitar a comunica\u00e7\u00e3o entre as partes do dom\u00ednio, s\u00e3o normalmente utilizadas API como a Message Passing Interface (MPI), que prov\u00ea fun\u00e7\u00f5es para distribui\u00e7\u00e3o e agrega\u00e7\u00e3o de dados entre os v\u00e1rios processos. Este tipo de sistemas distribu\u00eddos s\u00e3o o que chamamos de fortemente acoplados pois a falha em um dos componentes leva normalmente \u00e0 falha de todo o sistema. Do ponto de vista deste curso, estamos mais interessados em sistemas fracamente acoplados. Sistemas de Informa\u00e7\u00e3o Provavelmente mais comuns entre os profissionais da computa\u00e7\u00e3o, os sistemas de informa\u00e7\u00e3o distribu\u00eddos s\u00e3o encontrados em diversas formas. De fato, o termo \"sistema de informa\u00e7\u00e3o\" \u00e9 t\u00e3o abrangente, que dificilmente um sistema distribu\u00eddo n\u00e3o estaria nesta classe. O seguinte \u00e9 um exemplo de uma arquitetura em tr\u00eas camadas, onde a primeira implementa a interface com o usu\u00e1rio, a segunda cont\u00e9m a l\u00f3gica do neg\u00f3cio, e a terceira mantem os dados. Pe\u00e7a fundamental desta abordagem, os bancos de dados na terceira camada s\u00e3o frequentemente transacionais. Isto \u00e9, eles prov\u00eaem as garantias na execu\u00e7\u00e3o de transa\u00e7\u00f5es conhecidas como propriedades ACID. ACID Atomicidade: transa\u00e7\u00f5es s\u00e3o tratadas de forma indivis\u00edvel, isto \u00e9, ou tudo ou nada. Consist\u00eancia: transa\u00e7\u00f5es levam banco de um estado consistente a outro. E.g., x == 2*y Isolamento: transa\u00e7\u00f5es n\u00e3o v\u00eaem dados n\u00e3o comitados umas das outras. Durabilidade: os efeitos de uma transa\u00e7\u00e3o comitada devem persistir no sistema a despeito de falhas. Para relembrar no que implica ACID, considere a seguinte sequ\u00eancia de opera\u00e7\u00f5es, onde X e Y s\u00e3o valores guardados pelo banco de dados, a, b e c s\u00e3o vari\u00e1veis definidas no programa, e SELECT e SET s\u00e3o comandos para ler e modificar o banco de dados. 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: SET Y=b Suponha duas inst\u00e2ncias desta sequ\u00eancia, $T_1$ e $T_2$, concorrentes, em que as opera\u00e7\u00f5es escalonadas da seguinte forma. T1 T2 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: a = SELECT X 6: c = a * 2 7: b = c + 10 8: SET X=c 9: SET Y=b 10:SET Y=b Ao final da execu\u00e7\u00e3o, X ter\u00e1 o valor atribu\u00eddo por $T_2$, mas $Y$ ter\u00e1 o valor de $T_1$. Este escalonamento violou a consist\u00eancia do banco de dados por qu\u00ea as opera\u00e7\u00f5es n\u00e3o foram executadas isoladamente . Tente imaginar a dificuldade de se implementar um banco de dados distribu\u00eddo. Isto \u00e9, um banco em que v\u00e1rios n\u00f3s mantem os dados, participam de transa\u00e7\u00f5es e, portanto, precisam coordenar-se para manter os dados consistentes. A figura a seguir mostra um cen\u00e1rio com tr\u00eas bancos. Imagine que em um deles est\u00e1 uma rela\u00e7\u00e3o com os dados dos clientes, em outro, os dados do estoque e no terceiro as ordens de compra. Quando um cliente faz um pedido, o cliente deve ser validado no primeiro n\u00f3, o item \u00e9 removido do estoque no segundo n\u00f3, e no terceiro \u00e9 disparada uma cobran\u00e7a para o cliente. Se qualquer destas tr\u00eas rela\u00e7\u00f5es n\u00e3o for corretamente consultada e alterada, os efeitos podem ser catastr\u00f3ficos para o neg\u00f3cio ou para o cliente. Como implementar ACID neste banco de dados? Embora veremos isso um pouco mais para frente neste material, por enquanto, apenas assuma que n\u00e3o \u00e9 exatamente f\u00e1cil ou barato. Esta dificuldade foi a raz\u00e3o do surgimento dos bancos de dados NOSQL (n\u00e9e NoSQL), dos quais uma pequena amostra \u00e9 dada pela seguinte figura. Tambem discutiremos como estes bancos de dados funcionam, quando falarmos sobre sistemas P2P. Integra\u00e7\u00e3o de Aplica\u00e7\u00f5es Frequentemente \u00e9 necess\u00e1rio integrar sistemas de informa\u00e7\u00e3o legados com sistemas mais modernos, ou simplesmente exp\u00f4-los usando uma interface mais moderna. Nestes casos, \u00e9 poss\u00edvel integrar diversos sistemas usando um middleware que os encapsule. O middleware pode, por exemplo, se expor via interface REST para os clientes, mas consultar o sistema legado em um padr\u00e3o antigo. Outro exemplo \u00e9 o sistema na imagem seguinte, que mostra diversos departamentos de uma empresa conversando via troca de mensagens. Observe que nenhum departamento precisa conversar diretamente com os outros, ou mesmo conhec\u00ea-los. Eles apenas publicam a mensagem para quem puder tratar. Da mesma forma, a resposta vem na forma de uma mensagem. Este \u00e9 um exemplo de sistema fracamente acoplado , pois nenhum componente tem que saber da exist\u00eancia do outro ou se torna indispon\u00edvel caso os outros falhem. Siga este link para ler mais sobre este tipo de sistema. Sistemas Pervasivos/Ub\u00edquos Segundo Weiser, 1993 Ubiquitous computing is the method of enhancing computer use by making many computers available throughout the physical environment, but making them effectively invisible to the user. O que \u00e9 importante aqui \u00e9 o foco na tarefa em vez de na ferramenta. Assim, sistemas pervasivos devem ajudar as pessoas a realizar suas tarefas, de forma impl\u00edcita, sem ter que pensar em como a tarefa ser\u00e1 executada. Para que seja realizada, a computa\u00e7\u00e3o pervasiva requer que dispositivos detectem o contexto em que est\u00e3o inseridos, combinem-se de forma ad-hod e compartilhem informa\u00e7\u00f5es . Veja alguns exemplos interessantes, fict\u00edcios e reais. Smart Life: Esta \u00e9 uma vis\u00e3o futur\u00edstica da Microsoft para a integra\u00e7\u00e3o de tecnologias. Amazon Go: Este mercado automatiza o pagamento dos itens escolhidos pelo consumidor, utilizando t\u00e9cnicas de processamento digital de imagens, aprendizado de m\u00e1quina e sensores. Reality Check: Para quem viu o filme Minority Report e sonhou com as UI do futuro, aqui vai um reality check . Para quem n\u00e3o viu ainda, corrija esta falha em sua forma\u00e7\u00e3o t\u00e9cnica o mais rapidamente poss\u00edvel. Redes de Sensores e Internet das Coisas Eu vou me arriscar colocando Redes de Sensores e Internet das Coisas como uma subsess\u00e3o de Sistemas Pervasivos. Isto porqu\u00ea, a meu ver, as redes de sensores s\u00e3o parte da infraestrutura para se obter sistemas pervasivos; s\u00e3o os sensores que percebem mudan\u00e7as contexto e \"le\u00eam\" o estado do contexto atual e alimentam outros sistemas que reagem a tal estado. A Internet das Coisas (IoT, do ingl\u00eas Internet of Things ) vai tamb\u00e9m na mesma linha, levando \u00e0 integra\u00e7\u00e3o entre sensores, atuadores, e outros dispositivos que nos servem, em um ambiente de computa\u00e7\u00e3o pervasiva. \"Mas se \u00e9 assim, qual o risco?\", voc\u00ea pergunta. Bem, a Internet das Coisas pode ser vista como algo al\u00e9m dos sistemas pervasivos, pois se estes \u00faltimos s\u00e3o focados nos humanos em um certo contexto, a IoT n\u00e3o necessariamente foca-se nos humanos, mas na realiza\u00e7\u00e3o de alguma tarefa. Por exemplo, um sistema de irriga\u00e7\u00e3o que percebe o n\u00edvel de humidade do ar, analisa previs\u00f5es de chuva e decide em quanto irrigar uma planta\u00e7\u00e3o de laranjas provavelmente n\u00e3o se importar\u00e1 com a presen\u00e7a ou n\u00e3o de um humano na planta\u00e7\u00e3o. Para aprender mais sobre IoT, veja este link que descreve diversos projetos europeus na \u00e1rea. TODO Alguns exemplos de IoT e redes de sensores: Smart grid e lavadora que escolhe hor\u00e1rio Termostatos que percebem movimento Fechaduras que se abrem quando o dono se aproxima Movimenta\u00e7\u00e3o de tropas e de fauna \u00cdndices de polui\u00e7\u00e3o Abalos s\u00edsmicos e predi\u00e7\u00e3o de avalanches link Uma nota sobre privacidade nos sistemas pervasivos \u00c0 medida em que aumentamos o ambiente ao nosso redor ou a n\u00f3s mesmos com dispositivos computacionais, por um lado facilitamos nossa vida pois somos assistidos por tais dispositivos, mas por outro, nos tornamos cada vez mais dependentes nos mesmos, com s\u00e9rios riscos \u00e0 nossa privacidade. Isto ocorre por que para que realizem suas tarefas, os sistemas pervasivos precisam de cada vez mais informa\u00e7\u00f5es sobre n\u00f3s, e h\u00e1 sempre o risco de que estas informa\u00e7\u00f5es sejam usadas de forma que n\u00e3o nos apetece. TODO Exemplos de problemas de privacidade. Roomba mapeando sua casa . Ghost in the shell Snow crash (Neil Stephenson) Computa\u00e7\u00e3o Utilit\u00e1ria Um tipo importante de sistema distribu\u00eddo mais recente s\u00e3o as nuvens computacionais, usadas no provimento de computa\u00e7\u00e3o utilit\u00e1ria. Este tipo de sistema, embora possa ser pensando como infraestrutura para outros sistemas distribu\u00eddos, s\u00e3o, na verdade, complexas pe\u00e7as de engenharia, com diversos subsistemas respons\u00e1veis por sincroniza\u00e7\u00e3o de rel\u00f3gios, monitora\u00e7\u00e3o de falhas, coleta de logs, roteamento eficiente tolerante a falhas, movimenta\u00e7\u00e3o de recursos virtualizados para consolida\u00e7\u00e3o de recursos f\u00edsicos, armazenamento redundante de dados, etc. O seguinte v\u00eddeo mostra, em 360 graus, um dos datacenters do Google, para que voc\u00ea tenha ideia da escala em que estes sistemas s\u00e3o constru\u00eddos. Para uma viagem fotogr\u00e1fica, siga este link Arquiteturas De acordo com David Garlan and Mary Shaw, January 1994, CMU-CS-94-166, em An Introduction to Software Architecture ... an architectural style determines the vocabulary of components and connectors that can be used in instances of that style, together with a set of constraints on how they can be combined. These can include topological constraints on architectural descriptions (e.g., no cycles). Other constraints\u2014say, having to do with execution semantics\u2014might also be part of the style definition. Em outras palavras, um estilo ou padr\u00e3o arquitetural \u00e9 o conjunto de princ\u00edpios que prov\u00ea uma infraestrutura abstrata para uma fam\u00edlia de sistemas, e promove o reuso de projeto ao prover solu\u00e7\u00f5es para problemas recorrentes e frequentes . Componentes e Conectores Quando falamos sobre arquiteturas em sistemas distribu\u00eddos, estamos primariamente focados na forma como componentes se conectam, por meio de conectores, para implementar a solu\u00e7\u00e3o para um problema. Dependendo de como s\u00e3o conectados, haver\u00e1 maior ou menor depend\u00eancia entre os componentes. Quando houver forte depend\u00eancia, diremos que os componentes est\u00e3o fortemente acoplados ( tightly coupled ). Caso contr\u00e1rio, diremos que est\u00e3o fracamente acoplados ( loosely coupled ). A raz\u00e3o \u00f3bvia para preferir sistemas fracamente conectados \u00e9 sua capacidade de tolerar disrup\u00e7\u00f5es; se um componente depende pouco de outro, ent\u00e3o n\u00e3o se incomodar\u00e1 com sua aus\u00eancia por causa de uma falha. Certos middleware permitem um acoplamento t\u00e3o fraco entre componentes, que estes n\u00e3o precisam se conhecer ou sequer estar ativos no mesmo momento. Tamb\u00e9m a quest\u00e3o da simplifica\u00e7\u00e3o de API, uma vez que o middleware pode impor um padr\u00e3o a ser seguido por todos os componentes e minimizar a necessidade os componentes conhecerem as interfaces uns dos outros. Cliente/Servidor A forma como os componentes se comunicam, isto \u00e9, os conectores usados, \u00e9 importante no estudo arquitetural. Mas tamb\u00e9m s\u00e3o importantes os pap\u00e9is assumidos pelos componentes na realiza\u00e7\u00e3o de tarefas. Neste sentido, provavelmente a arquitetura de computa\u00e7\u00e3o distribu\u00edda mais famosa \u00e9 a Cliente/Servidor . Na arquitetura Cliente/Servidor, como implicado pelo nome, h\u00e1 um processo que serve a pedidos realizados por outros processos. Isto \u00e9 feito quando o cliente o contacta o servidor e requer ( request ) a realiza\u00e7\u00e3o do servi\u00e7o. O servidor , por sua vez, pode desempenhar tarefas como fazer c\u00e1lculos, armazenar dados, ou repassar uma mensagem e, ao final da realiza\u00e7\u00e3o da tarefa, responder ( response ) ao cliente. Um mesmo servidor pode atender a diversos clientes e, geralmente, a comunica\u00e7\u00e3o entre os mesmos \u00e9 feita diretamente por sockets. Embora seja poss\u00edvel usar sockets de forma ass\u00edncrona, a API mais comum \u00e9 s\u00edncrona, isto \u00e9, quando um processo espera receber uma mensagem de outro, ele fica bloqueado esperando algum dado estar dispon\u00edvel para leitura no referido socket. Assim, geralmente a comunica\u00e7\u00e3o entre cliente e servidor segue o seguinte esquema: Observe que o cliente fica inativo enquanto espera a resposta e que o servidor fica inativo enquanto espera outras requisi\u00e7\u00f5es. Para minimizar os per\u00edodos de inatividade, o cliente pode usar o socket ass\u00edncronamente, o que n\u00e3o \u00e9 exatamente simples, ou usar m\u00faltiplos threads, para que continue operando mesmo enquanto um thread estiver bloqueado esperando a resposta do servidor. No lado do servidor, o minimiza\u00e7\u00e3o da ociosidade \u00e9 feita pelo uso de m\u00faltiplos clientes, concorrentes, e tamb\u00e9m pelo uso de m\u00faltiplos threads. Neste caso, contudo, \u00e9 necess\u00e1rio tomar muito cuidado para garantir que a concorr\u00eancia n\u00e3o causar\u00e1 efeitos indesejados nos dados e execu\u00e7\u00e3o das tarefas. Veja o caso de um banco de dados transacional, por exemplo, como discutido acima; ele precisa garantir ACID entre as transa\u00e7\u00f5es propostas pelos clientes. Embora tenhamos colocado aqui apenas um servidor atendendo aos clientes, em muitas aplica\u00e7\u00f5es modernas, m\u00faltiplos servidores atender\u00e3o ao conjunto de clientes. Pense por exemplo no servi\u00e7o de email do Google, o Gmail. Com os milh\u00f5es de usu\u00e1rios que tem, certamente h\u00e1 mais de um servidor implementando o servi\u00e7o. Provavelmente estes diversos servidores ficam atr\u00e1s do que chamamos de um balanceador de carga, que roteia as requisi\u00e7\u00f5es seguindo diferentes pol\u00edticas, por exemplo, round robin . Par-a-Par (P2P) Diferentemente de sistemas cliente/servidor, em que um n\u00f3 serve o outro, em sistemas par-a-par, os n\u00f3s s\u00e3o parceiros e tem igual responsabilidade (e da\u00ed o nome) na execu\u00e7\u00e3o das tarefas. Diversos sistemas P2P existem, sendo, provavelmente, os mais famosos, os sistemas de compartilhamento de arquivos. Nesta linha, embora diversos tenham existido, hoje o mais famoso \u00e9 o Bittorrent, mesmo que, como veremos adiante, n\u00e3o seja P2P puro. Outro exemplo importante por ter inspirado diversos outros sistemas \u00e9 o Chord. Neste sistema, n\u00f3s organizam-se em um anel l\u00f3gico e cada um se torna respons\u00e1vel por um dos segmentos do anel adjacente a onde se encontra no mesmo. Requisi\u00e7\u00f5es para correspondentes a um segmento s\u00e3o roteados para o n\u00f3 respons\u00e1vel usando uma tabela de rotas conhecida como finger table . Se tra\u00e7armos os caminhos apontados por esta tabela sobre o anel, desenharemos cordas sobre o mesmo, o que explica o nome do sistema. H\u00edbridos Embora cliente/servidor e P2P sejam arquiteturas cl\u00e1ssicas, boa parte dos sistemas que distribu\u00eddos podem ser na verdade consideradas h\u00edbridos. Considere um sistema de email, por exemplo. Embora clientes usem as funcionalidades dos servidores de email para enviar e receber mensagens, os servidores conversam uns com os outros para implementar a tarefa de encaminhar as mensagens. Neste sentido, o sistema \u00e9 um h\u00edbrido P2P e cliente/servidor. Outros exemplos abundam. Bancos de dados, e.g., DynamoDB, CassandraDB , Redis,... Jogos multiplayer (pense no particionamento dos mapas ) Compartilhamento de arquivos: Bittorrent Voltemos ao exemplo do Bittorrent; observe na figura adiante os diversos passos necess\u00e1rios \u00e0 recupera\u00e7\u00e3o do arquivo de interesse neste sistema. Diversos passos seguem a arquitetura cliente/servidor enquanto \"somente\" o passo de compartilhamento de arquivos \u00e9 P2P. Voltando ao exemplo do sistema de informa\u00e7\u00e3o, observe que o cliente acessa um servi\u00e7o, implementado por pares de n\u00f3s. Podemos dizer que tamb\u00e9m este \u00e9 h\u00edbrido. Sistemas multi-camadas Outra forma de hibridismo que podemos citar \u00e9 quando um componente haje tanto como cliente quanto como servidor. Veja o seguinte exemplo, conhecido no meio como arquitetura em 3-camadas (3 tiers ). Neste caso, \u00e9 interessante notar que esta disposi\u00e7\u00e3o dos componentes \u00e9 independente da disposi\u00e7\u00e3o f\u00edsica. De fato, as tr\u00eas camadas podem estar em um mesmo n\u00f3, ou combinadas duas a duas, neste \u00faltimo caso resultando em duas camadas. Por outro lado, cada camada pode ser subdividida em mais componentes, resultando \u00e9 m\u00faltiplos tiers, como neste exemplo de um sistema de busca na Web. Outras arquiteturas Diversas outras arquiteturas podem e foram propostas para o desenvolvimento de Sistemas Distribu\u00eddos. A moda da vez \u00e9 a chamada arquitetura de micro servi\u00e7os, na qual a divis\u00e3o de tarefas entre componentes visa levar aos componentes mais simples para tal tarefa. Assim, os mesmos podem ser replicados, escalonados, desenvolvidos e mantidos independentemnte. Cada tarefa conta ent\u00e3o com diversos componentes, organizados em camadas resolvendo um problema em espec\u00edfico, mas todos contribuindo para a realiza\u00e7\u00e3o de uma tarefa maior comum. N\u00f3s discutiremos micro-servi\u00e7os mais adiante. Por agora, apenas tenha em mente que embora seja vendido por muitos como tal, os micro-servi\u00e7os n\u00e3o s\u00e3o uma panac\u00e9ia . TODO Event sourcing Para aprender mais Para aprender mais sobre arquiteturas, consulte a seguinte refer\u00eancia: Distributed System Architectures and Architectural Styles . Para aprender um pouco sobre como funcionam as redes de um datacenter, definidas por software, assista ao seguinte v\u00eddeo, que fala sobre a infra-estrutura do Facebook. Cap\u00edtulo 1, Figura 1, Distributed Systems: Principles and Paradigms \u21a9 IEEE Floating Point \u21a9 IBM Floating Point \u21a9 Simplifica\u00e7\u00f5es s\u00e3o poss\u00edveis, mas introduzem outras complexidades. \u21a9 O Google stadia \u00e9 uma plataforma de jogos que vai na contram\u00e3o desta ideia, levando todo o processamento pesado para a nuvem. \u21a9","title":"Introdu\u00e7\u00e3o"},{"location":"intro/#introducao","text":"As \u00e1reas ligadas ao desenvolvimentos de sistemas computacionais, como Ci\u00eancia e Engenharia de Computa\u00e7\u00e3o e Sistemas de Informa\u00e7\u00e3o, est\u00e3o extremamente em voga e tem atra\u00eddo mais e mais profissionais, mais ou menos qualificados, tornando este mercado cada vez mais competitivo . Ter conhecimentos espec\u00edficos da sub\u00e1rea de desenvolvimento de sistemas distribu\u00eddos e pode ser uma excelente vantagem e forma de se destacar de seus colegas e competidores. \"Como assim?\", voc\u00ea pergunta, j\u00e1 que nunca ouviu falar em sistemas distribu\u00eddos at\u00e9 ter que se matricular nesta disciplina. Bem, o desenvolvimento da teoria da computa\u00e7\u00e3o distribu\u00edda, na forma do estudo de algoritmos e t\u00e9cnicas de implementa\u00e7\u00e3o, e sua coloca\u00e7\u00e3o em pr\u00e1tica, na forma do desenvolvimento de sistemas distribu\u00eddos, n\u00e3o \u00e9 t\u00e3o \"quente\" como outras \u00e1reas, por exemplo intelig\u00eancia artificial e ci\u00eancia de dados. Mas acontece que sem a computa\u00e7\u00e3o distribu\u00edda, nenhum desenvolvimento s\u00e9rio destas outras \u00e1reas, sedentas por desempenho, escalaria para problemas reais. Veja por exemplo a seguinte descri\u00e7\u00e3o dos skills necess\u00e1rios para atuar como cientista de dados ou como engenheiro no Facebook . Se estiver convencido de que esta \u00e9 uma \u00e1rea importante, \u00f3timo! Neste curso apesentaremos uma vis\u00e3o geral do que s\u00e3o sistemas distribu\u00eddos, por qu\u00eas t\u00e9cnicos para os desenvolvemos, e como faz\u00ea-lo, com uma forte componente pr\u00e1tica, por meio do desenvolvimento de um projeto com (um dos) p\u00e9s na realidade. Caso contr\u00e1rio, bem, voc\u00ea n\u00e3o tem muita escolha, certo? Ent\u00e3o tente aproveitar esta vis\u00e3o geral para praticar um pouco de programa\u00e7\u00e3o neuro-ligu\u00edstica e repita o seguinte mantra: heeeeeeeuuuuummmmmm amo computa\u00e7\u00e3o distribu\u00edda. Brincadeiras a parte, voc\u00ea desenvolver\u00e1 um projeto em v\u00e1rias etapas que lhe permitir\u00e1 exercitar os conceitos vistos aqui e que te levar\u00e1 a: programar processos que se comuniquem via redes de computadores; conhecer arquiteturas cl\u00e1ssicas de sistemas distribu\u00eddos (e.g, cliente/servidor, p2p e h\u00edbrida), seus usos e limita\u00e7\u00f5es; escrever programas multithreaded simples e a entender como o uso de multithreading afeta os componentes de um sistema distribu\u00eddo; entender a problem\u00e1tica da coordena\u00e7\u00e3o e do controle de concorr\u00eancia em sistemas distribu\u00eddos; entender o uso de sistemas de nomea\u00e7\u00e3o em sistemas distribu\u00eddos bem como diversas formas de se implementar tais sistemas de nomea\u00e7\u00e3o; entender os conceitos b\u00e1sicos de replica\u00e7\u00e3o e toler\u00e2ncia a falhas; entender as implica\u00e7\u00f5es da dessincroniza\u00e7\u00e3o de rel\u00f3gios na coordena\u00e7\u00e3o, replica\u00e7\u00e3o e toler\u00e2ncia a falhas; projetar sistemas com componentes geograficamente distantes, fracamente acoplados; entender onde os diversos middleware podem ser usados para acoplar tais componentes; conhecer v\u00e1rias t\u00e9cnicas que controle de concorr\u00eancia controlar o acesso a um recurso compartilhado;","title":"Introdu\u00e7\u00e3o"},{"location":"intro/#o-que","text":"Mas afinal, o qu\u00ea \u00e9 um sistema distribu\u00eddo? Talvez seja mais f\u00e1cil come\u00e7armos por sistemas n\u00e3o distribu\u00eddos, ou como normalmente os denominamos, sistemas centralizados. Pense na maioria das aplica\u00e7\u00f5es que desenvolveu no curso at\u00e9 agora. Elas provavelmente executam integralmente em um \u00fanico processo, executando em uma \u00fanica m\u00e1quina. Mesmo que use diferentes bibliotecas e frameworks , toda l\u00f3gica de neg\u00f3cio, armazenamento e interface com usu\u00e1rio est\u00e1 contida em um mesmo lugar, e por isso s\u00e3o chamadas centralizadas. Quando come\u00e7ou a programar este tipo de aplica\u00e7\u00e3o, o trabalho era basicamente colar blocos Lego, que se encaixavam perfeitamente, bastando importar a biblioteca correta e invocar suas fun\u00e7\u00f5es. O cen\u00e1rio deve ter mudado um pouco no decorrer do curso e com o in\u00edcio de sua atividade profissional, quando passou a ter muito mais blocos, de muito mais tipos, para encaixar uns nos outros, aumentando consideravelmente a complexidade do desenvolvimento. Mesmo que haja diferentes bibliotecas a serem usadas, com desenvolvedores e estilos diferentes, bem ou mal testadas, seus encaixes ainda fazem sentido. Infelizmente, programar sistemas distribu\u00eddos \u00e9 muito mais complexo que sistemas centralizados. Frequentemente temos pe\u00e7as que nunca foram pensadas para trabalharem juntas, e nos resta usar um pouco de crazy glue , persuas\u00e3o, e muito arame. No caso, o arame \u00e9 de um tipo especial conhecido como cabo de rede, usado para estabelecer um canal de comunica\u00e7\u00e3o entre as diferentes partes do sistema. De fato, a principal caracter\u00edstica de um sistema distribu\u00eddo em rela\u00e7\u00e3o a um n\u00e3o distribu\u00eddo, \u00e9 a separa\u00e7\u00e3o de suas partes em v\u00e1rios componentes independentes (processos, sensores, atuadores), mas que se coordenam por meio de canais de comunica\u00e7\u00e3o para execu\u00e7\u00e3o de alguma tarefa. Assim, uma poss\u00edvel defini\u00e7\u00e3o de Sistema Distribu\u00eddo, que me agrada, \u00e9 a seguinte: Sistema Distribu\u00eddo Cole\u00e7\u00e3o de sistemas computacionais (software ou hardware), independentes mas com alguma forma de comunica\u00e7\u00e3o, que colaboram na execu\u00e7\u00e3o de alguma tarefa. Uma defini\u00e7\u00e3o mais c\u00ednica mas definitivamente realista \u00e9 a de Leslie Lamport , que certa vez disse: A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable. Mas se esta \u00e9 a realidade da programa\u00e7\u00e3o distribu\u00edda, por qu\u00ea faz\u00ea-lo?","title":"O qu\u00ea?"},{"location":"intro/#por-que","text":"Todos estamos a par de que aplica\u00e7\u00f5es importantes nos dias de hoje s\u00e3o aplica\u00e7\u00f5es distribu\u00eddas rodando em grandes data centers com milhares de m\u00e1quinas . Alguns exemplos \u00f3bvios s\u00e3o Amazon.com , Facebook , e GMail . Mas as raz\u00f5es que levam a este cen\u00e1rio s\u00e3o v\u00e1lidas para diversas outras aplica\u00e7\u00f5es. De fato, praticamente qualquer sistema de informa\u00e7\u00e3o que precise atingir um p\u00fablico consider\u00e1vel, necessitar\u00e1 aplicar t\u00e9cnicas de computa\u00e7\u00e3o distribu\u00edda para conseguir escalar , isto \u00e9, \"ser grande\", seja no n\u00famero de clientes que atende (computacionais ou humanos), seja em sua \u00e1rea de cobertura, ou na qualidade do servi\u00e7o que presta, mesmo que n\u00e3o cheguem a estas escalas. Este \u00faltimo ponto, sobre qualidade do servi\u00e7o, tem a ver com a capacidade de um sistema se manter no ar a despeito de problemas, isto \u00e9, de ser tolerante a falhas. Toler\u00e2ncia a falhas implica em redund\u00e2ncia, em c\u00f3pias, o que fatidicamente implica em distribui\u00e7\u00e3o e em Sistemas Distribu\u00eddos . H\u00e1 quem diga que somos todos desenvolvedores de sistemas distribu\u00eddos agora . O fato \u00e9 que computadores individuais tem capacidade limitada de processamento e armazenamento, mas nossa necessidade de poder computacional cresce exponencialmente. Assim, precisamos crescer nosso poder computacional, mas aumentar a capacidade de um dispositivo ( scale up ) mesmo de forma linear tem custo exponencial. O que nos resta ent\u00e3o \u00e9 agregar o poder computacional de diversos computadores \"baratos\" ( scale out ) para satisfazer nossas necessidades. O rem\u00e9dio, contudo, \u00e9 bem amargo: com muitos computadores conectados, vem a necessidade de coorden\u00e1-los, de forma a agir de forma coerente, mesmo quando alguns deles falhem, e quanto mais computadores, maior \u00e9 a probabilidade de que pelo menos um deles tenha uma CPU, disco, fonte, ou que quer que seja, falhando. E estejam certos, computadores falham o tempo todo! N\u00f3s precisamos ent\u00e3o entender este ambiente e determinar qual a probabilidade de um n\u00f3 falhar; como os computadores, ou melhor, como os processos se comunicam; se mensagens podem ser perdidas, atrasadas, corrompidas; se os rel\u00f3gios dos computadores s\u00e3o sincronizados; se h\u00e1 agentes maliciosos que possam querer perturbar o sistema; quais os padr\u00f5es de acesso ao servi\u00e7os, isto \u00e9, se aumentam \u00e0 noite, diminuem no ver\u00e3o, etc. Assim, definimos modelos computacionais , que nos permitem desenvolver algoritmos adequados aos diversos problemas que enfrentamos. Modelos cl\u00e1ssicos englobam tr\u00eas vari\u00e1veis: Comunica\u00e7\u00e3o; Sincronismo; e, Falhas. Definido o modelo computacional, podemos distribuir nosso sistema, isto \u00e9, dividir a computa\u00e7\u00e3o/armazenamento em diversas m\u00e1quinas, e coordenar suas a\u00e7\u00f5es para que sejam consistentes com a especifica\u00e7\u00e3o, de forma a minimizar o tempo que o servi\u00e7o fica fora do ar, entregando o servi\u00e7o de acordo com expectativas especificadas. Para isto, precisamos entender como falhas (bugs, por exemplo) afetam a execu\u00e7\u00e3o; como evitar que a falha de algum componente possa levar o sistema a parar como um todo; e garantir que clientes em qualquer lugar do mundo tenham a mesma facilidade em acessar o servi\u00e7o. Vejamos algumas exemplos de tarefas executadas por sistemas distribu\u00eddos, que voc\u00ea usa hoje. Entregue este email para fulano@knowhere.uni. Envie o item X para este endere\u00e7o, ap\u00f3s cobran\u00e7a de Y dinheiros da conta Z. Em um ambiente de simula\u00e7\u00e3o de batalhas em 3D, simule o disparo de um proj\u00e9til nesta dire\u00e7\u00e3o e sentido, com velocidade v, enquanto movimenta o avatar A para a esquerda. Autorize a transfer\u00eancia de X dinheiros da conta C para a conta C'. Movimente o bra\u00e7o mec\u00e2nico que est\u00e1 segurando um bisturi, 3cm \u00e0 direita, ent\u00e3o abaixe-o 3mm, e movimente-o 4cm para a esquerda Inclua o coment\u00e1rio ``LOL!!!'' na lista de coment\u00e1rios do item XYZ, com marca de tempo T Leia o valor do sensor de temperatura S e, caso seu valor supere V, emita alarme luminoso vermelho intermitente e alarme sonoro Um sistema distribu\u00eddo implica em algum tipo de colabora\u00e7\u00e3o entre componentes, para permitir que recursos de um sejam usados por outro. Por exemplo, capacidade de armazenamento, de processamento, conex\u00e3o f\u00edsica com uma impressora, ou localiza\u00e7\u00e3o geogr\u00e1fica. Por qu\u00ea distribuir? As principais raz\u00f5es para se desenvolver sistemas distribu\u00eddos s\u00e3o duas, ambas resultantes da agrega\u00e7\u00e3o (correta) do poder computacional de m\u00faltiplas m\u00e1quinas: escalabilidade e toler\u00e2ncia a falhas.","title":"Por qu\u00ea?"},{"location":"intro/#como","text":"Refor\u00e7ando, distribuir \u00e9 dividir a computa\u00e7\u00e3o/armazenamento em diversos componentes, possivelmente geograficamente distantes , e coordenar suas a\u00e7\u00f5es para que resolvam a tarefa em quest\u00e3o de forma correta. Com a distribui\u00e7\u00e3o objetiva-se usar recursos dispon\u00edveis nos hosts onde os componentes s\u00e3o executados e usar de redund\u00e2ncia para garantir que o servi\u00e7o sofra degrada\u00e7\u00e3o graciosa em caso de falhas. Ou seja, fazer com que o servi\u00e7o continue funcionando, mesmo que com vaz\u00e3o reduzida, lat\u00eancia aumentada, com limita\u00e7\u00e3o no quantidade de conex\u00f5es paralelas suportadas, ou nas funcionalidades que mantem dispon\u00edvel. Para colaborar, as diversas partes do sistema distribu\u00eddo devem se comunicar. Isto pode ser feito de diversas formas e em diversos n\u00edveis de abstra\u00e7\u00e3o. Por exemplo, troca de mensagens , streams de dados , ou invoca\u00e7\u00e3o remota de procedimentos . Implementar estas abstra\u00e7\u00f5es em si j\u00e1 \u00e9 uma tarefa complicada, pois \u00e9 preciso levar em considera\u00e7\u00e3o que os componentes de um sistema distribu\u00eddo falham independentemente , executam em hosts com rel\u00f3gios dessincronizados , s\u00e3o desenvolvidos usando-se linguagens diversas , sistemas operacionais distintos , com arquiteturas diferentes e por times independentes . Apesar de tantas vari\u00e1veis, as abstra\u00e7\u00f5es precisam permitir que as aplica\u00e7\u00f5es que as usem possam se coordenar nos m\u00ednimos detalhes. Quero dizer, a complexidade de se implementar estas abstra\u00e7\u00f5es j\u00e1 \u00e9 grande por si s\u00f3 e se formos reinventar a roda a cada novo sistema, n\u00e3o faremos muitos avan\u00e7os. Mas, como voc\u00eas bem sabem, camadas de abstra\u00e7\u00e3o s\u00e3o a chave para se lidar com complexidade. Assim, sistemas distribu\u00eddos s\u00e3o como cebolas, cheias de camadas e que nos fazem chorar quando precisamos manipul\u00e1-las. Mas lembrem-se, tamb\u00e9m que e voc\u00ea n\u00e3o quer que seu sistema seja como ogros, temperamentais e mal-cheirosos. Felizmente, para cada problema que tenha que resolver, h\u00e1 uma boa probabilidade de que algu\u00e9m j\u00e1 o tenha atacado e disponibilizado uma solu\u00e7\u00e3o, de forma comercial ou n\u00e3o. Com sistemas distribu\u00eddos, n\u00e3o \u00e9 diferente, e no caso da comunica\u00e7\u00e3o entre componentes distribu\u00eddos, a solu\u00e7\u00e3o normalmente \u00e9 usar um middleware .","title":"Como?"},{"location":"intro/#middleware","text":"De acordo com Tanenbaum & Van Steen , middleware \u00e9 ... the software layer that lies between the operating system and applications on each side of a distributed computing system in a network. Isto \u00e9, o middleware \u00e9 a camada ware que fica no middle , entre, o software e o hardware . Software, no caso, \u00e9 a aplica\u00e7\u00e3o distribu\u00edda sendo desenvolvida e hardware \u00e9 a abstra\u00e7\u00e3o do host em que se executam os componentes, provida pelo sistema operacional. Uso aqui o termo abstra\u00e7\u00e3o porqu\u00ea o sistema operacional pode encapsular hardware real, mas tamb\u00e9m pode encapsular outra abstra\u00e7\u00e3o de hardware , por exemplo, uma m\u00e1quina virtual ou cont\u00eainer. A figura seguinte 1 mostra um exemplo com tr\u00eas aplica\u00e7\u00f5es executando sobre um middleware , que por sua vez \u00e9 executado sobre diferentes sistemas operacionais, em hosts conectados por uma rede de comunica\u00e7\u00e3o. Com este cen\u00e1rio em mente, \u00e9 importante entender o que diz Sacha Krakowiak quando afirma que as principais fun\u00e7\u00f5es do middleware s\u00e3o: esconder a distribui\u00e7\u00e3o e o fato de que um aplica\u00e7\u00e3o \u00e9 geralmente composta por m\u00faltiplas partes, executando em localiza\u00e7\u00f5es geograficamente distintas, esconder a heterogeneidade dos v\u00e1rios componentes de hardware, sistemas operacionais e protocolos de comunica\u00e7\u00e3o prover interfaces uniformes, de alto n\u00edvel e padronizadas para os desenvolvedores de aplica\u00e7\u00e3o e integradores, de forma que aplica\u00e7\u00f5es possam ser facilmente compostas, reusadas, portadas e feitas interoper\u00e1veis. Assim, os middleware facilitam a conex\u00e3o entre componentes e permitem o uso de protocolos mais abstratos que as opera\u00e7\u00f5es de write(byte[]) e read(): byte[] dos de baixo n\u00edvel, escondendo a complexidade da coordena\u00e7\u00e3o de sistemas independentes. Desenvolver sistemas distribu\u00eddos sem usar um middleware \u00e9 como desenvolver um aplicativo qualquer, sem usar bibliotecas: poss\u00edvel, mas complicado, e estar\u00e1 certamente reinventando a roda. Isto \u00e9, voc\u00ea praticamente tem que refazer o middleware antes de desenvolver o sistema em si. Idealmente, com o middleware se obteria transpar\u00eancia total do fato da aplica\u00e7\u00e3o estar distribu\u00edda, levando o sistema, uma cole\u00e7\u00e3o de sistemas computacionais (software ou hardware) independentes, a se apresentar para o usu\u00e1rio como um sistema \u00fanico , centralizado. Pense no browser e na WWW: o quanto voc\u00ea sabe sobre as p\u00e1ginas estarem particionadas em milh\u00f5es de servidores?","title":"Middleware"},{"location":"intro/#transparencia","text":"Podemos quebrar esta \"transpar\u00eancia total\" em v\u00e1rias transpar\u00eancias mais simples: Acesso , Localiza\u00e7\u00e3o , Reloca\u00e7\u00e3o , Migra\u00e7\u00e3o , Replica\u00e7\u00e3o , e Falha . Vejamos cada uma destas separadamente.","title":"Transpar\u00eancia"},{"location":"intro/#transparencia-de-acesso","text":"A transpar\u00eancia de acesso diz respeito \u00e0 representa\u00e7\u00e3o de dados e mecanismos de invoca\u00e7\u00e3o (arquitetura, formatos, linguagens...). Cada computador tem uma arquitetura e uma forma de representar seus dados. Por exemplo, considere os padr\u00f5es para representa\u00e7\u00e3o de n\u00fameros em ponto flutuante IEEE e IBM. Ambos dividem os bits em sinal, expoente e mantissa, mas com tamanhos diferentes. IEEE 2 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Half 16 1 5 10 Single 32 1 8 23 Double 64 1 11 52 Quadruple 128 1 15 112 IBM 3 Precis\u00e3o Tamanho total (bits) Sinal (bits) Expoente (bits) Mantissa (bits) Single 32 1 7 24 Double 64 1 7 56 Quadruple 128 1 7 112 (8b ignorados) E se dois componentes de um SD executam em m\u00e1quinas com arquiteturas diferentes, como trocam n\u00fameros em ponto flutuante? \u00c9 preciso que usem um padr\u00e3o conhecido por ambos os hosts , seja o padr\u00e3o \"nativo\" da mesma, ou um padr\u00e3o intermedi\u00e1rio, definido pelo middleware . A mesma quest\u00e3o \u00e9 v\u00e1lida para representa\u00e7\u00f5es de strings e classes, e diferen\u00e7as de sistemas operacionais e linguagens. No caso espec\u00edfico das strings, pense em um programa escrito em linguagem C; uma string \u00e9 uma sequ\u00eancia de bytes imprim\u00edveis terminadas por um \\0 . J\u00e1 em um programa escrito em Java, uma string \u00e9 uma classe que encapsula uma sequ\u00eancia de chars, sendo que cada char \u00e9 um c\u00f3digo 16 bits representativo de um c\u00f3digo Unicode 4 . Como transferir strings entre duas plataforms? N\u00e3o faz\u00ea-lo? Simplificar a string Java? Estender a string C? Transpar\u00eancia de Acesso Para se tentar obter transapar\u00eancia de acesso, \u00e9 importante que se use padr\u00f5es implementados em m\u00faltiplas arquiteturas, abertos e bem conhecidos, com interfaces bem definidas .","title":"Transpar\u00eancia de Acesso"},{"location":"intro/#transparencia-de-localizacao","text":"A transpar\u00eancia de localiza\u00e7\u00e3o diz respeito a onde est\u00e1 o objeto: pouco importa ao usu\u00e1rio, se o servi\u00e7o est\u00e1 dentro da mesma m\u00e1quina em que acessa o servi\u00e7o, se na sala do lado, ou na nuvem, do outro lado do globo, desde que o servi\u00e7o seja provido de forma r\u00e1pida e confi\u00e1vel. A esta transpar\u00eancia \u00e9 essencial uma boa distribui\u00e7\u00e3o do servi\u00e7o, sobre uma rede com baixa lat\u00eancia, ou o uso de t\u00e9cnicas que permitam esconder a lat\u00eancia.","title":"Transpar\u00eancia de Localiza\u00e7\u00e3o"},{"location":"intro/#escondendo-a-latencia","text":"Para se esconder a lat\u00eancia, v\u00e1rias t\u00e1ticas s\u00e3o utiliz\u00e1veis: Caching de dados Em vez de sempre buscar os dados no servidor, mantenha c\u00f3pias locais dos dados que mudam menos (e.g., o CSS do stackoverflow). Use paralelismo Em vez de validar formul\u00e1rio ap\u00f3s preenchimento de cada campo, valide em paralelo enquanto usu\u00e1rio preenche o campo seguinte. Use callbacks para indicar campos com problemas a serem corrigidos. Saiba que nem todo problema \u00e9 paraleliz\u00e1vel, por exemplo, autentica\u00e7\u00e3o Use programa\u00e7\u00e3o ass\u00edncrona AsyncIO C# await/async Futures e Promises Outra forma de diminuir lat\u00eancia \u00e9 trazer para pr\u00f3ximo do usu\u00e1rio parte da computa\u00e7\u00e3o. Isto \u00e9 comumente feito com a interface com usu\u00e1rio, mas pode ser usado tamb\u00e9m para outras partes do sistema. Como exemplo do primeiro, pense em consoles de video-game que fazem o processamento gr\u00e1fico pesado de jogos online na casa do usu\u00e1rio 5 . Como exemplo do segundo, pense em aplicativos que mant\u00e9m os dados em celulares at\u00e9 que uma boa conex\u00e3o, por exemplo WiFi, esteja dispon\u00edvel para sincronizar com o servidor. De forma geral, pense em esconder lat\u00eancia pelos seguintes passos: Distribua tarefas Delegue computa\u00e7\u00e3o aos clientes (e.g., JavaScript e Applets Java) Particione dados entre servidores (e.g., Domain Name Service e World Wide Web) para dividir a carga e aumentar a vaz\u00e3o Aproxime dados dos clientes Mantenha c\u00f3pias de dados em m\u00faltiplos lugares. Atualize dados de acordo com necessidade (e.g., cache do navegador, com c\u00f3digo do google.com sendo atualizado a cada 4 dias)","title":"Escondendo a Lat\u00eancia"},{"location":"intro/#transparencia-de-relocacao","text":"As vezes componentes do sistema distribu\u00eddo precisam ser movimentados de uma localiza\u00e7\u00e3o \u00e0 outra, por exemplo porqu\u00ea um novo host foi contratado. Se implementadas corretamente, as t\u00e9cnicas que entregam transpar\u00eancia de localiza\u00e7\u00e3o n\u00e3o deixam que o cliente perceba a movimenta\u00e7\u00e3o, no que chamamos transpar\u00eancia de Reloca\u00e7\u00e3o. Rede de baixa lat\u00eancia Distribui\u00e7\u00e3o inteligente E.g: Servi\u00e7os de nome M\u00faltiplas c\u00f3pias C\u00f3pias tempor\u00e1rias","title":"Transpar\u00eancia de Reloca\u00e7\u00e3o"},{"location":"intro/#transparencia-de-migracao","text":"Do ponto de vista do pr\u00f3prio servi\u00e7o, n\u00e3o perceber que se est\u00e1 sendo movimentado \u00e9 chamado transpar\u00eancia de Migra\u00e7\u00e3o. Um servi\u00e7o com esta propriedade, n\u00e3o precisa ser parado e reconfigurado quando a mudan\u00e7a acontece. Uma das formas de se implementar esta propriedade \u00e9 atrav\u00e9s da migra\u00e7\u00e3o provida por m\u00e1quinas virtuais, usado, por exemplo, para consolidar o uso de servidores em nuvens computacionais. Veja o exemplo do VMotion da VMware Na verdade, a movimenta\u00e7\u00e3o neste cen\u00e1rio, \u00e9 uma c\u00f3pia da m\u00e1quina virtual. Uma vez que a c\u00f3pia esteja pr\u00f3xima do fim, a imagem original \u00e9 congelada, a c\u00f3pia conclu\u00edda, e h\u00e1 um chaveamento na rede para se direcionar toda comunica\u00e7\u00e3o para nova c\u00f3pia. O m\u00e1quina original \u00e9 ent\u00e3o descartada.","title":"Transpar\u00eancia de Migra\u00e7\u00e3o"},{"location":"intro/#transparencia-de-replicacao","text":"A capacidade de ter c\u00f3pias de um servi\u00e7o e de direcionar trabalho de uma para outra \u00e9 tamb\u00e9m \u00fatil para se obter transpar\u00eancia no caso de falhas. Isto porqu\u00ea para se manter um servi\u00e7o funcional a despeito de falhas, \u00e9 preciso ter m\u00faltiplas c\u00f3pias, prontas para funcionar a qualquer momento. Dependendo das garantias desejadas na manuten\u00e7\u00e3o da consist\u00eancia entre as c\u00f3pias, o custo pode variar muito, de forma que para se ter um custo menor, tem-se garantias mais fracas, por exemplo, que as r\u00e9plicas tem um atraso entre elas de no m\u00e1ximo $X$ minutos. Este \u00e9 um dilema parecido com o TCP x UDP, em que mais garantias implicam em maior custo de comunica\u00e7\u00e3o. Algumas aplica\u00e7\u00f5es toleram inconsist\u00eancias e podem viver com menores custos. Um exemplo famoso \u00e9 o dos \"carrinhos de compra\" da Amazon.com , que podem fechar pedidos com conte\u00fado diferente do desejado pelo cliente. Outras aplica\u00e7\u00f5es s\u00e3o normalmente constru\u00eddas com requisitos de consist\u00eancia forte entre as r\u00e9plicas, como sistemas financeiros. Para estas aplica\u00e7\u00f5es, uma t\u00e9cnica importante para se conseguir replica\u00e7\u00e3o \u00e9 o uso de frameworks de comunica\u00e7\u00e3o em grupo , que entregam para m\u00faltiplas inst\u00e2ncias de um mesmo servi\u00e7o, as mesmas mensagens, permitindo que elas se mantenham como c\u00f3pias. Esta t\u00e9cnica funciona se os servi\u00e7os forem m\u00e1quinas de estado determin\u00edsticas, que consideram como eventos as mensagens entregues pelo protocolo de comunica\u00e7\u00e3o em grupo e \u00e9 denominada **replica\u00e7\u00e3o de m\u00e1quinas de estado . TODO: Figura com state machine replication Novamente \u00e9 preciso chamar \u00e0 aten\u00e7\u00e3o a quest\u00e3o dos custos desta t\u00e9cnica. Replica\u00e7\u00e3o de M\u00e1quinas de Estados \u00e9 muito custosa e por isso faz-se um esfor\u00e7o para n\u00e3o utiliz\u00e1-la ou para utiliz\u00e1-la em \"cantinhos\" do sistema ondo inconsist\u00eancias s\u00e3o absolutamente caras demais para sere permitidas. Isto porqu\u00ea manter m\u00faltiplas c\u00f3pias $\\Rightarrow$ sincroniza\u00e7\u00e3o $\\Rightarrow$ custos. Se houver mudan\u00e7as frequentes nos dados, tal custo precisa ser pago tamb\u00e9m frequentemente. Mitiga\u00e7\u00f5es incluem uso de r\u00e9plicas tempor\u00e1rias, protocolos de invalida\u00e7\u00e3o de cache, contrata\u00e7\u00e3o de redes com mais largura de banda e menor lat\u00eancia, sendo que estes \u00faltimos esbarram em limita\u00e7\u00f5es financeiras e f\u00edsicas.","title":"Transpar\u00eancia de Replica\u00e7\u00e3o"},{"location":"intro/#transparencia-de-concorrencia","text":"Outra transpar\u00eancia almej\u00e1vel \u00e9 de concorr\u00eancia. Isto \u00e9, quem acessa um servi\u00e7o deveria ser indiferente ao fato de que o mesmo pode estar sendo acessado por outros. Isto \u00e9 importante tanto em termos de seguran\u00e7a, no sentido de que um cliente n\u00e3o deveria acessar os dados do outro, caso isso seja um requisito do sistema, quanto tem termos de desempenho. Nuvens computacionais s\u00e3o um exemplo de onde este tipo de transpar\u00eancia \u00e9 essencial. Considere um servi\u00e7o de banco de dados em uma nuvem qualquer. Para prover a mesma interface com a qual usu\u00e1rios est\u00e3o acostumados a anos, \u00e9 poss\u00edvel que este servi\u00e7o seja simplesmente um wrapper ao redor do SGBD que se comprava e instalava in-house anteriormente. Para se tornar vi\u00e1vel, contudo, uma mesma inst\u00e2ncia deve servir m\u00faltiplos clientes, os tenants , sem que a carga de trabalho introduzida por um, interfira no desempenho do outro. No meio, chamamos esta propriedade de multi-tenancy , mas \u00e9 apenas um exemplo de transpar\u00eancia de concorr\u00eancia. Esta transpar\u00eancia est\u00e1 fundamentalmente ligada \u00e0 escalabilidade, isto \u00e9, \u00e0 adequa\u00e7\u00e3o dos pool de recursos \u00e0s demandas dos clientes: se mais clientes est\u00e3o presentes, ent\u00e3o aumente a quantidade de servidores ( scale up ) e separe as cargas ( sharding ); se menos clientes est\u00e3o presentes, ent\u00e3o desligue algumas m\u00e1quinas ( scale down ) e consolide recursos.","title":"Transpar\u00eancia de Concorr\u00eancia"},{"location":"intro/#desafios-para-se-obter-transparencia","text":"Apesar de desej\u00e1veis, as transpar\u00eancia discutidas s\u00e3o dif\u00edceis de se conseguir, principalmente se em conjunto. Isto porqu\u00ea, do ponto de vista de usu\u00e1rios espalhados pelo globo, atr\u00e1s de redes heterog\u00eaneas e com possibilidade de erros, acontecer\u00e3o atrasos e perdas na comunica\u00e7\u00e3o, denunciando a distribui\u00e7\u00e3o. Do ponto de vista do desenvolvedor , \u00e9 preciso tomar decis\u00f5es baseado em premissas ligadas \u00e0 realidade da rede. Por exemplo, se uma requisi\u00e7\u00e3o n\u00e3o foi respondida, quanto tempo um cliente deve esperar antes de reenvi\u00e1-la, possivelmente para outro servidor, sem incorrer em risco significativo da requisi\u00e7\u00e3o ser processada duas vezes? A resposta para esta pergunta \u00e9 muito mais complicada do que pode parecer. De forma geral , qualquer aumento de transpar\u00eancia tem um custo, seja em termos monet\u00e1rios (e.g., contrata\u00e7\u00e3o de enlace dedicado ou de host em outra posi\u00e7\u00e3o geogr\u00e1fica), ou em termos de desempenho (e.g., coordenar a entrega de mensagens em sistemas de comunica\u00e7\u00e3o em grupo). Provavelmente os maiores obst\u00e1culos para se alcan\u00e7ar os diversos tipos de transpar\u00eancia s\u00e3o impostos pela parte da infraestrutura que torna o sistema distribu\u00eddo poss\u00edvel, a rede. Para entender o porqu\u00ea, vejamos algumas premissas normalmente assumidas sobre a rede que n\u00e3o s\u00e3o, definitivamente, verdade: A lat\u00eancia \u00e9 zero. A largura de banda \u00e9 infinita. A rede \u00e9 confi\u00e1vel. A rede \u00e9 segura. A rede \u00e9 homog\u00eanea. A rede \u00e9 est\u00e1tica. A rede tem acesso gr\u00e1tis. A rede \u00e9 administrada por voc\u00ea ou algu\u00e9m acess\u00edvel.","title":"Desafios para se obter transpar\u00eancia"},{"location":"intro/#escalabilidade","text":"Para terminar, deixem-me apenas retomar um termo usado acima, escalabilidade . O termo est\u00e1 muito em voga e \u00e9 usado, normalmente, para descrever a capacidade de um sistema de se adequar a varia\u00e7\u00f5es de carga de trabalho. Embora seja um uso v\u00e1lido, h\u00e1 outros tipos de escalabilidade. Escalabilidade Tamanho: N\u00famero de usu\u00e1rios que suporta. Geogr\u00e1fica: Regi\u00e3o que cobre. Administrativa: N\u00famero de dom\u00ednios administrativos. H\u00e1 v\u00e1rias possibilidades: seja espec\u00edfico e exija especificidade.","title":"Escalabilidade"},{"location":"intro/#tipos","text":"Diversas s\u00e3o as finalidades dos sistemas distribu\u00eddos que constru\u00edmos, assim como s\u00e3o diversas as arquiteturas que usamos. Classifica\u00e7\u00f5es nos ajudam a pensar sobre sistemas e a encontrar e reusar solu\u00e7\u00f5es previamente testadas.","title":"Tipos"},{"location":"intro/#computacao-de-alto-desempelho-high-performance-computing","text":"A possibilidade de agregar poder de processamento de muitos computadores em um rede de comunica\u00e7\u00e3o com alt\u00edssima largura de banda nos permite atacar problemas computacionalmente muito intensos. Clusters como o da imagem a seguir, do Hight Performance Computing Center de Stuttgart, s\u00e3o compartilhados por pesquisadores resolvendo problemas \u00e1reas como bio-inform\u00e1tica, engenharia, economia, intelig\u00eancia artificial, etc. Na engenharia, por exemplo, HPC pode ser usada para testar a efici\u00eancia de projetos sem construir prot\u00f3tipos, seja de uma turbina um carro ou uma vaca Os n\u00f3s de um cluster s\u00e3o normalmente divididos em tr\u00eas categorias: administra\u00e7ao, computa\u00e7\u00e3o e armazenamento. N\u00f3s de administra\u00e7\u00e3o implementam um monitoramento distribu\u00eddo dos demais n\u00f3s, servem de ponto de entrada para usu\u00e1rios e prov\u00eaem interface para submiss\u00e3o de tarefas. O Oscar , por exemplo, \u00e9 uma \u00e9 conjunto de softwares para gerenciamento de clusters. Uma das ferramentas inclusas no Oscar \u00e9 o OpenPBS, pelo qual tarefas s\u00e3o atribu\u00eddas aos diversos n\u00f3s do sistema que sejam alocados para tal tarefa. O OpenPBS portanto \u00e9 tamb\u00e9m um sistema distribu\u00eddo. Finalmente, as tarefas submetidas em si s\u00e3o normalmente aplica\u00e7\u00f5es distribu\u00eddas. Cada processo executando em uma m\u00e1quina distrinta \u00e9 normalmente respons\u00e1vel por resolver uma parte do problema. Para facilitar a comunica\u00e7\u00e3o entre as partes do dom\u00ednio, s\u00e3o normalmente utilizadas API como a Message Passing Interface (MPI), que prov\u00ea fun\u00e7\u00f5es para distribui\u00e7\u00e3o e agrega\u00e7\u00e3o de dados entre os v\u00e1rios processos. Este tipo de sistemas distribu\u00eddos s\u00e3o o que chamamos de fortemente acoplados pois a falha em um dos componentes leva normalmente \u00e0 falha de todo o sistema. Do ponto de vista deste curso, estamos mais interessados em sistemas fracamente acoplados.","title":"Computa\u00e7\u00e3o de Alto Desempelho - High Performance Computing"},{"location":"intro/#sistemas-de-informacao","text":"Provavelmente mais comuns entre os profissionais da computa\u00e7\u00e3o, os sistemas de informa\u00e7\u00e3o distribu\u00eddos s\u00e3o encontrados em diversas formas. De fato, o termo \"sistema de informa\u00e7\u00e3o\" \u00e9 t\u00e3o abrangente, que dificilmente um sistema distribu\u00eddo n\u00e3o estaria nesta classe. O seguinte \u00e9 um exemplo de uma arquitetura em tr\u00eas camadas, onde a primeira implementa a interface com o usu\u00e1rio, a segunda cont\u00e9m a l\u00f3gica do neg\u00f3cio, e a terceira mantem os dados. Pe\u00e7a fundamental desta abordagem, os bancos de dados na terceira camada s\u00e3o frequentemente transacionais. Isto \u00e9, eles prov\u00eaem as garantias na execu\u00e7\u00e3o de transa\u00e7\u00f5es conhecidas como propriedades ACID. ACID Atomicidade: transa\u00e7\u00f5es s\u00e3o tratadas de forma indivis\u00edvel, isto \u00e9, ou tudo ou nada. Consist\u00eancia: transa\u00e7\u00f5es levam banco de um estado consistente a outro. E.g., x == 2*y Isolamento: transa\u00e7\u00f5es n\u00e3o v\u00eaem dados n\u00e3o comitados umas das outras. Durabilidade: os efeitos de uma transa\u00e7\u00e3o comitada devem persistir no sistema a despeito de falhas. Para relembrar no que implica ACID, considere a seguinte sequ\u00eancia de opera\u00e7\u00f5es, onde X e Y s\u00e3o valores guardados pelo banco de dados, a, b e c s\u00e3o vari\u00e1veis definidas no programa, e SELECT e SET s\u00e3o comandos para ler e modificar o banco de dados. 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: SET Y=b Suponha duas inst\u00e2ncias desta sequ\u00eancia, $T_1$ e $T_2$, concorrentes, em que as opera\u00e7\u00f5es escalonadas da seguinte forma. T1 T2 1: a = SELECT X 2: c = a * 2 3: b = c + 10 4: SET X=c 5: a = SELECT X 6: c = a * 2 7: b = c + 10 8: SET X=c 9: SET Y=b 10:SET Y=b Ao final da execu\u00e7\u00e3o, X ter\u00e1 o valor atribu\u00eddo por $T_2$, mas $Y$ ter\u00e1 o valor de $T_1$. Este escalonamento violou a consist\u00eancia do banco de dados por qu\u00ea as opera\u00e7\u00f5es n\u00e3o foram executadas isoladamente . Tente imaginar a dificuldade de se implementar um banco de dados distribu\u00eddo. Isto \u00e9, um banco em que v\u00e1rios n\u00f3s mantem os dados, participam de transa\u00e7\u00f5es e, portanto, precisam coordenar-se para manter os dados consistentes. A figura a seguir mostra um cen\u00e1rio com tr\u00eas bancos. Imagine que em um deles est\u00e1 uma rela\u00e7\u00e3o com os dados dos clientes, em outro, os dados do estoque e no terceiro as ordens de compra. Quando um cliente faz um pedido, o cliente deve ser validado no primeiro n\u00f3, o item \u00e9 removido do estoque no segundo n\u00f3, e no terceiro \u00e9 disparada uma cobran\u00e7a para o cliente. Se qualquer destas tr\u00eas rela\u00e7\u00f5es n\u00e3o for corretamente consultada e alterada, os efeitos podem ser catastr\u00f3ficos para o neg\u00f3cio ou para o cliente. Como implementar ACID neste banco de dados? Embora veremos isso um pouco mais para frente neste material, por enquanto, apenas assuma que n\u00e3o \u00e9 exatamente f\u00e1cil ou barato. Esta dificuldade foi a raz\u00e3o do surgimento dos bancos de dados NOSQL (n\u00e9e NoSQL), dos quais uma pequena amostra \u00e9 dada pela seguinte figura. Tambem discutiremos como estes bancos de dados funcionam, quando falarmos sobre sistemas P2P.","title":"Sistemas de Informa\u00e7\u00e3o"},{"location":"intro/#integracao-de-aplicacoes","text":"Frequentemente \u00e9 necess\u00e1rio integrar sistemas de informa\u00e7\u00e3o legados com sistemas mais modernos, ou simplesmente exp\u00f4-los usando uma interface mais moderna. Nestes casos, \u00e9 poss\u00edvel integrar diversos sistemas usando um middleware que os encapsule. O middleware pode, por exemplo, se expor via interface REST para os clientes, mas consultar o sistema legado em um padr\u00e3o antigo. Outro exemplo \u00e9 o sistema na imagem seguinte, que mostra diversos departamentos de uma empresa conversando via troca de mensagens. Observe que nenhum departamento precisa conversar diretamente com os outros, ou mesmo conhec\u00ea-los. Eles apenas publicam a mensagem para quem puder tratar. Da mesma forma, a resposta vem na forma de uma mensagem. Este \u00e9 um exemplo de sistema fracamente acoplado , pois nenhum componente tem que saber da exist\u00eancia do outro ou se torna indispon\u00edvel caso os outros falhem. Siga este link para ler mais sobre este tipo de sistema.","title":"Integra\u00e7\u00e3o de Aplica\u00e7\u00f5es"},{"location":"intro/#sistemas-pervasivosubiquos","text":"Segundo Weiser, 1993 Ubiquitous computing is the method of enhancing computer use by making many computers available throughout the physical environment, but making them effectively invisible to the user. O que \u00e9 importante aqui \u00e9 o foco na tarefa em vez de na ferramenta. Assim, sistemas pervasivos devem ajudar as pessoas a realizar suas tarefas, de forma impl\u00edcita, sem ter que pensar em como a tarefa ser\u00e1 executada. Para que seja realizada, a computa\u00e7\u00e3o pervasiva requer que dispositivos detectem o contexto em que est\u00e3o inseridos, combinem-se de forma ad-hod e compartilhem informa\u00e7\u00f5es . Veja alguns exemplos interessantes, fict\u00edcios e reais. Smart Life: Esta \u00e9 uma vis\u00e3o futur\u00edstica da Microsoft para a integra\u00e7\u00e3o de tecnologias. Amazon Go: Este mercado automatiza o pagamento dos itens escolhidos pelo consumidor, utilizando t\u00e9cnicas de processamento digital de imagens, aprendizado de m\u00e1quina e sensores. Reality Check: Para quem viu o filme Minority Report e sonhou com as UI do futuro, aqui vai um reality check . Para quem n\u00e3o viu ainda, corrija esta falha em sua forma\u00e7\u00e3o t\u00e9cnica o mais rapidamente poss\u00edvel.","title":"Sistemas Pervasivos/Ub\u00edquos"},{"location":"intro/#redes-de-sensores-e-internet-das-coisas","text":"Eu vou me arriscar colocando Redes de Sensores e Internet das Coisas como uma subsess\u00e3o de Sistemas Pervasivos. Isto porqu\u00ea, a meu ver, as redes de sensores s\u00e3o parte da infraestrutura para se obter sistemas pervasivos; s\u00e3o os sensores que percebem mudan\u00e7as contexto e \"le\u00eam\" o estado do contexto atual e alimentam outros sistemas que reagem a tal estado. A Internet das Coisas (IoT, do ingl\u00eas Internet of Things ) vai tamb\u00e9m na mesma linha, levando \u00e0 integra\u00e7\u00e3o entre sensores, atuadores, e outros dispositivos que nos servem, em um ambiente de computa\u00e7\u00e3o pervasiva. \"Mas se \u00e9 assim, qual o risco?\", voc\u00ea pergunta. Bem, a Internet das Coisas pode ser vista como algo al\u00e9m dos sistemas pervasivos, pois se estes \u00faltimos s\u00e3o focados nos humanos em um certo contexto, a IoT n\u00e3o necessariamente foca-se nos humanos, mas na realiza\u00e7\u00e3o de alguma tarefa. Por exemplo, um sistema de irriga\u00e7\u00e3o que percebe o n\u00edvel de humidade do ar, analisa previs\u00f5es de chuva e decide em quanto irrigar uma planta\u00e7\u00e3o de laranjas provavelmente n\u00e3o se importar\u00e1 com a presen\u00e7a ou n\u00e3o de um humano na planta\u00e7\u00e3o. Para aprender mais sobre IoT, veja este link que descreve diversos projetos europeus na \u00e1rea.","title":"Redes de Sensores e Internet das Coisas"},{"location":"intro/#uma-nota-sobre-privacidade-nos-sistemas-pervasivos","text":"\u00c0 medida em que aumentamos o ambiente ao nosso redor ou a n\u00f3s mesmos com dispositivos computacionais, por um lado facilitamos nossa vida pois somos assistidos por tais dispositivos, mas por outro, nos tornamos cada vez mais dependentes nos mesmos, com s\u00e9rios riscos \u00e0 nossa privacidade. Isto ocorre por que para que realizem suas tarefas, os sistemas pervasivos precisam de cada vez mais informa\u00e7\u00f5es sobre n\u00f3s, e h\u00e1 sempre o risco de que estas informa\u00e7\u00f5es sejam usadas de forma que n\u00e3o nos apetece.","title":"Uma nota sobre privacidade nos sistemas pervasivos"},{"location":"intro/#computacao-utilitaria","text":"Um tipo importante de sistema distribu\u00eddo mais recente s\u00e3o as nuvens computacionais, usadas no provimento de computa\u00e7\u00e3o utilit\u00e1ria. Este tipo de sistema, embora possa ser pensando como infraestrutura para outros sistemas distribu\u00eddos, s\u00e3o, na verdade, complexas pe\u00e7as de engenharia, com diversos subsistemas respons\u00e1veis por sincroniza\u00e7\u00e3o de rel\u00f3gios, monitora\u00e7\u00e3o de falhas, coleta de logs, roteamento eficiente tolerante a falhas, movimenta\u00e7\u00e3o de recursos virtualizados para consolida\u00e7\u00e3o de recursos f\u00edsicos, armazenamento redundante de dados, etc. O seguinte v\u00eddeo mostra, em 360 graus, um dos datacenters do Google, para que voc\u00ea tenha ideia da escala em que estes sistemas s\u00e3o constru\u00eddos. Para uma viagem fotogr\u00e1fica, siga este link","title":"Computa\u00e7\u00e3o Utilit\u00e1ria"},{"location":"intro/#arquiteturas","text":"De acordo com David Garlan and Mary Shaw, January 1994, CMU-CS-94-166, em An Introduction to Software Architecture ... an architectural style determines the vocabulary of components and connectors that can be used in instances of that style, together with a set of constraints on how they can be combined. These can include topological constraints on architectural descriptions (e.g., no cycles). Other constraints\u2014say, having to do with execution semantics\u2014might also be part of the style definition. Em outras palavras, um estilo ou padr\u00e3o arquitetural \u00e9 o conjunto de princ\u00edpios que prov\u00ea uma infraestrutura abstrata para uma fam\u00edlia de sistemas, e promove o reuso de projeto ao prover solu\u00e7\u00f5es para problemas recorrentes e frequentes .","title":"Arquiteturas"},{"location":"intro/#componentes-e-conectores","text":"Quando falamos sobre arquiteturas em sistemas distribu\u00eddos, estamos primariamente focados na forma como componentes se conectam, por meio de conectores, para implementar a solu\u00e7\u00e3o para um problema. Dependendo de como s\u00e3o conectados, haver\u00e1 maior ou menor depend\u00eancia entre os componentes. Quando houver forte depend\u00eancia, diremos que os componentes est\u00e3o fortemente acoplados ( tightly coupled ). Caso contr\u00e1rio, diremos que est\u00e3o fracamente acoplados ( loosely coupled ). A raz\u00e3o \u00f3bvia para preferir sistemas fracamente conectados \u00e9 sua capacidade de tolerar disrup\u00e7\u00f5es; se um componente depende pouco de outro, ent\u00e3o n\u00e3o se incomodar\u00e1 com sua aus\u00eancia por causa de uma falha. Certos middleware permitem um acoplamento t\u00e3o fraco entre componentes, que estes n\u00e3o precisam se conhecer ou sequer estar ativos no mesmo momento. Tamb\u00e9m a quest\u00e3o da simplifica\u00e7\u00e3o de API, uma vez que o middleware pode impor um padr\u00e3o a ser seguido por todos os componentes e minimizar a necessidade os componentes conhecerem as interfaces uns dos outros.","title":"Componentes e Conectores"},{"location":"intro/#clienteservidor","text":"A forma como os componentes se comunicam, isto \u00e9, os conectores usados, \u00e9 importante no estudo arquitetural. Mas tamb\u00e9m s\u00e3o importantes os pap\u00e9is assumidos pelos componentes na realiza\u00e7\u00e3o de tarefas. Neste sentido, provavelmente a arquitetura de computa\u00e7\u00e3o distribu\u00edda mais famosa \u00e9 a Cliente/Servidor . Na arquitetura Cliente/Servidor, como implicado pelo nome, h\u00e1 um processo que serve a pedidos realizados por outros processos. Isto \u00e9 feito quando o cliente o contacta o servidor e requer ( request ) a realiza\u00e7\u00e3o do servi\u00e7o. O servidor , por sua vez, pode desempenhar tarefas como fazer c\u00e1lculos, armazenar dados, ou repassar uma mensagem e, ao final da realiza\u00e7\u00e3o da tarefa, responder ( response ) ao cliente. Um mesmo servidor pode atender a diversos clientes e, geralmente, a comunica\u00e7\u00e3o entre os mesmos \u00e9 feita diretamente por sockets. Embora seja poss\u00edvel usar sockets de forma ass\u00edncrona, a API mais comum \u00e9 s\u00edncrona, isto \u00e9, quando um processo espera receber uma mensagem de outro, ele fica bloqueado esperando algum dado estar dispon\u00edvel para leitura no referido socket. Assim, geralmente a comunica\u00e7\u00e3o entre cliente e servidor segue o seguinte esquema: Observe que o cliente fica inativo enquanto espera a resposta e que o servidor fica inativo enquanto espera outras requisi\u00e7\u00f5es. Para minimizar os per\u00edodos de inatividade, o cliente pode usar o socket ass\u00edncronamente, o que n\u00e3o \u00e9 exatamente simples, ou usar m\u00faltiplos threads, para que continue operando mesmo enquanto um thread estiver bloqueado esperando a resposta do servidor. No lado do servidor, o minimiza\u00e7\u00e3o da ociosidade \u00e9 feita pelo uso de m\u00faltiplos clientes, concorrentes, e tamb\u00e9m pelo uso de m\u00faltiplos threads. Neste caso, contudo, \u00e9 necess\u00e1rio tomar muito cuidado para garantir que a concorr\u00eancia n\u00e3o causar\u00e1 efeitos indesejados nos dados e execu\u00e7\u00e3o das tarefas. Veja o caso de um banco de dados transacional, por exemplo, como discutido acima; ele precisa garantir ACID entre as transa\u00e7\u00f5es propostas pelos clientes. Embora tenhamos colocado aqui apenas um servidor atendendo aos clientes, em muitas aplica\u00e7\u00f5es modernas, m\u00faltiplos servidores atender\u00e3o ao conjunto de clientes. Pense por exemplo no servi\u00e7o de email do Google, o Gmail. Com os milh\u00f5es de usu\u00e1rios que tem, certamente h\u00e1 mais de um servidor implementando o servi\u00e7o. Provavelmente estes diversos servidores ficam atr\u00e1s do que chamamos de um balanceador de carga, que roteia as requisi\u00e7\u00f5es seguindo diferentes pol\u00edticas, por exemplo, round robin .","title":"Cliente/Servidor"},{"location":"intro/#par-a-par-p2p","text":"Diferentemente de sistemas cliente/servidor, em que um n\u00f3 serve o outro, em sistemas par-a-par, os n\u00f3s s\u00e3o parceiros e tem igual responsabilidade (e da\u00ed o nome) na execu\u00e7\u00e3o das tarefas. Diversos sistemas P2P existem, sendo, provavelmente, os mais famosos, os sistemas de compartilhamento de arquivos. Nesta linha, embora diversos tenham existido, hoje o mais famoso \u00e9 o Bittorrent, mesmo que, como veremos adiante, n\u00e3o seja P2P puro. Outro exemplo importante por ter inspirado diversos outros sistemas \u00e9 o Chord. Neste sistema, n\u00f3s organizam-se em um anel l\u00f3gico e cada um se torna respons\u00e1vel por um dos segmentos do anel adjacente a onde se encontra no mesmo. Requisi\u00e7\u00f5es para correspondentes a um segmento s\u00e3o roteados para o n\u00f3 respons\u00e1vel usando uma tabela de rotas conhecida como finger table . Se tra\u00e7armos os caminhos apontados por esta tabela sobre o anel, desenharemos cordas sobre o mesmo, o que explica o nome do sistema.","title":"Par-a-Par (P2P)"},{"location":"intro/#hibridos","text":"Embora cliente/servidor e P2P sejam arquiteturas cl\u00e1ssicas, boa parte dos sistemas que distribu\u00eddos podem ser na verdade consideradas h\u00edbridos. Considere um sistema de email, por exemplo. Embora clientes usem as funcionalidades dos servidores de email para enviar e receber mensagens, os servidores conversam uns com os outros para implementar a tarefa de encaminhar as mensagens. Neste sentido, o sistema \u00e9 um h\u00edbrido P2P e cliente/servidor. Outros exemplos abundam. Bancos de dados, e.g., DynamoDB, CassandraDB , Redis,... Jogos multiplayer (pense no particionamento dos mapas ) Compartilhamento de arquivos: Bittorrent Voltemos ao exemplo do Bittorrent; observe na figura adiante os diversos passos necess\u00e1rios \u00e0 recupera\u00e7\u00e3o do arquivo de interesse neste sistema. Diversos passos seguem a arquitetura cliente/servidor enquanto \"somente\" o passo de compartilhamento de arquivos \u00e9 P2P. Voltando ao exemplo do sistema de informa\u00e7\u00e3o, observe que o cliente acessa um servi\u00e7o, implementado por pares de n\u00f3s. Podemos dizer que tamb\u00e9m este \u00e9 h\u00edbrido.","title":"H\u00edbridos"},{"location":"intro/#sistemas-multi-camadas","text":"Outra forma de hibridismo que podemos citar \u00e9 quando um componente haje tanto como cliente quanto como servidor. Veja o seguinte exemplo, conhecido no meio como arquitetura em 3-camadas (3 tiers ). Neste caso, \u00e9 interessante notar que esta disposi\u00e7\u00e3o dos componentes \u00e9 independente da disposi\u00e7\u00e3o f\u00edsica. De fato, as tr\u00eas camadas podem estar em um mesmo n\u00f3, ou combinadas duas a duas, neste \u00faltimo caso resultando em duas camadas. Por outro lado, cada camada pode ser subdividida em mais componentes, resultando \u00e9 m\u00faltiplos tiers, como neste exemplo de um sistema de busca na Web.","title":"Sistemas multi-camadas"},{"location":"intro/#outras-arquiteturas","text":"Diversas outras arquiteturas podem e foram propostas para o desenvolvimento de Sistemas Distribu\u00eddos. A moda da vez \u00e9 a chamada arquitetura de micro servi\u00e7os, na qual a divis\u00e3o de tarefas entre componentes visa levar aos componentes mais simples para tal tarefa. Assim, os mesmos podem ser replicados, escalonados, desenvolvidos e mantidos independentemnte. Cada tarefa conta ent\u00e3o com diversos componentes, organizados em camadas resolvendo um problema em espec\u00edfico, mas todos contribuindo para a realiza\u00e7\u00e3o de uma tarefa maior comum. N\u00f3s discutiremos micro-servi\u00e7os mais adiante. Por agora, apenas tenha em mente que embora seja vendido por muitos como tal, os micro-servi\u00e7os n\u00e3o s\u00e3o uma panac\u00e9ia .","title":"Outras arquiteturas"},{"location":"intro/#para-aprender-mais","text":"Para aprender mais sobre arquiteturas, consulte a seguinte refer\u00eancia: Distributed System Architectures and Architectural Styles . Para aprender um pouco sobre como funcionam as redes de um datacenter, definidas por software, assista ao seguinte v\u00eddeo, que fala sobre a infra-estrutura do Facebook. Cap\u00edtulo 1, Figura 1, Distributed Systems: Principles and Paradigms \u21a9 IEEE Floating Point \u21a9 IBM Floating Point \u21a9 Simplifica\u00e7\u00f5es s\u00e3o poss\u00edveis, mas introduzem outras complexidades. \u21a9 O Google stadia \u00e9 uma plataforma de jogos que vai na contram\u00e3o desta ideia, levando todo o processamento pesado para a nuvem. \u21a9","title":"Para aprender mais"},{"location":"microservices/0_intro/","text":"TODO","title":"Microsservi\u00e7os"},{"location":"p2p/0_intro/","text":"Neste cap\u00edtulo falaremos sobre os sistemas P2P, do ingl\u00eas, peer-to-peer , e mostraremos como as DHT, o mais proeminente exemplo de P2P, evoluiram do Chord, essencialmente de uso acad\u00eamico, aos bancos de dados NOSQL, com representantes como Cassandra e o DynamoDB, muito difundidos na ind\u00fastria. Arquitetura P2P Uma forma de ver a arquitetura P2P \u00e9 como uma substitui\u00e7\u00e3o dos pap\u00e9is de clientes e servidores, onde h\u00e1 uma \"hirarquia\" entre os componentes, por uma onde todos os n\u00f3s s\u00e3o pares na execu\u00e7\u00e3o da tarefa em quest\u00e3o, isto \u00e9, executam as mesmas fun\u00e7\u00f5es. Um exemplo comum destas arquitetura s\u00e3o os sistemas de compartilhamento de arquivos, em que cada n\u00f3 armazena e disponibiliza parte dos dados, bem como acessa os dados disponibilizados por outros n\u00f3s. Na pr\u00e1tica, muitos sistemas mant\u00e9m os pap\u00e9is de clientes e servidores, mas distribuem as tarefas dos servidores entre pares para aquela fun\u00e7\u00e3o; s\u00e3o sistemas h\u00edbridos. \u00c9 assim que funcionam, por exemplo, boa parte os bancos de dados NOSQL, como Cassandra e DynamoDB, que discutiremos mais adiante neste cap\u00edtulo. Como principais caracter\u00edsticas destes sistemas P2P, podemos destacar as seguintes: * arquitetura decentralizada; * n\u00e3o h\u00e1 distin\u00e7\u00e3o de pap\u00e9is entre n\u00f3s ou conjuntos de n\u00f3s desempenham os mesmos pap\u00e9is, em parceria; * pode haver entrada e sa\u00edda de n\u00f3s do sistema com alta frequ\u00eancia; * n\u00f3s se organizam em redes sobrepostas (em ingl\u00eas, overlay ), redes l\u00f3gicas sobre as redes f\u00edsicas. Os principais objetivos do uso arquitetura P2P s\u00e3o comuns a todas as arquiteturas distribu\u00eddas, isto \u00e9: * agregar poder computacional de m\u00faltiplos n\u00f3s e * tolerar falhas de componentes sem paralizar o servi\u00e7o, isto \u00e9, alta-disponibilidade. Devido \u00e0 forma como s\u00e3o constru\u00eddos, sistemas P2P tamb\u00e9m podem visar * escalabilidade geogr\u00e1fica global, isto \u00e9, com n\u00f3s espalhados por todo o globo e * auto-administra\u00e7\u00e3o, pois seria praticamente imposs\u00edvel centralizar a administra\u00e7\u00e3o de tantos n\u00f3s, com tantas configura\u00e7\u00f5es distintas e em tantas localiza\u00e7\u00f5es diferentes. TODO: Exemplos de sistemas P2P Rede Sobreposta Como j\u00e1 mencionado, em sistemas P2P, os n\u00f3s ou componentes do sistema se organizam em uma rede sobreposta \u00e0 rede f\u00edsica. Esta rede l\u00f3gica \u00e9 constitu\u00edda pelos processos atuando como n\u00f3s e pelos canais de comunica\u00e7\u00e3o estabelecidos entre os n\u00f3s, tipicamente na forma de conex\u00f5es TCP/IP. Nestas redes sobrepostas s\u00e3o executados diversos algoritmos, como de descoberta de n\u00f3s, roteamento de pacotes e de otimiza\u00e7\u00e3o de rotas pelo descarte e cria\u00e7\u00e3o de conex\u00f5es. Uma vez que as conex\u00f5es na rede sobreposta n\u00e3o correspondem a conex\u00f5es f\u00edsicas, como se pode ver na seguinte figura, vizinhos em um rede sobreposta n\u00e3o necessariamente correspondem a vizinhos na rede f\u00edsica e vice-versa. Isto tamb\u00e9m implica que a otimiza\u00e7\u00e3o da rota l\u00f3gica n\u00e3o necessariamente leva \u00e0 otimiza\u00e7\u00e3o da rota f\u00edsica. Dependendo em como esta rede \u00e9 organizada (ou n\u00e3o), a mesma \u00e9 classificada como estruturada ou n\u00e3o-estruturada . Rede N\u00e3o-Estruturada Se a rede \u00e9 constru\u00edda de forma aleat\u00f3ria, por exemplo deixando os n\u00f3s se conectarem apenas aos vizinhos na rede no ponto em que se conectaram inicialmente, ent\u00e3o esta \u00e9 denominada uma rede n\u00e3o-estruturada . A figura a seguir \u00e9 um exemplo que se percebe que n\u00f3s tem graus diferentes de conectividade e que n\u00e3o est\u00e3o particularmente organizados em nenhuma topologia. Suponha que esta rede seja usada para armazenar e consultar dados. Inser\u00e7\u00f5es de dados podem ser feitas muito rapidamente, armazenando-os no primeiro n\u00f3 dispon\u00edvel encontrado. Buscas, contudo, ter\u00e3o que vasculhar a rede usando algoritmos como * busca em largura * busca em profundidade * caminhada aleat\u00f3ria (resposta probabil\u00edstica) Rede Estruturada Se as conex\u00f5es s\u00e3o constru\u00eddas e mantidas de forma a gerar uma topologia bem definida, chamamos esta rede de estruturada. Nesta rede, a inser\u00e7\u00e3o de n\u00f3s requer a propaga\u00e7\u00e3o desta informa\u00e7\u00e3o para outros n\u00f3s e a atualiza\u00e7\u00e3o das conex\u00f5es para manter a estrutura. A estrutura geralmente serve ao prop\u00f3sito de associar os n\u00f3s aos dados de uma forma planejada. Por exemplo, n\u00f3s pr\u00f3ximos na rede podem ser respons\u00e1veis por dados logicamente pr\u00f3ximos. Claramente, a inser\u00e7\u00e3o e acesso a dados nesta rede \u00e9 mais custosa, pois independentemente de onde a requisi\u00e7\u00e3o \u00e9 feita, isto \u00e9, a partir de qual n\u00f3, ela dever\u00e1 ser atendida por um n\u00f3 espec\u00edfico. Veja o exemplo do Chord, uma rede P2P em que os n\u00f3s formam um anel l\u00f3gico, cujos detalhes veremos adiante. Cada n\u00f3 \u00e9 respons\u00e1vel pela faixa de valores indexados por chaves entre o identificador do n\u00f3 e o do n\u00f3 anterior. Logo, qualquer inser\u00e7\u00e3o ou consulta de dados, deve ser feita especificamente para um determinado n\u00f3, e deve ser roteada para o mesmo. A estrutura da rede permite que tal roteamento seja feito eficientemente, no n\u00edvel da rede sobreposta. Como outro exemplo considere uma rede em que os n\u00f3s armazenam informa\u00e7\u00f5es sobre os dados de uma certa \u00e1rea geogr\u00e1fica, e que n\u00f3s vizinhos na rede sejam aqueles respons\u00e1veis por \u00e1reas que se tocam. Neste exemplo, para se acessar os dados de um certo ponto no mapa, basta rotear a requisi\u00e7\u00e3o para o vizinho mais pr\u00f3ximo do ponto; necessariamente a requisi\u00e7\u00e3o chegar\u00e1 ao n\u00f3 correto. Resumo Estruturada N\u00e3o-Estruturada Estrutura bem definida Estrutura aleat\u00f3ria Adi\u00e7\u00e3o de dados \u00e9 lenta Adi\u00e7\u00e3o de dados \u00e9 r\u00e1pida Adi\u00e7\u00e3o de n\u00f3s \u00e9 lenta Adi\u00e7\u00e3o de n\u00f3s \u00e9 r\u00e1pida Busca por dados \u00e9 r\u00e1pida Busca por dados lenta De n\u00e3o estruturada a estruturada Em certos cen\u00e1rios, \u00e9 poss\u00edvel conseguir o melhor de dois mundos. Por exemplo, seja uma grade $N \\times N$ em que n\u00f3s se conectam aleatoriamente uns aos outros, e que n\u00f3s em uma borda da matriz conseguem se conectar aos n\u00f3s da borda oposta, com dist\u00e2ncia 1. Efetivamente, temos a rede sobreposta \u00e0 esquerda. Se cada n\u00f3 executar executar o seguinte protocolo, a rede evoluir\u00e1 da topologia n\u00e3o estruturada para a estruturada \u00e0 direita. * Divida a organiza\u00e7\u00e3o da topologia em dois m\u00f3dulos, um de descoberta de novos n\u00f3s e outro de sele\u00e7\u00e3o. O m\u00f3dulo de descoberta, repetidamente, pergunta aos seus vizinhos quem s\u00e3o os seus vizinhos e se conecta aos mesmos. O m\u00f3dulo de sele\u00e7\u00e3o computa a dist\u00e2ncia entre o n\u00f3 e todos os seus vizinhos, e descarta as conex\u00f5es com maior dist\u00e2ncia, onde a = (x,y)$, $b = (x', y')$ $dx_{a,b} = min(|x - x'|, N - |x - x'|)$ $dy_{a,b} = min(|y - y'|, N - |y - y'|)$ Ao final de m\u00faltiplas intera\u00e7\u00f5es, cada n\u00f3 conhecer\u00e1 seus vizinhos \u00e0 direita, esquerda, acima e abaixo. Outra visuzaliza\u00e7\u00e3o desta topologia \u00e9 apresentada a seguir: Se em vez da dist\u00e2ncia cartesiana fosse usada a dist\u00e2ncia de Hamming entre os identificadores dos n\u00f3s, ao final das itera\u00e7\u00f5es, a topologia alcan\u00e7ada seria um hyper-cubo, no qual diversos esquemas de roteamento eficientes podem ser usados.","title":"P2P"},{"location":"p2p/0_intro/#arquitetura-p2p","text":"Uma forma de ver a arquitetura P2P \u00e9 como uma substitui\u00e7\u00e3o dos pap\u00e9is de clientes e servidores, onde h\u00e1 uma \"hirarquia\" entre os componentes, por uma onde todos os n\u00f3s s\u00e3o pares na execu\u00e7\u00e3o da tarefa em quest\u00e3o, isto \u00e9, executam as mesmas fun\u00e7\u00f5es. Um exemplo comum destas arquitetura s\u00e3o os sistemas de compartilhamento de arquivos, em que cada n\u00f3 armazena e disponibiliza parte dos dados, bem como acessa os dados disponibilizados por outros n\u00f3s. Na pr\u00e1tica, muitos sistemas mant\u00e9m os pap\u00e9is de clientes e servidores, mas distribuem as tarefas dos servidores entre pares para aquela fun\u00e7\u00e3o; s\u00e3o sistemas h\u00edbridos. \u00c9 assim que funcionam, por exemplo, boa parte os bancos de dados NOSQL, como Cassandra e DynamoDB, que discutiremos mais adiante neste cap\u00edtulo. Como principais caracter\u00edsticas destes sistemas P2P, podemos destacar as seguintes: * arquitetura decentralizada; * n\u00e3o h\u00e1 distin\u00e7\u00e3o de pap\u00e9is entre n\u00f3s ou conjuntos de n\u00f3s desempenham os mesmos pap\u00e9is, em parceria; * pode haver entrada e sa\u00edda de n\u00f3s do sistema com alta frequ\u00eancia; * n\u00f3s se organizam em redes sobrepostas (em ingl\u00eas, overlay ), redes l\u00f3gicas sobre as redes f\u00edsicas. Os principais objetivos do uso arquitetura P2P s\u00e3o comuns a todas as arquiteturas distribu\u00eddas, isto \u00e9: * agregar poder computacional de m\u00faltiplos n\u00f3s e * tolerar falhas de componentes sem paralizar o servi\u00e7o, isto \u00e9, alta-disponibilidade. Devido \u00e0 forma como s\u00e3o constru\u00eddos, sistemas P2P tamb\u00e9m podem visar * escalabilidade geogr\u00e1fica global, isto \u00e9, com n\u00f3s espalhados por todo o globo e * auto-administra\u00e7\u00e3o, pois seria praticamente imposs\u00edvel centralizar a administra\u00e7\u00e3o de tantos n\u00f3s, com tantas configura\u00e7\u00f5es distintas e em tantas localiza\u00e7\u00f5es diferentes. TODO: Exemplos de sistemas P2P","title":"Arquitetura P2P"},{"location":"p2p/0_intro/#rede-sobreposta","text":"Como j\u00e1 mencionado, em sistemas P2P, os n\u00f3s ou componentes do sistema se organizam em uma rede sobreposta \u00e0 rede f\u00edsica. Esta rede l\u00f3gica \u00e9 constitu\u00edda pelos processos atuando como n\u00f3s e pelos canais de comunica\u00e7\u00e3o estabelecidos entre os n\u00f3s, tipicamente na forma de conex\u00f5es TCP/IP. Nestas redes sobrepostas s\u00e3o executados diversos algoritmos, como de descoberta de n\u00f3s, roteamento de pacotes e de otimiza\u00e7\u00e3o de rotas pelo descarte e cria\u00e7\u00e3o de conex\u00f5es. Uma vez que as conex\u00f5es na rede sobreposta n\u00e3o correspondem a conex\u00f5es f\u00edsicas, como se pode ver na seguinte figura, vizinhos em um rede sobreposta n\u00e3o necessariamente correspondem a vizinhos na rede f\u00edsica e vice-versa. Isto tamb\u00e9m implica que a otimiza\u00e7\u00e3o da rota l\u00f3gica n\u00e3o necessariamente leva \u00e0 otimiza\u00e7\u00e3o da rota f\u00edsica. Dependendo em como esta rede \u00e9 organizada (ou n\u00e3o), a mesma \u00e9 classificada como estruturada ou n\u00e3o-estruturada .","title":"Rede Sobreposta"},{"location":"p2p/0_intro/#rede-nao-estruturada","text":"Se a rede \u00e9 constru\u00edda de forma aleat\u00f3ria, por exemplo deixando os n\u00f3s se conectarem apenas aos vizinhos na rede no ponto em que se conectaram inicialmente, ent\u00e3o esta \u00e9 denominada uma rede n\u00e3o-estruturada . A figura a seguir \u00e9 um exemplo que se percebe que n\u00f3s tem graus diferentes de conectividade e que n\u00e3o est\u00e3o particularmente organizados em nenhuma topologia. Suponha que esta rede seja usada para armazenar e consultar dados. Inser\u00e7\u00f5es de dados podem ser feitas muito rapidamente, armazenando-os no primeiro n\u00f3 dispon\u00edvel encontrado. Buscas, contudo, ter\u00e3o que vasculhar a rede usando algoritmos como * busca em largura * busca em profundidade * caminhada aleat\u00f3ria (resposta probabil\u00edstica)","title":"Rede N\u00e3o-Estruturada"},{"location":"p2p/0_intro/#rede-estruturada","text":"Se as conex\u00f5es s\u00e3o constru\u00eddas e mantidas de forma a gerar uma topologia bem definida, chamamos esta rede de estruturada. Nesta rede, a inser\u00e7\u00e3o de n\u00f3s requer a propaga\u00e7\u00e3o desta informa\u00e7\u00e3o para outros n\u00f3s e a atualiza\u00e7\u00e3o das conex\u00f5es para manter a estrutura. A estrutura geralmente serve ao prop\u00f3sito de associar os n\u00f3s aos dados de uma forma planejada. Por exemplo, n\u00f3s pr\u00f3ximos na rede podem ser respons\u00e1veis por dados logicamente pr\u00f3ximos. Claramente, a inser\u00e7\u00e3o e acesso a dados nesta rede \u00e9 mais custosa, pois independentemente de onde a requisi\u00e7\u00e3o \u00e9 feita, isto \u00e9, a partir de qual n\u00f3, ela dever\u00e1 ser atendida por um n\u00f3 espec\u00edfico. Veja o exemplo do Chord, uma rede P2P em que os n\u00f3s formam um anel l\u00f3gico, cujos detalhes veremos adiante. Cada n\u00f3 \u00e9 respons\u00e1vel pela faixa de valores indexados por chaves entre o identificador do n\u00f3 e o do n\u00f3 anterior. Logo, qualquer inser\u00e7\u00e3o ou consulta de dados, deve ser feita especificamente para um determinado n\u00f3, e deve ser roteada para o mesmo. A estrutura da rede permite que tal roteamento seja feito eficientemente, no n\u00edvel da rede sobreposta. Como outro exemplo considere uma rede em que os n\u00f3s armazenam informa\u00e7\u00f5es sobre os dados de uma certa \u00e1rea geogr\u00e1fica, e que n\u00f3s vizinhos na rede sejam aqueles respons\u00e1veis por \u00e1reas que se tocam. Neste exemplo, para se acessar os dados de um certo ponto no mapa, basta rotear a requisi\u00e7\u00e3o para o vizinho mais pr\u00f3ximo do ponto; necessariamente a requisi\u00e7\u00e3o chegar\u00e1 ao n\u00f3 correto.","title":"Rede Estruturada"},{"location":"p2p/0_intro/#resumo","text":"Estruturada N\u00e3o-Estruturada Estrutura bem definida Estrutura aleat\u00f3ria Adi\u00e7\u00e3o de dados \u00e9 lenta Adi\u00e7\u00e3o de dados \u00e9 r\u00e1pida Adi\u00e7\u00e3o de n\u00f3s \u00e9 lenta Adi\u00e7\u00e3o de n\u00f3s \u00e9 r\u00e1pida Busca por dados \u00e9 r\u00e1pida Busca por dados lenta","title":"Resumo"},{"location":"p2p/0_intro/#de-nao-estruturada-a-estruturada","text":"Em certos cen\u00e1rios, \u00e9 poss\u00edvel conseguir o melhor de dois mundos. Por exemplo, seja uma grade $N \\times N$ em que n\u00f3s se conectam aleatoriamente uns aos outros, e que n\u00f3s em uma borda da matriz conseguem se conectar aos n\u00f3s da borda oposta, com dist\u00e2ncia 1. Efetivamente, temos a rede sobreposta \u00e0 esquerda. Se cada n\u00f3 executar executar o seguinte protocolo, a rede evoluir\u00e1 da topologia n\u00e3o estruturada para a estruturada \u00e0 direita. * Divida a organiza\u00e7\u00e3o da topologia em dois m\u00f3dulos, um de descoberta de novos n\u00f3s e outro de sele\u00e7\u00e3o. O m\u00f3dulo de descoberta, repetidamente, pergunta aos seus vizinhos quem s\u00e3o os seus vizinhos e se conecta aos mesmos. O m\u00f3dulo de sele\u00e7\u00e3o computa a dist\u00e2ncia entre o n\u00f3 e todos os seus vizinhos, e descarta as conex\u00f5es com maior dist\u00e2ncia, onde a = (x,y)$, $b = (x', y')$ $dx_{a,b} = min(|x - x'|, N - |x - x'|)$ $dy_{a,b} = min(|y - y'|, N - |y - y'|)$ Ao final de m\u00faltiplas intera\u00e7\u00f5es, cada n\u00f3 conhecer\u00e1 seus vizinhos \u00e0 direita, esquerda, acima e abaixo. Outra visuzaliza\u00e7\u00e3o desta topologia \u00e9 apresentada a seguir: Se em vez da dist\u00e2ncia cartesiana fosse usada a dist\u00e2ncia de Hamming entre os identificadores dos n\u00f3s, ao final das itera\u00e7\u00f5es, a topologia alcan\u00e7ada seria um hyper-cubo, no qual diversos esquemas de roteamento eficientes podem ser usados.","title":"De n\u00e3o estruturada a estruturada"},{"location":"p2p/1_1_chord/","text":"Chord Chord \u00e9 uma sistema P2P de m\u00faltiplas aplica\u00e7\u00f5es desenvolvido pelos membros do CSAIL, do MIT, e publicado em 2001. Desde ent\u00e3o, inspirou diversos outros sistemas, tornando-se sin\u00f4nimo com P2P. No Chord, cada n\u00f3 tem um identificador \u00fanico de $m$ bits , gerado aleatoriamente. Como $m$ normalmente \u00e9 grande, com mais de uma centena de bits, a probabilidade de dois n\u00f3s terem o mesmo identificar \u00e9 desprez\u00edvel. O Chord mant\u00e9m uma rede estruturada na forma de um anel l\u00f3gico , em que os n\u00f3s aparecem ordenadamente de acordo com seus identificadores. A figura a seguir mostra as posi\u00e7\u00f5es dispon\u00edveis no anel de um Chord com 4 bits (sem utilidade pr\u00e1tica). Dados s\u00e3o tamb\u00e9m identificados por uma chave de $m$ bits . Esta chave \u00e9 gerada por meio de uma fun\u00e7\u00e3o hash criptogr\u00e1fica a partir de alguma chave que fa\u00e7a sentido para a aplica\u00e7\u00e3o, por exemplo um nome, telefone, ou CPF. Como a fun\u00e7\u00e3o hash \u00e9 criptogr\u00e1fica, uma pequena varia\u00e7\u00e3o na entrada implica em grande varia\u00e7\u00e3o na sa\u00edda, e para que observa apenas a sa\u00edda da fun\u00e7\u00e3o, uma sequ\u00eancia de chaves \u00e9 indistingu\u00edvel de uma sequ\u00eancia aleat\u00f3ria. Cada chave \u00e9 associada a um n\u00f3, respons\u00e1vel por atender requisi\u00e7\u00f5es de cria\u00e7\u00e3o, consulta, modifica\u00e7\u00e3o e remo\u00e7\u00e3o dos dados relacionados \u00e0quela chave. O dado com chave $k$ \u00e9 responsabilidade do n\u00f3 com menor identificador $i \\geq k$, aka, sucessor de $k$ ($i = suc(k)$). Na figura anterior, considere que apenas as posi\u00e7\u00f5es em cinza est\u00e3o preenchidas, isto \u00e9, que h\u00e1 apenas cinco n\u00f3s no sistema, com identificadores 1, 4, 7, 12 e 15. Neste cen\u00e1rio, o n\u00f3 7 \u00e9 respons\u00e1vel por dados cujas chaves s\u00e3o 5, 6 e 7. Roteamento Suponha que um cliente solicite ao Chord do exemplo anterior que armazene o valor $v$ associado \u00e0 chave $k$. A solicita\u00e7\u00e3o \u00e9 feita pelo contato a um dos n\u00f3s no sistema, que pode ou n\u00e3o ser o respons\u00e1vel por $k$. Caso seja o respons\u00e1vel, a solicita\u00e7\u00e3o \u00e9 executada localmente e uma resposta devolvida ao cliente. Caso contr\u00e1rio, a requisi\u00e7\u00e3o \u00e9 repassada ou roteada para o n\u00f3 correto. Na rede estruturada definida at\u00e9 agora, uma op\u00e7\u00e3o \u00f3bvia \u00e9 repassar a requisi\u00e7\u00e3o para \"a direita\" sucessivamente at\u00e9 que alcance o n\u00f3 correto. Esta solu\u00e7\u00e3o, correta, tem custo da ordem do n\u00famero de n\u00f3s no sistema, $O(n)$. Em uma inst\u00e2ncia com milhares de n\u00f3s, $O(n)$ \u00e9 um custo muito alto, ainda mais se considerarmos que cada salto na rede sobreposta potencialmente cruza toda a Internet, uma vez que, refor\u00e7ando, a proximidade na rede sobreposta n\u00e3o implica em proximidade na rede f\u00edsica abaixo. Observe que o custo em termos de espa\u00e7o para se implementar esta solu\u00e7\u00e3o \u00e9 $O(1)$ para cada n\u00f3 do sistema. Outra alternativa \u00e9 fazer com que cada n\u00f3 do sistema conhe\u00e7a todos os outros. Assim, cada requisi\u00e7\u00e3o pode ser diretamente encaminhada ao n\u00f3 respons\u00e1vel por trat\u00e1-la. O custo do roteamento, neste caso, \u00e9 $O(1)$ , muito mais r\u00e1pido que na abordagem anterior. O custo de armazenamento da tabela de rotas \u00e9, contudo, $O(n)$ , o que pode ser proibitivo em uma rede com milhares de n\u00f3s, apesar de ser uma solu\u00e7\u00e3o vi\u00e1vel em redes menores. Este \u00e9 o caso do CassandraDB, uma banco de dados distribu\u00eddo baseado no Chord, que estudaremos melhor mais adiante, considerado uma DHT de salto \u00fanico ( single-hop DHT). Como frequentemente acontece, um solu\u00e7\u00e3o melhor pode ser nem uma nem outra op\u00e7\u00e3o, mas algo intermedi\u00e1rio. O Chord prop\u00f5e a cria\u00e7\u00e3o de uma tabela de rotas tamb\u00e9m conhecida como finger-table , constru\u00edda da seguinte forma, onde $m$ \u00e9 a quantidade de bits usados para identificar n\u00f3s no sistema: * seja $F_p$ a finger-table do processo $p$; * seja $F_p[i]$ a $i$-\u00e9sima da tabela; e, * $F_p[i] = suc(p+2^{i-1})$. Observe que nesta tabela, a $i$-\u00e9sima entrada aponta para o processo que no que sucede $p$ pelo menos $2^{i-1}$, e que esta dist\u00e2ncia de sucess\u00e3o aumenta exponencialmente. Observe tamb\u00e9m que a maior dist\u00e2ncia \u00e9 proporcional a metade do tamanho do anel. Isto quer dizer que o \u00faltimo finger da tabela proporciona um salto de $1/2$ anel, o pen\u00faltimo $1/4$ do anel, o ante-pen\u00faltimo $1/8$, e assim sucessivamente. Outra forma de se ver esta tabela \u00e9 como proporcionando um salto de pelo menos metade da dist\u00e2ncia restante para o n\u00f3 respons\u00e1vel pela chave, resultando em um roteamento com custo $O(log n)$ . Mas como este potencial \u00e9 explorado? Usando-se o seguinte algoritmo de busca pela entrada correta na tabela de roteamento, do ponto de vista do processo $p$: * seja $k$ a chave para qual estamos procurando o sucessor; * itere pela tabela at\u00e9 achar a primeira entrada cujo valor, i.e., o identificador de um n\u00f3, \u00e9 maior que $k$; * se a entrada \u00e9 a primeira da tabela, ent\u00e3o encaminhe a requisi\u00e7\u00e3o para o n\u00f3 apontado, pois ele \u00e9 o sucessor de $k$, at\u00e9 onde $p$ consegue determinar; * sen\u00e3o, encaminhe a requisi\u00e7\u00e3o para a entrada anterior, pois o n\u00f3 referenciado est\u00e1 mais pr\u00f3ximo do sucessor para determin\u00e1-lo com seguran\u00e7a. Considere no exemplo a seguir a busca pelo sucessor de 26, iniciada pelo n\u00f3 1. Duas observa\u00e7\u00f5es s\u00e3o importantes aqui. A primeira, \u00e9 que as compara\u00e7\u00f5es para se encontrar a entrada correta, deve respeitar o anel, por exemplo, em um anel com 32 posi\u00e7\u00f5es, por exemplo, $31 < 0$. No seguinte exemplo, considere por exemplo a busca que o n\u00f3 21 faz pelo sucessor de 31; qual deve ser a entrada selecionada? A segunda observa\u00e7\u00e3o \u00e9 que n\u00e3o se pode encaminhar a requisi\u00e7\u00e3o diretamente para o n\u00f3 apontado na entrada encontrada, pois a vis\u00e3o de $p$ pode ser incompleta para partes distantes do anel. Tente identificar exemplos no anel a seguir onde este comportamento seria errado. A organiza\u00e7\u00e3o dos n\u00f3s em um anel virtual e a distribui\u00e7\u00e3o da responsabilidade dos dados pelo particionamento do espa\u00e7o das chaves de forma correspondente \u00e0s faixas no anel l\u00f3gico \u00e9 a t\u00e9cnica conhecida como espalhamento consistente , do ingl\u00eas, consistent hashing . Churn Apesar do espalhamento consistente ser uma t\u00e9cnica muito \u00fatil, ela n\u00e3o resolve todos os problemas. Ali\u00e1s, v\u00e1rios outros problemas precisam ser resolvidos, sendo o primeiro deles lidar com a entrada e sa\u00edda de n\u00f3s, principalmente por falhas de n\u00f3s e comunica\u00e7\u00e3o. Quando um novo n\u00f3 entra do sistema, ele precisa seguir os seguintes passos: * Escolher um novo Identificador $I$ * Identificar o sucessor $S$ de $I$ * Identificar o antecessor $A$ de $I$ * Informar $A$ e $S$ de sua entrada, para que ajustem suas tabelas de rota. * $A$ e $S$ propagam a informa\u00e7\u00e3o da entrada de $I$ para seus vizinhos, permitindo que ajustem suas tabelas de rota. Al\u00e9m disto, a reorganiza\u00e7\u00e3o dos n\u00f3s exige movimenta\u00e7\u00e3o de dados, pois parte dos dados armazenados em $S$, com chaves menores que $I$, precisam ser copiadas para $I$, o novo respons\u00e1vel. As principais quest\u00f5es a serem respondidas durante a movimenta\u00e7\u00e3o dos dados s\u00e3o * como manter os dados dispon\u00edveis para inser\u00e7\u00e3o e consulta durante todo o processo, e * como minimizar o impacto da reorganiza\u00e7\u00e3o nos n\u00f3s vizinhos ao novo n\u00f3 Quanto \u00e0 primeira quest\u00e3o, pode-se rotear as requisi\u00e7\u00f5es para os dois n\u00f3s respons\u00e1veis, o atual e o novo, e combinar as respostas, mantendo os dados mais recentes. Quanto \u00e0 segunda, uma op\u00e7\u00e3o \u00e9 fazer com que cada novo n\u00f3 assuma diversas posi\u00e7\u00f5es no anel, com identificadores distintos, passando a \"incomodar\" m\u00faltiplos processos, mas de forma mais suave. Embora se possa \"facilmente\" resolver os problemas da entrada de n\u00f3s, os da sa\u00edda s\u00e3o mais complexos, principalmente porqu\u00ea a sa\u00edda acontece geralmente bruscamente, por exemplo por falhas no sistema. Quanto \u00e0 reorganiza\u00e7\u00e3o das tabelas de rota, cada n\u00f3 precisa monitorar os n\u00f3s que figuram em sua tabela e, caso pare\u00e7am indispon\u00edveis, ajustar par apontar para outro n\u00f3. Contudo, caso a suspeita seja indevida, isto pode levar a dados serem consultados e armazenados nos n\u00f3s errados. Tamb\u00e9m com rela\u00e7\u00e3o aos dados, h\u00e1 o problema de n\u00e3o perd\u00ea-los quando o n\u00f3 respons\u00e1vel se torna indispon\u00edvel. O tratamento destes problemas est\u00e1 relacionado e \u00e9 feito pelo replica\u00e7\u00e3o dos dados em m\u00faltiplos n\u00f3s. Isto \u00e9 feito no Chord, por exemplo, da seguinte forma: * para cada dado, com chave $k$, h\u00e1 $r$ c\u00f3pias; * a primeira c\u00f3pia \u00e9 mantida no sucessor de $k$; * a segunda c\u00f3pia, no sucessor do sucessor de $k$, e assim por diante; * cada escrita \u00e9 feita na primeira c\u00f3pia, respondida, e replicada para as demais c\u00f3pias; * cada leitura \u00e9 feita na c\u00f3pia com menor identificador. No caso de falha de uma c\u00f3pia, h\u00e1 $r-1$ c\u00f3pias ainda dispon\u00edveis para responder \u00e0 requisi\u00e7\u00e3o, mantendo o sistema dispon\u00edvel a despeito de ($r-1$) falhas, no que se chama de degrada\u00e7\u00e3o graciosa . H\u00e1 contudo, um problema introduzido por esta abordagem. Assuma a seguinte sequ\u00eancia de passos, em um sistema com $r=2$. * escrita na c\u00f3pia 1; * resposta ao cliente; * replica\u00e7\u00e3o para c\u00f3pia 2; * escrita na c\u00f3pia 1; * resposta ao cliente; * falha da c\u00f3pia 1; * leitura na c\u00f3pia 2. O cliente, ao ler o dado, l\u00ea uma vers\u00e3o antiga do mesmo, inconsistente com a vis\u00e3o que tinha do sistema. De fato, este tipo de sistema \u00e9 chamado de eventualmente consistente pois somente na aus\u00eancia de falhas e de escritas as diversas r\u00e9plicas ser\u00e3o consistentes umas com as outras. Continuemos a sequ\u00eancia: * escrita na c\u00f3pia 2; * c\u00f3pia 1 volta a funcionar; * leitura na c\u00f3pia 1. Neste caso, a c\u00f3pia \"secund\u00e1ria\" 2 tem um dado mais atual, que precisa ser repassado para a c\u00f3pia 1; este movimento de converg\u00eancia de dados \u00e9 conhecido como anti-entropia. Finalmente, continuemos a sequ\u00eancia: * escrita na c\u00f3pia 1, por outro cliente. Assim, ambas as c\u00f3pias, 1 e 2, tem dados derivados da primeira escrita, mas feitos \"concorrentemente\", um conflito . Qual dos dois \u00e9 o correto neste contexto? \u00c9 imposs\u00edvel apresentar uma estrat\u00e9gia gen\u00e9rica para resolver esta situa\u00e7\u00e3o, mas alguns sistemas usar\u00e3o uma estrat\u00e9gia do tipo \"a \u00faltima escrita vence\", onde a \u00faltima escrita pode ser determinada em por rel\u00f3gios l\u00f3gicos, vetoriais, tempo, e uma pitada de \"arranjo t\u00e9cnico\" para quebrar empates. O Dynamo, que veremos a seguir, \u00e9 um destes sistemas. Refer\u00eancias https://www.cs.cmu.edu/~dga/15-744/S07/lectures/16-dht.pdf","title":"Chord"},{"location":"p2p/1_1_chord/#chord","text":"Chord \u00e9 uma sistema P2P de m\u00faltiplas aplica\u00e7\u00f5es desenvolvido pelos membros do CSAIL, do MIT, e publicado em 2001. Desde ent\u00e3o, inspirou diversos outros sistemas, tornando-se sin\u00f4nimo com P2P. No Chord, cada n\u00f3 tem um identificador \u00fanico de $m$ bits , gerado aleatoriamente. Como $m$ normalmente \u00e9 grande, com mais de uma centena de bits, a probabilidade de dois n\u00f3s terem o mesmo identificar \u00e9 desprez\u00edvel. O Chord mant\u00e9m uma rede estruturada na forma de um anel l\u00f3gico , em que os n\u00f3s aparecem ordenadamente de acordo com seus identificadores. A figura a seguir mostra as posi\u00e7\u00f5es dispon\u00edveis no anel de um Chord com 4 bits (sem utilidade pr\u00e1tica). Dados s\u00e3o tamb\u00e9m identificados por uma chave de $m$ bits . Esta chave \u00e9 gerada por meio de uma fun\u00e7\u00e3o hash criptogr\u00e1fica a partir de alguma chave que fa\u00e7a sentido para a aplica\u00e7\u00e3o, por exemplo um nome, telefone, ou CPF. Como a fun\u00e7\u00e3o hash \u00e9 criptogr\u00e1fica, uma pequena varia\u00e7\u00e3o na entrada implica em grande varia\u00e7\u00e3o na sa\u00edda, e para que observa apenas a sa\u00edda da fun\u00e7\u00e3o, uma sequ\u00eancia de chaves \u00e9 indistingu\u00edvel de uma sequ\u00eancia aleat\u00f3ria. Cada chave \u00e9 associada a um n\u00f3, respons\u00e1vel por atender requisi\u00e7\u00f5es de cria\u00e7\u00e3o, consulta, modifica\u00e7\u00e3o e remo\u00e7\u00e3o dos dados relacionados \u00e0quela chave. O dado com chave $k$ \u00e9 responsabilidade do n\u00f3 com menor identificador $i \\geq k$, aka, sucessor de $k$ ($i = suc(k)$). Na figura anterior, considere que apenas as posi\u00e7\u00f5es em cinza est\u00e3o preenchidas, isto \u00e9, que h\u00e1 apenas cinco n\u00f3s no sistema, com identificadores 1, 4, 7, 12 e 15. Neste cen\u00e1rio, o n\u00f3 7 \u00e9 respons\u00e1vel por dados cujas chaves s\u00e3o 5, 6 e 7.","title":"Chord"},{"location":"p2p/1_1_chord/#roteamento","text":"Suponha que um cliente solicite ao Chord do exemplo anterior que armazene o valor $v$ associado \u00e0 chave $k$. A solicita\u00e7\u00e3o \u00e9 feita pelo contato a um dos n\u00f3s no sistema, que pode ou n\u00e3o ser o respons\u00e1vel por $k$. Caso seja o respons\u00e1vel, a solicita\u00e7\u00e3o \u00e9 executada localmente e uma resposta devolvida ao cliente. Caso contr\u00e1rio, a requisi\u00e7\u00e3o \u00e9 repassada ou roteada para o n\u00f3 correto. Na rede estruturada definida at\u00e9 agora, uma op\u00e7\u00e3o \u00f3bvia \u00e9 repassar a requisi\u00e7\u00e3o para \"a direita\" sucessivamente at\u00e9 que alcance o n\u00f3 correto. Esta solu\u00e7\u00e3o, correta, tem custo da ordem do n\u00famero de n\u00f3s no sistema, $O(n)$. Em uma inst\u00e2ncia com milhares de n\u00f3s, $O(n)$ \u00e9 um custo muito alto, ainda mais se considerarmos que cada salto na rede sobreposta potencialmente cruza toda a Internet, uma vez que, refor\u00e7ando, a proximidade na rede sobreposta n\u00e3o implica em proximidade na rede f\u00edsica abaixo. Observe que o custo em termos de espa\u00e7o para se implementar esta solu\u00e7\u00e3o \u00e9 $O(1)$ para cada n\u00f3 do sistema. Outra alternativa \u00e9 fazer com que cada n\u00f3 do sistema conhe\u00e7a todos os outros. Assim, cada requisi\u00e7\u00e3o pode ser diretamente encaminhada ao n\u00f3 respons\u00e1vel por trat\u00e1-la. O custo do roteamento, neste caso, \u00e9 $O(1)$ , muito mais r\u00e1pido que na abordagem anterior. O custo de armazenamento da tabela de rotas \u00e9, contudo, $O(n)$ , o que pode ser proibitivo em uma rede com milhares de n\u00f3s, apesar de ser uma solu\u00e7\u00e3o vi\u00e1vel em redes menores. Este \u00e9 o caso do CassandraDB, uma banco de dados distribu\u00eddo baseado no Chord, que estudaremos melhor mais adiante, considerado uma DHT de salto \u00fanico ( single-hop DHT). Como frequentemente acontece, um solu\u00e7\u00e3o melhor pode ser nem uma nem outra op\u00e7\u00e3o, mas algo intermedi\u00e1rio. O Chord prop\u00f5e a cria\u00e7\u00e3o de uma tabela de rotas tamb\u00e9m conhecida como finger-table , constru\u00edda da seguinte forma, onde $m$ \u00e9 a quantidade de bits usados para identificar n\u00f3s no sistema: * seja $F_p$ a finger-table do processo $p$; * seja $F_p[i]$ a $i$-\u00e9sima da tabela; e, * $F_p[i] = suc(p+2^{i-1})$. Observe que nesta tabela, a $i$-\u00e9sima entrada aponta para o processo que no que sucede $p$ pelo menos $2^{i-1}$, e que esta dist\u00e2ncia de sucess\u00e3o aumenta exponencialmente. Observe tamb\u00e9m que a maior dist\u00e2ncia \u00e9 proporcional a metade do tamanho do anel. Isto quer dizer que o \u00faltimo finger da tabela proporciona um salto de $1/2$ anel, o pen\u00faltimo $1/4$ do anel, o ante-pen\u00faltimo $1/8$, e assim sucessivamente. Outra forma de se ver esta tabela \u00e9 como proporcionando um salto de pelo menos metade da dist\u00e2ncia restante para o n\u00f3 respons\u00e1vel pela chave, resultando em um roteamento com custo $O(log n)$ . Mas como este potencial \u00e9 explorado? Usando-se o seguinte algoritmo de busca pela entrada correta na tabela de roteamento, do ponto de vista do processo $p$: * seja $k$ a chave para qual estamos procurando o sucessor; * itere pela tabela at\u00e9 achar a primeira entrada cujo valor, i.e., o identificador de um n\u00f3, \u00e9 maior que $k$; * se a entrada \u00e9 a primeira da tabela, ent\u00e3o encaminhe a requisi\u00e7\u00e3o para o n\u00f3 apontado, pois ele \u00e9 o sucessor de $k$, at\u00e9 onde $p$ consegue determinar; * sen\u00e3o, encaminhe a requisi\u00e7\u00e3o para a entrada anterior, pois o n\u00f3 referenciado est\u00e1 mais pr\u00f3ximo do sucessor para determin\u00e1-lo com seguran\u00e7a. Considere no exemplo a seguir a busca pelo sucessor de 26, iniciada pelo n\u00f3 1. Duas observa\u00e7\u00f5es s\u00e3o importantes aqui. A primeira, \u00e9 que as compara\u00e7\u00f5es para se encontrar a entrada correta, deve respeitar o anel, por exemplo, em um anel com 32 posi\u00e7\u00f5es, por exemplo, $31 < 0$. No seguinte exemplo, considere por exemplo a busca que o n\u00f3 21 faz pelo sucessor de 31; qual deve ser a entrada selecionada? A segunda observa\u00e7\u00e3o \u00e9 que n\u00e3o se pode encaminhar a requisi\u00e7\u00e3o diretamente para o n\u00f3 apontado na entrada encontrada, pois a vis\u00e3o de $p$ pode ser incompleta para partes distantes do anel. Tente identificar exemplos no anel a seguir onde este comportamento seria errado. A organiza\u00e7\u00e3o dos n\u00f3s em um anel virtual e a distribui\u00e7\u00e3o da responsabilidade dos dados pelo particionamento do espa\u00e7o das chaves de forma correspondente \u00e0s faixas no anel l\u00f3gico \u00e9 a t\u00e9cnica conhecida como espalhamento consistente , do ingl\u00eas, consistent hashing .","title":"Roteamento"},{"location":"p2p/1_1_chord/#churn","text":"Apesar do espalhamento consistente ser uma t\u00e9cnica muito \u00fatil, ela n\u00e3o resolve todos os problemas. Ali\u00e1s, v\u00e1rios outros problemas precisam ser resolvidos, sendo o primeiro deles lidar com a entrada e sa\u00edda de n\u00f3s, principalmente por falhas de n\u00f3s e comunica\u00e7\u00e3o. Quando um novo n\u00f3 entra do sistema, ele precisa seguir os seguintes passos: * Escolher um novo Identificador $I$ * Identificar o sucessor $S$ de $I$ * Identificar o antecessor $A$ de $I$ * Informar $A$ e $S$ de sua entrada, para que ajustem suas tabelas de rota. * $A$ e $S$ propagam a informa\u00e7\u00e3o da entrada de $I$ para seus vizinhos, permitindo que ajustem suas tabelas de rota. Al\u00e9m disto, a reorganiza\u00e7\u00e3o dos n\u00f3s exige movimenta\u00e7\u00e3o de dados, pois parte dos dados armazenados em $S$, com chaves menores que $I$, precisam ser copiadas para $I$, o novo respons\u00e1vel. As principais quest\u00f5es a serem respondidas durante a movimenta\u00e7\u00e3o dos dados s\u00e3o * como manter os dados dispon\u00edveis para inser\u00e7\u00e3o e consulta durante todo o processo, e * como minimizar o impacto da reorganiza\u00e7\u00e3o nos n\u00f3s vizinhos ao novo n\u00f3 Quanto \u00e0 primeira quest\u00e3o, pode-se rotear as requisi\u00e7\u00f5es para os dois n\u00f3s respons\u00e1veis, o atual e o novo, e combinar as respostas, mantendo os dados mais recentes. Quanto \u00e0 segunda, uma op\u00e7\u00e3o \u00e9 fazer com que cada novo n\u00f3 assuma diversas posi\u00e7\u00f5es no anel, com identificadores distintos, passando a \"incomodar\" m\u00faltiplos processos, mas de forma mais suave. Embora se possa \"facilmente\" resolver os problemas da entrada de n\u00f3s, os da sa\u00edda s\u00e3o mais complexos, principalmente porqu\u00ea a sa\u00edda acontece geralmente bruscamente, por exemplo por falhas no sistema. Quanto \u00e0 reorganiza\u00e7\u00e3o das tabelas de rota, cada n\u00f3 precisa monitorar os n\u00f3s que figuram em sua tabela e, caso pare\u00e7am indispon\u00edveis, ajustar par apontar para outro n\u00f3. Contudo, caso a suspeita seja indevida, isto pode levar a dados serem consultados e armazenados nos n\u00f3s errados. Tamb\u00e9m com rela\u00e7\u00e3o aos dados, h\u00e1 o problema de n\u00e3o perd\u00ea-los quando o n\u00f3 respons\u00e1vel se torna indispon\u00edvel. O tratamento destes problemas est\u00e1 relacionado e \u00e9 feito pelo replica\u00e7\u00e3o dos dados em m\u00faltiplos n\u00f3s. Isto \u00e9 feito no Chord, por exemplo, da seguinte forma: * para cada dado, com chave $k$, h\u00e1 $r$ c\u00f3pias; * a primeira c\u00f3pia \u00e9 mantida no sucessor de $k$; * a segunda c\u00f3pia, no sucessor do sucessor de $k$, e assim por diante; * cada escrita \u00e9 feita na primeira c\u00f3pia, respondida, e replicada para as demais c\u00f3pias; * cada leitura \u00e9 feita na c\u00f3pia com menor identificador. No caso de falha de uma c\u00f3pia, h\u00e1 $r-1$ c\u00f3pias ainda dispon\u00edveis para responder \u00e0 requisi\u00e7\u00e3o, mantendo o sistema dispon\u00edvel a despeito de ($r-1$) falhas, no que se chama de degrada\u00e7\u00e3o graciosa . H\u00e1 contudo, um problema introduzido por esta abordagem. Assuma a seguinte sequ\u00eancia de passos, em um sistema com $r=2$. * escrita na c\u00f3pia 1; * resposta ao cliente; * replica\u00e7\u00e3o para c\u00f3pia 2; * escrita na c\u00f3pia 1; * resposta ao cliente; * falha da c\u00f3pia 1; * leitura na c\u00f3pia 2. O cliente, ao ler o dado, l\u00ea uma vers\u00e3o antiga do mesmo, inconsistente com a vis\u00e3o que tinha do sistema. De fato, este tipo de sistema \u00e9 chamado de eventualmente consistente pois somente na aus\u00eancia de falhas e de escritas as diversas r\u00e9plicas ser\u00e3o consistentes umas com as outras. Continuemos a sequ\u00eancia: * escrita na c\u00f3pia 2; * c\u00f3pia 1 volta a funcionar; * leitura na c\u00f3pia 1. Neste caso, a c\u00f3pia \"secund\u00e1ria\" 2 tem um dado mais atual, que precisa ser repassado para a c\u00f3pia 1; este movimento de converg\u00eancia de dados \u00e9 conhecido como anti-entropia. Finalmente, continuemos a sequ\u00eancia: * escrita na c\u00f3pia 1, por outro cliente. Assim, ambas as c\u00f3pias, 1 e 2, tem dados derivados da primeira escrita, mas feitos \"concorrentemente\", um conflito . Qual dos dois \u00e9 o correto neste contexto? \u00c9 imposs\u00edvel apresentar uma estrat\u00e9gia gen\u00e9rica para resolver esta situa\u00e7\u00e3o, mas alguns sistemas usar\u00e3o uma estrat\u00e9gia do tipo \"a \u00faltima escrita vence\", onde a \u00faltima escrita pode ser determinada em por rel\u00f3gios l\u00f3gicos, vetoriais, tempo, e uma pitada de \"arranjo t\u00e9cnico\" para quebrar empates. O Dynamo, que veremos a seguir, \u00e9 um destes sistemas.","title":"Churn"},{"location":"p2p/1_1_chord/#referencias","text":"https://www.cs.cmu.edu/~dga/15-744/S07/lectures/16-dht.pdf","title":"Refer\u00eancias"},{"location":"p2p/1_2_dynamo/","text":"DynamoDB \u00e9 o marco fundamental dos bancos de dados NoSQL. Neste v\u00eddeo , um dos integrantes do time que o desenvolveu e tamb\u00e9m um de seus evangelizadores, descreve rapidamente o banco, os cen\u00e1rios em que deveria ser usado e diversos padr\u00f5es de projeto para modelagem de dados. Enquanto o assiste, alguns pontos devem ser ressaltados sobre o Dynamo de forma espec\u00edfica e os NoSQL de forma geral: * surgiram da necessidade de escalabilidade dos bancos de dados, isto \u00e9, da necessidade de lidar com milh\u00f5es e milh\u00f5es de entradas de dados, gerados e processados com baixa lat\u00eancia e alta vaz\u00e3o, a despeito de falhas; * maior escalabilidade implica em maior exposi\u00e7\u00e3o a particionamentos da rede em que o sistema roda, que associado \u00e0 necessidade de manuten\u00e7\u00e3o de alta disponibilidade, implica em perda de garantias de consist\u00eancia (veremos o Teorema CAP adiante); * Partition keys s\u00e3o as chaves usadas para roteamento dos dados, ou seja, as chaves discutidas anteriormente neste cap\u00edtulo sobre sistema P2P; * Sort keys s\u00e3o chaves usadas dentro de cada n\u00f3 para ordenar os dados na hora de gerar as SSTables ( String Sorted Tables ), e se usadas em agregados de valores, s\u00e3o equivalentes ao GROUP BY do SQL; * Lambda functions s\u00e3o fun\u00e7\u00f5es para processamento de dados executadas em entradas definidas por um pipeline de processamento sem a defini\u00e7\u00e3o expl\u00edcita de sockets e portas, em um modelo conhecido como Serverless . Este modelo \u00e9 adequado a algumas aplica\u00e7\u00f5es, como o carrinho de compras da Amazon.com, aplica\u00e7\u00e3o para a qual o Dynamodb foi inicialmente desenvolvido. Nesta aplica\u00e7\u00e3o, cada usu\u00e1rio tem um identificador \u00fanico , recuperado no momento em que se loga ao sistema da Amazon. Este identificador \u00fanico \u00e9 a chave de particionamento e os dados s\u00e3o o conte\u00fado do carrinho de compras. Para lidar com falhas, o conte\u00fado do carrinho \u00e9 replicado nos n\u00f3s sucessivos ao respons\u00e1vel pela dupla chave valor. O carrinho \u00e9 modificado atomicamente , isto \u00e9, sobrescrito por inteiro. A replica\u00e7\u00e3o, associada \u00e0s modifica\u00e7\u00f5es at\u00f4micas, potencializa conflitos, que s\u00e3o identificados comparando-se os vetores de vers\u00e3o (rel\u00f3gios vetoriais) associados a cada valor escrito. No caso de conflitos, as m\u00faltiplas c\u00f3pias concorrentes s\u00e3o apresentadas ao usu\u00e1rio na forma de um carrinho de compras com a uni\u00e3o dos itens nos respectivos carrinhos, de forma que o usu\u00e1rio possa corrig\u00ed-lo. Na pior das hip\u00f3teses, uma compra com erros ser\u00e1 feita, e necessitar\u00e1 de uma atividade compensat\u00f3ria para o usu\u00e1rio, como um brinde. Um disclaimer importante \u00e9 que este material foi preparado com base no DynamoDB original, n\u00e3o na vers\u00e3o atualmente dispon\u00edvel na AWS, com diversas novas funcionalidades.","title":"DynamoDB"},{"location":"p2p/1_3_cassandra/","text":"O CassandraDB se aproxima do modelo relacional, facilitando o desenvolvimento de certas aplica\u00e7\u00f5es, sem perder as caracter\u00edsticas desej\u00e1veis das DHT. A principal caracter\u00edstica neste sentido \u00e9 o modelo h\u00edbrido chave-valor/relacional, em que os valores associados a uma chave s\u00e3o divididos em colunas. A combina\u00e7\u00e3o chave-colunas s\u00e3o denominadas column-families e seu conjunto keyspace . Estas duas estruturas s\u00e3o equivalente \u00e0s tabelas/rela\u00e7\u00f5es e aos bancos de dados, dos bancos de dados relacionais. Uma diferen\u00e7a fundamental entre column-families e rela\u00e7\u00f5es \u00e9 que as \u00faltimas precisam de um esquema pr\u00e9-definido, enquanto que as primeiras n\u00e3o tem um esquema. Isto quer dizer que novas colunas podem ser adicionadas dinamicamente e que nem todas precisam estar presentes para cada chave. De fato, m\u00faltiplos registros com a mesma chave, ou linhas, podem ter conjuntos de colunas diferentes. Para que o correto conjunto de colunas associado a uma chave possa ser apurado, ap\u00f3s m\u00faltiplas escritas com a mesma chave tenham ocorrido, a cada tupla (chave,coluna,valor) \u00e9 associado tamb\u00e9m um timestamp . . Assim, dados uma mesma chave e coluna, o valor v\u00e1lido \u00e9 o com o maior timestamp. Dentro de um n\u00f3, entradas s\u00e3o ordenadas por chaves, possivelmente compostas com os valores de algumas colunas ( chave composta ). Para facilitar mais ainda o desenvolvimento, o Cassandra conta com uma linguagem de consulta similar ao SQL (Structured Query Language), a CQL (Cassandra Query Language). Para aprender mais sobre o Cassandra, visite o s\u00edtio do projeto, aqui , ou explore uma das muitas aplica\u00e7\u00f5es Open Source que o usam, por exemplo, o clone de Twiter Twissandra","title":"Cassandra"},{"location":"p2p/1_dht/","text":"Tabelas Hash As tabelas hash tem uma interface muito simples de armazenamento de dados, sendo adequadas a v\u00e1rios cen\u00e1rios. Em ess\u00eancia, s\u00e3o fun\u00e7\u00f5es, no sentido matem\u00e1tico da palavra, que mapeiam uma chave para um valor. * $f(K): V \\cup$ {null} * $K$: Universo de chaves * $V$: Universo de valores * isto \u00e9, $f(k) = v, k\\in K, v \\in V$ ou $v =$ null. Na pr\u00e1tica, s\u00e3o estruturas de dados adapt\u00e1veis, com um API muito simples. * v' = put(k,v) //Retorna valor j\u00e1 existente * v' = update(k,v) //Retorna valor j\u00e1 existente * v' = get(k) //Retorna valor j\u00e1 existente * v' = del(k) //Retorna valor j\u00e1 existente Sobre os valores mapeados, dizemos que s\u00e3o blobs de dados, isto \u00e9, sem nenhuma forma distinta, e por isso podem ser usadas para resolver uma gama de resolu\u00e7\u00f5es. Al\u00e9m disso, \u00e9 suas opera\u00e7\u00f5es s\u00e3o eficientes em termos de tempo, uma vez que todas as opera\u00e7\u00f5es tem tempo de execu\u00e7\u00e3o (mais ou menos) constante. Distributed Hash Tables. Se as tabelas de espalhamento s\u00e3o estruturas de dados \u00fateis, uma vers\u00e3o distribu\u00edda seria ainda mais \u00fatil, principalmente porqu\u00ea ela poderia ser tolerante a falhas e ter escalabilidade linear . Justamente desta idea que surgem as DHT, literalmente tabelas de espalhamento distribu\u00eddas (ingl\u00eas distributed hash tables ), estruturas de dados que mant\u00e9m a mesma API e funcionalidades de tabelas de espalhamento, mas que agrega capacidades de diversos hosts . Os desafios na implementa\u00e7\u00e3o de DHT incluem * \"O que usar como chave?\", uma vez que tal estrutura precisa ser gen\u00e9rica para que possa ser aplicada a diversos problemas; * \"Como dividir a carga entre hosts?\", para garantir um bom balanceamento de carga; e, * \"Como rotear requisi\u00e7\u00f5es para o host correto?\", uma vez que os dados devem ser particionados entre hosts para garantir escalabilidade. Identifica\u00e7\u00e3o A identifica\u00e7\u00e3o de objetos precisa ser facilmente determin\u00e1vel pela aplica\u00e7\u00e3o para permitir a recupera\u00e7\u00e3o precisa dos dados. Por exemplo, pode-se dividir faixas de nomes entre os processos. * A -- C -- Host1 * CA -- E -- Host2 * EA -- G -- Host3 * ... Esta distribui\u00e7\u00e3o tem tr\u00eas problemas graves. O primeiro, \u00e9 no fato de nomes n\u00e3o serem un\u00edvocos . Neste caso, uma exemplo melhor seria o uso do CPF. * 000.000.000-00 -- 111.111.111-00 -- Host1 * 111.111.111-01 -- 222.222.222-00 -- Host2 * 222.222.222-01 -- 333.333.333-00 -- Host3 * ... O segundo problema, presente tamb\u00e9m no uso de CPF, tem a ver com a distribui\u00e7\u00e3o da carga de trabalho entre os hosts. Nem nomes e nem CPF tem distribui\u00e7\u00e3o uniforme, ent\u00e3o alguns n\u00f3s ficariam mais carregados que outros. O terceiro problema tem a ver com o uso de chaves n\u00e3o gen\u00e9ricas, dependentes da aplica\u00e7\u00e3o. Para este problema, poder\u00edamos usar um identificador auto-increment\u00e1vel, por exemplo, mas em muitas situa\u00e7\u00f5es esta abordagem implicaria em dificuldade para se recuperar os dados: \"qual \u00e9 mesmo o identificador num\u00e9rico do livro How Fascism Works ?\" Para resolver estes tr\u00eas problemas, recorremos a uma abordagem usada na literatura da \u00e1rea, dividindo a identifica\u00e7\u00e3o em duas camadas: * Seja $i$ o identificador do objeto, dado pela aplica\u00e7\u00e3o (e.g., CPF, nome, telefone) * Seja $h$ uma fun\u00e7\u00e3o criptogr\u00e1fica * Seja $k = h(i)$ o identificador do objeto $i$. Se usarmos, por exemplo, MD5, \u00e9 fato que $k$ tem distribui\u00e7\u00e3o uniforme no espa\u00e7o de 0 a $2^{160}-1$ poss\u00edveis valores. Para dividirmos os dados entre os hosts tamb\u00e9m uniformemente, distribua os valores entre os hosts em fun\u00e7\u00e3o de $k$. Alguns exemplos de divis\u00e3o s\u00e3o: * definia buckets para cada host e atribua o dado com chave $k$ para bucket $k \\% b$, onde $b$ \u00e9 o n\u00famero de buckets * divida a faixa de valores em $b$ segmentos e atribua a cada host uma faixa * dados $2^n$ hosts, atribua ao host $0 < x < 2^n-1$ os dados cujas chaves terminem com o valor $x$. S\u00e3o v\u00e1rias as formas de se dividir os dados e est\u00e3o intimamente ligadas \u00e0 rede sobreposta que se pretende montar. Vejamos um caso espec\u00edfico e famoso, o Chord, e de dois outros sistemas que se inspiraram nele.","title":"DHT"},{"location":"p2p/1_dht/#tabelas-hash","text":"As tabelas hash tem uma interface muito simples de armazenamento de dados, sendo adequadas a v\u00e1rios cen\u00e1rios. Em ess\u00eancia, s\u00e3o fun\u00e7\u00f5es, no sentido matem\u00e1tico da palavra, que mapeiam uma chave para um valor. * $f(K): V \\cup$ {null} * $K$: Universo de chaves * $V$: Universo de valores * isto \u00e9, $f(k) = v, k\\in K, v \\in V$ ou $v =$ null. Na pr\u00e1tica, s\u00e3o estruturas de dados adapt\u00e1veis, com um API muito simples. * v' = put(k,v) //Retorna valor j\u00e1 existente * v' = update(k,v) //Retorna valor j\u00e1 existente * v' = get(k) //Retorna valor j\u00e1 existente * v' = del(k) //Retorna valor j\u00e1 existente Sobre os valores mapeados, dizemos que s\u00e3o blobs de dados, isto \u00e9, sem nenhuma forma distinta, e por isso podem ser usadas para resolver uma gama de resolu\u00e7\u00f5es. Al\u00e9m disso, \u00e9 suas opera\u00e7\u00f5es s\u00e3o eficientes em termos de tempo, uma vez que todas as opera\u00e7\u00f5es tem tempo de execu\u00e7\u00e3o (mais ou menos) constante.","title":"Tabelas Hash"},{"location":"p2p/1_dht/#distributed-hash-tables","text":"Se as tabelas de espalhamento s\u00e3o estruturas de dados \u00fateis, uma vers\u00e3o distribu\u00edda seria ainda mais \u00fatil, principalmente porqu\u00ea ela poderia ser tolerante a falhas e ter escalabilidade linear . Justamente desta idea que surgem as DHT, literalmente tabelas de espalhamento distribu\u00eddas (ingl\u00eas distributed hash tables ), estruturas de dados que mant\u00e9m a mesma API e funcionalidades de tabelas de espalhamento, mas que agrega capacidades de diversos hosts . Os desafios na implementa\u00e7\u00e3o de DHT incluem * \"O que usar como chave?\", uma vez que tal estrutura precisa ser gen\u00e9rica para que possa ser aplicada a diversos problemas; * \"Como dividir a carga entre hosts?\", para garantir um bom balanceamento de carga; e, * \"Como rotear requisi\u00e7\u00f5es para o host correto?\", uma vez que os dados devem ser particionados entre hosts para garantir escalabilidade.","title":"Distributed Hash Tables."},{"location":"p2p/1_dht/#identificacao","text":"A identifica\u00e7\u00e3o de objetos precisa ser facilmente determin\u00e1vel pela aplica\u00e7\u00e3o para permitir a recupera\u00e7\u00e3o precisa dos dados. Por exemplo, pode-se dividir faixas de nomes entre os processos. * A -- C -- Host1 * CA -- E -- Host2 * EA -- G -- Host3 * ... Esta distribui\u00e7\u00e3o tem tr\u00eas problemas graves. O primeiro, \u00e9 no fato de nomes n\u00e3o serem un\u00edvocos . Neste caso, uma exemplo melhor seria o uso do CPF. * 000.000.000-00 -- 111.111.111-00 -- Host1 * 111.111.111-01 -- 222.222.222-00 -- Host2 * 222.222.222-01 -- 333.333.333-00 -- Host3 * ... O segundo problema, presente tamb\u00e9m no uso de CPF, tem a ver com a distribui\u00e7\u00e3o da carga de trabalho entre os hosts. Nem nomes e nem CPF tem distribui\u00e7\u00e3o uniforme, ent\u00e3o alguns n\u00f3s ficariam mais carregados que outros. O terceiro problema tem a ver com o uso de chaves n\u00e3o gen\u00e9ricas, dependentes da aplica\u00e7\u00e3o. Para este problema, poder\u00edamos usar um identificador auto-increment\u00e1vel, por exemplo, mas em muitas situa\u00e7\u00f5es esta abordagem implicaria em dificuldade para se recuperar os dados: \"qual \u00e9 mesmo o identificador num\u00e9rico do livro How Fascism Works ?\" Para resolver estes tr\u00eas problemas, recorremos a uma abordagem usada na literatura da \u00e1rea, dividindo a identifica\u00e7\u00e3o em duas camadas: * Seja $i$ o identificador do objeto, dado pela aplica\u00e7\u00e3o (e.g., CPF, nome, telefone) * Seja $h$ uma fun\u00e7\u00e3o criptogr\u00e1fica * Seja $k = h(i)$ o identificador do objeto $i$. Se usarmos, por exemplo, MD5, \u00e9 fato que $k$ tem distribui\u00e7\u00e3o uniforme no espa\u00e7o de 0 a $2^{160}-1$ poss\u00edveis valores. Para dividirmos os dados entre os hosts tamb\u00e9m uniformemente, distribua os valores entre os hosts em fun\u00e7\u00e3o de $k$. Alguns exemplos de divis\u00e3o s\u00e3o: * definia buckets para cada host e atribua o dado com chave $k$ para bucket $k \\% b$, onde $b$ \u00e9 o n\u00famero de buckets * divida a faixa de valores em $b$ segmentos e atribua a cada host uma faixa * dados $2^n$ hosts, atribua ao host $0 < x < 2^n-1$ os dados cujas chaves terminem com o valor $x$. S\u00e3o v\u00e1rias as formas de se dividir os dados e est\u00e3o intimamente ligadas \u00e0 rede sobreposta que se pretende montar. Vejamos um caso espec\u00edfico e famoso, o Chord, e de dois outros sistemas que se inspiraram nele.","title":"Identifica\u00e7\u00e3o"},{"location":"p2p/2_ed_sd/","text":"Qualquer que seja a escolha de algoritmo para fazer o particionamento dos dados entre servidores, sobra ainda a quest\u00e3o de como manipular os dados dentro do servidor. Idealmente, toda opera\u00e7\u00e3o seria executada a partir da mem\u00f3ria principal, tendo assim a menor lat\u00eancia poss\u00edvel. Contudo, para que se tenha tamb\u00e9m durabilidade das opera\u00e7\u00f5es executadas, para que os dados manipulados sobrevivam a reinicializa\u00e7\u00f5es do servidor, intencionais ou n\u00e3o, \u00e9 preciso armazenar os dados em mem\u00f3ria est\u00e1vel , da qual a mais comum \u00e9 s\u00e3o os discos r\u00edgidos . \u00c9 not\u00f3rio que escritas em disco s\u00e3o muito mais lentas que em mem\u00f3ria principal, mas o que exatamente \u00e9 lento no acesso ao disco? Essencialmente, o posicionamento da cabeca de leitura/escrita na trilha correta do disco, pois esta opera\u00e7\u00e3o \u00e9 mec\u00e2nica. Por esta raz\u00e3o, acessos aleat\u00f3rios s\u00e3o mais custosos que acessos sequenciais, pois neste o custo de posicionamento \u00e9 pago apenas uma vez. Por este motivo, muitos bancos de dados, especialmente DHT pois tem seu uso focado em quantidades muito grandes de dados, gerados e acessados com grande velocidade, tentam acessar o disco sempre de forma sequencial. Alguns bancos de dados, como o Cassandra, armazenam os dados na forma de uma Log Structured Merge Tree , ou LSMT. Log Structured Merge Tree Uma Log Structured Merge Tree \u00e9 uma forma de se armazenar dados em disco de forma de forma quase sempre sequencial, minimizando assim os o impacto da durabilidade no desempenho do sistema. Considere um banco armazenando uma pequena quantidade de dados, que cabe em mem\u00f3ria principal. Na LSMT, opera\u00e7\u00f5es de escrita s\u00e3o adicionadas a um commit log , em disco, e somente ent\u00e3o s\u00e3o executadas em mem\u00f3ria principal e confirmadas para o cliente; a estrutura que armazena os dados em mem\u00f3ria \u00e9 denominada memory table , ou simplesmente memtable . Neste cen\u00e1rio o acesso ao disco na escrita \u00e9 sequencial, o melhor que se pode ter em um disco, e a recupera\u00e7\u00e3o dos dados \u00e9 feita diretamente da mem\u00f3ria, r\u00e1pida. No caso de uma reinicializa\u00e7\u00e3o do processo, a reexecu\u00e7\u00e3o do commit log restaurar\u00e1 o estado da memtable. Contudo, se o commit log for extenso, reexecut\u00e1-lo demandar\u00e1 um tempo significativo. Uma forma de acelerar o processo \u00e9 fazer snapshots da memtable de forma sincronizada com a escrita no log. Isto \u00e9, digamos que todas as opera\u00e7\u00f5es de escrita, at\u00e9 a d\u00e9cima, est\u00e3o salvas no commit log e refletidas na memtable. Digamos tamb\u00e9m que todas as opera\u00e7\u00f5es s\u00e3o modifica\u00e7\u00f5es da mesma linha do banco de dados em mem\u00f3ria. Se um snapshot \u00e9 tomado, ele ser\u00e1 correspondente ao commit log, isto \u00e9, conter\u00e1 o efeito de exatamente as mesmas 10 opera\u00e7\u00f5es, mas de forma mais compacta que o log, uma vez que o log conter\u00e1 dez opera\u00e7\u00f5es e o snapshot somente uma linha de dados. Ap\u00f3s o snapshot ser conclu\u00eddo, o log correspondente pode ser apagado. Novas opera\u00e7\u00f5es de escrita devem ser armazenadas em um novo log e, no caso de uma reinicializa\u00e7\u00e3o, primeiro se deve restaurar o snapshot e ent\u00e3o o novo log. Para lidar com corrup\u00e7\u00f5es de arquivo no sistema, pode ser uma boa ideia manter mais do que o \u00faltimo log e snapshot , j\u00e1 que a recupera\u00e7\u00e3o do estado exigiria voltar mais atr\u00e1s na reexecu\u00e7\u00e3o de opera\u00e7\u00f5es. Observe que, al\u00e9m da escrita dos logs, todos os outros acessos ao disco tamb\u00e9m s\u00e3o sequenciais, seja o flush das memtables, ou a leitura dos snapshots para recupera\u00e7\u00e3o e do commit log para reexecu\u00e7\u00e3o, e j\u00e1 que opera\u00e7\u00f5es de leitura s\u00e3o todas respondidas da mem\u00f3ria, o sistema ter\u00e1 um excelente desempenho. Contudo, h\u00e1 outro limitante de desempenho importante, relacionado \u00e0 premissa pouco realista de que os dados cabem todos em mem\u00f3ria. Isto \u00e9, se os dados n\u00e3o cabem em mem\u00f3ria, snapshots ser\u00e3o importantes n\u00e3o somente para permitir coletar lixo dos logs, isto \u00e9, dados obsoletos, mas tamb\u00e9m, para usar a capacidade de armazenamento dos discos. Consideremos ent\u00e3o um cen\u00e1rio em que a memtable cabe apenas n entradas; quando a opera\u00e7\u00e3o para adicionar $n+1$-\u00e9sima entrada \u00e0 memtable \u00e9 recebida, um flushs dos dados para um novo snapshot \u00e9 feito e a memtable \u00e9 resetada , liberando espa\u00e7o em mem\u00f3ria. Para melhorar o desempenho, estas descargas podem ser feitas proativamente antes da chegada de novas entradas e fora do caminho cr\u00edtico da opera\u00e7\u00e3o de escrita, mas isto \u00e9 apenas uma otimiza\u00e7\u00e3o e portanto n\u00e3o a consideraremos aqui. Neste novo fluxo, os arquivos em disco n\u00e3o correspondem mais a snapshots do banco de dados, ent\u00e3o nos referiremos a eles como stable storage tables , ou sstables , em oposi\u00e7\u00e3o \u00e0s memtables , pelo menos por enquanto. Compacta\u00e7\u00f5es Apesar deste novo fluxo de escrita aumentar a capacidade de armazenamento do nosso banco de dados, ele traz problemas para o fluxo de leitura. Digamos que a chave $k$ teve um valor atribu\u00eddo e descarregado em uma sstable em diversas ocasi\u00f5es. O primeiro problema aqui \u00e9 que h\u00e1 v\u00e1rios valores antigos associados a $k$, inutilmente e ocupando espa\u00e7o, isto \u00e9, lixo. O segundo \u00e9 que caso o valor associado a $k$ seja requisitado, o sistema dever\u00e1 retornar a \u00faltima vers\u00e3o, que pode estar em diversos arquivos. Para lidar com ambos os problemas, podemos compactar as sstables juntas, eliminados dados obsoletos e minimizando o n\u00famero de arquivos a serem pesquisados no caso de leitura. Caso a sstables estejam ordenadas, o procedimento de compacta\u00e7\u00e3o pode ser feito como a uni\u00e3o de dois segmentos de dados no merge sort , isto \u00e9, iterando-se paralelamente nos dois arquivos e escolhendo sempre a menor chave da vez e movendo-a para um novo segmento que conter\u00e1 a uni\u00e3o dos dados. A figura a seguir mostra um exemplo que v\u00e1rias sstables de n\u00edvel 0, aquelas geradas por flushs , s\u00e3o unidas gerando sstables de n\u00edvel 1 e assim sucessivamente. Observe como as compacta\u00e7\u00f5es geram uma \u00e1rvore (na verdade, uma floresta), raz\u00e3o do nome merge tree . No caso de uma pesquisa, somente as tabelas mais \u00e0 direita e de n\u00edvel mais alto precisam ser consultadas e portanto as sstables j\u00e1 usadas como entrada podem ser eliminadas como lixo do sistema. Ainda assim, no caso de uma leitura, diversas sstables potencialmente cont\u00e9m o dado a ser retornado. O problema se agrava em sistemas em que partes do dado possam ser gravadas independentemente, como no CassandraDB, em que cada coluna \u00e9 independente das outras. Diversas propostas poderiam ser feitas para se identificar mais rapidamente se uma sstable cont\u00e9m uma chave. Por exemplo, pode-se associar a cada tabela um bitmap indicando a presen\u00e7a ou n\u00e3o de uma certa chave, mas esta abordagem obviamente falha se o espa\u00e7o de chaves for grande. Outra possibilidade \u00e9 lembrar a faixa de chaves contida na tabela. Esta estrat\u00e9gia pode ser \u00fatil caso haja localidade no espa\u00e7o de chaves no momento da escrita, mas falhar\u00e1 miseravelmente se o espa\u00e7o de chaves for usado uniformemente, resultando em faixas grandes entre a menor e maior chaves de cada tabela. Como acelerar a identifica\u00e7\u00e3o das sstables pertinentes? Entram em cena os filtros de Bloom . Filtros de Bloom De acordo com nossa fonte mais que confi\u00e1vel, a Wikipedia A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not, thus a Bloom filter has a 100% recall rate. In other words, a query returns either \"possibly in set\" or \"definitely not in set\" . Se associarmos a cada sstable um filtro de Bloom, ent\u00e3o s\u00f3 ser\u00e1 preciso l\u00ea-la se o filtro correspondente disser que a chave possivelmente est\u00e1 contida, como no seguinte exemplo. Mas como exatamente constru\u00edmos um filtro de Bloom? Iniciamos com um vetor de bits inicialmente zerados e um conjunto finito de fun\u00e7\u00f5es de hash cujo resultado seja uniformemente distribu\u00eddo no tamanho do vetor de bits. Para cada elemento colocado no conjunto a ser refletido pelo filtro, aplicamos cada uma das fun\u00e7\u00f5es hash e colocamos o bit 1 na posi\u00e7\u00e3o do vetor igual ao resultado da fun\u00e7\u00e3o. No exemplo a seguir, inserimos os elementos x, y e z e usamos tr\u00eas fun\u00e7\u00f5es hash. Na consulta , cada elemento passa por pelas mesmas fun\u00e7\u00f5es hash. Se algum dos \u00edndices apontados n\u00e3o estiver com um 1, como no caso do w, no exemplo, o elemento n\u00e3o pertence ao conjunto. Caso contr\u00e1rio, o filtro responder\u00e1 que \u00e9 poss\u00edvel que perten\u00e7a. Mas qu\u00e3o bom \u00e9 um filtro de Bloom na identifica\u00e7\u00e3o do das sstables? Ou, de outra forma, quais fatores influenciam na taxa de falsos positivos do filtro? * o n\u00famero $n$ de elementos no conjunto, uma vez que quanto mais elementos, mais bits 1; * o n\u00famero $k$ de hashes, pois quanto mais hashes, mais bits transformados em 1; e, * o n\u00famero $m$ de bits no vetor, pois quanto menos bits, mais colis\u00f5es de bits. De forma mais precisa, * a probabilidade de setar um certo bit na inser\u00e7\u00e3o de um elemento \u00e9 $1/m$, e * a probabilidade de n\u00e3o setar tal bit \u00e9 $1 - 1/m$; * a probabilidade de $k$ hashes n\u00e3o setarem um bit \u00e9 $(1 - 1/m)^k$; * a probabilidade de n\u00e3o setar um bit ap\u00f3s $n$ inser\u00e7\u00f5es \u00e9 $(1 - 1/m)^{kn}$; * a probabilidade de setar um bit ap\u00f3s $n$ inser\u00e7\u00f5es \u00e9 $1 - (1 - 1/m)^{kn}$ Logo, * a probabilidade de falso positivo $p = (1 - (1 - 1/m)^{kn})^k \\approx (1 - e^{-kn/m})^k$ O que nos permite chegar \u00e0 rela\u00e7\u00e3o * $m/n = - 1.44\\log_2 p$, em que podemos calcular $m$ em fun\u00e7\u00e3o do $n$ esperado e do $p$ desejado. E podemos tamb\u00e9m identificar o $k$ \u00f3timo para a situa\u00e7\u00e3o, pela equa\u00e7\u00e3o * $k = - \\frac{\\ln p}{\\ln 2} = - \\log_2 p$ Uma forma \"simples\" de visualizar este resultado \u00e9 dada pela figura a seguir, em que o eixo Y d\u00e1 a taxa de falsos positivos do filtro em fun\u00e7\u00e3o do n\u00famero de elementos inseridos, indicado no eixo X, para diversas configura\u00e7\u00f5es, apresentadas como curvas. Por exemplo, com um filtro com $m = 2^{24}b = 2MB$, ap\u00f3s 1 milh\u00e3o de inser\u00e7\u00f5es, tem-se probabilidade de falsos positivo $p = 0,0001$. Refer\u00eancias Modern Algorithms and Data Structures: Bloom-Filter Merkle Trees TODO Como sincronizar duas m\u00e1quinas? Suponha que um mesmo arquivo exista em duas m\u00e1quinas. Como sincroniz\u00e1-los de forma eficiente, onde efici\u00eancia se mede em termos de uso da rede? Copie os arquivos de um servidor para outro Mantenha o mais novo Isso \u00e9 eficiente? Como sincronizar duas m\u00e1quinas? Produza um hash dos arquivos Troque hashes Se hashes iguais, pronto. Se hashes diferentes, volte para o slide anterior. Merkle Trees Divida o arquivo em blocos de mesmo tamanho Fa\u00e7a um hash de cada bloco Se mais de um hash gerado, Concatene os hashes em um arquivo Volte para o primeiro item Troque hashes da raiz. Se hashes iguais, pronto. Se hashes diferentes \\pause compare sub\u00e1rvore. Se a \u00fanica mudan\u00e7a no arquivo foi a adi\u00e7\u00e3o de um byte no come\u00e7o do arquivo? Refer\u00eancias Modern Algorithms and Data Structures: Merkle Trees Rabin Fingerprint Rolling Hash","title":"Estruturas de Dados para SD"},{"location":"p2p/2_ed_sd/#log-structured-merge-tree","text":"Uma Log Structured Merge Tree \u00e9 uma forma de se armazenar dados em disco de forma de forma quase sempre sequencial, minimizando assim os o impacto da durabilidade no desempenho do sistema. Considere um banco armazenando uma pequena quantidade de dados, que cabe em mem\u00f3ria principal. Na LSMT, opera\u00e7\u00f5es de escrita s\u00e3o adicionadas a um commit log , em disco, e somente ent\u00e3o s\u00e3o executadas em mem\u00f3ria principal e confirmadas para o cliente; a estrutura que armazena os dados em mem\u00f3ria \u00e9 denominada memory table , ou simplesmente memtable . Neste cen\u00e1rio o acesso ao disco na escrita \u00e9 sequencial, o melhor que se pode ter em um disco, e a recupera\u00e7\u00e3o dos dados \u00e9 feita diretamente da mem\u00f3ria, r\u00e1pida. No caso de uma reinicializa\u00e7\u00e3o do processo, a reexecu\u00e7\u00e3o do commit log restaurar\u00e1 o estado da memtable. Contudo, se o commit log for extenso, reexecut\u00e1-lo demandar\u00e1 um tempo significativo. Uma forma de acelerar o processo \u00e9 fazer snapshots da memtable de forma sincronizada com a escrita no log. Isto \u00e9, digamos que todas as opera\u00e7\u00f5es de escrita, at\u00e9 a d\u00e9cima, est\u00e3o salvas no commit log e refletidas na memtable. Digamos tamb\u00e9m que todas as opera\u00e7\u00f5es s\u00e3o modifica\u00e7\u00f5es da mesma linha do banco de dados em mem\u00f3ria. Se um snapshot \u00e9 tomado, ele ser\u00e1 correspondente ao commit log, isto \u00e9, conter\u00e1 o efeito de exatamente as mesmas 10 opera\u00e7\u00f5es, mas de forma mais compacta que o log, uma vez que o log conter\u00e1 dez opera\u00e7\u00f5es e o snapshot somente uma linha de dados. Ap\u00f3s o snapshot ser conclu\u00eddo, o log correspondente pode ser apagado. Novas opera\u00e7\u00f5es de escrita devem ser armazenadas em um novo log e, no caso de uma reinicializa\u00e7\u00e3o, primeiro se deve restaurar o snapshot e ent\u00e3o o novo log. Para lidar com corrup\u00e7\u00f5es de arquivo no sistema, pode ser uma boa ideia manter mais do que o \u00faltimo log e snapshot , j\u00e1 que a recupera\u00e7\u00e3o do estado exigiria voltar mais atr\u00e1s na reexecu\u00e7\u00e3o de opera\u00e7\u00f5es. Observe que, al\u00e9m da escrita dos logs, todos os outros acessos ao disco tamb\u00e9m s\u00e3o sequenciais, seja o flush das memtables, ou a leitura dos snapshots para recupera\u00e7\u00e3o e do commit log para reexecu\u00e7\u00e3o, e j\u00e1 que opera\u00e7\u00f5es de leitura s\u00e3o todas respondidas da mem\u00f3ria, o sistema ter\u00e1 um excelente desempenho. Contudo, h\u00e1 outro limitante de desempenho importante, relacionado \u00e0 premissa pouco realista de que os dados cabem todos em mem\u00f3ria. Isto \u00e9, se os dados n\u00e3o cabem em mem\u00f3ria, snapshots ser\u00e3o importantes n\u00e3o somente para permitir coletar lixo dos logs, isto \u00e9, dados obsoletos, mas tamb\u00e9m, para usar a capacidade de armazenamento dos discos. Consideremos ent\u00e3o um cen\u00e1rio em que a memtable cabe apenas n entradas; quando a opera\u00e7\u00e3o para adicionar $n+1$-\u00e9sima entrada \u00e0 memtable \u00e9 recebida, um flushs dos dados para um novo snapshot \u00e9 feito e a memtable \u00e9 resetada , liberando espa\u00e7o em mem\u00f3ria. Para melhorar o desempenho, estas descargas podem ser feitas proativamente antes da chegada de novas entradas e fora do caminho cr\u00edtico da opera\u00e7\u00e3o de escrita, mas isto \u00e9 apenas uma otimiza\u00e7\u00e3o e portanto n\u00e3o a consideraremos aqui. Neste novo fluxo, os arquivos em disco n\u00e3o correspondem mais a snapshots do banco de dados, ent\u00e3o nos referiremos a eles como stable storage tables , ou sstables , em oposi\u00e7\u00e3o \u00e0s memtables , pelo menos por enquanto.","title":"Log Structured Merge Tree"},{"location":"p2p/2_ed_sd/#compactacoes","text":"Apesar deste novo fluxo de escrita aumentar a capacidade de armazenamento do nosso banco de dados, ele traz problemas para o fluxo de leitura. Digamos que a chave $k$ teve um valor atribu\u00eddo e descarregado em uma sstable em diversas ocasi\u00f5es. O primeiro problema aqui \u00e9 que h\u00e1 v\u00e1rios valores antigos associados a $k$, inutilmente e ocupando espa\u00e7o, isto \u00e9, lixo. O segundo \u00e9 que caso o valor associado a $k$ seja requisitado, o sistema dever\u00e1 retornar a \u00faltima vers\u00e3o, que pode estar em diversos arquivos. Para lidar com ambos os problemas, podemos compactar as sstables juntas, eliminados dados obsoletos e minimizando o n\u00famero de arquivos a serem pesquisados no caso de leitura. Caso a sstables estejam ordenadas, o procedimento de compacta\u00e7\u00e3o pode ser feito como a uni\u00e3o de dois segmentos de dados no merge sort , isto \u00e9, iterando-se paralelamente nos dois arquivos e escolhendo sempre a menor chave da vez e movendo-a para um novo segmento que conter\u00e1 a uni\u00e3o dos dados. A figura a seguir mostra um exemplo que v\u00e1rias sstables de n\u00edvel 0, aquelas geradas por flushs , s\u00e3o unidas gerando sstables de n\u00edvel 1 e assim sucessivamente. Observe como as compacta\u00e7\u00f5es geram uma \u00e1rvore (na verdade, uma floresta), raz\u00e3o do nome merge tree . No caso de uma pesquisa, somente as tabelas mais \u00e0 direita e de n\u00edvel mais alto precisam ser consultadas e portanto as sstables j\u00e1 usadas como entrada podem ser eliminadas como lixo do sistema. Ainda assim, no caso de uma leitura, diversas sstables potencialmente cont\u00e9m o dado a ser retornado. O problema se agrava em sistemas em que partes do dado possam ser gravadas independentemente, como no CassandraDB, em que cada coluna \u00e9 independente das outras. Diversas propostas poderiam ser feitas para se identificar mais rapidamente se uma sstable cont\u00e9m uma chave. Por exemplo, pode-se associar a cada tabela um bitmap indicando a presen\u00e7a ou n\u00e3o de uma certa chave, mas esta abordagem obviamente falha se o espa\u00e7o de chaves for grande. Outra possibilidade \u00e9 lembrar a faixa de chaves contida na tabela. Esta estrat\u00e9gia pode ser \u00fatil caso haja localidade no espa\u00e7o de chaves no momento da escrita, mas falhar\u00e1 miseravelmente se o espa\u00e7o de chaves for usado uniformemente, resultando em faixas grandes entre a menor e maior chaves de cada tabela. Como acelerar a identifica\u00e7\u00e3o das sstables pertinentes? Entram em cena os filtros de Bloom .","title":"Compacta\u00e7\u00f5es"},{"location":"p2p/2_ed_sd/#filtros-de-bloom","text":"De acordo com nossa fonte mais que confi\u00e1vel, a Wikipedia A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not, thus a Bloom filter has a 100% recall rate. In other words, a query returns either \"possibly in set\" or \"definitely not in set\" . Se associarmos a cada sstable um filtro de Bloom, ent\u00e3o s\u00f3 ser\u00e1 preciso l\u00ea-la se o filtro correspondente disser que a chave possivelmente est\u00e1 contida, como no seguinte exemplo. Mas como exatamente constru\u00edmos um filtro de Bloom? Iniciamos com um vetor de bits inicialmente zerados e um conjunto finito de fun\u00e7\u00f5es de hash cujo resultado seja uniformemente distribu\u00eddo no tamanho do vetor de bits. Para cada elemento colocado no conjunto a ser refletido pelo filtro, aplicamos cada uma das fun\u00e7\u00f5es hash e colocamos o bit 1 na posi\u00e7\u00e3o do vetor igual ao resultado da fun\u00e7\u00e3o. No exemplo a seguir, inserimos os elementos x, y e z e usamos tr\u00eas fun\u00e7\u00f5es hash. Na consulta , cada elemento passa por pelas mesmas fun\u00e7\u00f5es hash. Se algum dos \u00edndices apontados n\u00e3o estiver com um 1, como no caso do w, no exemplo, o elemento n\u00e3o pertence ao conjunto. Caso contr\u00e1rio, o filtro responder\u00e1 que \u00e9 poss\u00edvel que perten\u00e7a. Mas qu\u00e3o bom \u00e9 um filtro de Bloom na identifica\u00e7\u00e3o do das sstables? Ou, de outra forma, quais fatores influenciam na taxa de falsos positivos do filtro? * o n\u00famero $n$ de elementos no conjunto, uma vez que quanto mais elementos, mais bits 1; * o n\u00famero $k$ de hashes, pois quanto mais hashes, mais bits transformados em 1; e, * o n\u00famero $m$ de bits no vetor, pois quanto menos bits, mais colis\u00f5es de bits. De forma mais precisa, * a probabilidade de setar um certo bit na inser\u00e7\u00e3o de um elemento \u00e9 $1/m$, e * a probabilidade de n\u00e3o setar tal bit \u00e9 $1 - 1/m$; * a probabilidade de $k$ hashes n\u00e3o setarem um bit \u00e9 $(1 - 1/m)^k$; * a probabilidade de n\u00e3o setar um bit ap\u00f3s $n$ inser\u00e7\u00f5es \u00e9 $(1 - 1/m)^{kn}$; * a probabilidade de setar um bit ap\u00f3s $n$ inser\u00e7\u00f5es \u00e9 $1 - (1 - 1/m)^{kn}$ Logo, * a probabilidade de falso positivo $p = (1 - (1 - 1/m)^{kn})^k \\approx (1 - e^{-kn/m})^k$ O que nos permite chegar \u00e0 rela\u00e7\u00e3o * $m/n = - 1.44\\log_2 p$, em que podemos calcular $m$ em fun\u00e7\u00e3o do $n$ esperado e do $p$ desejado. E podemos tamb\u00e9m identificar o $k$ \u00f3timo para a situa\u00e7\u00e3o, pela equa\u00e7\u00e3o * $k = - \\frac{\\ln p}{\\ln 2} = - \\log_2 p$ Uma forma \"simples\" de visualizar este resultado \u00e9 dada pela figura a seguir, em que o eixo Y d\u00e1 a taxa de falsos positivos do filtro em fun\u00e7\u00e3o do n\u00famero de elementos inseridos, indicado no eixo X, para diversas configura\u00e7\u00f5es, apresentadas como curvas. Por exemplo, com um filtro com $m = 2^{24}b = 2MB$, ap\u00f3s 1 milh\u00e3o de inser\u00e7\u00f5es, tem-se probabilidade de falsos positivo $p = 0,0001$.","title":"Filtros de Bloom"},{"location":"p2p/2_ed_sd/#referencias","text":"Modern Algorithms and Data Structures: Bloom-Filter","title":"Refer\u00eancias"},{"location":"p2p/2_ed_sd/#merkle-trees","text":"TODO","title":"Merkle Trees"},{"location":"p2p/2_ed_sd/#como-sincronizar-duas-maquinas","text":"Suponha que um mesmo arquivo exista em duas m\u00e1quinas. Como sincroniz\u00e1-los de forma eficiente, onde efici\u00eancia se mede em termos de uso da rede? Copie os arquivos de um servidor para outro Mantenha o mais novo Isso \u00e9 eficiente?","title":"Como sincronizar duas m\u00e1quinas?"},{"location":"p2p/2_ed_sd/#como-sincronizar-duas-maquinas_1","text":"Produza um hash dos arquivos Troque hashes Se hashes iguais, pronto. Se hashes diferentes, volte para o slide anterior.","title":"Como sincronizar duas m\u00e1quinas?"},{"location":"p2p/2_ed_sd/#merkle-trees_1","text":"Divida o arquivo em blocos de mesmo tamanho Fa\u00e7a um hash de cada bloco Se mais de um hash gerado, Concatene os hashes em um arquivo Volte para o primeiro item Troque hashes da raiz. Se hashes iguais, pronto. Se hashes diferentes \\pause compare sub\u00e1rvore. Se a \u00fanica mudan\u00e7a no arquivo foi a adi\u00e7\u00e3o de um byte no come\u00e7o do arquivo?","title":"Merkle Trees"},{"location":"p2p/2_ed_sd/#referencias_1","text":"Modern Algorithms and Data Structures: Merkle Trees","title":"Refer\u00eancias"},{"location":"p2p/2_ed_sd/#rabin-fingerprint","text":"Rolling Hash","title":"Rabin Fingerprint"},{"location":"projeto/projeto/","text":"TODO Propor projeto de sistema NoSQL. * Etapa 1 - Cliente/Servidor * Objetivos * Hash Table acess\u00edvel remotamente por interface CRUD sobre HTML. * Armazenamento em disco com recupera\u00e7\u00e3o de dados no caso de falhas * Desafios * Especifica\u00e7\u00e3o do protocolo para dados gen\u00e9ricos * Armazenamento at\u00f4mico no disco * Multithreading para garantir escalabilidade * Controle de concorr\u00eancia * Est\u00e1gios * Etapa 2 - P2P * Objetivos * DHT com roteamento estilo Chord * Armazenamento em Log de opera\u00e7\u00f5es e em arquivo de snapshots * Comunica\u00e7\u00e3o usando RPC * Desafios * Uso adequado da interface funcional do RPC * Uso do log + snapshots para recupera\u00e7\u00e3o * Roteamento no anel * Bootstrap dos processos * Log Structured Merge Tree * Etapa 3 - Toler\u00e2ncia a Falhas * Objetivos * Cada servidor \u00e9 uma m\u00e1quina de estados replicada * Desafios * Usar adequadamente Difus\u00e3o At\u00f4mica * Entender Commit Distribu\u00eddo","title":"TODO"},{"location":"projeto/projeto/#todo","text":"Propor projeto de sistema NoSQL. * Etapa 1 - Cliente/Servidor * Objetivos * Hash Table acess\u00edvel remotamente por interface CRUD sobre HTML. * Armazenamento em disco com recupera\u00e7\u00e3o de dados no caso de falhas * Desafios * Especifica\u00e7\u00e3o do protocolo para dados gen\u00e9ricos * Armazenamento at\u00f4mico no disco * Multithreading para garantir escalabilidade * Controle de concorr\u00eancia * Est\u00e1gios * Etapa 2 - P2P * Objetivos * DHT com roteamento estilo Chord * Armazenamento em Log de opera\u00e7\u00f5es e em arquivo de snapshots * Comunica\u00e7\u00e3o usando RPC * Desafios * Uso adequado da interface funcional do RPC * Uso do log + snapshots para recupera\u00e7\u00e3o * Roteamento no anel * Bootstrap dos processos * Log Structured Merge Tree * Etapa 3 - Toler\u00e2ncia a Falhas * Objetivos * Cada servidor \u00e9 uma m\u00e1quina de estados replicada * Desafios * Usar adequadamente Difus\u00e3o At\u00f4mica * Entender Commit Distribu\u00eddo","title":"TODO"},{"location":"tempo/0_intro/","text":"Neste cap\u00edtulo discutiremos o qu\u00ea s\u00e3o sistemas distribu\u00eddos, por qu\u00ea os desenvolvemos, e damos uma vis\u00e3o geral de como isto \u00e9 feito.","title":"Tempo"},{"location":"tempo/1_fisico/","text":"Tempo Se um mesmo arquivo no Dropbox \u00e9 modificado em duas m\u00e1quinas diferentes, enquanto as mesmas est\u00e3o desconectadas, o qu\u00ea acontece quando elas se reconectam? Problema Se dois arquivos com o mesmo nome s\u00e3o enviadas ao servidor, qual deve ser mantido? Uma possibilidade \u00e9 aceitar o arquivo que chega primeiro e rejeitar o que chega depois. Mas imagine que seu servi\u00e7o esteja interessado em registrar a anterioridade de ideias anotadas nos arquivos. Neste caso, o sistema poderia dar anterioridade ao arquivo errado, isto \u00e9, o mais recentemente criado. Outra abordagem, \u00e9 manter janelas de aceite de arquivos, e dentro destas janelas, manter os arquivos com hor\u00e1rio de cria\u00e7\u00e3o menor. Neste caso, um trapaceiro poderia modificar seu rel\u00f3gico para fazer seu arquivo passar na frente. Uma terceira abordagem \u00e9 gerar uma terceira vers\u00e3o, com a \"soma\" das duas conflitantes. Para gerar esta terceira vers\u00e3o, faz mais sentido quebrar os arquivos em opera\u00e7\u00f5es de modifica\u00e7\u00e3o , e executar as opera\u00e7\u00f5es de forma a chegar ao resultado final. O problema permanece, pois as opera\u00e7\u00f5es agora devem ser ordenadas. Em qualquer destas linhas de atua\u00e7\u00e3o, voc\u00ea tem em m\u00e3os um conflito para resolver, e autmatizar a resolu\u00e7\u00e3o do mesmo \u00e9 muito complicado. \u00c9 por isso que o Dropbox deixa os dois arquivos para que o usu\u00e1rio analize e decida o que fazer, que servidores git permitem a submiss\u00e3o de apenas um conjunto de opera\u00e7\u00f5es por vez para um mesmo reposit\u00f3rio, e o Perforce trabalhe com locks de arquivos. De forma mais gen\u00e9rica, Problema Se duas opera\u00e7\u00f5es originadas em clientes s\u00e3o enviadas ao servidor, qual deve ser executada primeiro? Alguns sistemas, contudo, tentam resolver automaticamente os conflitos. No caso do CassandraDB, usa-se CassandraDB \"last write wins\" ou \"latest version wins\" Onde last \u00e9 definido pelo rel\u00f3gio do cliente. Acontece que a maior parte dos nossos sistemas n\u00e3o d\u00e1 garantias de tempo na entrega de mensagens ou processamento de instru\u00e7\u00f5es. Assim, temos novo problema: Problema Como determinar qual foi enviada primeiro, em um sistema ass\u00edncrono? Assim, precisamos encontrar uma fonte de tempo confi\u00e1vel e distribu\u00edda . O desafio come\u00e7a com o entendimento de rel\u00f3gios f\u00edsicos. Rel\u00f3gios F\u00edsicos Rel\u00f3gio de Quartzo Diapaz\u00e3o de cristal cortado a laser. Efeito Piezoel\u00e9trico invertido: corrente el\u00e9trica gera oscil\u00e7\u00e3o Efeito Piezoel\u00e9trico: oscila\u00e7\u00e3o gera impulsos Oscila a $32768 = 2^{15}$Hz Contador conta 1 segundo por overflow Trabalha de 5 a 35 Celcius Tem erro de 1/2 segundo/dia Frequ\u00eancia muda com idade temperatura corrente el\u00e9trica imperfei\u00e7\u00f5es Fonte Embora adequado para humanos, o erro dos rel\u00f3gios de quartzo \u00e9 inaceit\u00e1vel em algumas opera\u00e7\u00f5es computacionais. Felizmente, estes rel\u00f3gios podem ser corrigidos usando outras constantes f\u00edsicas. Rel\u00f3gio At\u00f4mico rel\u00f3gio de quartzo gera 9.192.631.770 impulsos por segundo impulsos mantem cesium-133 excitado se n\u00famero de \u00e1tomos excitados cai, rel\u00f3gio \u00e9 corrigido. drift de 1 segundo em 6.000.000 anos. Uma vez que agora temos um rel\u00f3gio com alt\u00edssima precis\u00e3o, como podemos espalhar esta informa\u00e7\u00e3o para nossos computadores pessoais? A resposta est\u00e1 no UTC, Tempo Universal Coordenado (da sigla em Franc\u00eas). Tempo Coordenado Universal -- UTC (do nome em Franc\u00eas) Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60 seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61 seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2 milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59 seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary. Abrindo um par\u00eantese, o UTC \u00e9 usado como base para os rel\u00f3gios locais, mas fatores pol\u00edticos tamb\u00e9m s\u00e3o importantes. Fuso-hor\u00e1rios Fonte Mas como o UTC \u00e9 definido? Com base no TAI, Tempo At\u00f4mico Internacional, calculado como a m\u00e9dia dos valores de rel\u00f3gios at\u00f4micos espalhados pelo globo. O TAI mede perfeitamente a passagem do tempo, mas como a rota\u00e7\u00e3o da terra \u00e9 irregular, medir perfeitamente n\u00e3o \u00e9 o adequado. Assim, o UTC leva em considera\u00e7\u00e3o o fato do dia n\u00e3o ter exatamente 24 horas e, de fato, n\u00e3o ter dura\u00e7\u00e3o constante. Por exemplo, ap\u00f3s um grande terremoto o centro de massa da terra pode ser alterado e a rota\u00e7\u00e3o ter sua velocidade aumentada ou diminu\u00edda. UTC TAI - Tempo At\u00f4mico Internacional -- m\u00e9dia de +- 200 rel\u00f3gios at\u00f4micos. UT0 - Tempo solar, em Greenwich; observa\u00e7\u00f5es astron\u00f4micas UT1 - UT0 + corre\u00e7\u00f5es por movimento polar (terra se inclinou?) UT2 - UT1 + varia\u00e7\u00f5es sazonais na rota\u00e7\u00e3o (placas tect\u00f4nicas se movimentaram) UTC - Medido como TAI mas aproximado para UT0 para dar percep\u00e7\u00e3o de que \"meio dia \u00e9 meio dia\" Dado o UTC, temos ent\u00e3o uma refer\u00eancia de tempo adequada para uso em sistemas computacionais. Nos resta ainda, propagar a refer\u00eancia do UTC para os sistemas. Vejamos como o tempo \u00e9 mantido em um computador. Rel\u00f3gios nos Computadores Cada computador mant\u00e9m uma vis\u00e3o local do tempo. Rel\u00f3gio de quartzo mede a passagem de tempo. Bateria usada para per\u00edodos de desconex\u00e3o. Interrup\u00e7\u00f5es programadas: Linux >2.6 usa 250Hz por padr\u00e3o; m\u00e1ximo 1000Hz. Interrup\u00e7\u00f5es incrementam contador: 1000Hz, 1 interrup\u00e7\u00e3o a cada 1ms 500Hz, 1 interrup\u00e7\u00e3o a cada 2ms Contador usado como base para rel\u00f3gio em software $C$. Este rel\u00f3gio em software, $C$, que usa um rel\u00f3gio de quartzo, impreciso, pode marcar a passagem do tempo com erro para mais ou para menos. Embora o erro exato do rel\u00f3gio seja desconhecido, o mesmo pode ser limitado. Sincroniza\u00e7\u00e3o C - clock t - tempo, ou melhor aproxima\u00e7\u00e3o, UTC $\\rho$ - Clock-drift/Drift rate $1 - \\rho \\leq \\frac{dC}{dt} \\leq 1 + \\rho$. Logo, dado um mecanismo de sincroniza\u00e7\u00e3o com UTC ou outra fonte confi\u00e1vel, podemos limitar a dessincroniza\u00e7\u00e3o com UTC. Frequencia de Sincroniza\u00e7\u00e3o Como garantir que dois rel\u00f3gios do sistema n\u00e3o diferir\u00e3o em mais que $\\delta$ unidades de tempo? Sincronize pelo menos a cada $\\frac{\\delta}{2\\rho}$ segundos. Vejamos um exemplo: $\\rho = 0,1$ $\\delta$ = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Como cada n\u00f3 poderia estar errando em \"dire\u00e7\u00f5es\" diferentes, ap\u00f3s 5s, um n\u00f3 poderia se adiantar em 0,5s enquanto o outro se atrasa pela mesma quantidade de tempo, somando 1s de diferen\u00e7a. Logo, eles tem que se sincronizar a cada 5s, i.e, $\\frac{\\delta}{2\\rho} = \\frac{1s}{2 \\times 0,1} = \\frac{1s}{0,2} = 5s$ Mas n\u00e3o se pode apenas ajustar o rel\u00f3gio para corrigir atrasos e adiantamentos. \u00c9 preciso tomar certos cuidados para se garantir o funcionamento correto do sistema. Cuidados Nunca voltar no tempo Corre\u00e7\u00e3o gradual: acelere ou desacelere o rel\u00f3gio (em software) Diminua/Aumente frequ\u00eancia de interrup\u00e7\u00e3o para atrasar/adiantar rel\u00f3gio Diminua/Aumente incremento com cada interrup\u00e7\u00e3o Ajustes peri\u00f3dicos para fazer curvas convergirem. Corre\u00e7\u00e3o ap\u00f3s dormir ser\u00e1 mais dr\u00e1stica At\u00e9 agora definimos que rel\u00f3gios podem ser sincronizados com UTC, pois \u00e9 uma boa aproxima\u00e7\u00e3o do tempo percebido por nossos sentidos, e a frequ\u00eancia com que a sincroniza\u00e7\u00e3o deve acontecer. Contudo, falta ainda definir o protocolo pelo qual a sincroniza\u00e7\u00e3o \u00e9 feita e exatamente com quem, uma vez que simpleste UTC \u00e9 muito gen\u00e9rico. Comecemos com \"quem\". Em um extremo, sincronize com rel\u00f3gios at\u00f4micos em sat\u00e9lites GPS Sincronizar com quem? GPS Coloque um receptor GPS em cada n\u00f3. Tenha erro de 0,1ns a 1ms do UTC. Receptores GPS, com seus rel\u00f3gios sincronizados com os dos sat\u00e9lites, que difundem regularmente sua posi\u00e7\u00e3o e o instante em que a difus\u00e3o \u00e9 feita, determinam sua posi\u00e7\u00e3o relativa aos sat\u00e9lites, em uma t\u00e9cnica conhecida como trilatera\u00e7\u00e3o. Baseado na informa\u00e7\u00e3o de um sat\u00e9lite, o receptor determina sua dist\u00e2ncia ao mesmo e, portanto, determina que est\u00e1 em uma esfera no entorno do sat\u00e9lite. Combinando a informa\u00e7\u00e3o de 2 sat\u00e9lites, a posi\u00e7\u00e3o do receptor \u00e9 limitada a uma circunfer\u00eancia, isto \u00e9, a interse\u00e7\u00e3o de duas esferas. Com um terceiro sat\u00e9lite, a posi\u00e7\u00e3o \u00e9 reduzida a dois pontos, a interse\u00e7\u00e3o de uma esfera e uma circunfer\u00eancia, sendo um no espa\u00e7o e que pode ser facilmente descartado. Trilatera\u00e7\u00e3o Como dito, a trilatera\u00e7\u00e3o consiste em determinar a dist\u00e2ncia do receptor em termos dos eixos $x$, $y$ e $z$ em rela\u00e7\u00e3o a cada um dos sat\u00e9lites. Contudo, para que funcione, rel\u00f3gios precisam estar sincronizados, o que \u00e9 exatamente o problema que estamos tentando resolver. Para contornar esta restri\u00e7\u00e3o, usa-se um quarto sat\u00e9lite, para determinar a dist\u00e2ncia no \"eixo temporal\". Apesar da queda dos pre\u00e7os dos receptores, colocar um GPS em cada dispositivo pode ser custoso demais. Em vez disso, podemos usar um recurso amplamente dispon\u00edvel, redes de computadores, e sincronizar com outra m\u00e1quina, que fez o investimento necess\u00e1rio para manter o erro baixo. Sincronizar com quem? Outra m\u00e1quina Pergunte que horas s\u00e3o. Use a resposta para ajudar o rel\u00f3gio local. Considere o erro introduzido pela lat\u00eancia vari\u00e1vel da rede. Algoritmo de Cristian Assumindo que o rel\u00f3gio da m\u00e1quina se sincronizando, $M_1$, \u00e9 bom o suficiente para medir a passagem de tempo em per\u00edodos curtos, mesmo que tenha uma drift rate consider\u00e1vem em per\u00edodos mais longos, execute o seguinte protocolo para se sincronizar com $M_2$. Algoritmo de Cristian $M_1$ rergunta \"que horas s\u00e3o?\" - $t_0$ $M_2$ recebe pergunta - $t_1$ $M_2$ anota o valor do rel\u00f3gio - $t_s$ $M_2$ envia resposta - $t_2$ $M_1$ recebe resposta - $t_3$ Assuma $t_1 = t_s = t_2$ Assuma $\\frac{t_3-t_0}{2}$ como o tempo de transmiss\u00e3o da resposta (m\u00e9dia da ida e da volta) $M_1$ ajusta rel\u00f3gio para $t_c = t_s + \\frac{t_3-t_0}{2}$ Mas e a aproxima\u00e7\u00e3o $\\frac{t_3-t_0}{2}$, \u00e9 boa? Podemos estimar o erro que ela introduz na sincroniza\u00e7\u00e3o, caso as mensagens tenham tempos de ida e volta assim\u00e9tricos. Apesar das diferen\u00e7as no tempo de ida e volta, existe um tempo m\u00ednimo para o tr\u00e1fego em cada um dos sentidos, $T_{min}$. Erro m\u00e1ximo? Tempo m\u00ednimo de transmiss\u00e3o: $T_{min}$ Fonte H\u00e1 dois casos extremos de erro na estimativa. No primeiro caso, dado um tempo de ida + volta igual a $T_1 - T_0$, na figura, a mensagem de ida trafega no tempo m\u00ednimo e a volta lentamente. Neste caso, a estimativa $\\frac{t_3-t_0}{2}$ \u00e9 menor que o tempo de volta real. No segundo caso, a mensagem de ida trafega lentamente e a de volta no tempo m\u00ednimo, levando $\\frac{t_3-t_0}{2}$ a ser maior que tempo de transmiss\u00e3o real da mensagem. O erro, contudo, est\u00e1 limitado \u00e0 faixa amarela no desenho, que tem dura\u00e7\u00e3o $T_1 - T_0 - 2T_{min}$. O erro ent\u00e3o varia de mais ou menos metade deste valor. Algoritmo de Berkeley Enquanto o algoritmo de Cristian permite sincronizar um n\u00f3 com uma fonte, outro algoritmo, de Berkeley, permite sincronizar m\u00faltiplos n\u00f3s uns com os outros. Este algoritmo funciona assim: Algoritmo de Berkeley Premissas N\u00e3o h\u00e1 fonte da verdade Sintoniza\u00e7\u00e3o em vez de sincroniza\u00e7\u00e3o (sincroniza\u00e7\u00e3o interna x externa) Todos convergem para m\u00e9dia Todos executam ``time d\\ae mon'' Mestre e escravos Algoritmo Mestre requisita rel\u00f3gio de cada escravo Rel\u00f3gios ajustados com algoritmo de Cristian Computa m\u00e9dia Envia ajuste para cada escravo Importante Ignora \\emph{outliers} Mestre pode ser substitu\u00eddo facilmente Embora interessantes, estes algoritmos n\u00e3o s\u00e3o normalmente usados, pelo menos n\u00e3o em sua forma \"pura\", em sistemas computacionais. Em vez deles, usamos o Network Time Protocol (NTP). Network Time Protocol 1991/1992: RFC 1305 2010: RFC 5905-5908 -- IPv6, 10s ms de acur\u00e1cia Uso na Internet Sincroniza\u00e7\u00e3o com UTC Estat\u00edstica permite minimizar erros Tolerante a falhas: caminhos redundantes; servidores redundantes Escal\u00e1vel: modelo hier\u00e1rquico Seguro: usa autentica\u00e7\u00e3o Os diversos componentes do NTP s\u00e3o organizados em camadas, ou estrata, de forma que a informa\u00e7\u00e3o do tempo flui da camada 0 (stratum 0) at\u00e9 a camada 15 (stratum 15). Os componentes n\u00e3o est\u00e3o presos a camadas, que podem ser alteradas a medida que falhas acontecem e s\u00e3o dedicadas, e novos caminhos s\u00e3o encontrados usando-se um algoritmo de \u00e1rvore geradora m\u00ednima. Network Time Protocol Fonte: Benjamin D. Esham, (bdesham) - Based upon Ntp.png by Kim Meyrick Stratum 0: rel\u00f3gios at\u00f4micos/receptores GPS Stratum 1: ms to stratum 0 Stratum 2: contata m\u00faltiplos stratum 1 e pares Strata 3...15 Stratum 16: dessincronizado Bellman-Ford: \u00e1rvore geradora m\u00ednima para stratum 1 O s\u00edtio do Comit\u00ea Gestor da Internet, CGI, tem uma entrada muito boa sobre o NTP, NTP.br . De forma resumida, o NTP trabalha em diferentes modos, que permitem aos n\u00f3s receberem informa\u00e7\u00f5es de fontes de tempo das camadas superiores ou de pares, filtrar estas informa\u00e7\u00f5es para escolher as mais confi\u00e1veis, e ajustar o rel\u00f3gio local de acordo com a filtragem. Modos de trabalho do NTP Modo multicast: propaga tempo em rede local RPC: algoritmo de Cristian Sim\u00e9trico: parecido com Berkeley Na pr\u00e1tica, boa parte dos dispositivos usa uma vers\u00e3o simplificada do NTP, adequada aos n\u00f3s nas folhas da hierarquia. O SNTP \u00e9 essencialmente o algoritmo de Cristian. Simple NTP Vers\u00e3o simplificada do NTP Recomendado para folhas da \u00e1rvore $\\delta = (t_4-t_1)-(t_2-t_3)$ $t = \\frac{(t_2-t_1)+(t3-t_4)}{2}$ $t_c = t_4+t$ Veja um exemplo do ajuste de um rel\u00f3gio usando SNTP. Exemplo do SNTP $t_1 = 1100, t_2 = 800, t_3=850, t_4=1200$ $t = ((800-1100)+(850-1200))/2 = (-300 -350)/ = -325$ $t_c = 1200-325 = 875$ Mais recentemente foi proposta um novo protocolo de sincroniza\u00e7\u00e3o de rel\u00f3gios com melhor qualidade de serv\u00e7o, Precision Time Protocol, PTP. PTP - Precision Time Protocol IEEE 1588 LAN sub $\\mu s$ (versus ordem de $ms$ no NTP) Escolha mestre Administrador Classe do rel\u00f3gio Acur\u00e1cia do rel\u00f3gio Vari\u00e2ncia do rel\u00f3gio Identificador Como algoritmo de Cristian, mas quem ajusta n\u00e3o \u00e9 quem inicia. Assumindo que tenhamos sincronizado os rel\u00f3gios de um sistema computacional, o que podemos fazer agora? H\u00e1 uma s\u00e9rie de problemas interessantes que podem ser resolvidos. Usos de rel\u00f3gios sincronizados autentica\u00e7\u00e3o termina\u00e7\u00e3o de transa\u00e7\u00f5es aloca\u00e7\u00e3o de ``leases''. outros exemplos, Liskov, B. Distrib Comput (1993) 6: 211. doi:10.1007/BF02242709 Um exemplo interessante \u00e9 a ordena\u00e7\u00e3o de eventos em um banco de dados. Para entender este problema, considere o seguinte cen\u00e1rio. Sistema Banc\u00e1rio Se os comandos chegam primeiro para a replica mais pr\u00f3xima e s\u00e3o executados na ordem em que chegam, temos inconsist\u00eancias entre as r\u00e9plicas (p.e., assuma que update 1 \u00e9 \"atualize para 10\" e 2 \u00e9 \"atualize para 20\") Assim, precisamos ordenar os comandos! Nos foquemos em apenas uma r\u00e9plica. Assuma que rel\u00f3gios est\u00e3o perfeitamente sincronizados, que o tempo de propaga\u00e7\u00e3o m\u00e1ximo de uma mensagem \u00e9 $\\tau$, e que toda mensagem/update carrega o timestamp de quando foi enviada consigo. Considere o seguinte proposta: R\u00e9plicas processam mensagens na ordem que foram enviadas, o que pode ser identificado pelos seus timestamps. Em outras palavras, ao receber uma mensagem com timestamp $t$, uma r\u00e9plica espera at\u00e9 ter certeza de que Ordena\u00e7\u00e3o de Requisi\u00e7\u00f5es Rel\u00f3gios perfeitamente sincronizados $\\tau$. Cliente 1 envia mensagem Update1 no instante $t$. Ao receber Update1 com timestamp $t$, a r\u00e9plica deve esperar para executar o update? O \u00faltimo instante em que qualquer mensagem com timestamp $t' < t$ pode ser recebido pela r\u00e9plica \u00e9 $t+\\tau$, pois qualquer mensagem recebida em $t''> t+\\tau'$, precisa ter sido enviada ap\u00f3s $t$, e portanto ter\u00e1 timestamp $> t$. Implementar este protocolo \u00e9 muito simples: Toda mensagem recebida \u00e9 colocada em uma fila ordenada por timestamp . Quando o rel\u00f3gio marcar um tempo maior que $t + \\tau$, onde $t$ \u00e9 o timestamp da mensagem na cabe\u00e7a da fila, execute tal mensagem e a retire da fila. Entretanto, este protocolo n\u00e3o leva em considera\u00e7\u00e3o a dessincroniza\u00e7\u00e3o inerente dos rel\u00f3gios em um sistema distribu\u00eddo. Como faz\u00ea-lo, supondo uma diverg\u00eancia m\u00e1xima de $\\Delta$ entre quaisquer dois rel\u00f3gios, algo que pode ser arranjado, como visto antes, sincronizando-se os rel\u00f3gios a cada $\\frac{\\Delta}{2*\\rho}$. Se $\\Delta$ \u00e9 a diferen\u00e7a m\u00e1xima entre rel\u00f3gios, ent\u00e3o ap\u00f3s o uma mensagem ser enviada com timestamp $t$, at\u00e9 $\\Delta$ depois, outro processo, atrasado em rela\u00e7\u00e3o ao primeiro, poder\u00e1 enviar uma mensagem com timestamp $t' < t$. Tal mensagem pode demorar at\u00e9 $\\tau$ para ser entregue \u00e0 r\u00e9plica, ou seja, no instante $t + \\tau + \\Delta$, do ponto de vista do primeiro cliente. Se a r\u00e9plica estiver sincronizada com cliente, ent\u00e3o se esperar at\u00e9 $t + \\tau + \\Delta$ para executar o comando, o far\u00e1 de forma segura. Se estiver atrasada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o acabar\u00e1 por esperar al\u00e9m do necess\u00e1rio, mas sem violar a corretude do sistema. Finalmente, se a r\u00e9plica estiver adiantada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o seu rel\u00f3gio alcan\u00e7ar\u00e1 $t + \\tau + \\Delta$ antes do rel\u00f3gio do primeiro cliente, mas isso n\u00e3o \u00e9 um problema. Isto porqu\u00ea, o \u00faltimo instante em que o cliente 2 poder\u00e1 enviar uma mensagem com timestamp $t' < t$ \u00e9 o instante em que o rel\u00f3gio da r\u00e9plica marcar $t + \\Delta$, e portanto dever\u00e1 tamb\u00e9m ser recebido at\u00e9 que o mesmo rel\u00f3gio marque $t + \\tau + \\Delta$. Ordena\u00e7\u00e3o de Requisi\u00e7\u00f5es Rel\u00f3gios dessincronizados $\\tau$. $\\Delta$ O \u00faltimo instante em que qualquer mensagem com timestamp $t' < t$ pode ser recebido pela r\u00e9plica \u00e9 $t+\\tau + \\Delta$, pois qualquer mensagem recebida em $t''> t+\\tau + \\Delta'$, precisa ter sido enviada ap\u00f3s $t+\\Delta$, e portanto ter\u00e1 timestamp $> t$. O mesmo racioc\u00ednio pode ser usado para definir um protocolo de acesso recursos para os quais leases s\u00e3o distribu\u00eddos, onde um lease \u00e9 uma permiss\u00e3o de acesso durante uma janela de tempo, emitida por um coordenador (possivelmente eleito usando os algoritmos vistos anteriormente), e $\\Delta$ \u00e9 o m\u00e1ximo de dessincronismo entre os rel\u00f3gios. O seguinte protocolo resolve este problema: Lease $\\Delta$ - dessincroniza\u00e7\u00e3o m\u00e1xima. Ao receber um lease para a janela de tempo $t_1$ a $t_2$ espera at\u00e9 $t_1 + \\Delta$ usa o recurso at\u00e9 $t_2$. Se rel\u00f3gio estiver adiantado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 $t_1+\\Delta$ enquanto o anterior acha que \u00e9 $t_1$; exclus\u00e3o m\u00fatua garantida. Se rel\u00f3gio estiver atrasado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 $t_1 - \\Delta$, e continua esperando, enquanto ele acha que j\u00e1 \u00e9 $t_1$ e para de usar; exclus\u00e3o m\u00fatua garantida. Recurso fica ocioso por $\\Delta$, em m\u00e9dia, a cada lease. Devido ao alto custo de se manter o recurso n\u00e3o utilizado, $\\Delta$ deve ser feito t\u00e3o pequeno quanto poss\u00edvel. Leia Google True Time e Spanner para como o Google consegue manter a diferen\u00e7a em sub milisegundos, usando rel\u00f3gios at\u00f4micos dentro de seus datacenters e um API para gera\u00e7\u00e3o de timestamps.","title":"Tempo F\u00edsico"},{"location":"tempo/1_fisico/#tempo","text":"Se um mesmo arquivo no Dropbox \u00e9 modificado em duas m\u00e1quinas diferentes, enquanto as mesmas est\u00e3o desconectadas, o qu\u00ea acontece quando elas se reconectam?","title":"Tempo"},{"location":"tempo/1_fisico/#problema","text":"Se dois arquivos com o mesmo nome s\u00e3o enviadas ao servidor, qual deve ser mantido? Uma possibilidade \u00e9 aceitar o arquivo que chega primeiro e rejeitar o que chega depois. Mas imagine que seu servi\u00e7o esteja interessado em registrar a anterioridade de ideias anotadas nos arquivos. Neste caso, o sistema poderia dar anterioridade ao arquivo errado, isto \u00e9, o mais recentemente criado. Outra abordagem, \u00e9 manter janelas de aceite de arquivos, e dentro destas janelas, manter os arquivos com hor\u00e1rio de cria\u00e7\u00e3o menor. Neste caso, um trapaceiro poderia modificar seu rel\u00f3gico para fazer seu arquivo passar na frente. Uma terceira abordagem \u00e9 gerar uma terceira vers\u00e3o, com a \"soma\" das duas conflitantes. Para gerar esta terceira vers\u00e3o, faz mais sentido quebrar os arquivos em opera\u00e7\u00f5es de modifica\u00e7\u00e3o , e executar as opera\u00e7\u00f5es de forma a chegar ao resultado final. O problema permanece, pois as opera\u00e7\u00f5es agora devem ser ordenadas. Em qualquer destas linhas de atua\u00e7\u00e3o, voc\u00ea tem em m\u00e3os um conflito para resolver, e autmatizar a resolu\u00e7\u00e3o do mesmo \u00e9 muito complicado. \u00c9 por isso que o Dropbox deixa os dois arquivos para que o usu\u00e1rio analize e decida o que fazer, que servidores git permitem a submiss\u00e3o de apenas um conjunto de opera\u00e7\u00f5es por vez para um mesmo reposit\u00f3rio, e o Perforce trabalhe com locks de arquivos. De forma mais gen\u00e9rica,","title":"Problema"},{"location":"tempo/1_fisico/#problema_1","text":"Se duas opera\u00e7\u00f5es originadas em clientes s\u00e3o enviadas ao servidor, qual deve ser executada primeiro? Alguns sistemas, contudo, tentam resolver automaticamente os conflitos. No caso do CassandraDB, usa-se","title":"Problema"},{"location":"tempo/1_fisico/#cassandradb","text":"\"last write wins\" ou \"latest version wins\" Onde last \u00e9 definido pelo rel\u00f3gio do cliente. Acontece que a maior parte dos nossos sistemas n\u00e3o d\u00e1 garantias de tempo na entrega de mensagens ou processamento de instru\u00e7\u00f5es. Assim, temos novo problema:","title":"CassandraDB"},{"location":"tempo/1_fisico/#problema_2","text":"Como determinar qual foi enviada primeiro, em um sistema ass\u00edncrono? Assim, precisamos encontrar uma fonte de tempo confi\u00e1vel e distribu\u00edda . O desafio come\u00e7a com o entendimento de rel\u00f3gios f\u00edsicos.","title":"Problema"},{"location":"tempo/1_fisico/#relogios-fisicos","text":"","title":"Rel\u00f3gios F\u00edsicos"},{"location":"tempo/1_fisico/#relogio-de-quartzo","text":"Diapaz\u00e3o de cristal cortado a laser. Efeito Piezoel\u00e9trico invertido: corrente el\u00e9trica gera oscil\u00e7\u00e3o Efeito Piezoel\u00e9trico: oscila\u00e7\u00e3o gera impulsos Oscila a $32768 = 2^{15}$Hz Contador conta 1 segundo por overflow Trabalha de 5 a 35 Celcius Tem erro de 1/2 segundo/dia Frequ\u00eancia muda com idade temperatura corrente el\u00e9trica imperfei\u00e7\u00f5es Fonte Embora adequado para humanos, o erro dos rel\u00f3gios de quartzo \u00e9 inaceit\u00e1vel em algumas opera\u00e7\u00f5es computacionais. Felizmente, estes rel\u00f3gios podem ser corrigidos usando outras constantes f\u00edsicas.","title":"Rel\u00f3gio de Quartzo"},{"location":"tempo/1_fisico/#relogio-atomico","text":"rel\u00f3gio de quartzo gera 9.192.631.770 impulsos por segundo impulsos mantem cesium-133 excitado se n\u00famero de \u00e1tomos excitados cai, rel\u00f3gio \u00e9 corrigido. drift de 1 segundo em 6.000.000 anos. Uma vez que agora temos um rel\u00f3gio com alt\u00edssima precis\u00e3o, como podemos espalhar esta informa\u00e7\u00e3o para nossos computadores pessoais? A resposta est\u00e1 no UTC, Tempo Universal Coordenado (da sigla em Franc\u00eas).","title":"Rel\u00f3gio At\u00f4mico"},{"location":"tempo/1_fisico/#tempo-coordenado-universal-utc-do-nome-em-frances","text":"Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60 seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61 seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2 milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59 seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary. Abrindo um par\u00eantese, o UTC \u00e9 usado como base para os rel\u00f3gios locais, mas fatores pol\u00edticos tamb\u00e9m s\u00e3o importantes.","title":"Tempo Coordenado Universal -- UTC (do nome em Franc\u00eas)"},{"location":"tempo/1_fisico/#fuso-horarios","text":"Fonte Mas como o UTC \u00e9 definido? Com base no TAI, Tempo At\u00f4mico Internacional, calculado como a m\u00e9dia dos valores de rel\u00f3gios at\u00f4micos espalhados pelo globo. O TAI mede perfeitamente a passagem do tempo, mas como a rota\u00e7\u00e3o da terra \u00e9 irregular, medir perfeitamente n\u00e3o \u00e9 o adequado. Assim, o UTC leva em considera\u00e7\u00e3o o fato do dia n\u00e3o ter exatamente 24 horas e, de fato, n\u00e3o ter dura\u00e7\u00e3o constante. Por exemplo, ap\u00f3s um grande terremoto o centro de massa da terra pode ser alterado e a rota\u00e7\u00e3o ter sua velocidade aumentada ou diminu\u00edda.","title":"Fuso-hor\u00e1rios"},{"location":"tempo/1_fisico/#utc","text":"TAI - Tempo At\u00f4mico Internacional -- m\u00e9dia de +- 200 rel\u00f3gios at\u00f4micos. UT0 - Tempo solar, em Greenwich; observa\u00e7\u00f5es astron\u00f4micas UT1 - UT0 + corre\u00e7\u00f5es por movimento polar (terra se inclinou?) UT2 - UT1 + varia\u00e7\u00f5es sazonais na rota\u00e7\u00e3o (placas tect\u00f4nicas se movimentaram) UTC - Medido como TAI mas aproximado para UT0 para dar percep\u00e7\u00e3o de que \"meio dia \u00e9 meio dia\" Dado o UTC, temos ent\u00e3o uma refer\u00eancia de tempo adequada para uso em sistemas computacionais. Nos resta ainda, propagar a refer\u00eancia do UTC para os sistemas. Vejamos como o tempo \u00e9 mantido em um computador.","title":"UTC"},{"location":"tempo/1_fisico/#relogios-nos-computadores","text":"Cada computador mant\u00e9m uma vis\u00e3o local do tempo. Rel\u00f3gio de quartzo mede a passagem de tempo. Bateria usada para per\u00edodos de desconex\u00e3o. Interrup\u00e7\u00f5es programadas: Linux >2.6 usa 250Hz por padr\u00e3o; m\u00e1ximo 1000Hz. Interrup\u00e7\u00f5es incrementam contador: 1000Hz, 1 interrup\u00e7\u00e3o a cada 1ms 500Hz, 1 interrup\u00e7\u00e3o a cada 2ms Contador usado como base para rel\u00f3gio em software $C$. Este rel\u00f3gio em software, $C$, que usa um rel\u00f3gio de quartzo, impreciso, pode marcar a passagem do tempo com erro para mais ou para menos. Embora o erro exato do rel\u00f3gio seja desconhecido, o mesmo pode ser limitado.","title":"Rel\u00f3gios nos Computadores"},{"location":"tempo/1_fisico/#sincronizacao","text":"C - clock t - tempo, ou melhor aproxima\u00e7\u00e3o, UTC $\\rho$ - Clock-drift/Drift rate $1 - \\rho \\leq \\frac{dC}{dt} \\leq 1 + \\rho$. Logo, dado um mecanismo de sincroniza\u00e7\u00e3o com UTC ou outra fonte confi\u00e1vel, podemos limitar a dessincroniza\u00e7\u00e3o com UTC.","title":"Sincroniza\u00e7\u00e3o"},{"location":"tempo/1_fisico/#frequencia-de-sincronizacao","text":"Como garantir que dois rel\u00f3gios do sistema n\u00e3o diferir\u00e3o em mais que $\\delta$ unidades de tempo? Sincronize pelo menos a cada $\\frac{\\delta}{2\\rho}$ segundos. Vejamos um exemplo: $\\rho = 0,1$ $\\delta$ = 1s Ap\u00f3s 10s, um n\u00f3 com estas caracter\u00edsticas se dessincronizaria em, no m\u00e1ximo, 1s em rela\u00e7\u00e3o ao UTC. Como cada n\u00f3 poderia estar errando em \"dire\u00e7\u00f5es\" diferentes, ap\u00f3s 5s, um n\u00f3 poderia se adiantar em 0,5s enquanto o outro se atrasa pela mesma quantidade de tempo, somando 1s de diferen\u00e7a. Logo, eles tem que se sincronizar a cada 5s, i.e, $\\frac{\\delta}{2\\rho} = \\frac{1s}{2 \\times 0,1} = \\frac{1s}{0,2} = 5s$ Mas n\u00e3o se pode apenas ajustar o rel\u00f3gio para corrigir atrasos e adiantamentos. \u00c9 preciso tomar certos cuidados para se garantir o funcionamento correto do sistema.","title":"Frequencia de Sincroniza\u00e7\u00e3o"},{"location":"tempo/1_fisico/#cuidados","text":"Nunca voltar no tempo Corre\u00e7\u00e3o gradual: acelere ou desacelere o rel\u00f3gio (em software) Diminua/Aumente frequ\u00eancia de interrup\u00e7\u00e3o para atrasar/adiantar rel\u00f3gio Diminua/Aumente incremento com cada interrup\u00e7\u00e3o Ajustes peri\u00f3dicos para fazer curvas convergirem. Corre\u00e7\u00e3o ap\u00f3s dormir ser\u00e1 mais dr\u00e1stica At\u00e9 agora definimos que rel\u00f3gios podem ser sincronizados com UTC, pois \u00e9 uma boa aproxima\u00e7\u00e3o do tempo percebido por nossos sentidos, e a frequ\u00eancia com que a sincroniza\u00e7\u00e3o deve acontecer. Contudo, falta ainda definir o protocolo pelo qual a sincroniza\u00e7\u00e3o \u00e9 feita e exatamente com quem, uma vez que simpleste UTC \u00e9 muito gen\u00e9rico. Comecemos com \"quem\". Em um extremo, sincronize com rel\u00f3gios at\u00f4micos em sat\u00e9lites GPS","title":"Cuidados"},{"location":"tempo/1_fisico/#sincronizar-com-quem-gps","text":"Coloque um receptor GPS em cada n\u00f3. Tenha erro de 0,1ns a 1ms do UTC. Receptores GPS, com seus rel\u00f3gios sincronizados com os dos sat\u00e9lites, que difundem regularmente sua posi\u00e7\u00e3o e o instante em que a difus\u00e3o \u00e9 feita, determinam sua posi\u00e7\u00e3o relativa aos sat\u00e9lites, em uma t\u00e9cnica conhecida como trilatera\u00e7\u00e3o. Baseado na informa\u00e7\u00e3o de um sat\u00e9lite, o receptor determina sua dist\u00e2ncia ao mesmo e, portanto, determina que est\u00e1 em uma esfera no entorno do sat\u00e9lite. Combinando a informa\u00e7\u00e3o de 2 sat\u00e9lites, a posi\u00e7\u00e3o do receptor \u00e9 limitada a uma circunfer\u00eancia, isto \u00e9, a interse\u00e7\u00e3o de duas esferas. Com um terceiro sat\u00e9lite, a posi\u00e7\u00e3o \u00e9 reduzida a dois pontos, a interse\u00e7\u00e3o de uma esfera e uma circunfer\u00eancia, sendo um no espa\u00e7o e que pode ser facilmente descartado.","title":"Sincronizar com quem? GPS"},{"location":"tempo/1_fisico/#trilateracao","text":"Como dito, a trilatera\u00e7\u00e3o consiste em determinar a dist\u00e2ncia do receptor em termos dos eixos $x$, $y$ e $z$ em rela\u00e7\u00e3o a cada um dos sat\u00e9lites. Contudo, para que funcione, rel\u00f3gios precisam estar sincronizados, o que \u00e9 exatamente o problema que estamos tentando resolver. Para contornar esta restri\u00e7\u00e3o, usa-se um quarto sat\u00e9lite, para determinar a dist\u00e2ncia no \"eixo temporal\". Apesar da queda dos pre\u00e7os dos receptores, colocar um GPS em cada dispositivo pode ser custoso demais. Em vez disso, podemos usar um recurso amplamente dispon\u00edvel, redes de computadores, e sincronizar com outra m\u00e1quina, que fez o investimento necess\u00e1rio para manter o erro baixo.","title":"Trilatera\u00e7\u00e3o"},{"location":"tempo/1_fisico/#sincronizar-com-quem-outra-maquina","text":"Pergunte que horas s\u00e3o. Use a resposta para ajudar o rel\u00f3gio local. Considere o erro introduzido pela lat\u00eancia vari\u00e1vel da rede.","title":"Sincronizar com quem? Outra m\u00e1quina"},{"location":"tempo/1_fisico/#algoritmo-de-cristian","text":"Assumindo que o rel\u00f3gio da m\u00e1quina se sincronizando, $M_1$, \u00e9 bom o suficiente para medir a passagem de tempo em per\u00edodos curtos, mesmo que tenha uma drift rate consider\u00e1vem em per\u00edodos mais longos, execute o seguinte protocolo para se sincronizar com $M_2$.","title":"Algoritmo de Cristian"},{"location":"tempo/1_fisico/#algoritmo-de-cristian_1","text":"$M_1$ rergunta \"que horas s\u00e3o?\" - $t_0$ $M_2$ recebe pergunta - $t_1$ $M_2$ anota o valor do rel\u00f3gio - $t_s$ $M_2$ envia resposta - $t_2$ $M_1$ recebe resposta - $t_3$ Assuma $t_1 = t_s = t_2$ Assuma $\\frac{t_3-t_0}{2}$ como o tempo de transmiss\u00e3o da resposta (m\u00e9dia da ida e da volta) $M_1$ ajusta rel\u00f3gio para $t_c = t_s + \\frac{t_3-t_0}{2}$ Mas e a aproxima\u00e7\u00e3o $\\frac{t_3-t_0}{2}$, \u00e9 boa? Podemos estimar o erro que ela introduz na sincroniza\u00e7\u00e3o, caso as mensagens tenham tempos de ida e volta assim\u00e9tricos. Apesar das diferen\u00e7as no tempo de ida e volta, existe um tempo m\u00ednimo para o tr\u00e1fego em cada um dos sentidos, $T_{min}$.","title":"Algoritmo de Cristian"},{"location":"tempo/1_fisico/#erro-maximo","text":"Tempo m\u00ednimo de transmiss\u00e3o: $T_{min}$ Fonte H\u00e1 dois casos extremos de erro na estimativa. No primeiro caso, dado um tempo de ida + volta igual a $T_1 - T_0$, na figura, a mensagem de ida trafega no tempo m\u00ednimo e a volta lentamente. Neste caso, a estimativa $\\frac{t_3-t_0}{2}$ \u00e9 menor que o tempo de volta real. No segundo caso, a mensagem de ida trafega lentamente e a de volta no tempo m\u00ednimo, levando $\\frac{t_3-t_0}{2}$ a ser maior que tempo de transmiss\u00e3o real da mensagem. O erro, contudo, est\u00e1 limitado \u00e0 faixa amarela no desenho, que tem dura\u00e7\u00e3o $T_1 - T_0 - 2T_{min}$. O erro ent\u00e3o varia de mais ou menos metade deste valor.","title":"Erro m\u00e1ximo?"},{"location":"tempo/1_fisico/#algoritmo-de-berkeley","text":"Enquanto o algoritmo de Cristian permite sincronizar um n\u00f3 com uma fonte, outro algoritmo, de Berkeley, permite sincronizar m\u00faltiplos n\u00f3s uns com os outros. Este algoritmo funciona assim:","title":"Algoritmo de Berkeley"},{"location":"tempo/1_fisico/#algoritmo-de-berkeley_1","text":"Premissas N\u00e3o h\u00e1 fonte da verdade Sintoniza\u00e7\u00e3o em vez de sincroniza\u00e7\u00e3o (sincroniza\u00e7\u00e3o interna x externa) Todos convergem para m\u00e9dia Todos executam ``time d\\ae mon'' Mestre e escravos Algoritmo Mestre requisita rel\u00f3gio de cada escravo Rel\u00f3gios ajustados com algoritmo de Cristian Computa m\u00e9dia Envia ajuste para cada escravo Importante Ignora \\emph{outliers} Mestre pode ser substitu\u00eddo facilmente Embora interessantes, estes algoritmos n\u00e3o s\u00e3o normalmente usados, pelo menos n\u00e3o em sua forma \"pura\", em sistemas computacionais. Em vez deles, usamos o Network Time Protocol (NTP).","title":"Algoritmo de Berkeley"},{"location":"tempo/1_fisico/#network-time-protocol","text":"1991/1992: RFC 1305 2010: RFC 5905-5908 -- IPv6, 10s ms de acur\u00e1cia Uso na Internet Sincroniza\u00e7\u00e3o com UTC Estat\u00edstica permite minimizar erros Tolerante a falhas: caminhos redundantes; servidores redundantes Escal\u00e1vel: modelo hier\u00e1rquico Seguro: usa autentica\u00e7\u00e3o Os diversos componentes do NTP s\u00e3o organizados em camadas, ou estrata, de forma que a informa\u00e7\u00e3o do tempo flui da camada 0 (stratum 0) at\u00e9 a camada 15 (stratum 15). Os componentes n\u00e3o est\u00e3o presos a camadas, que podem ser alteradas a medida que falhas acontecem e s\u00e3o dedicadas, e novos caminhos s\u00e3o encontrados usando-se um algoritmo de \u00e1rvore geradora m\u00ednima.","title":"Network Time Protocol"},{"location":"tempo/1_fisico/#network-time-protocol_1","text":"Fonte: Benjamin D. Esham, (bdesham) - Based upon Ntp.png by Kim Meyrick Stratum 0: rel\u00f3gios at\u00f4micos/receptores GPS Stratum 1: ms to stratum 0 Stratum 2: contata m\u00faltiplos stratum 1 e pares Strata 3...15 Stratum 16: dessincronizado Bellman-Ford: \u00e1rvore geradora m\u00ednima para stratum 1 O s\u00edtio do Comit\u00ea Gestor da Internet, CGI, tem uma entrada muito boa sobre o NTP, NTP.br . De forma resumida, o NTP trabalha em diferentes modos, que permitem aos n\u00f3s receberem informa\u00e7\u00f5es de fontes de tempo das camadas superiores ou de pares, filtrar estas informa\u00e7\u00f5es para escolher as mais confi\u00e1veis, e ajustar o rel\u00f3gio local de acordo com a filtragem.","title":"Network Time Protocol"},{"location":"tempo/1_fisico/#modos-de-trabalho-do-ntp","text":"Modo multicast: propaga tempo em rede local RPC: algoritmo de Cristian Sim\u00e9trico: parecido com Berkeley Na pr\u00e1tica, boa parte dos dispositivos usa uma vers\u00e3o simplificada do NTP, adequada aos n\u00f3s nas folhas da hierarquia. O SNTP \u00e9 essencialmente o algoritmo de Cristian.","title":"Modos de trabalho do NTP"},{"location":"tempo/1_fisico/#simple-ntp","text":"Vers\u00e3o simplificada do NTP Recomendado para folhas da \u00e1rvore $\\delta = (t_4-t_1)-(t_2-t_3)$ $t = \\frac{(t_2-t_1)+(t3-t_4)}{2}$ $t_c = t_4+t$ Veja um exemplo do ajuste de um rel\u00f3gio usando SNTP.","title":"Simple NTP"},{"location":"tempo/1_fisico/#exemplo-do-sntp","text":"$t_1 = 1100, t_2 = 800, t_3=850, t_4=1200$ $t = ((800-1100)+(850-1200))/2 = (-300 -350)/ = -325$ $t_c = 1200-325 = 875$ Mais recentemente foi proposta um novo protocolo de sincroniza\u00e7\u00e3o de rel\u00f3gios com melhor qualidade de serv\u00e7o, Precision Time Protocol, PTP.","title":"Exemplo do SNTP"},{"location":"tempo/1_fisico/#ptp-precision-time-protocol","text":"IEEE 1588 LAN sub $\\mu s$ (versus ordem de $ms$ no NTP) Escolha mestre Administrador Classe do rel\u00f3gio Acur\u00e1cia do rel\u00f3gio Vari\u00e2ncia do rel\u00f3gio Identificador Como algoritmo de Cristian, mas quem ajusta n\u00e3o \u00e9 quem inicia. Assumindo que tenhamos sincronizado os rel\u00f3gios de um sistema computacional, o que podemos fazer agora? H\u00e1 uma s\u00e9rie de problemas interessantes que podem ser resolvidos.","title":"PTP - Precision Time Protocol"},{"location":"tempo/1_fisico/#usos-de-relogios-sincronizados","text":"autentica\u00e7\u00e3o termina\u00e7\u00e3o de transa\u00e7\u00f5es aloca\u00e7\u00e3o de ``leases''. outros exemplos, Liskov, B. Distrib Comput (1993) 6: 211. doi:10.1007/BF02242709 Um exemplo interessante \u00e9 a ordena\u00e7\u00e3o de eventos em um banco de dados. Para entender este problema, considere o seguinte cen\u00e1rio.","title":"Usos de rel\u00f3gios sincronizados"},{"location":"tempo/1_fisico/#sistema-bancario","text":"Se os comandos chegam primeiro para a replica mais pr\u00f3xima e s\u00e3o executados na ordem em que chegam, temos inconsist\u00eancias entre as r\u00e9plicas (p.e., assuma que update 1 \u00e9 \"atualize para 10\" e 2 \u00e9 \"atualize para 20\") Assim, precisamos ordenar os comandos! Nos foquemos em apenas uma r\u00e9plica. Assuma que rel\u00f3gios est\u00e3o perfeitamente sincronizados, que o tempo de propaga\u00e7\u00e3o m\u00e1ximo de uma mensagem \u00e9 $\\tau$, e que toda mensagem/update carrega o timestamp de quando foi enviada consigo. Considere o seguinte proposta: R\u00e9plicas processam mensagens na ordem que foram enviadas, o que pode ser identificado pelos seus timestamps. Em outras palavras, ao receber uma mensagem com timestamp $t$, uma r\u00e9plica espera at\u00e9 ter certeza de que","title":"Sistema Banc\u00e1rio"},{"location":"tempo/1_fisico/#ordenacao-de-requisicoes","text":"Rel\u00f3gios perfeitamente sincronizados $\\tau$. Cliente 1 envia mensagem Update1 no instante $t$. Ao receber Update1 com timestamp $t$, a r\u00e9plica deve esperar para executar o update? O \u00faltimo instante em que qualquer mensagem com timestamp $t' < t$ pode ser recebido pela r\u00e9plica \u00e9 $t+\\tau$, pois qualquer mensagem recebida em $t''> t+\\tau'$, precisa ter sido enviada ap\u00f3s $t$, e portanto ter\u00e1 timestamp $> t$. Implementar este protocolo \u00e9 muito simples: Toda mensagem recebida \u00e9 colocada em uma fila ordenada por timestamp . Quando o rel\u00f3gio marcar um tempo maior que $t + \\tau$, onde $t$ \u00e9 o timestamp da mensagem na cabe\u00e7a da fila, execute tal mensagem e a retire da fila. Entretanto, este protocolo n\u00e3o leva em considera\u00e7\u00e3o a dessincroniza\u00e7\u00e3o inerente dos rel\u00f3gios em um sistema distribu\u00eddo. Como faz\u00ea-lo, supondo uma diverg\u00eancia m\u00e1xima de $\\Delta$ entre quaisquer dois rel\u00f3gios, algo que pode ser arranjado, como visto antes, sincronizando-se os rel\u00f3gios a cada $\\frac{\\Delta}{2*\\rho}$. Se $\\Delta$ \u00e9 a diferen\u00e7a m\u00e1xima entre rel\u00f3gios, ent\u00e3o ap\u00f3s o uma mensagem ser enviada com timestamp $t$, at\u00e9 $\\Delta$ depois, outro processo, atrasado em rela\u00e7\u00e3o ao primeiro, poder\u00e1 enviar uma mensagem com timestamp $t' < t$. Tal mensagem pode demorar at\u00e9 $\\tau$ para ser entregue \u00e0 r\u00e9plica, ou seja, no instante $t + \\tau + \\Delta$, do ponto de vista do primeiro cliente. Se a r\u00e9plica estiver sincronizada com cliente, ent\u00e3o se esperar at\u00e9 $t + \\tau + \\Delta$ para executar o comando, o far\u00e1 de forma segura. Se estiver atrasada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o acabar\u00e1 por esperar al\u00e9m do necess\u00e1rio, mas sem violar a corretude do sistema. Finalmente, se a r\u00e9plica estiver adiantada em rela\u00e7\u00e3o ao primeiro cliente, ent\u00e3o seu rel\u00f3gio alcan\u00e7ar\u00e1 $t + \\tau + \\Delta$ antes do rel\u00f3gio do primeiro cliente, mas isso n\u00e3o \u00e9 um problema. Isto porqu\u00ea, o \u00faltimo instante em que o cliente 2 poder\u00e1 enviar uma mensagem com timestamp $t' < t$ \u00e9 o instante em que o rel\u00f3gio da r\u00e9plica marcar $t + \\Delta$, e portanto dever\u00e1 tamb\u00e9m ser recebido at\u00e9 que o mesmo rel\u00f3gio marque $t + \\tau + \\Delta$.","title":"Ordena\u00e7\u00e3o de Requisi\u00e7\u00f5es"},{"location":"tempo/1_fisico/#ordenacao-de-requisicoes_1","text":"Rel\u00f3gios dessincronizados $\\tau$. $\\Delta$ O \u00faltimo instante em que qualquer mensagem com timestamp $t' < t$ pode ser recebido pela r\u00e9plica \u00e9 $t+\\tau + \\Delta$, pois qualquer mensagem recebida em $t''> t+\\tau + \\Delta'$, precisa ter sido enviada ap\u00f3s $t+\\Delta$, e portanto ter\u00e1 timestamp $> t$. O mesmo racioc\u00ednio pode ser usado para definir um protocolo de acesso recursos para os quais leases s\u00e3o distribu\u00eddos, onde um lease \u00e9 uma permiss\u00e3o de acesso durante uma janela de tempo, emitida por um coordenador (possivelmente eleito usando os algoritmos vistos anteriormente), e $\\Delta$ \u00e9 o m\u00e1ximo de dessincronismo entre os rel\u00f3gios. O seguinte protocolo resolve este problema:","title":"Ordena\u00e7\u00e3o de Requisi\u00e7\u00f5es"},{"location":"tempo/1_fisico/#lease","text":"$\\Delta$ - dessincroniza\u00e7\u00e3o m\u00e1xima. Ao receber um lease para a janela de tempo $t_1$ a $t_2$ espera at\u00e9 $t_1 + \\Delta$ usa o recurso at\u00e9 $t_2$. Se rel\u00f3gio estiver adiantado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 $t_1+\\Delta$ enquanto o anterior acha que \u00e9 $t_1$; exclus\u00e3o m\u00fatua garantida. Se rel\u00f3gio estiver atrasado em rela\u00e7\u00e3o ao cliente anterior, vai achar que \u00e9 $t_1 - \\Delta$, e continua esperando, enquanto ele acha que j\u00e1 \u00e9 $t_1$ e para de usar; exclus\u00e3o m\u00fatua garantida. Recurso fica ocioso por $\\Delta$, em m\u00e9dia, a cada lease. Devido ao alto custo de se manter o recurso n\u00e3o utilizado, $\\Delta$ deve ser feito t\u00e3o pequeno quanto poss\u00edvel. Leia Google True Time e Spanner para como o Google consegue manter a diferen\u00e7a em sub milisegundos, usando rel\u00f3gios at\u00f4micos dentro de seus datacenters e um API para gera\u00e7\u00e3o de timestamps.","title":"Lease"},{"location":"tempo/2_logico/","text":"Rel\u00f3gio L\u00f3gicos Nas solu\u00e7\u00f5es anteriores, um n\u00f3 precisa esperar por muito tempo antes de usar um recurso. E se ele aprendesse antes que os outros n\u00f3s n\u00e3o far\u00e3o requisi\u00e7\u00f5es? Que n\u00e3o haver\u00e3o sobreposi\u00e7\u00f5es de requisi\u00e7\u00f5es? E se houvesse um rel\u00f3gio que avan\u00e7asse n\u00e3o com o tempo, mas com eventos interessantes do sistema? Esta \u00e9 a ideia dos rel\u00f3gios l\u00f3gicos . Rel\u00f3gios L\u00f3gicos Envio e recep\u00e7\u00e3o (e possivelmente outros eventos) fazem o rel\u00f3gio ``ticar''. Processos podem usar este rel\u00f3gio para concordar na ordem dos eventos, mesmo que n\u00e3o no instante do evento. N\u00e3o h\u00e1 fonte da verdade em termos de tempo. Cada processo mant\u00e9m seu pr\u00f3prio rel\u00f3gio que pode ser relacionado com rel\u00f3gios de outros processos. Para chegarmos aos rel\u00f3gios l\u00f3gicos, precisamos primeiro entender a rela\u00e7\u00e3o Happened-Before , proposta por Leslie Lamport em Time, Clocks and the Ordering of Events in a Distributed System. July 5, 1978 , que lhe rendeu um Pr\u00eamio Turing em 2014 . Neste artigo, se estabelece o vocabul\u00e1rio para falar sobre ordem de eventos em um sistema computacional, em especial um distribu\u00eddo. Happened-Before $a \\rightarrow b$: evento $a$ aconteceu antes do evento $b$ Considerando um \u00fanico processo (thread): Se $a$ foi executado antes de $b$ no processo, ent\u00e3o $a \\rightarrow b$. Considerando dois processos: Se $a$ \u00e9 o envio de uma mensagem e $b$ sua recep\u00e7\u00e3o, ent\u00e3o $a \\rightarrow b$. Transitividade faz sentido: Se $a \\rightarrow b$ e $b \\rightarrow c$, ent\u00e3o $a \\rightarrow c$ Esta rela\u00e7\u00e3o captura a causalidade entre eventos. Isto \u00e9, se $a \\rightarrow b$ ent\u00e3o $a$ potencialmente causou $b$ ($a$ precede $b$ em uma ordem causal). Note que se $a \\rightarrow b$ \u00e9 falso e $b \\rightarrow a$ \u00e9 falso, ent\u00e3o $a$ e $b$ s\u00e3o concorrentes . Se capturarmos a causalidade de eventos, podemos usar esta informa\u00e7\u00e3o para ordenar o se processamento, de forma a fazer sentido. Considere o seguinte exemplo: TODO: Exemplo e emails com pergunta e respostas. Para que computadores possam usar a causalidade, precisamos capturar a rela\u00e7\u00e3o de acontecer antes em um sistema. Lamport prop\u00f4s uma tal forma, que denominou rel\u00f3gio l\u00f3gico, mas que hoje \u00e9 conhecido universalmente como Rel\u00f3gios de Lamport. Estes rel\u00f3gios permitem associar um timestamp a eventos de forma a se garantir a seguinte propriedade: * seja $e$ um evento * seja $C(e)$ o valor do rel\u00f3gio l\u00f3gico quando associado a $e$ * se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$ Mas como definir a fun\u00e7\u00e3o $C$? Experimentemos a seguinte defini\u00e7\u00e3o: * Seja $c_p$ um contador em $p$ com valor inicialmente igual a 0. * $C(e) = c++$ no momento em que $e$ ocorreu. * Usamos como $ < $ a rela\u00e7\u00e3o normal de inteiros. Assim, cada processo conta os eventos executados localmente. Veja um exemplo desta defini\u00e7\u00e3o em a\u00e7\u00e3o. !(LC - Primeira tentativa)(imagess/lc_cont.png) \u00c9 verdade neste cen\u00e1rio que se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$? Observe com aten\u00e7\u00e3o os eventos $f$ e $k$. Para estes, a regra n\u00e3o \u00e9 respeitada. Para que seja, precisamos garantir que, na recep\u00e7\u00e3o de uma mensagem, os contadores sejam atualizados para que sejam maiores tanto que os rel\u00f3gios dos eventos locais quanto dos eventos que antecederam o envio da mensagem sendo recebida. Com este ajuste, temos os Rel\u00f3gios de Lamport. Lamport Clock Seja $c_p$ um contador em $p$ com valor inicialmente igual a 0. Se o evento $e$ \u00e9 uma opera\u00e7\u00e3o local, $C(e) = ++c$ no momento em que $e$ ocorreu. Se o evento $e$ \u00e9 o envio de uma mensagem, ent\u00e3o $C(e)$ \u00e9 enviado com a mensagem como seu timestamp. Se o evento $e$ \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp $ts$, ent\u00e3o $C(e) = max(c,ts)+1$. !(LC - Primeira tentativa)(imagess/lc_lamport.png) Neste caso, temos que para quaisquer eventos $a,b$, se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$. TODO: Exemplo em que n\u00e3o \u00e9 bom o suficiente. Se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$. Contudo, a volta n\u00e3o \u00e9 verdade, isto \u00e9, se $C(a) < C(b)$ ent\u00e3o $a \\rightarrow b$. Esta propriedade \u00e9 interessante na ordena\u00e7\u00e3o de eventos, pois evita que eventos concorrentes sejam ordenados. Entram os rel\u00f3gios vetoriais. Rel\u00f3gio vetorial Sejam $n$ processos. No processo $p$ * Seja $c_p[i], 1 \\leq i \\leq n$ um contador, inicialmente igual a 0. * Se o evento $e$ \u00e9 uma opera\u00e7\u00e3o local, $c_p[p]++$ e $C(e) = c_p$ no momento em que $e$ ocorreu. * Se o evento $e$ \u00e9 o envio de uma mensagem, ent\u00e3o $C(e)$ \u00e9 enviado com a mensagem como seu timestamp. * Se o evento $e$ \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp $ts$ de $q$, ent\u00e3o * $c_p[i] = max(c_p[i], ts[i]), i \\neq p$ * $c_p[p]++$ * $C(e) = c_p$ !(Rel\u00f3gio Vetorial)[images/lc_vc.png] Como dito, este rel\u00f3gio l\u00f3gico tem a seguinte propriedade: se $a \\rightarrow b \\RightLeftArrow C(a) < C(b)$. Mas como \u00e9 defido $ < $ para vetores? * $V = V' \\iff V[i] = V'[i], 1 \\leq i \\leq n$ * $V \\leq V' \\iff V[i] \\leq V'[i], 1 \\leq i \\leq n$ Sejam dois eventos $e$ e $e'$ * Se $e \\rightarrow e' \\iff V(e) < V(e')$ * Se $V(e) \\not\\leq V(e')$ e $V(e') \\not\\leq V(e)$, s\u00e3o concorrentes. Mas o que quer dizer $c_p[q] = k$? Quer dizer que $p$ sabe que $q$ enviou $k$ mensagens. E da\u00ed? O que pode ser feito com isso? Com estes mecanismos \u00e9 poss\u00edvel implementar * Multicast Totalmente Ordenado: * Multicast: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) * Totalmente Ordenado: todos os processos entregam as mensagens na mesma ordem * Multicast Causalmente Ordenado: * Causalmente Ordenado: uma mensagem s\u00f3 \u00e9 entregue se todas as que causalmente a precedem j\u00e1 foram entregues. Novamente voc\u00ea pergunta, e da\u00ed? Bem, com estas abstra\u00e7\u00f5es, podemos resolver problemas interessantes como o seguinte. Considere um programa qualquer, que se comporte de forma determin\u00edstica (isto \u00e9, dada uma mesma entrada, gera sempre uma mesma sa\u00edda). Como todo programa, este \u00e9 uma m\u00e1quina de estados, com a peculiaridade de ser determin\u00edstica. Logo, se tivermos v\u00e1rias c\u00f3pias deste programa, executando em locais distintos, mas garantirmos que cada c\u00f3pia ver\u00e1 exatamente a mesma entrada de dados, ent\u00e3o garantiremos que todas as c\u00f3pias transitar\u00e3o pelos mesmos estados e chegar\u00e3o ao mesmo estado final. Acontece que multicast totalmente ordenado pode garantir exatamente isso, que todas as c\u00f3pias receber\u00e3o a mesma entrada. !(State Machine Replication)[images/06-11.png] Esta t\u00e9cnica \u00e9 conhecida como Replica\u00e7\u00e3o de Ma\u00e1quinas de Estados (em ingl\u00eas, ( State Machine Replication )[https://en.wikipedia.org/wiki/State_machine_replication]), ou pelo menos o seu princ\u00edpio. Mas como podemos implementar estas primitivas de multicast usando rel\u00f3gios l\u00f3gicos? Considere o seguinte algoritmo. Multicast totalmente ordenado Fila com prioridade em cada processo. Mensagens s\u00e3o enviadas a todos os processos e colocadas em uma fila local. Mensagens recebidas s\u00e3o colocadas na fila local e ack \u00e9 enviado de volta. $p$ s\u00f3 entrega uma mensagem $m$ recebida de $q$, com timestamp $ts$ quando $m$ est\u00e1 na cabe\u00e7a da fila de $p$ Para cada processo $q$, h\u00e1 uma mensagem $m'$ de $q$, $ts'$, na fila de $p$ tal $ts < ts'$ Canais confi\u00e1veis e FIFO. Multicast causalmente ordenado Mensagens s\u00e3o enviadas a todos os processos. $p$ incrementa $c_p[p]$ somente no envio de mensagens. $p$ s\u00f3 entrega uma mensagem recebida de $q$, com timestamp $ts$ quando $ts[q] = c_p[q]+1$ $ts[k] \\leq c_p[k], k \\neq q$ \\includegraphics[width=.5\\textwidth]{images/06-13} Considere $c_{P_2}[0,2,2]$ e $ts=[1,3,0]$, de $P_0$. O que $P_2$ est\u00e1 esperando? Como age ao receber mensagem com $ts$? Exclusao M\u00fatua Revisitada Retorno \u00e0 exclus\u00e3o m\u00fatua TODO: (Algoritmos de Exclu\u00e3o m\u00fatua baeados em LC)[http://www.cs.cmu.edu/~dga/15-440/F10/lectures/Distributed-Mutual-Exclusion-slides.pdf] TODO: Algoritmo de Lamport, Ricart e agrawalla TODO: Algoritmo de (Maekawa)[https://www.coursera.org/learn/cloud-computing-2/lecture/GMHYN/2-4-maekawas-algorithm-and-wrap-up] Rel\u00f3gios H\u00edbridos TODO: (Google TrueTime)[https://cloud.google.com/spanner/docs/true-time-external-consistency) Hibrid Logical Clocks !(Hibrid Logical Clock)[images/lc_hybrid] Onde se l\u00ea 3,13, leia-se 3,10,3. (Fonte)(http://muratbuffalo.blogspot.com.br/2014/07/hybrid-logical-clocks.html) Interceptadores !(Transparente para a aplica\u00e7\u00e3o)[images/06-10]","title":"Tempo L\u00f3gico"},{"location":"tempo/2_logico/#relogio-logicos","text":"Nas solu\u00e7\u00f5es anteriores, um n\u00f3 precisa esperar por muito tempo antes de usar um recurso. E se ele aprendesse antes que os outros n\u00f3s n\u00e3o far\u00e3o requisi\u00e7\u00f5es? Que n\u00e3o haver\u00e3o sobreposi\u00e7\u00f5es de requisi\u00e7\u00f5es? E se houvesse um rel\u00f3gio que avan\u00e7asse n\u00e3o com o tempo, mas com eventos interessantes do sistema? Esta \u00e9 a ideia dos rel\u00f3gios l\u00f3gicos .","title":"Rel\u00f3gio L\u00f3gicos"},{"location":"tempo/2_logico/#relogios-logicos","text":"Envio e recep\u00e7\u00e3o (e possivelmente outros eventos) fazem o rel\u00f3gio ``ticar''. Processos podem usar este rel\u00f3gio para concordar na ordem dos eventos, mesmo que n\u00e3o no instante do evento. N\u00e3o h\u00e1 fonte da verdade em termos de tempo. Cada processo mant\u00e9m seu pr\u00f3prio rel\u00f3gio que pode ser relacionado com rel\u00f3gios de outros processos. Para chegarmos aos rel\u00f3gios l\u00f3gicos, precisamos primeiro entender a rela\u00e7\u00e3o Happened-Before , proposta por Leslie Lamport em Time, Clocks and the Ordering of Events in a Distributed System. July 5, 1978 , que lhe rendeu um Pr\u00eamio Turing em 2014 . Neste artigo, se estabelece o vocabul\u00e1rio para falar sobre ordem de eventos em um sistema computacional, em especial um distribu\u00eddo.","title":"Rel\u00f3gios L\u00f3gicos"},{"location":"tempo/2_logico/#happened-before","text":"$a \\rightarrow b$: evento $a$ aconteceu antes do evento $b$ Considerando um \u00fanico processo (thread): Se $a$ foi executado antes de $b$ no processo, ent\u00e3o $a \\rightarrow b$. Considerando dois processos: Se $a$ \u00e9 o envio de uma mensagem e $b$ sua recep\u00e7\u00e3o, ent\u00e3o $a \\rightarrow b$. Transitividade faz sentido: Se $a \\rightarrow b$ e $b \\rightarrow c$, ent\u00e3o $a \\rightarrow c$ Esta rela\u00e7\u00e3o captura a causalidade entre eventos. Isto \u00e9, se $a \\rightarrow b$ ent\u00e3o $a$ potencialmente causou $b$ ($a$ precede $b$ em uma ordem causal). Note que se $a \\rightarrow b$ \u00e9 falso e $b \\rightarrow a$ \u00e9 falso, ent\u00e3o $a$ e $b$ s\u00e3o concorrentes . Se capturarmos a causalidade de eventos, podemos usar esta informa\u00e7\u00e3o para ordenar o se processamento, de forma a fazer sentido. Considere o seguinte exemplo: TODO: Exemplo e emails com pergunta e respostas. Para que computadores possam usar a causalidade, precisamos capturar a rela\u00e7\u00e3o de acontecer antes em um sistema. Lamport prop\u00f4s uma tal forma, que denominou rel\u00f3gio l\u00f3gico, mas que hoje \u00e9 conhecido universalmente como Rel\u00f3gios de Lamport. Estes rel\u00f3gios permitem associar um timestamp a eventos de forma a se garantir a seguinte propriedade: * seja $e$ um evento * seja $C(e)$ o valor do rel\u00f3gio l\u00f3gico quando associado a $e$ * se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$ Mas como definir a fun\u00e7\u00e3o $C$? Experimentemos a seguinte defini\u00e7\u00e3o: * Seja $c_p$ um contador em $p$ com valor inicialmente igual a 0. * $C(e) = c++$ no momento em que $e$ ocorreu. * Usamos como $ < $ a rela\u00e7\u00e3o normal de inteiros. Assim, cada processo conta os eventos executados localmente. Veja um exemplo desta defini\u00e7\u00e3o em a\u00e7\u00e3o. !(LC - Primeira tentativa)(imagess/lc_cont.png) \u00c9 verdade neste cen\u00e1rio que se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$? Observe com aten\u00e7\u00e3o os eventos $f$ e $k$. Para estes, a regra n\u00e3o \u00e9 respeitada. Para que seja, precisamos garantir que, na recep\u00e7\u00e3o de uma mensagem, os contadores sejam atualizados para que sejam maiores tanto que os rel\u00f3gios dos eventos locais quanto dos eventos que antecederam o envio da mensagem sendo recebida. Com este ajuste, temos os Rel\u00f3gios de Lamport.","title":"Happened-Before"},{"location":"tempo/2_logico/#lamport-clock","text":"Seja $c_p$ um contador em $p$ com valor inicialmente igual a 0. Se o evento $e$ \u00e9 uma opera\u00e7\u00e3o local, $C(e) = ++c$ no momento em que $e$ ocorreu. Se o evento $e$ \u00e9 o envio de uma mensagem, ent\u00e3o $C(e)$ \u00e9 enviado com a mensagem como seu timestamp. Se o evento $e$ \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp $ts$, ent\u00e3o $C(e) = max(c,ts)+1$. !(LC - Primeira tentativa)(imagess/lc_lamport.png) Neste caso, temos que para quaisquer eventos $a,b$, se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$. TODO: Exemplo em que n\u00e3o \u00e9 bom o suficiente. Se $a \\rightarrow b$ ent\u00e3o $C(a) < C(b)$. Contudo, a volta n\u00e3o \u00e9 verdade, isto \u00e9, se $C(a) < C(b)$ ent\u00e3o $a \\rightarrow b$. Esta propriedade \u00e9 interessante na ordena\u00e7\u00e3o de eventos, pois evita que eventos concorrentes sejam ordenados. Entram os rel\u00f3gios vetoriais.","title":"Lamport Clock"},{"location":"tempo/2_logico/#relogio-vetorial","text":"Sejam $n$ processos. No processo $p$ * Seja $c_p[i], 1 \\leq i \\leq n$ um contador, inicialmente igual a 0. * Se o evento $e$ \u00e9 uma opera\u00e7\u00e3o local, $c_p[p]++$ e $C(e) = c_p$ no momento em que $e$ ocorreu. * Se o evento $e$ \u00e9 o envio de uma mensagem, ent\u00e3o $C(e)$ \u00e9 enviado com a mensagem como seu timestamp. * Se o evento $e$ \u00e9 a recep\u00e7\u00e3o de uma mensagem com timestamp $ts$ de $q$, ent\u00e3o * $c_p[i] = max(c_p[i], ts[i]), i \\neq p$ * $c_p[p]++$ * $C(e) = c_p$ !(Rel\u00f3gio Vetorial)[images/lc_vc.png] Como dito, este rel\u00f3gio l\u00f3gico tem a seguinte propriedade: se $a \\rightarrow b \\RightLeftArrow C(a) < C(b)$. Mas como \u00e9 defido $ < $ para vetores? * $V = V' \\iff V[i] = V'[i], 1 \\leq i \\leq n$ * $V \\leq V' \\iff V[i] \\leq V'[i], 1 \\leq i \\leq n$ Sejam dois eventos $e$ e $e'$ * Se $e \\rightarrow e' \\iff V(e) < V(e')$ * Se $V(e) \\not\\leq V(e')$ e $V(e') \\not\\leq V(e)$, s\u00e3o concorrentes. Mas o que quer dizer $c_p[q] = k$? Quer dizer que $p$ sabe que $q$ enviou $k$ mensagens. E da\u00ed? O que pode ser feito com isso? Com estes mecanismos \u00e9 poss\u00edvel implementar * Multicast Totalmente Ordenado: * Multicast: mensagens s\u00e3o enviadas de 1 para n (comunica\u00e7\u00e3o em grupo) * Totalmente Ordenado: todos os processos entregam as mensagens na mesma ordem * Multicast Causalmente Ordenado: * Causalmente Ordenado: uma mensagem s\u00f3 \u00e9 entregue se todas as que causalmente a precedem j\u00e1 foram entregues. Novamente voc\u00ea pergunta, e da\u00ed? Bem, com estas abstra\u00e7\u00f5es, podemos resolver problemas interessantes como o seguinte. Considere um programa qualquer, que se comporte de forma determin\u00edstica (isto \u00e9, dada uma mesma entrada, gera sempre uma mesma sa\u00edda). Como todo programa, este \u00e9 uma m\u00e1quina de estados, com a peculiaridade de ser determin\u00edstica. Logo, se tivermos v\u00e1rias c\u00f3pias deste programa, executando em locais distintos, mas garantirmos que cada c\u00f3pia ver\u00e1 exatamente a mesma entrada de dados, ent\u00e3o garantiremos que todas as c\u00f3pias transitar\u00e3o pelos mesmos estados e chegar\u00e3o ao mesmo estado final. Acontece que multicast totalmente ordenado pode garantir exatamente isso, que todas as c\u00f3pias receber\u00e3o a mesma entrada. !(State Machine Replication)[images/06-11.png] Esta t\u00e9cnica \u00e9 conhecida como Replica\u00e7\u00e3o de Ma\u00e1quinas de Estados (em ingl\u00eas, ( State Machine Replication )[https://en.wikipedia.org/wiki/State_machine_replication]), ou pelo menos o seu princ\u00edpio. Mas como podemos implementar estas primitivas de multicast usando rel\u00f3gios l\u00f3gicos? Considere o seguinte algoritmo.","title":"Rel\u00f3gio vetorial"},{"location":"tempo/2_logico/#multicast-totalmente-ordenado","text":"Fila com prioridade em cada processo. Mensagens s\u00e3o enviadas a todos os processos e colocadas em uma fila local. Mensagens recebidas s\u00e3o colocadas na fila local e ack \u00e9 enviado de volta. $p$ s\u00f3 entrega uma mensagem $m$ recebida de $q$, com timestamp $ts$ quando $m$ est\u00e1 na cabe\u00e7a da fila de $p$ Para cada processo $q$, h\u00e1 uma mensagem $m'$ de $q$, $ts'$, na fila de $p$ tal $ts < ts'$ Canais confi\u00e1veis e FIFO.","title":"Multicast totalmente ordenado"},{"location":"tempo/2_logico/#multicast-causalmente-ordenado","text":"Mensagens s\u00e3o enviadas a todos os processos. $p$ incrementa $c_p[p]$ somente no envio de mensagens. $p$ s\u00f3 entrega uma mensagem recebida de $q$, com timestamp $ts$ quando $ts[q] = c_p[q]+1$ $ts[k] \\leq c_p[k], k \\neq q$ \\includegraphics[width=.5\\textwidth]{images/06-13} Considere $c_{P_2}[0,2,2]$ e $ts=[1,3,0]$, de $P_0$. O que $P_2$ est\u00e1 esperando? Como age ao receber mensagem com $ts$?","title":"Multicast causalmente ordenado"},{"location":"tempo/2_logico/#exclusao-mutua-revisitada","text":"Retorno \u00e0 exclus\u00e3o m\u00fatua TODO: (Algoritmos de Exclu\u00e3o m\u00fatua baeados em LC)[http://www.cs.cmu.edu/~dga/15-440/F10/lectures/Distributed-Mutual-Exclusion-slides.pdf] TODO: Algoritmo de Lamport, Ricart e agrawalla TODO: Algoritmo de (Maekawa)[https://www.coursera.org/learn/cloud-computing-2/lecture/GMHYN/2-4-maekawas-algorithm-and-wrap-up]","title":"Exclusao M\u00fatua Revisitada"},{"location":"tempo/2_logico/#relogios-hibridos","text":"TODO: (Google TrueTime)[https://cloud.google.com/spanner/docs/true-time-external-consistency)","title":"Rel\u00f3gios H\u00edbridos"},{"location":"tempo/2_logico/#hibrid-logical-clocks","text":"!(Hibrid Logical Clock)[images/lc_hybrid] Onde se l\u00ea 3,13, leia-se 3,10,3. (Fonte)(http://muratbuffalo.blogspot.com.br/2014/07/hybrid-logical-clocks.html)","title":"Hibrid Logical Clocks"},{"location":"tempo/2_logico/#interceptadores","text":"!(Transparente para a aplica\u00e7\u00e3o)[images/06-10]","title":"Interceptadores"}]}